 > Problema: tomita6nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 1e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 18.609735
 >> iter 2000, loss: 15.095441
 >> iter 3000, loss: 13.769023
 >> iter 4000, loss: 13.276756
 >> iter 5000, loss: 13.077717
 >> iter 6000, loss: 13.005024
 >> iter 7000, loss: 12.964290
 >> iter 8000, loss: 12.955441
 >> iter 9000, loss: 12.938815
 >> iter 10000, loss: 12.943088
   Number of active neurons: 4
 >> iter 11000, loss: 12.929547
 >> iter 12000, loss: 12.934570
 >> iter 13000, loss: 12.922465
 >> iter 14000, loss: 12.927367
 >> iter 15000, loss: 12.750607
 >> iter 16000, loss: 11.937018
 >> iter 17000, loss: 8.326522
 >> iter 18000, loss: 3.154217
 >> iter 19000, loss: 1.194646
 >> iter 20000, loss: 0.462082
   Number of active neurons: 9
 >> iter 21000, loss: 0.187172
 >> iter 22000, loss: 0.082805
 >> iter 23000, loss: 0.042083
 >> iter 24000, loss: 0.025927
 >> iter 25000, loss: 0.018685
 >> iter 26000, loss: 0.015423
 >> iter 27000, loss: 0.013394
 >> iter 28000, loss: 0.012329
 >> iter 29000, loss: 0.011347
 >> iter 30000, loss: 0.010820
   Number of active neurons: 9
 >> iter 31000, loss: 0.010176
 >> iter 32000, loss: 0.009847
 >> iter 33000, loss: 0.009372
 >> iter 34000, loss: 0.009156
 >> iter 35000, loss: 0.008784
 >> iter 36000, loss: 0.008631
 >> iter 37000, loss: 0.008326
 >> iter 38000, loss: 0.008231
 >> iter 39000, loss: 0.007973
 >> iter 40000, loss: 0.007912
   Number of active neurons: 9
 >> iter 41000, loss: 0.007687
 >> iter 42000, loss: 0.007661
 >> iter 43000, loss: 0.007462
 >> iter 44000, loss: 0.007446
 >> iter 45000, loss: 0.007271
 >> iter 46000, loss: 0.007291
 >> iter 47000, loss: 0.007124
 >> iter 48000, loss: 0.007147
 >> iter 49000, loss: 0.007004
 >> iter 50000, loss: 0.007045
   Number of active neurons: 9
 >> iter 51000, loss: 0.006911
 >> iter 52000, loss: 0.006959
 >> iter 53000, loss: 0.006833
 >> iter 54000, loss: 0.006889
 >> iter 55000, loss: 0.006770
 >> iter 56000, loss: 0.006835
 >> iter 57000, loss: 0.006722
 >> iter 58000, loss: 0.006790
 >> iter 59000, loss: 0.006687
 >> iter 60000, loss: 0.006752
   Number of active neurons: 9
 >> iter 61000, loss: 0.006658
 >> iter 62000, loss: 0.006718
 >> iter 63000, loss: 0.006629
 >> iter 64000, loss: 0.006686
 >> iter 65000, loss: 0.006607
 >> iter 66000, loss: 0.006652
 >> iter 67000, loss: 0.006581
 >> iter 68000, loss: 0.006620
 >> iter 69000, loss: 0.006558
 >> iter 70000, loss: 0.006591
   Number of active neurons: 9
 >> iter 71000, loss: 0.006538
 >> iter 72000, loss: 0.006570
 >> iter 73000, loss: 0.006510
 >> iter 74000, loss: 0.006546
 >> iter 75000, loss: 0.006487
 >> iter 76000, loss: 0.006522
 >> iter 77000, loss: 0.006468
 >> iter 78000, loss: 0.006497
 >> iter 79000, loss: 0.006446
 >> iter 80000, loss: 0.006473
   Number of active neurons: 9
 >> iter 81000, loss: 0.006423
 >> iter 82000, loss: 0.006441
 >> iter 83000, loss: 0.006390
 >> iter 84000, loss: 0.006408
 >> iter 85000, loss: 0.006355
 >> iter 86000, loss: 0.006369
 >> iter 87000, loss: 0.006305
 >> iter 88000, loss: 0.006316
 >> iter 89000, loss: 0.006253
 >> iter 90000, loss: 0.006256
   Number of active neurons: 9
 >> iter 91000, loss: 0.006194
 >> iter 92000, loss: 0.006196
 >> iter 93000, loss: 0.006137
 >> iter 94000, loss: 0.006135
 >> iter 95000, loss: 0.006072
 >> iter 96000, loss: 0.006067
 >> iter 97000, loss: 0.006007
 >> iter 98000, loss: 0.005995
 >> iter 99000, loss: 0.005937
 >> iter 100000, loss: 0.005920
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 18.622809
 >> iter 2000, loss: 15.095082
 >> iter 3000, loss: 13.759577
 >> iter 4000, loss: 13.263793
 >> iter 5000, loss: 13.065085
 >> iter 6000, loss: 12.994291
 >> iter 7000, loss: 12.956867
 >> iter 8000, loss: 12.949997
 >> iter 9000, loss: 12.936294
 >> iter 10000, loss: 12.942174
   Number of active neurons: 4
 >> iter 11000, loss: 12.930545
 >> iter 12000, loss: 12.937091
 >> iter 13000, loss: 12.926110
 >> iter 14000, loss: 12.935182
 >> iter 15000, loss: 12.926726
 >> iter 16000, loss: 12.934396
 >> iter 17000, loss: 12.927293
 >> iter 18000, loss: 12.932346
 >> iter 19000, loss: 12.923845
 >> iter 20000, loss: 12.933978
   Number of active neurons: 4
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 4
 >> iter 21000, loss: 12.921739
 >> iter 22000, loss: 12.929269
 >> iter 23000, loss: 12.827455
 >> iter 24000, loss: 12.063074
 >> iter 25000, loss: 8.113223
 >> iter 26000, loss: 3.086712
 >> iter 27000, loss: 1.162363
 >> iter 28000, loss: 0.444891
 >> iter 29000, loss: 0.176865
 >> iter 30000, loss: 0.075848
   Number of active neurons: 8
 >> iter 31000, loss: 0.037158
 >> iter 32000, loss: 0.021875
 >> iter 33000, loss: 0.015460
 >> iter 34000, loss: 0.012531
 >> iter 35000, loss: 0.010964
 >> iter 36000, loss: 0.010047
 >> iter 37000, loss: 0.009382
 >> iter 38000, loss: 0.008919
 >> iter 39000, loss: 0.008510
 >> iter 40000, loss: 0.008219
   Number of active neurons: 8
 >> iter 41000, loss: 0.007926
 >> iter 42000, loss: 0.007728
 >> iter 43000, loss: 0.007505
 >> iter 44000, loss: 0.007363
 >> iter 45000, loss: 0.007188
 >> iter 46000, loss: 0.007085
 >> iter 47000, loss: 0.006942
 >> iter 48000, loss: 0.006865
 >> iter 49000, loss: 0.006747
 >> iter 50000, loss: 0.006695
   Number of active neurons: 8
 >> iter 51000, loss: 0.006594
 >> iter 52000, loss: 0.006558
 >> iter 53000, loss: 0.006468
 >> iter 54000, loss: 0.006447
 >> iter 55000, loss: 0.006364
 >> iter 56000, loss: 0.006353
 >> iter 57000, loss: 0.006276
 >> iter 58000, loss: 0.006271
 >> iter 59000, loss: 0.006199
 >> iter 60000, loss: 0.006200
   Number of active neurons: 8
 >> iter 61000, loss: 0.006132
 >> iter 62000, loss: 0.006134
 >> iter 63000, loss: 0.006068
 >> iter 64000, loss: 0.006072
 >> iter 65000, loss: 0.006012
 >> iter 66000, loss: 0.006014
 >> iter 67000, loss: 0.005963
 >> iter 68000, loss: 0.005966
 >> iter 69000, loss: 0.005916
 >> iter 70000, loss: 0.005920
   Number of active neurons: 8
 >> iter 71000, loss: 0.005878
 >> iter 72000, loss: 0.005890
 >> iter 73000, loss: 0.005851
 >> iter 74000, loss: 0.005870
 >> iter 75000, loss: 0.005829
 >> iter 76000, loss: 0.005850
 >> iter 77000, loss: 0.005808
 >> iter 78000, loss: 0.005830
 >> iter 79000, loss: 0.005787
 >> iter 80000, loss: 0.005810
   Number of active neurons: 8
 >> iter 81000, loss: 0.005763
 >> iter 82000, loss: 0.005784
 >> iter 83000, loss: 0.005735
 >> iter 84000, loss: 0.005757
 >> iter 85000, loss: 0.005708
 >> iter 86000, loss: 0.005731
 >> iter 87000, loss: 0.005683
 >> iter 88000, loss: 0.005708
 >> iter 89000, loss: 0.005661
 >> iter 90000, loss: 0.005686
   Number of active neurons: 8
 >> iter 91000, loss: 0.005641
 >> iter 92000, loss: 0.005667
 >> iter 93000, loss: 0.005622
 >> iter 94000, loss: 0.005640
 >> iter 95000, loss: 0.005595
 >> iter 96000, loss: 0.005618
 >> iter 97000, loss: 0.005575
 >> iter 98000, loss: 0.005597
 >> iter 99000, loss: 0.005555
 >> iter 100000, loss: 0.005575
   Number of active neurons: 8
 >> iter 101000, loss: 0.005535
 >> iter 102000, loss: 0.005556
 >> iter 103000, loss: 0.005518
 >> iter 104000, loss: 0.005537
 >> iter 105000, loss: 0.005502
 >> iter 106000, loss: 0.005521
 >> iter 107000, loss: 0.005487
 >> iter 108000, loss: 0.005507
 >> iter 109000, loss: 0.005472
 >> iter 110000, loss: 0.005493
   Number of active neurons: 8
 >> iter 111000, loss: 0.005457
 >> iter 112000, loss: 0.005483
 >> iter 113000, loss: 0.005443
 >> iter 114000, loss: 0.005469
 >> iter 115000, loss: 0.005429
 >> iter 116000, loss: 0.005456
 >> iter 117000, loss: 0.005418
 >> iter 118000, loss: 0.005441
 >> iter 119000, loss: 0.005405
 >> iter 120000, loss: 0.005427
   Number of active neurons: 8
 >> iter 121000, loss: 0.005391
 >> iter 122000, loss: 0.005412
 >> iter 123000, loss: 0.005378
 >> iter 124000, loss: 0.005398
 >> iter 125000, loss: 0.005361
 >> iter 126000, loss: 0.005381
 >> iter 127000, loss: 0.005344
 >> iter 128000, loss: 0.005361
 >> iter 129000, loss: 0.005323
 >> iter 130000, loss: 0.005339
   Number of active neurons: 8
 >> iter 131000, loss: 0.005302
 >> iter 132000, loss: 0.005320
 >> iter 133000, loss: 0.005283
 >> iter 134000, loss: 0.005302
 >> iter 135000, loss: 0.005262
 >> iter 136000, loss: 0.005282
 >> iter 137000, loss: 0.005243
 >> iter 138000, loss: 0.005262
 >> iter 139000, loss: 0.005223
 >> iter 140000, loss: 0.005245
   Number of active neurons: 8
 >> iter 141000, loss: 0.005205
 >> iter 142000, loss: 0.005229
 >> iter 143000, loss: 0.005189
 >> iter 144000, loss: 0.005214
 >> iter 145000, loss: 0.005174
 >> iter 146000, loss: 0.005195
 >> iter 147000, loss: 0.005155
 >> iter 148000, loss: 0.005176
 >> iter 149000, loss: 0.005137
 >> iter 150000, loss: 0.005156
   Number of active neurons: 8
 >> iter 151000, loss: 0.005114
 >> iter 152000, loss: 0.005131
 >> iter 153000, loss: 0.005091
 >> iter 154000, loss: 0.005107
 >> iter 155000, loss: 0.005070
 >> iter 156000, loss: 0.005083
 >> iter 157000, loss: 0.005046
 >> iter 158000, loss: 0.005065
 >> iter 159000, loss: 0.005032
 >> iter 160000, loss: 0.005037
   Number of active neurons: 8
 >> iter 161000, loss: 0.005003
 >> iter 162000, loss: 0.005015
 >> iter 163000, loss: 0.004983
 >> iter 164000, loss: 0.004989
 >> iter 165000, loss: 0.004958
 >> iter 166000, loss: 0.004971
 >> iter 167000, loss: 0.004943
 >> iter 168000, loss: 0.004951
 >> iter 169000, loss: 0.004925
 >> iter 170000, loss: 0.004936
   Number of active neurons: 8
 >> iter 171000, loss: 0.004906
 >> iter 172000, loss: 0.004913
 >> iter 173000, loss: 0.004884
 >> iter 174000, loss: 0.004896
 >> iter 175000, loss: 0.004866
 >> iter 176000, loss: 0.004875
 >> iter 177000, loss: 0.004846
 >> iter 178000, loss: 0.004860
 >> iter 179000, loss: 0.004828
 >> iter 180000, loss: 0.004841
   Number of active neurons: 8
 >> iter 181000, loss: 0.004811
 >> iter 182000, loss: 0.004826
 >> iter 183000, loss: 0.004798
 >> iter 184000, loss: 0.004812
 >> iter 185000, loss: 0.004784
 >> iter 186000, loss: 0.004803
 >> iter 187000, loss: 0.004772
 >> iter 188000, loss: 0.004791
 >> iter 189000, loss: 0.004761
 >> iter 190000, loss: 0.004784
   Number of active neurons: 7
 >> iter 191000, loss: 0.004752
 >> iter 192000, loss: 0.004777
 >> iter 193000, loss: 0.004746
 >> iter 194000, loss: 0.004770
 >> iter 195000, loss: 0.004742
 >> iter 196000, loss: 0.004765
 >> iter 197000, loss: 0.004738
 >> iter 198000, loss: 0.004760
 >> iter 199000, loss: 0.004735
 >> iter 200000, loss: 0.004758
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.634029
 >> iter 2000, loss: 15.104960
 >> iter 3000, loss: 13.766874
 >> iter 4000, loss: 13.268193
 >> iter 5000, loss: 13.062981
 >> iter 6000, loss: 12.991050
 >> iter 7000, loss: 12.951328
 >> iter 8000, loss: 12.945624
 >> iter 9000, loss: 12.931369
 >> iter 10000, loss: 12.938245
   Number of active neurons: 4
 >> iter 11000, loss: 12.926355
 >> iter 12000, loss: 12.933060
 >> iter 13000, loss: 12.922079
 >> iter 14000, loss: 12.929444
 >> iter 15000, loss: 12.900540
 >> iter 16000, loss: 12.288926
 >> iter 17000, loss: 11.054141
 >> iter 18000, loss: 10.289573
 >> iter 19000, loss: 5.194396
 >> iter 20000, loss: 2.146134
   Number of active neurons: 8
 >> iter 21000, loss: 0.818021
 >> iter 22000, loss: 0.317183
 >> iter 23000, loss: 0.129259
 >> iter 24000, loss: 0.057777
 >> iter 25000, loss: 0.030173
 >> iter 26000, loss: 0.018926
 >> iter 27000, loss: 0.014142
 >> iter 28000, loss: 0.011751
 >> iter 29000, loss: 0.010509
 >> iter 30000, loss: 0.009626
   Number of active neurons: 8
 >> iter 31000, loss: 0.009087
 >> iter 32000, loss: 0.008576
 >> iter 33000, loss: 0.008257
 >> iter 34000, loss: 0.007892
 >> iter 35000, loss: 0.007675
 >> iter 36000, loss: 0.007395
 >> iter 37000, loss: 0.007254
 >> iter 38000, loss: 0.007025
 >> iter 39000, loss: 0.006931
 >> iter 40000, loss: 0.006741
   Number of active neurons: 8
 >> iter 41000, loss: 0.006679
 >> iter 42000, loss: 0.006518
 >> iter 43000, loss: 0.006478
 >> iter 44000, loss: 0.006341
 >> iter 45000, loss: 0.006318
 >> iter 46000, loss: 0.006199
 >> iter 47000, loss: 0.006191
 >> iter 48000, loss: 0.006083
 >> iter 49000, loss: 0.006088
 >> iter 50000, loss: 0.005990
   Number of active neurons: 8
 >> iter 51000, loss: 0.006001
 >> iter 52000, loss: 0.005910
 >> iter 53000, loss: 0.005929
 >> iter 54000, loss: 0.005845
 >> iter 55000, loss: 0.005866
 >> iter 56000, loss: 0.005787
 >> iter 57000, loss: 0.005811
 >> iter 58000, loss: 0.005732
 >> iter 59000, loss: 0.005759
 >> iter 60000, loss: 0.005686
   Number of active neurons: 8
 >> iter 61000, loss: 0.005715
 >> iter 62000, loss: 0.005648
 >> iter 63000, loss: 0.005677
 >> iter 64000, loss: 0.005613
 >> iter 65000, loss: 0.005643
 >> iter 66000, loss: 0.005582
 >> iter 67000, loss: 0.005611
 >> iter 68000, loss: 0.005552
 >> iter 69000, loss: 0.005582
 >> iter 70000, loss: 0.005527
   Number of active neurons: 8
 >> iter 71000, loss: 0.005556
 >> iter 72000, loss: 0.005503
 >> iter 73000, loss: 0.005532
 >> iter 74000, loss: 0.005479
 >> iter 75000, loss: 0.005508
 >> iter 76000, loss: 0.005455
 >> iter 77000, loss: 0.005484
 >> iter 78000, loss: 0.005430
 >> iter 79000, loss: 0.005468
 >> iter 80000, loss: 0.005407
   Number of active neurons: 8
 >> iter 81000, loss: 0.005445
 >> iter 82000, loss: 0.005389
 >> iter 83000, loss: 0.005426
 >> iter 84000, loss: 0.005371
 >> iter 85000, loss: 0.005408
 >> iter 86000, loss: 0.005352
 >> iter 87000, loss: 0.005401
 >> iter 88000, loss: 0.005336
 >> iter 89000, loss: 0.005386
 >> iter 90000, loss: 0.005320
   Number of active neurons: 8
 >> iter 91000, loss: 0.005370
 >> iter 92000, loss: 0.005305
 >> iter 93000, loss: 0.005357
 >> iter 94000, loss: 0.005294
 >> iter 95000, loss: 0.005343
 >> iter 96000, loss: 0.005275
 >> iter 97000, loss: 0.005323
 >> iter 98000, loss: 0.005255
 >> iter 99000, loss: 0.005305
 >> iter 100000, loss: 0.005235
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.624034
 >> iter 2000, loss: 15.114135
 >> iter 3000, loss: 13.784574
 >> iter 4000, loss: 13.287278
 >> iter 5000, loss: 13.086060
 >> iter 6000, loss: 13.011960
 >> iter 7000, loss: 12.973216
 >> iter 8000, loss: 12.964678
 >> iter 9000, loss: 12.950715
 >> iter 10000, loss: 12.955663
   Number of active neurons: 5
 >> iter 11000, loss: 12.944277
 >> iter 12000, loss: 12.949942
 >> iter 13000, loss: 12.939548
 >> iter 14000, loss: 12.947074
 >> iter 15000, loss: 12.939170
 >> iter 16000, loss: 12.927663
 >> iter 17000, loss: 12.599717
 >> iter 18000, loss: 11.715463
 >> iter 19000, loss: 4.471074
 >> iter 20000, loss: 1.672180
   Number of active neurons: 7
 >> iter 21000, loss: 0.631659
 >> iter 22000, loss: 0.244257
 >> iter 23000, loss: 0.099423
 >> iter 24000, loss: 0.044617
 >> iter 25000, loss: 0.023501
 >> iter 26000, loss: 0.015007
 >> iter 27000, loss: 0.011378
 >> iter 28000, loss: 0.009629
 >> iter 29000, loss: 0.008681
 >> iter 30000, loss: 0.008060
   Number of active neurons: 7
 >> iter 31000, loss: 0.007634
 >> iter 32000, loss: 0.007293
 >> iter 33000, loss: 0.007022
 >> iter 34000, loss: 0.006791
 >> iter 35000, loss: 0.006601
 >> iter 36000, loss: 0.006433
 >> iter 37000, loss: 0.006299
 >> iter 38000, loss: 0.006178
 >> iter 39000, loss: 0.006076
 >> iter 40000, loss: 0.005983
   Number of active neurons: 7
 >> iter 41000, loss: 0.005907
 >> iter 42000, loss: 0.005827
 >> iter 43000, loss: 0.005767
 >> iter 44000, loss: 0.005703
 >> iter 45000, loss: 0.005653
 >> iter 46000, loss: 0.005600
 >> iter 47000, loss: 0.005558
 >> iter 48000, loss: 0.005513
 >> iter 49000, loss: 0.005477
 >> iter 50000, loss: 0.005439
   Number of active neurons: 7
 >> iter 51000, loss: 0.005408
 >> iter 52000, loss: 0.005374
 >> iter 53000, loss: 0.005347
 >> iter 54000, loss: 0.005319
 >> iter 55000, loss: 0.005296
 >> iter 56000, loss: 0.005272
 >> iter 57000, loss: 0.005256
 >> iter 58000, loss: 0.005231
 >> iter 59000, loss: 0.005218
 >> iter 60000, loss: 0.005195
   Number of active neurons: 7
 >> iter 61000, loss: 0.005187
 >> iter 62000, loss: 0.005165
 >> iter 63000, loss: 0.005158
 >> iter 64000, loss: 0.005136
 >> iter 65000, loss: 0.005134
 >> iter 66000, loss: 0.005111
 >> iter 67000, loss: 0.005113
 >> iter 68000, loss: 0.005089
 >> iter 69000, loss: 0.005093
 >> iter 70000, loss: 0.005069
   Number of active neurons: 7
 >> iter 71000, loss: 0.005074
 >> iter 72000, loss: 0.005050
 >> iter 73000, loss: 0.005057
 >> iter 74000, loss: 0.005032
 >> iter 75000, loss: 0.005038
 >> iter 76000, loss: 0.005011
 >> iter 77000, loss: 0.005020
 >> iter 78000, loss: 0.004992
 >> iter 79000, loss: 0.005003
 >> iter 80000, loss: 0.004973
   Number of active neurons: 7
 >> iter 81000, loss: 0.004987
 >> iter 82000, loss: 0.004954
 >> iter 83000, loss: 0.004966
 >> iter 84000, loss: 0.004931
 >> iter 85000, loss: 0.004942
 >> iter 86000, loss: 0.004904
 >> iter 87000, loss: 0.004917
 >> iter 88000, loss: 0.004878
 >> iter 89000, loss: 0.004896
 >> iter 90000, loss: 0.004859
   Number of active neurons: 7
 >> iter 91000, loss: 0.004878
 >> iter 92000, loss: 0.004843
 >> iter 93000, loss: 0.004862
 >> iter 94000, loss: 0.004827
 >> iter 95000, loss: 0.004848
 >> iter 96000, loss: 0.004814
 >> iter 97000, loss: 0.004835
 >> iter 98000, loss: 0.004802
 >> iter 99000, loss: 0.004821
 >> iter 100000, loss: 0.004785
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.619123
 >> iter 2000, loss: 15.098636
 >> iter 3000, loss: 13.761212
 >> iter 4000, loss: 13.263831
 >> iter 5000, loss: 13.066329
 >> iter 6000, loss: 12.996109
 >> iter 7000, loss: 12.960703
 >> iter 8000, loss: 12.954556
 >> iter 9000, loss: 12.942818
 >> iter 10000, loss: 12.948495
   Number of active neurons: 5
 >> iter 11000, loss: 12.938519
 >> iter 12000, loss: 12.942684
 >> iter 13000, loss: 12.929425
 >> iter 14000, loss: 12.722675
 >> iter 15000, loss: 9.066235
 >> iter 16000, loss: 3.399706
 >> iter 17000, loss: 1.280213
 >> iter 18000, loss: 0.490762
 >> iter 19000, loss: 0.195556
 >> iter 20000, loss: 0.084250
   Number of active neurons: 6
 >> iter 21000, loss: 0.041405
 >> iter 22000, loss: 0.024401
 >> iter 23000, loss: 0.017129
 >> iter 24000, loss: 0.013756
 >> iter 25000, loss: 0.011883
 >> iter 26000, loss: 0.010755
 >> iter 27000, loss: 0.009913
 >> iter 28000, loss: 0.009305
 >> iter 29000, loss: 0.008777
 >> iter 30000, loss: 0.008366
   Number of active neurons: 6
 >> iter 31000, loss: 0.007989
 >> iter 32000, loss: 0.007687
 >> iter 33000, loss: 0.007404
 >> iter 34000, loss: 0.007170
 >> iter 35000, loss: 0.006950
 >> iter 36000, loss: 0.006764
 >> iter 37000, loss: 0.006591
 >> iter 38000, loss: 0.006441
 >> iter 39000, loss: 0.006301
 >> iter 40000, loss: 0.006176
   Number of active neurons: 6
 >> iter 41000, loss: 0.006063
 >> iter 42000, loss: 0.005953
 >> iter 43000, loss: 0.005860
 >> iter 44000, loss: 0.005767
 >> iter 45000, loss: 0.005690
 >> iter 46000, loss: 0.005608
 >> iter 47000, loss: 0.005544
 >> iter 48000, loss: 0.005470
 >> iter 49000, loss: 0.005416
 >> iter 50000, loss: 0.005351
   Number of active neurons: 6
 >> iter 51000, loss: 0.005308
 >> iter 52000, loss: 0.005251
 >> iter 53000, loss: 0.005218
 >> iter 54000, loss: 0.005170
 >> iter 55000, loss: 0.005145
 >> iter 56000, loss: 0.005102
 >> iter 57000, loss: 0.005085
 >> iter 58000, loss: 0.005044
 >> iter 59000, loss: 0.005032
 >> iter 60000, loss: 0.004993
   Number of active neurons: 6
 >> iter 61000, loss: 0.004984
 >> iter 62000, loss: 0.004945
 >> iter 63000, loss: 0.004935
 >> iter 64000, loss: 0.004897
 >> iter 65000, loss: 0.004888
 >> iter 66000, loss: 0.004851
 >> iter 67000, loss: 0.004842
 >> iter 68000, loss: 0.004804
 >> iter 69000, loss: 0.004796
 >> iter 70000, loss: 0.004759
   Number of active neurons: 6
 >> iter 71000, loss: 0.004752
 >> iter 72000, loss: 0.004717
 >> iter 73000, loss: 0.004709
 >> iter 74000, loss: 0.004677
 >> iter 75000, loss: 0.004669
 >> iter 76000, loss: 0.004638
 >> iter 77000, loss: 0.004633
 >> iter 78000, loss: 0.004601
 >> iter 79000, loss: 0.004596
 >> iter 80000, loss: 0.004565
   Number of active neurons: 6
 >> iter 81000, loss: 0.004561
 >> iter 82000, loss: 0.004532
 >> iter 83000, loss: 0.004528
 >> iter 84000, loss: 0.004499
 >> iter 85000, loss: 0.004497
 >> iter 86000, loss: 0.004468
 >> iter 87000, loss: 0.004467
 >> iter 88000, loss: 0.004437
 >> iter 89000, loss: 0.004437
 >> iter 90000, loss: 0.004408
   Number of active neurons: 6
 >> iter 91000, loss: 0.004409
 >> iter 92000, loss: 0.004379
 >> iter 93000, loss: 0.004380
 >> iter 94000, loss: 0.004351
 >> iter 95000, loss: 0.004353
 >> iter 96000, loss: 0.004324
 >> iter 97000, loss: 0.004326
 >> iter 98000, loss: 0.004299
 >> iter 99000, loss: 0.004299
 >> iter 100000, loss: 0.004273
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.605142
 >> iter 2000, loss: 15.088047
 >> iter 3000, loss: 13.756082
 >> iter 4000, loss: 13.262155
 >> iter 5000, loss: 13.066666
 >> iter 6000, loss: 12.996972
 >> iter 7000, loss: 12.961956
 >> iter 8000, loss: 12.955846
 >> iter 9000, loss: 12.944262
 >> iter 10000, loss: 12.950188
   Number of active neurons: 5
 >> iter 11000, loss: 12.940309
 >> iter 12000, loss: 12.945822
 >> iter 13000, loss: 12.936516
 >> iter 14000, loss: 12.936930
 >> iter 15000, loss: 12.666689
 >> iter 16000, loss: 7.832737
 >> iter 17000, loss: 3.006670
 >> iter 18000, loss: 1.155686
 >> iter 19000, loss: 0.457718
 >> iter 20000, loss: 0.193109
   Number of active neurons: 7
 >> iter 21000, loss: 0.090898
 >> iter 22000, loss: 0.050363
 >> iter 23000, loss: 0.033135
 >> iter 24000, loss: 0.025322
 >> iter 25000, loss: 0.021107
 >> iter 26000, loss: 0.018691
 >> iter 27000, loss: 0.016935
 >> iter 28000, loss: 0.015732
 >> iter 29000, loss: 0.014683
 >> iter 30000, loss: 0.013906
   Number of active neurons: 7
 >> iter 31000, loss: 0.013175
 >> iter 32000, loss: 0.012621
 >> iter 33000, loss: 0.012081
 >> iter 34000, loss: 0.011662
 >> iter 35000, loss: 0.011251
 >> iter 36000, loss: 0.010923
 >> iter 37000, loss: 0.010604
 >> iter 38000, loss: 0.010341
 >> iter 39000, loss: 0.010091
 >> iter 40000, loss: 0.009875
   Number of active neurons: 7
 >> iter 41000, loss: 0.009684
 >> iter 42000, loss: 0.009501
 >> iter 43000, loss: 0.009322
 >> iter 44000, loss: 0.009161
 >> iter 45000, loss: 0.010443
 >> iter 46000, loss: 0.010181
 >> iter 47000, loss: 0.009314
 >> iter 48000, loss: 0.008819
 >> iter 49000, loss: 0.008523
 >> iter 50000, loss: 0.008368
   Number of active neurons: 7
 >> iter 51000, loss: 0.008241
 >> iter 52000, loss: 0.008168
 >> iter 53000, loss: 0.008090
 >> iter 54000, loss: 0.008040
 >> iter 55000, loss: 0.007960
 >> iter 56000, loss: 0.007939
 >> iter 57000, loss: 0.007852
 >> iter 58000, loss: 0.007844
 >> iter 59000, loss: 0.007758
 >> iter 60000, loss: 0.007752
   Number of active neurons: 7
 >> iter 61000, loss: 0.007668
 >> iter 62000, loss: 0.007668
 >> iter 63000, loss: 0.007587
 >> iter 64000, loss: 0.007591
 >> iter 65000, loss: 0.007516
 >> iter 66000, loss: 0.007516
 >> iter 67000, loss: 0.007454
 >> iter 68000, loss: 0.007451
 >> iter 69000, loss: 0.007397
 >> iter 70000, loss: 0.007392
   Number of active neurons: 7
 >> iter 71000, loss: 0.007345
 >> iter 72000, loss: 0.007338
 >> iter 73000, loss: 0.007297
 >> iter 74000, loss: 0.007292
 >> iter 75000, loss: 0.007258
 >> iter 76000, loss: 0.007254
 >> iter 77000, loss: 0.007228
 >> iter 78000, loss: 0.007220
 >> iter 79000, loss: 0.007198
 >> iter 80000, loss: 0.007190
   Number of active neurons: 7
 >> iter 81000, loss: 0.007174
 >> iter 82000, loss: 0.007164
 >> iter 83000, loss: 0.007151
 >> iter 84000, loss: 0.007142
 >> iter 85000, loss: 0.007132
 >> iter 86000, loss: 0.007123
 >> iter 87000, loss: 0.007112
 >> iter 88000, loss: 0.007105
 >> iter 89000, loss: 0.007091
 >> iter 90000, loss: 0.007085
   Number of active neurons: 7
 >> iter 91000, loss: 0.007066
 >> iter 92000, loss: 0.007061
 >> iter 93000, loss: 0.007035
 >> iter 94000, loss: 0.007033
 >> iter 95000, loss: 0.007014
 >> iter 96000, loss: 0.007012
 >> iter 97000, loss: 0.007000
 >> iter 98000, loss: 0.006993
 >> iter 99000, loss: 0.006982
 >> iter 100000, loss: 0.006975
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0029999700003
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.603457
 >> iter 2000, loss: 15.080323
 >> iter 3000, loss: 13.749746
 >> iter 4000, loss: 13.257404
 >> iter 5000, loss: 13.062234
 >> iter 6000, loss: 12.994828
 >> iter 7000, loss: 12.960234
 >> iter 8000, loss: 12.955984
 >> iter 9000, loss: 12.944209
 >> iter 10000, loss: 12.951415
   Number of active neurons: 4
 >> iter 11000, loss: 12.940844
 >> iter 12000, loss: 12.947669
 >> iter 13000, loss: 12.937482
 >> iter 14000, loss: 12.946181
 >> iter 15000, loss: 12.938469
 >> iter 16000, loss: 12.945132
 >> iter 17000, loss: 12.938521
 >> iter 18000, loss: 12.909438
 >> iter 19000, loss: 11.945984
 >> iter 20000, loss: 7.004953
   Number of active neurons: 8
 >> iter 21000, loss: 2.658122
 >> iter 22000, loss: 1.017922
 >> iter 23000, loss: 0.401711
 >> iter 24000, loss: 0.168890
 >> iter 25000, loss: 0.079415
 >> iter 26000, loss: 0.044100
 >> iter 27000, loss: 0.029270
 >> iter 28000, loss: 0.022578
 >> iter 29000, loss: 0.019021
 >> iter 30000, loss: 0.016974
   Number of active neurons: 8
 >> iter 31000, loss: 0.015483
 >> iter 32000, loss: 0.014461
 >> iter 33000, loss: 0.013549
 >> iter 34000, loss: 0.012888
 >> iter 35000, loss: 0.012233
 >> iter 36000, loss: 0.011768
 >> iter 37000, loss: 0.011260
 >> iter 38000, loss: 0.010917
 >> iter 39000, loss: 0.010507
 >> iter 40000, loss: 0.010252
   Number of active neurons: 8
 >> iter 41000, loss: 0.009915
 >> iter 42000, loss: 0.009717
 >> iter 43000, loss: 0.009437
 >> iter 44000, loss: 0.009282
 >> iter 45000, loss: 0.009048
 >> iter 46000, loss: 0.008928
 >> iter 47000, loss: 0.008725
 >> iter 48000, loss: 0.008629
 >> iter 49000, loss: 0.008456
 >> iter 50000, loss: 0.008380
   Number of active neurons: 8
 >> iter 51000, loss: 0.008225
 >> iter 52000, loss: 0.008166
 >> iter 53000, loss: 0.008025
 >> iter 54000, loss: 0.007984
 >> iter 55000, loss: 0.007854
 >> iter 56000, loss: 0.007824
 >> iter 57000, loss: 0.007704
 >> iter 58000, loss: 0.007682
 >> iter 59000, loss: 0.007573
 >> iter 60000, loss: 0.007559
   Number of active neurons: 8
 >> iter 61000, loss: 0.007453
 >> iter 62000, loss: 0.007446
 >> iter 63000, loss: 0.007347
 >> iter 64000, loss: 0.007353
 >> iter 65000, loss: 0.007250
 >> iter 66000, loss: 0.007260
 >> iter 67000, loss: 0.007168
 >> iter 68000, loss: 0.007180
 >> iter 69000, loss: 0.007094
 >> iter 70000, loss: 0.007108
   Number of active neurons: 8
 >> iter 71000, loss: 0.007025
 >> iter 72000, loss: 0.007044
 >> iter 73000, loss: 0.006962
 >> iter 74000, loss: 0.006986
 >> iter 75000, loss: 0.006904
 >> iter 76000, loss: 0.006926
 >> iter 77000, loss: 0.006847
 >> iter 78000, loss: 0.006869
 >> iter 79000, loss: 0.006793
 >> iter 80000, loss: 0.006816
   Number of active neurons: 8
 >> iter 81000, loss: 0.006745
 >> iter 82000, loss: 0.006763
 >> iter 83000, loss: 0.006695
 >> iter 84000, loss: 0.006713
 >> iter 85000, loss: 0.006649
 >> iter 86000, loss: 0.006667
 >> iter 87000, loss: 0.006604
 >> iter 88000, loss: 0.006622
 >> iter 89000, loss: 0.006559
 >> iter 90000, loss: 0.006579
   Number of active neurons: 8
 >> iter 91000, loss: 0.006517
 >> iter 92000, loss: 0.006537
 >> iter 93000, loss: 0.006476
 >> iter 94000, loss: 0.006498
 >> iter 95000, loss: 0.006438
 >> iter 96000, loss: 0.006462
 >> iter 97000, loss: 0.006407
 >> iter 98000, loss: 0.006431
 >> iter 99000, loss: 0.006375
 >> iter 100000, loss: 0.006401
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.635645
 >> iter 2000, loss: 15.097321
 >> iter 3000, loss: 13.757724
 >> iter 4000, loss: 13.261676
 >> iter 5000, loss: 13.061696
 >> iter 6000, loss: 12.992795
 >> iter 7000, loss: 12.955544
 >> iter 8000, loss: 12.950406
 >> iter 9000, loss: 12.936727
 >> iter 10000, loss: 12.942639
   Number of active neurons: 4
 >> iter 11000, loss: 12.930712
 >> iter 12000, loss: 12.934854
 >> iter 13000, loss: 12.915821
 >> iter 14000, loss: 12.449026
 >> iter 15000, loss: 7.879882
 >> iter 16000, loss: 3.004802
 >> iter 17000, loss: 1.146553
 >> iter 18000, loss: 0.526700
 >> iter 19000, loss: 0.214866
 >> iter 20000, loss: 0.095612
   Number of active neurons: 8
 >> iter 21000, loss: 0.048873
 >> iter 22000, loss: 0.030012
 >> iter 23000, loss: 0.021640
 >> iter 24000, loss: 0.017691
 >> iter 25000, loss: 0.015360
 >> iter 26000, loss: 0.013977
 >> iter 27000, loss: 0.012882
 >> iter 28000, loss: 0.012143
 >> iter 29000, loss: 0.011451
 >> iter 30000, loss: 0.010962
   Number of active neurons: 8
 >> iter 31000, loss: 0.010468
 >> iter 32000, loss: 0.010117
 >> iter 33000, loss: 0.009758
 >> iter 34000, loss: 0.009505
 >> iter 35000, loss: 0.009244
 >> iter 36000, loss: 0.009052
 >> iter 37000, loss: 0.008847
 >> iter 38000, loss: 0.008698
 >> iter 39000, loss: 0.008529
 >> iter 40000, loss: 0.008412
   Number of active neurons: 8
 >> iter 41000, loss: 0.008274
 >> iter 42000, loss: 0.008172
 >> iter 43000, loss: 0.008059
 >> iter 44000, loss: 0.007975
 >> iter 45000, loss: 0.007880
 >> iter 46000, loss: 0.007806
 >> iter 47000, loss: 0.007720
 >> iter 48000, loss: 0.007651
 >> iter 49000, loss: 0.007579
 >> iter 50000, loss: 0.007518
   Number of active neurons: 8
 >> iter 51000, loss: 0.007453
 >> iter 52000, loss: 0.007398
 >> iter 53000, loss: 0.007339
 >> iter 54000, loss: 0.007294
 >> iter 55000, loss: 0.007239
 >> iter 56000, loss: 0.007194
 >> iter 57000, loss: 0.007146
 >> iter 58000, loss: 0.007107
 >> iter 59000, loss: 0.007066
 >> iter 60000, loss: 0.007032
   Number of active neurons: 8
 >> iter 61000, loss: 0.006995
 >> iter 62000, loss: 0.006964
 >> iter 63000, loss: 0.006925
 >> iter 64000, loss: 0.006901
 >> iter 65000, loss: 0.006867
 >> iter 66000, loss: 0.006843
 >> iter 67000, loss: 0.006814
 >> iter 68000, loss: 0.006790
 >> iter 69000, loss: 0.006764
 >> iter 70000, loss: 0.006741
   Number of active neurons: 8
 >> iter 71000, loss: 0.006714
 >> iter 72000, loss: 0.006693
 >> iter 73000, loss: 0.006657
 >> iter 74000, loss: 0.006643
 >> iter 75000, loss: 0.006609
 >> iter 76000, loss: 0.006596
 >> iter 77000, loss: 0.006563
 >> iter 78000, loss: 0.006550
 >> iter 79000, loss: 0.006520
 >> iter 80000, loss: 0.006510
   Number of active neurons: 8
 >> iter 81000, loss: 0.006479
 >> iter 82000, loss: 0.006471
 >> iter 83000, loss: 0.006436
 >> iter 84000, loss: 0.006430
 >> iter 85000, loss: 0.006392
 >> iter 86000, loss: 0.006387
 >> iter 87000, loss: 0.006350
 >> iter 88000, loss: 0.006348
 >> iter 89000, loss: 0.006310
 >> iter 90000, loss: 0.006306
   Number of active neurons: 8
 >> iter 91000, loss: 0.006271
 >> iter 92000, loss: 0.006264
 >> iter 93000, loss: 0.006233
 >> iter 94000, loss: 0.006222
 >> iter 95000, loss: 0.006193
 >> iter 96000, loss: 0.006183
 >> iter 97000, loss: 0.006159
 >> iter 98000, loss: 0.006149
 >> iter 99000, loss: 0.006124
 >> iter 100000, loss: 0.006113
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.621695
 >> iter 2000, loss: 15.080584
 >> iter 3000, loss: 13.738402
 >> iter 4000, loss: 13.243895
 >> iter 5000, loss: 13.046003
 >> iter 6000, loss: 12.978983
 >> iter 7000, loss: 12.942831
 >> iter 8000, loss: 12.938802
 >> iter 9000, loss: 12.926047
 >> iter 10000, loss: 12.932456
   Number of active neurons: 3
 >> iter 11000, loss: 12.917567
 >> iter 12000, loss: 12.485340
 >> iter 13000, loss: 8.944518
 >> iter 14000, loss: 3.355613
 >> iter 15000, loss: 1.262907
 >> iter 16000, loss: 0.483140
 >> iter 17000, loss: 0.191173
 >> iter 18000, loss: 0.081550
 >> iter 19000, loss: 0.039438
 >> iter 20000, loss: 0.022972
   Number of active neurons: 7
 >> iter 21000, loss: 0.015935
 >> iter 22000, loss: 0.012828
 >> iter 23000, loss: 0.011028
 >> iter 24000, loss: 0.010093
 >> iter 25000, loss: 0.009255
 >> iter 26000, loss: 0.008779
 >> iter 27000, loss: 0.008212
 >> iter 28000, loss: 0.007902
 >> iter 29000, loss: 0.007477
 >> iter 30000, loss: 0.007267
   Number of active neurons: 7
 >> iter 31000, loss: 0.006931
 >> iter 32000, loss: 0.006766
 >> iter 33000, loss: 0.006501
 >> iter 34000, loss: 0.006388
 >> iter 35000, loss: 0.006185
 >> iter 36000, loss: 0.006112
 >> iter 37000, loss: 0.005957
 >> iter 38000, loss: 0.005916
 >> iter 39000, loss: 0.005795
 >> iter 40000, loss: 0.005778
   Number of active neurons: 7
 >> iter 41000, loss: 0.005676
 >> iter 42000, loss: 0.005673
 >> iter 43000, loss: 0.005586
 >> iter 44000, loss: 0.005592
 >> iter 45000, loss: 0.005517
 >> iter 46000, loss: 0.005530
 >> iter 47000, loss: 0.005461
 >> iter 48000, loss: 0.005479
 >> iter 49000, loss: 0.005416
 >> iter 50000, loss: 0.005440
   Number of active neurons: 7
 >> iter 51000, loss: 0.005378
 >> iter 52000, loss: 0.005405
 >> iter 53000, loss: 0.005344
 >> iter 54000, loss: 0.005374
 >> iter 55000, loss: 0.005314
 >> iter 56000, loss: 0.005346
 >> iter 57000, loss: 0.005290
 >> iter 58000, loss: 0.005323
 >> iter 59000, loss: 0.005272
 >> iter 60000, loss: 0.005304
   Number of active neurons: 7
 >> iter 61000, loss: 0.005252
 >> iter 62000, loss: 0.005283
 >> iter 63000, loss: 0.005232
 >> iter 64000, loss: 0.005263
 >> iter 65000, loss: 0.005214
 >> iter 66000, loss: 0.005241
 >> iter 67000, loss: 0.005195
 >> iter 68000, loss: 0.005223
 >> iter 69000, loss: 0.005176
 >> iter 70000, loss: 0.005203
   Number of active neurons: 7
 >> iter 71000, loss: 0.005159
 >> iter 72000, loss: 0.005184
 >> iter 73000, loss: 0.005137
 >> iter 74000, loss: 0.005163
 >> iter 75000, loss: 0.005117
 >> iter 76000, loss: 0.005144
 >> iter 77000, loss: 0.005100
 >> iter 78000, loss: 0.005124
 >> iter 79000, loss: 0.005085
 >> iter 80000, loss: 0.005103
   Number of active neurons: 7
 >> iter 81000, loss: 0.005067
 >> iter 82000, loss: 0.005088
 >> iter 83000, loss: 0.005049
 >> iter 84000, loss: 0.005072
 >> iter 85000, loss: 0.005033
 >> iter 86000, loss: 0.005055
 >> iter 87000, loss: 0.005018
 >> iter 88000, loss: 0.005040
 >> iter 89000, loss: 0.005003
 >> iter 90000, loss: 0.005025
   Number of active neurons: 7
 >> iter 91000, loss: 0.004990
 >> iter 92000, loss: 0.005010
 >> iter 93000, loss: 0.004978
 >> iter 94000, loss: 0.004995
 >> iter 95000, loss: 0.004965
 >> iter 96000, loss: 0.004981
 >> iter 97000, loss: 0.004953
 >> iter 98000, loss: 0.004971
 >> iter 99000, loss: 0.004938
 >> iter 100000, loss: 0.004953
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.609394
 >> iter 2000, loss: 15.082971
 >> iter 3000, loss: 13.744334
 >> iter 4000, loss: 13.248870
 >> iter 5000, loss: 13.050009
 >> iter 6000, loss: 12.981428
 >> iter 7000, loss: 12.944965
 >> iter 8000, loss: 12.939769
 >> iter 9000, loss: 12.926806
 >> iter 10000, loss: 12.879074
   Number of active neurons: 4
 >> iter 11000, loss: 12.317319
 >> iter 12000, loss: 7.338118
 >> iter 13000, loss: 2.757477
 >> iter 14000, loss: 1.041304
 >> iter 15000, loss: 0.400631
 >> iter 16000, loss: 0.160583
 >> iter 17000, loss: 0.069712
 >> iter 18000, loss: 0.034666
 >> iter 19000, loss: 0.020613
 >> iter 20000, loss: 0.014634
   Number of active neurons: 6
 >> iter 21000, loss: 0.011785
 >> iter 22000, loss: 0.010262
 >> iter 23000, loss: 0.009291
 >> iter 24000, loss: 0.008626
 >> iter 25000, loss: 0.008098
 >> iter 26000, loss: 0.007694
 >> iter 27000, loss: 0.007340
 >> iter 28000, loss: 0.007061
 >> iter 29000, loss: 0.006802
 >> iter 30000, loss: 0.006595
   Number of active neurons: 6
 >> iter 31000, loss: 0.006396
 >> iter 32000, loss: 0.006241
 >> iter 33000, loss: 0.006087
 >> iter 34000, loss: 0.005967
 >> iter 35000, loss: 0.005846
 >> iter 36000, loss: 0.005749
 >> iter 37000, loss: 0.005651
 >> iter 38000, loss: 0.005575
 >> iter 39000, loss: 0.005493
 >> iter 40000, loss: 0.005432
   Number of active neurons: 6
 >> iter 41000, loss: 0.005361
 >> iter 42000, loss: 0.005312
 >> iter 43000, loss: 0.005251
 >> iter 44000, loss: 0.005214
 >> iter 45000, loss: 0.005159
 >> iter 46000, loss: 0.005130
 >> iter 47000, loss: 0.005080
 >> iter 48000, loss: 0.005055
 >> iter 49000, loss: 0.005010
 >> iter 50000, loss: 0.004992
   Number of active neurons: 6
 >> iter 51000, loss: 0.004951
 >> iter 52000, loss: 0.004937
 >> iter 53000, loss: 0.004903
 >> iter 54000, loss: 0.004894
 >> iter 55000, loss: 0.004867
 >> iter 56000, loss: 0.004865
 >> iter 57000, loss: 0.004844
 >> iter 58000, loss: 0.004845
 >> iter 59000, loss: 0.004827
 >> iter 60000, loss: 0.004831
   Number of active neurons: 6
 >> iter 61000, loss: 0.004813
 >> iter 62000, loss: 0.004819
 >> iter 63000, loss: 0.004802
 >> iter 64000, loss: 0.004809
 >> iter 65000, loss: 0.004793
 >> iter 66000, loss: 0.004800
 >> iter 67000, loss: 0.004783
 >> iter 68000, loss: 0.004788
 >> iter 69000, loss: 0.004774
 >> iter 70000, loss: 0.004778
   Number of active neurons: 6
 >> iter 71000, loss: 0.004765
 >> iter 72000, loss: 0.004770
 >> iter 73000, loss: 0.004755
 >> iter 74000, loss: 0.004760
 >> iter 75000, loss: 0.004746
 >> iter 76000, loss: 0.004749
 >> iter 77000, loss: 0.004736
 >> iter 78000, loss: 0.004738
 >> iter 79000, loss: 0.004727
 >> iter 80000, loss: 0.004726
   Number of active neurons: 6
 >> iter 81000, loss: 0.004716
 >> iter 82000, loss: 0.004714
 >> iter 83000, loss: 0.004704
 >> iter 84000, loss: 0.004702
 >> iter 85000, loss: 0.004691
 >> iter 86000, loss: 0.004689
 >> iter 87000, loss: 0.004680
 >> iter 88000, loss: 0.004676
 >> iter 89000, loss: 0.004668
 >> iter 90000, loss: 0.004663
   Number of active neurons: 6
 >> iter 91000, loss: 0.004655
 >> iter 92000, loss: 0.004649
 >> iter 93000, loss: 0.004642
 >> iter 94000, loss: 0.004636
 >> iter 95000, loss: 0.004630
 >> iter 96000, loss: 0.004623
 >> iter 97000, loss: 0.004618
 >> iter 98000, loss: 0.004611
 >> iter 99000, loss: 0.004606
 >> iter 100000, loss: 0.004598
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.623492
 >> iter 2000, loss: 15.107906
 >> iter 3000, loss: 13.769397
 >> iter 4000, loss: 13.270407
 >> iter 5000, loss: 13.071843
 >> iter 6000, loss: 13.000672
 >> iter 7000, loss: 12.964481
 >> iter 8000, loss: 12.957673
 >> iter 9000, loss: 12.945271
 >> iter 10000, loss: 12.950885
   Number of active neurons: 5
 >> iter 11000, loss: 12.940375
 >> iter 12000, loss: 12.946107
 >> iter 13000, loss: 12.936303
 >> iter 14000, loss: 12.943811
 >> iter 15000, loss: 12.936543
 >> iter 16000, loss: 12.938897
 >> iter 17000, loss: 12.816097
 >> iter 18000, loss: 11.127502
 >> iter 19000, loss: 4.340834
 >> iter 20000, loss: 1.643656
   Number of active neurons: 8
 >> iter 21000, loss: 0.632107
 >> iter 22000, loss: 0.252430
 >> iter 23000, loss: 0.108543
 >> iter 24000, loss: 0.053150
 >> iter 25000, loss: 0.030938
 >> iter 26000, loss: 0.021618
 >> iter 27000, loss: 0.017171
 >> iter 28000, loss: 0.014900
 >> iter 29000, loss: 0.013416
 >> iter 30000, loss: 0.012484
   Number of active neurons: 8
 >> iter 31000, loss: 0.011689
 >> iter 32000, loss: 0.011148
 >> iter 33000, loss: 0.010616
 >> iter 34000, loss: 0.010254
 >> iter 35000, loss: 0.009862
 >> iter 36000, loss: 0.009610
 >> iter 37000, loss: 0.009311
 >> iter 38000, loss: 0.009131
 >> iter 39000, loss: 0.008888
 >> iter 40000, loss: 0.008757
   Number of active neurons: 8
 >> iter 41000, loss: 0.008551
 >> iter 42000, loss: 0.008455
 >> iter 43000, loss: 0.008284
 >> iter 44000, loss: 0.008215
 >> iter 45000, loss: 0.008073
 >> iter 46000, loss: 0.008026
 >> iter 47000, loss: 0.007902
 >> iter 48000, loss: 0.007866
 >> iter 49000, loss: 0.007757
 >> iter 50000, loss: 0.007729
   Number of active neurons: 7
 >> iter 51000, loss: 0.007632
 >> iter 52000, loss: 0.007610
 >> iter 53000, loss: 0.007520
 >> iter 54000, loss: 0.007507
 >> iter 55000, loss: 0.007424
 >> iter 56000, loss: 0.007417
 >> iter 57000, loss: 0.007344
 >> iter 58000, loss: 0.007340
 >> iter 59000, loss: 0.007277
 >> iter 60000, loss: 0.007275
   Number of active neurons: 7
 >> iter 61000, loss: 0.007216
 >> iter 62000, loss: 0.007217
 >> iter 63000, loss: 0.007159
 >> iter 64000, loss: 0.007164
 >> iter 65000, loss: 0.007109
 >> iter 66000, loss: 0.007113
 >> iter 67000, loss: 0.007102
 >> iter 68000, loss: 0.007068
 >> iter 69000, loss: 0.007061
 >> iter 70000, loss: 0.007023
   Number of active neurons: 7
 >> iter 71000, loss: 0.007024
 >> iter 72000, loss: 0.006986
 >> iter 73000, loss: 0.006989
 >> iter 74000, loss: 0.006952
 >> iter 75000, loss: 0.006956
 >> iter 76000, loss: 0.006918
 >> iter 77000, loss: 0.006922
 >> iter 78000, loss: 0.006882
 >> iter 79000, loss: 0.006890
 >> iter 80000, loss: 0.006848
   Number of active neurons: 7
 >> iter 81000, loss: 0.006858
 >> iter 82000, loss: 0.006813
 >> iter 83000, loss: 0.006825
 >> iter 84000, loss: 0.006780
 >> iter 85000, loss: 0.006796
 >> iter 86000, loss: 0.006751
 >> iter 87000, loss: 0.006769
 >> iter 88000, loss: 0.006724
 >> iter 89000, loss: 0.006746
 >> iter 90000, loss: 0.006700
   Number of active neurons: 7
 >> iter 91000, loss: 0.006731
 >> iter 92000, loss: 0.006685
 >> iter 93000, loss: 0.006717
 >> iter 94000, loss: 0.006667
 >> iter 95000, loss: 0.006703
 >> iter 96000, loss: 0.006648
 >> iter 97000, loss: 0.006690
 >> iter 98000, loss: 0.006631
 >> iter 99000, loss: 0.006679
 >> iter 100000, loss: 0.006615
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.616808
 >> iter 2000, loss: 15.099152
 >> iter 3000, loss: 13.763400
 >> iter 4000, loss: 13.265622
 >> iter 5000, loss: 13.066339
 >> iter 6000, loss: 12.996513
 >> iter 7000, loss: 12.960679
 >> iter 8000, loss: 12.955549
 >> iter 9000, loss: 12.943429
 >> iter 10000, loss: 12.950233
   Number of active neurons: 5
 >> iter 11000, loss: 12.939649
 >> iter 12000, loss: 12.946301
 >> iter 13000, loss: 12.936274
 >> iter 14000, loss: 12.944872
 >> iter 15000, loss: 12.937348
 >> iter 16000, loss: 12.944136
 >> iter 17000, loss: 12.938055
 >> iter 18000, loss: 12.940502
 >> iter 19000, loss: 12.917940
 >> iter 20000, loss: 12.565906
   Number of active neurons: 5
 >> iter 21000, loss: 7.519653
 >> iter 22000, loss: 2.808019
 >> iter 23000, loss: 1.054279
 >> iter 24000, loss: 0.402702
 >> iter 25000, loss: 0.159739
 >> iter 26000, loss: 0.068468
 >> iter 27000, loss: 0.033562
 >> iter 28000, loss: 0.019848
 >> iter 29000, loss: 0.014088
 >> iter 30000, loss: 0.011481
   Number of active neurons: 7
 >> iter 31000, loss: 0.010079
 >> iter 32000, loss: 0.009263
 >> iter 33000, loss: 0.008664
 >> iter 34000, loss: 0.008243
 >> iter 35000, loss: 0.007875
 >> iter 36000, loss: 0.007600
 >> iter 37000, loss: 0.007340
 >> iter 38000, loss: 0.007146
 >> iter 39000, loss: 0.006950
 >> iter 40000, loss: 0.006809
   Number of active neurons: 7
 >> iter 41000, loss: 0.006657
 >> iter 42000, loss: 0.006549
 >> iter 43000, loss: 0.006428
 >> iter 44000, loss: 0.006347
 >> iter 45000, loss: 0.006249
 >> iter 46000, loss: 0.006185
 >> iter 47000, loss: 0.006102
 >> iter 48000, loss: 0.006049
 >> iter 49000, loss: 0.005975
 >> iter 50000, loss: 0.005933
   Number of active neurons: 7
 >> iter 51000, loss: 0.005866
 >> iter 52000, loss: 0.005834
 >> iter 53000, loss: 0.005773
 >> iter 54000, loss: 0.005750
 >> iter 55000, loss: 0.005696
 >> iter 56000, loss: 0.005680
 >> iter 57000, loss: 0.005631
 >> iter 58000, loss: 0.005620
 >> iter 59000, loss: 0.005574
 >> iter 60000, loss: 0.005568
   Number of active neurons: 7
 >> iter 61000, loss: 0.005526
 >> iter 62000, loss: 0.005523
 >> iter 63000, loss: 0.005483
 >> iter 64000, loss: 0.005484
 >> iter 65000, loss: 0.005447
 >> iter 66000, loss: 0.005449
 >> iter 67000, loss: 0.005412
 >> iter 68000, loss: 0.005415
 >> iter 69000, loss: 0.005377
 >> iter 70000, loss: 0.005382
   Number of active neurons: 7
 >> iter 71000, loss: 0.005342
 >> iter 72000, loss: 0.005350
 >> iter 73000, loss: 0.005312
 >> iter 74000, loss: 0.005325
 >> iter 75000, loss: 0.005286
 >> iter 76000, loss: 0.005301
 >> iter 77000, loss: 0.005263
 >> iter 78000, loss: 0.005280
 >> iter 79000, loss: 0.005241
 >> iter 80000, loss: 0.005260
   Number of active neurons: 7
 >> iter 81000, loss: 0.005222
 >> iter 82000, loss: 0.005242
 >> iter 83000, loss: 0.005204
 >> iter 84000, loss: 0.005225
 >> iter 85000, loss: 0.005187
 >> iter 86000, loss: 0.005210
 >> iter 87000, loss: 0.005172
 >> iter 88000, loss: 0.005196
 >> iter 89000, loss: 0.005158
 >> iter 90000, loss: 0.005184
   Number of active neurons: 7
 >> iter 91000, loss: 0.005145
 >> iter 92000, loss: 0.005171
 >> iter 93000, loss: 0.005132
 >> iter 94000, loss: 0.005158
 >> iter 95000, loss: 0.005118
 >> iter 96000, loss: 0.005142
 >> iter 97000, loss: 0.005103
 >> iter 98000, loss: 0.005128
 >> iter 99000, loss: 0.005089
 >> iter 100000, loss: 0.005111
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.627348
 >> iter 2000, loss: 15.094647
 >> iter 3000, loss: 13.758179
 >> iter 4000, loss: 13.264144
 >> iter 5000, loss: 13.066419
 >> iter 6000, loss: 12.996659
 >> iter 7000, loss: 12.960873
 >> iter 8000, loss: 12.955638
 >> iter 9000, loss: 12.943557
 >> iter 10000, loss: 12.950472
   Number of active neurons: 5
 >> iter 11000, loss: 12.939888
 >> iter 12000, loss: 12.946730
 >> iter 13000, loss: 12.936653
 >> iter 14000, loss: 12.945459
 >> iter 15000, loss: 12.937835
 >> iter 16000, loss: 12.945029
 >> iter 17000, loss: 12.938839
 >> iter 18000, loss: 12.943159
 >> iter 19000, loss: 12.935553
 >> iter 20000, loss: 12.942682
   Number of active neurons: 5
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 5
 >> iter 21000, loss: 12.867344
 >> iter 22000, loss: 10.376906
 >> iter 23000, loss: 4.016364
 >> iter 24000, loss: 1.516251
 >> iter 25000, loss: 0.580940
 >> iter 26000, loss: 0.230543
 >> iter 27000, loss: 0.098290
 >> iter 28000, loss: 0.047526
 >> iter 29000, loss: 0.027417
 >> iter 30000, loss: 0.018975
   Number of active neurons: 8
 >> iter 31000, loss: 0.015116
 >> iter 32000, loss: 0.013094
 >> iter 33000, loss: 0.011897
 >> iter 34000, loss: 0.011059
 >> iter 35000, loss: 0.010453
 >> iter 36000, loss: 0.009952
 >> iter 37000, loss: 0.009565
 >> iter 38000, loss: 0.009216
 >> iter 39000, loss: 0.008948
 >> iter 40000, loss: 0.008688
   Number of active neurons: 8
 >> iter 41000, loss: 0.008491
 >> iter 42000, loss: 0.008286
 >> iter 43000, loss: 0.008141
 >> iter 44000, loss: 0.007979
 >> iter 45000, loss: 0.007872
 >> iter 46000, loss: 0.007738
 >> iter 47000, loss: 0.007651
 >> iter 48000, loss: 0.007536
 >> iter 49000, loss: 0.007468
 >> iter 50000, loss: 0.007366
   Number of active neurons: 8
 >> iter 51000, loss: 0.007307
 >> iter 52000, loss: 0.007212
 >> iter 53000, loss: 0.007159
 >> iter 54000, loss: 0.007077
 >> iter 55000, loss: 0.007031
 >> iter 56000, loss: 0.006953
 >> iter 57000, loss: 0.006916
 >> iter 58000, loss: 0.006837
 >> iter 59000, loss: 0.006813
 >> iter 60000, loss: 0.006741
   Number of active neurons: 8
 >> iter 61000, loss: 0.006727
 >> iter 62000, loss: 0.006659
 >> iter 63000, loss: 0.006652
 >> iter 64000, loss: 0.006591
 >> iter 65000, loss: 0.006587
 >> iter 66000, loss: 0.006525
 >> iter 67000, loss: 0.006527
 >> iter 68000, loss: 0.006464
 >> iter 69000, loss: 0.006469
 >> iter 70000, loss: 0.006407
   Number of active neurons: 8
 >> iter 71000, loss: 0.006420
 >> iter 72000, loss: 0.006358
 >> iter 73000, loss: 0.006367
 >> iter 74000, loss: 0.006305
 >> iter 75000, loss: 0.006318
 >> iter 76000, loss: 0.006258
 >> iter 77000, loss: 0.006273
 >> iter 78000, loss: 0.006212
 >> iter 79000, loss: 0.006231
 >> iter 80000, loss: 0.006169
   Number of active neurons: 8
 >> iter 81000, loss: 0.006189
 >> iter 82000, loss: 0.006127
 >> iter 83000, loss: 0.006146
 >> iter 84000, loss: 0.006085
 >> iter 85000, loss: 0.006104
 >> iter 86000, loss: 0.006042
 >> iter 87000, loss: 0.006067
 >> iter 88000, loss: 0.005999
 >> iter 89000, loss: 0.006024
 >> iter 90000, loss: 0.005958
   Number of active neurons: 7
 >> iter 91000, loss: 0.005988
 >> iter 92000, loss: 0.005922
 >> iter 93000, loss: 0.005956
 >> iter 94000, loss: 0.005891
 >> iter 95000, loss: 0.005926
 >> iter 96000, loss: 0.005861
 >> iter 97000, loss: 0.005897
 >> iter 98000, loss: 0.005831
 >> iter 99000, loss: 0.005865
 >> iter 100000, loss: 0.005798
   Number of active neurons: 7
 >> iter 101000, loss: 0.005832
 >> iter 102000, loss: 0.005768
 >> iter 103000, loss: 0.005804
 >> iter 104000, loss: 0.005741
 >> iter 105000, loss: 0.005781
 >> iter 106000, loss: 0.005716
 >> iter 107000, loss: 0.005755
 >> iter 108000, loss: 0.005694
 >> iter 109000, loss: 0.005732
 >> iter 110000, loss: 0.005673
   Number of active neurons: 7
 >> iter 111000, loss: 0.005705
 >> iter 112000, loss: 0.005653
 >> iter 113000, loss: 0.005680
 >> iter 114000, loss: 0.005633
 >> iter 115000, loss: 0.005659
 >> iter 116000, loss: 0.005615
 >> iter 117000, loss: 0.005635
 >> iter 118000, loss: 0.005592
 >> iter 119000, loss: 0.005606
 >> iter 120000, loss: 0.005563
   Number of active neurons: 7
 >> iter 121000, loss: 0.005571
 >> iter 122000, loss: 0.005529
 >> iter 123000, loss: 0.005537
 >> iter 124000, loss: 0.005501
 >> iter 125000, loss: 0.005507
 >> iter 126000, loss: 0.005479
 >> iter 127000, loss: 0.005480
 >> iter 128000, loss: 0.005455
 >> iter 129000, loss: 0.005452
 >> iter 130000, loss: 0.005433
   Number of active neurons: 7
 >> iter 131000, loss: 0.005429
 >> iter 132000, loss: 0.005415
 >> iter 133000, loss: 0.005409
 >> iter 134000, loss: 0.005400
 >> iter 135000, loss: 0.005391
 >> iter 136000, loss: 0.005387
 >> iter 137000, loss: 0.005375
 >> iter 138000, loss: 0.005375
 >> iter 139000, loss: 0.005361
 >> iter 140000, loss: 0.005363
   Number of active neurons: 7
 >> iter 141000, loss: 0.005346
 >> iter 142000, loss: 0.005351
 >> iter 143000, loss: 0.005334
 >> iter 144000, loss: 0.005340
 >> iter 145000, loss: 0.005323
 >> iter 146000, loss: 0.005329
 >> iter 147000, loss: 0.005310
 >> iter 148000, loss: 0.005316
 >> iter 149000, loss: 0.005297
 >> iter 150000, loss: 0.005305
   Number of active neurons: 7
 >> iter 151000, loss: 0.005285
 >> iter 152000, loss: 0.005295
 >> iter 153000, loss: 0.005274
 >> iter 154000, loss: 0.005284
 >> iter 155000, loss: 0.005261
 >> iter 156000, loss: 0.005274
 >> iter 157000, loss: 0.005249
 >> iter 158000, loss: 0.005264
 >> iter 159000, loss: 0.005246
 >> iter 160000, loss: 0.005254
   Number of active neurons: 7
 >> iter 161000, loss: 0.005233
 >> iter 162000, loss: 0.005243
 >> iter 163000, loss: 0.005222
 >> iter 164000, loss: 0.005229
 >> iter 165000, loss: 0.005210
 >> iter 166000, loss: 0.005220
 >> iter 167000, loss: 0.005198
 >> iter 168000, loss: 0.005208
 >> iter 169000, loss: 0.005187
 >> iter 170000, loss: 0.005198
   Number of active neurons: 7
 >> iter 171000, loss: 0.005176
 >> iter 172000, loss: 0.005187
 >> iter 173000, loss: 0.005165
 >> iter 174000, loss: 0.005177
 >> iter 175000, loss: 0.005151
 >> iter 176000, loss: 0.005162
 >> iter 177000, loss: 0.005137
 >> iter 178000, loss: 0.005146
 >> iter 179000, loss: 0.005123
 >> iter 180000, loss: 0.005132
   Number of active neurons: 7
 >> iter 181000, loss: 0.005110
 >> iter 182000, loss: 0.005118
 >> iter 183000, loss: 0.005099
 >> iter 184000, loss: 0.005106
 >> iter 185000, loss: 0.005086
 >> iter 186000, loss: 0.005093
 >> iter 187000, loss: 0.005074
 >> iter 188000, loss: 0.005080
 >> iter 189000, loss: 0.005062
 >> iter 190000, loss: 0.005063
   Number of active neurons: 7
 >> iter 191000, loss: 0.005049
 >> iter 192000, loss: 0.005047
 >> iter 193000, loss: 0.005036
 >> iter 194000, loss: 0.005031
 >> iter 195000, loss: 0.005022
 >> iter 196000, loss: 0.005015
 >> iter 197000, loss: 0.005009
 >> iter 198000, loss: 0.005001
 >> iter 199000, loss: 0.004997
 >> iter 200000, loss: 0.004987
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 38.0307979468
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.615141
 >> iter 2000, loss: 15.085252
 >> iter 3000, loss: 13.752404
 >> iter 4000, loss: 13.257442
 >> iter 5000, loss: 13.056351
 >> iter 6000, loss: 12.986539
 >> iter 7000, loss: 12.948543
 >> iter 8000, loss: 12.943665
 >> iter 9000, loss: 12.930024
 >> iter 10000, loss: 12.937212
   Number of active neurons: 4
 >> iter 11000, loss: 12.925589
 >> iter 12000, loss: 12.932351
 >> iter 13000, loss: 12.921473
 >> iter 14000, loss: 12.924365
 >> iter 15000, loss: 12.554020
 >> iter 16000, loss: 11.539940
 >> iter 17000, loss: 8.523187
 >> iter 18000, loss: 3.208895
 >> iter 19000, loss: 1.203975
 >> iter 20000, loss: 0.458268
   Number of active neurons: 9
 >> iter 21000, loss: 0.180644
 >> iter 22000, loss: 0.076134
 >> iter 23000, loss: 0.036547
 >> iter 24000, loss: 0.020756
 >> iter 25000, loss: 0.014387
 >> iter 26000, loss: 0.011276
 >> iter 27000, loss: 0.009791
 >> iter 28000, loss: 0.008731
 >> iter 29000, loss: 0.008096
 >> iter 30000, loss: 0.007532
   Number of active neurons: 9
 >> iter 31000, loss: 0.007146
 >> iter 32000, loss: 0.006797
 >> iter 33000, loss: 0.006539
 >> iter 34000, loss: 0.006309
 >> iter 35000, loss: 0.006127
 >> iter 36000, loss: 0.005973
 >> iter 37000, loss: 0.005838
 >> iter 38000, loss: 0.005730
 >> iter 39000, loss: 0.005627
 >> iter 40000, loss: 0.005550
   Number of active neurons: 9
 >> iter 41000, loss: 0.005472
 >> iter 42000, loss: 0.005419
 >> iter 43000, loss: 0.005361
 >> iter 44000, loss: 0.005325
 >> iter 45000, loss: 0.005275
 >> iter 46000, loss: 0.005247
 >> iter 47000, loss: 0.005203
 >> iter 48000, loss: 0.005182
 >> iter 49000, loss: 0.005144
 >> iter 50000, loss: 0.005130
   Number of active neurons: 9
 >> iter 51000, loss: 0.005094
 >> iter 52000, loss: 0.005081
 >> iter 53000, loss: 0.005042
 >> iter 54000, loss: 0.005033
 >> iter 55000, loss: 0.004993
 >> iter 56000, loss: 0.004985
 >> iter 57000, loss: 0.004948
 >> iter 58000, loss: 0.004941
 >> iter 59000, loss: 0.004905
 >> iter 60000, loss: 0.004900
   Number of active neurons: 8
 >> iter 61000, loss: 0.004861
 >> iter 62000, loss: 0.004856
 >> iter 63000, loss: 0.004817
 >> iter 64000, loss: 0.004815
 >> iter 65000, loss: 0.004778
 >> iter 66000, loss: 0.004776
 >> iter 67000, loss: 0.004738
 >> iter 68000, loss: 0.004737
 >> iter 69000, loss: 0.004701
 >> iter 70000, loss: 0.004702
   Number of active neurons: 8
 >> iter 71000, loss: 0.004669
 >> iter 72000, loss: 0.004672
 >> iter 73000, loss: 0.004637
 >> iter 74000, loss: 0.004642
 >> iter 75000, loss: 0.004605
 >> iter 76000, loss: 0.004613
 >> iter 77000, loss: 0.004578
 >> iter 78000, loss: 0.004588
 >> iter 79000, loss: 0.004557
 >> iter 80000, loss: 0.004564
   Number of active neurons: 8
 >> iter 81000, loss: 0.004536
 >> iter 82000, loss: 0.004544
 >> iter 83000, loss: 0.004516
 >> iter 84000, loss: 0.004524
 >> iter 85000, loss: 0.004496
 >> iter 86000, loss: 0.004505
 >> iter 87000, loss: 0.004481
 >> iter 88000, loss: 0.004491
 >> iter 89000, loss: 0.004469
 >> iter 90000, loss: 0.004481
   Number of active neurons: 8
 >> iter 91000, loss: 0.004461
 >> iter 92000, loss: 0.004475
 >> iter 93000, loss: 0.004457
 >> iter 94000, loss: 0.004471
 >> iter 95000, loss: 0.004454
 >> iter 96000, loss: 0.004468
 >> iter 97000, loss: 0.004453
 >> iter 98000, loss: 0.004467
 >> iter 99000, loss: 0.004452
 >> iter 100000, loss: 0.004465
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.633057
 >> iter 2000, loss: 15.112494
 >> iter 3000, loss: 13.780938
 >> iter 4000, loss: 13.286623
 >> iter 5000, loss: 13.085738
 >> iter 6000, loss: 13.010727
 >> iter 7000, loss: 12.966581
 >> iter 8000, loss: 12.956000
 >> iter 9000, loss: 12.937930
 >> iter 10000, loss: 12.942948
   Number of active neurons: 3
 >> iter 11000, loss: 12.929369
 >> iter 12000, loss: 12.936046
 >> iter 13000, loss: 12.924056
 >> iter 14000, loss: 12.933320
 >> iter 15000, loss: 12.924300
 >> iter 16000, loss: 12.931763
 >> iter 17000, loss: 12.924040
 >> iter 18000, loss: 12.909903
 >> iter 19000, loss: 12.444503
 >> iter 20000, loss: 7.762864
   Number of active neurons: 8
 >> iter 21000, loss: 2.916741
 >> iter 22000, loss: 1.101620
 >> iter 23000, loss: 0.424285
 >> iter 24000, loss: 0.170622
 >> iter 25000, loss: 0.074611
 >> iter 26000, loss: 0.037593
 >> iter 27000, loss: 0.022747
 >> iter 28000, loss: 0.016423
 >> iter 29000, loss: 0.013417
 >> iter 30000, loss: 0.011801
   Number of active neurons: 8
 >> iter 31000, loss: 0.010792
 >> iter 32000, loss: 0.010088
 >> iter 33000, loss: 0.009557
 >> iter 34000, loss: 0.009126
 >> iter 35000, loss: 0.008778
 >> iter 36000, loss: 0.008478
 >> iter 37000, loss: 0.008235
 >> iter 38000, loss: 0.008015
 >> iter 39000, loss: 0.007840
 >> iter 40000, loss: 0.007673
   Number of active neurons: 8
 >> iter 41000, loss: 0.007543
 >> iter 42000, loss: 0.007411
 >> iter 43000, loss: 0.007312
 >> iter 44000, loss: 0.007208
 >> iter 45000, loss: 0.007134
 >> iter 46000, loss: 0.007047
 >> iter 47000, loss: 0.006988
 >> iter 48000, loss: 0.006913
 >> iter 49000, loss: 0.006865
 >> iter 50000, loss: 0.006803
   Number of active neurons: 8
 >> iter 51000, loss: 0.006763
 >> iter 52000, loss: 0.006709
 >> iter 53000, loss: 0.006675
 >> iter 54000, loss: 0.006628
 >> iter 55000, loss: 0.006598
 >> iter 56000, loss: 0.006558
 >> iter 57000, loss: 0.006533
 >> iter 58000, loss: 0.006496
 >> iter 59000, loss: 0.006477
 >> iter 60000, loss: 0.006449
   Number of active neurons: 8
 >> iter 61000, loss: 0.006431
 >> iter 62000, loss: 0.006404
 >> iter 63000, loss: 0.006384
 >> iter 64000, loss: 0.006360
 >> iter 65000, loss: 0.006341
 >> iter 66000, loss: 0.006316
 >> iter 67000, loss: 0.006295
 >> iter 68000, loss: 0.006270
 >> iter 69000, loss: 0.006251
 >> iter 70000, loss: 0.006226
   Number of active neurons: 7
 >> iter 71000, loss: 0.006209
 >> iter 72000, loss: 0.006186
 >> iter 73000, loss: 0.006168
 >> iter 74000, loss: 0.006149
 >> iter 75000, loss: 0.006132
 >> iter 76000, loss: 0.006115
 >> iter 77000, loss: 0.006100
 >> iter 78000, loss: 0.006082
 >> iter 79000, loss: 0.006069
 >> iter 80000, loss: 0.006052
   Number of active neurons: 7
 >> iter 81000, loss: 0.006042
 >> iter 82000, loss: 0.006028
 >> iter 83000, loss: 0.006016
 >> iter 84000, loss: 0.006002
 >> iter 85000, loss: 0.005988
 >> iter 86000, loss: 0.005971
 >> iter 87000, loss: 0.005958
 >> iter 88000, loss: 0.005940
 >> iter 89000, loss: 0.005927
 >> iter 90000, loss: 0.005910
   Number of active neurons: 7
 >> iter 91000, loss: 0.005900
 >> iter 92000, loss: 0.005884
 >> iter 93000, loss: 0.005875
 >> iter 94000, loss: 0.005861
 >> iter 95000, loss: 0.005850
 >> iter 96000, loss: 0.005833
 >> iter 97000, loss: 0.005822
 >> iter 98000, loss: 0.005806
 >> iter 99000, loss: 0.005794
 >> iter 100000, loss: 0.005777
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.607145
 >> iter 2000, loss: 15.100969
 >> iter 3000, loss: 13.772171
 >> iter 4000, loss: 13.275651
 >> iter 5000, loss: 13.070980
 >> iter 6000, loss: 12.996795
 >> iter 7000, loss: 12.955809
 >> iter 8000, loss: 12.948643
 >> iter 9000, loss: 12.933708
 >> iter 10000, loss: 12.939964
   Number of active neurons: 4
 >> iter 11000, loss: 12.927779
 >> iter 12000, loss: 12.934291
 >> iter 13000, loss: 12.923140
 >> iter 14000, loss: 12.930945
 >> iter 15000, loss: 12.920349
 >> iter 16000, loss: 12.590435
 >> iter 17000, loss: 8.503757
 >> iter 18000, loss: 3.178748
 >> iter 19000, loss: 1.192708
 >> iter 20000, loss: 0.454596
   Number of active neurons: 9
 >> iter 21000, loss: 0.179523
 >> iter 22000, loss: 0.076204
 >> iter 23000, loss: 0.036823
 >> iter 24000, loss: 0.021349
 >> iter 25000, loss: 0.014935
 >> iter 26000, loss: 0.012020
 >> iter 27000, loss: 0.010511
 >> iter 28000, loss: 0.009606
 >> iter 29000, loss: 0.008983
 >> iter 30000, loss: 0.008513
   Number of active neurons: 9
 >> iter 31000, loss: 0.008137
 >> iter 32000, loss: 0.007828
 >> iter 33000, loss: 0.007566
 >> iter 34000, loss: 0.007343
 >> iter 35000, loss: 0.007151
 >> iter 36000, loss: 0.006981
 >> iter 37000, loss: 0.006834
 >> iter 38000, loss: 0.006701
 >> iter 39000, loss: 0.006586
 >> iter 40000, loss: 0.006476
   Number of active neurons: 9
 >> iter 41000, loss: 0.006381
 >> iter 42000, loss: 0.006286
 >> iter 43000, loss: 0.006206
 >> iter 44000, loss: 0.006123
 >> iter 45000, loss: 0.006054
 >> iter 46000, loss: 0.005981
 >> iter 47000, loss: 0.005923
 >> iter 48000, loss: 0.005862
 >> iter 49000, loss: 0.005818
 >> iter 50000, loss: 0.005765
   Number of active neurons: 9
 >> iter 51000, loss: 0.005728
 >> iter 52000, loss: 0.005680
 >> iter 53000, loss: 0.005648
 >> iter 54000, loss: 0.005605
 >> iter 55000, loss: 0.005579
 >> iter 56000, loss: 0.005540
 >> iter 57000, loss: 0.005519
 >> iter 58000, loss: 0.005478
 >> iter 59000, loss: 0.005461
 >> iter 60000, loss: 0.005426
   Number of active neurons: 9
 >> iter 61000, loss: 0.005406
 >> iter 62000, loss: 0.005372
 >> iter 63000, loss: 0.005353
 >> iter 64000, loss: 0.005322
 >> iter 65000, loss: 0.005304
 >> iter 66000, loss: 0.005275
 >> iter 67000, loss: 0.005257
 >> iter 68000, loss: 0.005229
 >> iter 69000, loss: 0.005214
 >> iter 70000, loss: 0.005188
   Number of active neurons: 9
 >> iter 71000, loss: 0.005176
 >> iter 72000, loss: 0.005153
 >> iter 73000, loss: 0.005140
 >> iter 74000, loss: 0.005118
 >> iter 75000, loss: 0.005107
 >> iter 76000, loss: 0.005085
 >> iter 77000, loss: 0.005075
 >> iter 78000, loss: 0.005052
 >> iter 79000, loss: 0.005044
 >> iter 80000, loss: 0.005019
   Number of active neurons: 9
 >> iter 81000, loss: 0.005013
 >> iter 82000, loss: 0.004991
 >> iter 83000, loss: 0.004979
 >> iter 84000, loss: 0.004958
 >> iter 85000, loss: 0.004947
 >> iter 86000, loss: 0.004926
 >> iter 87000, loss: 0.004919
 >> iter 88000, loss: 0.004896
 >> iter 89000, loss: 0.004890
 >> iter 90000, loss: 0.004865
   Number of active neurons: 9
 >> iter 91000, loss: 0.004859
 >> iter 92000, loss: 0.004833
 >> iter 93000, loss: 0.004827
 >> iter 94000, loss: 0.004801
 >> iter 95000, loss: 0.004796
 >> iter 96000, loss: 0.004769
 >> iter 97000, loss: 0.004764
 >> iter 98000, loss: 0.004741
 >> iter 99000, loss: 0.004732
 >> iter 100000, loss: 0.004705
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.610746
 >> iter 2000, loss: 15.091497
 >> iter 3000, loss: 13.756434
 >> iter 4000, loss: 13.260935
 >> iter 5000, loss: 13.063614
 >> iter 6000, loss: 12.994899
 >> iter 7000, loss: 12.959817
 >> iter 8000, loss: 12.955178
 >> iter 9000, loss: 12.943383
 >> iter 10000, loss: 12.950496
   Number of active neurons: 5
 >> iter 11000, loss: 12.940031
 >> iter 12000, loss: 12.946876
 >> iter 13000, loss: 12.936803
 >> iter 14000, loss: 12.945468
 >> iter 15000, loss: 12.937773
 >> iter 16000, loss: 12.943705
 >> iter 17000, loss: 12.932473
 >> iter 18000, loss: 12.704722
 >> iter 19000, loss: 11.302980
 >> iter 20000, loss: 10.331385
   Number of active neurons: 6
 >> iter 21000, loss: 8.663889
 >> iter 22000, loss: 3.539330
 >> iter 23000, loss: 1.344971
 >> iter 24000, loss: 0.655700
 >> iter 25000, loss: 0.263225
 >> iter 26000, loss: 0.214058
 >> iter 27000, loss: 0.094108
 >> iter 28000, loss: 0.046550
 >> iter 29000, loss: 0.027315
 >> iter 30000, loss: 0.019388
   Number of active neurons: 7
 >> iter 31000, loss: 0.015388
 >> iter 32000, loss: 0.013549
 >> iter 33000, loss: 0.012213
 >> iter 34000, loss: 0.011477
 >> iter 35000, loss: 0.010637
 >> iter 36000, loss: 0.010236
 >> iter 37000, loss: 0.009647
 >> iter 38000, loss: 0.009394
 >> iter 39000, loss: 0.008952
 >> iter 40000, loss: 0.008782
   Number of active neurons: 7
 >> iter 41000, loss: 0.008428
 >> iter 42000, loss: 0.008307
 >> iter 43000, loss: 0.008016
 >> iter 44000, loss: 0.007933
 >> iter 45000, loss: 0.007689
 >> iter 46000, loss: 0.007630
 >> iter 47000, loss: 0.007418
 >> iter 48000, loss: 0.007377
 >> iter 49000, loss: 0.007196
 >> iter 50000, loss: 0.007170
   Number of active neurons: 7
 >> iter 51000, loss: 0.007007
 >> iter 52000, loss: 0.006994
 >> iter 53000, loss: 0.006847
 >> iter 54000, loss: 0.006843
 >> iter 55000, loss: 0.006714
 >> iter 56000, loss: 0.006713
 >> iter 57000, loss: 0.006599
 >> iter 58000, loss: 0.006600
 >> iter 59000, loss: 0.006497
 >> iter 60000, loss: 0.006499
   Number of active neurons: 7
 >> iter 61000, loss: 0.006406
 >> iter 62000, loss: 0.006412
 >> iter 63000, loss: 0.006325
 >> iter 64000, loss: 0.006337
 >> iter 65000, loss: 0.006259
 >> iter 66000, loss: 0.006269
 >> iter 67000, loss: 0.006200
 >> iter 68000, loss: 0.006210
 >> iter 69000, loss: 0.006148
 >> iter 70000, loss: 0.006156
   Number of active neurons: 7
 >> iter 71000, loss: 0.006101
 >> iter 72000, loss: 0.006110
 >> iter 73000, loss: 0.006056
 >> iter 74000, loss: 0.006069
 >> iter 75000, loss: 0.006017
 >> iter 76000, loss: 0.006031
 >> iter 77000, loss: 0.005984
 >> iter 78000, loss: 0.005998
 >> iter 79000, loss: 0.005952
 >> iter 80000, loss: 0.005967
   Number of active neurons: 7
 >> iter 81000, loss: 0.005923
 >> iter 82000, loss: 0.005937
 >> iter 83000, loss: 0.005894
 >> iter 84000, loss: 0.005911
 >> iter 85000, loss: 0.005870
 >> iter 86000, loss: 0.005886
 >> iter 87000, loss: 0.005847
 >> iter 88000, loss: 0.005865
 >> iter 89000, loss: 0.005827
 >> iter 90000, loss: 0.005844
   Number of active neurons: 7
 >> iter 91000, loss: 0.005810
 >> iter 92000, loss: 0.005825
 >> iter 93000, loss: 0.005794
 >> iter 94000, loss: 0.005807
 >> iter 95000, loss: 0.005779
 >> iter 96000, loss: 0.005791
 >> iter 97000, loss: 0.005767
 >> iter 98000, loss: 0.005776
 >> iter 99000, loss: 0.005753
 >> iter 100000, loss: 0.005760
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.630417
 >> iter 2000, loss: 15.110630
 >> iter 3000, loss: 13.774745
 >> iter 4000, loss: 13.277966
 >> iter 5000, loss: 13.079685
 >> iter 6000, loss: 13.009443
 >> iter 7000, loss: 12.973981
 >> iter 8000, loss: 12.968151
 >> iter 9000, loss: 12.956068
 >> iter 10000, loss: 12.962063
   Number of active neurons: 5
 >> iter 11000, loss: 12.950877
 >> iter 12000, loss: 12.956366
 >> iter 13000, loss: 12.943903
 >> iter 14000, loss: 12.950446
 >> iter 15000, loss: 12.939536
 >> iter 16000, loss: 12.944360
 >> iter 17000, loss: 12.935050
 >> iter 18000, loss: 12.930617
 >> iter 19000, loss: 12.867904
 >> iter 20000, loss: 12.552980
   Number of active neurons: 6
 >> iter 21000, loss: 11.135535
 >> iter 22000, loss: 4.357692
 >> iter 23000, loss: 1.641674
 >> iter 24000, loss: 0.628150
 >> iter 25000, loss: 0.248228
 >> iter 26000, loss: 0.104771
 >> iter 27000, loss: 0.049761
 >> iter 28000, loss: 0.028356
 >> iter 29000, loss: 0.019228
 >> iter 30000, loss: 0.015205
   Number of active neurons: 8
 >> iter 31000, loss: 0.012942
 >> iter 32000, loss: 0.011767
 >> iter 33000, loss: 0.010780
 >> iter 34000, loss: 0.010209
 >> iter 35000, loss: 0.009588
 >> iter 36000, loss: 0.009233
 >> iter 37000, loss: 0.008780
 >> iter 38000, loss: 0.008546
 >> iter 39000, loss: 0.008197
 >> iter 40000, loss: 0.008038
   Number of active neurons: 8
 >> iter 41000, loss: 0.007759
 >> iter 42000, loss: 0.007645
 >> iter 43000, loss: 0.007416
 >> iter 44000, loss: 0.007334
 >> iter 45000, loss: 0.007145
 >> iter 46000, loss: 0.007087
 >> iter 47000, loss: 0.006924
 >> iter 48000, loss: 0.006885
 >> iter 49000, loss: 0.006742
 >> iter 50000, loss: 0.006715
   Number of active neurons: 8
 >> iter 51000, loss: 0.006586
 >> iter 52000, loss: 0.006565
 >> iter 53000, loss: 0.006451
 >> iter 54000, loss: 0.006438
 >> iter 55000, loss: 0.006331
 >> iter 56000, loss: 0.006324
 >> iter 57000, loss: 0.006225
 >> iter 58000, loss: 0.006220
 >> iter 59000, loss: 0.006129
 >> iter 60000, loss: 0.006126
   Number of active neurons: 8
 >> iter 61000, loss: 0.006039
 >> iter 62000, loss: 0.006042
 >> iter 63000, loss: 0.005958
 >> iter 64000, loss: 0.005968
 >> iter 65000, loss: 0.005887
 >> iter 66000, loss: 0.005901
 >> iter 67000, loss: 0.005825
 >> iter 68000, loss: 0.005842
 >> iter 69000, loss: 0.005768
 >> iter 70000, loss: 0.005788
   Number of active neurons: 8
 >> iter 71000, loss: 0.005718
 >> iter 72000, loss: 0.005741
 >> iter 73000, loss: 0.005673
 >> iter 74000, loss: 0.005699
 >> iter 75000, loss: 0.005633
 >> iter 76000, loss: 0.005661
 >> iter 77000, loss: 0.005598
 >> iter 78000, loss: 0.005626
 >> iter 79000, loss: 0.005565
 >> iter 80000, loss: 0.005594
   Number of active neurons: 8
 >> iter 81000, loss: 0.005532
 >> iter 82000, loss: 0.005558
 >> iter 83000, loss: 0.005496
 >> iter 84000, loss: 0.005521
 >> iter 85000, loss: 0.005462
 >> iter 86000, loss: 0.005487
 >> iter 87000, loss: 0.005432
 >> iter 88000, loss: 0.005455
 >> iter 89000, loss: 0.005400
 >> iter 90000, loss: 0.005423
   Number of active neurons: 8
 >> iter 91000, loss: 0.005372
 >> iter 92000, loss: 0.005393
 >> iter 93000, loss: 0.005346
 >> iter 94000, loss: 0.005363
 >> iter 95000, loss: 0.005318
 >> iter 96000, loss: 0.005331
 >> iter 97000, loss: 0.005289
 >> iter 98000, loss: 0.005299
 >> iter 99000, loss: 0.005259
 >> iter 100000, loss: 0.005265
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 30.7246183588
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.632325
 >> iter 2000, loss: 15.115713
 >> iter 3000, loss: 13.783761
 >> iter 4000, loss: 13.285584
 >> iter 5000, loss: 13.083126
 >> iter 6000, loss: 13.009163
 >> iter 7000, loss: 12.969509
 >> iter 8000, loss: 12.961165
 >> iter 9000, loss: 12.946857
 >> iter 10000, loss: 12.952222
   Number of active neurons: 4
 >> iter 11000, loss: 12.940673
 >> iter 12000, loss: 12.946518
 >> iter 13000, loss: 12.935819
 >> iter 14000, loss: 12.943134
 >> iter 15000, loss: 12.934391
 >> iter 16000, loss: 12.906227
 >> iter 17000, loss: 12.312984
 >> iter 18000, loss: 10.689144
 >> iter 19000, loss: 4.051735
 >> iter 20000, loss: 1.525043
   Number of active neurons: 9
 >> iter 21000, loss: 0.582492
 >> iter 22000, loss: 0.230481
 >> iter 23000, loss: 0.097658
 >> iter 24000, loss: 0.046884
 >> iter 25000, loss: 0.026558
 >> iter 26000, loss: 0.018061
 >> iter 27000, loss: 0.014010
 >> iter 28000, loss: 0.011953
 >> iter 29000, loss: 0.010647
 >> iter 30000, loss: 0.009846
   Number of active neurons: 9
 >> iter 31000, loss: 0.009187
 >> iter 32000, loss: 0.008758
 >> iter 33000, loss: 0.008340
 >> iter 34000, loss: 0.008077
 >> iter 35000, loss: 0.007780
 >> iter 36000, loss: 0.007612
 >> iter 37000, loss: 0.007383
 >> iter 38000, loss: 0.007273
 >> iter 39000, loss: 0.007088
 >> iter 40000, loss: 0.007017
   Number of active neurons: 9
 >> iter 41000, loss: 0.006869
 >> iter 42000, loss: 0.006814
 >> iter 43000, loss: 0.006696
 >> iter 44000, loss: 0.006661
 >> iter 45000, loss: 0.006564
 >> iter 46000, loss: 0.006544
 >> iter 47000, loss: 0.006460
 >> iter 48000, loss: 0.006449
 >> iter 49000, loss: 0.006380
 >> iter 50000, loss: 0.006371
   Number of active neurons: 9
 >> iter 51000, loss: 0.006302
 >> iter 52000, loss: 0.006296
 >> iter 53000, loss: 0.006227
 >> iter 54000, loss: 0.006228
 >> iter 55000, loss: 0.006163
 >> iter 56000, loss: 0.006165
 >> iter 57000, loss: 0.006104
 >> iter 58000, loss: 0.006107
 >> iter 59000, loss: 0.006052
 >> iter 60000, loss: 0.006064
   Number of active neurons: 9
 >> iter 61000, loss: 0.006002
 >> iter 62000, loss: 0.006015
 >> iter 63000, loss: 0.005954
 >> iter 64000, loss: 0.005979
 >> iter 65000, loss: 0.005912
 >> iter 66000, loss: 0.005934
 >> iter 67000, loss: 0.005871
 >> iter 68000, loss: 0.005896
 >> iter 69000, loss: 0.005833
 >> iter 70000, loss: 0.005858
   Number of active neurons: 9
 >> iter 71000, loss: 0.005799
 >> iter 72000, loss: 0.005827
 >> iter 73000, loss: 0.005768
 >> iter 74000, loss: 0.005798
 >> iter 75000, loss: 0.005739
 >> iter 76000, loss: 0.005769
 >> iter 77000, loss: 0.005709
 >> iter 78000, loss: 0.005738
 >> iter 79000, loss: 0.005678
 >> iter 80000, loss: 0.005707
   Number of active neurons: 9
 >> iter 81000, loss: 0.005648
 >> iter 82000, loss: 0.005678
 >> iter 83000, loss: 0.005622
 >> iter 84000, loss: 0.005651
 >> iter 85000, loss: 0.005597
 >> iter 86000, loss: 0.005625
 >> iter 87000, loss: 0.005572
 >> iter 88000, loss: 0.005603
 >> iter 89000, loss: 0.005551
 >> iter 90000, loss: 0.005583
   Number of active neurons: 9
 >> iter 91000, loss: 0.005533
 >> iter 92000, loss: 0.005565
 >> iter 93000, loss: 0.005517
 >> iter 94000, loss: 0.005549
 >> iter 95000, loss: 0.005503
 >> iter 96000, loss: 0.005536
 >> iter 97000, loss: 0.005491
 >> iter 98000, loss: 0.005523
 >> iter 99000, loss: 0.005479
 >> iter 100000, loss: 0.005512
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0139998600014
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.594297
 >> iter 2000, loss: 15.088063
 >> iter 3000, loss: 13.763426
 >> iter 4000, loss: 13.271176
 >> iter 5000, loss: 13.071062
 >> iter 6000, loss: 13.000139
 >> iter 7000, loss: 12.961414
 >> iter 8000, loss: 12.955088
 >> iter 9000, loss: 12.940203
 >> iter 10000, loss: 12.945537
   Number of active neurons: 5
 >> iter 11000, loss: 12.932496
 >> iter 12000, loss: 12.937711
 >> iter 13000, loss: 12.925983
 >> iter 14000, loss: 12.931848
 >> iter 15000, loss: 12.806285
 >> iter 16000, loss: 12.043625
 >> iter 17000, loss: 5.765588
 >> iter 18000, loss: 2.153334
 >> iter 19000, loss: 0.811440
 >> iter 20000, loss: 0.312494
   Number of active neurons: 8
 >> iter 21000, loss: 0.126404
 >> iter 22000, loss: 0.056096
 >> iter 23000, loss: 0.029208
 >> iter 24000, loss: 0.018370
 >> iter 25000, loss: 0.013843
 >> iter 26000, loss: 0.011604
 >> iter 27000, loss: 0.010467
 >> iter 28000, loss: 0.009669
 >> iter 29000, loss: 0.009181
 >> iter 30000, loss: 0.008722
   Number of active neurons: 8
 >> iter 31000, loss: 0.008426
 >> iter 32000, loss: 0.008107
 >> iter 33000, loss: 0.007901
 >> iter 34000, loss: 0.007660
 >> iter 35000, loss: 0.007505
 >> iter 36000, loss: 0.007316
 >> iter 37000, loss: 0.007196
 >> iter 38000, loss: 0.007043
 >> iter 39000, loss: 0.006951
 >> iter 40000, loss: 0.006825
   Number of active neurons: 8
 >> iter 41000, loss: 0.006753
 >> iter 42000, loss: 0.006643
 >> iter 43000, loss: 0.006583
 >> iter 44000, loss: 0.006492
 >> iter 45000, loss: 0.006440
 >> iter 46000, loss: 0.006362
 >> iter 47000, loss: 0.006317
 >> iter 48000, loss: 0.006251
 >> iter 49000, loss: 0.006211
 >> iter 50000, loss: 0.006158
   Number of active neurons: 8
 >> iter 51000, loss: 0.006119
 >> iter 52000, loss: 0.006073
 >> iter 53000, loss: 0.006035
 >> iter 54000, loss: 0.005998
 >> iter 55000, loss: 0.005960
 >> iter 56000, loss: 0.005931
 >> iter 57000, loss: 0.005896
 >> iter 58000, loss: 0.005870
 >> iter 59000, loss: 0.005836
 >> iter 60000, loss: 0.005818
   Number of active neurons: 8
 >> iter 61000, loss: 0.005781
 >> iter 62000, loss: 0.005767
 >> iter 63000, loss: 0.005727
 >> iter 64000, loss: 0.005722
 >> iter 65000, loss: 0.005681
 >> iter 66000, loss: 0.005682
 >> iter 67000, loss: 0.005645
 >> iter 68000, loss: 0.005650
 >> iter 69000, loss: 0.005612
 >> iter 70000, loss: 0.005622
   Number of active neurons: 8
 >> iter 71000, loss: 0.005584
 >> iter 72000, loss: 0.005595
 >> iter 73000, loss: 0.005554
 >> iter 74000, loss: 0.005568
 >> iter 75000, loss: 0.005525
 >> iter 76000, loss: 0.005542
 >> iter 77000, loss: 0.005497
 >> iter 78000, loss: 0.005510
 >> iter 79000, loss: 0.005467
 >> iter 80000, loss: 0.005482
   Number of active neurons: 8
 >> iter 81000, loss: 0.005439
 >> iter 82000, loss: 0.005457
 >> iter 83000, loss: 0.005413
 >> iter 84000, loss: 0.005435
 >> iter 85000, loss: 0.005393
 >> iter 86000, loss: 0.005414
 >> iter 87000, loss: 0.005373
 >> iter 88000, loss: 0.005391
 >> iter 89000, loss: 0.005352
 >> iter 90000, loss: 0.005372
   Number of active neurons: 8
 >> iter 91000, loss: 0.005336
 >> iter 92000, loss: 0.005356
 >> iter 93000, loss: 0.005322
 >> iter 94000, loss: 0.005340
 >> iter 95000, loss: 0.005309
 >> iter 96000, loss: 0.005326
 >> iter 97000, loss: 0.005299
 >> iter 98000, loss: 0.005315
 >> iter 99000, loss: 0.005289
 >> iter 100000, loss: 0.005302
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

