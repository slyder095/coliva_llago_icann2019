 > Problema: tomita7nueva
 > Args:
   - Hidden size: 18
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.762816
 >> iter 2000, loss: 9.518779
 >> iter 3000, loss: 5.197363
 >> iter 4000, loss: 2.897769
 >> iter 5000, loss: 2.069972
 >> iter 6000, loss: 1.603323
 >> iter 7000, loss: 1.111766
 >> iter 8000, loss: 0.947865
 >> iter 9000, loss: 0.832654
 >> iter 10000, loss: 0.689854
   Number of active neurons: 6
 >> iter 11000, loss: 0.688769
 >> iter 12000, loss: 0.504921
 >> iter 13000, loss: 0.466890
 >> iter 14000, loss: 0.729201
 >> iter 15000, loss: 0.765894
 >> iter 16000, loss: 0.677014
 >> iter 17000, loss: 0.777793
 >> iter 18000, loss: 0.597762
 >> iter 19000, loss: 0.509407
 >> iter 20000, loss: 0.466361
   Number of active neurons: 6
 >> iter 21000, loss: 0.509914
 >> iter 22000, loss: 0.546396
 >> iter 23000, loss: 0.403474
 >> iter 24000, loss: 0.436768
 >> iter 25000, loss: 0.544233
 >> iter 26000, loss: 0.434510
 >> iter 27000, loss: 0.437320
 >> iter 28000, loss: 0.435354
 >> iter 29000, loss: 0.480882
 >> iter 30000, loss: 0.445104
   Number of active neurons: 6
 >> iter 31000, loss: 0.662640
 >> iter 32000, loss: 0.534600
 >> iter 33000, loss: 0.560582
 >> iter 34000, loss: 0.607158
 >> iter 35000, loss: 0.529490
 >> iter 36000, loss: 0.419600
 >> iter 37000, loss: 0.448136
 >> iter 38000, loss: 0.670388
 >> iter 39000, loss: 0.577451
 >> iter 40000, loss: 0.470153
   Number of active neurons: 6
 >> iter 41000, loss: 0.310404
 >> iter 42000, loss: 0.346875
 >> iter 43000, loss: 0.463295
 >> iter 44000, loss: 0.407838
 >> iter 45000, loss: 0.379297
 >> iter 46000, loss: 0.489126
 >> iter 47000, loss: 0.458779
 >> iter 48000, loss: 0.495269
 >> iter 49000, loss: 0.418948
 >> iter 50000, loss: 0.486037
   Number of active neurons: 6
 >> iter 51000, loss: 0.353651
 >> iter 52000, loss: 0.328733
 >> iter 53000, loss: 0.314484
 >> iter 54000, loss: 0.370884
 >> iter 55000, loss: 0.405903
 >> iter 56000, loss: 0.524449
 >> iter 57000, loss: 0.407257
 >> iter 58000, loss: 0.368977
 >> iter 59000, loss: 0.325666
 >> iter 60000, loss: 0.397925
   Number of active neurons: 6
 >> iter 61000, loss: 0.339265
 >> iter 62000, loss: 0.328061
 >> iter 63000, loss: 0.450303
 >> iter 64000, loss: 0.403221
 >> iter 65000, loss: 0.414564
 >> iter 66000, loss: 0.321972
 >> iter 67000, loss: 0.343199
 >> iter 68000, loss: 0.331395
 >> iter 69000, loss: 0.354695
 >> iter 70000, loss: 0.387338
   Number of active neurons: 6
 >> iter 71000, loss: 0.520379
 >> iter 72000, loss: 0.422893
 >> iter 73000, loss: 0.448297
 >> iter 74000, loss: 0.527482
 >> iter 75000, loss: 0.512813
 >> iter 76000, loss: 0.365619
 >> iter 77000, loss: 0.368601
 >> iter 78000, loss: 0.443473
 >> iter 79000, loss: 0.461656
 >> iter 80000, loss: 0.511899
   Number of active neurons: 6
 >> iter 81000, loss: 0.424370
 >> iter 82000, loss: 0.334356
 >> iter 83000, loss: 0.330484
 >> iter 84000, loss: 0.348998
 >> iter 85000, loss: 0.460503
 >> iter 86000, loss: 0.428217
 >> iter 87000, loss: 0.467801
 >> iter 88000, loss: 0.555880
 >> iter 89000, loss: 0.441168
 >> iter 90000, loss: 0.337631
   Number of active neurons: 6
 >> iter 91000, loss: 0.331789
 >> iter 92000, loss: 0.484924
 >> iter 93000, loss: 0.440664
 >> iter 94000, loss: 0.517497
 >> iter 95000, loss: 0.474599
 >> iter 96000, loss: 0.412008
 >> iter 97000, loss: 0.376948
 >> iter 98000, loss: 0.352670
 >> iter 99000, loss: 0.559635
 >> iter 100000, loss: 0.517129
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.769894
 >> iter 2000, loss: 9.672326
 >> iter 3000, loss: 4.885314
 >> iter 4000, loss: 2.131467
 >> iter 5000, loss: 1.057384
 >> iter 6000, loss: 0.538401
 >> iter 7000, loss: 0.309678
 >> iter 8000, loss: 0.340613
 >> iter 9000, loss: 0.225908
 >> iter 10000, loss: 0.236894
   Number of active neurons: 10
 >> iter 11000, loss: 0.185022
 >> iter 12000, loss: 0.162176
 >> iter 13000, loss: 0.172085
 >> iter 14000, loss: 0.255263
 >> iter 15000, loss: 0.299027
 >> iter 16000, loss: 0.305936
 >> iter 17000, loss: 0.258261
 >> iter 18000, loss: 0.221370
 >> iter 19000, loss: 0.305888
 >> iter 20000, loss: 0.308819
   Number of active neurons: 10
 >> iter 21000, loss: 0.380242
 >> iter 22000, loss: 0.221685
 >> iter 23000, loss: 0.270204
 >> iter 24000, loss: 0.309431
 >> iter 25000, loss: 0.251153
 >> iter 26000, loss: 0.232346
 >> iter 27000, loss: 0.284671
 >> iter 28000, loss: 0.253754
 >> iter 29000, loss: 0.385745
 >> iter 30000, loss: 0.348518
   Number of active neurons: 9
 >> iter 31000, loss: 0.374522
 >> iter 32000, loss: 0.268371
 >> iter 33000, loss: 0.327594
 >> iter 34000, loss: 0.262592
 >> iter 35000, loss: 0.208934
 >> iter 36000, loss: 0.220759
 >> iter 37000, loss: 0.254382
 >> iter 38000, loss: 0.327347
 >> iter 39000, loss: 0.285836
 >> iter 40000, loss: 0.271290
   Number of active neurons: 9
 >> iter 41000, loss: 0.239333
 >> iter 42000, loss: 0.244738
 >> iter 43000, loss: 0.245901
 >> iter 44000, loss: 0.243995
 >> iter 45000, loss: 0.214249
 >> iter 46000, loss: 0.181916
 >> iter 47000, loss: 0.211428
 >> iter 48000, loss: 0.208676
 >> iter 49000, loss: 0.310485
 >> iter 50000, loss: 0.249862
   Number of active neurons: 7
 >> iter 51000, loss: 0.268587
 >> iter 52000, loss: 0.279744
 >> iter 53000, loss: 0.232650
 >> iter 54000, loss: 0.179548
 >> iter 55000, loss: 0.302896
 >> iter 56000, loss: 0.303930
 >> iter 57000, loss: 0.274371
 >> iter 58000, loss: 0.280609
 >> iter 59000, loss: 0.307285
 >> iter 60000, loss: 0.265753
   Number of active neurons: 7
 >> iter 61000, loss: 0.218002
 >> iter 62000, loss: 0.286438
 >> iter 63000, loss: 0.432768
 >> iter 64000, loss: 0.311900
 >> iter 65000, loss: 0.272091
 >> iter 66000, loss: 0.340555
 >> iter 67000, loss: 0.330254
 >> iter 68000, loss: 0.324845
 >> iter 69000, loss: 0.293141
 >> iter 70000, loss: 0.291603
   Number of active neurons: 7
 >> iter 71000, loss: 0.267891
 >> iter 72000, loss: 0.250990
 >> iter 73000, loss: 0.279070
 >> iter 74000, loss: 0.292353
 >> iter 75000, loss: 0.441810
 >> iter 76000, loss: 0.347383
 >> iter 77000, loss: 0.343839
 >> iter 78000, loss: 0.346778
 >> iter 79000, loss: 0.346012
 >> iter 80000, loss: 0.360219
   Number of active neurons: 7
 >> iter 81000, loss: 0.328138
 >> iter 82000, loss: 0.298375
 >> iter 83000, loss: 0.305968
 >> iter 84000, loss: 0.255133
 >> iter 85000, loss: 0.232610
 >> iter 86000, loss: 0.270662
 >> iter 87000, loss: 0.369941
 >> iter 88000, loss: 0.337469
 >> iter 89000, loss: 0.231003
 >> iter 90000, loss: 0.235371
   Number of active neurons: 7
 >> iter 91000, loss: 0.212748
 >> iter 92000, loss: 0.303041
 >> iter 93000, loss: 0.323540
 >> iter 94000, loss: 0.352665
 >> iter 95000, loss: 0.343449
 >> iter 96000, loss: 0.386989
 >> iter 97000, loss: 0.349217
 >> iter 98000, loss: 0.406912
 >> iter 99000, loss: 0.357437
 >> iter 100000, loss: 0.210705
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.532021
 >> iter 2000, loss: 11.643827
 >> iter 3000, loss: 5.899306
 >> iter 4000, loss: 2.808296
 >> iter 5000, loss: 1.622941
 >> iter 6000, loss: 0.914556
 >> iter 7000, loss: 0.610853
 >> iter 8000, loss: 0.452493
 >> iter 9000, loss: 0.338950
 >> iter 10000, loss: 0.323875
   Number of active neurons: 6
 >> iter 11000, loss: 0.388333
 >> iter 12000, loss: 0.367150
 >> iter 13000, loss: 0.389930
 >> iter 14000, loss: 0.328798
 >> iter 15000, loss: 0.373637
 >> iter 16000, loss: 0.331616
 >> iter 17000, loss: 0.288625
 >> iter 18000, loss: 0.357637
 >> iter 19000, loss: 0.403991
 >> iter 20000, loss: 0.360741
   Number of active neurons: 6
 >> iter 21000, loss: 0.251900
 >> iter 22000, loss: 0.238943
 >> iter 23000, loss: 0.430916
 >> iter 24000, loss: 0.318734
 >> iter 25000, loss: 0.283283
 >> iter 26000, loss: 0.309120
 >> iter 27000, loss: 0.397998
 >> iter 28000, loss: 0.380237
 >> iter 29000, loss: 0.365169
 >> iter 30000, loss: 0.311002
   Number of active neurons: 6
 >> iter 31000, loss: 0.415169
 >> iter 32000, loss: 0.438913
 >> iter 33000, loss: 0.267602
 >> iter 34000, loss: 0.320449
 >> iter 35000, loss: 0.353512
 >> iter 36000, loss: 0.257082
 >> iter 37000, loss: 0.217863
 >> iter 38000, loss: 0.338194
 >> iter 39000, loss: 0.315694
 >> iter 40000, loss: 0.216089
   Number of active neurons: 6
 >> iter 41000, loss: 0.257436
 >> iter 42000, loss: 0.283030
 >> iter 43000, loss: 0.259367
 >> iter 44000, loss: 0.268817
 >> iter 45000, loss: 0.250656
 >> iter 46000, loss: 0.237013
 >> iter 47000, loss: 0.338373
 >> iter 48000, loss: 0.249551
 >> iter 49000, loss: 0.291590
 >> iter 50000, loss: 0.274453
   Number of active neurons: 6
 >> iter 51000, loss: 0.202276
 >> iter 52000, loss: 0.310360
 >> iter 53000, loss: 0.236610
 >> iter 54000, loss: 0.262590
 >> iter 55000, loss: 0.253902
 >> iter 56000, loss: 0.235223
 >> iter 57000, loss: 0.224304
 >> iter 58000, loss: 0.312112
 >> iter 59000, loss: 0.213232
 >> iter 60000, loss: 0.203732
   Number of active neurons: 6
 >> iter 61000, loss: 0.252268
 >> iter 62000, loss: 0.338037
 >> iter 63000, loss: 0.290007
 >> iter 64000, loss: 0.276968
 >> iter 65000, loss: 0.341101
 >> iter 66000, loss: 0.329160
 >> iter 67000, loss: 0.287954
 >> iter 68000, loss: 0.290172
 >> iter 69000, loss: 0.251353
 >> iter 70000, loss: 0.235077
   Number of active neurons: 6
 >> iter 71000, loss: 0.251096
 >> iter 72000, loss: 0.270797
 >> iter 73000, loss: 0.229232
 >> iter 74000, loss: 0.220767
 >> iter 75000, loss: 0.439072
 >> iter 76000, loss: 0.287040
 >> iter 77000, loss: 0.370857
 >> iter 78000, loss: 0.262254
 >> iter 79000, loss: 0.282472
 >> iter 80000, loss: 0.219770
   Number of active neurons: 6
 >> iter 81000, loss: 0.257925
 >> iter 82000, loss: 0.314878
 >> iter 83000, loss: 0.327659
 >> iter 84000, loss: 0.302629
 >> iter 85000, loss: 0.352588
 >> iter 86000, loss: 0.233887
 >> iter 87000, loss: 0.247124
 >> iter 88000, loss: 0.227966
 >> iter 89000, loss: 0.300070
 >> iter 90000, loss: 0.294680
   Number of active neurons: 6
 >> iter 91000, loss: 0.234134
 >> iter 92000, loss: 0.301979
 >> iter 93000, loss: 0.314884
 >> iter 94000, loss: 0.260481
 >> iter 95000, loss: 0.226493
 >> iter 96000, loss: 0.274585
 >> iter 97000, loss: 0.297255
 >> iter 98000, loss: 0.339757
 >> iter 99000, loss: 0.310679
 >> iter 100000, loss: 0.301067
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 16.986825
 >> iter 2000, loss: 9.423421
 >> iter 3000, loss: 5.157432
 >> iter 4000, loss: 3.214420
 >> iter 5000, loss: 1.989049
 >> iter 6000, loss: 1.544979
 >> iter 7000, loss: 0.979732
 >> iter 8000, loss: 0.723497
 >> iter 9000, loss: 0.537831
 >> iter 10000, loss: 0.450427
   Number of active neurons: 5
 >> iter 11000, loss: 0.550464
 >> iter 12000, loss: 0.479193
 >> iter 13000, loss: 0.516521
 >> iter 14000, loss: 0.415457
 >> iter 15000, loss: 0.444771
 >> iter 16000, loss: 0.499474
 >> iter 17000, loss: 0.436344
 >> iter 18000, loss: 0.716960
 >> iter 19000, loss: 0.577510
 >> iter 20000, loss: 0.405111
   Number of active neurons: 5
 >> iter 21000, loss: 0.373738
 >> iter 22000, loss: 0.362546
 >> iter 23000, loss: 0.349378
 >> iter 24000, loss: 0.293409
 >> iter 25000, loss: 0.358088
 >> iter 26000, loss: 0.377595
 >> iter 27000, loss: 0.404751
 >> iter 28000, loss: 0.355178
 >> iter 29000, loss: 0.417003
 >> iter 30000, loss: 0.319012
   Number of active neurons: 5
 >> iter 31000, loss: 0.395040
 >> iter 32000, loss: 0.354769
 >> iter 33000, loss: 0.530278
 >> iter 34000, loss: 0.601335
 >> iter 35000, loss: 0.499967
 >> iter 36000, loss: 0.411884
 >> iter 37000, loss: 0.399636
 >> iter 38000, loss: 0.461865
 >> iter 39000, loss: 0.571681
 >> iter 40000, loss: 0.520487
   Number of active neurons: 5
 >> iter 41000, loss: 0.574316
 >> iter 42000, loss: 0.583425
 >> iter 43000, loss: 0.470176
 >> iter 44000, loss: 0.584394
 >> iter 45000, loss: 0.548105
 >> iter 46000, loss: 0.529875
 >> iter 47000, loss: 0.446951
 >> iter 48000, loss: 0.530771
 >> iter 49000, loss: 0.503168
 >> iter 50000, loss: 0.458415
   Number of active neurons: 5
 >> iter 51000, loss: 0.548265
 >> iter 52000, loss: 0.535248
 >> iter 53000, loss: 0.459017
 >> iter 54000, loss: 0.469744
 >> iter 55000, loss: 0.473877
 >> iter 56000, loss: 0.495348
 >> iter 57000, loss: 0.559598
 >> iter 58000, loss: 0.446883
 >> iter 59000, loss: 0.364857
 >> iter 60000, loss: 0.426421
   Number of active neurons: 5
 >> iter 61000, loss: 0.440280
 >> iter 62000, loss: 0.388447
 >> iter 63000, loss: 0.426350
 >> iter 64000, loss: 0.480650
 >> iter 65000, loss: 0.450038
 >> iter 66000, loss: 0.489087
 >> iter 67000, loss: 0.612036
 >> iter 68000, loss: 0.567762
 >> iter 69000, loss: 0.441900
 >> iter 70000, loss: 0.406416
   Number of active neurons: 5
 >> iter 71000, loss: 0.554815
 >> iter 72000, loss: 0.369965
 >> iter 73000, loss: 0.494790
 >> iter 74000, loss: 0.581546
 >> iter 75000, loss: 0.457514
 >> iter 76000, loss: 0.483149
 >> iter 77000, loss: 0.454440
 >> iter 78000, loss: 0.546983
 >> iter 79000, loss: 0.579124
 >> iter 80000, loss: 0.518585
   Number of active neurons: 5
 >> iter 81000, loss: 0.530343
 >> iter 82000, loss: 0.542533
 >> iter 83000, loss: 0.431045
 >> iter 84000, loss: 0.418809
 >> iter 85000, loss: 0.430668
 >> iter 86000, loss: 0.508361
 >> iter 87000, loss: 0.553569
 >> iter 88000, loss: 0.562258
 >> iter 89000, loss: 0.441381
 >> iter 90000, loss: 0.430737
   Number of active neurons: 5
 >> iter 91000, loss: 0.521445
 >> iter 92000, loss: 0.487595
 >> iter 93000, loss: 0.430451
 >> iter 94000, loss: 0.480015
 >> iter 95000, loss: 0.532043
 >> iter 96000, loss: 0.476107
 >> iter 97000, loss: 0.441848
 >> iter 98000, loss: 0.465969
 >> iter 99000, loss: 0.408458
 >> iter 100000, loss: 0.539567
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.025787
 >> iter 2000, loss: 10.038100
 >> iter 3000, loss: 6.402865
 >> iter 4000, loss: 3.392021
 >> iter 5000, loss: 1.993443
 >> iter 6000, loss: 1.384825
 >> iter 7000, loss: 1.040506
 >> iter 8000, loss: 0.915983
 >> iter 9000, loss: 0.854074
 >> iter 10000, loss: 0.690078
   Number of active neurons: 6
 >> iter 11000, loss: 0.696787
 >> iter 12000, loss: 0.705865
 >> iter 13000, loss: 0.774436
 >> iter 14000, loss: 0.762168
 >> iter 15000, loss: 0.677342
 >> iter 16000, loss: 0.554362
 >> iter 17000, loss: 0.480361
 >> iter 18000, loss: 0.561221
 >> iter 19000, loss: 0.521053
 >> iter 20000, loss: 0.427785
   Number of active neurons: 5
 >> iter 21000, loss: 0.540768
 >> iter 22000, loss: 0.503150
 >> iter 23000, loss: 0.475996
 >> iter 24000, loss: 0.572370
 >> iter 25000, loss: 0.549813
 >> iter 26000, loss: 0.484766
 >> iter 27000, loss: 0.391480
 >> iter 28000, loss: 0.388725
 >> iter 29000, loss: 0.407638
 >> iter 30000, loss: 0.581520
   Number of active neurons: 5
 >> iter 31000, loss: 0.548397
 >> iter 32000, loss: 0.469827
 >> iter 33000, loss: 0.353643
 >> iter 34000, loss: 0.523542
 >> iter 35000, loss: 0.591556
 >> iter 36000, loss: 0.493149
 >> iter 37000, loss: 0.413421
 >> iter 38000, loss: 0.530788
 >> iter 39000, loss: 0.380829
 >> iter 40000, loss: 0.486424
   Number of active neurons: 5
 >> iter 41000, loss: 0.464556
 >> iter 42000, loss: 0.567147
 >> iter 43000, loss: 0.431426
 >> iter 44000, loss: 0.455290
 >> iter 45000, loss: 0.477062
 >> iter 46000, loss: 0.426413
 >> iter 47000, loss: 0.427601
 >> iter 48000, loss: 0.480834
 >> iter 49000, loss: 0.392327
 >> iter 50000, loss: 0.525479
   Number of active neurons: 5
 >> iter 51000, loss: 0.498701
 >> iter 52000, loss: 0.569917
 >> iter 53000, loss: 0.583051
 >> iter 54000, loss: 0.459074
 >> iter 55000, loss: 0.459523
 >> iter 56000, loss: 0.439005
 >> iter 57000, loss: 0.358608
 >> iter 58000, loss: 0.535372
 >> iter 59000, loss: 0.546937
 >> iter 60000, loss: 0.504633
   Number of active neurons: 5
 >> iter 61000, loss: 0.479319
 >> iter 62000, loss: 0.477137
 >> iter 63000, loss: 0.443654
 >> iter 64000, loss: 0.484628
 >> iter 65000, loss: 0.620752
 >> iter 66000, loss: 0.632042
 >> iter 67000, loss: 0.487482
 >> iter 68000, loss: 0.439196
 >> iter 69000, loss: 0.473900
 >> iter 70000, loss: 0.356486
   Number of active neurons: 5
 >> iter 71000, loss: 0.409143
 >> iter 72000, loss: 0.439202
 >> iter 73000, loss: 0.334254
 >> iter 74000, loss: 0.415829
 >> iter 75000, loss: 0.467574
 >> iter 76000, loss: 0.440853
 >> iter 77000, loss: 0.381222
 >> iter 78000, loss: 0.390636
 >> iter 79000, loss: 0.542626
 >> iter 80000, loss: 0.413832
   Number of active neurons: 5
 >> iter 81000, loss: 0.572763
 >> iter 82000, loss: 0.402791
 >> iter 83000, loss: 0.435243
 >> iter 84000, loss: 0.443954
 >> iter 85000, loss: 0.699214
 >> iter 86000, loss: 0.505107
 >> iter 87000, loss: 0.535126
 >> iter 88000, loss: 0.512950
 >> iter 89000, loss: 0.565747
 >> iter 90000, loss: 0.405887
   Number of active neurons: 5
 >> iter 91000, loss: 0.388412
 >> iter 92000, loss: 0.381091
 >> iter 93000, loss: 0.506830
 >> iter 94000, loss: 0.407115
 >> iter 95000, loss: 0.546622
 >> iter 96000, loss: 0.490975
 >> iter 97000, loss: 0.446060
 >> iter 98000, loss: 0.500263
 >> iter 99000, loss: 0.456621
 >> iter 100000, loss: 0.565716
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.189137
 >> iter 2000, loss: 10.321965
 >> iter 3000, loss: 5.848590
 >> iter 4000, loss: 2.631594
 >> iter 5000, loss: 1.306977
 >> iter 6000, loss: 0.733707
 >> iter 7000, loss: 0.536155
 >> iter 8000, loss: 0.434835
 >> iter 9000, loss: 0.287770
 >> iter 10000, loss: 0.434315
   Number of active neurons: 12
 >> iter 11000, loss: 0.385845
 >> iter 12000, loss: 0.431952
 >> iter 13000, loss: 0.468400
 >> iter 14000, loss: 0.426035
 >> iter 15000, loss: 0.381846
 >> iter 16000, loss: 0.311300
 >> iter 17000, loss: 0.276088
 >> iter 18000, loss: 0.354216
 >> iter 19000, loss: 0.266406
 >> iter 20000, loss: 0.288623
   Number of active neurons: 11
 >> iter 21000, loss: 0.400597
 >> iter 22000, loss: 0.432812
 >> iter 23000, loss: 0.543643
 >> iter 24000, loss: 0.372507
 >> iter 25000, loss: 0.390463
 >> iter 26000, loss: 0.405463
 >> iter 27000, loss: 0.393109
 >> iter 28000, loss: 0.309422
 >> iter 29000, loss: 0.278445
 >> iter 30000, loss: 0.311157
   Number of active neurons: 10
 >> iter 31000, loss: 0.275153
 >> iter 32000, loss: 0.368875
 >> iter 33000, loss: 0.330809
 >> iter 34000, loss: 0.399774
 >> iter 35000, loss: 0.277745
 >> iter 36000, loss: 0.322673
 >> iter 37000, loss: 0.477058
 >> iter 38000, loss: 0.325992
 >> iter 39000, loss: 0.390250
 >> iter 40000, loss: 0.392597
   Number of active neurons: 10
 >> iter 41000, loss: 0.414299
 >> iter 42000, loss: 0.401593
 >> iter 43000, loss: 0.408452
 >> iter 44000, loss: 0.328589
 >> iter 45000, loss: 0.414410
 >> iter 46000, loss: 0.332750
 >> iter 47000, loss: 0.453151
 >> iter 48000, loss: 0.407391
 >> iter 49000, loss: 0.402583
 >> iter 50000, loss: 0.447283
   Number of active neurons: 9
 >> iter 51000, loss: 0.423622
 >> iter 52000, loss: 0.386917
 >> iter 53000, loss: 0.477183
 >> iter 54000, loss: 0.476265
 >> iter 55000, loss: 0.460663
 >> iter 56000, loss: 0.384503
 >> iter 57000, loss: 0.253022
 >> iter 58000, loss: 0.479588
 >> iter 59000, loss: 0.379857
 >> iter 60000, loss: 0.515868
   Number of active neurons: 9
 >> iter 61000, loss: 0.555761
 >> iter 62000, loss: 0.414411
 >> iter 63000, loss: 0.577659
 >> iter 64000, loss: 0.462901
 >> iter 65000, loss: 0.681892
 >> iter 66000, loss: 0.524399
 >> iter 67000, loss: 0.378384
 >> iter 68000, loss: 0.438539
 >> iter 69000, loss: 0.348587
 >> iter 70000, loss: 0.438362
   Number of active neurons: 9
 >> iter 71000, loss: 0.444864
 >> iter 72000, loss: 0.453861
 >> iter 73000, loss: 0.342370
 >> iter 74000, loss: 0.424365
 >> iter 75000, loss: 0.542981
 >> iter 76000, loss: 0.375690
 >> iter 77000, loss: 0.432735
 >> iter 78000, loss: 0.306016
 >> iter 79000, loss: 0.236105
 >> iter 80000, loss: 0.349954
   Number of active neurons: 9
 >> iter 81000, loss: 0.243059
 >> iter 82000, loss: 0.288341
 >> iter 83000, loss: 0.280099
 >> iter 84000, loss: 0.223828
 >> iter 85000, loss: 0.351758
 >> iter 86000, loss: 0.332695
 >> iter 87000, loss: 0.236002
 >> iter 88000, loss: 0.354451
 >> iter 89000, loss: 0.285080
 >> iter 90000, loss: 0.328408
   Number of active neurons: 9
 >> iter 91000, loss: 0.363514
 >> iter 92000, loss: 0.303823
 >> iter 93000, loss: 0.255320
 >> iter 94000, loss: 0.364828
 >> iter 95000, loss: 0.334105
 >> iter 96000, loss: 0.406471
 >> iter 97000, loss: 0.412216
 >> iter 98000, loss: 0.292383
 >> iter 99000, loss: 0.218848
 >> iter 100000, loss: 0.366901
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.995615
 >> iter 2000, loss: 9.929190
 >> iter 3000, loss: 5.688965
 >> iter 4000, loss: 2.589917
 >> iter 5000, loss: 1.207539
 >> iter 6000, loss: 0.587498
 >> iter 7000, loss: 0.336795
 >> iter 8000, loss: 0.272282
 >> iter 9000, loss: 0.234928
 >> iter 10000, loss: 0.303580
   Number of active neurons: 9
 >> iter 11000, loss: 0.309396
 >> iter 12000, loss: 0.286292
 >> iter 13000, loss: 0.259456
 >> iter 14000, loss: 0.195304
 >> iter 15000, loss: 0.276331
 >> iter 16000, loss: 0.350426
 >> iter 17000, loss: 0.270946
 >> iter 18000, loss: 0.231822
 >> iter 19000, loss: 0.284033
 >> iter 20000, loss: 0.227753
   Number of active neurons: 9
 >> iter 21000, loss: 0.217305
 >> iter 22000, loss: 0.308469
 >> iter 23000, loss: 0.310248
 >> iter 24000, loss: 0.256717
 >> iter 25000, loss: 0.263674
 >> iter 26000, loss: 0.270001
 >> iter 27000, loss: 0.283520
 >> iter 28000, loss: 0.339394
 >> iter 29000, loss: 0.378441
 >> iter 30000, loss: 0.267746
   Number of active neurons: 9
 >> iter 31000, loss: 0.253919
 >> iter 32000, loss: 0.250133
 >> iter 33000, loss: 0.233651
 >> iter 34000, loss: 0.250455
 >> iter 35000, loss: 0.186246
 >> iter 36000, loss: 0.223228
 >> iter 37000, loss: 0.204553
 >> iter 38000, loss: 0.207897
 >> iter 39000, loss: 0.312386
 >> iter 40000, loss: 0.235386
   Number of active neurons: 9
 >> iter 41000, loss: 0.329334
 >> iter 42000, loss: 0.294914
 >> iter 43000, loss: 0.286116
 >> iter 44000, loss: 0.206971
 >> iter 45000, loss: 0.321792
 >> iter 46000, loss: 0.281992
 >> iter 47000, loss: 0.239096
 >> iter 48000, loss: 0.206114
 >> iter 49000, loss: 0.211682
 >> iter 50000, loss: 0.228220
   Number of active neurons: 9
 >> iter 51000, loss: 0.201349
 >> iter 52000, loss: 0.215313
 >> iter 53000, loss: 0.263517
 >> iter 54000, loss: 0.264597
 >> iter 55000, loss: 0.351462
 >> iter 56000, loss: 0.319714
 >> iter 57000, loss: 0.261118
 >> iter 58000, loss: 0.213359
 >> iter 59000, loss: 0.262936
 >> iter 60000, loss: 0.208447
   Number of active neurons: 9
 >> iter 61000, loss: 0.273070
 >> iter 62000, loss: 0.280071
 >> iter 63000, loss: 0.229217
 >> iter 64000, loss: 0.240041
 >> iter 65000, loss: 0.191877
 >> iter 66000, loss: 0.191453
 >> iter 67000, loss: 0.317893
 >> iter 68000, loss: 0.291519
 >> iter 69000, loss: 0.257056
 >> iter 70000, loss: 0.219264
   Number of active neurons: 9
 >> iter 71000, loss: 0.265529
 >> iter 72000, loss: 0.319593
 >> iter 73000, loss: 0.284285
 >> iter 74000, loss: 0.201822
 >> iter 75000, loss: 0.156111
 >> iter 76000, loss: 0.218496
 >> iter 77000, loss: 0.204304
 >> iter 78000, loss: 0.186229
 >> iter 79000, loss: 0.338018
 >> iter 80000, loss: 0.244461
   Number of active neurons: 9
 >> iter 81000, loss: 0.225563
 >> iter 82000, loss: 0.224825
 >> iter 83000, loss: 0.236893
 >> iter 84000, loss: 0.304660
 >> iter 85000, loss: 0.367300
 >> iter 86000, loss: 0.264934
 >> iter 87000, loss: 0.232306
 >> iter 88000, loss: 0.200966
 >> iter 89000, loss: 0.169980
 >> iter 90000, loss: 0.145951
   Number of active neurons: 9
 >> iter 91000, loss: 0.188265
 >> iter 92000, loss: 0.286048
 >> iter 93000, loss: 0.275906
 >> iter 94000, loss: 0.262957
 >> iter 95000, loss: 0.294198
 >> iter 96000, loss: 0.256383
 >> iter 97000, loss: 0.198082
 >> iter 98000, loss: 0.195778
 >> iter 99000, loss: 0.214717
 >> iter 100000, loss: 0.160961
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.711211
 >> iter 2000, loss: 9.815048
 >> iter 3000, loss: 6.232176
 >> iter 4000, loss: 2.964257
 >> iter 5000, loss: 1.505830
 >> iter 6000, loss: 0.769168
 >> iter 7000, loss: 0.619772
 >> iter 8000, loss: 0.374574
 >> iter 9000, loss: 0.351877
 >> iter 10000, loss: 0.403373
   Number of active neurons: 9
 >> iter 11000, loss: 0.372078
 >> iter 12000, loss: 0.279653
 >> iter 13000, loss: 0.304802
 >> iter 14000, loss: 0.300015
 >> iter 15000, loss: 0.391942
 >> iter 16000, loss: 0.294296
 >> iter 17000, loss: 0.383260
 >> iter 18000, loss: 0.322327
 >> iter 19000, loss: 0.358659
 >> iter 20000, loss: 0.313426
   Number of active neurons: 8
 >> iter 21000, loss: 0.238347
 >> iter 22000, loss: 0.325945
 >> iter 23000, loss: 0.334602
 >> iter 24000, loss: 0.322423
 >> iter 25000, loss: 0.287777
 >> iter 26000, loss: 0.279217
 >> iter 27000, loss: 0.306966
 >> iter 28000, loss: 0.283875
 >> iter 29000, loss: 0.255558
 >> iter 30000, loss: 0.303303
   Number of active neurons: 8
 >> iter 31000, loss: 0.267502
 >> iter 32000, loss: 0.245879
 >> iter 33000, loss: 0.356667
 >> iter 34000, loss: 0.343077
 >> iter 35000, loss: 0.302074
 >> iter 36000, loss: 0.358471
 >> iter 37000, loss: 0.383307
 >> iter 38000, loss: 0.485851
 >> iter 39000, loss: 0.548040
 >> iter 40000, loss: 0.337670
   Number of active neurons: 7
 >> iter 41000, loss: 0.349390
 >> iter 42000, loss: 0.321787
 >> iter 43000, loss: 0.351713
 >> iter 44000, loss: 0.256718
 >> iter 45000, loss: 0.305998
 >> iter 46000, loss: 0.317123
 >> iter 47000, loss: 0.284926
 >> iter 48000, loss: 0.214336
 >> iter 49000, loss: 0.295661
 >> iter 50000, loss: 0.268843
   Number of active neurons: 7
 >> iter 51000, loss: 0.271905
 >> iter 52000, loss: 0.287400
 >> iter 53000, loss: 0.351398
 >> iter 54000, loss: 0.320278
 >> iter 55000, loss: 0.250799
 >> iter 56000, loss: 0.216298
 >> iter 57000, loss: 0.286094
 >> iter 58000, loss: 0.278575
 >> iter 59000, loss: 0.353386
 >> iter 60000, loss: 0.368075
   Number of active neurons: 7
 >> iter 61000, loss: 0.330275
 >> iter 62000, loss: 0.287705
 >> iter 63000, loss: 0.299584
 >> iter 64000, loss: 0.289770
 >> iter 65000, loss: 0.241428
 >> iter 66000, loss: 0.413075
 >> iter 67000, loss: 0.292670
 >> iter 68000, loss: 0.238384
 >> iter 69000, loss: 0.278571
 >> iter 70000, loss: 0.280446
   Number of active neurons: 7
 >> iter 71000, loss: 0.226592
 >> iter 72000, loss: 0.327870
 >> iter 73000, loss: 0.339426
 >> iter 74000, loss: 0.272849
 >> iter 75000, loss: 0.203217
 >> iter 76000, loss: 0.273734
 >> iter 77000, loss: 0.370941
 >> iter 78000, loss: 0.293345
 >> iter 79000, loss: 0.257032
 >> iter 80000, loss: 0.263834
   Number of active neurons: 7
 >> iter 81000, loss: 0.376819
 >> iter 82000, loss: 0.326064
 >> iter 83000, loss: 0.252407
 >> iter 84000, loss: 0.245099
 >> iter 85000, loss: 0.330314
 >> iter 86000, loss: 0.272709
 >> iter 87000, loss: 0.345735
 >> iter 88000, loss: 0.354965
 >> iter 89000, loss: 0.239281
 >> iter 90000, loss: 0.225592
   Number of active neurons: 7
 >> iter 91000, loss: 0.259569
 >> iter 92000, loss: 0.253928
 >> iter 93000, loss: 0.217501
 >> iter 94000, loss: 0.290691
 >> iter 95000, loss: 0.306593
 >> iter 96000, loss: 0.239419
 >> iter 97000, loss: 0.298307
 >> iter 98000, loss: 0.328869
 >> iter 99000, loss: 0.224187
 >> iter 100000, loss: 0.231383
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.468143
 >> iter 2000, loss: 9.567177
 >> iter 3000, loss: 5.084849
 >> iter 4000, loss: 2.418420
 >> iter 5000, loss: 1.225632
 >> iter 6000, loss: 0.749449
 >> iter 7000, loss: 0.588408
 >> iter 8000, loss: 0.454925
 >> iter 9000, loss: 0.334625
 >> iter 10000, loss: 0.265234
   Number of active neurons: 10
 >> iter 11000, loss: 0.245021
 >> iter 12000, loss: 0.405059
 >> iter 13000, loss: 0.330973
 >> iter 14000, loss: 0.502119
 >> iter 15000, loss: 0.342344
 >> iter 16000, loss: 0.320442
 >> iter 17000, loss: 0.351955
 >> iter 18000, loss: 0.241644
 >> iter 19000, loss: 0.328037
 >> iter 20000, loss: 0.345646
   Number of active neurons: 10
 >> iter 21000, loss: 0.314254
 >> iter 22000, loss: 0.273765
 >> iter 23000, loss: 0.451428
 >> iter 24000, loss: 0.353252
 >> iter 25000, loss: 0.388326
 >> iter 26000, loss: 0.442961
 >> iter 27000, loss: 0.468599
 >> iter 28000, loss: 0.463986
 >> iter 29000, loss: 0.428725
 >> iter 30000, loss: 0.299330
   Number of active neurons: 10
 >> iter 31000, loss: 0.251224
 >> iter 32000, loss: 0.301494
 >> iter 33000, loss: 0.350641
 >> iter 34000, loss: 0.301572
 >> iter 35000, loss: 0.343577
 >> iter 36000, loss: 0.433625
 >> iter 37000, loss: 0.312293
 >> iter 38000, loss: 0.327612
 >> iter 39000, loss: 0.294236
 >> iter 40000, loss: 0.241248
   Number of active neurons: 10
 >> iter 41000, loss: 0.309309
 >> iter 42000, loss: 0.316470
 >> iter 43000, loss: 0.229682
 >> iter 44000, loss: 0.259621
 >> iter 45000, loss: 0.241898
 >> iter 46000, loss: 0.262852
 >> iter 47000, loss: 0.193316
 >> iter 48000, loss: 0.214489
 >> iter 49000, loss: 0.355248
 >> iter 50000, loss: 0.380733
   Number of active neurons: 9
 >> iter 51000, loss: 0.265319
 >> iter 52000, loss: 0.277871
 >> iter 53000, loss: 0.301138
 >> iter 54000, loss: 0.290855
 >> iter 55000, loss: 0.167408
 >> iter 56000, loss: 0.182458
 >> iter 57000, loss: 0.205969
 >> iter 58000, loss: 0.139222
 >> iter 59000, loss: 0.183832
 >> iter 60000, loss: 0.260392
   Number of active neurons: 9
 >> iter 61000, loss: 0.353626
 >> iter 62000, loss: 0.334656
 >> iter 63000, loss: 0.339924
 >> iter 64000, loss: 0.189877
 >> iter 65000, loss: 0.193659
 >> iter 66000, loss: 0.198153
 >> iter 67000, loss: 0.260224
 >> iter 68000, loss: 0.204095
 >> iter 69000, loss: 0.302287
 >> iter 70000, loss: 0.264331
   Number of active neurons: 9
 >> iter 71000, loss: 0.310582
 >> iter 72000, loss: 0.308348
 >> iter 73000, loss: 0.270377
 >> iter 74000, loss: 0.165527
 >> iter 75000, loss: 0.169106
 >> iter 76000, loss: 0.235571
 >> iter 77000, loss: 0.228365
 >> iter 78000, loss: 0.190001
 >> iter 79000, loss: 0.286136
 >> iter 80000, loss: 0.303749
   Number of active neurons: 9
 >> iter 81000, loss: 0.393829
 >> iter 82000, loss: 0.366223
 >> iter 83000, loss: 0.245544
 >> iter 84000, loss: 0.247237
 >> iter 85000, loss: 0.377814
 >> iter 86000, loss: 0.272986
 >> iter 87000, loss: 0.300707
 >> iter 88000, loss: 0.237678
 >> iter 89000, loss: 0.373772
 >> iter 90000, loss: 0.249316
   Number of active neurons: 8
 >> iter 91000, loss: 0.237992
 >> iter 92000, loss: 0.196558
 >> iter 93000, loss: 0.216154
 >> iter 94000, loss: 0.244051
 >> iter 95000, loss: 0.362145
 >> iter 96000, loss: 0.313685
 >> iter 97000, loss: 0.257836
 >> iter 98000, loss: 0.237435
 >> iter 99000, loss: 0.197668
 >> iter 100000, loss: 0.185176
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.002385
 >> iter 2000, loss: 10.348822
 >> iter 3000, loss: 7.735591
 >> iter 4000, loss: 5.687950
 >> iter 5000, loss: 3.737560
 >> iter 6000, loss: 2.324139
 >> iter 7000, loss: 1.662220
 >> iter 8000, loss: 1.095140
 >> iter 9000, loss: 0.884410
 >> iter 10000, loss: 0.835890
   Number of active neurons: 6
 >> iter 11000, loss: 0.690426
 >> iter 12000, loss: 0.518692
 >> iter 13000, loss: 0.510377
 >> iter 14000, loss: 0.474313
 >> iter 15000, loss: 0.560119
 >> iter 16000, loss: 0.497151
 >> iter 17000, loss: 0.535072
 >> iter 18000, loss: 0.502928
 >> iter 19000, loss: 0.397216
 >> iter 20000, loss: 0.393068
   Number of active neurons: 6
 >> iter 21000, loss: 0.461010
 >> iter 22000, loss: 0.400336
 >> iter 23000, loss: 0.364460
 >> iter 24000, loss: 0.428783
 >> iter 25000, loss: 0.513260
 >> iter 26000, loss: 0.531791
 >> iter 27000, loss: 0.537358
 >> iter 28000, loss: 0.478505
 >> iter 29000, loss: 0.528245
 >> iter 30000, loss: 0.399109
   Number of active neurons: 6
 >> iter 31000, loss: 0.465729
 >> iter 32000, loss: 0.347093
 >> iter 33000, loss: 0.467009
 >> iter 34000, loss: 0.550824
 >> iter 35000, loss: 0.604875
 >> iter 36000, loss: 0.600804
 >> iter 37000, loss: 0.549535
 >> iter 38000, loss: 0.476190
 >> iter 39000, loss: 0.459001
 >> iter 40000, loss: 0.482913
   Number of active neurons: 6
 >> iter 41000, loss: 0.543357
 >> iter 42000, loss: 0.390244
 >> iter 43000, loss: 0.353046
 >> iter 44000, loss: 0.446200
 >> iter 45000, loss: 0.544145
 >> iter 46000, loss: 0.588154
 >> iter 47000, loss: 0.646986
 >> iter 48000, loss: 0.592550
 >> iter 49000, loss: 0.564235
 >> iter 50000, loss: 0.458791
   Number of active neurons: 6
 >> iter 51000, loss: 0.649631
 >> iter 52000, loss: 0.576643
 >> iter 53000, loss: 0.572311
 >> iter 54000, loss: 0.577835
 >> iter 55000, loss: 0.434347
 >> iter 56000, loss: 0.488129
 >> iter 57000, loss: 0.498910
 >> iter 58000, loss: 0.533796
 >> iter 59000, loss: 0.576516
 >> iter 60000, loss: 0.499125
   Number of active neurons: 6
 >> iter 61000, loss: 0.483316
 >> iter 62000, loss: 0.555683
 >> iter 63000, loss: 0.701258
 >> iter 64000, loss: 0.682756
 >> iter 65000, loss: 0.552809
 >> iter 66000, loss: 0.668624
 >> iter 67000, loss: 0.723866
 >> iter 68000, loss: 0.721582
 >> iter 69000, loss: 0.681096
 >> iter 70000, loss: 0.649226
   Number of active neurons: 6
 >> iter 71000, loss: 0.627927
 >> iter 72000, loss: 0.478295
 >> iter 73000, loss: 0.447051
 >> iter 74000, loss: 0.502173
 >> iter 75000, loss: 0.536810
 >> iter 76000, loss: 0.512189
 >> iter 77000, loss: 0.552668
 >> iter 78000, loss: 0.578309
 >> iter 79000, loss: 0.809992
 >> iter 80000, loss: 0.689690
   Number of active neurons: 6
 >> iter 81000, loss: 0.588960
 >> iter 82000, loss: 0.606394
 >> iter 83000, loss: 0.752370
 >> iter 84000, loss: 0.746616
 >> iter 85000, loss: 0.681126
 >> iter 86000, loss: 0.545468
 >> iter 87000, loss: 0.492792
 >> iter 88000, loss: 0.449646
 >> iter 89000, loss: 0.700650
 >> iter 90000, loss: 0.675301
   Number of active neurons: 11
 >> iter 91000, loss: 0.758547
 >> iter 92000, loss: 0.614062
 >> iter 93000, loss: 0.576200
 >> iter 94000, loss: 0.570179
 >> iter 95000, loss: 0.568148
 >> iter 96000, loss: 0.578298
 >> iter 97000, loss: 0.536500
 >> iter 98000, loss: 0.541166
 >> iter 99000, loss: 0.504115
 >> iter 100000, loss: 0.433225
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.700725
 >> iter 2000, loss: 9.708796
 >> iter 3000, loss: 5.975875
 >> iter 4000, loss: 3.748299
 >> iter 5000, loss: 2.356404
 >> iter 6000, loss: 1.565357
 >> iter 7000, loss: 1.107690
 >> iter 8000, loss: 0.821035
 >> iter 9000, loss: 0.823125
 >> iter 10000, loss: 0.652803
   Number of active neurons: 9
 >> iter 11000, loss: 0.518227
 >> iter 12000, loss: 0.454112
 >> iter 13000, loss: 0.540299
 >> iter 14000, loss: 0.408581
 >> iter 15000, loss: 0.374876
 >> iter 16000, loss: 0.353206
 >> iter 17000, loss: 0.284453
 >> iter 18000, loss: 0.441882
 >> iter 19000, loss: 0.363821
 >> iter 20000, loss: 0.316535
   Number of active neurons: 8
 >> iter 21000, loss: 0.332990
 >> iter 22000, loss: 0.254152
 >> iter 23000, loss: 0.216019
 >> iter 24000, loss: 0.313218
 >> iter 25000, loss: 0.267832
 >> iter 26000, loss: 0.383433
 >> iter 27000, loss: 0.504047
 >> iter 28000, loss: 0.469941
 >> iter 29000, loss: 0.344332
 >> iter 30000, loss: 0.440485
   Number of active neurons: 7
 >> iter 31000, loss: 0.458765
 >> iter 32000, loss: 0.471065
 >> iter 33000, loss: 0.421692
 >> iter 34000, loss: 0.531569
 >> iter 35000, loss: 0.468963
 >> iter 36000, loss: 0.468221
 >> iter 37000, loss: 0.494314
 >> iter 38000, loss: 0.417867
 >> iter 39000, loss: 0.452050
 >> iter 40000, loss: 0.365542
   Number of active neurons: 7
 >> iter 41000, loss: 0.406021
 >> iter 42000, loss: 0.443462
 >> iter 43000, loss: 0.411543
 >> iter 44000, loss: 0.364225
 >> iter 45000, loss: 0.433522
 >> iter 46000, loss: 0.247307
 >> iter 47000, loss: 0.345935
 >> iter 48000, loss: 0.458236
 >> iter 49000, loss: 0.363483
 >> iter 50000, loss: 0.448072
   Number of active neurons: 6
 >> iter 51000, loss: 0.340120
 >> iter 52000, loss: 0.454880
 >> iter 53000, loss: 0.359513
 >> iter 54000, loss: 0.524040
 >> iter 55000, loss: 0.416553
 >> iter 56000, loss: 0.364203
 >> iter 57000, loss: 0.462151
 >> iter 58000, loss: 0.444678
 >> iter 59000, loss: 0.348820
 >> iter 60000, loss: 0.450474
   Number of active neurons: 6
 >> iter 61000, loss: 0.330150
 >> iter 62000, loss: 0.330363
 >> iter 63000, loss: 0.260833
 >> iter 64000, loss: 0.312606
 >> iter 65000, loss: 0.323652
 >> iter 66000, loss: 0.378990
 >> iter 67000, loss: 0.333370
 >> iter 68000, loss: 0.417051
 >> iter 69000, loss: 0.419100
 >> iter 70000, loss: 0.443383
   Number of active neurons: 6
 >> iter 71000, loss: 0.472239
 >> iter 72000, loss: 0.514898
 >> iter 73000, loss: 0.501604
 >> iter 74000, loss: 0.366692
 >> iter 75000, loss: 0.317912
 >> iter 76000, loss: 0.393654
 >> iter 77000, loss: 0.381991
 >> iter 78000, loss: 0.398287
 >> iter 79000, loss: 0.376020
 >> iter 80000, loss: 0.342437
   Number of active neurons: 6
 >> iter 81000, loss: 0.349477
 >> iter 82000, loss: 0.392447
 >> iter 83000, loss: 0.358681
 >> iter 84000, loss: 0.536631
 >> iter 85000, loss: 0.416991
 >> iter 86000, loss: 0.410346
 >> iter 87000, loss: 0.348276
 >> iter 88000, loss: 0.332432
 >> iter 89000, loss: 0.363749
 >> iter 90000, loss: 0.299455
   Number of active neurons: 7
 >> iter 91000, loss: 0.266284
 >> iter 92000, loss: 0.381743
 >> iter 93000, loss: 0.454197
 >> iter 94000, loss: 0.272896
 >> iter 95000, loss: 0.306384
 >> iter 96000, loss: 0.302569
 >> iter 97000, loss: 0.382539
 >> iter 98000, loss: 0.290943
 >> iter 99000, loss: 0.291593
 >> iter 100000, loss: 0.238946
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.479056
 >> iter 2000, loss: 9.544565
 >> iter 3000, loss: 5.842169
 >> iter 4000, loss: 3.068140
 >> iter 5000, loss: 1.597487
 >> iter 6000, loss: 0.958604
 >> iter 7000, loss: 0.739483
 >> iter 8000, loss: 0.471552
 >> iter 9000, loss: 0.445059
 >> iter 10000, loss: 0.595262
   Number of active neurons: 8
 >> iter 11000, loss: 0.428394
 >> iter 12000, loss: 0.484213
 >> iter 13000, loss: 0.460598
 >> iter 14000, loss: 0.460366
 >> iter 15000, loss: 0.379527
 >> iter 16000, loss: 0.458232
 >> iter 17000, loss: 0.478048
 >> iter 18000, loss: 0.447348
 >> iter 19000, loss: 0.346046
 >> iter 20000, loss: 0.194431
   Number of active neurons: 7
 >> iter 21000, loss: 0.427938
 >> iter 22000, loss: 0.390169
 >> iter 23000, loss: 0.391238
 >> iter 24000, loss: 0.398211
 >> iter 25000, loss: 0.328074
 >> iter 26000, loss: 0.240827
 >> iter 27000, loss: 0.203783
 >> iter 28000, loss: 0.223534
 >> iter 29000, loss: 0.254911
 >> iter 30000, loss: 0.337561
   Number of active neurons: 7
 >> iter 31000, loss: 0.313462
 >> iter 32000, loss: 0.274307
 >> iter 33000, loss: 0.326439
 >> iter 34000, loss: 0.255942
 >> iter 35000, loss: 0.332426
 >> iter 36000, loss: 0.359606
 >> iter 37000, loss: 0.312564
 >> iter 38000, loss: 0.427568
 >> iter 39000, loss: 0.394543
 >> iter 40000, loss: 0.404343
   Number of active neurons: 7
 >> iter 41000, loss: 0.366328
 >> iter 42000, loss: 0.355620
 >> iter 43000, loss: 0.282683
 >> iter 44000, loss: 0.212805
 >> iter 45000, loss: 0.275810
 >> iter 46000, loss: 0.436541
 >> iter 47000, loss: 0.405930
 >> iter 48000, loss: 0.381750
 >> iter 49000, loss: 0.210969
 >> iter 50000, loss: 0.335849
   Number of active neurons: 7
 >> iter 51000, loss: 0.233077
 >> iter 52000, loss: 0.352104
 >> iter 53000, loss: 0.377614
 >> iter 54000, loss: 0.362389
 >> iter 55000, loss: 0.363497
 >> iter 56000, loss: 0.271538
 >> iter 57000, loss: 0.422373
 >> iter 58000, loss: 0.355111
 >> iter 59000, loss: 0.330177
 >> iter 60000, loss: 0.387800
   Number of active neurons: 5
 >> iter 61000, loss: 0.324658
 >> iter 62000, loss: 0.289610
 >> iter 63000, loss: 0.445340
 >> iter 64000, loss: 0.395682
 >> iter 65000, loss: 0.517783
 >> iter 66000, loss: 0.388526
 >> iter 67000, loss: 0.486308
 >> iter 68000, loss: 0.304875
 >> iter 69000, loss: 0.257716
 >> iter 70000, loss: 0.271415
   Number of active neurons: 5
 >> iter 71000, loss: 0.208001
 >> iter 72000, loss: 0.225919
 >> iter 73000, loss: 0.350549
 >> iter 74000, loss: 0.295942
 >> iter 75000, loss: 0.221126
 >> iter 76000, loss: 0.273623
 >> iter 77000, loss: 0.384557
 >> iter 78000, loss: 0.238391
 >> iter 79000, loss: 0.277042
 >> iter 80000, loss: 0.265436
   Number of active neurons: 5
 >> iter 81000, loss: 0.295671
 >> iter 82000, loss: 0.221711
 >> iter 83000, loss: 0.283492
 >> iter 84000, loss: 0.450221
 >> iter 85000, loss: 0.381021
 >> iter 86000, loss: 0.305487
 >> iter 87000, loss: 0.231496
 >> iter 88000, loss: 0.237878
 >> iter 89000, loss: 0.235735
 >> iter 90000, loss: 0.261863
   Number of active neurons: 5
 >> iter 91000, loss: 0.252415
 >> iter 92000, loss: 0.215228
 >> iter 93000, loss: 0.307211
 >> iter 94000, loss: 0.229264
 >> iter 95000, loss: 0.290709
 >> iter 96000, loss: 0.290229
 >> iter 97000, loss: 0.290356
 >> iter 98000, loss: 0.213897
 >> iter 99000, loss: 0.249750
 >> iter 100000, loss: 0.275972
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.734092
 >> iter 2000, loss: 9.625372
 >> iter 3000, loss: 5.652632
 >> iter 4000, loss: 2.938538
 >> iter 5000, loss: 1.495963
 >> iter 6000, loss: 0.901922
 >> iter 7000, loss: 0.548361
 >> iter 8000, loss: 0.483422
 >> iter 9000, loss: 0.422686
 >> iter 10000, loss: 0.286203
   Number of active neurons: 8
 >> iter 11000, loss: 0.253795
 >> iter 12000, loss: 0.326284
 >> iter 13000, loss: 0.371011
 >> iter 14000, loss: 0.245523
 >> iter 15000, loss: 0.280753
 >> iter 16000, loss: 0.298629
 >> iter 17000, loss: 0.321510
 >> iter 18000, loss: 0.289020
 >> iter 19000, loss: 0.299262
 >> iter 20000, loss: 0.286162
   Number of active neurons: 8
 >> iter 21000, loss: 0.365028
 >> iter 22000, loss: 0.567233
 >> iter 23000, loss: 0.357955
 >> iter 24000, loss: 0.285968
 >> iter 25000, loss: 0.223762
 >> iter 26000, loss: 0.208081
 >> iter 27000, loss: 0.337159
 >> iter 28000, loss: 0.284796
 >> iter 29000, loss: 0.252505
 >> iter 30000, loss: 0.272693
   Number of active neurons: 7
 >> iter 31000, loss: 0.251256
 >> iter 32000, loss: 0.331438
 >> iter 33000, loss: 0.323522
 >> iter 34000, loss: 0.308160
 >> iter 35000, loss: 0.364580
 >> iter 36000, loss: 0.306157
 >> iter 37000, loss: 0.266404
 >> iter 38000, loss: 0.359607
 >> iter 39000, loss: 0.377192
 >> iter 40000, loss: 0.294756
   Number of active neurons: 7
 >> iter 41000, loss: 0.233155
 >> iter 42000, loss: 0.327139
 >> iter 43000, loss: 0.358810
 >> iter 44000, loss: 0.326526
 >> iter 45000, loss: 0.285114
 >> iter 46000, loss: 0.271599
 >> iter 47000, loss: 0.308579
 >> iter 48000, loss: 0.429812
 >> iter 49000, loss: 0.378747
 >> iter 50000, loss: 0.425572
   Number of active neurons: 6
 >> iter 51000, loss: 0.363109
 >> iter 52000, loss: 0.364657
 >> iter 53000, loss: 0.318565
 >> iter 54000, loss: 0.342229
 >> iter 55000, loss: 0.331600
 >> iter 56000, loss: 0.416199
 >> iter 57000, loss: 0.317965
 >> iter 58000, loss: 0.375604
 >> iter 59000, loss: 0.426558
 >> iter 60000, loss: 0.343008
   Number of active neurons: 6
 >> iter 61000, loss: 0.384331
 >> iter 62000, loss: 0.297386
 >> iter 63000, loss: 0.277500
 >> iter 64000, loss: 0.396599
 >> iter 65000, loss: 0.358590
 >> iter 66000, loss: 0.324557
 >> iter 67000, loss: 0.350810
 >> iter 68000, loss: 0.273523
 >> iter 69000, loss: 0.277462
 >> iter 70000, loss: 0.402226
   Number of active neurons: 6
 >> iter 71000, loss: 0.449397
 >> iter 72000, loss: 0.377850
 >> iter 73000, loss: 0.454440
 >> iter 74000, loss: 0.358453
 >> iter 75000, loss: 0.303640
 >> iter 76000, loss: 0.445477
 >> iter 77000, loss: 0.467592
 >> iter 78000, loss: 0.333166
 >> iter 79000, loss: 0.553442
 >> iter 80000, loss: 0.390959
   Number of active neurons: 6
 >> iter 81000, loss: 0.303329
 >> iter 82000, loss: 0.328263
 >> iter 83000, loss: 0.363321
 >> iter 84000, loss: 0.379727
 >> iter 85000, loss: 0.337795
 >> iter 86000, loss: 0.290956
 >> iter 87000, loss: 0.323945
 >> iter 88000, loss: 0.415792
 >> iter 89000, loss: 0.427204
 >> iter 90000, loss: 0.354559
   Number of active neurons: 6
 >> iter 91000, loss: 0.280001
 >> iter 92000, loss: 0.268275
 >> iter 93000, loss: 0.319187
 >> iter 94000, loss: 0.319870
 >> iter 95000, loss: 0.311258
 >> iter 96000, loss: 0.290045
 >> iter 97000, loss: 0.364363
 >> iter 98000, loss: 0.398573
 >> iter 99000, loss: 0.331027
 >> iter 100000, loss: 0.340689
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 17.496988
 >> iter 2000, loss: 9.937577
 >> iter 3000, loss: 4.561955
 >> iter 4000, loss: 1.923390
 >> iter 5000, loss: 0.860007
 >> iter 6000, loss: 0.601959
 >> iter 7000, loss: 0.460227
 >> iter 8000, loss: 0.349442
 >> iter 9000, loss: 0.241944
 >> iter 10000, loss: 0.253488
   Number of active neurons: 9
 >> iter 11000, loss: 0.273849
 >> iter 12000, loss: 0.222024
 >> iter 13000, loss: 0.208961
 >> iter 14000, loss: 0.191544
 >> iter 15000, loss: 0.243853
 >> iter 16000, loss: 0.216805
 >> iter 17000, loss: 0.340344
 >> iter 18000, loss: 0.262692
 >> iter 19000, loss: 0.272666
 >> iter 20000, loss: 0.198674
   Number of active neurons: 9
 >> iter 21000, loss: 0.206708
 >> iter 22000, loss: 0.218301
 >> iter 23000, loss: 0.175658
 >> iter 24000, loss: 0.150541
 >> iter 25000, loss: 0.213940
 >> iter 26000, loss: 0.267921
 >> iter 27000, loss: 0.214285
 >> iter 28000, loss: 0.236032
 >> iter 29000, loss: 0.261302
 >> iter 30000, loss: 0.163277
   Number of active neurons: 9
 >> iter 31000, loss: 0.253420
 >> iter 32000, loss: 0.180875
 >> iter 33000, loss: 0.235073
 >> iter 34000, loss: 0.228195
 >> iter 35000, loss: 0.201359
 >> iter 36000, loss: 0.273096
 >> iter 37000, loss: 0.210599
 >> iter 38000, loss: 0.238160
 >> iter 39000, loss: 0.214862
 >> iter 40000, loss: 0.170398
   Number of active neurons: 9
 >> iter 41000, loss: 0.153736
 >> iter 42000, loss: 0.165174
 >> iter 43000, loss: 0.219254
 >> iter 44000, loss: 0.225644
 >> iter 45000, loss: 0.216348
 >> iter 46000, loss: 0.269151
 >> iter 47000, loss: 0.221876
 >> iter 48000, loss: 0.221366
 >> iter 49000, loss: 0.271363
 >> iter 50000, loss: 0.220140
   Number of active neurons: 9
 >> iter 51000, loss: 0.147420
 >> iter 52000, loss: 0.258720
 >> iter 53000, loss: 0.297628
 >> iter 54000, loss: 0.305856
 >> iter 55000, loss: 0.271388
 >> iter 56000, loss: 0.247063
 >> iter 57000, loss: 0.309351
 >> iter 58000, loss: 0.281216
 >> iter 59000, loss: 0.271922
 >> iter 60000, loss: 0.254767
   Number of active neurons: 9
 >> iter 61000, loss: 0.298720
 >> iter 62000, loss: 0.328522
 >> iter 63000, loss: 0.227975
 >> iter 64000, loss: 0.229692
 >> iter 65000, loss: 0.374955
 >> iter 66000, loss: 0.261520
 >> iter 67000, loss: 0.271402
 >> iter 68000, loss: 0.216484
 >> iter 69000, loss: 0.176832
 >> iter 70000, loss: 0.201138
   Number of active neurons: 8
 >> iter 71000, loss: 0.289220
 >> iter 72000, loss: 0.264527
 >> iter 73000, loss: 0.197381
 >> iter 74000, loss: 0.214712
 >> iter 75000, loss: 0.200762
 >> iter 76000, loss: 0.249427
 >> iter 77000, loss: 0.199724
 >> iter 78000, loss: 0.168802
 >> iter 79000, loss: 0.302126
 >> iter 80000, loss: 0.256419
   Number of active neurons: 8
 >> iter 81000, loss: 0.393583
 >> iter 82000, loss: 0.317989
 >> iter 83000, loss: 0.300824
 >> iter 84000, loss: 0.239448
 >> iter 85000, loss: 0.224931
 >> iter 86000, loss: 0.303606
 >> iter 87000, loss: 0.318869
 >> iter 88000, loss: 0.215752
 >> iter 89000, loss: 0.253336
 >> iter 90000, loss: 0.200557
   Number of active neurons: 8
 >> iter 91000, loss: 0.192030
 >> iter 92000, loss: 0.130395
 >> iter 93000, loss: 0.260303
 >> iter 94000, loss: 0.263102
 >> iter 95000, loss: 0.242634
 >> iter 96000, loss: 0.251322
 >> iter 97000, loss: 0.209540
 >> iter 98000, loss: 0.338380
 >> iter 99000, loss: 0.257898
 >> iter 100000, loss: 0.288396
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.479691
 >> iter 2000, loss: 9.699653
 >> iter 3000, loss: 6.268299
 >> iter 4000, loss: 3.136822
 >> iter 5000, loss: 1.630546
 >> iter 6000, loss: 1.005866
 >> iter 7000, loss: 0.641344
 >> iter 8000, loss: 0.721296
 >> iter 9000, loss: 0.445962
 >> iter 10000, loss: 0.514182
   Number of active neurons: 12
 >> iter 11000, loss: 0.441274
 >> iter 12000, loss: 0.444608
 >> iter 13000, loss: 0.368965
 >> iter 14000, loss: 0.355425
 >> iter 15000, loss: 0.462956
 >> iter 16000, loss: 0.306563
 >> iter 17000, loss: 0.402212
 >> iter 18000, loss: 0.325080
 >> iter 19000, loss: 0.319243
 >> iter 20000, loss: 0.284818
   Number of active neurons: 11
 >> iter 21000, loss: 0.293027
 >> iter 22000, loss: 0.295086
 >> iter 23000, loss: 0.251492
 >> iter 24000, loss: 0.354537
 >> iter 25000, loss: 0.371692
 >> iter 26000, loss: 0.332350
 >> iter 27000, loss: 0.218202
 >> iter 28000, loss: 0.236427
 >> iter 29000, loss: 0.235972
 >> iter 30000, loss: 0.252301
   Number of active neurons: 11
 >> iter 31000, loss: 0.272334
 >> iter 32000, loss: 0.221678
 >> iter 33000, loss: 0.210165
 >> iter 34000, loss: 0.346385
 >> iter 35000, loss: 0.314762
 >> iter 36000, loss: 0.355367
 >> iter 37000, loss: 0.416698
 >> iter 38000, loss: 0.363316
 >> iter 39000, loss: 0.394274
 >> iter 40000, loss: 0.306735
   Number of active neurons: 10
 >> iter 41000, loss: 0.358858
 >> iter 42000, loss: 0.235320
 >> iter 43000, loss: 0.308162
 >> iter 44000, loss: 0.324473
 >> iter 45000, loss: 0.275366
 >> iter 46000, loss: 0.229106
 >> iter 47000, loss: 0.259378
 >> iter 48000, loss: 0.306668
 >> iter 49000, loss: 0.239668
 >> iter 50000, loss: 0.368834
   Number of active neurons: 10
 >> iter 51000, loss: 0.368301
 >> iter 52000, loss: 0.281032
 >> iter 53000, loss: 0.295443
 >> iter 54000, loss: 0.298488
 >> iter 55000, loss: 0.191660
 >> iter 56000, loss: 0.291183
 >> iter 57000, loss: 0.309664
 >> iter 58000, loss: 0.281811
 >> iter 59000, loss: 0.264575
 >> iter 60000, loss: 0.393146
   Number of active neurons: 9
 >> iter 61000, loss: 0.241335
 >> iter 62000, loss: 0.247552
 >> iter 63000, loss: 0.204771
 >> iter 64000, loss: 0.312300
 >> iter 65000, loss: 0.298828
 >> iter 66000, loss: 0.352374
 >> iter 67000, loss: 0.448942
 >> iter 68000, loss: 0.274658
 >> iter 69000, loss: 0.223683
 >> iter 70000, loss: 0.267801
   Number of active neurons: 9
 >> iter 71000, loss: 0.284779
 >> iter 72000, loss: 0.286178
 >> iter 73000, loss: 0.255933
 >> iter 74000, loss: 0.307528
 >> iter 75000, loss: 0.341303
 >> iter 76000, loss: 0.278120
 >> iter 77000, loss: 0.279080
 >> iter 78000, loss: 0.349744
 >> iter 79000, loss: 0.312486
 >> iter 80000, loss: 0.356532
   Number of active neurons: 9
 >> iter 81000, loss: 0.355144
 >> iter 82000, loss: 0.267477
 >> iter 83000, loss: 0.273443
 >> iter 84000, loss: 0.299666
 >> iter 85000, loss: 0.240599
 >> iter 86000, loss: 0.207081
 >> iter 87000, loss: 0.226920
 >> iter 88000, loss: 0.221692
 >> iter 89000, loss: 0.332831
 >> iter 90000, loss: 0.266981
   Number of active neurons: 9
 >> iter 91000, loss: 0.339332
 >> iter 92000, loss: 0.443088
 >> iter 93000, loss: 0.362398
 >> iter 94000, loss: 0.377031
 >> iter 95000, loss: 0.304967
 >> iter 96000, loss: 0.300116
 >> iter 97000, loss: 0.239437
 >> iter 98000, loss: 0.195757
 >> iter 99000, loss: 0.245762
 >> iter 100000, loss: 0.187662
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.549350
 >> iter 2000, loss: 9.874140
 >> iter 3000, loss: 5.944147
 >> iter 4000, loss: 2.784829
 >> iter 5000, loss: 1.406089
 >> iter 6000, loss: 0.622426
 >> iter 7000, loss: 0.555234
 >> iter 8000, loss: 0.431528
 >> iter 9000, loss: 0.426384
 >> iter 10000, loss: 0.351384
   Number of active neurons: 9
 >> iter 11000, loss: 0.307583
 >> iter 12000, loss: 0.180759
 >> iter 13000, loss: 0.269363
 >> iter 14000, loss: 0.307496
 >> iter 15000, loss: 0.463999
 >> iter 16000, loss: 0.338377
 >> iter 17000, loss: 0.398578
 >> iter 18000, loss: 0.472671
 >> iter 19000, loss: 0.400987
 >> iter 20000, loss: 0.329394
   Number of active neurons: 9
 >> iter 21000, loss: 0.390512
 >> iter 22000, loss: 0.325797
 >> iter 23000, loss: 0.272704
 >> iter 24000, loss: 0.321200
 >> iter 25000, loss: 0.323150
 >> iter 26000, loss: 0.246223
 >> iter 27000, loss: 0.231174
 >> iter 28000, loss: 0.354423
 >> iter 29000, loss: 0.382018
 >> iter 30000, loss: 0.320860
   Number of active neurons: 9
 >> iter 31000, loss: 0.428679
 >> iter 32000, loss: 0.382672
 >> iter 33000, loss: 0.297348
 >> iter 34000, loss: 0.326967
 >> iter 35000, loss: 0.308508
 >> iter 36000, loss: 0.303090
 >> iter 37000, loss: 0.198504
 >> iter 38000, loss: 0.270176
 >> iter 39000, loss: 0.313951
 >> iter 40000, loss: 0.382646
   Number of active neurons: 8
 >> iter 41000, loss: 0.337339
 >> iter 42000, loss: 0.274052
 >> iter 43000, loss: 0.276600
 >> iter 44000, loss: 0.189651
 >> iter 45000, loss: 0.239036
 >> iter 46000, loss: 0.288955
 >> iter 47000, loss: 0.353984
 >> iter 48000, loss: 0.322282
 >> iter 49000, loss: 0.289090
 >> iter 50000, loss: 0.241791
   Number of active neurons: 8
 >> iter 51000, loss: 0.262809
 >> iter 52000, loss: 0.204548
 >> iter 53000, loss: 0.391824
 >> iter 54000, loss: 0.278467
 >> iter 55000, loss: 0.229859
 >> iter 56000, loss: 0.255703
 >> iter 57000, loss: 0.243181
 >> iter 58000, loss: 0.209002
 >> iter 59000, loss: 0.376317
 >> iter 60000, loss: 0.365562
   Number of active neurons: 8
 >> iter 61000, loss: 0.297431
 >> iter 62000, loss: 0.263575
 >> iter 63000, loss: 0.248660
 >> iter 64000, loss: 0.186038
 >> iter 65000, loss: 0.208568
 >> iter 66000, loss: 0.275670
 >> iter 67000, loss: 0.259258
 >> iter 68000, loss: 0.223469
 >> iter 69000, loss: 0.265726
 >> iter 70000, loss: 0.324982
   Number of active neurons: 8
 >> iter 71000, loss: 0.291296
 >> iter 72000, loss: 0.267246
 >> iter 73000, loss: 0.195255
 >> iter 74000, loss: 0.154221
 >> iter 75000, loss: 0.218259
 >> iter 76000, loss: 0.186373
 >> iter 77000, loss: 0.215893
 >> iter 78000, loss: 0.246412
 >> iter 79000, loss: 0.290930
 >> iter 80000, loss: 0.192179
   Number of active neurons: 8
 >> iter 81000, loss: 0.255656
 >> iter 82000, loss: 0.191464
 >> iter 83000, loss: 0.202603
 >> iter 84000, loss: 0.227537
 >> iter 85000, loss: 0.353328
 >> iter 86000, loss: 0.351320
 >> iter 87000, loss: 0.330707
 >> iter 88000, loss: 0.227258
 >> iter 89000, loss: 0.252581
 >> iter 90000, loss: 0.292530
   Number of active neurons: 8
 >> iter 91000, loss: 0.267362
 >> iter 92000, loss: 0.193031
 >> iter 93000, loss: 0.247697
 >> iter 94000, loss: 0.256880
 >> iter 95000, loss: 0.283679
 >> iter 96000, loss: 0.219725
 >> iter 97000, loss: 0.185603
 >> iter 98000, loss: 0.246028
 >> iter 99000, loss: 0.251360
 >> iter 100000, loss: 0.243713
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 16.444167
 >> iter 2000, loss: 9.621502
 >> iter 3000, loss: 5.687763
 >> iter 4000, loss: 3.288692
 >> iter 5000, loss: 2.113355
 >> iter 6000, loss: 1.457800
 >> iter 7000, loss: 1.140148
 >> iter 8000, loss: 0.898190
 >> iter 9000, loss: 1.019945
 >> iter 10000, loss: 0.924695
   Number of active neurons: 11
 >> iter 11000, loss: 0.721305
 >> iter 12000, loss: 0.826625
 >> iter 13000, loss: 0.714529
 >> iter 14000, loss: 0.586089
 >> iter 15000, loss: 0.491742
 >> iter 16000, loss: 0.586238
 >> iter 17000, loss: 0.490270
 >> iter 18000, loss: 0.428504
 >> iter 19000, loss: 0.540733
 >> iter 20000, loss: 0.544949
   Number of active neurons: 9
 >> iter 21000, loss: 0.521586
 >> iter 22000, loss: 0.592436
 >> iter 23000, loss: 0.572781
 >> iter 24000, loss: 0.513330
 >> iter 25000, loss: 0.679120
 >> iter 26000, loss: 0.562438
 >> iter 27000, loss: 0.496965
 >> iter 28000, loss: 0.624015
 >> iter 29000, loss: 0.473723
 >> iter 30000, loss: 0.469308
   Number of active neurons: 9
 >> iter 31000, loss: 0.498959
 >> iter 32000, loss: 0.466066
 >> iter 33000, loss: 0.462012
 >> iter 34000, loss: 0.537922
 >> iter 35000, loss: 0.605954
 >> iter 36000, loss: 0.556098
 >> iter 37000, loss: 0.501440
 >> iter 38000, loss: 0.513714
 >> iter 39000, loss: 0.503613
 >> iter 40000, loss: 0.469114
   Number of active neurons: 8
 >> iter 41000, loss: 0.502610
 >> iter 42000, loss: 0.392246
 >> iter 43000, loss: 0.379865
 >> iter 44000, loss: 0.439356
 >> iter 45000, loss: 0.556923
 >> iter 46000, loss: 0.525639
 >> iter 47000, loss: 0.542139
 >> iter 48000, loss: 0.406947
 >> iter 49000, loss: 0.437933
 >> iter 50000, loss: 0.461036
   Number of active neurons: 8
 >> iter 51000, loss: 0.424797
 >> iter 52000, loss: 0.571342
 >> iter 53000, loss: 0.540160
 >> iter 54000, loss: 0.484184
 >> iter 55000, loss: 0.421165
 >> iter 56000, loss: 0.357227
 >> iter 57000, loss: 0.498305
 >> iter 58000, loss: 0.450303
 >> iter 59000, loss: 0.576837
 >> iter 60000, loss: 0.466311
   Number of active neurons: 8
 >> iter 61000, loss: 0.600114
 >> iter 62000, loss: 0.581868
 >> iter 63000, loss: 0.581461
 >> iter 64000, loss: 0.559656
 >> iter 65000, loss: 0.544094
 >> iter 66000, loss: 0.454649
 >> iter 67000, loss: 0.478914
 >> iter 68000, loss: 0.525064
 >> iter 69000, loss: 0.447788
 >> iter 70000, loss: 0.474595
   Number of active neurons: 8
 >> iter 71000, loss: 0.417928
 >> iter 72000, loss: 0.450885
 >> iter 73000, loss: 0.612210
 >> iter 74000, loss: 0.542498
 >> iter 75000, loss: 0.527728
 >> iter 76000, loss: 0.458133
 >> iter 77000, loss: 0.593817
 >> iter 78000, loss: 0.495023
 >> iter 79000, loss: 0.544962
 >> iter 80000, loss: 0.380826
   Number of active neurons: 7
 >> iter 81000, loss: 0.508294
 >> iter 82000, loss: 0.421995
 >> iter 83000, loss: 0.515629
 >> iter 84000, loss: 0.482579
 >> iter 85000, loss: 0.499284
 >> iter 86000, loss: 0.646029
 >> iter 87000, loss: 0.515184
 >> iter 88000, loss: 0.432943
 >> iter 89000, loss: 0.523476
 >> iter 90000, loss: 0.397905
   Number of active neurons: 7
 >> iter 91000, loss: 0.397496
 >> iter 92000, loss: 0.382865
 >> iter 93000, loss: 0.345736
 >> iter 94000, loss: 0.620209
 >> iter 95000, loss: 0.600257
 >> iter 96000, loss: 0.550976
 >> iter 97000, loss: 0.696611
 >> iter 98000, loss: 0.506515
 >> iter 99000, loss: 0.462070
 >> iter 100000, loss: 0.494481
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455178
   Number of active neurons: 0
 >> iter 1000, loss: 17.007630
 >> iter 2000, loss: 10.125388
 >> iter 3000, loss: 6.613813
 >> iter 4000, loss: 3.374834
 >> iter 5000, loss: 1.844048
 >> iter 6000, loss: 1.047257
 >> iter 7000, loss: 0.723293
 >> iter 8000, loss: 0.491720
 >> iter 9000, loss: 0.347466
 >> iter 10000, loss: 0.327919
   Number of active neurons: 8
 >> iter 11000, loss: 0.275562
 >> iter 12000, loss: 0.328231
 >> iter 13000, loss: 0.260454
 >> iter 14000, loss: 0.236837
 >> iter 15000, loss: 0.253863
 >> iter 16000, loss: 0.271540
 >> iter 17000, loss: 0.308806
 >> iter 18000, loss: 0.360083
 >> iter 19000, loss: 0.270847
 >> iter 20000, loss: 0.280213
   Number of active neurons: 7
 >> iter 21000, loss: 0.327498
 >> iter 22000, loss: 0.337329
 >> iter 23000, loss: 0.256670
 >> iter 24000, loss: 0.299319
 >> iter 25000, loss: 0.343593
 >> iter 26000, loss: 0.307709
 >> iter 27000, loss: 0.291233
 >> iter 28000, loss: 0.306951
 >> iter 29000, loss: 0.336217
 >> iter 30000, loss: 0.302645
   Number of active neurons: 11
 >> iter 31000, loss: 0.342996
 >> iter 32000, loss: 0.320037
 >> iter 33000, loss: 0.328040
 >> iter 34000, loss: 0.319582
 >> iter 35000, loss: 0.369911
 >> iter 36000, loss: 0.329485
 >> iter 37000, loss: 0.408040
 >> iter 38000, loss: 0.430344
 >> iter 39000, loss: 0.385016
 >> iter 40000, loss: 0.281768
   Number of active neurons: 6
 >> iter 41000, loss: 0.334658
 >> iter 42000, loss: 0.288745
 >> iter 43000, loss: 0.307374
 >> iter 44000, loss: 0.233007
 >> iter 45000, loss: 0.243142
 >> iter 46000, loss: 0.350776
 >> iter 47000, loss: 0.388890
 >> iter 48000, loss: 0.347805
 >> iter 49000, loss: 0.354701
 >> iter 50000, loss: 0.432766
   Number of active neurons: 6
 >> iter 51000, loss: 0.238133
 >> iter 52000, loss: 0.317037
 >> iter 53000, loss: 0.367913
 >> iter 54000, loss: 0.380437
 >> iter 55000, loss: 0.442015
 >> iter 56000, loss: 0.339744
 >> iter 57000, loss: 0.426350
 >> iter 58000, loss: 0.398775
 >> iter 59000, loss: 0.416345
 >> iter 60000, loss: 0.370302
   Number of active neurons: 6
 >> iter 61000, loss: 0.481309
 >> iter 62000, loss: 0.398698
 >> iter 63000, loss: 0.395884
 >> iter 64000, loss: 0.254914
 >> iter 65000, loss: 0.350904
 >> iter 66000, loss: 0.343696
 >> iter 67000, loss: 0.319536
 >> iter 68000, loss: 0.341794
 >> iter 69000, loss: 0.390137
 >> iter 70000, loss: 0.337056
   Number of active neurons: 6
 >> iter 71000, loss: 0.343260
 >> iter 72000, loss: 0.430570
 >> iter 73000, loss: 0.340635
 >> iter 74000, loss: 0.416818
 >> iter 75000, loss: 0.299040
 >> iter 76000, loss: 0.278385
 >> iter 77000, loss: 0.321282
 >> iter 78000, loss: 0.326307
 >> iter 79000, loss: 0.423287
 >> iter 80000, loss: 0.335729
   Number of active neurons: 7
 >> iter 81000, loss: 0.351728
 >> iter 82000, loss: 0.526062
 >> iter 83000, loss: 0.448489
 >> iter 84000, loss: 0.369804
 >> iter 85000, loss: 0.393690
 >> iter 86000, loss: 0.416044
 >> iter 87000, loss: 0.398166
 >> iter 88000, loss: 0.336558
 >> iter 89000, loss: 0.483652
 >> iter 90000, loss: 0.440534
   Number of active neurons: 4
 >> iter 91000, loss: 0.512253
 >> iter 92000, loss: 0.557755
 >> iter 93000, loss: 0.543294
 >> iter 94000, loss: 0.410306
 >> iter 95000, loss: 0.327392
 >> iter 96000, loss: 0.341297
 >> iter 97000, loss: 0.274373
 >> iter 98000, loss: 0.319815
 >> iter 99000, loss: 0.421435
 >> iter 100000, loss: 0.383452
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.579457
 >> iter 2000, loss: 9.934494
 >> iter 3000, loss: 5.464569
 >> iter 4000, loss: 2.331620
 >> iter 5000, loss: 1.003278
 >> iter 6000, loss: 0.600259
 >> iter 7000, loss: 0.414481
 >> iter 8000, loss: 0.354903
 >> iter 9000, loss: 0.384631
 >> iter 10000, loss: 0.359717
   Number of active neurons: 13
 >> iter 11000, loss: 0.221908
 >> iter 12000, loss: 0.306100
 >> iter 13000, loss: 0.389361
 >> iter 14000, loss: 0.307291
 >> iter 15000, loss: 0.253121
 >> iter 16000, loss: 0.205594
 >> iter 17000, loss: 0.248529
 >> iter 18000, loss: 0.196155
 >> iter 19000, loss: 0.254841
 >> iter 20000, loss: 0.240383
   Number of active neurons: 13
 >> iter 21000, loss: 0.394856
 >> iter 22000, loss: 0.238564
 >> iter 23000, loss: 0.236368
 >> iter 24000, loss: 0.223860
 >> iter 25000, loss: 0.158490
 >> iter 26000, loss: 0.267273
 >> iter 27000, loss: 0.258658
 >> iter 28000, loss: 0.197662
 >> iter 29000, loss: 0.234264
 >> iter 30000, loss: 0.247810
   Number of active neurons: 11
 >> iter 31000, loss: 0.207180
 >> iter 32000, loss: 0.195927
 >> iter 33000, loss: 0.335642
 >> iter 34000, loss: 0.355016
 >> iter 35000, loss: 0.266165
 >> iter 36000, loss: 0.242458
 >> iter 37000, loss: 0.273073
 >> iter 38000, loss: 0.246096
 >> iter 39000, loss: 0.219538
 >> iter 40000, loss: 0.191329
   Number of active neurons: 10
 >> iter 41000, loss: 0.256582
 >> iter 42000, loss: 0.226077
 >> iter 43000, loss: 0.153530
 >> iter 44000, loss: 0.225281
 >> iter 45000, loss: 0.269230
 >> iter 46000, loss: 0.243700
 >> iter 47000, loss: 0.309181
 >> iter 48000, loss: 0.265000
 >> iter 49000, loss: 0.239647
 >> iter 50000, loss: 0.233678
   Number of active neurons: 8
 >> iter 51000, loss: 0.244628
 >> iter 52000, loss: 0.239594
 >> iter 53000, loss: 0.214988
 >> iter 54000, loss: 0.267165
 >> iter 55000, loss: 0.194295
 >> iter 56000, loss: 0.281566
 >> iter 57000, loss: 0.256727
 >> iter 58000, loss: 0.245756
 >> iter 59000, loss: 0.198798
 >> iter 60000, loss: 0.189319
   Number of active neurons: 8
 >> iter 61000, loss: 0.198824
 >> iter 62000, loss: 0.250098
 >> iter 63000, loss: 0.277253
 >> iter 64000, loss: 0.309717
 >> iter 65000, loss: 0.238126
 >> iter 66000, loss: 0.182911
 >> iter 67000, loss: 0.266805
 >> iter 68000, loss: 0.232544
 >> iter 69000, loss: 0.310419
 >> iter 70000, loss: 0.242568
   Number of active neurons: 8
 >> iter 71000, loss: 0.222246
 >> iter 72000, loss: 0.147794
 >> iter 73000, loss: 0.220140
 >> iter 74000, loss: 0.270822
 >> iter 75000, loss: 0.291204
 >> iter 76000, loss: 0.206721
 >> iter 77000, loss: 0.248488
 >> iter 78000, loss: 0.203866
 >> iter 79000, loss: 0.248123
 >> iter 80000, loss: 0.202830
   Number of active neurons: 8
 >> iter 81000, loss: 0.206404
 >> iter 82000, loss: 0.206134
 >> iter 83000, loss: 0.296169
 >> iter 84000, loss: 0.261729
 >> iter 85000, loss: 0.166927
 >> iter 86000, loss: 0.222683
 >> iter 87000, loss: 0.222604
 >> iter 88000, loss: 0.198792
 >> iter 89000, loss: 0.324707
 >> iter 90000, loss: 0.261266
   Number of active neurons: 8
 >> iter 91000, loss: 0.229269
 >> iter 92000, loss: 0.156353
 >> iter 93000, loss: 0.197381
 >> iter 94000, loss: 0.197055
 >> iter 95000, loss: 0.193948
 >> iter 96000, loss: 0.265138
 >> iter 97000, loss: 0.211732
 >> iter 98000, loss: 0.219558
 >> iter 99000, loss: 0.177184
 >> iter 100000, loss: 0.211319
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.411835
 >> iter 2000, loss: 11.584108
 >> iter 3000, loss: 8.948125
 >> iter 4000, loss: 5.831360
 >> iter 5000, loss: 3.409532
 >> iter 6000, loss: 1.796696
 >> iter 7000, loss: 1.128522
 >> iter 8000, loss: 0.839374
 >> iter 9000, loss: 0.590255
 >> iter 10000, loss: 0.632088
   Number of active neurons: 7
 >> iter 11000, loss: 0.653118
 >> iter 12000, loss: 0.621662
 >> iter 13000, loss: 0.486235
 >> iter 14000, loss: 0.492163
 >> iter 15000, loss: 0.512312
 >> iter 16000, loss: 0.366158
 >> iter 17000, loss: 0.462495
 >> iter 18000, loss: 0.514619
 >> iter 19000, loss: 0.424438
 >> iter 20000, loss: 0.518400
   Number of active neurons: 6
 >> iter 21000, loss: 0.491263
 >> iter 22000, loss: 0.422741
 >> iter 23000, loss: 0.381502
 >> iter 24000, loss: 0.275078
 >> iter 25000, loss: 0.398427
 >> iter 26000, loss: 0.382489
 >> iter 27000, loss: 0.278973
 >> iter 28000, loss: 0.356301
 >> iter 29000, loss: 0.390031
 >> iter 30000, loss: 0.313398
   Number of active neurons: 5
 >> iter 31000, loss: 0.320660
 >> iter 32000, loss: 0.326737
 >> iter 33000, loss: 0.441214
 >> iter 34000, loss: 0.460235
 >> iter 35000, loss: 0.326159
 >> iter 36000, loss: 0.431030
 >> iter 37000, loss: 0.428644
 >> iter 38000, loss: 0.389431
 >> iter 39000, loss: 0.321764
 >> iter 40000, loss: 0.219937
   Number of active neurons: 5
 >> iter 41000, loss: 0.246750
 >> iter 42000, loss: 0.245750
 >> iter 43000, loss: 0.234574
 >> iter 44000, loss: 0.305233
 >> iter 45000, loss: 0.379766
 >> iter 46000, loss: 0.456354
 >> iter 47000, loss: 0.425575
 >> iter 48000, loss: 0.388676
 >> iter 49000, loss: 0.383644
 >> iter 50000, loss: 0.397017
   Number of active neurons: 4
 >> iter 51000, loss: 0.308807
 >> iter 52000, loss: 0.341672
 >> iter 53000, loss: 0.347787
 >> iter 54000, loss: 0.395587
 >> iter 55000, loss: 0.379613
 >> iter 56000, loss: 0.367735
 >> iter 57000, loss: 0.463406
 >> iter 58000, loss: 0.451190
 >> iter 59000, loss: 0.459485
 >> iter 60000, loss: 0.457451
   Number of active neurons: 4
 >> iter 61000, loss: 0.533539
 >> iter 62000, loss: 0.426783
 >> iter 63000, loss: 0.377987
 >> iter 64000, loss: 0.393061
 >> iter 65000, loss: 0.420849
 >> iter 66000, loss: 0.306484
 >> iter 67000, loss: 0.440972
 >> iter 68000, loss: 0.318738
 >> iter 69000, loss: 0.350623
 >> iter 70000, loss: 0.290082
   Number of active neurons: 4
 >> iter 71000, loss: 0.281992
 >> iter 72000, loss: 0.421813
 >> iter 73000, loss: 0.354336
 >> iter 74000, loss: 0.415196
 >> iter 75000, loss: 0.417831
 >> iter 76000, loss: 0.276415
 >> iter 77000, loss: 0.378668
 >> iter 78000, loss: 0.452278
 >> iter 79000, loss: 0.294523
 >> iter 80000, loss: 0.301436
   Number of active neurons: 4
 >> iter 81000, loss: 0.296801
 >> iter 82000, loss: 0.473983
 >> iter 83000, loss: 0.362996
 >> iter 84000, loss: 0.347808
 >> iter 85000, loss: 0.651867
 >> iter 86000, loss: 0.539868
 >> iter 87000, loss: 0.515138
 >> iter 88000, loss: 0.402614
 >> iter 89000, loss: 0.462962
 >> iter 90000, loss: 0.314149
   Number of active neurons: 4
 >> iter 91000, loss: 0.265605
 >> iter 92000, loss: 0.228816
 >> iter 93000, loss: 0.322170
 >> iter 94000, loss: 0.308720
 >> iter 95000, loss: 0.278212
 >> iter 96000, loss: 0.412189
 >> iter 97000, loss: 0.394243
 >> iter 98000, loss: 0.415069
 >> iter 99000, loss: 0.334993
 >> iter 100000, loss: 0.382375
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

