 > Problema: tomita2nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 1e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.775179
 >> iter 2000, loss: 3.978111
 >> iter 3000, loss: 1.471065
 >> iter 4000, loss: 0.546349
 >> iter 5000, loss: 0.205398
 >> iter 6000, loss: 0.079160
 >> iter 7000, loss: 0.032464
 >> iter 8000, loss: 0.014859
 >> iter 9000, loss: 0.008283
 >> iter 10000, loss: 0.005596
   Number of active neurons: 8
 >> iter 11000, loss: 0.004573
 >> iter 12000, loss: 0.004003
 >> iter 13000, loss: 0.003796
 >> iter 14000, loss: 0.003567
 >> iter 15000, loss: 0.003532
 >> iter 16000, loss: 0.003362
 >> iter 17000, loss: 0.003376
 >> iter 18000, loss: 0.003240
 >> iter 19000, loss: 0.003275
 >> iter 20000, loss: 0.003159
   Number of active neurons: 7
 >> iter 21000, loss: 0.003201
 >> iter 22000, loss: 0.003097
 >> iter 23000, loss: 0.003148
 >> iter 24000, loss: 0.003052
 >> iter 25000, loss: 0.003107
 >> iter 26000, loss: 0.003016
 >> iter 27000, loss: 0.003073
 >> iter 28000, loss: 0.002987
 >> iter 29000, loss: 0.003047
 >> iter 30000, loss: 0.002968
   Number of active neurons: 7
 >> iter 31000, loss: 0.003026
 >> iter 32000, loss: 0.002950
 >> iter 33000, loss: 0.003003
 >> iter 34000, loss: 0.002937
 >> iter 35000, loss: 0.002984
 >> iter 36000, loss: 0.002924
 >> iter 37000, loss: 0.002968
 >> iter 38000, loss: 0.002912
 >> iter 39000, loss: 0.002954
 >> iter 40000, loss: 0.002906
   Number of active neurons: 7
 >> iter 41000, loss: 0.002945
 >> iter 42000, loss: 0.002898
 >> iter 43000, loss: 0.002938
 >> iter 44000, loss: 0.002895
 >> iter 45000, loss: 0.002932
 >> iter 46000, loss: 0.002889
 >> iter 47000, loss: 0.002927
 >> iter 48000, loss: 0.002883
 >> iter 49000, loss: 0.002922
 >> iter 50000, loss: 0.002878
   Number of active neurons: 7
 >> iter 51000, loss: 0.002916
 >> iter 52000, loss: 0.002876
 >> iter 53000, loss: 0.002908
 >> iter 54000, loss: 0.002872
 >> iter 55000, loss: 0.002903
 >> iter 56000, loss: 0.002867
 >> iter 57000, loss: 0.002895
 >> iter 58000, loss: 0.002859
 >> iter 59000, loss: 0.002888
 >> iter 60000, loss: 0.002852
   Number of active neurons: 7
 >> iter 61000, loss: 0.002882
 >> iter 62000, loss: 0.002842
 >> iter 63000, loss: 0.002869
 >> iter 64000, loss: 0.002831
 >> iter 65000, loss: 0.002856
 >> iter 66000, loss: 0.002820
 >> iter 67000, loss: 0.002843
 >> iter 68000, loss: 0.002810
 >> iter 69000, loss: 0.002829
 >> iter 70000, loss: 0.002798
   Number of active neurons: 7
 >> iter 71000, loss: 0.002814
 >> iter 72000, loss: 0.002782
 >> iter 73000, loss: 0.002799
 >> iter 74000, loss: 0.002765
 >> iter 75000, loss: 0.002780
 >> iter 76000, loss: 0.002749
 >> iter 77000, loss: 0.002764
 >> iter 78000, loss: 0.002733
 >> iter 79000, loss: 0.002749
 >> iter 80000, loss: 0.002717
   Number of active neurons: 5
 >> iter 81000, loss: 0.002734
 >> iter 82000, loss: 0.002704
 >> iter 83000, loss: 0.002723
 >> iter 84000, loss: 0.002694
 >> iter 85000, loss: 0.002711
 >> iter 86000, loss: 0.002683
 >> iter 87000, loss: 0.002701
 >> iter 88000, loss: 0.002677
 >> iter 89000, loss: 0.002692
 >> iter 90000, loss: 0.002667
   Number of active neurons: 5
 >> iter 91000, loss: 0.002682
 >> iter 92000, loss: 0.002661
 >> iter 93000, loss: 0.002676
 >> iter 94000, loss: 0.002654
 >> iter 95000, loss: 0.002670
 >> iter 96000, loss: 0.002647
 >> iter 97000, loss: 0.002663
 >> iter 98000, loss: 0.002640
 >> iter 99000, loss: 0.002657
 >> iter 100000, loss: 0.002635
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 10.794312
 >> iter 2000, loss: 3.986651
 >> iter 3000, loss: 1.475025
 >> iter 4000, loss: 0.548442
 >> iter 5000, loss: 0.206736
 >> iter 6000, loss: 0.080093
 >> iter 7000, loss: 0.033237
 >> iter 8000, loss: 0.015479
 >> iter 9000, loss: 0.008851
 >> iter 10000, loss: 0.006069
   Number of active neurons: 7
 >> iter 11000, loss: 0.005026
 >> iter 12000, loss: 0.004389
 >> iter 13000, loss: 0.004175
 >> iter 14000, loss: 0.003893
 >> iter 15000, loss: 0.003841
 >> iter 16000, loss: 0.003638
 >> iter 17000, loss: 0.003629
 >> iter 18000, loss: 0.003465
 >> iter 19000, loss: 0.003474
 >> iter 20000, loss: 0.003335
   Number of active neurons: 7
 >> iter 21000, loss: 0.003355
 >> iter 22000, loss: 0.003231
 >> iter 23000, loss: 0.003259
 >> iter 24000, loss: 0.003145
 >> iter 25000, loss: 0.003181
 >> iter 26000, loss: 0.003077
 >> iter 27000, loss: 0.003121
 >> iter 28000, loss: 0.003023
 >> iter 29000, loss: 0.003070
 >> iter 30000, loss: 0.002978
   Number of active neurons: 5
 >> iter 31000, loss: 0.003024
 >> iter 32000, loss: 0.002935
 >> iter 33000, loss: 0.002980
 >> iter 34000, loss: 0.002901
 >> iter 35000, loss: 0.002940
 >> iter 36000, loss: 0.002867
 >> iter 37000, loss: 0.002906
 >> iter 38000, loss: 0.002838
 >> iter 39000, loss: 0.002874
 >> iter 40000, loss: 0.002813
   Number of active neurons: 5
 >> iter 41000, loss: 0.002845
 >> iter 42000, loss: 0.002787
 >> iter 43000, loss: 0.002820
 >> iter 44000, loss: 0.002767
 >> iter 45000, loss: 0.002795
 >> iter 46000, loss: 0.002744
 >> iter 47000, loss: 0.002773
 >> iter 48000, loss: 0.002721
 >> iter 49000, loss: 0.002748
 >> iter 50000, loss: 0.002698
   Number of active neurons: 5
 >> iter 51000, loss: 0.002727
 >> iter 52000, loss: 0.002683
 >> iter 53000, loss: 0.002708
 >> iter 54000, loss: 0.002671
 >> iter 55000, loss: 0.002695
 >> iter 56000, loss: 0.002659
 >> iter 57000, loss: 0.002680
 >> iter 58000, loss: 0.002644
 >> iter 59000, loss: 0.002662
 >> iter 60000, loss: 0.002626
   Number of active neurons: 5
 >> iter 61000, loss: 0.002645
 >> iter 62000, loss: 0.002607
 >> iter 63000, loss: 0.002625
 >> iter 64000, loss: 0.002591
 >> iter 65000, loss: 0.002606
 >> iter 66000, loss: 0.002574
 >> iter 67000, loss: 0.002588
 >> iter 68000, loss: 0.002558
 >> iter 69000, loss: 0.002568
 >> iter 70000, loss: 0.002541
   Number of active neurons: 5
 >> iter 71000, loss: 0.002550
 >> iter 72000, loss: 0.002523
 >> iter 73000, loss: 0.002534
 >> iter 74000, loss: 0.002506
 >> iter 75000, loss: 0.002515
 >> iter 76000, loss: 0.002487
 >> iter 77000, loss: 0.002495
 >> iter 78000, loss: 0.002466
 >> iter 79000, loss: 0.002474
 >> iter 80000, loss: 0.002445
   Number of active neurons: 5
 >> iter 81000, loss: 0.002453
 >> iter 82000, loss: 0.002423
 >> iter 83000, loss: 0.002432
 >> iter 84000, loss: 0.002403
 >> iter 85000, loss: 0.002409
 >> iter 86000, loss: 0.002381
 >> iter 87000, loss: 0.002388
 >> iter 88000, loss: 0.002362
 >> iter 89000, loss: 0.002367
 >> iter 90000, loss: 0.002341
   Number of active neurons: 5
 >> iter 91000, loss: 0.002345
 >> iter 92000, loss: 0.002323
 >> iter 93000, loss: 0.002327
 >> iter 94000, loss: 0.002305
 >> iter 95000, loss: 0.002310
 >> iter 96000, loss: 0.002287
 >> iter 97000, loss: 0.002293
 >> iter 98000, loss: 0.002270
 >> iter 99000, loss: 0.002277
 >> iter 100000, loss: 0.002256
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.900864
 >> iter 2000, loss: 4.024879
 >> iter 3000, loss: 1.488121
 >> iter 4000, loss: 0.552870
 >> iter 5000, loss: 0.207995
 >> iter 6000, loss: 0.080392
 >> iter 7000, loss: 0.033141
 >> iter 8000, loss: 0.015355
 >> iter 9000, loss: 0.008673
 >> iter 10000, loss: 0.005953
   Number of active neurons: 8
 >> iter 11000, loss: 0.004893
 >> iter 12000, loss: 0.004312
 >> iter 13000, loss: 0.004077
 >> iter 14000, loss: 0.003837
 >> iter 15000, loss: 0.003769
 >> iter 16000, loss: 0.003595
 >> iter 17000, loss: 0.003572
 >> iter 18000, loss: 0.003431
 >> iter 19000, loss: 0.003434
 >> iter 20000, loss: 0.003310
   Number of active neurons: 8
 >> iter 21000, loss: 0.003324
 >> iter 22000, loss: 0.003210
 >> iter 23000, loss: 0.003228
 >> iter 24000, loss: 0.003122
 >> iter 25000, loss: 0.003148
 >> iter 26000, loss: 0.003048
 >> iter 27000, loss: 0.003087
 >> iter 28000, loss: 0.002992
 >> iter 29000, loss: 0.003037
 >> iter 30000, loss: 0.002949
   Number of active neurons: 7
 >> iter 31000, loss: 0.002994
 >> iter 32000, loss: 0.002907
 >> iter 33000, loss: 0.002952
 >> iter 34000, loss: 0.002873
 >> iter 35000, loss: 0.002916
 >> iter 36000, loss: 0.002841
 >> iter 37000, loss: 0.002883
 >> iter 38000, loss: 0.002814
 >> iter 39000, loss: 0.002856
 >> iter 40000, loss: 0.002795
   Number of active neurons: 7
 >> iter 41000, loss: 0.002831
 >> iter 42000, loss: 0.002772
 >> iter 43000, loss: 0.002810
 >> iter 44000, loss: 0.002758
 >> iter 45000, loss: 0.002793
 >> iter 46000, loss: 0.002742
 >> iter 47000, loss: 0.002780
 >> iter 48000, loss: 0.002731
 >> iter 49000, loss: 0.002770
 >> iter 50000, loss: 0.002723
   Number of active neurons: 7
 >> iter 51000, loss: 0.002761
 >> iter 52000, loss: 0.002719
 >> iter 53000, loss: 0.002753
 >> iter 54000, loss: 0.002717
 >> iter 55000, loss: 0.002750
 >> iter 56000, loss: 0.002712
 >> iter 57000, loss: 0.002741
 >> iter 58000, loss: 0.002704
 >> iter 59000, loss: 0.002734
 >> iter 60000, loss: 0.002700
   Number of active neurons: 7
 >> iter 61000, loss: 0.002734
 >> iter 62000, loss: 0.002696
 >> iter 63000, loss: 0.002728
 >> iter 64000, loss: 0.002694
 >> iter 65000, loss: 0.002724
 >> iter 66000, loss: 0.002692
 >> iter 67000, loss: 0.002722
 >> iter 68000, loss: 0.002694
 >> iter 69000, loss: 0.002719
 >> iter 70000, loss: 0.002693
   Number of active neurons: 6
 >> iter 71000, loss: 0.002717
 >> iter 72000, loss: 0.002691
 >> iter 73000, loss: 0.002719
 >> iter 74000, loss: 0.002692
 >> iter 75000, loss: 0.002718
 >> iter 76000, loss: 0.002691
 >> iter 77000, loss: 0.002716
 >> iter 78000, loss: 0.002688
 >> iter 79000, loss: 0.002715
 >> iter 80000, loss: 0.002686
   Number of active neurons: 6
 >> iter 81000, loss: 0.002713
 >> iter 82000, loss: 0.002684
 >> iter 83000, loss: 0.002712
 >> iter 84000, loss: 0.002683
 >> iter 85000, loss: 0.002709
 >> iter 86000, loss: 0.002680
 >> iter 87000, loss: 0.002704
 >> iter 88000, loss: 0.002679
 >> iter 89000, loss: 0.002701
 >> iter 90000, loss: 0.002675
   Number of active neurons: 6
 >> iter 91000, loss: 0.002696
 >> iter 92000, loss: 0.002675
 >> iter 93000, loss: 0.002694
 >> iter 94000, loss: 0.002670
 >> iter 95000, loss: 0.002688
 >> iter 96000, loss: 0.002662
 >> iter 97000, loss: 0.002679
 >> iter 98000, loss: 0.002653
 >> iter 99000, loss: 0.002671
 >> iter 100000, loss: 0.002647
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.807010
 >> iter 2000, loss: 3.991736
 >> iter 3000, loss: 1.476976
 >> iter 4000, loss: 0.549193
 >> iter 5000, loss: 0.207020
 >> iter 6000, loss: 0.080216
 >> iter 7000, loss: 0.033293
 >> iter 8000, loss: 0.015536
 >> iter 9000, loss: 0.008910
 >> iter 10000, loss: 0.006145
   Number of active neurons: 10
 >> iter 11000, loss: 0.005110
 >> iter 12000, loss: 0.004487
 >> iter 13000, loss: 0.004278
 >> iter 14000, loss: 0.004005
 >> iter 15000, loss: 0.003960
 >> iter 16000, loss: 0.003754
 >> iter 17000, loss: 0.003748
 >> iter 18000, loss: 0.003576
 >> iter 19000, loss: 0.003592
 >> iter 20000, loss: 0.003443
   Number of active neurons: 8
 >> iter 21000, loss: 0.003471
 >> iter 22000, loss: 0.003336
 >> iter 23000, loss: 0.003372
 >> iter 24000, loss: 0.003252
 >> iter 25000, loss: 0.003296
 >> iter 26000, loss: 0.003179
 >> iter 27000, loss: 0.003225
 >> iter 28000, loss: 0.003115
 >> iter 29000, loss: 0.003164
 >> iter 30000, loss: 0.003062
   Number of active neurons: 8
 >> iter 31000, loss: 0.003110
 >> iter 32000, loss: 0.003011
 >> iter 33000, loss: 0.003060
 >> iter 34000, loss: 0.002973
 >> iter 35000, loss: 0.003017
 >> iter 36000, loss: 0.002937
 >> iter 37000, loss: 0.002984
 >> iter 38000, loss: 0.002910
 >> iter 39000, loss: 0.002957
 >> iter 40000, loss: 0.002894
   Number of active neurons: 8
 >> iter 41000, loss: 0.002937
 >> iter 42000, loss: 0.002875
 >> iter 43000, loss: 0.002918
 >> iter 44000, loss: 0.002863
 >> iter 45000, loss: 0.002904
 >> iter 46000, loss: 0.002849
 >> iter 47000, loss: 0.002890
 >> iter 48000, loss: 0.002835
 >> iter 49000, loss: 0.002876
 >> iter 50000, loss: 0.002820
   Number of active neurons: 7
 >> iter 51000, loss: 0.002859
 >> iter 52000, loss: 0.002809
 >> iter 53000, loss: 0.002843
 >> iter 54000, loss: 0.002799
 >> iter 55000, loss: 0.002833
 >> iter 56000, loss: 0.002791
 >> iter 57000, loss: 0.002823
 >> iter 58000, loss: 0.002783
 >> iter 59000, loss: 0.002816
 >> iter 60000, loss: 0.002778
   Number of active neurons: 7
 >> iter 61000, loss: 0.002815
 >> iter 62000, loss: 0.002774
 >> iter 63000, loss: 0.002808
 >> iter 64000, loss: 0.002768
 >> iter 65000, loss: 0.002799
 >> iter 66000, loss: 0.002761
 >> iter 67000, loss: 0.002789
 >> iter 68000, loss: 0.002754
 >> iter 69000, loss: 0.002773
 >> iter 70000, loss: 0.002738
   Number of active neurons: 6
 >> iter 71000, loss: 0.002755
 >> iter 72000, loss: 0.002721
 >> iter 73000, loss: 0.002740
 >> iter 74000, loss: 0.002704
 >> iter 75000, loss: 0.002720
 >> iter 76000, loss: 0.002686
 >> iter 77000, loss: 0.002702
 >> iter 78000, loss: 0.002669
 >> iter 79000, loss: 0.002686
 >> iter 80000, loss: 0.002653
   Number of active neurons: 6
 >> iter 81000, loss: 0.002672
 >> iter 82000, loss: 0.002640
 >> iter 83000, loss: 0.002659
 >> iter 84000, loss: 0.002628
 >> iter 85000, loss: 0.002646
 >> iter 86000, loss: 0.002616
 >> iter 87000, loss: 0.002633
 >> iter 88000, loss: 0.002608
 >> iter 89000, loss: 0.002622
 >> iter 90000, loss: 0.002596
   Number of active neurons: 6
 >> iter 91000, loss: 0.002609
 >> iter 92000, loss: 0.002587
 >> iter 93000, loss: 0.002599
 >> iter 94000, loss: 0.002575
 >> iter 95000, loss: 0.002587
 >> iter 96000, loss: 0.002562
 >> iter 97000, loss: 0.002574
 >> iter 98000, loss: 0.002548
 >> iter 99000, loss: 0.002561
 >> iter 100000, loss: 0.002537
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.855608
 >> iter 2000, loss: 4.011070
 >> iter 3000, loss: 1.484431
 >> iter 4000, loss: 0.551957
 >> iter 5000, loss: 0.208120
 >> iter 6000, loss: 0.080598
 >> iter 7000, loss: 0.033469
 >> iter 8000, loss: 0.015563
 >> iter 9000, loss: 0.008919
 >> iter 10000, loss: 0.006105
   Number of active neurons: 8
 >> iter 11000, loss: 0.005078
 >> iter 12000, loss: 0.004426
 >> iter 13000, loss: 0.004222
 >> iter 14000, loss: 0.003933
 >> iter 15000, loss: 0.003905
 >> iter 16000, loss: 0.003682
 >> iter 17000, loss: 0.003696
 >> iter 18000, loss: 0.003515
 >> iter 19000, loss: 0.003549
 >> iter 20000, loss: 0.003392
   Number of active neurons: 8
 >> iter 21000, loss: 0.003432
 >> iter 22000, loss: 0.003288
 >> iter 23000, loss: 0.003334
 >> iter 24000, loss: 0.003202
 >> iter 25000, loss: 0.003253
 >> iter 26000, loss: 0.003131
 >> iter 27000, loss: 0.003187
 >> iter 28000, loss: 0.003074
 >> iter 29000, loss: 0.003131
 >> iter 30000, loss: 0.003022
   Number of active neurons: 8
 >> iter 31000, loss: 0.003077
 >> iter 32000, loss: 0.002975
 >> iter 33000, loss: 0.003032
 >> iter 34000, loss: 0.002942
 >> iter 35000, loss: 0.002992
 >> iter 36000, loss: 0.002907
 >> iter 37000, loss: 0.002955
 >> iter 38000, loss: 0.002873
 >> iter 39000, loss: 0.002917
 >> iter 40000, loss: 0.002848
   Number of active neurons: 8
 >> iter 41000, loss: 0.002886
 >> iter 42000, loss: 0.002820
 >> iter 43000, loss: 0.002860
 >> iter 44000, loss: 0.002800
 >> iter 45000, loss: 0.002835
 >> iter 46000, loss: 0.002773
 >> iter 47000, loss: 0.002807
 >> iter 48000, loss: 0.002747
 >> iter 49000, loss: 0.002784
 >> iter 50000, loss: 0.002728
   Number of active neurons: 8
 >> iter 51000, loss: 0.002766
 >> iter 52000, loss: 0.002716
 >> iter 53000, loss: 0.002748
 >> iter 54000, loss: 0.002703
 >> iter 55000, loss: 0.002732
 >> iter 56000, loss: 0.002686
 >> iter 57000, loss: 0.002713
 >> iter 58000, loss: 0.002670
 >> iter 59000, loss: 0.002697
 >> iter 60000, loss: 0.002656
   Number of active neurons: 8
 >> iter 61000, loss: 0.002688
 >> iter 62000, loss: 0.002647
 >> iter 63000, loss: 0.002674
 >> iter 64000, loss: 0.002636
 >> iter 65000, loss: 0.002661
 >> iter 66000, loss: 0.002625
 >> iter 67000, loss: 0.002649
 >> iter 68000, loss: 0.002619
 >> iter 69000, loss: 0.002639
 >> iter 70000, loss: 0.002611
   Number of active neurons: 8
 >> iter 71000, loss: 0.002629
 >> iter 72000, loss: 0.002602
 >> iter 73000, loss: 0.002623
 >> iter 74000, loss: 0.002594
 >> iter 75000, loss: 0.002613
 >> iter 76000, loss: 0.002586
 >> iter 77000, loss: 0.002605
 >> iter 78000, loss: 0.002577
 >> iter 79000, loss: 0.002596
 >> iter 80000, loss: 0.002568
   Number of active neurons: 8
 >> iter 81000, loss: 0.002588
 >> iter 82000, loss: 0.002561
 >> iter 83000, loss: 0.002581
 >> iter 84000, loss: 0.002554
 >> iter 85000, loss: 0.002573
 >> iter 86000, loss: 0.002548
 >> iter 87000, loss: 0.002568
 >> iter 88000, loss: 0.002547
 >> iter 89000, loss: 0.002564
 >> iter 90000, loss: 0.002542
   Number of active neurons: 8
 >> iter 91000, loss: 0.002557
 >> iter 92000, loss: 0.002539
 >> iter 93000, loss: 0.002555
 >> iter 94000, loss: 0.002537
 >> iter 95000, loss: 0.002554
 >> iter 96000, loss: 0.002534
 >> iter 97000, loss: 0.002551
 >> iter 98000, loss: 0.002532
 >> iter 99000, loss: 0.002549
 >> iter 100000, loss: 0.002532
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.823915
 >> iter 2000, loss: 3.998670
 >> iter 3000, loss: 1.479822
 >> iter 4000, loss: 0.550470
 >> iter 5000, loss: 0.207643
 >> iter 6000, loss: 0.080581
 >> iter 7000, loss: 0.033528
 >> iter 8000, loss: 0.015706
 >> iter 9000, loss: 0.009027
 >> iter 10000, loss: 0.006238
   Number of active neurons: 9
 >> iter 11000, loss: 0.005174
 >> iter 12000, loss: 0.004545
 >> iter 13000, loss: 0.004317
 >> iter 14000, loss: 0.004043
 >> iter 15000, loss: 0.003983
 >> iter 16000, loss: 0.003783
 >> iter 17000, loss: 0.003765
 >> iter 18000, loss: 0.003604
 >> iter 19000, loss: 0.003608
 >> iter 20000, loss: 0.003475
   Number of active neurons: 9
 >> iter 21000, loss: 0.003493
 >> iter 22000, loss: 0.003379
 >> iter 23000, loss: 0.003406
 >> iter 24000, loss: 0.003305
 >> iter 25000, loss: 0.003337
 >> iter 26000, loss: 0.003244
 >> iter 27000, loss: 0.003282
 >> iter 28000, loss: 0.003197
 >> iter 29000, loss: 0.003240
 >> iter 30000, loss: 0.003165
   Number of active neurons: 7
 >> iter 31000, loss: 0.003211
 >> iter 32000, loss: 0.003140
 >> iter 33000, loss: 0.003187
 >> iter 34000, loss: 0.003122
 >> iter 35000, loss: 0.003167
 >> iter 36000, loss: 0.003107
 >> iter 37000, loss: 0.003151
 >> iter 38000, loss: 0.003092
 >> iter 39000, loss: 0.003133
 >> iter 40000, loss: 0.003080
   Number of active neurons: 7
 >> iter 41000, loss: 0.003116
 >> iter 42000, loss: 0.003064
 >> iter 43000, loss: 0.003102
 >> iter 44000, loss: 0.003057
 >> iter 45000, loss: 0.003093
 >> iter 46000, loss: 0.003047
 >> iter 47000, loss: 0.003083
 >> iter 48000, loss: 0.003035
 >> iter 49000, loss: 0.003074
 >> iter 50000, loss: 0.003026
   Number of active neurons: 7
 >> iter 51000, loss: 0.003064
 >> iter 52000, loss: 0.003023
 >> iter 53000, loss: 0.003055
 >> iter 54000, loss: 0.003016
 >> iter 55000, loss: 0.003045
 >> iter 56000, loss: 0.003007
 >> iter 57000, loss: 0.003034
 >> iter 58000, loss: 0.002998
 >> iter 59000, loss: 0.003026
 >> iter 60000, loss: 0.002992
   Number of active neurons: 7
 >> iter 61000, loss: 0.003022
 >> iter 62000, loss: 0.002984
 >> iter 63000, loss: 0.003009
 >> iter 64000, loss: 0.002972
 >> iter 65000, loss: 0.002994
 >> iter 66000, loss: 0.002959
 >> iter 67000, loss: 0.002980
 >> iter 68000, loss: 0.002949
 >> iter 69000, loss: 0.002965
 >> iter 70000, loss: 0.002935
   Number of active neurons: 7
 >> iter 71000, loss: 0.002950
 >> iter 72000, loss: 0.002921
 >> iter 73000, loss: 0.002939
 >> iter 74000, loss: 0.002909
 >> iter 75000, loss: 0.002925
 >> iter 76000, loss: 0.002895
 >> iter 77000, loss: 0.002910
 >> iter 78000, loss: 0.002881
 >> iter 79000, loss: 0.002896
 >> iter 80000, loss: 0.002865
   Number of active neurons: 7
 >> iter 81000, loss: 0.002881
 >> iter 82000, loss: 0.002851
 >> iter 83000, loss: 0.002866
 >> iter 84000, loss: 0.002836
 >> iter 85000, loss: 0.002849
 >> iter 86000, loss: 0.002819
 >> iter 87000, loss: 0.002832
 >> iter 88000, loss: 0.002807
 >> iter 89000, loss: 0.002819
 >> iter 90000, loss: 0.002794
   Number of active neurons: 7
 >> iter 91000, loss: 0.002805
 >> iter 92000, loss: 0.002784
 >> iter 93000, loss: 0.002795
 >> iter 94000, loss: 0.002774
 >> iter 95000, loss: 0.002787
 >> iter 96000, loss: 0.002765
 >> iter 97000, loss: 0.002779
 >> iter 98000, loss: 0.002757
 >> iter 99000, loss: 0.002771
 >> iter 100000, loss: 0.002752
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.869322
 >> iter 2000, loss: 4.014266
 >> iter 3000, loss: 1.484393
 >> iter 4000, loss: 0.551468
 >> iter 5000, loss: 0.207474
 >> iter 6000, loss: 0.080104
 >> iter 7000, loss: 0.032969
 >> iter 8000, loss: 0.015172
 >> iter 9000, loss: 0.008512
 >> iter 10000, loss: 0.005760
   Number of active neurons: 8
 >> iter 11000, loss: 0.004713
 >> iter 12000, loss: 0.004103
 >> iter 13000, loss: 0.003885
 >> iter 14000, loss: 0.003622
 >> iter 15000, loss: 0.003582
 >> iter 16000, loss: 0.003371
 >> iter 17000, loss: 0.003375
 >> iter 18000, loss: 0.003205
 >> iter 19000, loss: 0.003229
 >> iter 20000, loss: 0.003085
   Number of active neurons: 7
 >> iter 21000, loss: 0.003124
 >> iter 22000, loss: 0.002998
 >> iter 23000, loss: 0.003046
 >> iter 24000, loss: 0.002932
 >> iter 25000, loss: 0.002983
 >> iter 26000, loss: 0.002876
 >> iter 27000, loss: 0.002929
 >> iter 28000, loss: 0.002828
 >> iter 29000, loss: 0.002883
 >> iter 30000, loss: 0.002790
   Number of active neurons: 7
 >> iter 31000, loss: 0.002845
 >> iter 32000, loss: 0.002756
 >> iter 33000, loss: 0.002809
 >> iter 34000, loss: 0.002728
 >> iter 35000, loss: 0.002773
 >> iter 36000, loss: 0.002694
 >> iter 37000, loss: 0.002735
 >> iter 38000, loss: 0.002663
 >> iter 39000, loss: 0.002704
 >> iter 40000, loss: 0.002641
   Number of active neurons: 6
 >> iter 41000, loss: 0.002677
 >> iter 42000, loss: 0.002617
 >> iter 43000, loss: 0.002650
 >> iter 44000, loss: 0.002596
 >> iter 45000, loss: 0.002629
 >> iter 46000, loss: 0.002579
 >> iter 47000, loss: 0.002614
 >> iter 48000, loss: 0.002567
 >> iter 49000, loss: 0.002604
 >> iter 50000, loss: 0.002558
   Number of active neurons: 6
 >> iter 51000, loss: 0.002594
 >> iter 52000, loss: 0.002554
 >> iter 53000, loss: 0.002586
 >> iter 54000, loss: 0.002549
 >> iter 55000, loss: 0.002580
 >> iter 56000, loss: 0.002543
 >> iter 57000, loss: 0.002573
 >> iter 58000, loss: 0.002536
 >> iter 59000, loss: 0.002567
 >> iter 60000, loss: 0.002531
   Number of active neurons: 6
 >> iter 61000, loss: 0.002564
 >> iter 62000, loss: 0.002524
 >> iter 63000, loss: 0.002551
 >> iter 64000, loss: 0.002512
 >> iter 65000, loss: 0.002537
 >> iter 66000, loss: 0.002499
 >> iter 67000, loss: 0.002523
 >> iter 68000, loss: 0.002490
 >> iter 69000, loss: 0.002509
 >> iter 70000, loss: 0.002476
   Number of active neurons: 6
 >> iter 71000, loss: 0.002491
 >> iter 72000, loss: 0.002459
 >> iter 73000, loss: 0.002476
 >> iter 74000, loss: 0.002444
 >> iter 75000, loss: 0.002459
 >> iter 76000, loss: 0.002428
 >> iter 77000, loss: 0.002442
 >> iter 78000, loss: 0.002412
 >> iter 79000, loss: 0.002428
 >> iter 80000, loss: 0.002398
   Number of active neurons: 6
 >> iter 81000, loss: 0.002415
 >> iter 82000, loss: 0.002387
 >> iter 83000, loss: 0.002405
 >> iter 84000, loss: 0.002378
 >> iter 85000, loss: 0.002395
 >> iter 86000, loss: 0.002369
 >> iter 87000, loss: 0.002385
 >> iter 88000, loss: 0.002363
 >> iter 89000, loss: 0.002377
 >> iter 90000, loss: 0.002355
   Number of active neurons: 6
 >> iter 91000, loss: 0.002369
 >> iter 92000, loss: 0.002351
 >> iter 93000, loss: 0.002365
 >> iter 94000, loss: 0.002344
 >> iter 95000, loss: 0.002359
 >> iter 96000, loss: 0.002339
 >> iter 97000, loss: 0.002353
 >> iter 98000, loss: 0.002332
 >> iter 99000, loss: 0.002348
 >> iter 100000, loss: 0.002328
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.819794
 >> iter 2000, loss: 3.996663
 >> iter 3000, loss: 1.478834
 >> iter 4000, loss: 0.549928
 >> iter 5000, loss: 0.207274
 >> iter 6000, loss: 0.080267
 >> iter 7000, loss: 0.033228
 >> iter 8000, loss: 0.015397
 >> iter 9000, loss: 0.008717
 >> iter 10000, loss: 0.005910
   Number of active neurons: 8
 >> iter 11000, loss: 0.004842
 >> iter 12000, loss: 0.004191
 >> iter 13000, loss: 0.003959
 >> iter 14000, loss: 0.003668
 >> iter 15000, loss: 0.003604
 >> iter 16000, loss: 0.003386
 >> iter 17000, loss: 0.003369
 >> iter 18000, loss: 0.003185
 >> iter 19000, loss: 0.003193
 >> iter 20000, loss: 0.003036
   Number of active neurons: 6
 >> iter 21000, loss: 0.003057
 >> iter 22000, loss: 0.002921
 >> iter 23000, loss: 0.002952
 >> iter 24000, loss: 0.002830
 >> iter 25000, loss: 0.002868
 >> iter 26000, loss: 0.002759
 >> iter 27000, loss: 0.002803
 >> iter 28000, loss: 0.002702
 >> iter 29000, loss: 0.002748
 >> iter 30000, loss: 0.002658
   Number of active neurons: 5
 >> iter 31000, loss: 0.002705
 >> iter 32000, loss: 0.002621
 >> iter 33000, loss: 0.002666
 >> iter 34000, loss: 0.002592
 >> iter 35000, loss: 0.002634
 >> iter 36000, loss: 0.002567
 >> iter 37000, loss: 0.002609
 >> iter 38000, loss: 0.002547
 >> iter 39000, loss: 0.002586
 >> iter 40000, loss: 0.002532
   Number of active neurons: 4
 >> iter 41000, loss: 0.002565
 >> iter 42000, loss: 0.002509
 >> iter 43000, loss: 0.002542
 >> iter 44000, loss: 0.002492
 >> iter 45000, loss: 0.002522
 >> iter 46000, loss: 0.002474
 >> iter 47000, loss: 0.002505
 >> iter 48000, loss: 0.002458
 >> iter 49000, loss: 0.002489
 >> iter 50000, loss: 0.002443
   Number of active neurons: 5
 >> iter 51000, loss: 0.002472
 >> iter 52000, loss: 0.002429
 >> iter 53000, loss: 0.002454
 >> iter 54000, loss: 0.002417
 >> iter 55000, loss: 0.002441
 >> iter 56000, loss: 0.002406
 >> iter 57000, loss: 0.002428
 >> iter 58000, loss: 0.002394
 >> iter 59000, loss: 0.002413
 >> iter 60000, loss: 0.002379
   Number of active neurons: 5
 >> iter 61000, loss: 0.002400
 >> iter 62000, loss: 0.002364
 >> iter 63000, loss: 0.002383
 >> iter 64000, loss: 0.002351
 >> iter 65000, loss: 0.002368
 >> iter 66000, loss: 0.002339
 >> iter 67000, loss: 0.002355
 >> iter 68000, loss: 0.002329
 >> iter 69000, loss: 0.002342
 >> iter 70000, loss: 0.002318
   Number of active neurons: 5
 >> iter 71000, loss: 0.002330
 >> iter 72000, loss: 0.002307
 >> iter 73000, loss: 0.002321
 >> iter 74000, loss: 0.002298
 >> iter 75000, loss: 0.002311
 >> iter 76000, loss: 0.002288
 >> iter 77000, loss: 0.002300
 >> iter 78000, loss: 0.002277
 >> iter 79000, loss: 0.002290
 >> iter 80000, loss: 0.002266
   Number of active neurons: 5
 >> iter 81000, loss: 0.002280
 >> iter 82000, loss: 0.002257
 >> iter 83000, loss: 0.002271
 >> iter 84000, loss: 0.002248
 >> iter 85000, loss: 0.002261
 >> iter 86000, loss: 0.002239
 >> iter 87000, loss: 0.002252
 >> iter 88000, loss: 0.002234
 >> iter 89000, loss: 0.002245
 >> iter 90000, loss: 0.002226
   Number of active neurons: 5
 >> iter 91000, loss: 0.002236
 >> iter 92000, loss: 0.002220
 >> iter 93000, loss: 0.002230
 >> iter 94000, loss: 0.002213
 >> iter 95000, loss: 0.002223
 >> iter 96000, loss: 0.002204
 >> iter 97000, loss: 0.002214
 >> iter 98000, loss: 0.002195
 >> iter 99000, loss: 0.002207
 >> iter 100000, loss: 0.002189
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.860905
 >> iter 2000, loss: 4.011744
 >> iter 3000, loss: 1.484462
 >> iter 4000, loss: 0.552128
 >> iter 5000, loss: 0.208180
 >> iter 6000, loss: 0.080730
 >> iter 7000, loss: 0.033503
 >> iter 8000, loss: 0.015625
 >> iter 9000, loss: 0.008903
 >> iter 10000, loss: 0.006101
   Number of active neurons: 6
 >> iter 11000, loss: 0.005014
 >> iter 12000, loss: 0.004374
 >> iter 13000, loss: 0.004129
 >> iter 14000, loss: 0.003848
 >> iter 15000, loss: 0.003777
 >> iter 16000, loss: 0.003572
 >> iter 17000, loss: 0.003548
 >> iter 18000, loss: 0.003381
 >> iter 19000, loss: 0.003379
 >> iter 20000, loss: 0.003235
   Number of active neurons: 6
 >> iter 21000, loss: 0.003246
 >> iter 22000, loss: 0.003115
 >> iter 23000, loss: 0.003137
 >> iter 24000, loss: 0.003018
 >> iter 25000, loss: 0.003048
 >> iter 26000, loss: 0.002937
 >> iter 27000, loss: 0.002973
 >> iter 28000, loss: 0.002867
 >> iter 29000, loss: 0.002906
 >> iter 30000, loss: 0.002806
   Number of active neurons: 6
 >> iter 31000, loss: 0.002847
 >> iter 32000, loss: 0.002751
 >> iter 33000, loss: 0.002793
 >> iter 34000, loss: 0.002705
 >> iter 35000, loss: 0.002741
 >> iter 36000, loss: 0.002654
 >> iter 37000, loss: 0.002689
 >> iter 38000, loss: 0.002605
 >> iter 39000, loss: 0.002642
 >> iter 40000, loss: 0.002569
   Number of active neurons: 6
 >> iter 41000, loss: 0.002603
 >> iter 42000, loss: 0.002534
 >> iter 43000, loss: 0.002571
 >> iter 44000, loss: 0.002508
 >> iter 45000, loss: 0.002546
 >> iter 46000, loss: 0.002486
 >> iter 47000, loss: 0.002527
 >> iter 48000, loss: 0.002469
 >> iter 49000, loss: 0.002513
 >> iter 50000, loss: 0.002456
   Number of active neurons: 6
 >> iter 51000, loss: 0.002498
 >> iter 52000, loss: 0.002444
 >> iter 53000, loss: 0.002480
 >> iter 54000, loss: 0.002434
 >> iter 55000, loss: 0.002469
 >> iter 56000, loss: 0.002425
 >> iter 57000, loss: 0.002461
 >> iter 58000, loss: 0.002419
 >> iter 59000, loss: 0.002455
 >> iter 60000, loss: 0.002417
   Number of active neurons: 6
 >> iter 61000, loss: 0.002455
 >> iter 62000, loss: 0.002415
 >> iter 63000, loss: 0.002451
 >> iter 64000, loss: 0.002416
 >> iter 65000, loss: 0.002451
 >> iter 66000, loss: 0.002418
 >> iter 67000, loss: 0.002452
 >> iter 68000, loss: 0.002422
 >> iter 69000, loss: 0.002450
 >> iter 70000, loss: 0.002420
   Number of active neurons: 6
 >> iter 71000, loss: 0.002444
 >> iter 72000, loss: 0.002415
 >> iter 73000, loss: 0.002442
 >> iter 74000, loss: 0.002412
 >> iter 75000, loss: 0.002438
 >> iter 76000, loss: 0.002409
 >> iter 77000, loss: 0.002434
 >> iter 78000, loss: 0.002405
 >> iter 79000, loss: 0.002431
 >> iter 80000, loss: 0.002402
   Number of active neurons: 6
 >> iter 81000, loss: 0.002427
 >> iter 82000, loss: 0.002399
 >> iter 83000, loss: 0.002425
 >> iter 84000, loss: 0.002396
 >> iter 85000, loss: 0.002419
 >> iter 86000, loss: 0.002392
 >> iter 87000, loss: 0.002415
 >> iter 88000, loss: 0.002392
 >> iter 89000, loss: 0.002413
 >> iter 90000, loss: 0.002390
   Number of active neurons: 6
 >> iter 91000, loss: 0.002410
 >> iter 92000, loss: 0.002390
 >> iter 93000, loss: 0.002409
 >> iter 94000, loss: 0.002388
 >> iter 95000, loss: 0.002407
 >> iter 96000, loss: 0.002386
 >> iter 97000, loss: 0.002405
 >> iter 98000, loss: 0.002384
 >> iter 99000, loss: 0.002403
 >> iter 100000, loss: 0.002384
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.784133
 >> iter 2000, loss: 3.982493
 >> iter 3000, loss: 1.472938
 >> iter 4000, loss: 0.547297
 >> iter 5000, loss: 0.205982
 >> iter 6000, loss: 0.079563
 >> iter 7000, loss: 0.032777
 >> iter 8000, loss: 0.015096
 >> iter 9000, loss: 0.008478
 >> iter 10000, loss: 0.005738
   Number of active neurons: 7
 >> iter 11000, loss: 0.004692
 >> iter 12000, loss: 0.004085
 >> iter 13000, loss: 0.003864
 >> iter 14000, loss: 0.003602
 >> iter 15000, loss: 0.003537
 >> iter 16000, loss: 0.003337
 >> iter 17000, loss: 0.003309
 >> iter 18000, loss: 0.003148
 >> iter 19000, loss: 0.003143
 >> iter 20000, loss: 0.003007
   Number of active neurons: 7
 >> iter 21000, loss: 0.003013
 >> iter 22000, loss: 0.002890
 >> iter 23000, loss: 0.002907
 >> iter 24000, loss: 0.002797
 >> iter 25000, loss: 0.002823
 >> iter 26000, loss: 0.002723
 >> iter 27000, loss: 0.002757
 >> iter 28000, loss: 0.002662
 >> iter 29000, loss: 0.002699
 >> iter 30000, loss: 0.002613
   Number of active neurons: 6
 >> iter 31000, loss: 0.002653
 >> iter 32000, loss: 0.002571
 >> iter 33000, loss: 0.002613
 >> iter 34000, loss: 0.002540
 >> iter 35000, loss: 0.002578
 >> iter 36000, loss: 0.002510
 >> iter 37000, loss: 0.002550
 >> iter 38000, loss: 0.002485
 >> iter 39000, loss: 0.002522
 >> iter 40000, loss: 0.002464
   Number of active neurons: 6
 >> iter 41000, loss: 0.002497
 >> iter 42000, loss: 0.002439
 >> iter 43000, loss: 0.002473
 >> iter 44000, loss: 0.002421
 >> iter 45000, loss: 0.002451
 >> iter 46000, loss: 0.002396
 >> iter 47000, loss: 0.002425
 >> iter 48000, loss: 0.002372
 >> iter 49000, loss: 0.002404
 >> iter 50000, loss: 0.002354
   Number of active neurons: 5
 >> iter 51000, loss: 0.002385
 >> iter 52000, loss: 0.002341
 >> iter 53000, loss: 0.002368
 >> iter 54000, loss: 0.002329
 >> iter 55000, loss: 0.002352
 >> iter 56000, loss: 0.002313
 >> iter 57000, loss: 0.002334
 >> iter 58000, loss: 0.002300
 >> iter 59000, loss: 0.002322
 >> iter 60000, loss: 0.002291
   Number of active neurons: 5
 >> iter 61000, loss: 0.002315
 >> iter 62000, loss: 0.002283
 >> iter 63000, loss: 0.002307
 >> iter 64000, loss: 0.002279
 >> iter 65000, loss: 0.002301
 >> iter 66000, loss: 0.002277
 >> iter 67000, loss: 0.002299
 >> iter 68000, loss: 0.002279
 >> iter 69000, loss: 0.002297
 >> iter 70000, loss: 0.002279
   Number of active neurons: 5
 >> iter 71000, loss: 0.002296
 >> iter 72000, loss: 0.002278
 >> iter 73000, loss: 0.002296
 >> iter 74000, loss: 0.002276
 >> iter 75000, loss: 0.002293
 >> iter 76000, loss: 0.002275
 >> iter 77000, loss: 0.002292
 >> iter 78000, loss: 0.002273
 >> iter 79000, loss: 0.002290
 >> iter 80000, loss: 0.002270
   Number of active neurons: 5
 >> iter 81000, loss: 0.002288
 >> iter 82000, loss: 0.002268
 >> iter 83000, loss: 0.002286
 >> iter 84000, loss: 0.002266
 >> iter 85000, loss: 0.002282
 >> iter 86000, loss: 0.002263
 >> iter 87000, loss: 0.002278
 >> iter 88000, loss: 0.002261
 >> iter 89000, loss: 0.002273
 >> iter 90000, loss: 0.002255
   Number of active neurons: 5
 >> iter 91000, loss: 0.002267
 >> iter 92000, loss: 0.002252
 >> iter 93000, loss: 0.002263
 >> iter 94000, loss: 0.002247
 >> iter 95000, loss: 0.002259
 >> iter 96000, loss: 0.002242
 >> iter 97000, loss: 0.002254
 >> iter 98000, loss: 0.002236
 >> iter 99000, loss: 0.002249
 >> iter 100000, loss: 0.002233
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 10.864064
 >> iter 2000, loss: 4.011652
 >> iter 3000, loss: 1.483145
 >> iter 4000, loss: 0.550886
 >> iter 5000, loss: 0.207135
 >> iter 6000, loss: 0.079926
 >> iter 7000, loss: 0.032852
 >> iter 8000, loss: 0.015120
 >> iter 9000, loss: 0.008486
 >> iter 10000, loss: 0.005777
   Number of active neurons: 9
 >> iter 11000, loss: 0.004742
 >> iter 12000, loss: 0.004166
 >> iter 13000, loss: 0.003954
 >> iter 14000, loss: 0.003719
 >> iter 15000, loss: 0.003683
 >> iter 16000, loss: 0.003496
 >> iter 17000, loss: 0.003505
 >> iter 18000, loss: 0.003350
 >> iter 19000, loss: 0.003384
 >> iter 20000, loss: 0.003249
   Number of active neurons: 8
 >> iter 21000, loss: 0.003297
 >> iter 22000, loss: 0.003171
 >> iter 23000, loss: 0.003226
 >> iter 24000, loss: 0.003109
 >> iter 25000, loss: 0.003170
 >> iter 26000, loss: 0.003060
 >> iter 27000, loss: 0.003127
 >> iter 28000, loss: 0.003023
 >> iter 29000, loss: 0.003093
 >> iter 30000, loss: 0.002995
   Number of active neurons: 8
 >> iter 31000, loss: 0.003064
 >> iter 32000, loss: 0.002967
 >> iter 33000, loss: 0.003035
 >> iter 34000, loss: 0.002943
 >> iter 35000, loss: 0.003002
 >> iter 36000, loss: 0.002915
 >> iter 37000, loss: 0.002974
 >> iter 38000, loss: 0.002892
 >> iter 39000, loss: 0.002946
 >> iter 40000, loss: 0.002873
   Number of active neurons: 8
 >> iter 41000, loss: 0.002918
 >> iter 42000, loss: 0.002851
 >> iter 43000, loss: 0.002898
 >> iter 44000, loss: 0.002839
 >> iter 45000, loss: 0.002882
 >> iter 46000, loss: 0.002824
 >> iter 47000, loss: 0.002869
 >> iter 48000, loss: 0.002815
 >> iter 49000, loss: 0.002862
 >> iter 50000, loss: 0.002810
   Number of active neurons: 8
 >> iter 51000, loss: 0.002855
 >> iter 52000, loss: 0.002811
 >> iter 53000, loss: 0.002849
 >> iter 54000, loss: 0.002808
 >> iter 55000, loss: 0.002843
 >> iter 56000, loss: 0.002801
 >> iter 57000, loss: 0.002834
 >> iter 58000, loss: 0.002795
 >> iter 59000, loss: 0.002828
 >> iter 60000, loss: 0.002791
   Number of active neurons: 7
 >> iter 61000, loss: 0.002828
 >> iter 62000, loss: 0.002787
 >> iter 63000, loss: 0.002822
 >> iter 64000, loss: 0.002786
 >> iter 65000, loss: 0.002819
 >> iter 66000, loss: 0.002784
 >> iter 67000, loss: 0.002815
 >> iter 68000, loss: 0.002783
 >> iter 69000, loss: 0.002808
 >> iter 70000, loss: 0.002778
   Number of active neurons: 6
 >> iter 71000, loss: 0.002801
 >> iter 72000, loss: 0.002773
 >> iter 73000, loss: 0.002800
 >> iter 74000, loss: 0.002769
 >> iter 75000, loss: 0.002795
 >> iter 76000, loss: 0.002765
 >> iter 77000, loss: 0.002789
 >> iter 78000, loss: 0.002758
 >> iter 79000, loss: 0.002782
 >> iter 80000, loss: 0.002750
   Number of active neurons: 6
 >> iter 81000, loss: 0.002775
 >> iter 82000, loss: 0.002743
 >> iter 83000, loss: 0.002769
 >> iter 84000, loss: 0.002738
 >> iter 85000, loss: 0.002762
 >> iter 86000, loss: 0.002732
 >> iter 87000, loss: 0.002755
 >> iter 88000, loss: 0.002730
 >> iter 89000, loss: 0.002750
 >> iter 90000, loss: 0.002723
   Number of active neurons: 6
 >> iter 91000, loss: 0.002741
 >> iter 92000, loss: 0.002718
 >> iter 93000, loss: 0.002736
 >> iter 94000, loss: 0.002712
 >> iter 95000, loss: 0.002731
 >> iter 96000, loss: 0.002706
 >> iter 97000, loss: 0.002724
 >> iter 98000, loss: 0.002699
 >> iter 99000, loss: 0.002717
 >> iter 100000, loss: 0.002693
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.815731
 >> iter 2000, loss: 3.992956
 >> iter 3000, loss: 1.476275
 >> iter 4000, loss: 0.548342
 >> iter 5000, loss: 0.206145
 >> iter 6000, loss: 0.079517
 >> iter 7000, loss: 0.032629
 >> iter 8000, loss: 0.014977
 >> iter 9000, loss: 0.008353
 >> iter 10000, loss: 0.005658
   Number of active neurons: 8
 >> iter 11000, loss: 0.004612
 >> iter 12000, loss: 0.004039
 >> iter 13000, loss: 0.003811
 >> iter 14000, loss: 0.003581
 >> iter 15000, loss: 0.003530
 >> iter 16000, loss: 0.003357
 >> iter 17000, loss: 0.003347
 >> iter 18000, loss: 0.003202
 >> iter 19000, loss: 0.003214
 >> iter 20000, loss: 0.003089
   Number of active neurons: 7
 >> iter 21000, loss: 0.003112
 >> iter 22000, loss: 0.002999
 >> iter 23000, loss: 0.003028
 >> iter 24000, loss: 0.002924
 >> iter 25000, loss: 0.002959
 >> iter 26000, loss: 0.002862
 >> iter 27000, loss: 0.002901
 >> iter 28000, loss: 0.002809
 >> iter 29000, loss: 0.002847
 >> iter 30000, loss: 0.002765
   Number of active neurons: 7
 >> iter 31000, loss: 0.002800
 >> iter 32000, loss: 0.002725
 >> iter 33000, loss: 0.002760
 >> iter 34000, loss: 0.002696
 >> iter 35000, loss: 0.002726
 >> iter 36000, loss: 0.002668
 >> iter 37000, loss: 0.002700
 >> iter 38000, loss: 0.002647
 >> iter 39000, loss: 0.002678
 >> iter 40000, loss: 0.002635
   Number of active neurons: 7
 >> iter 41000, loss: 0.002667
 >> iter 42000, loss: 0.002625
 >> iter 43000, loss: 0.002660
 >> iter 44000, loss: 0.002624
 >> iter 45000, loss: 0.002659
 >> iter 46000, loss: 0.002621
 >> iter 47000, loss: 0.002657
 >> iter 48000, loss: 0.002618
 >> iter 49000, loss: 0.002655
 >> iter 50000, loss: 0.002615
   Number of active neurons: 7
 >> iter 51000, loss: 0.002653
 >> iter 52000, loss: 0.002616
 >> iter 53000, loss: 0.002649
 >> iter 54000, loss: 0.002616
 >> iter 55000, loss: 0.002649
 >> iter 56000, loss: 0.002614
 >> iter 57000, loss: 0.002645
 >> iter 58000, loss: 0.002610
 >> iter 59000, loss: 0.002640
 >> iter 60000, loss: 0.002604
   Number of active neurons: 7
 >> iter 61000, loss: 0.002634
 >> iter 62000, loss: 0.002592
 >> iter 63000, loss: 0.002620
 >> iter 64000, loss: 0.002582
 >> iter 65000, loss: 0.002609
 >> iter 66000, loss: 0.002573
 >> iter 67000, loss: 0.002598
 >> iter 68000, loss: 0.002564
 >> iter 69000, loss: 0.002585
 >> iter 70000, loss: 0.002553
   Number of active neurons: 7
 >> iter 71000, loss: 0.002571
 >> iter 72000, loss: 0.002542
 >> iter 73000, loss: 0.002562
 >> iter 74000, loss: 0.002532
 >> iter 75000, loss: 0.002552
 >> iter 76000, loss: 0.002523
 >> iter 77000, loss: 0.002542
 >> iter 78000, loss: 0.002514
 >> iter 79000, loss: 0.002534
 >> iter 80000, loss: 0.002506
   Number of active neurons: 7
 >> iter 81000, loss: 0.002527
 >> iter 82000, loss: 0.002500
 >> iter 83000, loss: 0.002523
 >> iter 84000, loss: 0.002495
 >> iter 85000, loss: 0.002517
 >> iter 86000, loss: 0.002490
 >> iter 87000, loss: 0.002512
 >> iter 88000, loss: 0.002490
 >> iter 89000, loss: 0.002509
 >> iter 90000, loss: 0.002487
   Number of active neurons: 7
 >> iter 91000, loss: 0.002504
 >> iter 92000, loss: 0.002486
 >> iter 93000, loss: 0.002504
 >> iter 94000, loss: 0.002483
 >> iter 95000, loss: 0.002503
 >> iter 96000, loss: 0.002481
 >> iter 97000, loss: 0.002500
 >> iter 98000, loss: 0.002478
 >> iter 99000, loss: 0.002499
 >> iter 100000, loss: 0.002478
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.778419
 >> iter 2000, loss: 3.979456
 >> iter 3000, loss: 1.471586
 >> iter 4000, loss: 0.546541
 >> iter 5000, loss: 0.205459
 >> iter 6000, loss: 0.079154
 >> iter 7000, loss: 0.032436
 >> iter 8000, loss: 0.014810
 >> iter 9000, loss: 0.008231
 >> iter 10000, loss: 0.005534
   Number of active neurons: 8
 >> iter 11000, loss: 0.004517
 >> iter 12000, loss: 0.003949
 >> iter 13000, loss: 0.003749
 >> iter 14000, loss: 0.003524
 >> iter 15000, loss: 0.003498
 >> iter 16000, loss: 0.003329
 >> iter 17000, loss: 0.003344
 >> iter 18000, loss: 0.003206
 >> iter 19000, loss: 0.003237
 >> iter 20000, loss: 0.003121
   Number of active neurons: 8
 >> iter 21000, loss: 0.003159
 >> iter 22000, loss: 0.003056
 >> iter 23000, loss: 0.003101
 >> iter 24000, loss: 0.003007
 >> iter 25000, loss: 0.003058
 >> iter 26000, loss: 0.002972
 >> iter 27000, loss: 0.003024
 >> iter 28000, loss: 0.002943
 >> iter 29000, loss: 0.002995
 >> iter 30000, loss: 0.002923
   Number of active neurons: 8
 >> iter 31000, loss: 0.002976
 >> iter 32000, loss: 0.002907
 >> iter 33000, loss: 0.002959
 >> iter 34000, loss: 0.002896
 >> iter 35000, loss: 0.002938
 >> iter 36000, loss: 0.002881
 >> iter 37000, loss: 0.002923
 >> iter 38000, loss: 0.002871
 >> iter 39000, loss: 0.002912
 >> iter 40000, loss: 0.002867
   Number of active neurons: 8
 >> iter 41000, loss: 0.002904
 >> iter 42000, loss: 0.002859
 >> iter 43000, loss: 0.002898
 >> iter 44000, loss: 0.002857
 >> iter 45000, loss: 0.002895
 >> iter 46000, loss: 0.002852
 >> iter 47000, loss: 0.002891
 >> iter 48000, loss: 0.002848
 >> iter 49000, loss: 0.002890
 >> iter 50000, loss: 0.002847
   Number of active neurons: 8
 >> iter 51000, loss: 0.002888
 >> iter 52000, loss: 0.002850
 >> iter 53000, loss: 0.002887
 >> iter 54000, loss: 0.002852
 >> iter 55000, loss: 0.002888
 >> iter 56000, loss: 0.002853
 >> iter 57000, loss: 0.002887
 >> iter 58000, loss: 0.002853
 >> iter 59000, loss: 0.002887
 >> iter 60000, loss: 0.002854
   Number of active neurons: 8
 >> iter 61000, loss: 0.002891
 >> iter 62000, loss: 0.002854
 >> iter 63000, loss: 0.002889
 >> iter 64000, loss: 0.002855
 >> iter 65000, loss: 0.002887
 >> iter 66000, loss: 0.002855
 >> iter 67000, loss: 0.002886
 >> iter 68000, loss: 0.002857
 >> iter 69000, loss: 0.002884
 >> iter 70000, loss: 0.002857
   Number of active neurons: 8
 >> iter 71000, loss: 0.002881
 >> iter 72000, loss: 0.002855
 >> iter 73000, loss: 0.002882
 >> iter 74000, loss: 0.002853
 >> iter 75000, loss: 0.002876
 >> iter 76000, loss: 0.002847
 >> iter 77000, loss: 0.002868
 >> iter 78000, loss: 0.002838
 >> iter 79000, loss: 0.002861
 >> iter 80000, loss: 0.002832
   Number of active neurons: 8
 >> iter 81000, loss: 0.002856
 >> iter 82000, loss: 0.002828
 >> iter 83000, loss: 0.002854
 >> iter 84000, loss: 0.002826
 >> iter 85000, loss: 0.002850
 >> iter 86000, loss: 0.002823
 >> iter 87000, loss: 0.002847
 >> iter 88000, loss: 0.002825
 >> iter 89000, loss: 0.002846
 >> iter 90000, loss: 0.002823
   Number of active neurons: 6
 >> iter 91000, loss: 0.002842
 >> iter 92000, loss: 0.002823
 >> iter 93000, loss: 0.002843
 >> iter 94000, loss: 0.002821
 >> iter 95000, loss: 0.002842
 >> iter 96000, loss: 0.002820
 >> iter 97000, loss: 0.002840
 >> iter 98000, loss: 0.002817
 >> iter 99000, loss: 0.002839
 >> iter 100000, loss: 0.002817
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.834637
 >> iter 2000, loss: 4.002156
 >> iter 3000, loss: 1.480855
 >> iter 4000, loss: 0.550397
 >> iter 5000, loss: 0.207282
 >> iter 6000, loss: 0.080033
 >> iter 7000, loss: 0.032975
 >> iter 8000, loss: 0.015109
 >> iter 9000, loss: 0.008455
 >> iter 10000, loss: 0.005646
   Number of active neurons: 8
 >> iter 11000, loss: 0.004603
 >> iter 12000, loss: 0.003961
 >> iter 13000, loss: 0.003755
 >> iter 14000, loss: 0.003473
 >> iter 15000, loss: 0.003454
 >> iter 16000, loss: 0.003230
 >> iter 17000, loss: 0.003260
 >> iter 18000, loss: 0.003079
 >> iter 19000, loss: 0.003130
 >> iter 20000, loss: 0.002981
   Number of active neurons: 6
 >> iter 21000, loss: 0.003043
 >> iter 22000, loss: 0.002913
 >> iter 23000, loss: 0.002981
 >> iter 24000, loss: 0.002868
 >> iter 25000, loss: 0.002940
 >> iter 26000, loss: 0.002837
 >> iter 27000, loss: 0.002908
 >> iter 28000, loss: 0.002815
 >> iter 29000, loss: 0.002885
 >> iter 30000, loss: 0.002803
   Number of active neurons: 6
 >> iter 31000, loss: 0.002870
 >> iter 32000, loss: 0.002793
 >> iter 33000, loss: 0.002856
 >> iter 34000, loss: 0.002786
 >> iter 35000, loss: 0.002839
 >> iter 36000, loss: 0.002775
 >> iter 37000, loss: 0.002824
 >> iter 38000, loss: 0.002766
 >> iter 39000, loss: 0.002813
 >> iter 40000, loss: 0.002764
   Number of active neurons: 6
 >> iter 41000, loss: 0.002806
 >> iter 42000, loss: 0.002759
 >> iter 43000, loss: 0.002801
 >> iter 44000, loss: 0.002759
 >> iter 45000, loss: 0.002799
 >> iter 46000, loss: 0.002755
 >> iter 47000, loss: 0.002795
 >> iter 48000, loss: 0.002751
 >> iter 49000, loss: 0.002791
 >> iter 50000, loss: 0.002746
   Number of active neurons: 6
 >> iter 51000, loss: 0.002783
 >> iter 52000, loss: 0.002742
 >> iter 53000, loss: 0.002775
 >> iter 54000, loss: 0.002737
 >> iter 55000, loss: 0.002768
 >> iter 56000, loss: 0.002729
 >> iter 57000, loss: 0.002757
 >> iter 58000, loss: 0.002718
 >> iter 59000, loss: 0.002745
 >> iter 60000, loss: 0.002707
   Number of active neurons: 6
 >> iter 61000, loss: 0.002736
 >> iter 62000, loss: 0.002694
 >> iter 63000, loss: 0.002720
 >> iter 64000, loss: 0.002681
 >> iter 65000, loss: 0.002704
 >> iter 66000, loss: 0.002667
 >> iter 67000, loss: 0.002689
 >> iter 68000, loss: 0.002655
 >> iter 69000, loss: 0.002673
 >> iter 70000, loss: 0.002640
   Number of active neurons: 5
 >> iter 71000, loss: 0.002652
 >> iter 72000, loss: 0.002620
 >> iter 73000, loss: 0.002635
 >> iter 74000, loss: 0.002602
 >> iter 75000, loss: 0.002617
 >> iter 76000, loss: 0.002587
 >> iter 77000, loss: 0.002601
 >> iter 78000, loss: 0.002572
 >> iter 79000, loss: 0.002587
 >> iter 80000, loss: 0.002557
   Number of active neurons: 5
 >> iter 81000, loss: 0.002573
 >> iter 82000, loss: 0.002545
 >> iter 83000, loss: 0.002563
 >> iter 84000, loss: 0.002534
 >> iter 85000, loss: 0.002551
 >> iter 86000, loss: 0.002523
 >> iter 87000, loss: 0.002540
 >> iter 88000, loss: 0.002518
 >> iter 89000, loss: 0.002532
 >> iter 90000, loss: 0.002508
   Number of active neurons: 5
 >> iter 91000, loss: 0.002522
 >> iter 92000, loss: 0.002502
 >> iter 93000, loss: 0.002516
 >> iter 94000, loss: 0.002494
 >> iter 95000, loss: 0.002509
 >> iter 96000, loss: 0.002486
 >> iter 97000, loss: 0.002501
 >> iter 98000, loss: 0.002478
 >> iter 99000, loss: 0.002494
 >> iter 100000, loss: 0.002473
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.811372
 >> iter 2000, loss: 3.991537
 >> iter 3000, loss: 1.475950
 >> iter 4000, loss: 0.548305
 >> iter 5000, loss: 0.206242
 >> iter 6000, loss: 0.079614
 >> iter 7000, loss: 0.032747
 >> iter 8000, loss: 0.015074
 >> iter 9000, loss: 0.008459
 >> iter 10000, loss: 0.005751
   Number of active neurons: 7
 >> iter 11000, loss: 0.004716
 >> iter 12000, loss: 0.004131
 >> iter 13000, loss: 0.003916
 >> iter 14000, loss: 0.003676
 >> iter 15000, loss: 0.003624
 >> iter 16000, loss: 0.003447
 >> iter 17000, loss: 0.003433
 >> iter 18000, loss: 0.003285
 >> iter 19000, loss: 0.003291
 >> iter 20000, loss: 0.003160
   Number of active neurons: 7
 >> iter 21000, loss: 0.003176
 >> iter 22000, loss: 0.003060
 >> iter 23000, loss: 0.003082
 >> iter 24000, loss: 0.002976
 >> iter 25000, loss: 0.003004
 >> iter 26000, loss: 0.002908
 >> iter 27000, loss: 0.002946
 >> iter 28000, loss: 0.002857
 >> iter 29000, loss: 0.002899
 >> iter 30000, loss: 0.002817
   Number of active neurons: 7
 >> iter 31000, loss: 0.002861
 >> iter 32000, loss: 0.002782
 >> iter 33000, loss: 0.002825
 >> iter 34000, loss: 0.002753
 >> iter 35000, loss: 0.002790
 >> iter 36000, loss: 0.002722
 >> iter 37000, loss: 0.002758
 >> iter 38000, loss: 0.002692
 >> iter 39000, loss: 0.002726
 >> iter 40000, loss: 0.002667
   Number of active neurons: 7
 >> iter 41000, loss: 0.002695
 >> iter 42000, loss: 0.002638
 >> iter 43000, loss: 0.002668
 >> iter 44000, loss: 0.002618
 >> iter 45000, loss: 0.002649
 >> iter 46000, loss: 0.002600
 >> iter 47000, loss: 0.002631
 >> iter 48000, loss: 0.002583
 >> iter 49000, loss: 0.002613
 >> iter 50000, loss: 0.002564
   Number of active neurons: 6
 >> iter 51000, loss: 0.002593
 >> iter 52000, loss: 0.002551
 >> iter 53000, loss: 0.002577
 >> iter 54000, loss: 0.002542
 >> iter 55000, loss: 0.002569
 >> iter 56000, loss: 0.002535
 >> iter 57000, loss: 0.002561
 >> iter 58000, loss: 0.002529
 >> iter 59000, loss: 0.002556
 >> iter 60000, loss: 0.002526
   Number of active neurons: 6
 >> iter 61000, loss: 0.002551
 >> iter 62000, loss: 0.002516
 >> iter 63000, loss: 0.002540
 >> iter 64000, loss: 0.002509
 >> iter 65000, loss: 0.002532
 >> iter 66000, loss: 0.002504
 >> iter 67000, loss: 0.002527
 >> iter 68000, loss: 0.002502
 >> iter 69000, loss: 0.002521
 >> iter 70000, loss: 0.002499
   Number of active neurons: 6
 >> iter 71000, loss: 0.002516
 >> iter 72000, loss: 0.002495
 >> iter 73000, loss: 0.002515
 >> iter 74000, loss: 0.002492
 >> iter 75000, loss: 0.002512
 >> iter 76000, loss: 0.002490
 >> iter 77000, loss: 0.002508
 >> iter 78000, loss: 0.002486
 >> iter 79000, loss: 0.002505
 >> iter 80000, loss: 0.002482
   Number of active neurons: 6
 >> iter 81000, loss: 0.002501
 >> iter 82000, loss: 0.002478
 >> iter 83000, loss: 0.002498
 >> iter 84000, loss: 0.002475
 >> iter 85000, loss: 0.002493
 >> iter 86000, loss: 0.002471
 >> iter 87000, loss: 0.002488
 >> iter 88000, loss: 0.002470
 >> iter 89000, loss: 0.002485
 >> iter 90000, loss: 0.002466
   Number of active neurons: 6
 >> iter 91000, loss: 0.002480
 >> iter 92000, loss: 0.002463
 >> iter 93000, loss: 0.002476
 >> iter 94000, loss: 0.002457
 >> iter 95000, loss: 0.002471
 >> iter 96000, loss: 0.002451
 >> iter 97000, loss: 0.002465
 >> iter 98000, loss: 0.002445
 >> iter 99000, loss: 0.002459
 >> iter 100000, loss: 0.002441
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.876573
 >> iter 2000, loss: 4.014900
 >> iter 3000, loss: 1.483879
 >> iter 4000, loss: 0.550969
 >> iter 5000, loss: 0.206984
 >> iter 6000, loss: 0.079803
 >> iter 7000, loss: 0.032709
 >> iter 8000, loss: 0.015030
 >> iter 9000, loss: 0.008391
 >> iter 10000, loss: 0.005728
   Number of active neurons: 9
 >> iter 11000, loss: 0.004694
 >> iter 12000, loss: 0.004158
 >> iter 13000, loss: 0.003944
 >> iter 14000, loss: 0.003739
 >> iter 15000, loss: 0.003685
 >> iter 16000, loss: 0.003533
 >> iter 17000, loss: 0.003516
 >> iter 18000, loss: 0.003386
 >> iter 19000, loss: 0.003389
 >> iter 20000, loss: 0.003272
   Number of active neurons: 8
 >> iter 21000, loss: 0.003286
 >> iter 22000, loss: 0.003177
 >> iter 23000, loss: 0.003199
 >> iter 24000, loss: 0.003095
 >> iter 25000, loss: 0.003130
 >> iter 26000, loss: 0.003032
 >> iter 27000, loss: 0.003078
 >> iter 28000, loss: 0.002983
 >> iter 29000, loss: 0.003037
 >> iter 30000, loss: 0.002948
   Number of active neurons: 8
 >> iter 31000, loss: 0.003001
 >> iter 32000, loss: 0.002911
 >> iter 33000, loss: 0.002961
 >> iter 34000, loss: 0.002877
 >> iter 35000, loss: 0.002925
 >> iter 36000, loss: 0.002848
 >> iter 37000, loss: 0.002899
 >> iter 38000, loss: 0.002828
 >> iter 39000, loss: 0.002878
 >> iter 40000, loss: 0.002815
   Number of active neurons: 8
 >> iter 41000, loss: 0.002859
 >> iter 42000, loss: 0.002796
 >> iter 43000, loss: 0.002841
 >> iter 44000, loss: 0.002784
 >> iter 45000, loss: 0.002828
 >> iter 46000, loss: 0.002772
 >> iter 47000, loss: 0.002818
 >> iter 48000, loss: 0.002763
 >> iter 49000, loss: 0.002810
 >> iter 50000, loss: 0.002753
   Number of active neurons: 7
 >> iter 51000, loss: 0.002796
 >> iter 52000, loss: 0.002745
 >> iter 53000, loss: 0.002783
 >> iter 54000, loss: 0.002737
 >> iter 55000, loss: 0.002774
 >> iter 56000, loss: 0.002726
 >> iter 57000, loss: 0.002760
 >> iter 58000, loss: 0.002714
 >> iter 59000, loss: 0.002746
 >> iter 60000, loss: 0.002701
   Number of active neurons: 6
 >> iter 61000, loss: 0.002735
 >> iter 62000, loss: 0.002687
 >> iter 63000, loss: 0.002718
 >> iter 64000, loss: 0.002676
 >> iter 65000, loss: 0.002707
 >> iter 66000, loss: 0.002668
 >> iter 67000, loss: 0.002697
 >> iter 68000, loss: 0.002663
 >> iter 69000, loss: 0.002686
 >> iter 70000, loss: 0.002654
   Number of active neurons: 6
 >> iter 71000, loss: 0.002672
 >> iter 72000, loss: 0.002641
 >> iter 73000, loss: 0.002661
 >> iter 74000, loss: 0.002630
 >> iter 75000, loss: 0.002649
 >> iter 76000, loss: 0.002621
 >> iter 77000, loss: 0.002640
 >> iter 78000, loss: 0.002613
 >> iter 79000, loss: 0.002633
 >> iter 80000, loss: 0.002606
   Number of active neurons: 6
 >> iter 81000, loss: 0.002627
 >> iter 82000, loss: 0.002601
 >> iter 83000, loss: 0.002623
 >> iter 84000, loss: 0.002596
 >> iter 85000, loss: 0.002616
 >> iter 86000, loss: 0.002589
 >> iter 87000, loss: 0.002609
 >> iter 88000, loss: 0.002588
 >> iter 89000, loss: 0.002604
 >> iter 90000, loss: 0.002583
   Number of active neurons: 6
 >> iter 91000, loss: 0.002598
 >> iter 92000, loss: 0.002580
 >> iter 93000, loss: 0.002596
 >> iter 94000, loss: 0.002575
 >> iter 95000, loss: 0.002592
 >> iter 96000, loss: 0.002570
 >> iter 97000, loss: 0.002586
 >> iter 98000, loss: 0.002564
 >> iter 99000, loss: 0.002580
 >> iter 100000, loss: 0.002558
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.846489
 >> iter 2000, loss: 4.004890
 >> iter 3000, loss: 1.481017
 >> iter 4000, loss: 0.550268
 >> iter 5000, loss: 0.207053
 >> iter 6000, loss: 0.079971
 >> iter 7000, loss: 0.032925
 >> iter 8000, loss: 0.015167
 >> iter 9000, loss: 0.008506
 >> iter 10000, loss: 0.005761
   Number of active neurons: 7
 >> iter 11000, loss: 0.004697
 >> iter 12000, loss: 0.004092
 >> iter 13000, loss: 0.003855
 >> iter 14000, loss: 0.003599
 >> iter 15000, loss: 0.003525
 >> iter 16000, loss: 0.003341
 >> iter 17000, loss: 0.003309
 >> iter 18000, loss: 0.003160
 >> iter 19000, loss: 0.003151
 >> iter 20000, loss: 0.003027
   Number of active neurons: 7
 >> iter 21000, loss: 0.003029
 >> iter 22000, loss: 0.002919
 >> iter 23000, loss: 0.002930
 >> iter 24000, loss: 0.002829
 >> iter 25000, loss: 0.002848
 >> iter 26000, loss: 0.002753
 >> iter 27000, loss: 0.002777
 >> iter 28000, loss: 0.002690
 >> iter 29000, loss: 0.002718
 >> iter 30000, loss: 0.002639
   Number of active neurons: 7
 >> iter 31000, loss: 0.002670
 >> iter 32000, loss: 0.002598
 >> iter 33000, loss: 0.002632
 >> iter 34000, loss: 0.002570
 >> iter 35000, loss: 0.002603
 >> iter 36000, loss: 0.002548
 >> iter 37000, loss: 0.002583
 >> iter 38000, loss: 0.002531
 >> iter 39000, loss: 0.002566
 >> iter 40000, loss: 0.002519
   Number of active neurons: 6
 >> iter 41000, loss: 0.002552
 >> iter 42000, loss: 0.002507
 >> iter 43000, loss: 0.002542
 >> iter 44000, loss: 0.002502
 >> iter 45000, loss: 0.002536
 >> iter 46000, loss: 0.002493
 >> iter 47000, loss: 0.002526
 >> iter 48000, loss: 0.002483
 >> iter 49000, loss: 0.002517
 >> iter 50000, loss: 0.002474
   Number of active neurons: 5
 >> iter 51000, loss: 0.002506
 >> iter 52000, loss: 0.002469
 >> iter 53000, loss: 0.002497
 >> iter 54000, loss: 0.002465
 >> iter 55000, loss: 0.002492
 >> iter 56000, loss: 0.002461
 >> iter 57000, loss: 0.002484
 >> iter 58000, loss: 0.002452
 >> iter 59000, loss: 0.002473
 >> iter 60000, loss: 0.002442
   Number of active neurons: 5
 >> iter 61000, loss: 0.002466
 >> iter 62000, loss: 0.002433
 >> iter 63000, loss: 0.002456
 >> iter 64000, loss: 0.002426
 >> iter 65000, loss: 0.002447
 >> iter 66000, loss: 0.002420
 >> iter 67000, loss: 0.002440
 >> iter 68000, loss: 0.002415
 >> iter 69000, loss: 0.002431
 >> iter 70000, loss: 0.002409
   Number of active neurons: 5
 >> iter 71000, loss: 0.002424
 >> iter 72000, loss: 0.002402
 >> iter 73000, loss: 0.002419
 >> iter 74000, loss: 0.002396
 >> iter 75000, loss: 0.002412
 >> iter 76000, loss: 0.002389
 >> iter 77000, loss: 0.002404
 >> iter 78000, loss: 0.002381
 >> iter 79000, loss: 0.002398
 >> iter 80000, loss: 0.002374
   Number of active neurons: 5
 >> iter 81000, loss: 0.002391
 >> iter 82000, loss: 0.002368
 >> iter 83000, loss: 0.002386
 >> iter 84000, loss: 0.002363
 >> iter 85000, loss: 0.002380
 >> iter 86000, loss: 0.002358
 >> iter 87000, loss: 0.002375
 >> iter 88000, loss: 0.002357
 >> iter 89000, loss: 0.002372
 >> iter 90000, loss: 0.002353
   Number of active neurons: 5
 >> iter 91000, loss: 0.002367
 >> iter 92000, loss: 0.002352
 >> iter 93000, loss: 0.002366
 >> iter 94000, loss: 0.002349
 >> iter 95000, loss: 0.002365
 >> iter 96000, loss: 0.002347
 >> iter 97000, loss: 0.002363
 >> iter 98000, loss: 0.002345
 >> iter 99000, loss: 0.002361
 >> iter 100000, loss: 0.002345
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.971605
 >> iter 2000, loss: 4.056830
 >> iter 3000, loss: 1.499828
 >> iter 4000, loss: 0.557267
 >> iter 5000, loss: 0.209553
 >> iter 6000, loss: 0.080997
 >> iter 7000, loss: 0.033341
 >> iter 8000, loss: 0.015465
 >> iter 9000, loss: 0.008715
 >> iter 10000, loss: 0.006015
   Number of active neurons: 9
 >> iter 11000, loss: 0.004936
 >> iter 12000, loss: 0.004384
 >> iter 13000, loss: 0.004140
 >> iter 14000, loss: 0.003924
 >> iter 15000, loss: 0.003851
 >> iter 16000, loss: 0.003692
 >> iter 17000, loss: 0.003666
 >> iter 18000, loss: 0.003534
 >> iter 19000, loss: 0.003533
 >> iter 20000, loss: 0.003413
   Number of active neurons: 9
 >> iter 21000, loss: 0.003420
 >> iter 22000, loss: 0.003310
 >> iter 23000, loss: 0.003324
 >> iter 24000, loss: 0.003222
 >> iter 25000, loss: 0.003244
 >> iter 26000, loss: 0.003147
 >> iter 27000, loss: 0.003176
 >> iter 28000, loss: 0.003085
 >> iter 29000, loss: 0.003119
 >> iter 30000, loss: 0.003034
   Number of active neurons: 9
 >> iter 31000, loss: 0.003069
 >> iter 32000, loss: 0.002985
 >> iter 33000, loss: 0.003023
 >> iter 34000, loss: 0.002945
 >> iter 35000, loss: 0.002980
 >> iter 36000, loss: 0.002903
 >> iter 37000, loss: 0.002937
 >> iter 38000, loss: 0.002866
 >> iter 39000, loss: 0.002906
 >> iter 40000, loss: 0.002848
   Number of active neurons: 9
 >> iter 41000, loss: 0.002886
 >> iter 42000, loss: 0.002830
 >> iter 43000, loss: 0.002871
 >> iter 44000, loss: 0.002823
 >> iter 45000, loss: 0.002863
 >> iter 46000, loss: 0.002814
 >> iter 47000, loss: 0.002859
 >> iter 48000, loss: 0.002812
 >> iter 49000, loss: 0.002860
 >> iter 50000, loss: 0.002813
   Number of active neurons: 9
 >> iter 51000, loss: 0.002862
 >> iter 52000, loss: 0.002820
 >> iter 53000, loss: 0.002864
 >> iter 54000, loss: 0.002827
 >> iter 55000, loss: 0.002868
 >> iter 56000, loss: 0.002825
 >> iter 57000, loss: 0.002861
 >> iter 58000, loss: 0.002819
 >> iter 59000, loss: 0.002857
 >> iter 60000, loss: 0.002817
   Number of active neurons: 9
 >> iter 61000, loss: 0.002859
 >> iter 62000, loss: 0.002815
 >> iter 63000, loss: 0.002855
 >> iter 64000, loss: 0.002815
 >> iter 65000, loss: 0.002854
 >> iter 66000, loss: 0.002816
 >> iter 67000, loss: 0.002853
 >> iter 68000, loss: 0.002819
 >> iter 69000, loss: 0.002851
 >> iter 70000, loss: 0.002819
   Number of active neurons: 9
 >> iter 71000, loss: 0.002849
 >> iter 72000, loss: 0.002817
 >> iter 73000, loss: 0.002850
 >> iter 74000, loss: 0.002816
 >> iter 75000, loss: 0.002848
 >> iter 76000, loss: 0.002815
 >> iter 77000, loss: 0.002846
 >> iter 78000, loss: 0.002812
 >> iter 79000, loss: 0.002843
 >> iter 80000, loss: 0.002808
   Number of active neurons: 9
 >> iter 81000, loss: 0.002840
 >> iter 82000, loss: 0.002805
 >> iter 83000, loss: 0.002837
 >> iter 84000, loss: 0.002801
 >> iter 85000, loss: 0.002831
 >> iter 86000, loss: 0.002795
 >> iter 87000, loss: 0.002825
 >> iter 88000, loss: 0.002793
 >> iter 89000, loss: 0.002817
 >> iter 90000, loss: 0.002784
   Number of active neurons: 9
 >> iter 91000, loss: 0.002806
 >> iter 92000, loss: 0.002776
 >> iter 93000, loss: 0.002798
 >> iter 94000, loss: 0.002768
 >> iter 95000, loss: 0.002791
 >> iter 96000, loss: 0.002761
 >> iter 97000, loss: 0.002784
 >> iter 98000, loss: 0.002753
 >> iter 99000, loss: 0.002778
 >> iter 100000, loss: 0.002749
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.840947
 >> iter 2000, loss: 4.005848
 >> iter 3000, loss: 1.482776
 >> iter 4000, loss: 0.551710
 >> iter 5000, loss: 0.208195
 >> iter 6000, loss: 0.080849
 >> iter 7000, loss: 0.033705
 >> iter 8000, loss: 0.015817
 >> iter 9000, loss: 0.009133
 >> iter 10000, loss: 0.006306
   Number of active neurons: 9
 >> iter 11000, loss: 0.005249
 >> iter 12000, loss: 0.004577
 >> iter 13000, loss: 0.004349
 >> iter 14000, loss: 0.004032
 >> iter 15000, loss: 0.003979
 >> iter 16000, loss: 0.003729
 >> iter 17000, loss: 0.003721
 >> iter 18000, loss: 0.003517
 >> iter 19000, loss: 0.003532
 >> iter 20000, loss: 0.003362
   Number of active neurons: 8
 >> iter 21000, loss: 0.003388
 >> iter 22000, loss: 0.003232
 >> iter 23000, loss: 0.003270
 >> iter 24000, loss: 0.003127
 >> iter 25000, loss: 0.003174
 >> iter 26000, loss: 0.003044
 >> iter 27000, loss: 0.003098
 >> iter 28000, loss: 0.002978
 >> iter 29000, loss: 0.003038
 >> iter 30000, loss: 0.002931
   Number of active neurons: 8
 >> iter 31000, loss: 0.002996
 >> iter 32000, loss: 0.002897
 >> iter 33000, loss: 0.002966
 >> iter 34000, loss: 0.002877
 >> iter 35000, loss: 0.002943
 >> iter 36000, loss: 0.002859
 >> iter 37000, loss: 0.002925
 >> iter 38000, loss: 0.002844
 >> iter 39000, loss: 0.002909
 >> iter 40000, loss: 0.002837
   Number of active neurons: 8
 >> iter 41000, loss: 0.002898
 >> iter 42000, loss: 0.002825
 >> iter 43000, loss: 0.002885
 >> iter 44000, loss: 0.002819
 >> iter 45000, loss: 0.002877
 >> iter 46000, loss: 0.002810
 >> iter 47000, loss: 0.002866
 >> iter 48000, loss: 0.002800
 >> iter 49000, loss: 0.002854
 >> iter 50000, loss: 0.002791
   Number of active neurons: 8
 >> iter 51000, loss: 0.002845
 >> iter 52000, loss: 0.002789
 >> iter 53000, loss: 0.002838
 >> iter 54000, loss: 0.002789
 >> iter 55000, loss: 0.002834
 >> iter 56000, loss: 0.002786
 >> iter 57000, loss: 0.002829
 >> iter 58000, loss: 0.002785
 >> iter 59000, loss: 0.002828
 >> iter 60000, loss: 0.002787
   Number of active neurons: 8
 >> iter 61000, loss: 0.002832
 >> iter 62000, loss: 0.002787
 >> iter 63000, loss: 0.002829
 >> iter 64000, loss: 0.002788
 >> iter 65000, loss: 0.002827
 >> iter 66000, loss: 0.002787
 >> iter 67000, loss: 0.002823
 >> iter 68000, loss: 0.002786
 >> iter 69000, loss: 0.002816
 >> iter 70000, loss: 0.002781
   Number of active neurons: 8
 >> iter 71000, loss: 0.002809
 >> iter 72000, loss: 0.002775
 >> iter 73000, loss: 0.002805
 >> iter 74000, loss: 0.002769
 >> iter 75000, loss: 0.002795
 >> iter 76000, loss: 0.002760
 >> iter 77000, loss: 0.002785
 >> iter 78000, loss: 0.002750
 >> iter 79000, loss: 0.002775
 >> iter 80000, loss: 0.002741
   Number of active neurons: 7
 >> iter 81000, loss: 0.002766
 >> iter 82000, loss: 0.002734
 >> iter 83000, loss: 0.002760
 >> iter 84000, loss: 0.002728
 >> iter 85000, loss: 0.002753
 >> iter 86000, loss: 0.002722
 >> iter 87000, loss: 0.002746
 >> iter 88000, loss: 0.002720
 >> iter 89000, loss: 0.002741
 >> iter 90000, loss: 0.002714
   Number of active neurons: 5
 >> iter 91000, loss: 0.002732
 >> iter 92000, loss: 0.002708
 >> iter 93000, loss: 0.002724
 >> iter 94000, loss: 0.002699
 >> iter 95000, loss: 0.002716
 >> iter 96000, loss: 0.002690
 >> iter 97000, loss: 0.002707
 >> iter 98000, loss: 0.002682
 >> iter 99000, loss: 0.002700
 >> iter 100000, loss: 0.002677
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.875267
 >> iter 2000, loss: 4.015743
 >> iter 3000, loss: 1.484925
 >> iter 4000, loss: 0.551638
 >> iter 5000, loss: 0.207547
 >> iter 6000, loss: 0.080167
 >> iter 7000, loss: 0.033062
 >> iter 8000, loss: 0.015290
 >> iter 9000, loss: 0.008671
 >> iter 10000, loss: 0.005942
   Number of active neurons: 10
 >> iter 11000, loss: 0.004928
 >> iter 12000, loss: 0.004329
 >> iter 13000, loss: 0.004134
 >> iter 14000, loss: 0.003868
 >> iter 15000, loss: 0.003855
 >> iter 16000, loss: 0.003617
 >> iter 17000, loss: 0.003637
 >> iter 18000, loss: 0.003435
 >> iter 19000, loss: 0.003470
 >> iter 20000, loss: 0.003287
   Number of active neurons: 10
 >> iter 21000, loss: 0.003333
 >> iter 22000, loss: 0.003173
 >> iter 23000, loss: 0.003227
 >> iter 24000, loss: 0.003083
 >> iter 25000, loss: 0.003143
 >> iter 26000, loss: 0.003011
 >> iter 27000, loss: 0.003073
 >> iter 28000, loss: 0.002951
 >> iter 29000, loss: 0.003013
 >> iter 30000, loss: 0.002905
   Number of active neurons: 9
 >> iter 31000, loss: 0.002973
 >> iter 32000, loss: 0.002874
 >> iter 33000, loss: 0.002946
 >> iter 34000, loss: 0.002857
 >> iter 35000, loss: 0.002923
 >> iter 36000, loss: 0.002840
 >> iter 37000, loss: 0.002901
 >> iter 38000, loss: 0.002821
 >> iter 39000, loss: 0.002879
 >> iter 40000, loss: 0.002813
   Number of active neurons: 9
 >> iter 41000, loss: 0.002867
 >> iter 42000, loss: 0.002806
 >> iter 43000, loss: 0.002861
 >> iter 44000, loss: 0.002808
 >> iter 45000, loss: 0.002860
 >> iter 46000, loss: 0.002806
 >> iter 47000, loss: 0.002858
 >> iter 48000, loss: 0.002806
 >> iter 49000, loss: 0.002858
 >> iter 50000, loss: 0.002804
   Number of active neurons: 8
 >> iter 51000, loss: 0.002855
 >> iter 52000, loss: 0.002807
 >> iter 53000, loss: 0.002851
 >> iter 54000, loss: 0.002808
 >> iter 55000, loss: 0.002850
 >> iter 56000, loss: 0.002808
 >> iter 57000, loss: 0.002848
 >> iter 58000, loss: 0.002807
 >> iter 59000, loss: 0.002846
 >> iter 60000, loss: 0.002806
   Number of active neurons: 8
 >> iter 61000, loss: 0.002847
 >> iter 62000, loss: 0.002803
 >> iter 63000, loss: 0.002840
 >> iter 64000, loss: 0.002801
 >> iter 65000, loss: 0.002833
 >> iter 66000, loss: 0.002794
 >> iter 67000, loss: 0.002822
 >> iter 68000, loss: 0.002785
 >> iter 69000, loss: 0.002804
 >> iter 70000, loss: 0.002770
   Number of active neurons: 8
 >> iter 71000, loss: 0.002787
 >> iter 72000, loss: 0.002754
 >> iter 73000, loss: 0.002775
 >> iter 74000, loss: 0.002742
 >> iter 75000, loss: 0.002761
 >> iter 76000, loss: 0.002732
 >> iter 77000, loss: 0.002750
 >> iter 78000, loss: 0.002721
 >> iter 79000, loss: 0.002740
 >> iter 80000, loss: 0.002709
   Number of active neurons: 8
 >> iter 81000, loss: 0.002729
 >> iter 82000, loss: 0.002700
 >> iter 83000, loss: 0.002721
 >> iter 84000, loss: 0.002691
 >> iter 85000, loss: 0.002711
 >> iter 86000, loss: 0.002682
 >> iter 87000, loss: 0.002702
 >> iter 88000, loss: 0.002678
 >> iter 89000, loss: 0.002694
 >> iter 90000, loss: 0.002668
   Number of active neurons: 8
 >> iter 91000, loss: 0.002683
 >> iter 92000, loss: 0.002660
 >> iter 93000, loss: 0.002675
 >> iter 94000, loss: 0.002650
 >> iter 95000, loss: 0.002667
 >> iter 96000, loss: 0.002641
 >> iter 97000, loss: 0.002657
 >> iter 98000, loss: 0.002631
 >> iter 99000, loss: 0.002649
 >> iter 100000, loss: 0.002624
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

