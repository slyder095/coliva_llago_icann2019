 > Problema: tomita3nueva
 > Args:
   - Hidden size: 2
   - Noise level: 0.0
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.173787
 >> iter 2000, loss: 14.737914
 >> iter 3000, loss: 12.167949
 >> iter 4000, loss: 11.007558
 >> iter 5000, loss: 10.701159
 >> iter 6000, loss: 10.408583
 >> iter 7000, loss: 10.430037
 >> iter 8000, loss: 10.279096
 >> iter 9000, loss: 10.365930
 >> iter 10000, loss: 10.232824
   Number of active neurons: 2
 >> iter 11000, loss: 10.453256
 >> iter 12000, loss: 10.245502
 >> iter 13000, loss: 10.382927
 >> iter 14000, loss: 10.163259
 >> iter 15000, loss: 10.123104
 >> iter 16000, loss: 10.108106
 >> iter 17000, loss: 10.252457
 >> iter 18000, loss: 10.110556
 >> iter 19000, loss: 10.348647
 >> iter 20000, loss: 10.085656
   Number of active neurons: 2
 >> iter 21000, loss: 10.258159
 >> iter 22000, loss: 10.173716
 >> iter 23000, loss: 10.383378
 >> iter 24000, loss: 10.145610
 >> iter 25000, loss: 10.362802
 >> iter 26000, loss: 10.186100
 >> iter 27000, loss: 10.338145
 >> iter 28000, loss: 10.194701
 >> iter 29000, loss: 10.294118
 >> iter 30000, loss: 10.037688
   Number of active neurons: 2
 >> iter 31000, loss: 10.226369
 >> iter 32000, loss: 10.130226
 >> iter 33000, loss: 10.234137
 >> iter 34000, loss: 10.075695
 >> iter 35000, loss: 10.301475
 >> iter 36000, loss: 10.161094
 >> iter 37000, loss: 10.394355
 >> iter 38000, loss: 10.182563
 >> iter 39000, loss: 10.400849
 >> iter 40000, loss: 10.177142
   Number of active neurons: 2
 >> iter 41000, loss: 10.350805
 >> iter 42000, loss: 10.117420
 >> iter 43000, loss: 10.217363
 >> iter 44000, loss: 10.176360
 >> iter 45000, loss: 10.258514
 >> iter 46000, loss: 10.079528
 >> iter 47000, loss: 10.234205
 >> iter 48000, loss: 10.169600
 >> iter 49000, loss: 10.357956
 >> iter 50000, loss: 10.186245
   Number of active neurons: 2
 >> iter 51000, loss: 10.303875
 >> iter 52000, loss: 10.057001
 >> iter 53000, loss: 10.279033
 >> iter 54000, loss: 10.099010
 >> iter 55000, loss: 10.309473
 >> iter 56000, loss: 10.128809
 >> iter 57000, loss: 10.284475
 >> iter 58000, loss: 10.112037
 >> iter 59000, loss: 10.247710
 >> iter 60000, loss: 10.181741
   Number of active neurons: 2
 >> iter 61000, loss: 10.237903
 >> iter 62000, loss: 10.108662
 >> iter 63000, loss: 10.098096
 >> iter 64000, loss: 10.115612
 >> iter 65000, loss: 10.392733
 >> iter 66000, loss: 10.234805
 >> iter 67000, loss: 10.228373
 >> iter 68000, loss: 10.105515
 >> iter 69000, loss: 10.241344
 >> iter 70000, loss: 10.108290
   Number of active neurons: 2
 >> iter 71000, loss: 10.335944
 >> iter 72000, loss: 10.016783
 >> iter 73000, loss: 10.236939
 >> iter 74000, loss: 10.040856
 >> iter 75000, loss: 10.289031
 >> iter 76000, loss: 10.059835
 >> iter 77000, loss: 10.293791
 >> iter 78000, loss: 10.095767
 >> iter 79000, loss: 10.191962
 >> iter 80000, loss: 9.979749
   Number of active neurons: 2
 >> iter 81000, loss: 10.245048
 >> iter 82000, loss: 10.000446
 >> iter 83000, loss: 10.104635
 >> iter 84000, loss: 9.950797
 >> iter 85000, loss: 10.174042
 >> iter 86000, loss: 10.118827
 >> iter 87000, loss: 10.321299
 >> iter 88000, loss: 10.134086
 >> iter 89000, loss: 10.211783
 >> iter 90000, loss: 9.994704
   Number of active neurons: 2
 >> iter 91000, loss: 10.246264
 >> iter 92000, loss: 10.070526
 >> iter 93000, loss: 10.216096
 >> iter 94000, loss: 10.052240
 >> iter 95000, loss: 10.353255
 >> iter 96000, loss: 10.114606
 >> iter 97000, loss: 10.209199
 >> iter 98000, loss: 10.021836
 >> iter 99000, loss: 10.265313
 >> iter 100000, loss: 9.970520
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 17.6836463271
   - Test - Long: 3.64481775911
   - Test - Big: 17.7228227718
   - Test - A: 62.7824811679
   - Test - B: 21.8585427638
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.177940
 >> iter 2000, loss: 14.667070
 >> iter 3000, loss: 12.678458
 >> iter 4000, loss: 11.748411
 >> iter 5000, loss: 11.561546
 >> iter 6000, loss: 11.232395
 >> iter 7000, loss: 11.390803
 >> iter 8000, loss: 11.172304
 >> iter 9000, loss: 11.292812
 >> iter 10000, loss: 11.140529
   Number of active neurons: 2
 >> iter 11000, loss: 11.233899
 >> iter 12000, loss: 11.195244
 >> iter 13000, loss: 11.359816
 >> iter 14000, loss: 11.063591
 >> iter 15000, loss: 11.331500
 >> iter 16000, loss: 11.153029
 >> iter 17000, loss: 11.252790
 >> iter 18000, loss: 11.053129
 >> iter 19000, loss: 11.258844
 >> iter 20000, loss: 11.036909
   Number of active neurons: 2
 >> iter 21000, loss: 11.224504
 >> iter 22000, loss: 10.993200
 >> iter 23000, loss: 11.241769
 >> iter 24000, loss: 11.001771
 >> iter 25000, loss: 11.210851
 >> iter 26000, loss: 11.005681
 >> iter 27000, loss: 11.218190
 >> iter 28000, loss: 11.013126
 >> iter 29000, loss: 11.431956
 >> iter 30000, loss: 11.108764
   Number of active neurons: 2
 >> iter 31000, loss: 11.181653
 >> iter 32000, loss: 11.047641
 >> iter 33000, loss: 11.276091
 >> iter 34000, loss: 11.100793
 >> iter 35000, loss: 11.454678
 >> iter 36000, loss: 11.127316
 >> iter 37000, loss: 11.320200
 >> iter 38000, loss: 11.230481
 >> iter 39000, loss: 11.419871
 >> iter 40000, loss: 11.199492
   Number of active neurons: 2
 >> iter 41000, loss: 11.211168
 >> iter 42000, loss: 10.985269
 >> iter 43000, loss: 11.253301
 >> iter 44000, loss: 11.035549
 >> iter 45000, loss: 11.306575
 >> iter 46000, loss: 11.159347
 >> iter 47000, loss: 11.367465
 >> iter 48000, loss: 11.178254
 >> iter 49000, loss: 11.268488
 >> iter 50000, loss: 11.127352
   Number of active neurons: 2
 >> iter 51000, loss: 11.367940
 >> iter 52000, loss: 11.165859
 >> iter 53000, loss: 11.168763
 >> iter 54000, loss: 11.064624
 >> iter 55000, loss: 11.247973
 >> iter 56000, loss: 11.207741
 >> iter 57000, loss: 11.231695
 >> iter 58000, loss: 11.296252
 >> iter 59000, loss: 11.262159
 >> iter 60000, loss: 11.195103
   Number of active neurons: 2
 >> iter 61000, loss: 11.405594
 >> iter 62000, loss: 11.122717
 >> iter 63000, loss: 11.312108
 >> iter 64000, loss: 11.490785
 >> iter 65000, loss: 11.694304
 >> iter 66000, loss: 11.624764
 >> iter 67000, loss: 11.702923
 >> iter 68000, loss: 11.619341
 >> iter 69000, loss: 11.697713
 >> iter 70000, loss: 11.614380
   Number of active neurons: 2
 >> iter 71000, loss: 11.711693
 >> iter 72000, loss: 11.605829
 >> iter 73000, loss: 11.725560
 >> iter 74000, loss: 11.602760
 >> iter 75000, loss: 11.721577
 >> iter 76000, loss: 11.606275
 >> iter 77000, loss: 11.714961
 >> iter 78000, loss: 11.607272
 >> iter 79000, loss: 11.715565
 >> iter 80000, loss: 11.611989
   Number of active neurons: 2
 >> iter 81000, loss: 11.712009
 >> iter 82000, loss: 11.611258
 >> iter 83000, loss: 11.716824
 >> iter 84000, loss: 11.608720
 >> iter 85000, loss: 11.727009
 >> iter 86000, loss: 11.606361
 >> iter 87000, loss: 11.727070
 >> iter 88000, loss: 11.607197
 >> iter 89000, loss: 11.725534
 >> iter 90000, loss: 11.606502
   Number of active neurons: 2
 >> iter 91000, loss: 11.723412
 >> iter 92000, loss: 11.601204
 >> iter 93000, loss: 11.720230
 >> iter 94000, loss: 11.599876
 >> iter 95000, loss: 11.720658
 >> iter 96000, loss: 11.593663
 >> iter 97000, loss: 11.714384
 >> iter 98000, loss: 11.587267
 >> iter 99000, loss: 11.711914
 >> iter 100000, loss: 11.585121
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 22.6495470091
   - Test - Long: 4.48477576121
   - Test - Big: 22.5077749223
   - Test - A: 69.0487300847
   - Test - B: 16.1655889607
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.048362
 >> iter 2000, loss: 14.043624
 >> iter 3000, loss: 11.442375
 >> iter 4000, loss: 9.753435
 >> iter 5000, loss: 9.283271
 >> iter 6000, loss: 8.648078
 >> iter 7000, loss: 8.779243
 >> iter 8000, loss: 8.523737
 >> iter 9000, loss: 8.648640
 >> iter 10000, loss: 8.498920
   Number of active neurons: 2
 >> iter 11000, loss: 8.597867
 >> iter 12000, loss: 8.530133
 >> iter 13000, loss: 8.601156
 >> iter 14000, loss: 8.444441
 >> iter 15000, loss: 8.624955
 >> iter 16000, loss: 8.479049
 >> iter 17000, loss: 8.610659
 >> iter 18000, loss: 8.387640
 >> iter 19000, loss: 8.615281
 >> iter 20000, loss: 8.447100
   Number of active neurons: 2
 >> iter 21000, loss: 8.660335
 >> iter 22000, loss: 8.447069
 >> iter 23000, loss: 8.622960
 >> iter 24000, loss: 8.429661
 >> iter 25000, loss: 8.624512
 >> iter 26000, loss: 8.374189
 >> iter 27000, loss: 8.604406
 >> iter 28000, loss: 8.452822
 >> iter 29000, loss: 8.677252
 >> iter 30000, loss: 8.383454
   Number of active neurons: 2
 >> iter 31000, loss: 8.638107
 >> iter 32000, loss: 8.468430
 >> iter 33000, loss: 8.625529
 >> iter 34000, loss: 8.428377
 >> iter 35000, loss: 8.629963
 >> iter 36000, loss: 8.352557
 >> iter 37000, loss: 8.636044
 >> iter 38000, loss: 8.366978
 >> iter 39000, loss: 8.593408
 >> iter 40000, loss: 8.471542
   Number of active neurons: 2
 >> iter 41000, loss: 8.676484
 >> iter 42000, loss: 8.366721
 >> iter 43000, loss: 8.626011
 >> iter 44000, loss: 8.423869
 >> iter 45000, loss: 8.656192
 >> iter 46000, loss: 8.372593
 >> iter 47000, loss: 8.638111
 >> iter 48000, loss: 8.346435
 >> iter 49000, loss: 8.617903
 >> iter 50000, loss: 8.371144
   Number of active neurons: 2
 >> iter 51000, loss: 8.633045
 >> iter 52000, loss: 8.371424
 >> iter 53000, loss: 8.607031
 >> iter 54000, loss: 8.333300
 >> iter 55000, loss: 8.612807
 >> iter 56000, loss: 8.377565
 >> iter 57000, loss: 8.565500
 >> iter 58000, loss: 8.317855
 >> iter 59000, loss: 8.528704
 >> iter 60000, loss: 8.359250
   Number of active neurons: 2
 >> iter 61000, loss: 8.584548
 >> iter 62000, loss: 8.514322
 >> iter 63000, loss: 8.631280
 >> iter 64000, loss: 8.359854
 >> iter 65000, loss: 8.655195
 >> iter 66000, loss: 8.473096
 >> iter 67000, loss: 8.694280
 >> iter 68000, loss: 8.495332
 >> iter 69000, loss: 8.596430
 >> iter 70000, loss: 8.342523
   Number of active neurons: 2
 >> iter 71000, loss: 8.576661
 >> iter 72000, loss: 8.314067
 >> iter 73000, loss: 8.537133
 >> iter 74000, loss: 8.313505
 >> iter 75000, loss: 8.577773
 >> iter 76000, loss: 8.440826
 >> iter 77000, loss: 8.693115
 >> iter 78000, loss: 8.551154
 >> iter 79000, loss: 8.642126
 >> iter 80000, loss: 8.419376
   Number of active neurons: 2
 >> iter 81000, loss: 8.516593
 >> iter 82000, loss: 8.327484
 >> iter 83000, loss: 8.620697
 >> iter 84000, loss: 8.383502
 >> iter 85000, loss: 8.566992
 >> iter 86000, loss: 8.498866
 >> iter 87000, loss: 8.655653
 >> iter 88000, loss: 8.494063
 >> iter 89000, loss: 8.505453
 >> iter 90000, loss: 8.300342
   Number of active neurons: 2
 >> iter 91000, loss: 8.489305
 >> iter 92000, loss: 8.265847
 >> iter 93000, loss: 8.523399
 >> iter 94000, loss: 8.432353
 >> iter 95000, loss: 8.551791
 >> iter 96000, loss: 8.457818
 >> iter 97000, loss: 8.543786
 >> iter 98000, loss: 8.411447
 >> iter 99000, loss: 8.531824
 >> iter 100000, loss: 8.434673
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 12.2777544449
   - Test - Long: 2.67486625669
   - Test - Big: 11.8738812612
   - Test - A: 17.0521965202
   - Test - B: 26.6582227851
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.270016
 >> iter 2000, loss: 15.369584
 >> iter 3000, loss: 13.960147
 >> iter 4000, loss: 12.465011
 >> iter 5000, loss: 11.057680
 >> iter 6000, loss: 10.629584
 >> iter 7000, loss: 10.492294
 >> iter 8000, loss: 10.280007
 >> iter 9000, loss: 10.403137
 >> iter 10000, loss: 10.213978
   Number of active neurons: 2
 >> iter 11000, loss: 10.451681
 >> iter 12000, loss: 10.324156
 >> iter 13000, loss: 10.372856
 >> iter 14000, loss: 10.314979
 >> iter 15000, loss: 10.306818
 >> iter 16000, loss: 10.302956
 >> iter 17000, loss: 10.338483
 >> iter 18000, loss: 10.191897
 >> iter 19000, loss: 10.196813
 >> iter 20000, loss: 10.168508
   Number of active neurons: 2
 >> iter 21000, loss: 10.371304
 >> iter 22000, loss: 10.194655
 >> iter 23000, loss: 10.413792
 >> iter 24000, loss: 10.258793
 >> iter 25000, loss: 10.380837
 >> iter 26000, loss: 10.213516
 >> iter 27000, loss: 10.360424
 >> iter 28000, loss: 10.038702
 >> iter 29000, loss: 10.206464
 >> iter 30000, loss: 9.973712
   Number of active neurons: 2
 >> iter 31000, loss: 10.116599
 >> iter 32000, loss: 9.968351
 >> iter 33000, loss: 10.166377
 >> iter 34000, loss: 10.091081
 >> iter 35000, loss: 10.328234
 >> iter 36000, loss: 10.088727
 >> iter 37000, loss: 10.304682
 >> iter 38000, loss: 10.106979
 >> iter 39000, loss: 10.255319
 >> iter 40000, loss: 10.042006
   Number of active neurons: 2
 >> iter 41000, loss: 10.299484
 >> iter 42000, loss: 10.122959
 >> iter 43000, loss: 10.350926
 >> iter 44000, loss: 10.131457
 >> iter 45000, loss: 10.324947
 >> iter 46000, loss: 10.125367
 >> iter 47000, loss: 10.375064
 >> iter 48000, loss: 10.160226
 >> iter 49000, loss: 10.364976
 >> iter 50000, loss: 10.159580
   Number of active neurons: 2
 >> iter 51000, loss: 10.279566
 >> iter 52000, loss: 9.928392
 >> iter 53000, loss: 10.151459
 >> iter 54000, loss: 10.065752
 >> iter 55000, loss: 10.195182
 >> iter 56000, loss: 10.025132
 >> iter 57000, loss: 10.125208
 >> iter 58000, loss: 10.002174
 >> iter 59000, loss: 10.207991
 >> iter 60000, loss: 10.012761
   Number of active neurons: 2
 >> iter 61000, loss: 10.156316
 >> iter 62000, loss: 10.021487
 >> iter 63000, loss: 10.231389
 >> iter 64000, loss: 10.123280
 >> iter 65000, loss: 10.155709
 >> iter 66000, loss: 10.066243
 >> iter 67000, loss: 10.364220
 >> iter 68000, loss: 10.085426
 >> iter 69000, loss: 10.218858
 >> iter 70000, loss: 10.017876
   Number of active neurons: 2
 >> iter 71000, loss: 10.206683
 >> iter 72000, loss: 9.971123
 >> iter 73000, loss: 10.103055
 >> iter 74000, loss: 9.933468
 >> iter 75000, loss: 10.058002
 >> iter 76000, loss: 9.961539
 >> iter 77000, loss: 10.232194
 >> iter 78000, loss: 10.086907
 >> iter 79000, loss: 10.156981
 >> iter 80000, loss: 9.948792
   Number of active neurons: 2
 >> iter 81000, loss: 10.097482
 >> iter 82000, loss: 10.060330
 >> iter 83000, loss: 10.265972
 >> iter 84000, loss: 10.043505
 >> iter 85000, loss: 10.247919
 >> iter 86000, loss: 10.037021
 >> iter 87000, loss: 10.244525
 >> iter 88000, loss: 10.097917
 >> iter 89000, loss: 10.268794
 >> iter 90000, loss: 10.040990
   Number of active neurons: 2
 >> iter 91000, loss: 10.245359
 >> iter 92000, loss: 10.074094
 >> iter 93000, loss: 10.202665
 >> iter 94000, loss: 9.932490
 >> iter 95000, loss: 10.196796
 >> iter 96000, loss: 10.040560
 >> iter 97000, loss: 10.233110
 >> iter 98000, loss: 10.065819
 >> iter 99000, loss: 10.281940
 >> iter 100000, loss: 10.133001
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 16.8636627267
   - Test - Long: 3.46982650867
   - Test - Big: 16.6948330517
   - Test - A: 63.9024065062
   - Test - B: 14.8856742884
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.060529
 >> iter 2000, loss: 13.955693
 >> iter 3000, loss: 11.430397
 >> iter 4000, loss: 9.797472
 >> iter 5000, loss: 9.303007
 >> iter 6000, loss: 8.637155
 >> iter 7000, loss: 8.775315
 >> iter 8000, loss: 8.483638
 >> iter 9000, loss: 8.605566
 >> iter 10000, loss: 8.459706
   Number of active neurons: 2
 >> iter 11000, loss: 8.603441
 >> iter 12000, loss: 8.432754
 >> iter 13000, loss: 8.584720
 >> iter 14000, loss: 8.388168
 >> iter 15000, loss: 8.608143
 >> iter 16000, loss: 8.422839
 >> iter 17000, loss: 8.567612
 >> iter 18000, loss: 8.389381
 >> iter 19000, loss: 8.606160
 >> iter 20000, loss: 8.391961
   Number of active neurons: 2
 >> iter 21000, loss: 8.632335
 >> iter 22000, loss: 8.444301
 >> iter 23000, loss: 8.603275
 >> iter 24000, loss: 8.455984
 >> iter 25000, loss: 8.653915
 >> iter 26000, loss: 8.455790
 >> iter 27000, loss: 8.684555
 >> iter 28000, loss: 8.473405
 >> iter 29000, loss: 8.624174
 >> iter 30000, loss: 8.389033
   Number of active neurons: 2
 >> iter 31000, loss: 8.584942
 >> iter 32000, loss: 8.381559
 >> iter 33000, loss: 8.594275
 >> iter 34000, loss: 8.392078
 >> iter 35000, loss: 8.572928
 >> iter 36000, loss: 8.348949
 >> iter 37000, loss: 8.613585
 >> iter 38000, loss: 8.439826
 >> iter 39000, loss: 8.597526
 >> iter 40000, loss: 8.357406
   Number of active neurons: 2
 >> iter 41000, loss: 8.554970
 >> iter 42000, loss: 8.314683
 >> iter 43000, loss: 8.605746
 >> iter 44000, loss: 8.362911
 >> iter 45000, loss: 8.619121
 >> iter 46000, loss: 8.335234
 >> iter 47000, loss: 8.623667
 >> iter 48000, loss: 8.349678
 >> iter 49000, loss: 8.661304
 >> iter 50000, loss: 8.323215
   Number of active neurons: 2
 >> iter 51000, loss: 8.585673
 >> iter 52000, loss: 8.412290
 >> iter 53000, loss: 8.638588
 >> iter 54000, loss: 8.403056
 >> iter 55000, loss: 8.660768
 >> iter 56000, loss: 8.440368
 >> iter 57000, loss: 8.545892
 >> iter 58000, loss: 8.458533
 >> iter 59000, loss: 8.581199
 >> iter 60000, loss: 8.440852
   Number of active neurons: 2
 >> iter 61000, loss: 8.551761
 >> iter 62000, loss: 8.434054
 >> iter 63000, loss: 8.625879
 >> iter 64000, loss: 8.386768
 >> iter 65000, loss: 8.601562
 >> iter 66000, loss: 8.350807
 >> iter 67000, loss: 8.557269
 >> iter 68000, loss: 8.460617
 >> iter 69000, loss: 8.531399
 >> iter 70000, loss: 8.489487
   Number of active neurons: 2
 >> iter 71000, loss: 8.671792
 >> iter 72000, loss: 8.464121
 >> iter 73000, loss: 8.635854
 >> iter 74000, loss: 8.420676
 >> iter 75000, loss: 8.615116
 >> iter 76000, loss: 8.455967
 >> iter 77000, loss: 8.612758
 >> iter 78000, loss: 8.455437
 >> iter 79000, loss: 8.597267
 >> iter 80000, loss: 8.372077
   Number of active neurons: 2
 >> iter 81000, loss: 8.538581
 >> iter 82000, loss: 8.362088
 >> iter 83000, loss: 8.554889
 >> iter 84000, loss: 8.482043
 >> iter 85000, loss: 8.586070
 >> iter 86000, loss: 8.472200
 >> iter 87000, loss: 8.577330
 >> iter 88000, loss: 8.320807
 >> iter 89000, loss: 8.487210
 >> iter 90000, loss: 8.386749
   Number of active neurons: 2
 >> iter 91000, loss: 8.567541
 >> iter 92000, loss: 8.463946
 >> iter 93000, loss: 8.565040
 >> iter 94000, loss: 8.450350
 >> iter 95000, loss: 8.580284
 >> iter 96000, loss: 8.346151
 >> iter 97000, loss: 8.563109
 >> iter 98000, loss: 8.376945
 >> iter 99000, loss: 8.478062
 >> iter 100000, loss: 8.420027
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 12.2777544449
   - Test - Long: 2.67486625669
   - Test - Big: 11.8748812512
   - Test - A: 17.0521965202
   - Test - B: 26.6582227851
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.976514
 >> iter 2000, loss: 13.878656
 >> iter 3000, loss: 11.432158
 >> iter 4000, loss: 9.840657
 >> iter 5000, loss: 9.333859
 >> iter 6000, loss: 8.704577
 >> iter 7000, loss: 8.829571
 >> iter 8000, loss: 8.545493
 >> iter 9000, loss: 8.648349
 >> iter 10000, loss: 8.535316
   Number of active neurons: 2
 >> iter 11000, loss: 8.614302
 >> iter 12000, loss: 8.423621
 >> iter 13000, loss: 8.543046
 >> iter 14000, loss: 8.412065
 >> iter 15000, loss: 8.614177
 >> iter 16000, loss: 8.518446
 >> iter 17000, loss: 8.654068
 >> iter 18000, loss: 8.492346
 >> iter 19000, loss: 8.627552
 >> iter 20000, loss: 8.481104
   Number of active neurons: 2
 >> iter 21000, loss: 8.655205
 >> iter 22000, loss: 8.426761
 >> iter 23000, loss: 8.641233
 >> iter 24000, loss: 8.382935
 >> iter 25000, loss: 8.679603
 >> iter 26000, loss: 8.437727
 >> iter 27000, loss: 8.750142
 >> iter 28000, loss: 8.469498
 >> iter 29000, loss: 8.717798
 >> iter 30000, loss: 8.447048
   Number of active neurons: 2
 >> iter 31000, loss: 8.714839
 >> iter 32000, loss: 8.339909
 >> iter 33000, loss: 8.570903
 >> iter 34000, loss: 8.388953
 >> iter 35000, loss: 8.664788
 >> iter 36000, loss: 8.410518
 >> iter 37000, loss: 8.645802
 >> iter 38000, loss: 8.314044
 >> iter 39000, loss: 8.577218
 >> iter 40000, loss: 8.372450
   Number of active neurons: 2
 >> iter 41000, loss: 8.598011
 >> iter 42000, loss: 8.384170
 >> iter 43000, loss: 8.656357
 >> iter 44000, loss: 8.336054
 >> iter 45000, loss: 8.638967
 >> iter 46000, loss: 8.350887
 >> iter 47000, loss: 8.637474
 >> iter 48000, loss: 8.378512
 >> iter 49000, loss: 8.551975
 >> iter 50000, loss: 8.415923
   Number of active neurons: 2
 >> iter 51000, loss: 8.576382
 >> iter 52000, loss: 8.436836
 >> iter 53000, loss: 8.638148
 >> iter 54000, loss: 8.441080
 >> iter 55000, loss: 8.618455
 >> iter 56000, loss: 8.426065
 >> iter 57000, loss: 8.616503
 >> iter 58000, loss: 8.404632
 >> iter 59000, loss: 8.599410
 >> iter 60000, loss: 8.385384
   Number of active neurons: 2
 >> iter 61000, loss: 8.554631
 >> iter 62000, loss: 8.461529
 >> iter 63000, loss: 8.623309
 >> iter 64000, loss: 8.502588
 >> iter 65000, loss: 8.612459
 >> iter 66000, loss: 8.472561
 >> iter 67000, loss: 8.528072
 >> iter 68000, loss: 8.419864
 >> iter 69000, loss: 8.627122
 >> iter 70000, loss: 8.458217
   Number of active neurons: 2
 >> iter 71000, loss: 8.616891
 >> iter 72000, loss: 8.410878
 >> iter 73000, loss: 8.613840
 >> iter 74000, loss: 8.403945
 >> iter 75000, loss: 8.554760
 >> iter 76000, loss: 8.474073
 >> iter 77000, loss: 8.552184
 >> iter 78000, loss: 8.478776
 >> iter 79000, loss: 8.591434
 >> iter 80000, loss: 8.498156
   Number of active neurons: 2
 >> iter 81000, loss: 8.601517
 >> iter 82000, loss: 8.426460
 >> iter 83000, loss: 8.674981
 >> iter 84000, loss: 8.433055
 >> iter 85000, loss: 8.581991
 >> iter 86000, loss: 8.375411
 >> iter 87000, loss: 8.509087
 >> iter 88000, loss: 8.482837
 >> iter 89000, loss: 8.533073
 >> iter 90000, loss: 8.347630
   Number of active neurons: 2
 >> iter 91000, loss: 8.533265
 >> iter 92000, loss: 8.399129
 >> iter 93000, loss: 8.584095
 >> iter 94000, loss: 8.391457
 >> iter 95000, loss: 8.618092
 >> iter 96000, loss: 8.504557
 >> iter 97000, loss: 8.587279
 >> iter 98000, loss: 8.435497
 >> iter 99000, loss: 8.533700
 >> iter 100000, loss: 8.425468
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 12.2777544449
   - Test - Long: 2.67486625669
   - Test - Big: 11.8728812712
   - Test - A: 17.0521965202
   - Test - B: 27.6514899007
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.126550
 >> iter 2000, loss: 13.944849
 >> iter 3000, loss: 11.762474
 >> iter 4000, loss: 10.747485
 >> iter 5000, loss: 10.651883
 >> iter 6000, loss: 10.385039
 >> iter 7000, loss: 10.327788
 >> iter 8000, loss: 10.129360
 >> iter 9000, loss: 10.312389
 >> iter 10000, loss: 10.262099
   Number of active neurons: 2
 >> iter 11000, loss: 10.423739
 >> iter 12000, loss: 10.166759
 >> iter 13000, loss: 10.240707
 >> iter 14000, loss: 10.261579
 >> iter 15000, loss: 10.325511
 >> iter 16000, loss: 10.176276
 >> iter 17000, loss: 10.328175
 >> iter 18000, loss: 10.265648
 >> iter 19000, loss: 10.334439
 >> iter 20000, loss: 10.259790
   Number of active neurons: 2
 >> iter 21000, loss: 10.403572
 >> iter 22000, loss: 10.158344
 >> iter 23000, loss: 10.366658
 >> iter 24000, loss: 10.175259
 >> iter 25000, loss: 10.337027
 >> iter 26000, loss: 10.278760
 >> iter 27000, loss: 10.260735
 >> iter 28000, loss: 10.237826
 >> iter 29000, loss: 10.363678
 >> iter 30000, loss: 10.193240
   Number of active neurons: 2
 >> iter 31000, loss: 10.385265
 >> iter 32000, loss: 10.150949
 >> iter 33000, loss: 10.279161
 >> iter 34000, loss: 10.202616
 >> iter 35000, loss: 10.319420
 >> iter 36000, loss: 10.222201
 >> iter 37000, loss: 10.344662
 >> iter 38000, loss: 10.172749
 >> iter 39000, loss: 10.334842
 >> iter 40000, loss: 10.001595
   Number of active neurons: 2
 >> iter 41000, loss: 10.260968
 >> iter 42000, loss: 10.071416
 >> iter 43000, loss: 10.256528
 >> iter 44000, loss: 10.060240
 >> iter 45000, loss: 10.415023
 >> iter 46000, loss: 10.150605
 >> iter 47000, loss: 10.299003
 >> iter 48000, loss: 10.039593
 >> iter 49000, loss: 10.230455
 >> iter 50000, loss: 10.071538
   Number of active neurons: 2
 >> iter 51000, loss: 10.109747
 >> iter 52000, loss: 10.146790
 >> iter 53000, loss: 10.319964
 >> iter 54000, loss: 10.075355
 >> iter 55000, loss: 10.279308
 >> iter 56000, loss: 10.152864
 >> iter 57000, loss: 10.175023
 >> iter 58000, loss: 10.016021
 >> iter 59000, loss: 10.195873
 >> iter 60000, loss: 10.061006
   Number of active neurons: 2
 >> iter 61000, loss: 10.249481
 >> iter 62000, loss: 9.976604
 >> iter 63000, loss: 10.243454
 >> iter 64000, loss: 10.133957
 >> iter 65000, loss: 10.309724
 >> iter 66000, loss: 10.099975
 >> iter 67000, loss: 10.281947
 >> iter 68000, loss: 10.032820
 >> iter 69000, loss: 10.171544
 >> iter 70000, loss: 10.055344
   Number of active neurons: 2
 >> iter 71000, loss: 10.319083
 >> iter 72000, loss: 10.052006
 >> iter 73000, loss: 10.233604
 >> iter 74000, loss: 10.034151
 >> iter 75000, loss: 10.179466
 >> iter 76000, loss: 9.969865
 >> iter 77000, loss: 10.240913
 >> iter 78000, loss: 10.069945
 >> iter 79000, loss: 10.272317
 >> iter 80000, loss: 10.074300
   Number of active neurons: 2
 >> iter 81000, loss: 10.283776
 >> iter 82000, loss: 10.187691
 >> iter 83000, loss: 10.286818
 >> iter 84000, loss: 10.075951
 >> iter 85000, loss: 10.197719
 >> iter 86000, loss: 10.042379
 >> iter 87000, loss: 10.131199
 >> iter 88000, loss: 10.059153
 >> iter 89000, loss: 10.155912
 >> iter 90000, loss: 10.016979
   Number of active neurons: 2
 >> iter 91000, loss: 10.183421
 >> iter 92000, loss: 10.041699
 >> iter 93000, loss: 10.243219
 >> iter 94000, loss: 9.942338
 >> iter 95000, loss: 10.130471
 >> iter 96000, loss: 9.972025
 >> iter 97000, loss: 10.104669
 >> iter 98000, loss: 10.007326
 >> iter 99000, loss: 10.277044
 >> iter 100000, loss: 10.157576
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 18.2576348473
   - Test - Long: 4.02479876006
   - Test - Big: 18.4508154918
   - Test - A: 62.9558029465
   - Test - B: 16.1055929605
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.122856
 >> iter 2000, loss: 14.765730
 >> iter 3000, loss: 13.131547
 >> iter 4000, loss: 11.126993
 >> iter 5000, loss: 10.131900
 >> iter 6000, loss: 9.161722
 >> iter 7000, loss: 9.019797
 >> iter 8000, loss: 8.497073
 >> iter 9000, loss: 8.707494
 >> iter 10000, loss: 8.460013
   Number of active neurons: 2
 >> iter 11000, loss: 8.656335
 >> iter 12000, loss: 8.460129
 >> iter 13000, loss: 8.623900
 >> iter 14000, loss: 8.402740
 >> iter 15000, loss: 8.641832
 >> iter 16000, loss: 8.548510
 >> iter 17000, loss: 8.689160
 >> iter 18000, loss: 8.491563
 >> iter 19000, loss: 8.593223
 >> iter 20000, loss: 8.427977
   Number of active neurons: 2
 >> iter 21000, loss: 8.652975
 >> iter 22000, loss: 8.398862
 >> iter 23000, loss: 8.645823
 >> iter 24000, loss: 8.374653
 >> iter 25000, loss: 8.622152
 >> iter 26000, loss: 8.394299
 >> iter 27000, loss: 8.621734
 >> iter 28000, loss: 8.382008
 >> iter 29000, loss: 8.602960
 >> iter 30000, loss: 8.356759
   Number of active neurons: 2
 >> iter 31000, loss: 8.632567
 >> iter 32000, loss: 8.445735
 >> iter 33000, loss: 8.615604
 >> iter 34000, loss: 8.439215
 >> iter 35000, loss: 8.691180
 >> iter 36000, loss: 8.382143
 >> iter 37000, loss: 8.589265
 >> iter 38000, loss: 8.386072
 >> iter 39000, loss: 8.655203
 >> iter 40000, loss: 8.391161
   Number of active neurons: 2
 >> iter 41000, loss: 8.638194
 >> iter 42000, loss: 8.417347
 >> iter 43000, loss: 8.643004
 >> iter 44000, loss: 8.354935
 >> iter 45000, loss: 8.673353
 >> iter 46000, loss: 8.395958
 >> iter 47000, loss: 8.710107
 >> iter 48000, loss: 8.393414
 >> iter 49000, loss: 8.645486
 >> iter 50000, loss: 8.446665
   Number of active neurons: 2
 >> iter 51000, loss: 8.644945
 >> iter 52000, loss: 8.337699
 >> iter 53000, loss: 8.504272
 >> iter 54000, loss: 8.389416
 >> iter 55000, loss: 8.620808
 >> iter 56000, loss: 8.518526
 >> iter 57000, loss: 8.616567
 >> iter 58000, loss: 8.431413
 >> iter 59000, loss: 8.660064
 >> iter 60000, loss: 8.419314
   Number of active neurons: 2
 >> iter 61000, loss: 8.580705
 >> iter 62000, loss: 8.309112
 >> iter 63000, loss: 8.551980
 >> iter 64000, loss: 8.363388
 >> iter 65000, loss: 8.567620
 >> iter 66000, loss: 8.464180
 >> iter 67000, loss: 8.606187
 >> iter 68000, loss: 8.419923
 >> iter 69000, loss: 8.543695
 >> iter 70000, loss: 8.441303
   Number of active neurons: 2
 >> iter 71000, loss: 8.615684
 >> iter 72000, loss: 8.426084
 >> iter 73000, loss: 8.620664
 >> iter 74000, loss: 8.455981
 >> iter 75000, loss: 8.642724
 >> iter 76000, loss: 8.401940
 >> iter 77000, loss: 8.605547
 >> iter 78000, loss: 8.428097
 >> iter 79000, loss: 8.607554
 >> iter 80000, loss: 8.471700
   Number of active neurons: 2
 >> iter 81000, loss: 8.564548
 >> iter 82000, loss: 8.402251
 >> iter 83000, loss: 8.566830
 >> iter 84000, loss: 8.370151
 >> iter 85000, loss: 8.546935
 >> iter 86000, loss: 8.371189
 >> iter 87000, loss: 8.535038
 >> iter 88000, loss: 8.364041
 >> iter 89000, loss: 8.515879
 >> iter 90000, loss: 8.293128
   Number of active neurons: 2
 >> iter 91000, loss: 8.478638
 >> iter 92000, loss: 8.406063
 >> iter 93000, loss: 8.650519
 >> iter 94000, loss: 8.339417
 >> iter 95000, loss: 8.480043
 >> iter 96000, loss: 8.353697
 >> iter 97000, loss: 8.577580
 >> iter 98000, loss: 8.420797
 >> iter 99000, loss: 8.567791
 >> iter 100000, loss: 8.455041
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 11.9017619648
   - Test - Long: 2.53487325634
   - Test - Big: 11.6228837712
   - Test - A: 17.0521965202
   - Test - B: 15.3189787348
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.897193
 >> iter 2000, loss: 13.610831
 >> iter 3000, loss: 11.380021
 >> iter 4000, loss: 9.822887
 >> iter 5000, loss: 9.393277
 >> iter 6000, loss: 8.739941
 >> iter 7000, loss: 8.813866
 >> iter 8000, loss: 8.513929
 >> iter 9000, loss: 8.654569
 >> iter 10000, loss: 8.502757
   Number of active neurons: 2
 >> iter 11000, loss: 8.626815
 >> iter 12000, loss: 8.431759
 >> iter 13000, loss: 8.618663
 >> iter 14000, loss: 8.451898
 >> iter 15000, loss: 8.628024
 >> iter 16000, loss: 8.481427
 >> iter 17000, loss: 8.621994
 >> iter 18000, loss: 8.476776
 >> iter 19000, loss: 8.642430
 >> iter 20000, loss: 8.439574
   Number of active neurons: 2
 >> iter 21000, loss: 8.689862
 >> iter 22000, loss: 8.427073
 >> iter 23000, loss: 8.608840
 >> iter 24000, loss: 8.396447
 >> iter 25000, loss: 8.623646
 >> iter 26000, loss: 8.377463
 >> iter 27000, loss: 8.637833
 >> iter 28000, loss: 8.441352
 >> iter 29000, loss: 8.606209
 >> iter 30000, loss: 8.425676
   Number of active neurons: 2
 >> iter 31000, loss: 8.640301
 >> iter 32000, loss: 8.463761
 >> iter 33000, loss: 8.590613
 >> iter 34000, loss: 8.340727
 >> iter 35000, loss: 8.622673
 >> iter 36000, loss: 8.373575
 >> iter 37000, loss: 8.715565
 >> iter 38000, loss: 8.376817
 >> iter 39000, loss: 8.654703
 >> iter 40000, loss: 8.379403
   Number of active neurons: 2
 >> iter 41000, loss: 8.612369
 >> iter 42000, loss: 8.427185
 >> iter 43000, loss: 8.628503
 >> iter 44000, loss: 8.338589
 >> iter 45000, loss: 8.580835
 >> iter 46000, loss: 8.346076
 >> iter 47000, loss: 8.631319
 >> iter 48000, loss: 8.388053
 >> iter 49000, loss: 8.650613
 >> iter 50000, loss: 8.365831
   Number of active neurons: 2
 >> iter 51000, loss: 8.611547
 >> iter 52000, loss: 8.317517
 >> iter 53000, loss: 8.568771
 >> iter 54000, loss: 8.334749
 >> iter 55000, loss: 8.557070
 >> iter 56000, loss: 8.335797
 >> iter 57000, loss: 8.602207
 >> iter 58000, loss: 8.317885
 >> iter 59000, loss: 8.566304
 >> iter 60000, loss: 8.328906
   Number of active neurons: 2
 >> iter 61000, loss: 8.505420
 >> iter 62000, loss: 8.366849
 >> iter 63000, loss: 8.596170
 >> iter 64000, loss: 8.414931
 >> iter 65000, loss: 8.669592
 >> iter 66000, loss: 8.558957
 >> iter 67000, loss: 8.613847
 >> iter 68000, loss: 8.446916
 >> iter 69000, loss: 8.604623
 >> iter 70000, loss: 8.360847
   Number of active neurons: 2
 >> iter 71000, loss: 8.586450
 >> iter 72000, loss: 8.344545
 >> iter 73000, loss: 8.631363
 >> iter 74000, loss: 8.412865
 >> iter 75000, loss: 8.611508
 >> iter 76000, loss: 8.479652
 >> iter 77000, loss: 8.596794
 >> iter 78000, loss: 8.349880
 >> iter 79000, loss: 8.548013
 >> iter 80000, loss: 8.433218
   Number of active neurons: 2
 >> iter 81000, loss: 8.619551
 >> iter 82000, loss: 8.376906
 >> iter 83000, loss: 8.527401
 >> iter 84000, loss: 8.413418
 >> iter 85000, loss: 8.528429
 >> iter 86000, loss: 8.482904
 >> iter 87000, loss: 8.598862
 >> iter 88000, loss: 8.353955
 >> iter 89000, loss: 8.588820
 >> iter 90000, loss: 8.392076
   Number of active neurons: 2
 >> iter 91000, loss: 8.544467
 >> iter 92000, loss: 8.379271
 >> iter 93000, loss: 8.505838
 >> iter 94000, loss: 8.298074
 >> iter 95000, loss: 8.530143
 >> iter 96000, loss: 8.440190
 >> iter 97000, loss: 8.520829
 >> iter 98000, loss: 8.369229
 >> iter 99000, loss: 8.529302
 >> iter 100000, loss: 8.404034
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 12.605747885
   - Test - Long: 3.06984650767
   - Test - Big: 12.1358786412
   - Test - A: 24.4983667755
   - Test - B: 29.7913472435
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.093417
 >> iter 2000, loss: 14.718890
 >> iter 3000, loss: 11.942053
 >> iter 4000, loss: 10.665035
 >> iter 5000, loss: 10.530401
 >> iter 6000, loss: 10.405313
 >> iter 7000, loss: 10.541747
 >> iter 8000, loss: 10.185431
 >> iter 9000, loss: 10.247259
 >> iter 10000, loss: 10.219554
   Number of active neurons: 2
 >> iter 11000, loss: 10.293802
 >> iter 12000, loss: 10.299726
 >> iter 13000, loss: 10.398977
 >> iter 14000, loss: 10.269205
 >> iter 15000, loss: 10.312258
 >> iter 16000, loss: 10.201109
 >> iter 17000, loss: 10.290322
 >> iter 18000, loss: 10.121975
 >> iter 19000, loss: 10.302642
 >> iter 20000, loss: 10.165054
   Number of active neurons: 2
 >> iter 21000, loss: 10.317545
 >> iter 22000, loss: 10.139356
 >> iter 23000, loss: 10.391112
 >> iter 24000, loss: 10.156553
 >> iter 25000, loss: 10.442147
 >> iter 26000, loss: 10.155086
 >> iter 27000, loss: 10.458076
 >> iter 28000, loss: 10.300044
 >> iter 29000, loss: 10.349183
 >> iter 30000, loss: 10.132580
   Number of active neurons: 2
 >> iter 31000, loss: 10.308735
 >> iter 32000, loss: 10.191314
 >> iter 33000, loss: 10.423993
 >> iter 34000, loss: 10.137856
 >> iter 35000, loss: 10.281023
 >> iter 36000, loss: 10.157935
 >> iter 37000, loss: 10.427732
 >> iter 38000, loss: 10.161449
 >> iter 39000, loss: 10.252940
 >> iter 40000, loss: 10.110620
   Number of active neurons: 2
 >> iter 41000, loss: 10.293984
 >> iter 42000, loss: 10.134747
 >> iter 43000, loss: 10.442424
 >> iter 44000, loss: 10.219594
 >> iter 45000, loss: 10.379372
 >> iter 46000, loss: 10.125232
 >> iter 47000, loss: 10.269754
 >> iter 48000, loss: 10.038178
 >> iter 49000, loss: 10.177031
 >> iter 50000, loss: 10.117668
   Number of active neurons: 2
 >> iter 51000, loss: 10.146814
 >> iter 52000, loss: 10.027227
 >> iter 53000, loss: 10.100164
 >> iter 54000, loss: 9.942677
 >> iter 55000, loss: 10.235183
 >> iter 56000, loss: 10.146082
 >> iter 57000, loss: 10.423945
 >> iter 58000, loss: 10.144505
 >> iter 59000, loss: 10.369839
 >> iter 60000, loss: 10.257238
   Number of active neurons: 2
 >> iter 61000, loss: 10.306957
 >> iter 62000, loss: 10.157321
 >> iter 63000, loss: 10.160797
 >> iter 64000, loss: 10.041163
 >> iter 65000, loss: 10.138420
 >> iter 66000, loss: 10.066574
 >> iter 67000, loss: 10.209989
 >> iter 68000, loss: 10.077528
 >> iter 69000, loss: 10.306143
 >> iter 70000, loss: 10.034049
   Number of active neurons: 2
 >> iter 71000, loss: 10.195748
 >> iter 72000, loss: 10.140089
 >> iter 73000, loss: 10.309609
 >> iter 74000, loss: 10.068148
 >> iter 75000, loss: 10.154831
 >> iter 76000, loss: 10.086913
 >> iter 77000, loss: 10.205209
 >> iter 78000, loss: 10.107219
 >> iter 79000, loss: 10.342559
 >> iter 80000, loss: 10.102428
   Number of active neurons: 2
 >> iter 81000, loss: 10.218642
 >> iter 82000, loss: 10.023700
 >> iter 83000, loss: 10.186040
 >> iter 84000, loss: 10.047569
 >> iter 85000, loss: 10.279528
 >> iter 86000, loss: 10.102909
 >> iter 87000, loss: 10.288828
 >> iter 88000, loss: 10.006227
 >> iter 89000, loss: 10.146331
 >> iter 90000, loss: 9.975750
   Number of active neurons: 2
 >> iter 91000, loss: 10.128994
 >> iter 92000, loss: 10.038505
 >> iter 93000, loss: 10.193363
 >> iter 94000, loss: 10.000157
 >> iter 95000, loss: 10.197036
 >> iter 96000, loss: 10.086149
 >> iter 97000, loss: 10.099063
 >> iter 98000, loss: 10.000691
 >> iter 99000, loss: 10.170938
 >> iter 100000, loss: 9.981533
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 17.8676426471
   - Test - Long: 3.7598120094
   - Test - Big: 17.8888211118
   - Test - A: 64.822345177
   - Test - B: 21.9252049863
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.050937
 >> iter 2000, loss: 13.894780
 >> iter 3000, loss: 11.582001
 >> iter 4000, loss: 9.910561
 >> iter 5000, loss: 9.422253
 >> iter 6000, loss: 8.821434
 >> iter 7000, loss: 8.836731
 >> iter 8000, loss: 8.507528
 >> iter 9000, loss: 8.662224
 >> iter 10000, loss: 8.488586
   Number of active neurons: 2
 >> iter 11000, loss: 8.648381
 >> iter 12000, loss: 8.447693
 >> iter 13000, loss: 8.607589
 >> iter 14000, loss: 8.445307
 >> iter 15000, loss: 8.615988
 >> iter 16000, loss: 8.492480
 >> iter 17000, loss: 8.637834
 >> iter 18000, loss: 8.504315
 >> iter 19000, loss: 8.622345
 >> iter 20000, loss: 8.432617
   Number of active neurons: 2
 >> iter 21000, loss: 8.635322
 >> iter 22000, loss: 8.529699
 >> iter 23000, loss: 8.665103
 >> iter 24000, loss: 8.421976
 >> iter 25000, loss: 8.673376
 >> iter 26000, loss: 8.440317
 >> iter 27000, loss: 8.605193
 >> iter 28000, loss: 8.402955
 >> iter 29000, loss: 8.608485
 >> iter 30000, loss: 8.326646
   Number of active neurons: 2
 >> iter 31000, loss: 8.569593
 >> iter 32000, loss: 8.409981
 >> iter 33000, loss: 8.579444
 >> iter 34000, loss: 8.350818
 >> iter 35000, loss: 8.550542
 >> iter 36000, loss: 8.332677
 >> iter 37000, loss: 8.551798
 >> iter 38000, loss: 8.366245
 >> iter 39000, loss: 8.596235
 >> iter 40000, loss: 8.309160
   Number of active neurons: 2
 >> iter 41000, loss: 8.637622
 >> iter 42000, loss: 8.384832
 >> iter 43000, loss: 8.658789
 >> iter 44000, loss: 8.397961
 >> iter 45000, loss: 8.624568
 >> iter 46000, loss: 8.359557
 >> iter 47000, loss: 8.626719
 >> iter 48000, loss: 8.362036
 >> iter 49000, loss: 8.641444
 >> iter 50000, loss: 8.387652
   Number of active neurons: 2
 >> iter 51000, loss: 8.693425
 >> iter 52000, loss: 8.456561
 >> iter 53000, loss: 8.622231
 >> iter 54000, loss: 8.346629
 >> iter 55000, loss: 8.544430
 >> iter 56000, loss: 8.355378
 >> iter 57000, loss: 8.577742
 >> iter 58000, loss: 8.365678
 >> iter 59000, loss: 8.553573
 >> iter 60000, loss: 8.313519
   Number of active neurons: 2
 >> iter 61000, loss: 8.483019
 >> iter 62000, loss: 8.402166
 >> iter 63000, loss: 8.547525
 >> iter 64000, loss: 8.441055
 >> iter 65000, loss: 8.605115
 >> iter 66000, loss: 8.398276
 >> iter 67000, loss: 8.492034
 >> iter 68000, loss: 8.296553
 >> iter 69000, loss: 8.488093
 >> iter 70000, loss: 8.444016
   Number of active neurons: 2
 >> iter 71000, loss: 8.614864
 >> iter 72000, loss: 8.493846
 >> iter 73000, loss: 8.692977
 >> iter 74000, loss: 8.477559
 >> iter 75000, loss: 8.637633
 >> iter 76000, loss: 8.440803
 >> iter 77000, loss: 8.526242
 >> iter 78000, loss: 8.463459
 >> iter 79000, loss: 8.567816
 >> iter 80000, loss: 8.328995
   Number of active neurons: 2
 >> iter 81000, loss: 8.470873
 >> iter 82000, loss: 8.323458
 >> iter 83000, loss: 8.473003
 >> iter 84000, loss: 8.274052
 >> iter 85000, loss: 8.506963
 >> iter 86000, loss: 8.401808
 >> iter 87000, loss: 8.597519
 >> iter 88000, loss: 8.434162
 >> iter 89000, loss: 8.615421
 >> iter 90000, loss: 8.467365
   Number of active neurons: 2
 >> iter 91000, loss: 8.701256
 >> iter 92000, loss: 8.368662
 >> iter 93000, loss: 8.491126
 >> iter 94000, loss: 8.299024
 >> iter 95000, loss: 8.599182
 >> iter 96000, loss: 8.534005
 >> iter 97000, loss: 8.750406
 >> iter 98000, loss: 8.478548
 >> iter 99000, loss: 8.531153
 >> iter 100000, loss: 8.455240
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 11.9017619648
   - Test - Long: 2.53487325634
   - Test - Big: 11.6248837512
   - Test - A: 17.0521965202
   - Test - B: 15.3056462902
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.252123
 >> iter 2000, loss: 14.310332
 >> iter 3000, loss: 11.584954
 >> iter 4000, loss: 9.835304
 >> iter 5000, loss: 9.333718
 >> iter 6000, loss: 8.677024
 >> iter 7000, loss: 8.814755
 >> iter 8000, loss: 8.514872
 >> iter 9000, loss: 8.667525
 >> iter 10000, loss: 8.425797
   Number of active neurons: 2
 >> iter 11000, loss: 8.640820
 >> iter 12000, loss: 8.435781
 >> iter 13000, loss: 8.555378
 >> iter 14000, loss: 8.385360
 >> iter 15000, loss: 8.597928
 >> iter 16000, loss: 8.466115
 >> iter 17000, loss: 8.617479
 >> iter 18000, loss: 8.438280
 >> iter 19000, loss: 8.617281
 >> iter 20000, loss: 8.433118
   Number of active neurons: 2
 >> iter 21000, loss: 8.661670
 >> iter 22000, loss: 8.431379
 >> iter 23000, loss: 8.679616
 >> iter 24000, loss: 8.381257
 >> iter 25000, loss: 8.606346
 >> iter 26000, loss: 8.460768
 >> iter 27000, loss: 8.624746
 >> iter 28000, loss: 8.420049
 >> iter 29000, loss: 8.617536
 >> iter 30000, loss: 8.431123
   Number of active neurons: 2
 >> iter 31000, loss: 8.608035
 >> iter 32000, loss: 8.379502
 >> iter 33000, loss: 8.592278
 >> iter 34000, loss: 8.374075
 >> iter 35000, loss: 8.605380
 >> iter 36000, loss: 8.350197
 >> iter 37000, loss: 8.578304
 >> iter 38000, loss: 8.373833
 >> iter 39000, loss: 8.686188
 >> iter 40000, loss: 8.358357
   Number of active neurons: 2
 >> iter 41000, loss: 8.557326
 >> iter 42000, loss: 8.386771
 >> iter 43000, loss: 8.604841
 >> iter 44000, loss: 8.357696
 >> iter 45000, loss: 8.605233
 >> iter 46000, loss: 8.332059
 >> iter 47000, loss: 8.556862
 >> iter 48000, loss: 8.312356
 >> iter 49000, loss: 8.579148
 >> iter 50000, loss: 8.419289
   Number of active neurons: 2
 >> iter 51000, loss: 8.626964
 >> iter 52000, loss: 8.393673
 >> iter 53000, loss: 8.601806
 >> iter 54000, loss: 8.319249
 >> iter 55000, loss: 8.616942
 >> iter 56000, loss: 8.411175
 >> iter 57000, loss: 8.643187
 >> iter 58000, loss: 8.352571
 >> iter 59000, loss: 8.563870
 >> iter 60000, loss: 8.390216
   Number of active neurons: 2
 >> iter 61000, loss: 8.594174
 >> iter 62000, loss: 8.375234
 >> iter 63000, loss: 8.463860
 >> iter 64000, loss: 8.298834
 >> iter 65000, loss: 8.573969
 >> iter 66000, loss: 8.328016
 >> iter 67000, loss: 8.536337
 >> iter 68000, loss: 8.476035
 >> iter 69000, loss: 8.600896
 >> iter 70000, loss: 8.394100
   Number of active neurons: 2
 >> iter 71000, loss: 8.542356
 >> iter 72000, loss: 8.411517
 >> iter 73000, loss: 8.563399
 >> iter 74000, loss: 8.364739
 >> iter 75000, loss: 8.511702
 >> iter 76000, loss: 8.447381
 >> iter 77000, loss: 8.557533
 >> iter 78000, loss: 8.382374
 >> iter 79000, loss: 8.476612
 >> iter 80000, loss: 8.425627
   Number of active neurons: 2
 >> iter 81000, loss: 8.484468
 >> iter 82000, loss: 8.399916
 >> iter 83000, loss: 8.550286
 >> iter 84000, loss: 8.457096
 >> iter 85000, loss: 8.576962
 >> iter 86000, loss: 8.337302
 >> iter 87000, loss: 8.553584
 >> iter 88000, loss: 8.391632
 >> iter 89000, loss: 8.527554
 >> iter 90000, loss: 8.386196
   Number of active neurons: 2
 >> iter 91000, loss: 8.557309
 >> iter 92000, loss: 8.327314
 >> iter 93000, loss: 8.611601
 >> iter 94000, loss: 8.420119
 >> iter 95000, loss: 8.578415
 >> iter 96000, loss: 8.418196
 >> iter 97000, loss: 8.651294
 >> iter 98000, loss: 8.407751
 >> iter 99000, loss: 8.563322
 >> iter 100000, loss: 8.434647
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 11.9057618848
   - Test - Long: 2.53487325634
   - Test - Big: 11.6328836712
   - Test - A: 17.0521965202
   - Test - B: 15.325644957
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.040277
 >> iter 2000, loss: 15.013044
 >> iter 3000, loss: 12.291227
 >> iter 4000, loss: 10.974355
 >> iter 5000, loss: 10.628161
 >> iter 6000, loss: 10.389529
 >> iter 7000, loss: 10.433703
 >> iter 8000, loss: 10.355820
 >> iter 9000, loss: 10.398715
 >> iter 10000, loss: 10.303648
   Number of active neurons: 2
 >> iter 11000, loss: 10.371748
 >> iter 12000, loss: 10.293325
 >> iter 13000, loss: 10.405268
 >> iter 14000, loss: 10.260053
 >> iter 15000, loss: 10.362006
 >> iter 16000, loss: 10.286414
 >> iter 17000, loss: 10.507011
 >> iter 18000, loss: 10.387786
 >> iter 19000, loss: 10.439860
 >> iter 20000, loss: 10.292046
   Number of active neurons: 2
 >> iter 21000, loss: 10.421915
 >> iter 22000, loss: 10.245743
 >> iter 23000, loss: 10.363844
 >> iter 24000, loss: 10.171662
 >> iter 25000, loss: 10.426556
 >> iter 26000, loss: 10.306355
 >> iter 27000, loss: 10.365008
 >> iter 28000, loss: 10.254627
 >> iter 29000, loss: 10.368013
 >> iter 30000, loss: 10.198981
   Number of active neurons: 2
 >> iter 31000, loss: 10.287770
 >> iter 32000, loss: 10.206247
 >> iter 33000, loss: 10.401045
 >> iter 34000, loss: 10.221487
 >> iter 35000, loss: 10.355507
 >> iter 36000, loss: 10.179191
 >> iter 37000, loss: 10.213807
 >> iter 38000, loss: 10.100469
 >> iter 39000, loss: 10.318670
 >> iter 40000, loss: 10.156266
   Number of active neurons: 2
 >> iter 41000, loss: 10.323276
 >> iter 42000, loss: 10.152403
 >> iter 43000, loss: 10.204312
 >> iter 44000, loss: 10.051669
 >> iter 45000, loss: 10.142013
 >> iter 46000, loss: 10.090429
 >> iter 47000, loss: 10.207140
 >> iter 48000, loss: 10.151942
 >> iter 49000, loss: 10.366221
 >> iter 50000, loss: 10.062061
   Number of active neurons: 2
 >> iter 51000, loss: 10.242875
 >> iter 52000, loss: 10.070118
 >> iter 53000, loss: 10.144045
 >> iter 54000, loss: 10.026485
 >> iter 55000, loss: 10.190606
 >> iter 56000, loss: 10.116028
 >> iter 57000, loss: 10.327017
 >> iter 58000, loss: 10.186552
 >> iter 59000, loss: 10.214865
 >> iter 60000, loss: 10.204245
   Number of active neurons: 2
 >> iter 61000, loss: 10.381314
 >> iter 62000, loss: 10.089446
 >> iter 63000, loss: 10.314642
 >> iter 64000, loss: 10.161798
 >> iter 65000, loss: 10.261876
 >> iter 66000, loss: 10.116307
 >> iter 67000, loss: 10.145589
 >> iter 68000, loss: 10.070634
 >> iter 69000, loss: 10.253026
 >> iter 70000, loss: 10.113212
   Number of active neurons: 2
 >> iter 71000, loss: 10.250924
 >> iter 72000, loss: 10.070968
 >> iter 73000, loss: 10.316184
 >> iter 74000, loss: 10.114626
 >> iter 75000, loss: 10.280132
 >> iter 76000, loss: 10.122552
 >> iter 77000, loss: 10.373554
 >> iter 78000, loss: 10.176204
 >> iter 79000, loss: 10.230618
 >> iter 80000, loss: 10.072697
   Number of active neurons: 2
 >> iter 81000, loss: 10.273969
 >> iter 82000, loss: 10.107341
 >> iter 83000, loss: 10.408364
 >> iter 84000, loss: 10.129461
 >> iter 85000, loss: 10.342292
 >> iter 86000, loss: 10.070000
 >> iter 87000, loss: 10.113062
 >> iter 88000, loss: 10.009476
 >> iter 89000, loss: 10.229961
 >> iter 90000, loss: 10.073429
   Number of active neurons: 2
 >> iter 91000, loss: 10.237026
 >> iter 92000, loss: 10.111100
 >> iter 93000, loss: 10.246466
 >> iter 94000, loss: 10.125036
 >> iter 95000, loss: 10.262524
 >> iter 96000, loss: 10.065952
 >> iter 97000, loss: 10.274789
 >> iter 98000, loss: 10.084339
 >> iter 99000, loss: 10.223655
 >> iter 100000, loss: 10.120654
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 18.5096298074
   - Test - Long: 3.97980100995
   - Test - Big: 18.5118148819
   - Test - A: 64.9423371775
   - Test - B: 15.5722951803
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.113770
 >> iter 2000, loss: 13.830402
 >> iter 3000, loss: 11.366587
 >> iter 4000, loss: 9.776819
 >> iter 5000, loss: 9.346994
 >> iter 6000, loss: 8.695992
 >> iter 7000, loss: 8.790790
 >> iter 8000, loss: 8.480754
 >> iter 9000, loss: 8.633280
 >> iter 10000, loss: 8.471266
   Number of active neurons: 2
 >> iter 11000, loss: 8.633285
 >> iter 12000, loss: 8.438730
 >> iter 13000, loss: 8.617906
 >> iter 14000, loss: 8.424938
 >> iter 15000, loss: 8.604862
 >> iter 16000, loss: 8.493947
 >> iter 17000, loss: 8.660117
 >> iter 18000, loss: 8.423576
 >> iter 19000, loss: 8.603624
 >> iter 20000, loss: 8.414925
   Number of active neurons: 2
 >> iter 21000, loss: 8.609175
 >> iter 22000, loss: 8.480513
 >> iter 23000, loss: 8.711274
 >> iter 24000, loss: 8.514246
 >> iter 25000, loss: 8.690596
 >> iter 26000, loss: 8.462821
 >> iter 27000, loss: 8.630053
 >> iter 28000, loss: 8.406312
 >> iter 29000, loss: 8.575214
 >> iter 30000, loss: 8.386629
   Number of active neurons: 2
 >> iter 31000, loss: 8.582140
 >> iter 32000, loss: 8.357597
 >> iter 33000, loss: 8.696074
 >> iter 34000, loss: 8.330644
 >> iter 35000, loss: 8.613065
 >> iter 36000, loss: 8.329874
 >> iter 37000, loss: 8.664026
 >> iter 38000, loss: 8.422584
 >> iter 39000, loss: 8.624317
 >> iter 40000, loss: 8.379731
   Number of active neurons: 2
 >> iter 41000, loss: 8.592637
 >> iter 42000, loss: 8.354045
 >> iter 43000, loss: 8.577165
 >> iter 44000, loss: 8.378400
 >> iter 45000, loss: 8.667204
 >> iter 46000, loss: 8.414242
 >> iter 47000, loss: 8.640533
 >> iter 48000, loss: 8.330395
 >> iter 49000, loss: 8.629016
 >> iter 50000, loss: 8.345958
   Number of active neurons: 2
 >> iter 51000, loss: 8.598267
 >> iter 52000, loss: 8.348544
 >> iter 53000, loss: 8.563437
 >> iter 54000, loss: 8.346049
 >> iter 55000, loss: 8.618199
 >> iter 56000, loss: 8.412378
 >> iter 57000, loss: 8.609320
 >> iter 58000, loss: 8.424216
 >> iter 59000, loss: 8.570253
 >> iter 60000, loss: 8.373572
   Number of active neurons: 2
 >> iter 61000, loss: 8.613323
 >> iter 62000, loss: 8.460675
 >> iter 63000, loss: 8.620344
 >> iter 64000, loss: 8.509997
 >> iter 65000, loss: 8.617978
 >> iter 66000, loss: 8.480692
 >> iter 67000, loss: 8.599606
 >> iter 68000, loss: 8.467677
 >> iter 69000, loss: 8.589392
 >> iter 70000, loss: 8.371792
   Number of active neurons: 2
 >> iter 71000, loss: 8.618443
 >> iter 72000, loss: 8.497932
 >> iter 73000, loss: 8.713306
 >> iter 74000, loss: 8.399800
 >> iter 75000, loss: 8.551813
 >> iter 76000, loss: 8.380287
 >> iter 77000, loss: 8.540421
 >> iter 78000, loss: 8.419799
 >> iter 79000, loss: 8.723306
 >> iter 80000, loss: 8.477151
   Number of active neurons: 2
 >> iter 81000, loss: 8.632679
 >> iter 82000, loss: 8.397807
 >> iter 83000, loss: 8.618284
 >> iter 84000, loss: 8.429083
 >> iter 85000, loss: 8.568932
 >> iter 86000, loss: 8.339393
 >> iter 87000, loss: 8.541894
 >> iter 88000, loss: 8.344325
 >> iter 89000, loss: 8.527250
 >> iter 90000, loss: 8.394313
   Number of active neurons: 2
 >> iter 91000, loss: 8.526197
 >> iter 92000, loss: 8.397852
 >> iter 93000, loss: 8.591255
 >> iter 94000, loss: 8.494378
 >> iter 95000, loss: 8.644063
 >> iter 96000, loss: 8.427843
 >> iter 97000, loss: 8.533885
 >> iter 98000, loss: 8.446177
 >> iter 99000, loss: 8.499581
 >> iter 100000, loss: 8.394598
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 12.3237535249
   - Test - Long: 2.71486425679
   - Test - Big: 11.9188808112
   - Test - A: 17.0521965202
   - Test - B: 27.6648223452
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.105360
 >> iter 2000, loss: 15.043933
 >> iter 3000, loss: 14.281571
 >> iter 4000, loss: 13.583574
 >> iter 5000, loss: 13.622414
 >> iter 6000, loss: 13.285098
 >> iter 7000, loss: 13.456966
 >> iter 8000, loss: 12.209127
 >> iter 9000, loss: 11.788608
 >> iter 10000, loss: 11.332077
   Number of active neurons: 2
 >> iter 11000, loss: 11.400307
 >> iter 12000, loss: 11.189091
 >> iter 13000, loss: 11.309059
 >> iter 14000, loss: 11.048221
 >> iter 15000, loss: 11.411656
 >> iter 16000, loss: 11.109219
 >> iter 17000, loss: 11.199410
 >> iter 18000, loss: 11.161905
 >> iter 19000, loss: 11.319249
 >> iter 20000, loss: 11.016705
   Number of active neurons: 2
 >> iter 21000, loss: 11.203184
 >> iter 22000, loss: 11.065412
 >> iter 23000, loss: 11.346865
 >> iter 24000, loss: 11.076045
 >> iter 25000, loss: 11.422078
 >> iter 26000, loss: 11.068675
 >> iter 27000, loss: 11.214454
 >> iter 28000, loss: 11.053188
 >> iter 29000, loss: 11.256525
 >> iter 30000, loss: 11.108449
   Number of active neurons: 2
 >> iter 31000, loss: 11.278065
 >> iter 32000, loss: 11.171409
 >> iter 33000, loss: 11.391788
 >> iter 34000, loss: 11.138779
 >> iter 35000, loss: 11.372790
 >> iter 36000, loss: 11.111575
 >> iter 37000, loss: 11.280392
 >> iter 38000, loss: 11.229069
 >> iter 39000, loss: 11.294599
 >> iter 40000, loss: 11.094741
   Number of active neurons: 2
 >> iter 41000, loss: 11.234808
 >> iter 42000, loss: 11.051278
 >> iter 43000, loss: 11.213712
 >> iter 44000, loss: 11.019208
 >> iter 45000, loss: 11.237733
 >> iter 46000, loss: 11.095084
 >> iter 47000, loss: 11.389004
 >> iter 48000, loss: 11.131628
 >> iter 49000, loss: 11.277673
 >> iter 50000, loss: 11.148611
   Number of active neurons: 2
 >> iter 51000, loss: 11.249538
 >> iter 52000, loss: 11.236224
 >> iter 53000, loss: 11.407440
 >> iter 54000, loss: 11.319907
 >> iter 55000, loss: 11.345163
 >> iter 56000, loss: 11.232736
 >> iter 57000, loss: 11.252894
 >> iter 58000, loss: 11.299999
 >> iter 59000, loss: 11.478617
 >> iter 60000, loss: 11.181078
   Number of active neurons: 2
 >> iter 61000, loss: 11.237729
 >> iter 62000, loss: 11.139943
 >> iter 63000, loss: 11.337086
 >> iter 64000, loss: 11.221229
 >> iter 65000, loss: 11.387983
 >> iter 66000, loss: 11.165735
 >> iter 67000, loss: 11.394187
 >> iter 68000, loss: 11.143450
 >> iter 69000, loss: 11.246954
 >> iter 70000, loss: 11.247407
   Number of active neurons: 2
 >> iter 71000, loss: 11.265735
 >> iter 72000, loss: 11.269464
 >> iter 73000, loss: 11.615596
 >> iter 74000, loss: 11.273604
 >> iter 75000, loss: 11.475709
 >> iter 76000, loss: 11.295589
 >> iter 77000, loss: 11.270071
 >> iter 78000, loss: 11.154961
 >> iter 79000, loss: 11.282493
 >> iter 80000, loss: 11.161900
   Number of active neurons: 2
 >> iter 81000, loss: 11.153036
 >> iter 82000, loss: 11.146815
 >> iter 83000, loss: 11.208218
 >> iter 84000, loss: 11.285180
 >> iter 85000, loss: 11.364068
 >> iter 86000, loss: 11.218131
 >> iter 87000, loss: 11.490327
 >> iter 88000, loss: 11.202416
 >> iter 89000, loss: 11.426407
 >> iter 90000, loss: 11.307817
   Number of active neurons: 2
 >> iter 91000, loss: 11.397865
 >> iter 92000, loss: 11.168246
 >> iter 93000, loss: 11.365255
 >> iter 94000, loss: 11.338147
 >> iter 95000, loss: 11.419306
 >> iter 96000, loss: 11.299722
 >> iter 97000, loss: 11.269420
 >> iter 98000, loss: 11.156487
 >> iter 99000, loss: 11.378209
 >> iter 100000, loss: 11.295404
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 24.7915041699
   - Test - Long: 4.50977451127
   - Test - Big: 24.4837551624
   - Test - A: 69.1087260849
   - Test - B: 16.1789214052
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.591825
 >> iter 2000, loss: 13.290841
 >> iter 3000, loss: 11.130867
 >> iter 4000, loss: 9.627998
 >> iter 5000, loss: 9.241034
 >> iter 6000, loss: 8.636620
 >> iter 7000, loss: 8.791478
 >> iter 8000, loss: 8.490184
 >> iter 9000, loss: 8.620515
 >> iter 10000, loss: 8.478430
   Number of active neurons: 2
 >> iter 11000, loss: 8.596733
 >> iter 12000, loss: 8.411185
 >> iter 13000, loss: 8.516834
 >> iter 14000, loss: 8.451977
 >> iter 15000, loss: 8.667477
 >> iter 16000, loss: 8.514957
 >> iter 17000, loss: 8.621141
 >> iter 18000, loss: 8.476259
 >> iter 19000, loss: 8.593348
 >> iter 20000, loss: 8.421837
   Number of active neurons: 2
 >> iter 21000, loss: 8.580658
 >> iter 22000, loss: 8.409849
 >> iter 23000, loss: 8.619233
 >> iter 24000, loss: 8.445832
 >> iter 25000, loss: 8.609637
 >> iter 26000, loss: 8.419339
 >> iter 27000, loss: 8.595041
 >> iter 28000, loss: 8.357176
 >> iter 29000, loss: 8.609505
 >> iter 30000, loss: 8.370150
   Number of active neurons: 2
 >> iter 31000, loss: 8.566524
 >> iter 32000, loss: 8.381669
 >> iter 33000, loss: 8.650013
 >> iter 34000, loss: 8.436577
 >> iter 35000, loss: 8.689739
 >> iter 36000, loss: 8.400286
 >> iter 37000, loss: 8.623892
 >> iter 38000, loss: 8.383515
 >> iter 39000, loss: 8.598922
 >> iter 40000, loss: 8.328984
   Number of active neurons: 2
 >> iter 41000, loss: 8.668302
 >> iter 42000, loss: 8.303006
 >> iter 43000, loss: 8.614360
 >> iter 44000, loss: 8.402970
 >> iter 45000, loss: 8.643297
 >> iter 46000, loss: 8.461194
 >> iter 47000, loss: 8.672197
 >> iter 48000, loss: 8.362258
 >> iter 49000, loss: 8.544613
 >> iter 50000, loss: 8.299080
   Number of active neurons: 2
 >> iter 51000, loss: 8.541595
 >> iter 52000, loss: 8.388896
 >> iter 53000, loss: 8.642726
 >> iter 54000, loss: 8.404251
 >> iter 55000, loss: 8.566976
 >> iter 56000, loss: 8.354144
 >> iter 57000, loss: 8.562812
 >> iter 58000, loss: 8.463482
 >> iter 59000, loss: 8.620861
 >> iter 60000, loss: 8.484871
   Number of active neurons: 2
 >> iter 61000, loss: 8.666544
 >> iter 62000, loss: 8.395613
 >> iter 63000, loss: 8.566991
 >> iter 64000, loss: 8.453620
 >> iter 65000, loss: 8.614825
 >> iter 66000, loss: 8.543585
 >> iter 67000, loss: 8.636979
 >> iter 68000, loss: 8.377879
 >> iter 69000, loss: 8.663715
 >> iter 70000, loss: 8.417452
   Number of active neurons: 2
 >> iter 71000, loss: 8.615410
 >> iter 72000, loss: 8.473975
 >> iter 73000, loss: 8.536600
 >> iter 74000, loss: 8.415654
 >> iter 75000, loss: 8.716539
 >> iter 76000, loss: 8.491495
 >> iter 77000, loss: 8.611695
 >> iter 78000, loss: 8.422299
 >> iter 79000, loss: 8.507144
 >> iter 80000, loss: 8.410493
   Number of active neurons: 2
 >> iter 81000, loss: 8.602064
 >> iter 82000, loss: 8.499601
 >> iter 83000, loss: 8.660699
 >> iter 84000, loss: 8.422095
 >> iter 85000, loss: 8.525588
 >> iter 86000, loss: 8.403968
 >> iter 87000, loss: 8.598974
 >> iter 88000, loss: 8.466461
 >> iter 89000, loss: 8.616994
 >> iter 90000, loss: 8.511843
   Number of active neurons: 2
 >> iter 91000, loss: 8.580516
 >> iter 92000, loss: 8.318301
 >> iter 93000, loss: 8.421820
 >> iter 94000, loss: 8.241776
 >> iter 95000, loss: 8.481901
 >> iter 96000, loss: 8.444937
 >> iter 97000, loss: 8.565791
 >> iter 98000, loss: 8.478612
 >> iter 99000, loss: 8.548823
 >> iter 100000, loss: 8.352369
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 12.2997540049
   - Test - Long: 2.78486075696
   - Test - Big: 11.8688813112
   - Test - A: 17.0521965202
   - Test - B: 26.6582227851
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.105908
 >> iter 2000, loss: 13.935063
 >> iter 3000, loss: 11.410788
 >> iter 4000, loss: 9.747786
 >> iter 5000, loss: 9.323409
 >> iter 6000, loss: 8.637337
 >> iter 7000, loss: 8.772042
 >> iter 8000, loss: 8.503507
 >> iter 9000, loss: 8.635923
 >> iter 10000, loss: 8.452279
   Number of active neurons: 2
 >> iter 11000, loss: 8.624885
 >> iter 12000, loss: 8.480999
 >> iter 13000, loss: 8.559323
 >> iter 14000, loss: 8.418253
 >> iter 15000, loss: 8.599425
 >> iter 16000, loss: 8.441048
 >> iter 17000, loss: 8.597899
 >> iter 18000, loss: 8.392376
 >> iter 19000, loss: 8.554110
 >> iter 20000, loss: 8.376586
   Number of active neurons: 2
 >> iter 21000, loss: 8.685190
 >> iter 22000, loss: 8.457305
 >> iter 23000, loss: 8.619636
 >> iter 24000, loss: 8.425677
 >> iter 25000, loss: 8.635550
 >> iter 26000, loss: 8.379369
 >> iter 27000, loss: 8.572947
 >> iter 28000, loss: 8.425425
 >> iter 29000, loss: 8.609327
 >> iter 30000, loss: 8.407971
   Number of active neurons: 2
 >> iter 31000, loss: 8.559942
 >> iter 32000, loss: 8.346593
 >> iter 33000, loss: 8.608775
 >> iter 34000, loss: 8.392061
 >> iter 35000, loss: 8.635580
 >> iter 36000, loss: 8.377391
 >> iter 37000, loss: 8.604431
 >> iter 38000, loss: 8.363366
 >> iter 39000, loss: 8.598984
 >> iter 40000, loss: 8.288441
   Number of active neurons: 2
 >> iter 41000, loss: 8.586167
 >> iter 42000, loss: 8.350541
 >> iter 43000, loss: 8.618680
 >> iter 44000, loss: 8.343289
 >> iter 45000, loss: 8.612121
 >> iter 46000, loss: 8.317514
 >> iter 47000, loss: 8.621069
 >> iter 48000, loss: 8.295418
 >> iter 49000, loss: 8.584304
 >> iter 50000, loss: 8.322582
   Number of active neurons: 2
 >> iter 51000, loss: 8.605081
 >> iter 52000, loss: 8.470675
 >> iter 53000, loss: 8.663358
 >> iter 54000, loss: 8.461158
 >> iter 55000, loss: 8.580177
 >> iter 56000, loss: 8.420381
 >> iter 57000, loss: 8.641661
 >> iter 58000, loss: 8.428480
 >> iter 59000, loss: 8.615846
 >> iter 60000, loss: 8.389720
   Number of active neurons: 2
 >> iter 61000, loss: 8.578339
 >> iter 62000, loss: 8.448331
 >> iter 63000, loss: 8.628748
 >> iter 64000, loss: 8.439789
 >> iter 65000, loss: 8.629403
 >> iter 66000, loss: 8.363919
 >> iter 67000, loss: 8.566682
 >> iter 68000, loss: 8.474605
 >> iter 69000, loss: 8.590778
 >> iter 70000, loss: 8.348455
   Number of active neurons: 2
 >> iter 71000, loss: 8.584127
 >> iter 72000, loss: 8.447954
 >> iter 73000, loss: 8.633428
 >> iter 74000, loss: 8.382178
 >> iter 75000, loss: 8.578224
 >> iter 76000, loss: 8.465872
 >> iter 77000, loss: 8.614911
 >> iter 78000, loss: 8.460872
 >> iter 79000, loss: 8.613219
 >> iter 80000, loss: 8.475943
   Number of active neurons: 2
 >> iter 81000, loss: 8.650891
 >> iter 82000, loss: 8.429845
 >> iter 83000, loss: 8.554247
 >> iter 84000, loss: 8.433845
 >> iter 85000, loss: 8.563125
 >> iter 86000, loss: 8.409495
 >> iter 87000, loss: 8.594877
 >> iter 88000, loss: 8.365958
 >> iter 89000, loss: 8.541532
 >> iter 90000, loss: 8.424106
   Number of active neurons: 2
 >> iter 91000, loss: 8.621055
 >> iter 92000, loss: 8.383863
 >> iter 93000, loss: 8.506128
 >> iter 94000, loss: 8.433540
 >> iter 95000, loss: 8.556941
 >> iter 96000, loss: 8.339593
 >> iter 97000, loss: 8.583128
 >> iter 98000, loss: 8.330399
 >> iter 99000, loss: 8.439774
 >> iter 100000, loss: 8.382999
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 12.2777544449
   - Test - Long: 2.67486625669
   - Test - Big: 11.8738812612
   - Test - A: 17.0521965202
   - Test - B: 26.6582227851
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.137574
 >> iter 2000, loss: 14.214259
 >> iter 3000, loss: 11.538559
 >> iter 4000, loss: 9.825609
 >> iter 5000, loss: 9.333654
 >> iter 6000, loss: 8.641203
 >> iter 7000, loss: 8.787896
 >> iter 8000, loss: 8.521303
 >> iter 9000, loss: 8.653684
 >> iter 10000, loss: 8.473008
   Number of active neurons: 2
 >> iter 11000, loss: 8.622000
 >> iter 12000, loss: 8.531643
 >> iter 13000, loss: 8.614089
 >> iter 14000, loss: 8.466623
 >> iter 15000, loss: 8.615678
 >> iter 16000, loss: 8.500095
 >> iter 17000, loss: 8.683313
 >> iter 18000, loss: 8.385207
 >> iter 19000, loss: 8.522441
 >> iter 20000, loss: 8.428999
   Number of active neurons: 2
 >> iter 21000, loss: 8.670376
 >> iter 22000, loss: 8.457187
 >> iter 23000, loss: 8.670164
 >> iter 24000, loss: 8.468616
 >> iter 25000, loss: 8.616890
 >> iter 26000, loss: 8.410167
 >> iter 27000, loss: 8.649775
 >> iter 28000, loss: 8.414239
 >> iter 29000, loss: 8.618161
 >> iter 30000, loss: 8.379703
   Number of active neurons: 2
 >> iter 31000, loss: 8.553865
 >> iter 32000, loss: 8.394103
 >> iter 33000, loss: 8.603134
 >> iter 34000, loss: 8.381702
 >> iter 35000, loss: 8.598210
 >> iter 36000, loss: 8.373393
 >> iter 37000, loss: 8.582265
 >> iter 38000, loss: 8.300292
 >> iter 39000, loss: 8.577963
 >> iter 40000, loss: 8.372114
   Number of active neurons: 2
 >> iter 41000, loss: 8.669072
 >> iter 42000, loss: 8.363195
 >> iter 43000, loss: 8.637080
 >> iter 44000, loss: 8.367410
 >> iter 45000, loss: 8.635168
 >> iter 46000, loss: 8.447659
 >> iter 47000, loss: 8.651246
 >> iter 48000, loss: 8.306538
 >> iter 49000, loss: 8.578721
 >> iter 50000, loss: 8.393087
   Number of active neurons: 2
 >> iter 51000, loss: 8.561234
 >> iter 52000, loss: 8.321723
 >> iter 53000, loss: 8.605360
 >> iter 54000, loss: 8.439791
 >> iter 55000, loss: 8.604576
 >> iter 56000, loss: 8.357300
 >> iter 57000, loss: 8.592664
 >> iter 58000, loss: 8.451981
 >> iter 59000, loss: 8.660875
 >> iter 60000, loss: 8.464291
   Number of active neurons: 2
 >> iter 61000, loss: 8.622055
 >> iter 62000, loss: 8.531856
 >> iter 63000, loss: 8.675288
 >> iter 64000, loss: 8.523302
 >> iter 65000, loss: 8.636154
 >> iter 66000, loss: 8.495568
 >> iter 67000, loss: 8.635901
 >> iter 68000, loss: 8.452877
 >> iter 69000, loss: 8.731542
 >> iter 70000, loss: 8.580094
   Number of active neurons: 2
 >> iter 71000, loss: 8.657909
 >> iter 72000, loss: 8.447591
 >> iter 73000, loss: 8.567169
 >> iter 74000, loss: 8.382227
 >> iter 75000, loss: 8.567257
 >> iter 76000, loss: 8.438314
 >> iter 77000, loss: 8.571964
 >> iter 78000, loss: 8.437362
 >> iter 79000, loss: 8.534392
 >> iter 80000, loss: 8.475659
   Number of active neurons: 2
 >> iter 81000, loss: 8.536963
 >> iter 82000, loss: 8.401467
 >> iter 83000, loss: 8.567206
 >> iter 84000, loss: 8.471370
 >> iter 85000, loss: 8.655746
 >> iter 86000, loss: 8.482538
 >> iter 87000, loss: 8.628772
 >> iter 88000, loss: 8.348509
 >> iter 89000, loss: 8.518786
 >> iter 90000, loss: 8.475235
   Number of active neurons: 2
 >> iter 91000, loss: 8.651085
 >> iter 92000, loss: 8.390730
 >> iter 93000, loss: 8.525675
 >> iter 94000, loss: 8.354785
 >> iter 95000, loss: 8.661752
 >> iter 96000, loss: 8.382621
 >> iter 97000, loss: 8.565545
 >> iter 98000, loss: 8.384104
 >> iter 99000, loss: 8.610901
 >> iter 100000, loss: 8.430403
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 12.2777544449
   - Test - Long: 2.67486625669
   - Test - Big: 11.8738812612
   - Test - A: 17.0521965202
   - Test - B: 26.6582227851
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.002221
 >> iter 2000, loss: 14.611716
 >> iter 3000, loss: 12.759878
 >> iter 4000, loss: 11.800265
 >> iter 5000, loss: 11.543245
 >> iter 6000, loss: 11.223972
 >> iter 7000, loss: 11.343451
 >> iter 8000, loss: 11.195084
 >> iter 9000, loss: 11.361588
 >> iter 10000, loss: 11.149059
   Number of active neurons: 2
 >> iter 11000, loss: 11.357295
 >> iter 12000, loss: 11.122726
 >> iter 13000, loss: 11.252139
 >> iter 14000, loss: 11.073976
 >> iter 15000, loss: 11.272613
 >> iter 16000, loss: 11.084244
 >> iter 17000, loss: 11.252328
 >> iter 18000, loss: 11.051530
 >> iter 19000, loss: 11.244419
 >> iter 20000, loss: 11.031416
   Number of active neurons: 2
 >> iter 21000, loss: 11.248803
 >> iter 22000, loss: 11.058063
 >> iter 23000, loss: 11.232171
 >> iter 24000, loss: 11.004876
 >> iter 25000, loss: 11.137421
 >> iter 26000, loss: 10.938704
 >> iter 27000, loss: 11.178067
 >> iter 28000, loss: 10.959580
 >> iter 29000, loss: 11.189601
 >> iter 30000, loss: 10.954669
   Number of active neurons: 2
 >> iter 31000, loss: 11.190171
 >> iter 32000, loss: 11.099539
 >> iter 33000, loss: 11.341219
 >> iter 34000, loss: 11.141065
 >> iter 35000, loss: 11.253203
 >> iter 36000, loss: 11.003619
 >> iter 37000, loss: 11.205967
 >> iter 38000, loss: 11.120895
 >> iter 39000, loss: 11.283500
 >> iter 40000, loss: 11.124458
   Number of active neurons: 2
 >> iter 41000, loss: 11.252970
 >> iter 42000, loss: 11.059613
 >> iter 43000, loss: 11.191170
 >> iter 44000, loss: 11.180551
 >> iter 45000, loss: 11.428272
 >> iter 46000, loss: 11.091357
 >> iter 47000, loss: 11.265886
 >> iter 48000, loss: 11.206035
 >> iter 49000, loss: 11.325031
 >> iter 50000, loss: 11.261392
   Number of active neurons: 2
 >> iter 51000, loss: 11.216332
 >> iter 52000, loss: 11.042539
 >> iter 53000, loss: 11.281835
 >> iter 54000, loss: 11.223518
 >> iter 55000, loss: 11.245116
 >> iter 56000, loss: 11.133740
 >> iter 57000, loss: 11.270845
 >> iter 58000, loss: 11.128244
 >> iter 59000, loss: 11.328051
 >> iter 60000, loss: 11.222884
   Number of active neurons: 2
 >> iter 61000, loss: 11.255042
 >> iter 62000, loss: 11.242150
 >> iter 63000, loss: 11.557598
 >> iter 64000, loss: 11.569036
 >> iter 65000, loss: 11.686660
 >> iter 66000, loss: 11.612419
 >> iter 67000, loss: 11.696043
 >> iter 68000, loss: 11.615197
 >> iter 69000, loss: 11.694915
 >> iter 70000, loss: 11.610998
   Number of active neurons: 2
 >> iter 71000, loss: 11.709429
 >> iter 72000, loss: 11.603953
 >> iter 73000, loss: 11.723968
 >> iter 74000, loss: 11.601200
 >> iter 75000, loss: 11.720166
 >> iter 76000, loss: 11.604834
 >> iter 77000, loss: 11.713641
 >> iter 78000, loss: 11.605906
 >> iter 79000, loss: 11.714311
 >> iter 80000, loss: 11.610683
   Number of active neurons: 2
 >> iter 81000, loss: 11.710797
 >> iter 82000, loss: 11.610000
 >> iter 83000, loss: 11.715659
 >> iter 84000, loss: 11.607508
 >> iter 85000, loss: 11.725895
 >> iter 86000, loss: 11.605198
 >> iter 87000, loss: 11.725998
 >> iter 88000, loss: 11.606075
 >> iter 89000, loss: 11.724497
 >> iter 90000, loss: 11.605418
   Number of active neurons: 2
 >> iter 91000, loss: 11.722410
 >> iter 92000, loss: 11.600156
 >> iter 93000, loss: 11.719258
 >> iter 94000, loss: 11.598859
 >> iter 95000, loss: 11.719704
 >> iter 96000, loss: 11.592669
 >> iter 97000, loss: 11.713457
 >> iter 98000, loss: 11.586289
 >> iter 99000, loss: 11.711005
 >> iter 100000, loss: 11.584167
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 22.6495470091
   - Test - Long: 4.48477576121
   - Test - Big: 22.5077749223
   - Test - A: 69.0487300847
   - Test - B: 16.1655889607
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.195353
 >> iter 2000, loss: 14.233840
 >> iter 3000, loss: 11.543239
 >> iter 4000, loss: 9.816111
 >> iter 5000, loss: 9.312617
 >> iter 6000, loss: 8.692751
 >> iter 7000, loss: 8.811386
 >> iter 8000, loss: 8.506729
 >> iter 9000, loss: 8.656908
 >> iter 10000, loss: 8.450839
   Number of active neurons: 2
 >> iter 11000, loss: 8.607293
 >> iter 12000, loss: 8.496585
 >> iter 13000, loss: 8.618400
 >> iter 14000, loss: 8.439922
 >> iter 15000, loss: 8.584335
 >> iter 16000, loss: 8.446154
 >> iter 17000, loss: 8.628603
 >> iter 18000, loss: 8.405307
 >> iter 19000, loss: 8.603711
 >> iter 20000, loss: 8.415044
   Number of active neurons: 2
 >> iter 21000, loss: 8.637996
 >> iter 22000, loss: 8.443622
 >> iter 23000, loss: 8.613815
 >> iter 24000, loss: 8.435439
 >> iter 25000, loss: 8.656300
 >> iter 26000, loss: 8.368733
 >> iter 27000, loss: 8.581555
 >> iter 28000, loss: 8.321589
 >> iter 29000, loss: 8.557640
 >> iter 30000, loss: 8.328423
   Number of active neurons: 2
 >> iter 31000, loss: 8.590801
 >> iter 32000, loss: 8.374378
 >> iter 33000, loss: 8.595272
 >> iter 34000, loss: 8.343871
 >> iter 35000, loss: 8.575370
 >> iter 36000, loss: 8.343022
 >> iter 37000, loss: 8.610675
 >> iter 38000, loss: 8.290780
 >> iter 39000, loss: 8.477314
 >> iter 40000, loss: 8.335042
   Number of active neurons: 2
 >> iter 41000, loss: 8.593168
 >> iter 42000, loss: 8.360360
 >> iter 43000, loss: 8.528262
 >> iter 44000, loss: 8.387876
 >> iter 45000, loss: 8.648443
 >> iter 46000, loss: 8.356470
 >> iter 47000, loss: 8.579838
 >> iter 48000, loss: 8.330231
 >> iter 49000, loss: 8.586325
 >> iter 50000, loss: 8.396106
   Number of active neurons: 2
 >> iter 51000, loss: 8.626419
 >> iter 52000, loss: 8.346945
 >> iter 53000, loss: 8.581712
 >> iter 54000, loss: 8.291500
 >> iter 55000, loss: 8.600109
 >> iter 56000, loss: 8.418517
 >> iter 57000, loss: 8.573906
 >> iter 58000, loss: 8.447259
 >> iter 59000, loss: 8.576801
 >> iter 60000, loss: 8.385858
   Number of active neurons: 2
 >> iter 61000, loss: 8.601248
 >> iter 62000, loss: 8.464659
 >> iter 63000, loss: 8.632008
 >> iter 64000, loss: 8.463501
 >> iter 65000, loss: 8.637231
 >> iter 66000, loss: 8.503346
 >> iter 67000, loss: 8.767540
 >> iter 68000, loss: 8.538391
 >> iter 69000, loss: 8.663224
 >> iter 70000, loss: 8.497522
   Number of active neurons: 2
 >> iter 71000, loss: 8.634988
 >> iter 72000, loss: 8.420022
 >> iter 73000, loss: 8.614905
 >> iter 74000, loss: 8.405074
 >> iter 75000, loss: 8.583170
 >> iter 76000, loss: 8.422866
 >> iter 77000, loss: 8.553572
 >> iter 78000, loss: 8.404843
 >> iter 79000, loss: 8.558745
 >> iter 80000, loss: 8.398063
   Number of active neurons: 2
 >> iter 81000, loss: 8.510766
 >> iter 82000, loss: 8.464821
 >> iter 83000, loss: 8.700293
 >> iter 84000, loss: 8.478644
 >> iter 85000, loss: 8.593322
 >> iter 86000, loss: 8.365953
 >> iter 87000, loss: 8.460325
 >> iter 88000, loss: 8.341026
 >> iter 89000, loss: 8.544632
 >> iter 90000, loss: 8.405845
   Number of active neurons: 2
 >> iter 91000, loss: 8.498355
 >> iter 92000, loss: 8.404228
 >> iter 93000, loss: 8.493100
 >> iter 94000, loss: 8.327176
 >> iter 95000, loss: 8.509746
 >> iter 96000, loss: 8.313049
 >> iter 97000, loss: 8.378244
 >> iter 98000, loss: 8.354499
 >> iter 99000, loss: 8.471312
 >> iter 100000, loss: 8.346708
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 12.591748165
   - Test - Long: 4.64476776161
   - Test - Big: 12.1608783912
   - Test - A: 17.0521965202
   - Test - B: 29.8246783548

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

