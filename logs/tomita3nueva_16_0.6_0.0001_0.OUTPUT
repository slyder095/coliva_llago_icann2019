 > Problema: tomita3nueva
 > Args:
   - Hidden size: 16
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.938194
 >> iter 2000, loss: 11.114184
 >> iter 3000, loss: 5.012212
 >> iter 4000, loss: 2.310118
 >> iter 5000, loss: 1.163498
 >> iter 6000, loss: 0.803961
 >> iter 7000, loss: 0.558398
 >> iter 8000, loss: 0.402787
 >> iter 9000, loss: 0.362747
 >> iter 10000, loss: 0.462205
   Number of active neurons: 8
 >> iter 11000, loss: 0.483520
 >> iter 12000, loss: 0.488172
 >> iter 13000, loss: 0.493382
 >> iter 14000, loss: 0.397453
 >> iter 15000, loss: 0.334438
 >> iter 16000, loss: 0.344624
 >> iter 17000, loss: 0.377213
 >> iter 18000, loss: 0.370071
 >> iter 19000, loss: 0.345063
 >> iter 20000, loss: 0.397236
   Number of active neurons: 8
 >> iter 21000, loss: 0.358422
 >> iter 22000, loss: 0.263482
 >> iter 23000, loss: 0.323951
 >> iter 24000, loss: 0.253321
 >> iter 25000, loss: 0.221377
 >> iter 26000, loss: 0.267716
 >> iter 27000, loss: 0.327849
 >> iter 28000, loss: 0.276910
 >> iter 29000, loss: 0.265875
 >> iter 30000, loss: 0.324613
   Number of active neurons: 8
 >> iter 31000, loss: 0.510061
 >> iter 32000, loss: 0.468616
 >> iter 33000, loss: 0.397536
 >> iter 34000, loss: 0.297452
 >> iter 35000, loss: 0.169565
 >> iter 36000, loss: 0.242261
 >> iter 37000, loss: 0.254733
 >> iter 38000, loss: 0.196443
 >> iter 39000, loss: 0.293482
 >> iter 40000, loss: 0.191489
   Number of active neurons: 7
 >> iter 41000, loss: 0.236975
 >> iter 42000, loss: 0.350010
 >> iter 43000, loss: 0.251544
 >> iter 44000, loss: 0.269805
 >> iter 45000, loss: 0.229341
 >> iter 46000, loss: 0.400927
 >> iter 47000, loss: 0.288250
 >> iter 48000, loss: 0.344012
 >> iter 49000, loss: 0.307298
 >> iter 50000, loss: 0.319728
   Number of active neurons: 7
 >> iter 51000, loss: 0.231236
 >> iter 52000, loss: 0.261538
 >> iter 53000, loss: 0.189945
 >> iter 54000, loss: 0.247433
 >> iter 55000, loss: 0.163471
 >> iter 56000, loss: 0.443988
 >> iter 57000, loss: 0.444341
 >> iter 58000, loss: 0.356672
 >> iter 59000, loss: 0.202179
 >> iter 60000, loss: 0.241943
   Number of active neurons: 7
 >> iter 61000, loss: 0.183396
 >> iter 62000, loss: 0.252684
 >> iter 63000, loss: 0.292120
 >> iter 64000, loss: 0.264787
 >> iter 65000, loss: 0.204882
 >> iter 66000, loss: 0.245791
 >> iter 67000, loss: 0.335626
 >> iter 68000, loss: 0.309721
 >> iter 69000, loss: 0.302148
 >> iter 70000, loss: 0.427300
   Number of active neurons: 6
 >> iter 71000, loss: 0.318002
 >> iter 72000, loss: 0.196715
 >> iter 73000, loss: 0.175104
 >> iter 74000, loss: 0.199418
 >> iter 75000, loss: 0.145077
 >> iter 76000, loss: 0.150984
 >> iter 77000, loss: 0.260617
 >> iter 78000, loss: 0.204688
 >> iter 79000, loss: 0.286654
 >> iter 80000, loss: 0.171070
   Number of active neurons: 6
 >> iter 81000, loss: 0.185201
 >> iter 82000, loss: 0.289957
 >> iter 83000, loss: 0.202412
 >> iter 84000, loss: 0.255741
 >> iter 85000, loss: 0.281668
 >> iter 86000, loss: 0.265856
 >> iter 87000, loss: 0.360583
 >> iter 88000, loss: 0.247427
 >> iter 89000, loss: 0.224849
 >> iter 90000, loss: 0.202927
   Number of active neurons: 6
 >> iter 91000, loss: 0.328932
 >> iter 92000, loss: 0.223265
 >> iter 93000, loss: 0.194941
 >> iter 94000, loss: 0.193713
 >> iter 95000, loss: 0.319197
 >> iter 96000, loss: 0.307313
 >> iter 97000, loss: 0.293756
 >> iter 98000, loss: 0.241022
 >> iter 99000, loss: 0.165524
 >> iter 100000, loss: 0.171712
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.214769
 >> iter 2000, loss: 14.573634
 >> iter 3000, loss: 9.888101
 >> iter 4000, loss: 5.292384
 >> iter 5000, loss: 3.316121
 >> iter 6000, loss: 2.136156
 >> iter 7000, loss: 1.573426
 >> iter 8000, loss: 1.204295
 >> iter 9000, loss: 0.883079
 >> iter 10000, loss: 0.711702
   Number of active neurons: 7
 >> iter 11000, loss: 0.704057
 >> iter 12000, loss: 0.590313
 >> iter 13000, loss: 0.722415
 >> iter 14000, loss: 0.824755
 >> iter 15000, loss: 0.721888
 >> iter 16000, loss: 0.468270
 >> iter 17000, loss: 0.472347
 >> iter 18000, loss: 0.532827
 >> iter 19000, loss: 0.507513
 >> iter 20000, loss: 0.765266
   Number of active neurons: 7
 >> iter 21000, loss: 0.455834
 >> iter 22000, loss: 0.550685
 >> iter 23000, loss: 0.445805
 >> iter 24000, loss: 0.493449
 >> iter 25000, loss: 0.537580
 >> iter 26000, loss: 0.505114
 >> iter 27000, loss: 0.470730
 >> iter 28000, loss: 0.423603
 >> iter 29000, loss: 0.356138
 >> iter 30000, loss: 0.540345
   Number of active neurons: 7
 >> iter 31000, loss: 0.728505
 >> iter 32000, loss: 0.521002
 >> iter 33000, loss: 0.455900
 >> iter 34000, loss: 0.566108
 >> iter 35000, loss: 0.752007
 >> iter 36000, loss: 0.709698
 >> iter 37000, loss: 0.672818
 >> iter 38000, loss: 0.713332
 >> iter 39000, loss: 0.597149
 >> iter 40000, loss: 0.583058
   Number of active neurons: 7
 >> iter 41000, loss: 0.587826
 >> iter 42000, loss: 0.653391
 >> iter 43000, loss: 0.662048
 >> iter 44000, loss: 0.587888
 >> iter 45000, loss: 0.510289
 >> iter 46000, loss: 0.573508
 >> iter 47000, loss: 0.552216
 >> iter 48000, loss: 0.583815
 >> iter 49000, loss: 0.476207
 >> iter 50000, loss: 0.387719
   Number of active neurons: 6
 >> iter 51000, loss: 0.546822
 >> iter 52000, loss: 0.560701
 >> iter 53000, loss: 0.442505
 >> iter 54000, loss: 0.515036
 >> iter 55000, loss: 0.460101
 >> iter 56000, loss: 0.516668
 >> iter 57000, loss: 0.493524
 >> iter 58000, loss: 0.403318
 >> iter 59000, loss: 0.558452
 >> iter 60000, loss: 0.554649
   Number of active neurons: 6
 >> iter 61000, loss: 0.501079
 >> iter 62000, loss: 0.563971
 >> iter 63000, loss: 0.625486
 >> iter 64000, loss: 0.578540
 >> iter 65000, loss: 0.775859
 >> iter 66000, loss: 0.557476
 >> iter 67000, loss: 0.389008
 >> iter 68000, loss: 0.408645
 >> iter 69000, loss: 0.474541
 >> iter 70000, loss: 0.421989
   Number of active neurons: 6
 >> iter 71000, loss: 0.490431
 >> iter 72000, loss: 0.426663
 >> iter 73000, loss: 0.620369
 >> iter 74000, loss: 0.481322
 >> iter 75000, loss: 0.388679
 >> iter 76000, loss: 0.428135
 >> iter 77000, loss: 0.625277
 >> iter 78000, loss: 0.535107
 >> iter 79000, loss: 0.542397
 >> iter 80000, loss: 0.525033
   Number of active neurons: 6
 >> iter 81000, loss: 0.460283
 >> iter 82000, loss: 0.545376
 >> iter 83000, loss: 0.602030
 >> iter 84000, loss: 0.460752
 >> iter 85000, loss: 0.446197
 >> iter 86000, loss: 0.546225
 >> iter 87000, loss: 0.774095
 >> iter 88000, loss: 0.708008
 >> iter 89000, loss: 0.827974
 >> iter 90000, loss: 0.635172
   Number of active neurons: 6
 >> iter 91000, loss: 0.646160
 >> iter 92000, loss: 0.569188
 >> iter 93000, loss: 0.531011
 >> iter 94000, loss: 0.321234
 >> iter 95000, loss: 0.444469
 >> iter 96000, loss: 0.546080
 >> iter 97000, loss: 0.395916
 >> iter 98000, loss: 0.357034
 >> iter 99000, loss: 0.416278
 >> iter 100000, loss: 0.377891
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 18.929946
 >> iter 2000, loss: 10.792665
 >> iter 3000, loss: 4.817192
 >> iter 4000, loss: 2.157620
 >> iter 5000, loss: 0.936626
 >> iter 6000, loss: 0.555439
 >> iter 7000, loss: 0.510525
 >> iter 8000, loss: 0.289595
 >> iter 9000, loss: 0.263472
 >> iter 10000, loss: 0.484076
   Number of active neurons: 10
 >> iter 11000, loss: 0.381307
 >> iter 12000, loss: 0.410918
 >> iter 13000, loss: 0.316329
 >> iter 14000, loss: 0.287437
 >> iter 15000, loss: 0.482362
 >> iter 16000, loss: 0.403130
 >> iter 17000, loss: 0.358699
 >> iter 18000, loss: 0.302912
 >> iter 19000, loss: 0.469789
 >> iter 20000, loss: 0.392057
   Number of active neurons: 9
 >> iter 21000, loss: 0.452995
 >> iter 22000, loss: 0.434791
 >> iter 23000, loss: 0.308545
 >> iter 24000, loss: 0.170280
 >> iter 25000, loss: 0.257031
 >> iter 26000, loss: 0.203872
 >> iter 27000, loss: 0.392596
 >> iter 28000, loss: 0.322967
 >> iter 29000, loss: 0.397752
 >> iter 30000, loss: 0.252590
   Number of active neurons: 8
 >> iter 31000, loss: 0.407446
 >> iter 32000, loss: 0.364385
 >> iter 33000, loss: 0.364781
 >> iter 34000, loss: 0.420757
 >> iter 35000, loss: 0.320553
 >> iter 36000, loss: 0.216419
 >> iter 37000, loss: 0.230848
 >> iter 38000, loss: 0.271398
 >> iter 39000, loss: 0.574395
 >> iter 40000, loss: 0.447220
   Number of active neurons: 8
 >> iter 41000, loss: 0.402919
 >> iter 42000, loss: 0.234522
 >> iter 43000, loss: 0.268614
 >> iter 44000, loss: 0.224585
 >> iter 45000, loss: 0.154950
 >> iter 46000, loss: 0.135812
 >> iter 47000, loss: 0.220916
 >> iter 48000, loss: 0.322930
 >> iter 49000, loss: 0.498122
 >> iter 50000, loss: 0.544704
   Number of active neurons: 8
 >> iter 51000, loss: 0.412017
 >> iter 52000, loss: 0.354721
 >> iter 53000, loss: 0.623132
 >> iter 54000, loss: 0.410771
 >> iter 55000, loss: 0.223725
 >> iter 56000, loss: 0.402973
 >> iter 57000, loss: 0.281499
 >> iter 58000, loss: 0.282012
 >> iter 59000, loss: 0.389458
 >> iter 60000, loss: 0.324531
   Number of active neurons: 8
 >> iter 61000, loss: 0.412878
 >> iter 62000, loss: 0.265292
 >> iter 63000, loss: 0.328179
 >> iter 64000, loss: 0.321397
 >> iter 65000, loss: 0.269464
 >> iter 66000, loss: 0.407339
 >> iter 67000, loss: 0.262092
 >> iter 68000, loss: 0.165758
 >> iter 69000, loss: 0.304563
 >> iter 70000, loss: 0.325319
   Number of active neurons: 8
 >> iter 71000, loss: 0.409905
 >> iter 72000, loss: 0.423882
 >> iter 73000, loss: 0.411092
 >> iter 74000, loss: 0.415770
 >> iter 75000, loss: 0.249150
 >> iter 76000, loss: 0.300966
 >> iter 77000, loss: 0.281106
 >> iter 78000, loss: 0.317910
 >> iter 79000, loss: 0.218110
 >> iter 80000, loss: 0.234139
   Number of active neurons: 8
 >> iter 81000, loss: 0.252939
 >> iter 82000, loss: 0.375957
 >> iter 83000, loss: 0.415316
 >> iter 84000, loss: 0.265228
 >> iter 85000, loss: 0.342390
 >> iter 86000, loss: 0.441207
 >> iter 87000, loss: 0.337460
 >> iter 88000, loss: 0.228321
 >> iter 89000, loss: 0.270387
 >> iter 90000, loss: 0.252352
   Number of active neurons: 8
 >> iter 91000, loss: 0.351287
 >> iter 92000, loss: 0.307288
 >> iter 93000, loss: 0.211077
 >> iter 94000, loss: 0.299996
 >> iter 95000, loss: 0.429938
 >> iter 96000, loss: 0.261405
 >> iter 97000, loss: 0.257869
 >> iter 98000, loss: 0.263571
 >> iter 99000, loss: 0.316970
 >> iter 100000, loss: 0.203522
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.165624
 >> iter 2000, loss: 12.031832
 >> iter 3000, loss: 5.069211
 >> iter 4000, loss: 2.264830
 >> iter 5000, loss: 1.168227
 >> iter 6000, loss: 0.599539
 >> iter 7000, loss: 0.402785
 >> iter 8000, loss: 0.389202
 >> iter 9000, loss: 0.432464
 >> iter 10000, loss: 0.350402
   Number of active neurons: 7
 >> iter 11000, loss: 0.480341
 >> iter 12000, loss: 0.314881
 >> iter 13000, loss: 0.347322
 >> iter 14000, loss: 0.512446
 >> iter 15000, loss: 0.273134
 >> iter 16000, loss: 0.178760
 >> iter 17000, loss: 0.172751
 >> iter 18000, loss: 0.102161
 >> iter 19000, loss: 0.192080
 >> iter 20000, loss: 0.333430
   Number of active neurons: 7
 >> iter 21000, loss: 0.346639
 >> iter 22000, loss: 0.251106
 >> iter 23000, loss: 0.174475
 >> iter 24000, loss: 0.234521
 >> iter 25000, loss: 0.318392
 >> iter 26000, loss: 0.316675
 >> iter 27000, loss: 0.165760
 >> iter 28000, loss: 0.285256
 >> iter 29000, loss: 0.242060
 >> iter 30000, loss: 0.241129
   Number of active neurons: 7
 >> iter 31000, loss: 0.174294
 >> iter 32000, loss: 0.211941
 >> iter 33000, loss: 0.206131
 >> iter 34000, loss: 0.127521
 >> iter 35000, loss: 0.383803
 >> iter 36000, loss: 0.279747
 >> iter 37000, loss: 0.183189
 >> iter 38000, loss: 0.267165
 >> iter 39000, loss: 0.299072
 >> iter 40000, loss: 0.256926
   Number of active neurons: 7
 >> iter 41000, loss: 0.264635
 >> iter 42000, loss: 0.237268
 >> iter 43000, loss: 0.305891
 >> iter 44000, loss: 0.212630
 >> iter 45000, loss: 0.239349
 >> iter 46000, loss: 0.185856
 >> iter 47000, loss: 0.267729
 >> iter 48000, loss: 0.173462
 >> iter 49000, loss: 0.140758
 >> iter 50000, loss: 0.129676
   Number of active neurons: 7
 >> iter 51000, loss: 0.160481
 >> iter 52000, loss: 0.255952
 >> iter 53000, loss: 0.171899
 >> iter 54000, loss: 0.132756
 >> iter 55000, loss: 0.167636
 >> iter 56000, loss: 0.254746
 >> iter 57000, loss: 0.305904
 >> iter 58000, loss: 0.279984
 >> iter 59000, loss: 0.245197
 >> iter 60000, loss: 0.212893
   Number of active neurons: 6
 >> iter 61000, loss: 0.258307
 >> iter 62000, loss: 0.190957
 >> iter 63000, loss: 0.262048
 >> iter 64000, loss: 0.275457
 >> iter 65000, loss: 0.182605
 >> iter 66000, loss: 0.178699
 >> iter 67000, loss: 0.258696
 >> iter 68000, loss: 0.180522
 >> iter 69000, loss: 0.128825
 >> iter 70000, loss: 0.225440
   Number of active neurons: 5
 >> iter 71000, loss: 0.190597
 >> iter 72000, loss: 0.236793
 >> iter 73000, loss: 0.141190
 >> iter 74000, loss: 0.134401
 >> iter 75000, loss: 0.311691
 >> iter 76000, loss: 0.230350
 >> iter 77000, loss: 0.336646
 >> iter 78000, loss: 0.301049
 >> iter 79000, loss: 0.236830
 >> iter 80000, loss: 0.178418
   Number of active neurons: 5
 >> iter 81000, loss: 0.241659
 >> iter 82000, loss: 0.221007
 >> iter 83000, loss: 0.183292
 >> iter 84000, loss: 0.182097
 >> iter 85000, loss: 0.205526
 >> iter 86000, loss: 0.256199
 >> iter 87000, loss: 0.339636
 >> iter 88000, loss: 0.229216
 >> iter 89000, loss: 0.277546
 >> iter 90000, loss: 0.203286
   Number of active neurons: 5
 >> iter 91000, loss: 0.222949
 >> iter 92000, loss: 0.208202
 >> iter 93000, loss: 0.204966
 >> iter 94000, loss: 0.257666
 >> iter 95000, loss: 0.286186
 >> iter 96000, loss: 0.263841
 >> iter 97000, loss: 0.319161
 >> iter 98000, loss: 0.278178
 >> iter 99000, loss: 0.221947
 >> iter 100000, loss: 0.192070
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.162395
 >> iter 2000, loss: 11.317600
 >> iter 3000, loss: 4.970665
 >> iter 4000, loss: 2.108355
 >> iter 5000, loss: 1.122652
 >> iter 6000, loss: 0.743056
 >> iter 7000, loss: 0.561381
 >> iter 8000, loss: 0.277890
 >> iter 9000, loss: 0.338621
 >> iter 10000, loss: 0.331055
   Number of active neurons: 9
 >> iter 11000, loss: 0.400035
 >> iter 12000, loss: 0.234165
 >> iter 13000, loss: 0.164792
 >> iter 14000, loss: 0.157957
 >> iter 15000, loss: 0.164003
 >> iter 16000, loss: 0.272026
 >> iter 17000, loss: 0.257682
 >> iter 18000, loss: 0.207707
 >> iter 19000, loss: 0.230443
 >> iter 20000, loss: 0.337349
   Number of active neurons: 9
 >> iter 21000, loss: 0.375137
 >> iter 22000, loss: 0.337156
 >> iter 23000, loss: 0.247470
 >> iter 24000, loss: 0.253122
 >> iter 25000, loss: 0.203598
 >> iter 26000, loss: 0.250708
 >> iter 27000, loss: 0.371504
 >> iter 28000, loss: 0.288766
 >> iter 29000, loss: 0.247472
 >> iter 30000, loss: 0.281024
   Number of active neurons: 9
 >> iter 31000, loss: 0.225670
 >> iter 32000, loss: 0.164198
 >> iter 33000, loss: 0.207640
 >> iter 34000, loss: 0.227460
 >> iter 35000, loss: 0.312603
 >> iter 36000, loss: 0.257672
 >> iter 37000, loss: 0.160244
 >> iter 38000, loss: 0.198666
 >> iter 39000, loss: 0.129000
 >> iter 40000, loss: 0.306189
   Number of active neurons: 9
 >> iter 41000, loss: 0.243285
 >> iter 42000, loss: 0.225670
 >> iter 43000, loss: 0.186453
 >> iter 44000, loss: 0.143462
 >> iter 45000, loss: 0.286344
 >> iter 46000, loss: 0.267077
 >> iter 47000, loss: 0.279555
 >> iter 48000, loss: 0.254564
 >> iter 49000, loss: 0.216231
 >> iter 50000, loss: 0.154334
   Number of active neurons: 8
 >> iter 51000, loss: 0.184895
 >> iter 52000, loss: 0.297544
 >> iter 53000, loss: 0.268912
 >> iter 54000, loss: 0.215698
 >> iter 55000, loss: 0.212246
 >> iter 56000, loss: 0.159961
 >> iter 57000, loss: 0.153514
 >> iter 58000, loss: 0.254855
 >> iter 59000, loss: 0.204197
 >> iter 60000, loss: 0.220870
   Number of active neurons: 5
 >> iter 61000, loss: 0.224314
 >> iter 62000, loss: 0.303927
 >> iter 63000, loss: 0.263811
 >> iter 64000, loss: 0.225290
 >> iter 65000, loss: 0.176886
 >> iter 66000, loss: 0.342545
 >> iter 67000, loss: 0.277207
 >> iter 68000, loss: 0.235827
 >> iter 69000, loss: 0.434376
 >> iter 70000, loss: 0.259790
   Number of active neurons: 5
 >> iter 71000, loss: 0.201581
 >> iter 72000, loss: 0.175047
 >> iter 73000, loss: 0.246925
 >> iter 74000, loss: 0.296008
 >> iter 75000, loss: 0.244411
 >> iter 76000, loss: 0.230435
 >> iter 77000, loss: 0.166478
 >> iter 78000, loss: 0.132535
 >> iter 79000, loss: 0.151976
 >> iter 80000, loss: 0.189027
   Number of active neurons: 4
 >> iter 81000, loss: 0.182947
 >> iter 82000, loss: 0.129753
 >> iter 83000, loss: 0.232357
 >> iter 84000, loss: 0.182660
 >> iter 85000, loss: 0.228654
 >> iter 86000, loss: 0.174050
 >> iter 87000, loss: 0.291207
 >> iter 88000, loss: 0.307096
 >> iter 89000, loss: 0.247289
 >> iter 90000, loss: 0.228308
   Number of active neurons: 4
 >> iter 91000, loss: 0.266946
 >> iter 92000, loss: 0.221356
 >> iter 93000, loss: 0.214840
 >> iter 94000, loss: 0.131552
 >> iter 95000, loss: 0.106796
 >> iter 96000, loss: 0.200073
 >> iter 97000, loss: 0.283464
 >> iter 98000, loss: 0.192902
 >> iter 99000, loss: 0.178522
 >> iter 100000, loss: 0.131263
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.023512
 >> iter 2000, loss: 11.239401
 >> iter 3000, loss: 5.207468
 >> iter 4000, loss: 2.402079
 >> iter 5000, loss: 1.228819
 >> iter 6000, loss: 0.698733
 >> iter 7000, loss: 0.494584
 >> iter 8000, loss: 0.546337
 >> iter 9000, loss: 0.313540
 >> iter 10000, loss: 0.277576
   Number of active neurons: 7
 >> iter 11000, loss: 0.226375
 >> iter 12000, loss: 0.465976
 >> iter 13000, loss: 0.342287
 >> iter 14000, loss: 0.442499
 >> iter 15000, loss: 0.552092
 >> iter 16000, loss: 0.327216
 >> iter 17000, loss: 0.337346
 >> iter 18000, loss: 0.379184
 >> iter 19000, loss: 0.297333
 >> iter 20000, loss: 0.251534
   Number of active neurons: 7
 >> iter 21000, loss: 0.259488
 >> iter 22000, loss: 0.323137
 >> iter 23000, loss: 0.461390
 >> iter 24000, loss: 0.271554
 >> iter 25000, loss: 0.294426
 >> iter 26000, loss: 0.317964
 >> iter 27000, loss: 0.349414
 >> iter 28000, loss: 0.246310
 >> iter 29000, loss: 0.237814
 >> iter 30000, loss: 0.184453
   Number of active neurons: 7
 >> iter 31000, loss: 0.249285
 >> iter 32000, loss: 0.336808
 >> iter 33000, loss: 0.322512
 >> iter 34000, loss: 0.376060
 >> iter 35000, loss: 0.337231
 >> iter 36000, loss: 0.221512
 >> iter 37000, loss: 0.205125
 >> iter 38000, loss: 0.223333
 >> iter 39000, loss: 0.186049
 >> iter 40000, loss: 0.254777
   Number of active neurons: 7
 >> iter 41000, loss: 0.197427
 >> iter 42000, loss: 0.218768
 >> iter 43000, loss: 0.361936
 >> iter 44000, loss: 0.331256
 >> iter 45000, loss: 0.277194
 >> iter 46000, loss: 0.257871
 >> iter 47000, loss: 0.249897
 >> iter 48000, loss: 0.189116
 >> iter 49000, loss: 0.284348
 >> iter 50000, loss: 0.191212
   Number of active neurons: 7
 >> iter 51000, loss: 0.141646
 >> iter 52000, loss: 0.142738
 >> iter 53000, loss: 0.325627
 >> iter 54000, loss: 0.199423
 >> iter 55000, loss: 0.170661
 >> iter 56000, loss: 0.232066
 >> iter 57000, loss: 0.332627
 >> iter 58000, loss: 0.218967
 >> iter 59000, loss: 0.185872
 >> iter 60000, loss: 0.135766
   Number of active neurons: 7
 >> iter 61000, loss: 0.328762
 >> iter 62000, loss: 0.289758
 >> iter 63000, loss: 0.191521
 >> iter 64000, loss: 0.250091
 >> iter 65000, loss: 0.181892
 >> iter 66000, loss: 0.233292
 >> iter 67000, loss: 0.154344
 >> iter 68000, loss: 0.212366
 >> iter 69000, loss: 0.310386
 >> iter 70000, loss: 0.282540
   Number of active neurons: 7
 >> iter 71000, loss: 0.292742
 >> iter 72000, loss: 0.240855
 >> iter 73000, loss: 0.300376
 >> iter 74000, loss: 0.188965
 >> iter 75000, loss: 0.331306
 >> iter 76000, loss: 0.274607
 >> iter 77000, loss: 0.270662
 >> iter 78000, loss: 0.191473
 >> iter 79000, loss: 0.228657
 >> iter 80000, loss: 0.269161
   Number of active neurons: 7
 >> iter 81000, loss: 0.268345
 >> iter 82000, loss: 0.289033
 >> iter 83000, loss: 0.277574
 >> iter 84000, loss: 0.245852
 >> iter 85000, loss: 0.205269
 >> iter 86000, loss: 0.290419
 >> iter 87000, loss: 0.270287
 >> iter 88000, loss: 0.177904
 >> iter 89000, loss: 0.137411
 >> iter 90000, loss: 0.121625
   Number of active neurons: 6
 >> iter 91000, loss: 0.180469
 >> iter 92000, loss: 0.222373
 >> iter 93000, loss: 0.211861
 >> iter 94000, loss: 0.157546
 >> iter 95000, loss: 0.199362
 >> iter 96000, loss: 0.147590
 >> iter 97000, loss: 0.261510
 >> iter 98000, loss: 0.196311
 >> iter 99000, loss: 0.193481
 >> iter 100000, loss: 0.253341
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.098230
 >> iter 2000, loss: 10.483919
 >> iter 3000, loss: 4.849427
 >> iter 4000, loss: 2.190983
 >> iter 5000, loss: 0.993819
 >> iter 6000, loss: 0.608771
 >> iter 7000, loss: 0.488572
 >> iter 8000, loss: 0.444220
 >> iter 9000, loss: 0.442387
 >> iter 10000, loss: 0.266156
   Number of active neurons: 7
 >> iter 11000, loss: 0.342872
 >> iter 12000, loss: 0.388977
 >> iter 13000, loss: 0.304555
 >> iter 14000, loss: 0.211754
 >> iter 15000, loss: 0.401243
 >> iter 16000, loss: 0.425657
 >> iter 17000, loss: 0.273945
 >> iter 18000, loss: 0.230589
 >> iter 19000, loss: 0.319420
 >> iter 20000, loss: 0.260251
   Number of active neurons: 7
 >> iter 21000, loss: 0.207531
 >> iter 22000, loss: 0.213025
 >> iter 23000, loss: 0.128187
 >> iter 24000, loss: 0.163532
 >> iter 25000, loss: 0.261367
 >> iter 26000, loss: 0.280741
 >> iter 27000, loss: 0.436233
 >> iter 28000, loss: 0.287159
 >> iter 29000, loss: 0.267919
 >> iter 30000, loss: 0.191898
   Number of active neurons: 7
 >> iter 31000, loss: 0.324412
 >> iter 32000, loss: 0.267939
 >> iter 33000, loss: 0.192929
 >> iter 34000, loss: 0.261855
 >> iter 35000, loss: 0.313778
 >> iter 36000, loss: 0.253044
 >> iter 37000, loss: 0.223434
 >> iter 38000, loss: 0.192359
 >> iter 39000, loss: 0.198735
 >> iter 40000, loss: 0.152488
   Number of active neurons: 5
 >> iter 41000, loss: 0.171116
 >> iter 42000, loss: 0.152567
 >> iter 43000, loss: 0.241556
 >> iter 44000, loss: 0.265728
 >> iter 45000, loss: 0.236603
 >> iter 46000, loss: 0.143973
 >> iter 47000, loss: 0.264748
 >> iter 48000, loss: 0.229113
 >> iter 49000, loss: 0.380738
 >> iter 50000, loss: 0.232715
   Number of active neurons: 5
 >> iter 51000, loss: 0.176173
 >> iter 52000, loss: 0.242889
 >> iter 53000, loss: 0.239584
 >> iter 54000, loss: 0.269785
 >> iter 55000, loss: 0.174568
 >> iter 56000, loss: 0.196856
 >> iter 57000, loss: 0.316517
 >> iter 58000, loss: 0.208856
 >> iter 59000, loss: 0.301130
 >> iter 60000, loss: 0.221301
   Number of active neurons: 5
 >> iter 61000, loss: 0.171175
 >> iter 62000, loss: 0.253419
 >> iter 63000, loss: 0.132705
 >> iter 64000, loss: 0.145904
 >> iter 65000, loss: 0.146567
 >> iter 66000, loss: 0.221453
 >> iter 67000, loss: 0.204236
 >> iter 68000, loss: 0.506210
 >> iter 69000, loss: 0.264600
 >> iter 70000, loss: 0.173576
   Number of active neurons: 5
 >> iter 71000, loss: 0.218591
 >> iter 72000, loss: 0.176569
 >> iter 73000, loss: 0.125101
 >> iter 74000, loss: 0.195924
 >> iter 75000, loss: 0.319505
 >> iter 76000, loss: 0.249312
 >> iter 77000, loss: 0.202386
 >> iter 78000, loss: 0.286812
 >> iter 79000, loss: 0.194573
 >> iter 80000, loss: 0.393636
   Number of active neurons: 4
 >> iter 81000, loss: 0.268444
 >> iter 82000, loss: 0.228322
 >> iter 83000, loss: 0.171882
 >> iter 84000, loss: 0.113838
 >> iter 85000, loss: 0.164796
 >> iter 86000, loss: 0.281299
 >> iter 87000, loss: 0.230350
 >> iter 88000, loss: 0.190771
 >> iter 89000, loss: 0.223295
 >> iter 90000, loss: 0.185467
   Number of active neurons: 4
 >> iter 91000, loss: 0.255784
 >> iter 92000, loss: 0.162225
 >> iter 93000, loss: 0.111899
 >> iter 94000, loss: 0.148278
 >> iter 95000, loss: 0.147748
 >> iter 96000, loss: 0.143693
 >> iter 97000, loss: 0.302850
 >> iter 98000, loss: 0.182014
 >> iter 99000, loss: 0.108159
 >> iter 100000, loss: 0.153678
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.907951
 >> iter 2000, loss: 11.719524
 >> iter 3000, loss: 5.477683
 >> iter 4000, loss: 2.322338
 >> iter 5000, loss: 1.366122
 >> iter 6000, loss: 0.681227
 >> iter 7000, loss: 0.526309
 >> iter 8000, loss: 0.328558
 >> iter 9000, loss: 0.480693
 >> iter 10000, loss: 0.586155
   Number of active neurons: 8
 >> iter 11000, loss: 0.501079
 >> iter 12000, loss: 0.372458
 >> iter 13000, loss: 0.446749
 >> iter 14000, loss: 0.478637
 >> iter 15000, loss: 0.519329
 >> iter 16000, loss: 0.320684
 >> iter 17000, loss: 0.378010
 >> iter 18000, loss: 0.300982
 >> iter 19000, loss: 0.461541
 >> iter 20000, loss: 0.533189
   Number of active neurons: 8
 >> iter 21000, loss: 0.366554
 >> iter 22000, loss: 0.367853
 >> iter 23000, loss: 0.417699
 >> iter 24000, loss: 0.390885
 >> iter 25000, loss: 0.546672
 >> iter 26000, loss: 0.373349
 >> iter 27000, loss: 0.318689
 >> iter 28000, loss: 0.253407
 >> iter 29000, loss: 0.360858
 >> iter 30000, loss: 0.355422
   Number of active neurons: 8
 >> iter 31000, loss: 0.406674
 >> iter 32000, loss: 0.362234
 >> iter 33000, loss: 0.680929
 >> iter 34000, loss: 0.519517
 >> iter 35000, loss: 0.472529
 >> iter 36000, loss: 0.495492
 >> iter 37000, loss: 0.354349
 >> iter 38000, loss: 0.305650
 >> iter 39000, loss: 0.359151
 >> iter 40000, loss: 0.426597
   Number of active neurons: 8
 >> iter 41000, loss: 0.303728
 >> iter 42000, loss: 0.416783
 >> iter 43000, loss: 0.440768
 >> iter 44000, loss: 0.448595
 >> iter 45000, loss: 0.275191
 >> iter 46000, loss: 0.306848
 >> iter 47000, loss: 0.324842
 >> iter 48000, loss: 0.269504
 >> iter 49000, loss: 0.400096
 >> iter 50000, loss: 0.321239
   Number of active neurons: 8
 >> iter 51000, loss: 0.446611
 >> iter 52000, loss: 0.315870
 >> iter 53000, loss: 0.278269
 >> iter 54000, loss: 0.411219
 >> iter 55000, loss: 0.319377
 >> iter 56000, loss: 0.263629
 >> iter 57000, loss: 0.240079
 >> iter 58000, loss: 0.265917
 >> iter 59000, loss: 0.212004
 >> iter 60000, loss: 0.290675
   Number of active neurons: 8
 >> iter 61000, loss: 0.167695
 >> iter 62000, loss: 0.180731
 >> iter 63000, loss: 0.235553
 >> iter 64000, loss: 0.240990
 >> iter 65000, loss: 0.206439
 >> iter 66000, loss: 0.229204
 >> iter 67000, loss: 0.137541
 >> iter 68000, loss: 0.163543
 >> iter 69000, loss: 0.184441
 >> iter 70000, loss: 0.187736
   Number of active neurons: 8
 >> iter 71000, loss: 0.252531
 >> iter 72000, loss: 0.155535
 >> iter 73000, loss: 0.279494
 >> iter 74000, loss: 0.160684
 >> iter 75000, loss: 0.218110
 >> iter 76000, loss: 0.202093
 >> iter 77000, loss: 0.241503
 >> iter 78000, loss: 0.255036
 >> iter 79000, loss: 0.264046
 >> iter 80000, loss: 0.178572
   Number of active neurons: 7
 >> iter 81000, loss: 0.124865
 >> iter 82000, loss: 0.315656
 >> iter 83000, loss: 0.319486
 >> iter 84000, loss: 0.281728
 >> iter 85000, loss: 0.222868
 >> iter 86000, loss: 0.176380
 >> iter 87000, loss: 0.231272
 >> iter 88000, loss: 0.247800
 >> iter 89000, loss: 0.320807
 >> iter 90000, loss: 0.280991
   Number of active neurons: 5
 >> iter 91000, loss: 0.435852
 >> iter 92000, loss: 0.300750
 >> iter 93000, loss: 0.253385
 >> iter 94000, loss: 0.357766
 >> iter 95000, loss: 0.295108
 >> iter 96000, loss: 0.218167
 >> iter 97000, loss: 0.208352
 >> iter 98000, loss: 0.316054
 >> iter 99000, loss: 0.190593
 >> iter 100000, loss: 0.178760
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.131209
 >> iter 2000, loss: 10.163699
 >> iter 3000, loss: 4.282729
 >> iter 4000, loss: 2.054808
 >> iter 5000, loss: 1.149760
 >> iter 6000, loss: 0.529452
 >> iter 7000, loss: 0.312305
 >> iter 8000, loss: 0.222906
 >> iter 9000, loss: 0.300073
 >> iter 10000, loss: 0.275916
   Number of active neurons: 10
 >> iter 11000, loss: 0.444525
 >> iter 12000, loss: 0.352518
 >> iter 13000, loss: 0.354083
 >> iter 14000, loss: 0.353830
 >> iter 15000, loss: 0.317299
 >> iter 16000, loss: 0.316970
 >> iter 17000, loss: 0.265223
 >> iter 18000, loss: 0.241696
 >> iter 19000, loss: 0.224799
 >> iter 20000, loss: 0.322969
   Number of active neurons: 8
 >> iter 21000, loss: 0.301246
 >> iter 22000, loss: 0.254771
 >> iter 23000, loss: 0.337362
 >> iter 24000, loss: 0.315407
 >> iter 25000, loss: 0.284932
 >> iter 26000, loss: 0.487415
 >> iter 27000, loss: 0.373860
 >> iter 28000, loss: 0.373703
 >> iter 29000, loss: 0.315177
 >> iter 30000, loss: 0.276896
   Number of active neurons: 7
 >> iter 31000, loss: 0.289655
 >> iter 32000, loss: 0.361830
 >> iter 33000, loss: 0.486563
 >> iter 34000, loss: 0.383920
 >> iter 35000, loss: 0.245099
 >> iter 36000, loss: 0.294912
 >> iter 37000, loss: 0.194210
 >> iter 38000, loss: 0.225410
 >> iter 39000, loss: 0.293819
 >> iter 40000, loss: 0.310761
   Number of active neurons: 6
 >> iter 41000, loss: 0.181641
 >> iter 42000, loss: 0.238142
 >> iter 43000, loss: 0.303261
 >> iter 44000, loss: 0.349327
 >> iter 45000, loss: 0.268471
 >> iter 46000, loss: 0.256767
 >> iter 47000, loss: 0.430938
 >> iter 48000, loss: 0.248303
 >> iter 49000, loss: 0.315331
 >> iter 50000, loss: 0.304126
   Number of active neurons: 6
 >> iter 51000, loss: 0.230401
 >> iter 52000, loss: 0.375764
 >> iter 53000, loss: 0.312813
 >> iter 54000, loss: 0.321706
 >> iter 55000, loss: 0.391829
 >> iter 56000, loss: 0.233768
 >> iter 57000, loss: 0.191560
 >> iter 58000, loss: 0.175343
 >> iter 59000, loss: 0.147696
 >> iter 60000, loss: 0.209219
   Number of active neurons: 6
 >> iter 61000, loss: 0.131211
 >> iter 62000, loss: 0.220890
 >> iter 63000, loss: 0.201680
 >> iter 64000, loss: 0.183607
 >> iter 65000, loss: 0.162465
 >> iter 66000, loss: 0.297585
 >> iter 67000, loss: 0.292568
 >> iter 68000, loss: 0.177016
 >> iter 69000, loss: 0.282582
 >> iter 70000, loss: 0.233094
   Number of active neurons: 6
 >> iter 71000, loss: 0.200143
 >> iter 72000, loss: 0.210908
 >> iter 73000, loss: 0.262233
 >> iter 74000, loss: 0.228030
 >> iter 75000, loss: 0.148959
 >> iter 76000, loss: 0.150941
 >> iter 77000, loss: 0.154897
 >> iter 78000, loss: 0.247817
 >> iter 79000, loss: 0.274957
 >> iter 80000, loss: 0.286880
   Number of active neurons: 6
 >> iter 81000, loss: 0.328779
 >> iter 82000, loss: 0.345871
 >> iter 83000, loss: 0.239080
 >> iter 84000, loss: 0.190068
 >> iter 85000, loss: 0.247246
 >> iter 86000, loss: 0.358903
 >> iter 87000, loss: 0.277759
 >> iter 88000, loss: 0.447725
 >> iter 89000, loss: 0.272731
 >> iter 90000, loss: 0.192046
   Number of active neurons: 5
 >> iter 91000, loss: 0.207187
 >> iter 92000, loss: 0.201287
 >> iter 93000, loss: 0.185361
 >> iter 94000, loss: 0.171372
 >> iter 95000, loss: 0.142795
 >> iter 96000, loss: 0.222623
 >> iter 97000, loss: 0.288512
 >> iter 98000, loss: 0.193787
 >> iter 99000, loss: 0.126133
 >> iter 100000, loss: 0.106384
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.937697
 >> iter 2000, loss: 11.403874
 >> iter 3000, loss: 5.474182
 >> iter 4000, loss: 2.587595
 >> iter 5000, loss: 1.341827
 >> iter 6000, loss: 0.775469
 >> iter 7000, loss: 0.636478
 >> iter 8000, loss: 0.506334
 >> iter 9000, loss: 0.485030
 >> iter 10000, loss: 0.515373
   Number of active neurons: 8
 >> iter 11000, loss: 0.579983
 >> iter 12000, loss: 0.357376
 >> iter 13000, loss: 0.399630
 >> iter 14000, loss: 0.378399
 >> iter 15000, loss: 0.328736
 >> iter 16000, loss: 0.573144
 >> iter 17000, loss: 0.443040
 >> iter 18000, loss: 0.492876
 >> iter 19000, loss: 0.465279
 >> iter 20000, loss: 0.264306
   Number of active neurons: 8
 >> iter 21000, loss: 0.395635
 >> iter 22000, loss: 0.458662
 >> iter 23000, loss: 0.505151
 >> iter 24000, loss: 0.566102
 >> iter 25000, loss: 0.514227
 >> iter 26000, loss: 0.506537
 >> iter 27000, loss: 0.535023
 >> iter 28000, loss: 0.438786
 >> iter 29000, loss: 0.407144
 >> iter 30000, loss: 0.237034
   Number of active neurons: 8
 >> iter 31000, loss: 0.350274
 >> iter 32000, loss: 0.408736
 >> iter 33000, loss: 0.331711
 >> iter 34000, loss: 0.274195
 >> iter 35000, loss: 0.302528
 >> iter 36000, loss: 0.388048
 >> iter 37000, loss: 0.294682
 >> iter 38000, loss: 0.389419
 >> iter 39000, loss: 0.422398
 >> iter 40000, loss: 0.368070
   Number of active neurons: 8
 >> iter 41000, loss: 0.503214
 >> iter 42000, loss: 0.417470
 >> iter 43000, loss: 0.494541
 >> iter 44000, loss: 0.281020
 >> iter 45000, loss: 0.388369
 >> iter 46000, loss: 0.428775
 >> iter 47000, loss: 0.432802
 >> iter 48000, loss: 0.470647
 >> iter 49000, loss: 0.405659
 >> iter 50000, loss: 0.379114
   Number of active neurons: 8
 >> iter 51000, loss: 0.237836
 >> iter 52000, loss: 0.231246
 >> iter 53000, loss: 0.229914
 >> iter 54000, loss: 0.342081
 >> iter 55000, loss: 0.285056
 >> iter 56000, loss: 0.311892
 >> iter 57000, loss: 0.315146
 >> iter 58000, loss: 0.271757
 >> iter 59000, loss: 0.229326
 >> iter 60000, loss: 0.441248
   Number of active neurons: 7
 >> iter 61000, loss: 0.450583
 >> iter 62000, loss: 0.359136
 >> iter 63000, loss: 0.328632
 >> iter 64000, loss: 0.329213
 >> iter 65000, loss: 0.358573
 >> iter 66000, loss: 0.370301
 >> iter 67000, loss: 0.362275
 >> iter 68000, loss: 0.322930
 >> iter 69000, loss: 0.331280
 >> iter 70000, loss: 0.368515
   Number of active neurons: 7
 >> iter 71000, loss: 0.399635
 >> iter 72000, loss: 0.228321
 >> iter 73000, loss: 0.191360
 >> iter 74000, loss: 0.280802
 >> iter 75000, loss: 0.351722
 >> iter 76000, loss: 0.329294
 >> iter 77000, loss: 0.342162
 >> iter 78000, loss: 0.233288
 >> iter 79000, loss: 0.303414
 >> iter 80000, loss: 0.262034
   Number of active neurons: 7
 >> iter 81000, loss: 0.331370
 >> iter 82000, loss: 0.318543
 >> iter 83000, loss: 0.365328
 >> iter 84000, loss: 0.288145
 >> iter 85000, loss: 0.282809
 >> iter 86000, loss: 0.469068
 >> iter 87000, loss: 0.409430
 >> iter 88000, loss: 0.317353
 >> iter 89000, loss: 0.447804
 >> iter 90000, loss: 0.368557
   Number of active neurons: 6
 >> iter 91000, loss: 0.439153
 >> iter 92000, loss: 0.407889
 >> iter 93000, loss: 0.338784
 >> iter 94000, loss: 0.363195
 >> iter 95000, loss: 0.282671
 >> iter 96000, loss: 0.292584
 >> iter 97000, loss: 0.427588
 >> iter 98000, loss: 0.484149
 >> iter 99000, loss: 0.476068
 >> iter 100000, loss: 0.527014
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.946897
 >> iter 2000, loss: 11.345018
 >> iter 3000, loss: 5.061923
 >> iter 4000, loss: 2.226373
 >> iter 5000, loss: 0.995203
 >> iter 6000, loss: 0.478451
 >> iter 7000, loss: 0.267769
 >> iter 8000, loss: 0.432449
 >> iter 9000, loss: 0.370448
 >> iter 10000, loss: 0.266906
   Number of active neurons: 8
 >> iter 11000, loss: 0.366139
 >> iter 12000, loss: 0.219526
 >> iter 13000, loss: 0.431804
 >> iter 14000, loss: 0.292202
 >> iter 15000, loss: 0.225450
 >> iter 16000, loss: 0.258923
 >> iter 17000, loss: 0.352053
 >> iter 18000, loss: 0.300905
 >> iter 19000, loss: 0.252564
 >> iter 20000, loss: 0.307512
   Number of active neurons: 8
 >> iter 21000, loss: 0.174827
 >> iter 22000, loss: 0.307820
 >> iter 23000, loss: 0.414778
 >> iter 24000, loss: 0.258873
 >> iter 25000, loss: 0.168235
 >> iter 26000, loss: 0.377722
 >> iter 27000, loss: 0.276669
 >> iter 28000, loss: 0.304620
 >> iter 29000, loss: 0.162594
 >> iter 30000, loss: 0.237429
   Number of active neurons: 8
 >> iter 31000, loss: 0.283298
 >> iter 32000, loss: 0.192322
 >> iter 33000, loss: 0.219135
 >> iter 34000, loss: 0.266103
 >> iter 35000, loss: 0.241308
 >> iter 36000, loss: 0.197071
 >> iter 37000, loss: 0.192290
 >> iter 38000, loss: 0.382896
 >> iter 39000, loss: 0.184885
 >> iter 40000, loss: 0.142479
   Number of active neurons: 6
 >> iter 41000, loss: 0.163028
 >> iter 42000, loss: 0.162848
 >> iter 43000, loss: 0.243892
 >> iter 44000, loss: 0.296255
 >> iter 45000, loss: 0.214961
 >> iter 46000, loss: 0.337606
 >> iter 47000, loss: 0.221150
 >> iter 48000, loss: 0.146878
 >> iter 49000, loss: 0.214631
 >> iter 50000, loss: 0.141841
   Number of active neurons: 6
 >> iter 51000, loss: 0.217961
 >> iter 52000, loss: 0.201137
 >> iter 53000, loss: 0.190966
 >> iter 54000, loss: 0.153754
 >> iter 55000, loss: 0.271847
 >> iter 56000, loss: 0.250881
 >> iter 57000, loss: 0.201440
 >> iter 58000, loss: 0.217658
 >> iter 59000, loss: 0.233029
 >> iter 60000, loss: 0.316507
   Number of active neurons: 6
 >> iter 61000, loss: 0.231613
 >> iter 62000, loss: 0.160961
 >> iter 63000, loss: 0.176207
 >> iter 64000, loss: 0.205408
 >> iter 65000, loss: 0.176542
 >> iter 66000, loss: 0.176924
 >> iter 67000, loss: 0.341683
 >> iter 68000, loss: 0.275234
 >> iter 69000, loss: 0.178910
 >> iter 70000, loss: 0.149795
   Number of active neurons: 6
 >> iter 71000, loss: 0.229810
 >> iter 72000, loss: 0.242860
 >> iter 73000, loss: 0.267872
 >> iter 74000, loss: 0.250983
 >> iter 75000, loss: 0.301671
 >> iter 76000, loss: 0.250630
 >> iter 77000, loss: 0.236288
 >> iter 78000, loss: 0.211357
 >> iter 79000, loss: 0.182411
 >> iter 80000, loss: 0.195977
   Number of active neurons: 6
 >> iter 81000, loss: 0.300053
 >> iter 82000, loss: 0.193735
 >> iter 83000, loss: 0.159854
 >> iter 84000, loss: 0.101118
 >> iter 85000, loss: 0.113084
 >> iter 86000, loss: 0.141620
 >> iter 87000, loss: 0.144512
 >> iter 88000, loss: 0.158586
 >> iter 89000, loss: 0.120135
 >> iter 90000, loss: 0.272182
   Number of active neurons: 6
 >> iter 91000, loss: 0.278949
 >> iter 92000, loss: 0.218386
 >> iter 93000, loss: 0.200389
 >> iter 94000, loss: 0.150154
 >> iter 95000, loss: 0.213227
 >> iter 96000, loss: 0.255962
 >> iter 97000, loss: 0.175725
 >> iter 98000, loss: 0.191910
 >> iter 99000, loss: 0.263879
 >> iter 100000, loss: 0.222966
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 19.054275
 >> iter 2000, loss: 10.265177
 >> iter 3000, loss: 4.270086
 >> iter 4000, loss: 1.781853
 >> iter 5000, loss: 0.802831
 >> iter 6000, loss: 0.431709
 >> iter 7000, loss: 0.260002
 >> iter 8000, loss: 0.241322
 >> iter 9000, loss: 0.430626
 >> iter 10000, loss: 0.283442
   Number of active neurons: 9
 >> iter 11000, loss: 0.219191
 >> iter 12000, loss: 0.321265
 >> iter 13000, loss: 0.257065
 >> iter 14000, loss: 0.366092
 >> iter 15000, loss: 0.195022
 >> iter 16000, loss: 0.321379
 >> iter 17000, loss: 0.276562
 >> iter 18000, loss: 0.247154
 >> iter 19000, loss: 0.238438
 >> iter 20000, loss: 0.222836
   Number of active neurons: 7
 >> iter 21000, loss: 0.246517
 >> iter 22000, loss: 0.219280
 >> iter 23000, loss: 0.403688
 >> iter 24000, loss: 0.310858
 >> iter 25000, loss: 0.204439
 >> iter 26000, loss: 0.242674
 >> iter 27000, loss: 0.173920
 >> iter 28000, loss: 0.347014
 >> iter 29000, loss: 0.239119
 >> iter 30000, loss: 0.176603
   Number of active neurons: 6
 >> iter 31000, loss: 0.215874
 >> iter 32000, loss: 0.128941
 >> iter 33000, loss: 0.311024
 >> iter 34000, loss: 0.172640
 >> iter 35000, loss: 0.329650
 >> iter 36000, loss: 0.299577
 >> iter 37000, loss: 0.306979
 >> iter 38000, loss: 0.263061
 >> iter 39000, loss: 0.185894
 >> iter 40000, loss: 0.214552
   Number of active neurons: 5
 >> iter 41000, loss: 0.156200
 >> iter 42000, loss: 0.111001
 >> iter 43000, loss: 0.512058
 >> iter 44000, loss: 0.294762
 >> iter 45000, loss: 0.226304
 >> iter 46000, loss: 0.183257
 >> iter 47000, loss: 0.317551
 >> iter 48000, loss: 0.246071
 >> iter 49000, loss: 0.183472
 >> iter 50000, loss: 0.318571
   Number of active neurons: 5
 >> iter 51000, loss: 0.196446
 >> iter 52000, loss: 0.184535
 >> iter 53000, loss: 0.119214
 >> iter 54000, loss: 0.130768
 >> iter 55000, loss: 0.267342
 >> iter 56000, loss: 0.225727
 >> iter 57000, loss: 0.164497
 >> iter 58000, loss: 0.214060
 >> iter 59000, loss: 0.183810
 >> iter 60000, loss: 0.229941
   Number of active neurons: 5
 >> iter 61000, loss: 0.230583
 >> iter 62000, loss: 0.215187
 >> iter 63000, loss: 0.382856
 >> iter 64000, loss: 0.368114
 >> iter 65000, loss: 0.252284
 >> iter 66000, loss: 0.346446
 >> iter 67000, loss: 0.276182
 >> iter 68000, loss: 0.200450
 >> iter 69000, loss: 0.303971
 >> iter 70000, loss: 0.222046
   Number of active neurons: 5
 >> iter 71000, loss: 0.296881
 >> iter 72000, loss: 0.250947
 >> iter 73000, loss: 0.205544
 >> iter 74000, loss: 0.318543
 >> iter 75000, loss: 0.236603
 >> iter 76000, loss: 0.282780
 >> iter 77000, loss: 0.197386
 >> iter 78000, loss: 0.187508
 >> iter 79000, loss: 0.203459
 >> iter 80000, loss: 0.124564
   Number of active neurons: 5
 >> iter 81000, loss: 0.123603
 >> iter 82000, loss: 0.257584
 >> iter 83000, loss: 0.191183
 >> iter 84000, loss: 0.246356
 >> iter 85000, loss: 0.173124
 >> iter 86000, loss: 0.238484
 >> iter 87000, loss: 0.154962
 >> iter 88000, loss: 0.219405
 >> iter 89000, loss: 0.264438
 >> iter 90000, loss: 0.374524
   Number of active neurons: 5
 >> iter 91000, loss: 0.332232
 >> iter 92000, loss: 0.258089
 >> iter 93000, loss: 0.154589
 >> iter 94000, loss: 0.175852
 >> iter 95000, loss: 0.207008
 >> iter 96000, loss: 0.173420
 >> iter 97000, loss: 0.148594
 >> iter 98000, loss: 0.185586
 >> iter 99000, loss: 0.188605
 >> iter 100000, loss: 0.165974
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.903071
 >> iter 2000, loss: 11.501983
 >> iter 3000, loss: 6.087477
 >> iter 4000, loss: 2.923160
 >> iter 5000, loss: 1.414399
 >> iter 6000, loss: 0.881085
 >> iter 7000, loss: 0.618209
 >> iter 8000, loss: 0.425353
 >> iter 9000, loss: 0.402416
 >> iter 10000, loss: 0.342704
   Number of active neurons: 11
 >> iter 11000, loss: 0.260865
 >> iter 12000, loss: 0.318974
 >> iter 13000, loss: 0.381496
 >> iter 14000, loss: 0.261178
 >> iter 15000, loss: 0.349281
 >> iter 16000, loss: 0.581686
 >> iter 17000, loss: 0.486682
 >> iter 18000, loss: 0.294682
 >> iter 19000, loss: 0.260772
 >> iter 20000, loss: 0.202085
   Number of active neurons: 10
 >> iter 21000, loss: 0.400837
 >> iter 22000, loss: 0.325433
 >> iter 23000, loss: 0.370994
 >> iter 24000, loss: 0.263966
 >> iter 25000, loss: 0.356912
 >> iter 26000, loss: 0.287713
 >> iter 27000, loss: 0.342085
 >> iter 28000, loss: 0.391236
 >> iter 29000, loss: 0.294687
 >> iter 30000, loss: 0.301605
   Number of active neurons: 10
 >> iter 31000, loss: 0.423821
 >> iter 32000, loss: 0.340901
 >> iter 33000, loss: 0.220337
 >> iter 34000, loss: 0.147913
 >> iter 35000, loss: 0.238790
 >> iter 36000, loss: 0.195731
 >> iter 37000, loss: 0.353047
 >> iter 38000, loss: 0.267864
 >> iter 39000, loss: 0.328237
 >> iter 40000, loss: 0.196486
   Number of active neurons: 9
 >> iter 41000, loss: 0.239473
 >> iter 42000, loss: 0.255537
 >> iter 43000, loss: 0.520267
 >> iter 44000, loss: 0.330198
 >> iter 45000, loss: 0.201400
 >> iter 46000, loss: 0.189527
 >> iter 47000, loss: 0.316601
 >> iter 48000, loss: 0.303343
 >> iter 49000, loss: 0.195320
 >> iter 50000, loss: 0.109762
   Number of active neurons: 7
 >> iter 51000, loss: 0.146440
 >> iter 52000, loss: 0.175997
 >> iter 53000, loss: 0.234942
 >> iter 54000, loss: 0.162409
 >> iter 55000, loss: 0.159466
 >> iter 56000, loss: 0.238454
 >> iter 57000, loss: 0.215221
 >> iter 58000, loss: 0.264773
 >> iter 59000, loss: 0.162725
 >> iter 60000, loss: 0.152854
   Number of active neurons: 6
 >> iter 61000, loss: 0.289340
 >> iter 62000, loss: 0.187801
 >> iter 63000, loss: 0.241207
 >> iter 64000, loss: 0.295596
 >> iter 65000, loss: 0.376987
 >> iter 66000, loss: 0.253400
 >> iter 67000, loss: 0.329012
 >> iter 68000, loss: 0.184890
 >> iter 69000, loss: 0.213141
 >> iter 70000, loss: 0.241800
   Number of active neurons: 5
 >> iter 71000, loss: 0.142081
 >> iter 72000, loss: 0.256983
 >> iter 73000, loss: 0.213718
 >> iter 74000, loss: 0.252759
 >> iter 75000, loss: 0.253811
 >> iter 76000, loss: 0.257160
 >> iter 77000, loss: 0.355616
 >> iter 78000, loss: 0.293857
 >> iter 79000, loss: 0.258406
 >> iter 80000, loss: 0.268191
   Number of active neurons: 4
 >> iter 81000, loss: 0.152403
 >> iter 82000, loss: 0.261748
 >> iter 83000, loss: 0.168812
 >> iter 84000, loss: 0.189059
 >> iter 85000, loss: 0.149854
 >> iter 86000, loss: 0.256745
 >> iter 87000, loss: 0.231305
 >> iter 88000, loss: 0.170331
 >> iter 89000, loss: 0.192875
 >> iter 90000, loss: 0.307252
   Number of active neurons: 4
 >> iter 91000, loss: 0.339847
 >> iter 92000, loss: 0.417935
 >> iter 93000, loss: 0.352060
 >> iter 94000, loss: 0.213282
 >> iter 95000, loss: 0.324003
 >> iter 96000, loss: 0.218628
 >> iter 97000, loss: 0.278067
 >> iter 98000, loss: 0.311103
 >> iter 99000, loss: 0.186859
 >> iter 100000, loss: 0.164953
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.023740
 >> iter 2000, loss: 9.891362
 >> iter 3000, loss: 4.274513
 >> iter 4000, loss: 1.839710
 >> iter 5000, loss: 0.979263
 >> iter 6000, loss: 0.674246
 >> iter 7000, loss: 0.444123
 >> iter 8000, loss: 0.382094
 >> iter 9000, loss: 0.318205
 >> iter 10000, loss: 0.283175
   Number of active neurons: 7
 >> iter 11000, loss: 0.282244
 >> iter 12000, loss: 0.335842
 >> iter 13000, loss: 0.499626
 >> iter 14000, loss: 0.352580
 >> iter 15000, loss: 0.495612
 >> iter 16000, loss: 0.389648
 >> iter 17000, loss: 0.347837
 >> iter 18000, loss: 0.282673
 >> iter 19000, loss: 0.266754
 >> iter 20000, loss: 0.284322
   Number of active neurons: 7
 >> iter 21000, loss: 0.261026
 >> iter 22000, loss: 0.217595
 >> iter 23000, loss: 0.222914
 >> iter 24000, loss: 0.298190
 >> iter 25000, loss: 0.311410
 >> iter 26000, loss: 0.281707
 >> iter 27000, loss: 0.257365
 >> iter 28000, loss: 0.266838
 >> iter 29000, loss: 0.475214
 >> iter 30000, loss: 0.426321
   Number of active neurons: 6
 >> iter 31000, loss: 0.298760
 >> iter 32000, loss: 0.297863
 >> iter 33000, loss: 0.327803
 >> iter 34000, loss: 0.332356
 >> iter 35000, loss: 0.248012
 >> iter 36000, loss: 0.179529
 >> iter 37000, loss: 0.124911
 >> iter 38000, loss: 0.097579
 >> iter 39000, loss: 0.192472
 >> iter 40000, loss: 0.198009
   Number of active neurons: 6
 >> iter 41000, loss: 0.233105
 >> iter 42000, loss: 0.276796
 >> iter 43000, loss: 0.326355
 >> iter 44000, loss: 0.360636
 >> iter 45000, loss: 0.197183
 >> iter 46000, loss: 0.203500
 >> iter 47000, loss: 0.132542
 >> iter 48000, loss: 0.231847
 >> iter 49000, loss: 0.178689
 >> iter 50000, loss: 0.220978
   Number of active neurons: 5
 >> iter 51000, loss: 0.306024
 >> iter 52000, loss: 0.177246
 >> iter 53000, loss: 0.279639
 >> iter 54000, loss: 0.234883
 >> iter 55000, loss: 0.329239
 >> iter 56000, loss: 0.283839
 >> iter 57000, loss: 0.189414
 >> iter 58000, loss: 0.204920
 >> iter 59000, loss: 0.140741
 >> iter 60000, loss: 0.195954
   Number of active neurons: 5
 >> iter 61000, loss: 0.164253
 >> iter 62000, loss: 0.106838
 >> iter 63000, loss: 0.262394
 >> iter 64000, loss: 0.212857
 >> iter 65000, loss: 0.159002
 >> iter 66000, loss: 0.184265
 >> iter 67000, loss: 0.137745
 >> iter 68000, loss: 0.174355
 >> iter 69000, loss: 0.172935
 >> iter 70000, loss: 0.160651
   Number of active neurons: 5
 >> iter 71000, loss: 0.200042
 >> iter 72000, loss: 0.317221
 >> iter 73000, loss: 0.226960
 >> iter 74000, loss: 0.229191
 >> iter 75000, loss: 0.304590
 >> iter 76000, loss: 0.159007
 >> iter 77000, loss: 0.146641
 >> iter 78000, loss: 0.123737
 >> iter 79000, loss: 0.173880
 >> iter 80000, loss: 0.196926
   Number of active neurons: 5
 >> iter 81000, loss: 0.208864
 >> iter 82000, loss: 0.240828
 >> iter 83000, loss: 0.233695
 >> iter 84000, loss: 0.204543
 >> iter 85000, loss: 0.267779
 >> iter 86000, loss: 0.240018
 >> iter 87000, loss: 0.246399
 >> iter 88000, loss: 0.200800
 >> iter 89000, loss: 0.149537
 >> iter 90000, loss: 0.193225
   Number of active neurons: 4
 >> iter 91000, loss: 0.244251
 >> iter 92000, loss: 0.183966
 >> iter 93000, loss: 0.184818
 >> iter 94000, loss: 0.162265
 >> iter 95000, loss: 0.198772
 >> iter 96000, loss: 0.264903
 >> iter 97000, loss: 0.156125
 >> iter 98000, loss: 0.221674
 >> iter 99000, loss: 0.204696
 >> iter 100000, loss: 0.196998
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.153087
 >> iter 2000, loss: 10.954575
 >> iter 3000, loss: 5.025742
 >> iter 4000, loss: 2.155990
 >> iter 5000, loss: 1.185985
 >> iter 6000, loss: 0.698610
 >> iter 7000, loss: 0.490561
 >> iter 8000, loss: 0.353961
 >> iter 9000, loss: 0.279308
 >> iter 10000, loss: 0.268633
   Number of active neurons: 7
 >> iter 11000, loss: 0.322352
 >> iter 12000, loss: 0.331624
 >> iter 13000, loss: 0.358044
 >> iter 14000, loss: 0.474267
 >> iter 15000, loss: 0.351078
 >> iter 16000, loss: 0.282645
 >> iter 17000, loss: 0.287895
 >> iter 18000, loss: 0.288229
 >> iter 19000, loss: 0.430105
 >> iter 20000, loss: 0.312067
   Number of active neurons: 7
 >> iter 21000, loss: 0.288147
 >> iter 22000, loss: 0.402766
 >> iter 23000, loss: 0.212945
 >> iter 24000, loss: 0.419275
 >> iter 25000, loss: 0.378746
 >> iter 26000, loss: 0.288098
 >> iter 27000, loss: 0.359024
 >> iter 28000, loss: 0.308477
 >> iter 29000, loss: 0.231016
 >> iter 30000, loss: 0.240822
   Number of active neurons: 7
 >> iter 31000, loss: 0.254556
 >> iter 32000, loss: 0.259836
 >> iter 33000, loss: 0.233391
 >> iter 34000, loss: 0.343096
 >> iter 35000, loss: 0.248004
 >> iter 36000, loss: 0.231241
 >> iter 37000, loss: 0.181533
 >> iter 38000, loss: 0.154593
 >> iter 39000, loss: 0.305700
 >> iter 40000, loss: 0.295298
   Number of active neurons: 7
 >> iter 41000, loss: 0.187080
 >> iter 42000, loss: 0.225704
 >> iter 43000, loss: 0.164669
 >> iter 44000, loss: 0.172608
 >> iter 45000, loss: 0.226515
 >> iter 46000, loss: 0.146737
 >> iter 47000, loss: 0.282828
 >> iter 48000, loss: 0.211925
 >> iter 49000, loss: 0.347429
 >> iter 50000, loss: 0.275047
   Number of active neurons: 6
 >> iter 51000, loss: 0.276467
 >> iter 52000, loss: 0.206041
 >> iter 53000, loss: 0.304479
 >> iter 54000, loss: 0.221539
 >> iter 55000, loss: 0.304581
 >> iter 56000, loss: 0.288013
 >> iter 57000, loss: 0.341235
 >> iter 58000, loss: 0.217943
 >> iter 59000, loss: 0.280814
 >> iter 60000, loss: 0.322092
   Number of active neurons: 6
 >> iter 61000, loss: 0.171427
 >> iter 62000, loss: 0.249086
 >> iter 63000, loss: 0.287733
 >> iter 64000, loss: 0.251843
 >> iter 65000, loss: 0.159481
 >> iter 66000, loss: 0.215643
 >> iter 67000, loss: 0.220613
 >> iter 68000, loss: 0.192964
 >> iter 69000, loss: 0.254985
 >> iter 70000, loss: 0.235817
   Number of active neurons: 5
 >> iter 71000, loss: 0.237950
 >> iter 72000, loss: 0.219936
 >> iter 73000, loss: 0.228529
 >> iter 74000, loss: 0.349815
 >> iter 75000, loss: 0.214843
 >> iter 76000, loss: 0.157146
 >> iter 77000, loss: 0.194146
 >> iter 78000, loss: 0.165268
 >> iter 79000, loss: 0.256372
 >> iter 80000, loss: 0.204588
   Number of active neurons: 5
 >> iter 81000, loss: 0.167261
 >> iter 82000, loss: 0.132440
 >> iter 83000, loss: 0.228798
 >> iter 84000, loss: 0.315301
 >> iter 85000, loss: 0.258534
 >> iter 86000, loss: 0.180215
 >> iter 87000, loss: 0.251587
 >> iter 88000, loss: 0.248530
 >> iter 89000, loss: 0.217461
 >> iter 90000, loss: 0.241375
   Number of active neurons: 5
 >> iter 91000, loss: 0.135857
 >> iter 92000, loss: 0.273781
 >> iter 93000, loss: 0.308461
 >> iter 94000, loss: 0.296782
 >> iter 95000, loss: 0.192888
 >> iter 96000, loss: 0.231153
 >> iter 97000, loss: 0.206169
 >> iter 98000, loss: 0.313842
 >> iter 99000, loss: 0.236942
 >> iter 100000, loss: 0.256744
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.026803
 >> iter 2000, loss: 13.092720
 >> iter 3000, loss: 6.100943
 >> iter 4000, loss: 2.562458
 >> iter 5000, loss: 1.193365
 >> iter 6000, loss: 0.667534
 >> iter 7000, loss: 0.437521
 >> iter 8000, loss: 0.303616
 >> iter 9000, loss: 0.269436
 >> iter 10000, loss: 0.414231
   Number of active neurons: 9
 >> iter 11000, loss: 0.457518
 >> iter 12000, loss: 0.497484
 >> iter 13000, loss: 0.276388
 >> iter 14000, loss: 0.317518
 >> iter 15000, loss: 0.322443
 >> iter 16000, loss: 0.177181
 >> iter 17000, loss: 0.397213
 >> iter 18000, loss: 0.253925
 >> iter 19000, loss: 0.469058
 >> iter 20000, loss: 0.336623
   Number of active neurons: 9
 >> iter 21000, loss: 0.353226
 >> iter 22000, loss: 0.267224
 >> iter 23000, loss: 0.222327
 >> iter 24000, loss: 0.166224
 >> iter 25000, loss: 0.266258
 >> iter 26000, loss: 0.271257
 >> iter 27000, loss: 0.266450
 >> iter 28000, loss: 0.204119
 >> iter 29000, loss: 0.337116
 >> iter 30000, loss: 0.395468
   Number of active neurons: 9
 >> iter 31000, loss: 0.491244
 >> iter 32000, loss: 0.290048
 >> iter 33000, loss: 0.262044
 >> iter 34000, loss: 0.391234
 >> iter 35000, loss: 0.388283
 >> iter 36000, loss: 0.297157
 >> iter 37000, loss: 0.293530
 >> iter 38000, loss: 0.216725
 >> iter 39000, loss: 0.234424
 >> iter 40000, loss: 0.217293
   Number of active neurons: 9
 >> iter 41000, loss: 0.191201
 >> iter 42000, loss: 0.235026
 >> iter 43000, loss: 0.253573
 >> iter 44000, loss: 0.180376
 >> iter 45000, loss: 0.137256
 >> iter 46000, loss: 0.299647
 >> iter 47000, loss: 0.244939
 >> iter 48000, loss: 0.191623
 >> iter 49000, loss: 0.213391
 >> iter 50000, loss: 0.148123
   Number of active neurons: 7
 >> iter 51000, loss: 0.227918
 >> iter 52000, loss: 0.209375
 >> iter 53000, loss: 0.181081
 >> iter 54000, loss: 0.211371
 >> iter 55000, loss: 0.199020
 >> iter 56000, loss: 0.174282
 >> iter 57000, loss: 0.252549
 >> iter 58000, loss: 0.232420
 >> iter 59000, loss: 0.300286
 >> iter 60000, loss: 0.331795
   Number of active neurons: 6
 >> iter 61000, loss: 0.384991
 >> iter 62000, loss: 0.205191
 >> iter 63000, loss: 0.207165
 >> iter 64000, loss: 0.142137
 >> iter 65000, loss: 0.236757
 >> iter 66000, loss: 0.148288
 >> iter 67000, loss: 0.100208
 >> iter 68000, loss: 0.195281
 >> iter 69000, loss: 0.180999
 >> iter 70000, loss: 0.156098
   Number of active neurons: 5
 >> iter 71000, loss: 0.375398
 >> iter 72000, loss: 0.374154
 >> iter 73000, loss: 0.291744
 >> iter 74000, loss: 0.159490
 >> iter 75000, loss: 0.172149
 >> iter 76000, loss: 0.215676
 >> iter 77000, loss: 0.199679
 >> iter 78000, loss: 0.232514
 >> iter 79000, loss: 0.223834
 >> iter 80000, loss: 0.137860
   Number of active neurons: 5
 >> iter 81000, loss: 0.099311
 >> iter 82000, loss: 0.207849
 >> iter 83000, loss: 0.163042
 >> iter 84000, loss: 0.273189
 >> iter 85000, loss: 0.246222
 >> iter 86000, loss: 0.177100
 >> iter 87000, loss: 0.190810
 >> iter 88000, loss: 0.168755
 >> iter 89000, loss: 0.331909
 >> iter 90000, loss: 0.236321
   Number of active neurons: 5
 >> iter 91000, loss: 0.288610
 >> iter 92000, loss: 0.221627
 >> iter 93000, loss: 0.299512
 >> iter 94000, loss: 0.230534
 >> iter 95000, loss: 0.199863
 >> iter 96000, loss: 0.159795
 >> iter 97000, loss: 0.104749
 >> iter 98000, loss: 0.180662
 >> iter 99000, loss: 0.286272
 >> iter 100000, loss: 0.184161
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.853667
 >> iter 2000, loss: 11.038223
 >> iter 3000, loss: 4.820452
 >> iter 4000, loss: 2.074667
 >> iter 5000, loss: 1.306507
 >> iter 6000, loss: 0.786462
 >> iter 7000, loss: 0.471909
 >> iter 8000, loss: 0.251799
 >> iter 9000, loss: 0.229575
 >> iter 10000, loss: 0.314971
   Number of active neurons: 10
 >> iter 11000, loss: 0.239187
 >> iter 12000, loss: 0.303308
 >> iter 13000, loss: 0.350181
 >> iter 14000, loss: 0.255333
 >> iter 15000, loss: 0.377022
 >> iter 16000, loss: 0.425767
 >> iter 17000, loss: 0.259417
 >> iter 18000, loss: 0.254213
 >> iter 19000, loss: 0.242912
 >> iter 20000, loss: 0.344316
   Number of active neurons: 10
 >> iter 21000, loss: 0.277496
 >> iter 22000, loss: 0.323190
 >> iter 23000, loss: 0.227427
 >> iter 24000, loss: 0.214409
 >> iter 25000, loss: 0.304343
 >> iter 26000, loss: 0.289632
 >> iter 27000, loss: 0.277250
 >> iter 28000, loss: 0.380607
 >> iter 29000, loss: 0.405420
 >> iter 30000, loss: 0.282613
   Number of active neurons: 9
 >> iter 31000, loss: 0.320905
 >> iter 32000, loss: 0.264878
 >> iter 33000, loss: 0.362625
 >> iter 34000, loss: 0.350089
 >> iter 35000, loss: 0.235928
 >> iter 36000, loss: 0.183149
 >> iter 37000, loss: 0.298344
 >> iter 38000, loss: 0.197920
 >> iter 39000, loss: 0.198460
 >> iter 40000, loss: 0.215472
   Number of active neurons: 9
 >> iter 41000, loss: 0.316758
 >> iter 42000, loss: 0.217423
 >> iter 43000, loss: 0.255213
 >> iter 44000, loss: 0.490807
 >> iter 45000, loss: 0.290854
 >> iter 46000, loss: 0.210738
 >> iter 47000, loss: 0.313002
 >> iter 48000, loss: 0.291454
 >> iter 49000, loss: 0.197174
 >> iter 50000, loss: 0.169715
   Number of active neurons: 8
 >> iter 51000, loss: 0.256538
 >> iter 52000, loss: 0.222063
 >> iter 53000, loss: 0.250275
 >> iter 54000, loss: 0.415111
 >> iter 55000, loss: 0.275908
 >> iter 56000, loss: 0.196662
 >> iter 57000, loss: 0.353787
 >> iter 58000, loss: 0.399718
 >> iter 59000, loss: 0.417764
 >> iter 60000, loss: 0.336148
   Number of active neurons: 8
 >> iter 61000, loss: 0.244211
 >> iter 62000, loss: 0.253487
 >> iter 63000, loss: 0.246071
 >> iter 64000, loss: 0.250777
 >> iter 65000, loss: 0.323299
 >> iter 66000, loss: 0.358170
 >> iter 67000, loss: 0.477114
 >> iter 68000, loss: 0.374145
 >> iter 69000, loss: 0.322297
 >> iter 70000, loss: 0.220820
   Number of active neurons: 8
 >> iter 71000, loss: 0.159597
 >> iter 72000, loss: 0.228884
 >> iter 73000, loss: 0.312860
 >> iter 74000, loss: 0.331486
 >> iter 75000, loss: 0.353399
 >> iter 76000, loss: 0.293339
 >> iter 77000, loss: 0.331527
 >> iter 78000, loss: 0.361764
 >> iter 79000, loss: 0.176935
 >> iter 80000, loss: 0.255129
   Number of active neurons: 8
 >> iter 81000, loss: 0.239832
 >> iter 82000, loss: 0.259089
 >> iter 83000, loss: 0.204434
 >> iter 84000, loss: 0.631099
 >> iter 85000, loss: 0.442169
 >> iter 86000, loss: 0.363403
 >> iter 87000, loss: 0.225705
 >> iter 88000, loss: 0.277669
 >> iter 89000, loss: 0.191938
 >> iter 90000, loss: 0.215534
   Number of active neurons: 8
 >> iter 91000, loss: 0.297531
 >> iter 92000, loss: 0.264817
 >> iter 93000, loss: 0.365364
 >> iter 94000, loss: 0.291169
 >> iter 95000, loss: 0.320271
 >> iter 96000, loss: 0.299688
 >> iter 97000, loss: 0.199157
 >> iter 98000, loss: 0.266709
 >> iter 99000, loss: 0.312307
 >> iter 100000, loss: 0.309642
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.996423
 >> iter 2000, loss: 10.826428
 >> iter 3000, loss: 4.667063
 >> iter 4000, loss: 2.106460
 >> iter 5000, loss: 1.020435
 >> iter 6000, loss: 0.715143
 >> iter 7000, loss: 0.473412
 >> iter 8000, loss: 0.258814
 >> iter 9000, loss: 0.470198
 >> iter 10000, loss: 0.307852
   Number of active neurons: 10
 >> iter 11000, loss: 0.195317
 >> iter 12000, loss: 0.234017
 >> iter 13000, loss: 0.239518
 >> iter 14000, loss: 0.210063
 >> iter 15000, loss: 0.206714
 >> iter 16000, loss: 0.233682
 >> iter 17000, loss: 0.291756
 >> iter 18000, loss: 0.329670
 >> iter 19000, loss: 0.242111
 >> iter 20000, loss: 0.376133
   Number of active neurons: 9
 >> iter 21000, loss: 0.268881
 >> iter 22000, loss: 0.343000
 >> iter 23000, loss: 0.328389
 >> iter 24000, loss: 0.237277
 >> iter 25000, loss: 0.207228
 >> iter 26000, loss: 0.393626
 >> iter 27000, loss: 0.318652
 >> iter 28000, loss: 0.199379
 >> iter 29000, loss: 0.329062
 >> iter 30000, loss: 0.319684
   Number of active neurons: 8
 >> iter 31000, loss: 0.255640
 >> iter 32000, loss: 0.138142
 >> iter 33000, loss: 0.165910
 >> iter 34000, loss: 0.175036
 >> iter 35000, loss: 0.180166
 >> iter 36000, loss: 0.226902
 >> iter 37000, loss: 0.256904
 >> iter 38000, loss: 0.228570
 >> iter 39000, loss: 0.248721
 >> iter 40000, loss: 0.187537
   Number of active neurons: 8
 >> iter 41000, loss: 0.265649
 >> iter 42000, loss: 0.220648
 >> iter 43000, loss: 0.433140
 >> iter 44000, loss: 0.314580
 >> iter 45000, loss: 0.237918
 >> iter 46000, loss: 0.180990
 >> iter 47000, loss: 0.228172
 >> iter 48000, loss: 0.310004
 >> iter 49000, loss: 0.226515
 >> iter 50000, loss: 0.187883
   Number of active neurons: 8
 >> iter 51000, loss: 0.490387
 >> iter 52000, loss: 0.286699
 >> iter 53000, loss: 0.294296
 >> iter 54000, loss: 0.183739
 >> iter 55000, loss: 0.253898
 >> iter 56000, loss: 0.149739
 >> iter 57000, loss: 0.318538
 >> iter 58000, loss: 0.189381
 >> iter 59000, loss: 0.206768
 >> iter 60000, loss: 0.251971
   Number of active neurons: 8
 >> iter 61000, loss: 0.221070
 >> iter 62000, loss: 0.273728
 >> iter 63000, loss: 0.178680
 >> iter 64000, loss: 0.215890
 >> iter 65000, loss: 0.170055
 >> iter 66000, loss: 0.127403
 >> iter 67000, loss: 0.264144
 >> iter 68000, loss: 0.196084
 >> iter 69000, loss: 0.261889
 >> iter 70000, loss: 0.363477
   Number of active neurons: 7
 >> iter 71000, loss: 0.195285
 >> iter 72000, loss: 0.155648
 >> iter 73000, loss: 0.104219
 >> iter 74000, loss: 0.152348
 >> iter 75000, loss: 0.242367
 >> iter 76000, loss: 0.250980
 >> iter 77000, loss: 0.168379
 >> iter 78000, loss: 0.230515
 >> iter 79000, loss: 0.303300
 >> iter 80000, loss: 0.292221
   Number of active neurons: 7
 >> iter 81000, loss: 0.339117
 >> iter 82000, loss: 0.184904
 >> iter 83000, loss: 0.181520
 >> iter 84000, loss: 0.168100
 >> iter 85000, loss: 0.193104
 >> iter 86000, loss: 0.188685
 >> iter 87000, loss: 0.239981
 >> iter 88000, loss: 0.265025
 >> iter 89000, loss: 0.307894
 >> iter 90000, loss: 0.211173
   Number of active neurons: 7
 >> iter 91000, loss: 0.255634
 >> iter 92000, loss: 0.205643
 >> iter 93000, loss: 0.263314
 >> iter 94000, loss: 0.260366
 >> iter 95000, loss: 0.192834
 >> iter 96000, loss: 0.269125
 >> iter 97000, loss: 0.226095
 >> iter 98000, loss: 0.146254
 >> iter 99000, loss: 0.313842
 >> iter 100000, loss: 0.236065
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.132093
 >> iter 2000, loss: 11.454713
 >> iter 3000, loss: 5.956357
 >> iter 4000, loss: 2.833733
 >> iter 5000, loss: 1.483658
 >> iter 6000, loss: 0.871973
 >> iter 7000, loss: 0.475460
 >> iter 8000, loss: 0.320154
 >> iter 9000, loss: 0.350415
 >> iter 10000, loss: 0.294181
   Number of active neurons: 6
 >> iter 11000, loss: 0.311874
 >> iter 12000, loss: 0.293415
 >> iter 13000, loss: 0.368423
 >> iter 14000, loss: 0.301663
 >> iter 15000, loss: 0.302353
 >> iter 16000, loss: 0.258572
 >> iter 17000, loss: 0.199459
 >> iter 18000, loss: 0.352752
 >> iter 19000, loss: 0.257662
 >> iter 20000, loss: 0.242039
   Number of active neurons: 6
 >> iter 21000, loss: 0.302440
 >> iter 22000, loss: 0.341172
 >> iter 23000, loss: 0.282479
 >> iter 24000, loss: 0.279241
 >> iter 25000, loss: 0.212925
 >> iter 26000, loss: 0.306232
 >> iter 27000, loss: 0.230069
 >> iter 28000, loss: 0.287584
 >> iter 29000, loss: 0.405755
 >> iter 30000, loss: 0.249866
   Number of active neurons: 6
 >> iter 31000, loss: 0.207437
 >> iter 32000, loss: 0.240005
 >> iter 33000, loss: 0.255606
 >> iter 34000, loss: 0.306405
 >> iter 35000, loss: 0.272381
 >> iter 36000, loss: 0.241921
 >> iter 37000, loss: 0.274946
 >> iter 38000, loss: 0.260229
 >> iter 39000, loss: 0.226101
 >> iter 40000, loss: 0.243604
   Number of active neurons: 6
 >> iter 41000, loss: 0.248944
 >> iter 42000, loss: 0.277137
 >> iter 43000, loss: 0.348841
 >> iter 44000, loss: 0.252940
 >> iter 45000, loss: 0.299716
 >> iter 46000, loss: 0.456870
 >> iter 47000, loss: 0.305239
 >> iter 48000, loss: 0.249726
 >> iter 49000, loss: 0.210852
 >> iter 50000, loss: 0.336561
   Number of active neurons: 6
 >> iter 51000, loss: 0.347776
 >> iter 52000, loss: 0.274858
 >> iter 53000, loss: 0.352872
 >> iter 54000, loss: 0.229442
 >> iter 55000, loss: 0.211908
 >> iter 56000, loss: 0.238328
 >> iter 57000, loss: 0.217288
 >> iter 58000, loss: 0.225767
 >> iter 59000, loss: 0.216190
 >> iter 60000, loss: 0.205283
   Number of active neurons: 6
 >> iter 61000, loss: 0.252363
 >> iter 62000, loss: 0.200960
 >> iter 63000, loss: 0.211178
 >> iter 64000, loss: 0.373719
 >> iter 65000, loss: 0.289162
 >> iter 66000, loss: 0.301918
 >> iter 67000, loss: 0.297169
 >> iter 68000, loss: 0.271536
 >> iter 69000, loss: 0.227911
 >> iter 70000, loss: 0.155180
   Number of active neurons: 6
 >> iter 71000, loss: 0.153621
 >> iter 72000, loss: 0.216944
 >> iter 73000, loss: 0.244650
 >> iter 74000, loss: 0.246895
 >> iter 75000, loss: 0.261230
 >> iter 76000, loss: 0.230332
 >> iter 77000, loss: 0.284716
 >> iter 78000, loss: 0.152194
 >> iter 79000, loss: 0.168117
 >> iter 80000, loss: 0.148577
   Number of active neurons: 6
 >> iter 81000, loss: 0.187138
 >> iter 82000, loss: 0.246592
 >> iter 83000, loss: 0.141148
 >> iter 84000, loss: 0.246768
 >> iter 85000, loss: 0.181200
 >> iter 86000, loss: 0.313321
 >> iter 87000, loss: 0.255263
 >> iter 88000, loss: 0.183544
 >> iter 89000, loss: 0.171623
 >> iter 90000, loss: 0.145504
   Number of active neurons: 5
 >> iter 91000, loss: 0.150894
 >> iter 92000, loss: 0.202826
 >> iter 93000, loss: 0.361011
 >> iter 94000, loss: 0.238691
 >> iter 95000, loss: 0.277235
 >> iter 96000, loss: 0.318589
 >> iter 97000, loss: 0.320647
 >> iter 98000, loss: 0.194564
 >> iter 99000, loss: 0.234740
 >> iter 100000, loss: 0.213664
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.096006
 >> iter 2000, loss: 12.413076
 >> iter 3000, loss: 6.278372
 >> iter 4000, loss: 2.887203
 >> iter 5000, loss: 1.714228
 >> iter 6000, loss: 1.009349
 >> iter 7000, loss: 0.968202
 >> iter 8000, loss: 0.738745
 >> iter 9000, loss: 0.547752
 >> iter 10000, loss: 0.444402
   Number of active neurons: 9
 >> iter 11000, loss: 0.427740
 >> iter 12000, loss: 0.327061
 >> iter 13000, loss: 0.272205
 >> iter 14000, loss: 0.329739
 >> iter 15000, loss: 0.336118
 >> iter 16000, loss: 0.439428
 >> iter 17000, loss: 0.439855
 >> iter 18000, loss: 0.306461
 >> iter 19000, loss: 0.421186
 >> iter 20000, loss: 0.346274
   Number of active neurons: 9
 >> iter 21000, loss: 0.262519
 >> iter 22000, loss: 0.173171
 >> iter 23000, loss: 0.278642
 >> iter 24000, loss: 0.243416
 >> iter 25000, loss: 0.316312
 >> iter 26000, loss: 0.206266
 >> iter 27000, loss: 0.343829
 >> iter 28000, loss: 0.299658
 >> iter 29000, loss: 0.494402
 >> iter 30000, loss: 0.341224
   Number of active neurons: 8
 >> iter 31000, loss: 0.330189
 >> iter 32000, loss: 0.260627
 >> iter 33000, loss: 0.313105
 >> iter 34000, loss: 0.239027
 >> iter 35000, loss: 0.481382
 >> iter 36000, loss: 0.319578
 >> iter 37000, loss: 0.253698
 >> iter 38000, loss: 0.173164
 >> iter 39000, loss: 0.166800
 >> iter 40000, loss: 0.352523
   Number of active neurons: 8
 >> iter 41000, loss: 0.309220
 >> iter 42000, loss: 0.325765
 >> iter 43000, loss: 0.249859
 >> iter 44000, loss: 0.195919
 >> iter 45000, loss: 0.296481
 >> iter 46000, loss: 0.208939
 >> iter 47000, loss: 0.234952
 >> iter 48000, loss: 0.165470
 >> iter 49000, loss: 0.248999
 >> iter 50000, loss: 0.258920
   Number of active neurons: 7
 >> iter 51000, loss: 0.225634
 >> iter 52000, loss: 0.229485
 >> iter 53000, loss: 0.231431
 >> iter 54000, loss: 0.186706
 >> iter 55000, loss: 0.238741
 >> iter 56000, loss: 0.210906
 >> iter 57000, loss: 0.239442
 >> iter 58000, loss: 0.245890
 >> iter 59000, loss: 0.146193
 >> iter 60000, loss: 0.227490
   Number of active neurons: 6
 >> iter 61000, loss: 0.203192
 >> iter 62000, loss: 0.158753
 >> iter 63000, loss: 0.187439
 >> iter 64000, loss: 0.271395
 >> iter 65000, loss: 0.228029
 >> iter 66000, loss: 0.213877
 >> iter 67000, loss: 0.258435
 >> iter 68000, loss: 0.209559
 >> iter 69000, loss: 0.158393
 >> iter 70000, loss: 0.296521
   Number of active neurons: 6
 >> iter 71000, loss: 0.232126
 >> iter 72000, loss: 0.422458
 >> iter 73000, loss: 0.260512
 >> iter 74000, loss: 0.252987
 >> iter 75000, loss: 0.254405
 >> iter 76000, loss: 0.237406
 >> iter 77000, loss: 0.223088
 >> iter 78000, loss: 0.169955
 >> iter 79000, loss: 0.235366
 >> iter 80000, loss: 0.380663
   Number of active neurons: 5
 >> iter 81000, loss: 0.237667
 >> iter 82000, loss: 0.209234
 >> iter 83000, loss: 0.233216
 >> iter 84000, loss: 0.268786
 >> iter 85000, loss: 0.234228
 >> iter 86000, loss: 0.228731
 >> iter 87000, loss: 0.248177
 >> iter 88000, loss: 0.272697
 >> iter 89000, loss: 0.318461
 >> iter 90000, loss: 0.221411
   Number of active neurons: 5
 >> iter 91000, loss: 0.271404
 >> iter 92000, loss: 0.280440
 >> iter 93000, loss: 0.214203
 >> iter 94000, loss: 0.211464
 >> iter 95000, loss: 0.214674
 >> iter 96000, loss: 0.200640
 >> iter 97000, loss: 0.132281
 >> iter 98000, loss: 0.127350
 >> iter 99000, loss: 0.162009
 >> iter 100000, loss: 0.120365
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

