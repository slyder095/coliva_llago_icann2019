 > Problema: tomita4nueva
 > Args:
   - Hidden size: 20
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.804313
 >> iter 2000, loss: 9.253361
 >> iter 3000, loss: 4.331849
 >> iter 4000, loss: 2.333110
 >> iter 5000, loss: 1.272834
 >> iter 6000, loss: 0.727171
 >> iter 7000, loss: 0.733219
 >> iter 8000, loss: 0.372267
 >> iter 9000, loss: 0.345646
 >> iter 10000, loss: 0.551122
   Number of active neurons: 6
 >> iter 11000, loss: 0.426235
 >> iter 12000, loss: 0.349355
 >> iter 13000, loss: 0.491505
 >> iter 14000, loss: 0.610385
 >> iter 15000, loss: 0.496776
 >> iter 16000, loss: 0.387965
 >> iter 17000, loss: 0.331210
 >> iter 18000, loss: 0.235473
 >> iter 19000, loss: 0.267615
 >> iter 20000, loss: 0.288803
   Number of active neurons: 5
 >> iter 21000, loss: 0.279565
 >> iter 22000, loss: 0.286275
 >> iter 23000, loss: 0.156033
 >> iter 24000, loss: 0.344894
 >> iter 25000, loss: 0.429694
 >> iter 26000, loss: 0.245910
 >> iter 27000, loss: 0.192644
 >> iter 28000, loss: 0.420931
 >> iter 29000, loss: 0.438149
 >> iter 30000, loss: 0.338609
   Number of active neurons: 5
 >> iter 31000, loss: 0.247800
 >> iter 32000, loss: 0.231527
 >> iter 33000, loss: 0.308390
 >> iter 34000, loss: 0.561861
 >> iter 35000, loss: 0.264728
 >> iter 36000, loss: 0.226842
 >> iter 37000, loss: 0.186434
 >> iter 38000, loss: 0.293288
 >> iter 39000, loss: 0.511542
 >> iter 40000, loss: 0.493728
   Number of active neurons: 5
 >> iter 41000, loss: 0.319677
 >> iter 42000, loss: 0.169206
 >> iter 43000, loss: 0.255524
 >> iter 44000, loss: 0.350526
 >> iter 45000, loss: 0.250267
 >> iter 46000, loss: 0.425084
 >> iter 47000, loss: 0.324029
 >> iter 48000, loss: 0.269531
 >> iter 49000, loss: 0.235778
 >> iter 50000, loss: 0.216959
   Number of active neurons: 5
 >> iter 51000, loss: 0.249608
 >> iter 52000, loss: 0.235274
 >> iter 53000, loss: 0.190566
 >> iter 54000, loss: 0.180344
 >> iter 55000, loss: 0.233911
 >> iter 56000, loss: 0.197387
 >> iter 57000, loss: 0.229342
 >> iter 58000, loss: 0.437693
 >> iter 59000, loss: 0.409322
 >> iter 60000, loss: 0.438745
   Number of active neurons: 4
 >> iter 61000, loss: 0.323670
 >> iter 62000, loss: 0.212676
 >> iter 63000, loss: 0.405966
 >> iter 64000, loss: 0.426430
 >> iter 65000, loss: 0.370839
 >> iter 66000, loss: 0.363407
 >> iter 67000, loss: 0.203066
 >> iter 68000, loss: 0.300541
 >> iter 69000, loss: 0.267974
 >> iter 70000, loss: 0.413566
   Number of active neurons: 4
 >> iter 71000, loss: 0.404443
 >> iter 72000, loss: 0.349541
 >> iter 73000, loss: 0.230608
 >> iter 74000, loss: 0.368861
 >> iter 75000, loss: 0.229829
 >> iter 76000, loss: 0.278680
 >> iter 77000, loss: 0.141798
 >> iter 78000, loss: 0.140659
 >> iter 79000, loss: 0.173853
 >> iter 80000, loss: 0.348136
   Number of active neurons: 4
 >> iter 81000, loss: 0.301173
 >> iter 82000, loss: 0.189418
 >> iter 83000, loss: 0.150215
 >> iter 84000, loss: 0.195636
 >> iter 85000, loss: 0.122774
 >> iter 86000, loss: 0.379148
 >> iter 87000, loss: 0.375222
 >> iter 88000, loss: 0.237432
 >> iter 89000, loss: 0.264695
 >> iter 90000, loss: 0.385296
   Number of active neurons: 3
 >> iter 91000, loss: 0.373504
 >> iter 92000, loss: 0.214486
 >> iter 93000, loss: 0.218212
 >> iter 94000, loss: 0.186239
 >> iter 95000, loss: 0.340025
 >> iter 96000, loss: 0.207880
 >> iter 97000, loss: 0.202984
 >> iter 98000, loss: 0.216083
 >> iter 99000, loss: 0.267705
 >> iter 100000, loss: 0.353940
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.742875
 >> iter 2000, loss: 8.982125
 >> iter 3000, loss: 4.052361
 >> iter 4000, loss: 1.937715
 >> iter 5000, loss: 1.043784
 >> iter 6000, loss: 0.583427
 >> iter 7000, loss: 0.360174
 >> iter 8000, loss: 0.416940
 >> iter 9000, loss: 0.516522
 >> iter 10000, loss: 0.333936
   Number of active neurons: 6
 >> iter 11000, loss: 0.249145
 >> iter 12000, loss: 0.279322
 >> iter 13000, loss: 0.516348
 >> iter 14000, loss: 0.287731
 >> iter 15000, loss: 0.338373
 >> iter 16000, loss: 0.288090
 >> iter 17000, loss: 0.418235
 >> iter 18000, loss: 0.463200
 >> iter 19000, loss: 0.317027
 >> iter 20000, loss: 0.211999
   Number of active neurons: 5
 >> iter 21000, loss: 0.307896
 >> iter 22000, loss: 0.241402
 >> iter 23000, loss: 0.335668
 >> iter 24000, loss: 0.450335
 >> iter 25000, loss: 0.277982
 >> iter 26000, loss: 0.232861
 >> iter 27000, loss: 0.311487
 >> iter 28000, loss: 0.243848
 >> iter 29000, loss: 0.148138
 >> iter 30000, loss: 0.160869
   Number of active neurons: 3
 >> iter 31000, loss: 0.291348
 >> iter 32000, loss: 0.289374
 >> iter 33000, loss: 0.170693
 >> iter 34000, loss: 0.217434
 >> iter 35000, loss: 0.466945
 >> iter 36000, loss: 0.374972
 >> iter 37000, loss: 0.321932
 >> iter 38000, loss: 0.308841
 >> iter 39000, loss: 0.187572
 >> iter 40000, loss: 0.162158
   Number of active neurons: 3
 >> iter 41000, loss: 0.353467
 >> iter 42000, loss: 0.278967
 >> iter 43000, loss: 0.387849
 >> iter 44000, loss: 0.379198
 >> iter 45000, loss: 0.285903
 >> iter 46000, loss: 0.308988
 >> iter 47000, loss: 0.189946
 >> iter 48000, loss: 0.151190
 >> iter 49000, loss: 0.128197
 >> iter 50000, loss: 0.188122
   Number of active neurons: 3
 >> iter 51000, loss: 0.134750
 >> iter 52000, loss: 0.250485
 >> iter 53000, loss: 0.198446
 >> iter 54000, loss: 0.350300
 >> iter 55000, loss: 0.221616
 >> iter 56000, loss: 0.334557
 >> iter 57000, loss: 0.286764
 >> iter 58000, loss: 0.295490
 >> iter 59000, loss: 0.212160
 >> iter 60000, loss: 0.292548
   Number of active neurons: 3
 >> iter 61000, loss: 0.307801
 >> iter 62000, loss: 0.211552
 >> iter 63000, loss: 0.162369
 >> iter 64000, loss: 0.216058
 >> iter 65000, loss: 0.364516
 >> iter 66000, loss: 0.307767
 >> iter 67000, loss: 0.149318
 >> iter 68000, loss: 0.160180
 >> iter 69000, loss: 0.293758
 >> iter 70000, loss: 0.345656
   Number of active neurons: 3
 >> iter 71000, loss: 0.473193
 >> iter 72000, loss: 0.323481
 >> iter 73000, loss: 0.195752
 >> iter 74000, loss: 0.121453
 >> iter 75000, loss: 0.146514
 >> iter 76000, loss: 0.367267
 >> iter 77000, loss: 0.226292
 >> iter 78000, loss: 0.181286
 >> iter 79000, loss: 0.150507
 >> iter 80000, loss: 0.280404
   Number of active neurons: 3
 >> iter 81000, loss: 0.197266
 >> iter 82000, loss: 0.228235
 >> iter 83000, loss: 0.136814
 >> iter 84000, loss: 0.392017
 >> iter 85000, loss: 0.272140
 >> iter 86000, loss: 0.166590
 >> iter 87000, loss: 0.250367
 >> iter 88000, loss: 0.148827
 >> iter 89000, loss: 0.229415
 >> iter 90000, loss: 0.242412
   Number of active neurons: 3
 >> iter 91000, loss: 0.259401
 >> iter 92000, loss: 0.143125
 >> iter 93000, loss: 0.259934
 >> iter 94000, loss: 0.213746
 >> iter 95000, loss: 0.286162
 >> iter 96000, loss: 0.307435
 >> iter 97000, loss: 0.289023
 >> iter 98000, loss: 0.177583
 >> iter 99000, loss: 0.267403
 >> iter 100000, loss: 0.187829
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.470456
 >> iter 2000, loss: 8.358009
 >> iter 3000, loss: 3.734399
 >> iter 4000, loss: 1.682877
 >> iter 5000, loss: 1.080603
 >> iter 6000, loss: 0.617495
 >> iter 7000, loss: 0.523434
 >> iter 8000, loss: 0.437401
 >> iter 9000, loss: 0.553792
 >> iter 10000, loss: 0.415631
   Number of active neurons: 4
 >> iter 11000, loss: 0.423543
 >> iter 12000, loss: 0.255262
 >> iter 13000, loss: 0.373743
 >> iter 14000, loss: 0.305465
 >> iter 15000, loss: 0.179559
 >> iter 16000, loss: 0.255848
 >> iter 17000, loss: 0.398393
 >> iter 18000, loss: 0.427699
 >> iter 19000, loss: 0.450606
 >> iter 20000, loss: 0.368863
   Number of active neurons: 4
 >> iter 21000, loss: 0.451063
 >> iter 22000, loss: 0.304483
 >> iter 23000, loss: 0.354582
 >> iter 24000, loss: 0.282402
 >> iter 25000, loss: 0.205494
 >> iter 26000, loss: 0.313704
 >> iter 27000, loss: 0.363655
 >> iter 28000, loss: 0.322831
 >> iter 29000, loss: 0.566339
 >> iter 30000, loss: 0.379941
   Number of active neurons: 4
 >> iter 31000, loss: 0.566993
 >> iter 32000, loss: 0.360475
 >> iter 33000, loss: 0.272014
 >> iter 34000, loss: 0.202914
 >> iter 35000, loss: 0.184583
 >> iter 36000, loss: 0.362776
 >> iter 37000, loss: 0.506709
 >> iter 38000, loss: 0.456922
 >> iter 39000, loss: 0.508814
 >> iter 40000, loss: 0.279399
   Number of active neurons: 4
 >> iter 41000, loss: 0.304194
 >> iter 42000, loss: 0.253295
 >> iter 43000, loss: 0.311361
 >> iter 44000, loss: 0.419852
 >> iter 45000, loss: 0.400774
 >> iter 46000, loss: 0.278790
 >> iter 47000, loss: 0.204707
 >> iter 48000, loss: 0.369338
 >> iter 49000, loss: 0.219671
 >> iter 50000, loss: 0.295353
   Number of active neurons: 3
 >> iter 51000, loss: 0.153706
 >> iter 52000, loss: 0.246683
 >> iter 53000, loss: 0.182455
 >> iter 54000, loss: 0.179946
 >> iter 55000, loss: 0.275846
 >> iter 56000, loss: 0.226822
 >> iter 57000, loss: 0.371982
 >> iter 58000, loss: 0.292012
 >> iter 59000, loss: 0.253189
 >> iter 60000, loss: 0.281482
   Number of active neurons: 3
 >> iter 61000, loss: 0.269644
 >> iter 62000, loss: 0.255619
 >> iter 63000, loss: 0.186513
 >> iter 64000, loss: 0.159609
 >> iter 65000, loss: 0.198737
 >> iter 66000, loss: 0.183541
 >> iter 67000, loss: 0.260373
 >> iter 68000, loss: 0.314101
 >> iter 69000, loss: 0.291561
 >> iter 70000, loss: 0.193078
   Number of active neurons: 3
 >> iter 71000, loss: 0.349966
 >> iter 72000, loss: 0.347396
 >> iter 73000, loss: 0.332998
 >> iter 74000, loss: 0.344400
 >> iter 75000, loss: 0.355349
 >> iter 76000, loss: 0.183044
 >> iter 77000, loss: 0.182425
 >> iter 78000, loss: 0.267609
 >> iter 79000, loss: 0.220780
 >> iter 80000, loss: 0.243003
   Number of active neurons: 3
 >> iter 81000, loss: 0.156343
 >> iter 82000, loss: 0.216551
 >> iter 83000, loss: 0.217959
 >> iter 84000, loss: 0.402815
 >> iter 85000, loss: 0.316735
 >> iter 86000, loss: 0.450182
 >> iter 87000, loss: 0.224002
 >> iter 88000, loss: 0.272874
 >> iter 89000, loss: 0.322081
 >> iter 90000, loss: 0.336755
   Number of active neurons: 3
 >> iter 91000, loss: 0.224118
 >> iter 92000, loss: 0.357510
 >> iter 93000, loss: 0.270348
 >> iter 94000, loss: 0.317463
 >> iter 95000, loss: 0.318872
 >> iter 96000, loss: 0.180292
 >> iter 97000, loss: 0.266052
 >> iter 98000, loss: 0.207580
 >> iter 99000, loss: 0.152872
 >> iter 100000, loss: 0.337416
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.654078
 >> iter 2000, loss: 8.769018
 >> iter 3000, loss: 3.967018
 >> iter 4000, loss: 1.799745
 >> iter 5000, loss: 1.041571
 >> iter 6000, loss: 0.524025
 >> iter 7000, loss: 0.505749
 >> iter 8000, loss: 0.519444
 >> iter 9000, loss: 0.493401
 >> iter 10000, loss: 0.465397
   Number of active neurons: 5
 >> iter 11000, loss: 0.350029
 >> iter 12000, loss: 0.188221
 >> iter 13000, loss: 0.238087
 >> iter 14000, loss: 0.294907
 >> iter 15000, loss: 0.322092
 >> iter 16000, loss: 0.388727
 >> iter 17000, loss: 0.305998
 >> iter 18000, loss: 0.618234
 >> iter 19000, loss: 0.511383
 >> iter 20000, loss: 0.482586
   Number of active neurons: 5
 >> iter 21000, loss: 0.326975
 >> iter 22000, loss: 0.316948
 >> iter 23000, loss: 0.279743
 >> iter 24000, loss: 0.268870
 >> iter 25000, loss: 0.341699
 >> iter 26000, loss: 0.247841
 >> iter 27000, loss: 0.422853
 >> iter 28000, loss: 0.433681
 >> iter 29000, loss: 0.382933
 >> iter 30000, loss: 0.380368
   Number of active neurons: 5
 >> iter 31000, loss: 0.448129
 >> iter 32000, loss: 0.421744
 >> iter 33000, loss: 0.360574
 >> iter 34000, loss: 0.306679
 >> iter 35000, loss: 0.179322
 >> iter 36000, loss: 0.204856
 >> iter 37000, loss: 0.208742
 >> iter 38000, loss: 0.303528
 >> iter 39000, loss: 0.441732
 >> iter 40000, loss: 0.299990
   Number of active neurons: 5
 >> iter 41000, loss: 0.398847
 >> iter 42000, loss: 0.567686
 >> iter 43000, loss: 0.357568
 >> iter 44000, loss: 0.237761
 >> iter 45000, loss: 0.339083
 >> iter 46000, loss: 0.444972
 >> iter 47000, loss: 0.340693
 >> iter 48000, loss: 0.338876
 >> iter 49000, loss: 0.388966
 >> iter 50000, loss: 0.334287
   Number of active neurons: 4
 >> iter 51000, loss: 0.353164
 >> iter 52000, loss: 0.365923
 >> iter 53000, loss: 0.280164
 >> iter 54000, loss: 0.359997
 >> iter 55000, loss: 0.349557
 >> iter 56000, loss: 0.526327
 >> iter 57000, loss: 0.313228
 >> iter 58000, loss: 0.180820
 >> iter 59000, loss: 0.354790
 >> iter 60000, loss: 0.324197
   Number of active neurons: 4
 >> iter 61000, loss: 0.348824
 >> iter 62000, loss: 0.337166
 >> iter 63000, loss: 0.260307
 >> iter 64000, loss: 0.464690
 >> iter 65000, loss: 0.393771
 >> iter 66000, loss: 0.309589
 >> iter 67000, loss: 0.226177
 >> iter 68000, loss: 0.342727
 >> iter 69000, loss: 0.213947
 >> iter 70000, loss: 0.155695
   Number of active neurons: 3
 >> iter 71000, loss: 0.191132
 >> iter 72000, loss: 0.557254
 >> iter 73000, loss: 0.318152
 >> iter 74000, loss: 0.308198
 >> iter 75000, loss: 0.244089
 >> iter 76000, loss: 0.449851
 >> iter 77000, loss: 0.395507
 >> iter 78000, loss: 0.295727
 >> iter 79000, loss: 0.244307
 >> iter 80000, loss: 0.352638
   Number of active neurons: 3
 >> iter 81000, loss: 0.420781
 >> iter 82000, loss: 0.352788
 >> iter 83000, loss: 0.385509
 >> iter 84000, loss: 0.419097
 >> iter 85000, loss: 0.265816
 >> iter 86000, loss: 0.375710
 >> iter 87000, loss: 0.211227
 >> iter 88000, loss: 0.313957
 >> iter 89000, loss: 0.252252
 >> iter 90000, loss: 0.354983
   Number of active neurons: 3
 >> iter 91000, loss: 0.242399
 >> iter 92000, loss: 0.198080
 >> iter 93000, loss: 0.202553
 >> iter 94000, loss: 0.185712
 >> iter 95000, loss: 0.271363
 >> iter 96000, loss: 0.338150
 >> iter 97000, loss: 0.293541
 >> iter 98000, loss: 0.227526
 >> iter 99000, loss: 0.316307
 >> iter 100000, loss: 0.233777
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.574172
 >> iter 2000, loss: 8.902794
 >> iter 3000, loss: 3.924834
 >> iter 4000, loss: 1.901837
 >> iter 5000, loss: 1.085297
 >> iter 6000, loss: 0.696227
 >> iter 7000, loss: 0.560831
 >> iter 8000, loss: 0.479190
 >> iter 9000, loss: 0.321522
 >> iter 10000, loss: 0.512138
   Number of active neurons: 5
 >> iter 11000, loss: 0.308629
 >> iter 12000, loss: 0.151059
 >> iter 13000, loss: 0.249311
 >> iter 14000, loss: 0.294433
 >> iter 15000, loss: 0.168974
 >> iter 16000, loss: 0.612028
 >> iter 17000, loss: 0.423538
 >> iter 18000, loss: 0.246679
 >> iter 19000, loss: 0.297075
 >> iter 20000, loss: 0.452430
   Number of active neurons: 5
 >> iter 21000, loss: 0.363007
 >> iter 22000, loss: 0.339680
 >> iter 23000, loss: 0.335779
 >> iter 24000, loss: 0.386344
 >> iter 25000, loss: 0.397429
 >> iter 26000, loss: 0.621650
 >> iter 27000, loss: 0.451675
 >> iter 28000, loss: 0.440653
 >> iter 29000, loss: 0.416013
 >> iter 30000, loss: 0.377979
   Number of active neurons: 5
 >> iter 31000, loss: 0.335691
 >> iter 32000, loss: 0.484026
 >> iter 33000, loss: 0.318940
 >> iter 34000, loss: 0.205262
 >> iter 35000, loss: 0.377666
 >> iter 36000, loss: 0.295370
 >> iter 37000, loss: 0.414539
 >> iter 38000, loss: 0.367702
 >> iter 39000, loss: 0.420872
 >> iter 40000, loss: 0.374354
   Number of active neurons: 5
 >> iter 41000, loss: 0.391782
 >> iter 42000, loss: 0.547200
 >> iter 43000, loss: 0.472632
 >> iter 44000, loss: 0.472123
 >> iter 45000, loss: 0.487397
 >> iter 46000, loss: 0.344136
 >> iter 47000, loss: 0.421260
 >> iter 48000, loss: 0.535991
 >> iter 49000, loss: 0.411828
 >> iter 50000, loss: 0.306111
   Number of active neurons: 5
 >> iter 51000, loss: 0.265372
 >> iter 52000, loss: 0.235027
 >> iter 53000, loss: 0.289033
 >> iter 54000, loss: 0.226071
 >> iter 55000, loss: 0.393214
 >> iter 56000, loss: 0.292674
 >> iter 57000, loss: 0.392023
 >> iter 58000, loss: 0.251724
 >> iter 59000, loss: 0.337116
 >> iter 60000, loss: 0.299112
   Number of active neurons: 5
 >> iter 61000, loss: 0.250209
 >> iter 62000, loss: 0.191434
 >> iter 63000, loss: 0.243462
 >> iter 64000, loss: 0.283865
 >> iter 65000, loss: 0.168286
 >> iter 66000, loss: 0.137049
 >> iter 67000, loss: 0.277468
 >> iter 68000, loss: 0.137880
 >> iter 69000, loss: 0.264534
 >> iter 70000, loss: 0.488316
   Number of active neurons: 5
 >> iter 71000, loss: 0.601074
 >> iter 72000, loss: 0.366169
 >> iter 73000, loss: 0.359022
 >> iter 74000, loss: 0.196737
 >> iter 75000, loss: 0.187368
 >> iter 76000, loss: 0.235887
 >> iter 77000, loss: 0.327791
 >> iter 78000, loss: 0.374282
 >> iter 79000, loss: 0.225409
 >> iter 80000, loss: 0.356226
   Number of active neurons: 5
 >> iter 81000, loss: 0.391821
 >> iter 82000, loss: 0.362625
 >> iter 83000, loss: 0.242874
 >> iter 84000, loss: 0.282102
 >> iter 85000, loss: 0.565178
 >> iter 86000, loss: 0.482057
 >> iter 87000, loss: 0.313171
 >> iter 88000, loss: 0.151852
 >> iter 89000, loss: 0.105802
 >> iter 90000, loss: 0.378652
   Number of active neurons: 4
 >> iter 91000, loss: 0.322676
 >> iter 92000, loss: 0.309392
 >> iter 93000, loss: 0.242575
 >> iter 94000, loss: 0.289983
 >> iter 95000, loss: 0.216101
 >> iter 96000, loss: 0.184234
 >> iter 97000, loss: 0.210463
 >> iter 98000, loss: 0.179604
 >> iter 99000, loss: 0.165276
 >> iter 100000, loss: 0.204441
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.645709
 >> iter 2000, loss: 9.040288
 >> iter 3000, loss: 4.043926
 >> iter 4000, loss: 2.158100
 >> iter 5000, loss: 1.073336
 >> iter 6000, loss: 0.836333
 >> iter 7000, loss: 0.554008
 >> iter 8000, loss: 0.370800
 >> iter 9000, loss: 0.467039
 >> iter 10000, loss: 0.537295
   Number of active neurons: 7
 >> iter 11000, loss: 0.457837
 >> iter 12000, loss: 0.219214
 >> iter 13000, loss: 0.302045
 >> iter 14000, loss: 0.294489
 >> iter 15000, loss: 0.371345
 >> iter 16000, loss: 0.282121
 >> iter 17000, loss: 0.494886
 >> iter 18000, loss: 0.496656
 >> iter 19000, loss: 0.366918
 >> iter 20000, loss: 0.347393
   Number of active neurons: 7
 >> iter 21000, loss: 0.459361
 >> iter 22000, loss: 0.398035
 >> iter 23000, loss: 0.473827
 >> iter 24000, loss: 0.262784
 >> iter 25000, loss: 0.461915
 >> iter 26000, loss: 0.263620
 >> iter 27000, loss: 0.386077
 >> iter 28000, loss: 0.395771
 >> iter 29000, loss: 0.437959
 >> iter 30000, loss: 0.503835
   Number of active neurons: 5
 >> iter 31000, loss: 0.510223
 >> iter 32000, loss: 0.507454
 >> iter 33000, loss: 0.446022
 >> iter 34000, loss: 0.487514
 >> iter 35000, loss: 0.575360
 >> iter 36000, loss: 0.452332
 >> iter 37000, loss: 0.605191
 >> iter 38000, loss: 0.436200
 >> iter 39000, loss: 0.237279
 >> iter 40000, loss: 0.308808
   Number of active neurons: 5
 >> iter 41000, loss: 0.222261
 >> iter 42000, loss: 0.282054
 >> iter 43000, loss: 0.222427
 >> iter 44000, loss: 0.265915
 >> iter 45000, loss: 0.253432
 >> iter 46000, loss: 0.326082
 >> iter 47000, loss: 0.473147
 >> iter 48000, loss: 0.484668
 >> iter 49000, loss: 0.383144
 >> iter 50000, loss: 0.442242
   Number of active neurons: 5
 >> iter 51000, loss: 0.403814
 >> iter 52000, loss: 0.286385
 >> iter 53000, loss: 0.353212
 >> iter 54000, loss: 0.330530
 >> iter 55000, loss: 0.284043
 >> iter 56000, loss: 0.275457
 >> iter 57000, loss: 0.322790
 >> iter 58000, loss: 0.361019
 >> iter 59000, loss: 0.450022
 >> iter 60000, loss: 0.477528
   Number of active neurons: 5
 >> iter 61000, loss: 0.398544
 >> iter 62000, loss: 0.267483
 >> iter 63000, loss: 0.310262
 >> iter 64000, loss: 0.350279
 >> iter 65000, loss: 0.346118
 >> iter 66000, loss: 0.514409
 >> iter 67000, loss: 0.323971
 >> iter 68000, loss: 0.260097
 >> iter 69000, loss: 0.244843
 >> iter 70000, loss: 0.247601
   Number of active neurons: 5
 >> iter 71000, loss: 0.348728
 >> iter 72000, loss: 0.425552
 >> iter 73000, loss: 0.292272
 >> iter 74000, loss: 0.477205
 >> iter 75000, loss: 0.337773
 >> iter 76000, loss: 0.298128
 >> iter 77000, loss: 0.477263
 >> iter 78000, loss: 0.511792
 >> iter 79000, loss: 0.516651
 >> iter 80000, loss: 0.354159
   Number of active neurons: 5
 >> iter 81000, loss: 0.480210
 >> iter 82000, loss: 0.556176
 >> iter 83000, loss: 0.273380
 >> iter 84000, loss: 0.368321
 >> iter 85000, loss: 0.459937
 >> iter 86000, loss: 0.484101
 >> iter 87000, loss: 0.288882
 >> iter 88000, loss: 0.215406
 >> iter 89000, loss: 0.267057
 >> iter 90000, loss: 0.383619
   Number of active neurons: 5
 >> iter 91000, loss: 0.284212
 >> iter 92000, loss: 0.422238
 >> iter 93000, loss: 0.276731
 >> iter 94000, loss: 0.166171
 >> iter 95000, loss: 0.396013
 >> iter 96000, loss: 0.279330
 >> iter 97000, loss: 0.175322
 >> iter 98000, loss: 0.284448
 >> iter 99000, loss: 0.219679
 >> iter 100000, loss: 0.265859
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.394362
 >> iter 2000, loss: 8.685650
 >> iter 3000, loss: 3.876306
 >> iter 4000, loss: 1.713628
 >> iter 5000, loss: 1.009144
 >> iter 6000, loss: 0.496787
 >> iter 7000, loss: 0.440541
 >> iter 8000, loss: 0.313578
 >> iter 9000, loss: 0.385884
 >> iter 10000, loss: 0.517190
   Number of active neurons: 4
 >> iter 11000, loss: 0.446615
 >> iter 12000, loss: 0.383057
 >> iter 13000, loss: 0.342830
 >> iter 14000, loss: 0.369803
 >> iter 15000, loss: 0.611258
 >> iter 16000, loss: 0.457793
 >> iter 17000, loss: 0.384050
 >> iter 18000, loss: 0.382260
 >> iter 19000, loss: 0.259187
 >> iter 20000, loss: 0.344037
   Number of active neurons: 4
 >> iter 21000, loss: 0.326908
 >> iter 22000, loss: 0.296888
 >> iter 23000, loss: 0.285356
 >> iter 24000, loss: 0.238623
 >> iter 25000, loss: 0.441879
 >> iter 26000, loss: 0.507224
 >> iter 27000, loss: 0.358403
 >> iter 28000, loss: 0.212448
 >> iter 29000, loss: 0.279977
 >> iter 30000, loss: 0.341577
   Number of active neurons: 4
 >> iter 31000, loss: 0.396369
 >> iter 32000, loss: 0.450435
 >> iter 33000, loss: 0.311424
 >> iter 34000, loss: 0.224773
 >> iter 35000, loss: 0.209476
 >> iter 36000, loss: 0.159545
 >> iter 37000, loss: 0.226486
 >> iter 38000, loss: 0.324886
 >> iter 39000, loss: 0.172970
 >> iter 40000, loss: 0.113767
   Number of active neurons: 4
 >> iter 41000, loss: 0.238479
 >> iter 42000, loss: 0.182201
 >> iter 43000, loss: 0.511482
 >> iter 44000, loss: 0.400798
 >> iter 45000, loss: 0.421481
 >> iter 46000, loss: 0.417805
 >> iter 47000, loss: 0.212914
 >> iter 48000, loss: 0.215350
 >> iter 49000, loss: 0.251836
 >> iter 50000, loss: 0.225819
   Number of active neurons: 3
 >> iter 51000, loss: 0.359004
 >> iter 52000, loss: 0.273279
 >> iter 53000, loss: 0.417148
 >> iter 54000, loss: 0.292383
 >> iter 55000, loss: 0.299219
 >> iter 56000, loss: 0.270462
 >> iter 57000, loss: 0.268410
 >> iter 58000, loss: 0.294984
 >> iter 59000, loss: 0.245248
 >> iter 60000, loss: 0.189585
   Number of active neurons: 3
 >> iter 61000, loss: 0.191831
 >> iter 62000, loss: 0.196180
 >> iter 63000, loss: 0.207798
 >> iter 64000, loss: 0.146803
 >> iter 65000, loss: 0.338924
 >> iter 66000, loss: 0.185178
 >> iter 67000, loss: 0.182180
 >> iter 68000, loss: 0.123299
 >> iter 69000, loss: 0.114517
 >> iter 70000, loss: 0.325796
   Number of active neurons: 3
 >> iter 71000, loss: 0.307719
 >> iter 72000, loss: 0.419094
 >> iter 73000, loss: 0.414207
 >> iter 74000, loss: 0.218439
 >> iter 75000, loss: 0.337688
 >> iter 76000, loss: 0.207770
 >> iter 77000, loss: 0.215875
 >> iter 78000, loss: 0.178287
 >> iter 79000, loss: 0.275166
 >> iter 80000, loss: 0.234149
   Number of active neurons: 3
 >> iter 81000, loss: 0.188074
 >> iter 82000, loss: 0.102397
 >> iter 83000, loss: 0.355928
 >> iter 84000, loss: 0.198145
 >> iter 85000, loss: 0.259942
 >> iter 86000, loss: 0.333468
 >> iter 87000, loss: 0.204985
 >> iter 88000, loss: 0.397047
 >> iter 89000, loss: 0.223989
 >> iter 90000, loss: 0.242708
   Number of active neurons: 3
 >> iter 91000, loss: 0.388003
 >> iter 92000, loss: 0.277082
 >> iter 93000, loss: 0.447165
 >> iter 94000, loss: 0.297596
 >> iter 95000, loss: 0.312134
 >> iter 96000, loss: 0.366963
 >> iter 97000, loss: 0.193473
 >> iter 98000, loss: 0.326032
 >> iter 99000, loss: 0.215298
 >> iter 100000, loss: 0.165060
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.380787
 >> iter 2000, loss: 8.966097
 >> iter 3000, loss: 4.281184
 >> iter 4000, loss: 1.980802
 >> iter 5000, loss: 1.020311
 >> iter 6000, loss: 0.604907
 >> iter 7000, loss: 0.523041
 >> iter 8000, loss: 0.680741
 >> iter 9000, loss: 0.469701
 >> iter 10000, loss: 0.310714
   Number of active neurons: 6
 >> iter 11000, loss: 0.419158
 >> iter 12000, loss: 0.611661
 >> iter 13000, loss: 0.642202
 >> iter 14000, loss: 0.826878
 >> iter 15000, loss: 0.594213
 >> iter 16000, loss: 0.410786
 >> iter 17000, loss: 0.306181
 >> iter 18000, loss: 0.428922
 >> iter 19000, loss: 0.527208
 >> iter 20000, loss: 0.498664
   Number of active neurons: 6
 >> iter 21000, loss: 0.399619
 >> iter 22000, loss: 0.480085
 >> iter 23000, loss: 0.423914
 >> iter 24000, loss: 0.439314
 >> iter 25000, loss: 0.370788
 >> iter 26000, loss: 0.505601
 >> iter 27000, loss: 0.385019
 >> iter 28000, loss: 0.456315
 >> iter 29000, loss: 0.537551
 >> iter 30000, loss: 0.446092
   Number of active neurons: 6
 >> iter 31000, loss: 0.703176
 >> iter 32000, loss: 0.573176
 >> iter 33000, loss: 0.526600
 >> iter 34000, loss: 0.483371
 >> iter 35000, loss: 0.297776
 >> iter 36000, loss: 0.382672
 >> iter 37000, loss: 0.299427
 >> iter 38000, loss: 0.483523
 >> iter 39000, loss: 0.633005
 >> iter 40000, loss: 0.439597
   Number of active neurons: 6
 >> iter 41000, loss: 0.528907
 >> iter 42000, loss: 0.315870
 >> iter 43000, loss: 0.518276
 >> iter 44000, loss: 0.539347
 >> iter 45000, loss: 0.412537
 >> iter 46000, loss: 0.343649
 >> iter 47000, loss: 0.450183
 >> iter 48000, loss: 0.395740
 >> iter 49000, loss: 0.408048
 >> iter 50000, loss: 0.425516
   Number of active neurons: 6
 >> iter 51000, loss: 0.446590
 >> iter 52000, loss: 0.420398
 >> iter 53000, loss: 0.261055
 >> iter 54000, loss: 0.559641
 >> iter 55000, loss: 0.567437
 >> iter 56000, loss: 0.745937
 >> iter 57000, loss: 0.642945
 >> iter 58000, loss: 0.483122
 >> iter 59000, loss: 0.441121
 >> iter 60000, loss: 0.296072
   Number of active neurons: 5
 >> iter 61000, loss: 0.306647
 >> iter 62000, loss: 0.318813
 >> iter 63000, loss: 0.290320
 >> iter 64000, loss: 0.336894
 >> iter 65000, loss: 0.370428
 >> iter 66000, loss: 0.337676
 >> iter 67000, loss: 0.472735
 >> iter 68000, loss: 0.488708
 >> iter 69000, loss: 0.477632
 >> iter 70000, loss: 0.677778
   Number of active neurons: 5
 >> iter 71000, loss: 0.452699
 >> iter 72000, loss: 0.351029
 >> iter 73000, loss: 0.462290
 >> iter 74000, loss: 0.340361
 >> iter 75000, loss: 0.406458
 >> iter 76000, loss: 0.358119
 >> iter 77000, loss: 0.310542
 >> iter 78000, loss: 0.462340
 >> iter 79000, loss: 0.454835
 >> iter 80000, loss: 0.317031
   Number of active neurons: 5
 >> iter 81000, loss: 0.345902
 >> iter 82000, loss: 0.231932
 >> iter 83000, loss: 0.296057
 >> iter 84000, loss: 0.629804
 >> iter 85000, loss: 0.532696
 >> iter 86000, loss: 0.435319
 >> iter 87000, loss: 0.451975
 >> iter 88000, loss: 0.369829
 >> iter 89000, loss: 0.475664
 >> iter 90000, loss: 0.399421
   Number of active neurons: 4
 >> iter 91000, loss: 0.408522
 >> iter 92000, loss: 0.342283
 >> iter 93000, loss: 0.489309
 >> iter 94000, loss: 0.552250
 >> iter 95000, loss: 0.453464
 >> iter 96000, loss: 0.426907
 >> iter 97000, loss: 0.296760
 >> iter 98000, loss: 0.494418
 >> iter 99000, loss: 0.545119
 >> iter 100000, loss: 0.510050
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.413490
 >> iter 2000, loss: 8.686217
 >> iter 3000, loss: 4.120384
 >> iter 4000, loss: 1.867121
 >> iter 5000, loss: 1.065095
 >> iter 6000, loss: 0.708200
 >> iter 7000, loss: 0.446740
 >> iter 8000, loss: 0.517336
 >> iter 9000, loss: 0.310656
 >> iter 10000, loss: 0.290921
   Number of active neurons: 5
 >> iter 11000, loss: 0.435568
 >> iter 12000, loss: 0.348895
 >> iter 13000, loss: 0.457796
 >> iter 14000, loss: 0.477679
 >> iter 15000, loss: 0.385473
 >> iter 16000, loss: 0.386874
 >> iter 17000, loss: 0.431690
 >> iter 18000, loss: 0.295813
 >> iter 19000, loss: 0.350201
 >> iter 20000, loss: 0.289094
   Number of active neurons: 5
 >> iter 21000, loss: 0.430817
 >> iter 22000, loss: 0.288326
 >> iter 23000, loss: 0.294374
 >> iter 24000, loss: 0.188600
 >> iter 25000, loss: 0.154717
 >> iter 26000, loss: 0.422527
 >> iter 27000, loss: 0.414630
 >> iter 28000, loss: 0.319829
 >> iter 29000, loss: 0.304384
 >> iter 30000, loss: 0.392140
   Number of active neurons: 5
 >> iter 31000, loss: 0.300264
 >> iter 32000, loss: 0.306323
 >> iter 33000, loss: 0.273189
 >> iter 34000, loss: 0.229787
 >> iter 35000, loss: 0.291808
 >> iter 36000, loss: 0.385031
 >> iter 37000, loss: 0.461871
 >> iter 38000, loss: 0.422458
 >> iter 39000, loss: 0.502743
 >> iter 40000, loss: 0.334937
   Number of active neurons: 4
 >> iter 41000, loss: 0.477340
 >> iter 42000, loss: 0.527508
 >> iter 43000, loss: 0.605315
 >> iter 44000, loss: 0.358840
 >> iter 45000, loss: 0.226278
 >> iter 46000, loss: 0.141406
 >> iter 47000, loss: 0.226853
 >> iter 48000, loss: 0.300686
 >> iter 49000, loss: 0.172187
 >> iter 50000, loss: 0.175280
   Number of active neurons: 4
 >> iter 51000, loss: 0.198387
 >> iter 52000, loss: 0.199677
 >> iter 53000, loss: 0.180056
 >> iter 54000, loss: 0.470367
 >> iter 55000, loss: 0.332678
 >> iter 56000, loss: 0.401755
 >> iter 57000, loss: 0.288854
 >> iter 58000, loss: 0.182673
 >> iter 59000, loss: 0.238265
 >> iter 60000, loss: 0.148554
   Number of active neurons: 4
 >> iter 61000, loss: 0.273115
 >> iter 62000, loss: 0.370626
 >> iter 63000, loss: 0.242794
 >> iter 64000, loss: 0.314064
 >> iter 65000, loss: 0.314465
 >> iter 66000, loss: 0.320709
 >> iter 67000, loss: 0.214511
 >> iter 68000, loss: 0.275062
 >> iter 69000, loss: 0.132978
 >> iter 70000, loss: 0.294530
   Number of active neurons: 4
 >> iter 71000, loss: 0.223920
 >> iter 72000, loss: 0.287112
 >> iter 73000, loss: 0.256645
 >> iter 74000, loss: 0.274953
 >> iter 75000, loss: 0.199071
 >> iter 76000, loss: 0.226974
 >> iter 77000, loss: 0.204621
 >> iter 78000, loss: 0.231845
 >> iter 79000, loss: 0.153029
 >> iter 80000, loss: 0.179524
   Number of active neurons: 3
 >> iter 81000, loss: 0.207696
 >> iter 82000, loss: 0.126304
 >> iter 83000, loss: 0.150827
 >> iter 84000, loss: 0.186993
 >> iter 85000, loss: 0.379596
 >> iter 86000, loss: 0.381072
 >> iter 87000, loss: 0.237516
 >> iter 88000, loss: 0.234500
 >> iter 89000, loss: 0.127926
 >> iter 90000, loss: 0.218392
   Number of active neurons: 3
 >> iter 91000, loss: 0.279923
 >> iter 92000, loss: 0.400944
 >> iter 93000, loss: 0.265248
 >> iter 94000, loss: 0.295412
 >> iter 95000, loss: 0.308481
 >> iter 96000, loss: 0.231868
 >> iter 97000, loss: 0.185369
 >> iter 98000, loss: 0.185161
 >> iter 99000, loss: 0.211978
 >> iter 100000, loss: 0.277755
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.419148
 >> iter 2000, loss: 9.262384
 >> iter 3000, loss: 4.370932
 >> iter 4000, loss: 2.036086
 >> iter 5000, loss: 1.471228
 >> iter 6000, loss: 0.843855
 >> iter 7000, loss: 0.612827
 >> iter 8000, loss: 0.759208
 >> iter 9000, loss: 0.738945
 >> iter 10000, loss: 0.700701
   Number of active neurons: 5
 >> iter 11000, loss: 0.598146
 >> iter 12000, loss: 0.363961
 >> iter 13000, loss: 0.639229
 >> iter 14000, loss: 0.641896
 >> iter 15000, loss: 0.416164
 >> iter 16000, loss: 0.301644
 >> iter 17000, loss: 0.642276
 >> iter 18000, loss: 0.705554
 >> iter 19000, loss: 0.790177
 >> iter 20000, loss: 0.782709
   Number of active neurons: 4
 >> iter 21000, loss: 0.462704
 >> iter 22000, loss: 0.580774
 >> iter 23000, loss: 0.427202
 >> iter 24000, loss: 0.401187
 >> iter 25000, loss: 0.304726
 >> iter 26000, loss: 0.232112
 >> iter 27000, loss: 0.420086
 >> iter 28000, loss: 0.576546
 >> iter 29000, loss: 0.436570
 >> iter 30000, loss: 0.508629
   Number of active neurons: 4
 >> iter 31000, loss: 0.326977
 >> iter 32000, loss: 0.464475
 >> iter 33000, loss: 0.324786
 >> iter 34000, loss: 0.318328
 >> iter 35000, loss: 0.172060
 >> iter 36000, loss: 0.345888
 >> iter 37000, loss: 0.378698
 >> iter 38000, loss: 0.523886
 >> iter 39000, loss: 0.410313
 >> iter 40000, loss: 0.496906
   Number of active neurons: 4
 >> iter 41000, loss: 0.536707
 >> iter 42000, loss: 0.518066
 >> iter 43000, loss: 0.591036
 >> iter 44000, loss: 0.496780
 >> iter 45000, loss: 0.603878
 >> iter 46000, loss: 0.567522
 >> iter 47000, loss: 0.533158
 >> iter 48000, loss: 0.536483
 >> iter 49000, loss: 0.379548
 >> iter 50000, loss: 0.498276
   Number of active neurons: 4
 >> iter 51000, loss: 0.424719
 >> iter 52000, loss: 0.663263
 >> iter 53000, loss: 0.467022
 >> iter 54000, loss: 0.503982
 >> iter 55000, loss: 0.394980
 >> iter 56000, loss: 0.500665
 >> iter 57000, loss: 0.468757
 >> iter 58000, loss: 0.300368
 >> iter 59000, loss: 0.502521
 >> iter 60000, loss: 0.515287
   Number of active neurons: 4
 >> iter 61000, loss: 0.410926
 >> iter 62000, loss: 0.418658
 >> iter 63000, loss: 0.654485
 >> iter 64000, loss: 0.689153
 >> iter 65000, loss: 0.452107
 >> iter 66000, loss: 0.305252
 >> iter 67000, loss: 0.315853
 >> iter 68000, loss: 0.306087
 >> iter 69000, loss: 0.580883
 >> iter 70000, loss: 0.596294
   Number of active neurons: 4
 >> iter 71000, loss: 0.556064
 >> iter 72000, loss: 0.563434
 >> iter 73000, loss: 0.569704
 >> iter 74000, loss: 0.442900
 >> iter 75000, loss: 0.459102
 >> iter 76000, loss: 0.424133
 >> iter 77000, loss: 0.362162
 >> iter 78000, loss: 0.460802
 >> iter 79000, loss: 0.571786
 >> iter 80000, loss: 0.517160
   Number of active neurons: 4
 >> iter 81000, loss: 0.589869
 >> iter 82000, loss: 0.504714
 >> iter 83000, loss: 0.498396
 >> iter 84000, loss: 0.581177
 >> iter 85000, loss: 0.645156
 >> iter 86000, loss: 0.478351
 >> iter 87000, loss: 0.490778
 >> iter 88000, loss: 0.576935
 >> iter 89000, loss: 0.402349
 >> iter 90000, loss: 0.642861
   Number of active neurons: 4
 >> iter 91000, loss: 0.355790
 >> iter 92000, loss: 0.487328
 >> iter 93000, loss: 0.476094
 >> iter 94000, loss: 0.573649
 >> iter 95000, loss: 0.437424
 >> iter 96000, loss: 0.460553
 >> iter 97000, loss: 0.423159
 >> iter 98000, loss: 0.413252
 >> iter 99000, loss: 0.628956
 >> iter 100000, loss: 0.459376
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.632159
 >> iter 2000, loss: 8.736200
 >> iter 3000, loss: 4.043675
 >> iter 4000, loss: 2.138591
 >> iter 5000, loss: 1.211091
 >> iter 6000, loss: 0.900745
 >> iter 7000, loss: 0.420284
 >> iter 8000, loss: 0.502987
 >> iter 9000, loss: 0.486836
 >> iter 10000, loss: 0.411724
   Number of active neurons: 4
 >> iter 11000, loss: 0.367273
 >> iter 12000, loss: 0.267139
 >> iter 13000, loss: 0.343413
 >> iter 14000, loss: 0.391836
 >> iter 15000, loss: 0.351630
 >> iter 16000, loss: 0.455988
 >> iter 17000, loss: 0.263083
 >> iter 18000, loss: 0.313987
 >> iter 19000, loss: 0.281086
 >> iter 20000, loss: 0.364031
   Number of active neurons: 4
 >> iter 21000, loss: 0.456645
 >> iter 22000, loss: 0.353461
 >> iter 23000, loss: 0.311210
 >> iter 24000, loss: 0.374128
 >> iter 25000, loss: 0.416773
 >> iter 26000, loss: 0.264076
 >> iter 27000, loss: 0.392834
 >> iter 28000, loss: 0.369089
 >> iter 29000, loss: 0.294009
 >> iter 30000, loss: 0.260900
   Number of active neurons: 4
 >> iter 31000, loss: 0.315322
 >> iter 32000, loss: 0.284880
 >> iter 33000, loss: 0.169874
 >> iter 34000, loss: 0.275065
 >> iter 35000, loss: 0.241590
 >> iter 36000, loss: 0.249569
 >> iter 37000, loss: 0.255279
 >> iter 38000, loss: 0.138014
 >> iter 39000, loss: 0.175968
 >> iter 40000, loss: 0.187318
   Number of active neurons: 4
 >> iter 41000, loss: 0.267490
 >> iter 42000, loss: 0.383401
 >> iter 43000, loss: 0.318743
 >> iter 44000, loss: 0.254747
 >> iter 45000, loss: 0.541973
 >> iter 46000, loss: 0.496772
 >> iter 47000, loss: 0.432407
 >> iter 48000, loss: 0.275417
 >> iter 49000, loss: 0.308915
 >> iter 50000, loss: 0.203604
   Number of active neurons: 4
 >> iter 51000, loss: 0.129956
 >> iter 52000, loss: 0.142933
 >> iter 53000, loss: 0.359878
 >> iter 54000, loss: 0.189117
 >> iter 55000, loss: 0.202756
 >> iter 56000, loss: 0.337705
 >> iter 57000, loss: 0.225585
 >> iter 58000, loss: 0.234124
 >> iter 59000, loss: 0.265942
 >> iter 60000, loss: 0.262543
   Number of active neurons: 3
 >> iter 61000, loss: 0.296951
 >> iter 62000, loss: 0.265769
 >> iter 63000, loss: 0.206279
 >> iter 64000, loss: 0.167219
 >> iter 65000, loss: 0.203606
 >> iter 66000, loss: 0.242566
 >> iter 67000, loss: 0.195510
 >> iter 68000, loss: 0.145630
 >> iter 69000, loss: 0.238696
 >> iter 70000, loss: 0.348328
   Number of active neurons: 3
 >> iter 71000, loss: 0.355619
 >> iter 72000, loss: 0.387558
 >> iter 73000, loss: 0.452548
 >> iter 74000, loss: 0.243502
 >> iter 75000, loss: 0.195536
 >> iter 76000, loss: 0.148115
 >> iter 77000, loss: 0.193786
 >> iter 78000, loss: 0.249108
 >> iter 79000, loss: 0.186855
 >> iter 80000, loss: 0.244145
   Number of active neurons: 3
 >> iter 81000, loss: 0.180533
 >> iter 82000, loss: 0.161414
 >> iter 83000, loss: 0.173658
 >> iter 84000, loss: 0.122413
 >> iter 85000, loss: 0.267309
 >> iter 86000, loss: 0.200714
 >> iter 87000, loss: 0.419290
 >> iter 88000, loss: 0.337280
 >> iter 89000, loss: 0.183748
 >> iter 90000, loss: 0.210469
   Number of active neurons: 3
 >> iter 91000, loss: 0.240415
 >> iter 92000, loss: 0.272375
 >> iter 93000, loss: 0.285682
 >> iter 94000, loss: 0.209904
 >> iter 95000, loss: 0.170943
 >> iter 96000, loss: 0.156835
 >> iter 97000, loss: 0.222775
 >> iter 98000, loss: 0.213672
 >> iter 99000, loss: 0.142645
 >> iter 100000, loss: 0.137911
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.394457
 >> iter 2000, loss: 8.704233
 >> iter 3000, loss: 3.978855
 >> iter 4000, loss: 1.797545
 >> iter 5000, loss: 0.946314
 >> iter 6000, loss: 0.463993
 >> iter 7000, loss: 0.593684
 >> iter 8000, loss: 0.427660
 >> iter 9000, loss: 0.274215
 >> iter 10000, loss: 0.360862
   Number of active neurons: 6
 >> iter 11000, loss: 0.352520
 >> iter 12000, loss: 0.485760
 >> iter 13000, loss: 0.498162
 >> iter 14000, loss: 0.530301
 >> iter 15000, loss: 0.394375
 >> iter 16000, loss: 0.338997
 >> iter 17000, loss: 0.342597
 >> iter 18000, loss: 0.434486
 >> iter 19000, loss: 0.390847
 >> iter 20000, loss: 0.256113
   Number of active neurons: 5
 >> iter 21000, loss: 0.270966
 >> iter 22000, loss: 0.345641
 >> iter 23000, loss: 0.349800
 >> iter 24000, loss: 0.305483
 >> iter 25000, loss: 0.256531
 >> iter 26000, loss: 0.272196
 >> iter 27000, loss: 0.300728
 >> iter 28000, loss: 0.212370
 >> iter 29000, loss: 0.226938
 >> iter 30000, loss: 0.293815
   Number of active neurons: 4
 >> iter 31000, loss: 0.345666
 >> iter 32000, loss: 0.420341
 >> iter 33000, loss: 0.443480
 >> iter 34000, loss: 0.398940
 >> iter 35000, loss: 0.407814
 >> iter 36000, loss: 0.379266
 >> iter 37000, loss: 0.353842
 >> iter 38000, loss: 0.239645
 >> iter 39000, loss: 0.228134
 >> iter 40000, loss: 0.193676
   Number of active neurons: 3
 >> iter 41000, loss: 0.342779
 >> iter 42000, loss: 0.236789
 >> iter 43000, loss: 0.168916
 >> iter 44000, loss: 0.220372
 >> iter 45000, loss: 0.142496
 >> iter 46000, loss: 0.240200
 >> iter 47000, loss: 0.258692
 >> iter 48000, loss: 0.193585
 >> iter 49000, loss: 0.206099
 >> iter 50000, loss: 0.338873
   Number of active neurons: 3
 >> iter 51000, loss: 0.267968
 >> iter 52000, loss: 0.340285
 >> iter 53000, loss: 0.217480
 >> iter 54000, loss: 0.231996
 >> iter 55000, loss: 0.187119
 >> iter 56000, loss: 0.339995
 >> iter 57000, loss: 0.266721
 >> iter 58000, loss: 0.223780
 >> iter 59000, loss: 0.168581
 >> iter 60000, loss: 0.485527
   Number of active neurons: 3
 >> iter 61000, loss: 0.286741
 >> iter 62000, loss: 0.232653
 >> iter 63000, loss: 0.227507
 >> iter 64000, loss: 0.217251
 >> iter 65000, loss: 0.445873
 >> iter 66000, loss: 0.370112
 >> iter 67000, loss: 0.230707
 >> iter 68000, loss: 0.288127
 >> iter 69000, loss: 0.276953
 >> iter 70000, loss: 0.198674
   Number of active neurons: 3
 >> iter 71000, loss: 0.367044
 >> iter 72000, loss: 0.356311
 >> iter 73000, loss: 0.246786
 >> iter 74000, loss: 0.146960
 >> iter 75000, loss: 0.355570
 >> iter 76000, loss: 0.385970
 >> iter 77000, loss: 0.343118
 >> iter 78000, loss: 0.373487
 >> iter 79000, loss: 0.308518
 >> iter 80000, loss: 0.334656
   Number of active neurons: 3
 >> iter 81000, loss: 0.417848
 >> iter 82000, loss: 0.262534
 >> iter 83000, loss: 0.564770
 >> iter 84000, loss: 0.322125
 >> iter 85000, loss: 0.252728
 >> iter 86000, loss: 0.173924
 >> iter 87000, loss: 0.168642
 >> iter 88000, loss: 0.289899
 >> iter 89000, loss: 0.237696
 >> iter 90000, loss: 0.207844
   Number of active neurons: 3
 >> iter 91000, loss: 0.302132
 >> iter 92000, loss: 0.318783
 >> iter 93000, loss: 0.278301
 >> iter 94000, loss: 0.166386
 >> iter 95000, loss: 0.310317
 >> iter 96000, loss: 0.283699
 >> iter 97000, loss: 0.210067
 >> iter 98000, loss: 0.385104
 >> iter 99000, loss: 0.256131
 >> iter 100000, loss: 0.255413
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.775746
 >> iter 2000, loss: 9.600535
 >> iter 3000, loss: 4.742012
 >> iter 4000, loss: 2.393737
 >> iter 5000, loss: 1.111740
 >> iter 6000, loss: 0.682139
 >> iter 7000, loss: 0.553440
 >> iter 8000, loss: 0.310634
 >> iter 9000, loss: 0.450475
 >> iter 10000, loss: 0.529162
   Number of active neurons: 6
 >> iter 11000, loss: 0.584791
 >> iter 12000, loss: 0.481390
 >> iter 13000, loss: 0.500709
 >> iter 14000, loss: 0.443049
 >> iter 15000, loss: 0.308200
 >> iter 16000, loss: 0.308815
 >> iter 17000, loss: 0.340538
 >> iter 18000, loss: 0.394044
 >> iter 19000, loss: 0.380123
 >> iter 20000, loss: 0.281131
   Number of active neurons: 6
 >> iter 21000, loss: 0.296664
 >> iter 22000, loss: 0.321307
 >> iter 23000, loss: 0.385226
 >> iter 24000, loss: 0.454592
 >> iter 25000, loss: 0.444495
 >> iter 26000, loss: 0.530091
 >> iter 27000, loss: 0.284578
 >> iter 28000, loss: 0.230647
 >> iter 29000, loss: 0.275132
 >> iter 30000, loss: 0.231596
   Number of active neurons: 5
 >> iter 31000, loss: 0.309892
 >> iter 32000, loss: 0.390945
 >> iter 33000, loss: 0.354096
 >> iter 34000, loss: 0.315572
 >> iter 35000, loss: 0.289528
 >> iter 36000, loss: 0.382833
 >> iter 37000, loss: 0.422319
 >> iter 38000, loss: 0.309677
 >> iter 39000, loss: 0.415073
 >> iter 40000, loss: 0.398202
   Number of active neurons: 5
 >> iter 41000, loss: 0.561563
 >> iter 42000, loss: 0.362652
 >> iter 43000, loss: 0.441560
 >> iter 44000, loss: 0.291339
 >> iter 45000, loss: 0.251238
 >> iter 46000, loss: 0.302247
 >> iter 47000, loss: 0.305568
 >> iter 48000, loss: 0.364836
 >> iter 49000, loss: 0.304311
 >> iter 50000, loss: 0.288076
   Number of active neurons: 4
 >> iter 51000, loss: 0.389947
 >> iter 52000, loss: 0.369905
 >> iter 53000, loss: 0.431599
 >> iter 54000, loss: 0.459722
 >> iter 55000, loss: 0.510685
 >> iter 56000, loss: 0.402190
 >> iter 57000, loss: 0.247190
 >> iter 58000, loss: 0.216610
 >> iter 59000, loss: 0.385040
 >> iter 60000, loss: 0.206480
   Number of active neurons: 4
 >> iter 61000, loss: 0.259017
 >> iter 62000, loss: 0.320598
 >> iter 63000, loss: 0.448962
 >> iter 64000, loss: 0.289549
 >> iter 65000, loss: 0.197334
 >> iter 66000, loss: 0.255656
 >> iter 67000, loss: 0.332507
 >> iter 68000, loss: 0.234824
 >> iter 69000, loss: 0.235551
 >> iter 70000, loss: 0.194841
   Number of active neurons: 4
 >> iter 71000, loss: 0.484876
 >> iter 72000, loss: 0.207552
 >> iter 73000, loss: 0.193262
 >> iter 74000, loss: 0.325481
 >> iter 75000, loss: 0.326244
 >> iter 76000, loss: 0.304119
 >> iter 77000, loss: 0.316569
 >> iter 78000, loss: 0.272842
 >> iter 79000, loss: 0.236574
 >> iter 80000, loss: 0.241904
   Number of active neurons: 4
 >> iter 81000, loss: 0.217527
 >> iter 82000, loss: 0.262145
 >> iter 83000, loss: 0.228535
 >> iter 84000, loss: 0.165925
 >> iter 85000, loss: 0.370953
 >> iter 86000, loss: 0.458105
 >> iter 87000, loss: 0.294283
 >> iter 88000, loss: 0.329378
 >> iter 89000, loss: 0.248028
 >> iter 90000, loss: 0.185401
   Number of active neurons: 4
 >> iter 91000, loss: 0.235632
 >> iter 92000, loss: 0.239226
 >> iter 93000, loss: 0.452775
 >> iter 94000, loss: 0.292274
 >> iter 95000, loss: 0.214010
 >> iter 96000, loss: 0.561411
 >> iter 97000, loss: 0.591900
 >> iter 98000, loss: 0.397943
 >> iter 99000, loss: 0.182001
 >> iter 100000, loss: 0.200352
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.600562
 >> iter 2000, loss: 8.581298
 >> iter 3000, loss: 3.935562
 >> iter 4000, loss: 1.920373
 >> iter 5000, loss: 1.042082
 >> iter 6000, loss: 0.558533
 >> iter 7000, loss: 0.603746
 >> iter 8000, loss: 0.708221
 >> iter 9000, loss: 0.648538
 >> iter 10000, loss: 0.509546
   Number of active neurons: 7
 >> iter 11000, loss: 0.318206
 >> iter 12000, loss: 0.348310
 >> iter 13000, loss: 0.285935
 >> iter 14000, loss: 0.601837
 >> iter 15000, loss: 0.358138
 >> iter 16000, loss: 0.532003
 >> iter 17000, loss: 0.469567
 >> iter 18000, loss: 0.360087
 >> iter 19000, loss: 0.269079
 >> iter 20000, loss: 0.382114
   Number of active neurons: 6
 >> iter 21000, loss: 0.522615
 >> iter 22000, loss: 0.357027
 >> iter 23000, loss: 0.283625
 >> iter 24000, loss: 0.336099
 >> iter 25000, loss: 0.490714
 >> iter 26000, loss: 0.414872
 >> iter 27000, loss: 0.330314
 >> iter 28000, loss: 0.538111
 >> iter 29000, loss: 0.511376
 >> iter 30000, loss: 0.316350
   Number of active neurons: 6
 >> iter 31000, loss: 0.329033
 >> iter 32000, loss: 0.279852
 >> iter 33000, loss: 0.363368
 >> iter 34000, loss: 0.210984
 >> iter 35000, loss: 0.448880
 >> iter 36000, loss: 0.359684
 >> iter 37000, loss: 0.433718
 >> iter 38000, loss: 0.289935
 >> iter 39000, loss: 0.212512
 >> iter 40000, loss: 0.278585
   Number of active neurons: 6
 >> iter 41000, loss: 0.316650
 >> iter 42000, loss: 0.401558
 >> iter 43000, loss: 0.216169
 >> iter 44000, loss: 0.256889
 >> iter 45000, loss: 0.262438
 >> iter 46000, loss: 0.233686
 >> iter 47000, loss: 0.253827
 >> iter 48000, loss: 0.408792
 >> iter 49000, loss: 0.362393
 >> iter 50000, loss: 0.394765
   Number of active neurons: 5
 >> iter 51000, loss: 0.514879
 >> iter 52000, loss: 0.461721
 >> iter 53000, loss: 0.584871
 >> iter 54000, loss: 0.277746
 >> iter 55000, loss: 0.323858
 >> iter 56000, loss: 0.267345
 >> iter 57000, loss: 0.321129
 >> iter 58000, loss: 0.189165
 >> iter 59000, loss: 0.255667
 >> iter 60000, loss: 0.495658
   Number of active neurons: 5
 >> iter 61000, loss: 0.394777
 >> iter 62000, loss: 0.382103
 >> iter 63000, loss: 0.364279
 >> iter 64000, loss: 0.336937
 >> iter 65000, loss: 0.290123
 >> iter 66000, loss: 0.380675
 >> iter 67000, loss: 0.324181
 >> iter 68000, loss: 0.236278
 >> iter 69000, loss: 0.197609
 >> iter 70000, loss: 0.250524
   Number of active neurons: 5
 >> iter 71000, loss: 0.295617
 >> iter 72000, loss: 0.300985
 >> iter 73000, loss: 0.291663
 >> iter 74000, loss: 0.279691
 >> iter 75000, loss: 0.210200
 >> iter 76000, loss: 0.393025
 >> iter 77000, loss: 0.226502
 >> iter 78000, loss: 0.431860
 >> iter 79000, loss: 0.459263
 >> iter 80000, loss: 0.613717
   Number of active neurons: 8
 >> iter 81000, loss: 0.326748
 >> iter 82000, loss: 0.287006
 >> iter 83000, loss: 0.466669
 >> iter 84000, loss: 0.359202
 >> iter 85000, loss: 0.356681
 >> iter 86000, loss: 0.246292
 >> iter 87000, loss: 0.268848
 >> iter 88000, loss: 0.278973
 >> iter 89000, loss: 0.241359
 >> iter 90000, loss: 0.243146
   Number of active neurons: 5
 >> iter 91000, loss: 0.354493
 >> iter 92000, loss: 0.302629
 >> iter 93000, loss: 0.165045
 >> iter 94000, loss: 0.177401
 >> iter 95000, loss: 0.276687
 >> iter 96000, loss: 0.189741
 >> iter 97000, loss: 0.270104
 >> iter 98000, loss: 0.218614
 >> iter 99000, loss: 0.139350
 >> iter 100000, loss: 0.267034
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.908289
 >> iter 2000, loss: 10.099864
 >> iter 3000, loss: 4.759271
 >> iter 4000, loss: 2.347932
 >> iter 5000, loss: 1.242062
 >> iter 6000, loss: 0.797650
 >> iter 7000, loss: 0.734818
 >> iter 8000, loss: 0.502656
 >> iter 9000, loss: 0.481196
 >> iter 10000, loss: 0.349993
   Number of active neurons: 5
 >> iter 11000, loss: 0.474526
 >> iter 12000, loss: 0.465072
 >> iter 13000, loss: 0.331515
 >> iter 14000, loss: 0.318387
 >> iter 15000, loss: 0.514419
 >> iter 16000, loss: 0.423312
 >> iter 17000, loss: 0.330414
 >> iter 18000, loss: 0.242476
 >> iter 19000, loss: 0.244235
 >> iter 20000, loss: 0.278605
   Number of active neurons: 5
 >> iter 21000, loss: 0.431116
 >> iter 22000, loss: 0.596087
 >> iter 23000, loss: 0.355375
 >> iter 24000, loss: 0.377457
 >> iter 25000, loss: 0.347763
 >> iter 26000, loss: 0.496227
 >> iter 27000, loss: 0.324826
 >> iter 28000, loss: 0.361152
 >> iter 29000, loss: 0.363142
 >> iter 30000, loss: 0.355239
   Number of active neurons: 5
 >> iter 31000, loss: 0.236849
 >> iter 32000, loss: 0.381984
 >> iter 33000, loss: 0.485171
 >> iter 34000, loss: 0.352629
 >> iter 35000, loss: 0.540565
 >> iter 36000, loss: 0.532065
 >> iter 37000, loss: 0.423637
 >> iter 38000, loss: 0.333360
 >> iter 39000, loss: 0.271067
 >> iter 40000, loss: 0.201492
   Number of active neurons: 5
 >> iter 41000, loss: 0.310458
 >> iter 42000, loss: 0.200691
 >> iter 43000, loss: 0.206424
 >> iter 44000, loss: 0.187247
 >> iter 45000, loss: 0.284478
 >> iter 46000, loss: 0.240064
 >> iter 47000, loss: 0.234122
 >> iter 48000, loss: 0.325091
 >> iter 49000, loss: 0.306166
 >> iter 50000, loss: 0.297836
   Number of active neurons: 4
 >> iter 51000, loss: 0.349933
 >> iter 52000, loss: 0.456746
 >> iter 53000, loss: 0.221213
 >> iter 54000, loss: 0.207080
 >> iter 55000, loss: 0.235042
 >> iter 56000, loss: 0.317193
 >> iter 57000, loss: 0.292230
 >> iter 58000, loss: 0.278914
 >> iter 59000, loss: 0.427032
 >> iter 60000, loss: 0.403281
   Number of active neurons: 4
 >> iter 61000, loss: 0.203139
 >> iter 62000, loss: 0.267255
 >> iter 63000, loss: 0.165143
 >> iter 64000, loss: 0.189800
 >> iter 65000, loss: 0.212328
 >> iter 66000, loss: 0.388199
 >> iter 67000, loss: 0.226906
 >> iter 68000, loss: 0.415116
 >> iter 69000, loss: 0.414277
 >> iter 70000, loss: 0.261183
   Number of active neurons: 4
 >> iter 71000, loss: 0.198284
 >> iter 72000, loss: 0.299641
 >> iter 73000, loss: 0.242462
 >> iter 74000, loss: 0.276032
 >> iter 75000, loss: 0.317430
 >> iter 76000, loss: 0.340082
 >> iter 77000, loss: 0.184575
 >> iter 78000, loss: 0.356076
 >> iter 79000, loss: 0.261155
 >> iter 80000, loss: 0.222492
   Number of active neurons: 4
 >> iter 81000, loss: 0.238048
 >> iter 82000, loss: 0.369906
 >> iter 83000, loss: 0.288809
 >> iter 84000, loss: 0.225491
 >> iter 85000, loss: 0.302165
 >> iter 86000, loss: 0.363978
 >> iter 87000, loss: 0.446476
 >> iter 88000, loss: 0.366359
 >> iter 89000, loss: 0.331699
 >> iter 90000, loss: 0.217065
   Number of active neurons: 4
 >> iter 91000, loss: 0.424282
 >> iter 92000, loss: 0.379194
 >> iter 93000, loss: 0.318077
 >> iter 94000, loss: 0.421463
 >> iter 95000, loss: 0.262024
 >> iter 96000, loss: 0.178817
 >> iter 97000, loss: 0.214008
 >> iter 98000, loss: 0.522323
 >> iter 99000, loss: 0.446957
 >> iter 100000, loss: 0.263605
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.201081
 >> iter 2000, loss: 8.889711
 >> iter 3000, loss: 4.292515
 >> iter 4000, loss: 2.141626
 >> iter 5000, loss: 1.513720
 >> iter 6000, loss: 0.774102
 >> iter 7000, loss: 0.443135
 >> iter 8000, loss: 0.355857
 >> iter 9000, loss: 0.546469
 >> iter 10000, loss: 0.379164
   Number of active neurons: 6
 >> iter 11000, loss: 0.290263
 >> iter 12000, loss: 0.291897
 >> iter 13000, loss: 0.325317
 >> iter 14000, loss: 0.403327
 >> iter 15000, loss: 0.367924
 >> iter 16000, loss: 0.408374
 >> iter 17000, loss: 0.715739
 >> iter 18000, loss: 0.670705
 >> iter 19000, loss: 0.422375
 >> iter 20000, loss: 0.344707
   Number of active neurons: 5
 >> iter 21000, loss: 0.522403
 >> iter 22000, loss: 0.471732
 >> iter 23000, loss: 0.399045
 >> iter 24000, loss: 0.442331
 >> iter 25000, loss: 0.390165
 >> iter 26000, loss: 0.360926
 >> iter 27000, loss: 0.554734
 >> iter 28000, loss: 0.514944
 >> iter 29000, loss: 0.391604
 >> iter 30000, loss: 0.272984
   Number of active neurons: 5
 >> iter 31000, loss: 0.318933
 >> iter 32000, loss: 0.349721
 >> iter 33000, loss: 0.208711
 >> iter 34000, loss: 0.198212
 >> iter 35000, loss: 0.206947
 >> iter 36000, loss: 0.595302
 >> iter 37000, loss: 0.378472
 >> iter 38000, loss: 0.328620
 >> iter 39000, loss: 0.277698
 >> iter 40000, loss: 0.442764
   Number of active neurons: 5
 >> iter 41000, loss: 0.379329
 >> iter 42000, loss: 0.417880
 >> iter 43000, loss: 0.412424
 >> iter 44000, loss: 0.284130
 >> iter 45000, loss: 0.367986
 >> iter 46000, loss: 0.549229
 >> iter 47000, loss: 0.288772
 >> iter 48000, loss: 0.386500
 >> iter 49000, loss: 0.326422
 >> iter 50000, loss: 0.293923
   Number of active neurons: 5
 >> iter 51000, loss: 0.367974
 >> iter 52000, loss: 0.417831
 >> iter 53000, loss: 0.295925
 >> iter 54000, loss: 0.401414
 >> iter 55000, loss: 0.315896
 >> iter 56000, loss: 0.182850
 >> iter 57000, loss: 0.580011
 >> iter 58000, loss: 0.435024
 >> iter 59000, loss: 0.508491
 >> iter 60000, loss: 0.332771
   Number of active neurons: 5
 >> iter 61000, loss: 0.352136
 >> iter 62000, loss: 0.398010
 >> iter 63000, loss: 0.366906
 >> iter 64000, loss: 0.571631
 >> iter 65000, loss: 0.577430
 >> iter 66000, loss: 0.360035
 >> iter 67000, loss: 0.222359
 >> iter 68000, loss: 0.147964
 >> iter 69000, loss: 0.224164
 >> iter 70000, loss: 0.215088
   Number of active neurons: 4
 >> iter 71000, loss: 0.333001
 >> iter 72000, loss: 0.252328
 >> iter 73000, loss: 0.310836
 >> iter 74000, loss: 0.363058
 >> iter 75000, loss: 0.325083
 >> iter 76000, loss: 0.379337
 >> iter 77000, loss: 0.464135
 >> iter 78000, loss: 0.338540
 >> iter 79000, loss: 0.204611
 >> iter 80000, loss: 0.353847
   Number of active neurons: 4
 >> iter 81000, loss: 0.229414
 >> iter 82000, loss: 0.549647
 >> iter 83000, loss: 0.475023
 >> iter 84000, loss: 0.255920
 >> iter 85000, loss: 0.269793
 >> iter 86000, loss: 0.207348
 >> iter 87000, loss: 0.254879
 >> iter 88000, loss: 0.453206
 >> iter 89000, loss: 0.360521
 >> iter 90000, loss: 0.398544
   Number of active neurons: 4
 >> iter 91000, loss: 0.310833
 >> iter 92000, loss: 0.193382
 >> iter 93000, loss: 0.292124
 >> iter 94000, loss: 0.318473
 >> iter 95000, loss: 0.321459
 >> iter 96000, loss: 0.278174
 >> iter 97000, loss: 0.244085
 >> iter 98000, loss: 0.245873
 >> iter 99000, loss: 0.343966
 >> iter 100000, loss: 0.438844
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.724527
 >> iter 2000, loss: 8.834219
 >> iter 3000, loss: 4.177978
 >> iter 4000, loss: 2.198521
 >> iter 5000, loss: 1.075254
 >> iter 6000, loss: 0.637775
 >> iter 7000, loss: 0.455043
 >> iter 8000, loss: 0.412615
 >> iter 9000, loss: 0.525731
 >> iter 10000, loss: 0.292418
   Number of active neurons: 4
 >> iter 11000, loss: 0.351634
 >> iter 12000, loss: 0.329814
 >> iter 13000, loss: 0.260106
 >> iter 14000, loss: 0.361481
 >> iter 15000, loss: 0.438526
 >> iter 16000, loss: 0.393207
 >> iter 17000, loss: 0.392656
 >> iter 18000, loss: 0.289599
 >> iter 19000, loss: 0.246413
 >> iter 20000, loss: 0.449851
   Number of active neurons: 4
 >> iter 21000, loss: 0.328177
 >> iter 22000, loss: 0.347691
 >> iter 23000, loss: 0.486928
 >> iter 24000, loss: 0.405184
 >> iter 25000, loss: 0.340830
 >> iter 26000, loss: 0.328618
 >> iter 27000, loss: 0.299804
 >> iter 28000, loss: 0.235616
 >> iter 29000, loss: 0.350593
 >> iter 30000, loss: 0.285382
   Number of active neurons: 4
 >> iter 31000, loss: 0.267062
 >> iter 32000, loss: 0.291980
 >> iter 33000, loss: 0.422453
 >> iter 34000, loss: 0.250538
 >> iter 35000, loss: 0.281948
 >> iter 36000, loss: 0.331658
 >> iter 37000, loss: 0.291735
 >> iter 38000, loss: 0.196231
 >> iter 39000, loss: 0.276825
 >> iter 40000, loss: 0.335234
   Number of active neurons: 4
 >> iter 41000, loss: 0.209091
 >> iter 42000, loss: 0.239751
 >> iter 43000, loss: 0.183243
 >> iter 44000, loss: 0.494572
 >> iter 45000, loss: 0.226846
 >> iter 46000, loss: 0.333099
 >> iter 47000, loss: 0.609655
 >> iter 48000, loss: 0.577844
 >> iter 49000, loss: 0.367537
 >> iter 50000, loss: 0.230964
   Number of active neurons: 3
 >> iter 51000, loss: 0.187258
 >> iter 52000, loss: 0.228256
 >> iter 53000, loss: 0.293634
 >> iter 54000, loss: 0.150236
 >> iter 55000, loss: 0.251201
 >> iter 56000, loss: 0.153716
 >> iter 57000, loss: 0.180605
 >> iter 58000, loss: 0.219976
 >> iter 59000, loss: 0.224945
 >> iter 60000, loss: 0.183078
   Number of active neurons: 3
 >> iter 61000, loss: 0.271996
 >> iter 62000, loss: 0.260392
 >> iter 63000, loss: 0.233939
 >> iter 64000, loss: 0.297627
 >> iter 65000, loss: 0.513013
 >> iter 66000, loss: 0.323669
 >> iter 67000, loss: 0.380684
 >> iter 68000, loss: 0.291754
 >> iter 69000, loss: 0.185040
 >> iter 70000, loss: 0.204631
   Number of active neurons: 3
 >> iter 71000, loss: 0.189303
 >> iter 72000, loss: 0.208776
 >> iter 73000, loss: 0.276737
 >> iter 74000, loss: 0.391951
 >> iter 75000, loss: 0.397076
 >> iter 76000, loss: 0.251157
 >> iter 77000, loss: 0.279721
 >> iter 78000, loss: 0.181348
 >> iter 79000, loss: 0.210205
 >> iter 80000, loss: 0.141692
   Number of active neurons: 3
 >> iter 81000, loss: 0.230227
 >> iter 82000, loss: 0.164315
 >> iter 83000, loss: 0.102552
 >> iter 84000, loss: 0.291000
 >> iter 85000, loss: 0.143127
 >> iter 86000, loss: 0.161253
 >> iter 87000, loss: 0.209631
 >> iter 88000, loss: 0.351770
 >> iter 89000, loss: 0.282585
 >> iter 90000, loss: 0.316013
   Number of active neurons: 3
 >> iter 91000, loss: 0.238301
 >> iter 92000, loss: 0.152290
 >> iter 93000, loss: 0.160292
 >> iter 94000, loss: 0.219708
 >> iter 95000, loss: 0.194843
 >> iter 96000, loss: 0.302564
 >> iter 97000, loss: 0.159167
 >> iter 98000, loss: 0.245106
 >> iter 99000, loss: 0.162921
 >> iter 100000, loss: 0.176383
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.670078
 >> iter 2000, loss: 9.110576
 >> iter 3000, loss: 4.261564
 >> iter 4000, loss: 1.891877
 >> iter 5000, loss: 0.959874
 >> iter 6000, loss: 0.492723
 >> iter 7000, loss: 0.724456
 >> iter 8000, loss: 0.523582
 >> iter 9000, loss: 0.253497
 >> iter 10000, loss: 0.312072
   Number of active neurons: 6
 >> iter 11000, loss: 0.292634
 >> iter 12000, loss: 0.268219
 >> iter 13000, loss: 0.224323
 >> iter 14000, loss: 0.237839
 >> iter 15000, loss: 0.531517
 >> iter 16000, loss: 0.433775
 >> iter 17000, loss: 0.222945
 >> iter 18000, loss: 0.325022
 >> iter 19000, loss: 0.260084
 >> iter 20000, loss: 0.344710
   Number of active neurons: 4
 >> iter 21000, loss: 0.301000
 >> iter 22000, loss: 0.298058
 >> iter 23000, loss: 0.269963
 >> iter 24000, loss: 0.448576
 >> iter 25000, loss: 0.320871
 >> iter 26000, loss: 0.201339
 >> iter 27000, loss: 0.239372
 >> iter 28000, loss: 0.191498
 >> iter 29000, loss: 0.157979
 >> iter 30000, loss: 0.118903
   Number of active neurons: 3
 >> iter 31000, loss: 0.267666
 >> iter 32000, loss: 0.329437
 >> iter 33000, loss: 0.366666
 >> iter 34000, loss: 0.240372
 >> iter 35000, loss: 0.220781
 >> iter 36000, loss: 0.190269
 >> iter 37000, loss: 0.360529
 >> iter 38000, loss: 0.225324
 >> iter 39000, loss: 0.216575
 >> iter 40000, loss: 0.112235
   Number of active neurons: 3
 >> iter 41000, loss: 0.236798
 >> iter 42000, loss: 0.155541
 >> iter 43000, loss: 0.184995
 >> iter 44000, loss: 0.337558
 >> iter 45000, loss: 0.314845
 >> iter 46000, loss: 0.292645
 >> iter 47000, loss: 0.283066
 >> iter 48000, loss: 0.256763
 >> iter 49000, loss: 0.229184
 >> iter 50000, loss: 0.250883
   Number of active neurons: 3
 >> iter 51000, loss: 0.369880
 >> iter 52000, loss: 0.185651
 >> iter 53000, loss: 0.504651
 >> iter 54000, loss: 0.286620
 >> iter 55000, loss: 0.155647
 >> iter 56000, loss: 0.221477
 >> iter 57000, loss: 0.154396
 >> iter 58000, loss: 0.263856
 >> iter 59000, loss: 0.183214
 >> iter 60000, loss: 0.206494
   Number of active neurons: 3
 >> iter 61000, loss: 0.160410
 >> iter 62000, loss: 0.116285
 >> iter 63000, loss: 0.151139
 >> iter 64000, loss: 0.207777
 >> iter 65000, loss: 0.300631
 >> iter 66000, loss: 0.236527
 >> iter 67000, loss: 0.281312
 >> iter 68000, loss: 0.172288
 >> iter 69000, loss: 0.186229
 >> iter 70000, loss: 0.173363
   Number of active neurons: 3
 >> iter 71000, loss: 0.310132
 >> iter 72000, loss: 0.388119
 >> iter 73000, loss: 0.173549
 >> iter 74000, loss: 0.325626
 >> iter 75000, loss: 0.256963
 >> iter 76000, loss: 0.299925
 >> iter 77000, loss: 0.283509
 >> iter 78000, loss: 0.331859
 >> iter 79000, loss: 0.194603
 >> iter 80000, loss: 0.213884
   Number of active neurons: 3
 >> iter 81000, loss: 0.128617
 >> iter 82000, loss: 0.177753
 >> iter 83000, loss: 0.242618
 >> iter 84000, loss: 0.181859
 >> iter 85000, loss: 0.243184
 >> iter 86000, loss: 0.115338
 >> iter 87000, loss: 0.078248
 >> iter 88000, loss: 0.232880
 >> iter 89000, loss: 0.256606
 >> iter 90000, loss: 0.464210
   Number of active neurons: 3
 >> iter 91000, loss: 0.442527
 >> iter 92000, loss: 0.383651
 >> iter 93000, loss: 0.205454
 >> iter 94000, loss: 0.460446
 >> iter 95000, loss: 0.259613
 >> iter 96000, loss: 0.324960
 >> iter 97000, loss: 0.169202
 >> iter 98000, loss: 0.134537
 >> iter 99000, loss: 0.092047
 >> iter 100000, loss: 0.202215
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.559254
 >> iter 2000, loss: 9.310290
 >> iter 3000, loss: 4.346220
 >> iter 4000, loss: 2.301717
 >> iter 5000, loss: 1.221010
 >> iter 6000, loss: 0.745434
 >> iter 7000, loss: 0.460032
 >> iter 8000, loss: 0.593925
 >> iter 9000, loss: 0.600882
 >> iter 10000, loss: 0.549628
   Number of active neurons: 5
 >> iter 11000, loss: 0.459456
 >> iter 12000, loss: 0.379576
 >> iter 13000, loss: 0.340644
 >> iter 14000, loss: 0.207171
 >> iter 15000, loss: 0.345450
 >> iter 16000, loss: 0.388843
 >> iter 17000, loss: 0.325732
 >> iter 18000, loss: 0.467659
 >> iter 19000, loss: 0.211620
 >> iter 20000, loss: 0.425940
   Number of active neurons: 4
 >> iter 21000, loss: 0.382079
 >> iter 22000, loss: 0.489373
 >> iter 23000, loss: 0.361199
 >> iter 24000, loss: 0.530374
 >> iter 25000, loss: 0.405836
 >> iter 26000, loss: 0.268040
 >> iter 27000, loss: 0.277908
 >> iter 28000, loss: 0.274107
 >> iter 29000, loss: 0.307811
 >> iter 30000, loss: 0.272188
   Number of active neurons: 3
 >> iter 31000, loss: 0.280473
 >> iter 32000, loss: 0.372322
 >> iter 33000, loss: 0.371893
 >> iter 34000, loss: 0.243994
 >> iter 35000, loss: 0.167545
 >> iter 36000, loss: 0.230150
 >> iter 37000, loss: 0.169853
 >> iter 38000, loss: 0.257560
 >> iter 39000, loss: 0.353387
 >> iter 40000, loss: 0.425159
   Number of active neurons: 3
 >> iter 41000, loss: 0.311314
 >> iter 42000, loss: 0.303191
 >> iter 43000, loss: 0.354668
 >> iter 44000, loss: 0.252942
 >> iter 45000, loss: 0.192955
 >> iter 46000, loss: 0.280693
 >> iter 47000, loss: 0.385206
 >> iter 48000, loss: 0.323311
 >> iter 49000, loss: 0.266887
 >> iter 50000, loss: 0.395446
   Number of active neurons: 3
 >> iter 51000, loss: 0.302624
 >> iter 52000, loss: 0.503424
 >> iter 53000, loss: 0.429805
 >> iter 54000, loss: 0.480352
 >> iter 55000, loss: 0.338350
 >> iter 56000, loss: 0.197929
 >> iter 57000, loss: 0.410620
 >> iter 58000, loss: 0.231212
 >> iter 59000, loss: 0.359345
 >> iter 60000, loss: 0.372591
   Number of active neurons: 3
 >> iter 61000, loss: 0.253568
 >> iter 62000, loss: 0.295717
 >> iter 63000, loss: 0.252466
 >> iter 64000, loss: 0.196543
 >> iter 65000, loss: 0.215143
 >> iter 66000, loss: 0.294616
 >> iter 67000, loss: 0.228215
 >> iter 68000, loss: 0.345338
 >> iter 69000, loss: 0.271868
 >> iter 70000, loss: 0.323878
   Number of active neurons: 3
 >> iter 71000, loss: 0.368109
 >> iter 72000, loss: 0.241500
 >> iter 73000, loss: 0.337100
 >> iter 74000, loss: 0.463043
 >> iter 75000, loss: 0.334435
 >> iter 76000, loss: 0.560761
 >> iter 77000, loss: 0.383297
 >> iter 78000, loss: 0.369296
 >> iter 79000, loss: 0.387426
 >> iter 80000, loss: 0.285584
   Number of active neurons: 3
 >> iter 81000, loss: 0.192180
 >> iter 82000, loss: 0.256550
 >> iter 83000, loss: 0.435237
 >> iter 84000, loss: 0.514193
 >> iter 85000, loss: 0.298680
 >> iter 86000, loss: 0.151629
 >> iter 87000, loss: 0.177238
 >> iter 88000, loss: 0.278427
 >> iter 89000, loss: 0.388426
 >> iter 90000, loss: 0.326471
   Number of active neurons: 3
 >> iter 91000, loss: 0.231013
 >> iter 92000, loss: 0.160477
 >> iter 93000, loss: 0.210124
 >> iter 94000, loss: 0.199884
 >> iter 95000, loss: 0.166655
 >> iter 96000, loss: 0.378821
 >> iter 97000, loss: 0.317523
 >> iter 98000, loss: 0.309949
 >> iter 99000, loss: 0.208866
 >> iter 100000, loss: 0.120205
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.333253
 >> iter 2000, loss: 8.480050
 >> iter 3000, loss: 3.872378
 >> iter 4000, loss: 1.850152
 >> iter 5000, loss: 0.872825
 >> iter 6000, loss: 0.842170
 >> iter 7000, loss: 0.478267
 >> iter 8000, loss: 0.466599
 >> iter 9000, loss: 0.278380
 >> iter 10000, loss: 0.344055
   Number of active neurons: 5
 >> iter 11000, loss: 0.382790
 >> iter 12000, loss: 0.302793
 >> iter 13000, loss: 0.366816
 >> iter 14000, loss: 0.330993
 >> iter 15000, loss: 0.193817
 >> iter 16000, loss: 0.380121
 >> iter 17000, loss: 0.433165
 >> iter 18000, loss: 0.546870
 >> iter 19000, loss: 0.322847
 >> iter 20000, loss: 0.202865
   Number of active neurons: 5
 >> iter 21000, loss: 0.229820
 >> iter 22000, loss: 0.320888
 >> iter 23000, loss: 0.230358
 >> iter 24000, loss: 0.284650
 >> iter 25000, loss: 0.558705
 >> iter 26000, loss: 0.374448
 >> iter 27000, loss: 0.366237
 >> iter 28000, loss: 0.338939
 >> iter 29000, loss: 0.254133
 >> iter 30000, loss: 0.294750
   Number of active neurons: 4
 >> iter 31000, loss: 0.374567
 >> iter 32000, loss: 0.187784
 >> iter 33000, loss: 0.453411
 >> iter 34000, loss: 0.250736
 >> iter 35000, loss: 0.190307
 >> iter 36000, loss: 0.175878
 >> iter 37000, loss: 0.249550
 >> iter 38000, loss: 0.251355
 >> iter 39000, loss: 0.326189
 >> iter 40000, loss: 0.361264
   Number of active neurons: 4
 >> iter 41000, loss: 0.235599
 >> iter 42000, loss: 0.241436
 >> iter 43000, loss: 0.269187
 >> iter 44000, loss: 0.273080
 >> iter 45000, loss: 0.224341
 >> iter 46000, loss: 0.504496
 >> iter 47000, loss: 0.505431
 >> iter 48000, loss: 0.267844
 >> iter 49000, loss: 0.174411
 >> iter 50000, loss: 0.189582
   Number of active neurons: 4
 >> iter 51000, loss: 0.213012
 >> iter 52000, loss: 0.149482
 >> iter 53000, loss: 0.176031
 >> iter 54000, loss: 0.187637
 >> iter 55000, loss: 0.140985
 >> iter 56000, loss: 0.378130
 >> iter 57000, loss: 0.294794
 >> iter 58000, loss: 0.305507
 >> iter 59000, loss: 0.322868
 >> iter 60000, loss: 0.440857
   Number of active neurons: 4
 >> iter 61000, loss: 0.306910
 >> iter 62000, loss: 0.251197
 >> iter 63000, loss: 0.218943
 >> iter 64000, loss: 0.230718
 >> iter 65000, loss: 0.223671
 >> iter 66000, loss: 0.293558
 >> iter 67000, loss: 0.425164
 >> iter 68000, loss: 0.201658
 >> iter 69000, loss: 0.144015
 >> iter 70000, loss: 0.270023
   Number of active neurons: 4
 >> iter 71000, loss: 0.242446
 >> iter 72000, loss: 0.204775
 >> iter 73000, loss: 0.140247
 >> iter 74000, loss: 0.498215
 >> iter 75000, loss: 0.353632
 >> iter 76000, loss: 0.202944
 >> iter 77000, loss: 0.104805
 >> iter 78000, loss: 0.299861
 >> iter 79000, loss: 0.358880
 >> iter 80000, loss: 0.238400
   Number of active neurons: 3
 >> iter 81000, loss: 0.192195
 >> iter 82000, loss: 0.407607
 >> iter 83000, loss: 0.310780
 >> iter 84000, loss: 0.262317
 >> iter 85000, loss: 0.312394
 >> iter 86000, loss: 0.244836
 >> iter 87000, loss: 0.215446
 >> iter 88000, loss: 0.145052
 >> iter 89000, loss: 0.174316
 >> iter 90000, loss: 0.124185
   Number of active neurons: 3
 >> iter 91000, loss: 0.232630
 >> iter 92000, loss: 0.234569
 >> iter 93000, loss: 0.179446
 >> iter 94000, loss: 0.205371
 >> iter 95000, loss: 0.269179
 >> iter 96000, loss: 0.250665
 >> iter 97000, loss: 0.149056
 >> iter 98000, loss: 0.155443
 >> iter 99000, loss: 0.165874
 >> iter 100000, loss: 0.197366
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

