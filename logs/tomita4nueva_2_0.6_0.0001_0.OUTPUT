 > Problema: tomita4nueva
 > Args:
   - Hidden size: 2
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.688293
 >> iter 2000, loss: 12.376802
 >> iter 3000, loss: 8.623916
 >> iter 4000, loss: 7.309965
 >> iter 5000, loss: 6.877626
 >> iter 6000, loss: 6.135021
 >> iter 7000, loss: 5.738907
 >> iter 8000, loss: 5.490303
 >> iter 9000, loss: 5.801099
 >> iter 10000, loss: 5.152811
   Number of active neurons: 2
 >> iter 11000, loss: 4.843207
 >> iter 12000, loss: 4.926431
 >> iter 13000, loss: 5.254620
 >> iter 14000, loss: 4.891845
 >> iter 15000, loss: 5.168922
 >> iter 16000, loss: 4.616146
 >> iter 17000, loss: 4.634475
 >> iter 18000, loss: 4.699851
 >> iter 19000, loss: 4.659812
 >> iter 20000, loss: 4.321965
   Number of active neurons: 2
 >> iter 21000, loss: 4.134717
 >> iter 22000, loss: 4.207190
 >> iter 23000, loss: 4.042508
 >> iter 24000, loss: 3.898204
 >> iter 25000, loss: 3.779912
 >> iter 26000, loss: 4.035516
 >> iter 27000, loss: 4.208028
 >> iter 28000, loss: 4.533778
 >> iter 29000, loss: 3.659091
 >> iter 30000, loss: 4.000660
   Number of active neurons: 2
 >> iter 31000, loss: 3.945530
 >> iter 32000, loss: 3.948061
 >> iter 33000, loss: 3.507417
 >> iter 34000, loss: 3.517791
 >> iter 35000, loss: 3.878677
 >> iter 36000, loss: 3.706837
 >> iter 37000, loss: 3.879213
 >> iter 38000, loss: 3.560616
 >> iter 39000, loss: 3.757297
 >> iter 40000, loss: 3.912835
   Number of active neurons: 2
 >> iter 41000, loss: 3.822941
 >> iter 42000, loss: 3.744570
 >> iter 43000, loss: 3.826815
 >> iter 44000, loss: 3.724097
 >> iter 45000, loss: 3.778973
 >> iter 46000, loss: 3.893170
 >> iter 47000, loss: 3.982914
 >> iter 48000, loss: 4.083221
 >> iter 49000, loss: 3.317650
 >> iter 50000, loss: 3.796679
   Number of active neurons: 2
 >> iter 51000, loss: 3.752845
 >> iter 52000, loss: 3.563151
 >> iter 53000, loss: 3.397479
 >> iter 54000, loss: 3.590227
 >> iter 55000, loss: 3.525348
 >> iter 56000, loss: 3.458025
 >> iter 57000, loss: 3.615934
 >> iter 58000, loss: 3.731988
 >> iter 59000, loss: 3.285569
 >> iter 60000, loss: 3.631883
   Number of active neurons: 2
 >> iter 61000, loss: 3.156320
 >> iter 62000, loss: 3.215100
 >> iter 63000, loss: 3.723361
 >> iter 64000, loss: 3.578735
 >> iter 65000, loss: 3.512476
 >> iter 66000, loss: 3.537697
 >> iter 67000, loss: 3.299853
 >> iter 68000, loss: 3.669258
 >> iter 69000, loss: 3.313420
 >> iter 70000, loss: 3.810338
   Number of active neurons: 2
 >> iter 71000, loss: 3.838194
 >> iter 72000, loss: 3.379974
 >> iter 73000, loss: 3.184302
 >> iter 74000, loss: 3.342244
 >> iter 75000, loss: 3.412472
 >> iter 76000, loss: 3.200942
 >> iter 77000, loss: 3.264033
 >> iter 78000, loss: 3.294871
 >> iter 79000, loss: 3.028752
 >> iter 80000, loss: 3.292482
   Number of active neurons: 2
 >> iter 81000, loss: 3.233130
 >> iter 82000, loss: 3.630027
 >> iter 83000, loss: 3.531641
 >> iter 84000, loss: 3.574988
 >> iter 85000, loss: 3.361419
 >> iter 86000, loss: 3.399678
 >> iter 87000, loss: 3.292390
 >> iter 88000, loss: 3.088701
 >> iter 89000, loss: 3.512414
 >> iter 90000, loss: 3.397023
   Number of active neurons: 2
 >> iter 91000, loss: 3.326729
 >> iter 92000, loss: 3.489674
 >> iter 93000, loss: 3.395464
 >> iter 94000, loss: 3.356820
 >> iter 95000, loss: 3.002632
 >> iter 96000, loss: 3.166002
 >> iter 97000, loss: 3.222966
 >> iter 98000, loss: 3.368111
 >> iter 99000, loss: 3.140796
 >> iter 100000, loss: 3.430042
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.916902
 >> iter 2000, loss: 11.570072
 >> iter 3000, loss: 8.856923
 >> iter 4000, loss: 7.604703
 >> iter 5000, loss: 6.532280
 >> iter 6000, loss: 6.574534
 >> iter 7000, loss: 6.007664
 >> iter 8000, loss: 5.779516
 >> iter 9000, loss: 5.510193
 >> iter 10000, loss: 5.214999
   Number of active neurons: 2
 >> iter 11000, loss: 5.163512
 >> iter 12000, loss: 5.015125
 >> iter 13000, loss: 5.085221
 >> iter 14000, loss: 5.062555
 >> iter 15000, loss: 5.307664
 >> iter 16000, loss: 5.112141
 >> iter 17000, loss: 5.126018
 >> iter 18000, loss: 5.036134
 >> iter 19000, loss: 4.967932
 >> iter 20000, loss: 5.061291
   Number of active neurons: 2
 >> iter 21000, loss: 5.280668
 >> iter 22000, loss: 5.113583
 >> iter 23000, loss: 4.545967
 >> iter 24000, loss: 4.717828
 >> iter 25000, loss: 4.753028
 >> iter 26000, loss: 4.816875
 >> iter 27000, loss: 4.778854
 >> iter 28000, loss: 4.902635
 >> iter 29000, loss: 4.731346
 >> iter 30000, loss: 4.787123
   Number of active neurons: 2
 >> iter 31000, loss: 4.602071
 >> iter 32000, loss: 4.712217
 >> iter 33000, loss: 4.623378
 >> iter 34000, loss: 4.691236
 >> iter 35000, loss: 4.893034
 >> iter 36000, loss: 5.017573
 >> iter 37000, loss: 4.861847
 >> iter 38000, loss: 4.564064
 >> iter 39000, loss: 4.981332
 >> iter 40000, loss: 5.200009
   Number of active neurons: 2
 >> iter 41000, loss: 4.934473
 >> iter 42000, loss: 5.025610
 >> iter 43000, loss: 4.916311
 >> iter 44000, loss: 4.847821
 >> iter 45000, loss: 4.883520
 >> iter 46000, loss: 5.562363
 >> iter 47000, loss: 5.066355
 >> iter 48000, loss: 5.140035
 >> iter 49000, loss: 4.678227
 >> iter 50000, loss: 4.481698
   Number of active neurons: 2
 >> iter 51000, loss: 4.314799
 >> iter 52000, loss: 4.542604
 >> iter 53000, loss: 4.547254
 >> iter 54000, loss: 4.596615
 >> iter 55000, loss: 4.630440
 >> iter 56000, loss: 4.726277
 >> iter 57000, loss: 4.220503
 >> iter 58000, loss: 4.305817
 >> iter 59000, loss: 4.324293
 >> iter 60000, loss: 4.678267
   Number of active neurons: 2
 >> iter 61000, loss: 4.775285
 >> iter 62000, loss: 4.536320
 >> iter 63000, loss: 4.278782
 >> iter 64000, loss: 4.600725
 >> iter 65000, loss: 4.500115
 >> iter 66000, loss: 4.549516
 >> iter 67000, loss: 4.662759
 >> iter 68000, loss: 4.576239
 >> iter 69000, loss: 4.548141
 >> iter 70000, loss: 4.458890
   Number of active neurons: 2
 >> iter 71000, loss: 4.326329
 >> iter 72000, loss: 4.812195
 >> iter 73000, loss: 4.449082
 >> iter 74000, loss: 4.206838
 >> iter 75000, loss: 4.084163
 >> iter 76000, loss: 4.514555
 >> iter 77000, loss: 4.318979
 >> iter 78000, loss: 4.440393
 >> iter 79000, loss: 4.175357
 >> iter 80000, loss: 4.643860
   Number of active neurons: 2
 >> iter 81000, loss: 4.562040
 >> iter 82000, loss: 4.468211
 >> iter 83000, loss: 4.447145
 >> iter 84000, loss: 4.484467
 >> iter 85000, loss: 4.021971
 >> iter 86000, loss: 4.311262
 >> iter 87000, loss: 4.222966
 >> iter 88000, loss: 4.210005
 >> iter 89000, loss: 4.272999
 >> iter 90000, loss: 4.351639
   Number of active neurons: 2
 >> iter 91000, loss: 4.072516
 >> iter 92000, loss: 4.297424
 >> iter 93000, loss: 4.012525
 >> iter 94000, loss: 4.344285
 >> iter 95000, loss: 4.404989
 >> iter 96000, loss: 4.480248
 >> iter 97000, loss: 4.228211
 >> iter 98000, loss: 4.409954
 >> iter 99000, loss: 4.331282
 >> iter 100000, loss: 4.387715
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.657374
 >> iter 2000, loss: 12.093503
 >> iter 3000, loss: 8.635538
 >> iter 4000, loss: 6.865890
 >> iter 5000, loss: 6.181309
 >> iter 6000, loss: 5.875541
 >> iter 7000, loss: 5.634741
 >> iter 8000, loss: 5.186021
 >> iter 9000, loss: 5.413075
 >> iter 10000, loss: 5.425364
   Number of active neurons: 2
 >> iter 11000, loss: 5.529026
 >> iter 12000, loss: 5.344366
 >> iter 13000, loss: 5.162328
 >> iter 14000, loss: 5.307829
 >> iter 15000, loss: 5.271146
 >> iter 16000, loss: 4.844945
 >> iter 17000, loss: 5.087460
 >> iter 18000, loss: 4.909116
 >> iter 19000, loss: 4.770486
 >> iter 20000, loss: 5.110352
   Number of active neurons: 2
 >> iter 21000, loss: 5.100992
 >> iter 22000, loss: 5.052803
 >> iter 23000, loss: 4.793520
 >> iter 24000, loss: 5.173463
 >> iter 25000, loss: 4.906023
 >> iter 26000, loss: 4.946973
 >> iter 27000, loss: 5.004088
 >> iter 28000, loss: 5.134402
 >> iter 29000, loss: 4.833853
 >> iter 30000, loss: 4.973879
   Number of active neurons: 2
 >> iter 31000, loss: 5.039013
 >> iter 32000, loss: 5.016440
 >> iter 33000, loss: 4.615522
 >> iter 34000, loss: 4.943048
 >> iter 35000, loss: 4.952051
 >> iter 36000, loss: 4.797876
 >> iter 37000, loss: 4.574777
 >> iter 38000, loss: 4.579969
 >> iter 39000, loss: 4.653106
 >> iter 40000, loss: 4.917915
   Number of active neurons: 2
 >> iter 41000, loss: 4.811178
 >> iter 42000, loss: 4.865645
 >> iter 43000, loss: 4.634994
 >> iter 44000, loss: 4.980475
 >> iter 45000, loss: 4.795809
 >> iter 46000, loss: 4.636887
 >> iter 47000, loss: 5.009178
 >> iter 48000, loss: 4.697877
 >> iter 49000, loss: 4.991738
 >> iter 50000, loss: 4.553601
   Number of active neurons: 2
 >> iter 51000, loss: 4.637869
 >> iter 52000, loss: 4.810918
 >> iter 53000, loss: 4.526083
 >> iter 54000, loss: 4.480632
 >> iter 55000, loss: 4.418035
 >> iter 56000, loss: 4.454018
 >> iter 57000, loss: 4.641629
 >> iter 58000, loss: 4.832949
 >> iter 59000, loss: 4.135423
 >> iter 60000, loss: 4.531459
   Number of active neurons: 2
 >> iter 61000, loss: 4.547780
 >> iter 62000, loss: 4.582363
 >> iter 63000, loss: 4.216561
 >> iter 64000, loss: 4.078197
 >> iter 65000, loss: 4.568153
 >> iter 66000, loss: 4.224594
 >> iter 67000, loss: 4.285796
 >> iter 68000, loss: 4.601969
 >> iter 69000, loss: 4.549180
 >> iter 70000, loss: 4.566865
   Number of active neurons: 2
 >> iter 71000, loss: 4.275802
 >> iter 72000, loss: 4.438115
 >> iter 73000, loss: 4.385891
 >> iter 74000, loss: 4.396561
 >> iter 75000, loss: 4.618989
 >> iter 76000, loss: 4.765596
 >> iter 77000, loss: 4.313694
 >> iter 78000, loss: 4.154305
 >> iter 79000, loss: 4.023216
 >> iter 80000, loss: 4.011305
   Number of active neurons: 2
 >> iter 81000, loss: 4.261923
 >> iter 82000, loss: 4.274399
 >> iter 83000, loss: 4.242596
 >> iter 84000, loss: 4.149030
 >> iter 85000, loss: 4.364348
 >> iter 86000, loss: 4.021074
 >> iter 87000, loss: 4.030298
 >> iter 88000, loss: 4.121111
 >> iter 89000, loss: 4.436743
 >> iter 90000, loss: 4.074193
   Number of active neurons: 2
 >> iter 91000, loss: 3.987156
 >> iter 92000, loss: 3.850372
 >> iter 93000, loss: 3.902206
 >> iter 94000, loss: 4.502640
 >> iter 95000, loss: 4.163395
 >> iter 96000, loss: 4.203748
 >> iter 97000, loss: 3.974573
 >> iter 98000, loss: 4.057644
 >> iter 99000, loss: 4.222579
 >> iter 100000, loss: 4.044100
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524762
 >> iter 2000, loss: 18.054279
 >> iter 3000, loss: 17.068461
 >> iter 4000, loss: 16.779348
 >> iter 5000, loss: 16.602161
 >> iter 6000, loss: 16.598180
 >> iter 7000, loss: 16.539942
 >> iter 8000, loss: 16.570969
 >> iter 9000, loss: 16.532182
 >> iter 10000, loss: 16.581924
   Number of active neurons: 0
 >> iter 11000, loss: 16.532516
 >> iter 12000, loss: 16.591974
 >> iter 13000, loss: 16.533415
 >> iter 14000, loss: 16.598199
 >> iter 15000, loss: 16.533569
 >> iter 16000, loss: 16.105455
 >> iter 17000, loss: 12.312591
 >> iter 18000, loss: 8.983877
 >> iter 19000, loss: 7.417136
 >> iter 20000, loss: 6.653062
   Number of active neurons: 2
 >> iter 21000, loss: 6.488486
 >> iter 22000, loss: 5.989145
 >> iter 23000, loss: 5.917411
 >> iter 24000, loss: 6.079151
 >> iter 25000, loss: 6.269861
 >> iter 26000, loss: 5.708525
 >> iter 27000, loss: 5.264893
 >> iter 28000, loss: 5.335690
 >> iter 29000, loss: 4.677143
 >> iter 30000, loss: 5.226587
   Number of active neurons: 2
 >> iter 31000, loss: 4.978066
 >> iter 32000, loss: 4.866157
 >> iter 33000, loss: 4.843912
 >> iter 34000, loss: 4.775591
 >> iter 35000, loss: 4.531141
 >> iter 36000, loss: 4.662146
 >> iter 37000, loss: 4.831366
 >> iter 38000, loss: 4.334934
 >> iter 39000, loss: 4.358796
 >> iter 40000, loss: 4.638295
   Number of active neurons: 2
 >> iter 41000, loss: 4.193339
 >> iter 42000, loss: 4.057622
 >> iter 43000, loss: 4.119579
 >> iter 44000, loss: 4.013157
 >> iter 45000, loss: 4.042773
 >> iter 46000, loss: 3.948513
 >> iter 47000, loss: 4.091995
 >> iter 48000, loss: 4.179114
 >> iter 49000, loss: 4.010398
 >> iter 50000, loss: 4.191835
   Number of active neurons: 2
 >> iter 51000, loss: 3.795741
 >> iter 52000, loss: 3.883679
 >> iter 53000, loss: 3.786017
 >> iter 54000, loss: 3.546180
 >> iter 55000, loss: 3.812547
 >> iter 56000, loss: 4.121480
 >> iter 57000, loss: 3.889267
 >> iter 58000, loss: 3.996150
 >> iter 59000, loss: 3.920500
 >> iter 60000, loss: 3.656359
   Number of active neurons: 2
 >> iter 61000, loss: 3.348053
 >> iter 62000, loss: 3.897107
 >> iter 63000, loss: 3.710557
 >> iter 64000, loss: 3.704649
 >> iter 65000, loss: 3.646272
 >> iter 66000, loss: 3.411405
 >> iter 67000, loss: 3.784488
 >> iter 68000, loss: 3.581634
 >> iter 69000, loss: 4.141860
 >> iter 70000, loss: 4.142568
   Number of active neurons: 2
 >> iter 71000, loss: 3.619862
 >> iter 72000, loss: 3.371844
 >> iter 73000, loss: 3.633288
 >> iter 74000, loss: 3.648717
 >> iter 75000, loss: 3.479343
 >> iter 76000, loss: 3.315392
 >> iter 77000, loss: 3.397264
 >> iter 78000, loss: 3.627472
 >> iter 79000, loss: 3.470579
 >> iter 80000, loss: 3.485301
   Number of active neurons: 2
 >> iter 81000, loss: 3.739601
 >> iter 82000, loss: 4.065021
 >> iter 83000, loss: 3.585272
 >> iter 84000, loss: 3.193475
 >> iter 85000, loss: 3.217990
 >> iter 86000, loss: 3.372381
 >> iter 87000, loss: 3.504125
 >> iter 88000, loss: 3.337942
 >> iter 89000, loss: 3.474443
 >> iter 90000, loss: 3.455344
   Number of active neurons: 2
 >> iter 91000, loss: 3.054874
 >> iter 92000, loss: 3.195944
 >> iter 93000, loss: 3.439249
 >> iter 94000, loss: 3.333018
 >> iter 95000, loss: 3.482605
 >> iter 96000, loss: 3.466474
 >> iter 97000, loss: 3.218694
 >> iter 98000, loss: 3.725645
 >> iter 99000, loss: 3.259716
 >> iter 100000, loss: 3.330314
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.181775
 >> iter 2000, loss: 11.289752
 >> iter 3000, loss: 8.306105
 >> iter 4000, loss: 7.244658
 >> iter 5000, loss: 6.594939
 >> iter 6000, loss: 5.895318
 >> iter 7000, loss: 5.821028
 >> iter 8000, loss: 5.567817
 >> iter 9000, loss: 5.468156
 >> iter 10000, loss: 5.138378
   Number of active neurons: 2
 >> iter 11000, loss: 5.284258
 >> iter 12000, loss: 5.288654
 >> iter 13000, loss: 5.514607
 >> iter 14000, loss: 5.671059
 >> iter 15000, loss: 5.379576
 >> iter 16000, loss: 5.177836
 >> iter 17000, loss: 5.377023
 >> iter 18000, loss: 5.420301
 >> iter 19000, loss: 5.142528
 >> iter 20000, loss: 5.112640
   Number of active neurons: 2
 >> iter 21000, loss: 5.271994
 >> iter 22000, loss: 5.082992
 >> iter 23000, loss: 5.006119
 >> iter 24000, loss: 4.682234
 >> iter 25000, loss: 4.635356
 >> iter 26000, loss: 4.922279
 >> iter 27000, loss: 4.730412
 >> iter 28000, loss: 4.940788
 >> iter 29000, loss: 5.099843
 >> iter 30000, loss: 4.835725
   Number of active neurons: 2
 >> iter 31000, loss: 4.792160
 >> iter 32000, loss: 5.202237
 >> iter 33000, loss: 4.917154
 >> iter 34000, loss: 4.816005
 >> iter 35000, loss: 4.915297
 >> iter 36000, loss: 4.692177
 >> iter 37000, loss: 5.139739
 >> iter 38000, loss: 5.153814
 >> iter 39000, loss: 4.893524
 >> iter 40000, loss: 4.676166
   Number of active neurons: 2
 >> iter 41000, loss: 4.625375
 >> iter 42000, loss: 4.574752
 >> iter 43000, loss: 4.847602
 >> iter 44000, loss: 5.029162
 >> iter 45000, loss: 4.718936
 >> iter 46000, loss: 4.517144
 >> iter 47000, loss: 4.628036
 >> iter 48000, loss: 4.649345
 >> iter 49000, loss: 4.641101
 >> iter 50000, loss: 4.701074
   Number of active neurons: 2
 >> iter 51000, loss: 4.880372
 >> iter 52000, loss: 4.935300
 >> iter 53000, loss: 4.812393
 >> iter 54000, loss: 4.941829
 >> iter 55000, loss: 4.877224
 >> iter 56000, loss: 4.730673
 >> iter 57000, loss: 4.227904
 >> iter 58000, loss: 4.425157
 >> iter 59000, loss: 4.431265
 >> iter 60000, loss: 4.459199
   Number of active neurons: 2
 >> iter 61000, loss: 4.479210
 >> iter 62000, loss: 4.373167
 >> iter 63000, loss: 4.479332
 >> iter 64000, loss: 4.701971
 >> iter 65000, loss: 4.693186
 >> iter 66000, loss: 4.842554
 >> iter 67000, loss: 4.658433
 >> iter 68000, loss: 4.864951
 >> iter 69000, loss: 4.600462
 >> iter 70000, loss: 4.500281
   Number of active neurons: 2
 >> iter 71000, loss: 4.282995
 >> iter 72000, loss: 4.702449
 >> iter 73000, loss: 4.623899
 >> iter 74000, loss: 4.691296
 >> iter 75000, loss: 4.454520
 >> iter 76000, loss: 4.234659
 >> iter 77000, loss: 4.520450
 >> iter 78000, loss: 4.315090
 >> iter 79000, loss: 4.181282
 >> iter 80000, loss: 4.578988
   Number of active neurons: 2
 >> iter 81000, loss: 4.311668
 >> iter 82000, loss: 4.627753
 >> iter 83000, loss: 4.308279
 >> iter 84000, loss: 4.516268
 >> iter 85000, loss: 4.556427
 >> iter 86000, loss: 4.382915
 >> iter 87000, loss: 4.193412
 >> iter 88000, loss: 4.262636
 >> iter 89000, loss: 4.273629
 >> iter 90000, loss: 4.271089
   Number of active neurons: 2
 >> iter 91000, loss: 4.120179
 >> iter 92000, loss: 4.165758
 >> iter 93000, loss: 4.201973
 >> iter 94000, loss: 4.249974
 >> iter 95000, loss: 4.420841
 >> iter 96000, loss: 3.792176
 >> iter 97000, loss: 4.201243
 >> iter 98000, loss: 4.427331
 >> iter 99000, loss: 4.383003
 >> iter 100000, loss: 4.415858
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 18.797693
 >> iter 2000, loss: 12.762041
 >> iter 3000, loss: 9.276472
 >> iter 4000, loss: 7.947179
 >> iter 5000, loss: 7.214061
 >> iter 6000, loss: 6.601591
 >> iter 7000, loss: 6.521920
 >> iter 8000, loss: 6.200656
 >> iter 9000, loss: 6.207962
 >> iter 10000, loss: 6.294554
   Number of active neurons: 2
 >> iter 11000, loss: 6.132761
 >> iter 12000, loss: 5.746662
 >> iter 13000, loss: 5.947203
 >> iter 14000, loss: 5.753886
 >> iter 15000, loss: 5.820814
 >> iter 16000, loss: 5.799450
 >> iter 17000, loss: 5.626767
 >> iter 18000, loss: 5.703579
 >> iter 19000, loss: 5.694620
 >> iter 20000, loss: 5.655713
   Number of active neurons: 2
 >> iter 21000, loss: 5.680142
 >> iter 22000, loss: 5.584149
 >> iter 23000, loss: 5.598095
 >> iter 24000, loss: 5.344122
 >> iter 25000, loss: 5.103721
 >> iter 26000, loss: 4.991157
 >> iter 27000, loss: 4.843297
 >> iter 28000, loss: 5.002162
 >> iter 29000, loss: 5.164442
 >> iter 30000, loss: 5.095677
   Number of active neurons: 2
 >> iter 31000, loss: 4.675493
 >> iter 32000, loss: 4.604389
 >> iter 33000, loss: 4.607928
 >> iter 34000, loss: 4.241709
 >> iter 35000, loss: 3.968899
 >> iter 36000, loss: 4.031726
 >> iter 37000, loss: 3.921225
 >> iter 38000, loss: 4.085654
 >> iter 39000, loss: 3.666172
 >> iter 40000, loss: 3.950525
   Number of active neurons: 2
 >> iter 41000, loss: 3.863824
 >> iter 42000, loss: 3.664260
 >> iter 43000, loss: 3.993900
 >> iter 44000, loss: 4.140020
 >> iter 45000, loss: 3.778333
 >> iter 46000, loss: 3.761462
 >> iter 47000, loss: 3.965368
 >> iter 48000, loss: 3.856847
 >> iter 49000, loss: 3.590342
 >> iter 50000, loss: 3.827491
   Number of active neurons: 2
 >> iter 51000, loss: 3.789083
 >> iter 52000, loss: 4.035350
 >> iter 53000, loss: 3.887481
 >> iter 54000, loss: 3.886151
 >> iter 55000, loss: 3.873698
 >> iter 56000, loss: 3.628566
 >> iter 57000, loss: 4.065103
 >> iter 58000, loss: 4.090653
 >> iter 59000, loss: 4.006236
 >> iter 60000, loss: 3.581376
   Number of active neurons: 2
 >> iter 61000, loss: 3.479111
 >> iter 62000, loss: 3.655233
 >> iter 63000, loss: 3.599216
 >> iter 64000, loss: 3.474195
 >> iter 65000, loss: 3.453624
 >> iter 66000, loss: 3.589100
 >> iter 67000, loss: 3.253832
 >> iter 68000, loss: 3.609757
 >> iter 69000, loss: 3.500895
 >> iter 70000, loss: 3.819410
   Number of active neurons: 2
 >> iter 71000, loss: 3.643473
 >> iter 72000, loss: 3.544289
 >> iter 73000, loss: 3.527845
 >> iter 74000, loss: 3.543825
 >> iter 75000, loss: 3.544881
 >> iter 76000, loss: 3.110462
 >> iter 77000, loss: 3.754655
 >> iter 78000, loss: 3.452266
 >> iter 79000, loss: 3.347713
 >> iter 80000, loss: 2.938045
   Number of active neurons: 2
 >> iter 81000, loss: 3.353111
 >> iter 82000, loss: 3.275438
 >> iter 83000, loss: 3.332649
 >> iter 84000, loss: 3.508152
 >> iter 85000, loss: 3.578001
 >> iter 86000, loss: 3.481600
 >> iter 87000, loss: 3.328870
 >> iter 88000, loss: 3.491106
 >> iter 89000, loss: 3.140779
 >> iter 90000, loss: 3.697918
   Number of active neurons: 2
 >> iter 91000, loss: 3.860462
 >> iter 92000, loss: 3.271182
 >> iter 93000, loss: 3.705445
 >> iter 94000, loss: 3.471017
 >> iter 95000, loss: 3.562688
 >> iter 96000, loss: 3.361765
 >> iter 97000, loss: 3.411565
 >> iter 98000, loss: 3.561332
 >> iter 99000, loss: 3.502669
 >> iter 100000, loss: 3.269097
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.218798
 >> iter 2000, loss: 11.644679
 >> iter 3000, loss: 8.699203
 >> iter 4000, loss: 7.112229
 >> iter 5000, loss: 6.694888
 >> iter 6000, loss: 6.173116
 >> iter 7000, loss: 5.623419
 >> iter 8000, loss: 5.685836
 >> iter 9000, loss: 5.439538
 >> iter 10000, loss: 5.254097
   Number of active neurons: 2
 >> iter 11000, loss: 5.475588
 >> iter 12000, loss: 5.362799
 >> iter 13000, loss: 4.970435
 >> iter 14000, loss: 4.871003
 >> iter 15000, loss: 5.162373
 >> iter 16000, loss: 5.176508
 >> iter 17000, loss: 5.313774
 >> iter 18000, loss: 4.902130
 >> iter 19000, loss: 5.221612
 >> iter 20000, loss: 5.091003
   Number of active neurons: 2
 >> iter 21000, loss: 4.828132
 >> iter 22000, loss: 4.787359
 >> iter 23000, loss: 4.878936
 >> iter 24000, loss: 5.051963
 >> iter 25000, loss: 5.269534
 >> iter 26000, loss: 5.129613
 >> iter 27000, loss: 5.131487
 >> iter 28000, loss: 5.022985
 >> iter 29000, loss: 4.754615
 >> iter 30000, loss: 5.066179
   Number of active neurons: 2
 >> iter 31000, loss: 4.442104
 >> iter 32000, loss: 4.378388
 >> iter 33000, loss: 4.940975
 >> iter 34000, loss: 4.617896
 >> iter 35000, loss: 4.343317
 >> iter 36000, loss: 4.745697
 >> iter 37000, loss: 4.772119
 >> iter 38000, loss: 4.517855
 >> iter 39000, loss: 4.632058
 >> iter 40000, loss: 4.549623
   Number of active neurons: 2
 >> iter 41000, loss: 4.766134
 >> iter 42000, loss: 4.642454
 >> iter 43000, loss: 4.590066
 >> iter 44000, loss: 4.935623
 >> iter 45000, loss: 4.806982
 >> iter 46000, loss: 4.825266
 >> iter 47000, loss: 4.725195
 >> iter 48000, loss: 4.687988
 >> iter 49000, loss: 4.435334
 >> iter 50000, loss: 4.549355
   Number of active neurons: 2
 >> iter 51000, loss: 4.449066
 >> iter 52000, loss: 4.905559
 >> iter 53000, loss: 4.591747
 >> iter 54000, loss: 4.958405
 >> iter 55000, loss: 4.513467
 >> iter 56000, loss: 4.644021
 >> iter 57000, loss: 4.455749
 >> iter 58000, loss: 4.444850
 >> iter 59000, loss: 4.100665
 >> iter 60000, loss: 4.284213
   Number of active neurons: 2
 >> iter 61000, loss: 4.626380
 >> iter 62000, loss: 4.660400
 >> iter 63000, loss: 4.401478
 >> iter 64000, loss: 4.316294
 >> iter 65000, loss: 4.250413
 >> iter 66000, loss: 4.118213
 >> iter 67000, loss: 4.161808
 >> iter 68000, loss: 4.433376
 >> iter 69000, loss: 4.344753
 >> iter 70000, loss: 4.185258
   Number of active neurons: 2
 >> iter 71000, loss: 4.354839
 >> iter 72000, loss: 4.505519
 >> iter 73000, loss: 4.272184
 >> iter 74000, loss: 4.272576
 >> iter 75000, loss: 4.083948
 >> iter 76000, loss: 4.413615
 >> iter 77000, loss: 4.171855
 >> iter 78000, loss: 4.197707
 >> iter 79000, loss: 4.123428
 >> iter 80000, loss: 4.241255
   Number of active neurons: 2
 >> iter 81000, loss: 4.405947
 >> iter 82000, loss: 4.332904
 >> iter 83000, loss: 4.201238
 >> iter 84000, loss: 4.055571
 >> iter 85000, loss: 4.439400
 >> iter 86000, loss: 4.382714
 >> iter 87000, loss: 4.017827
 >> iter 88000, loss: 4.142976
 >> iter 89000, loss: 4.023448
 >> iter 90000, loss: 4.043582
   Number of active neurons: 2
 >> iter 91000, loss: 4.423808
 >> iter 92000, loss: 4.287285
 >> iter 93000, loss: 4.255750
 >> iter 94000, loss: 4.639495
 >> iter 95000, loss: 4.297086
 >> iter 96000, loss: 4.079321
 >> iter 97000, loss: 3.945757
 >> iter 98000, loss: 4.340625
 >> iter 99000, loss: 4.160292
 >> iter 100000, loss: 4.571248
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524754
 >> iter 2000, loss: 16.797963
 >> iter 3000, loss: 12.203534
 >> iter 4000, loss: 9.465457
 >> iter 5000, loss: 8.030569
 >> iter 6000, loss: 6.584183
 >> iter 7000, loss: 6.014779
 >> iter 8000, loss: 5.645608
 >> iter 9000, loss: 5.612385
 >> iter 10000, loss: 5.397951
   Number of active neurons: 2
 >> iter 11000, loss: 5.585300
 >> iter 12000, loss: 5.429373
 >> iter 13000, loss: 4.942177
 >> iter 14000, loss: 5.718711
 >> iter 15000, loss: 5.080206
 >> iter 16000, loss: 4.899104
 >> iter 17000, loss: 5.011701
 >> iter 18000, loss: 4.984303
 >> iter 19000, loss: 5.278419
 >> iter 20000, loss: 5.175858
   Number of active neurons: 2
 >> iter 21000, loss: 4.843962
 >> iter 22000, loss: 4.710234
 >> iter 23000, loss: 4.388986
 >> iter 24000, loss: 4.888674
 >> iter 25000, loss: 5.195042
 >> iter 26000, loss: 4.892933
 >> iter 27000, loss: 4.881069
 >> iter 28000, loss: 5.176197
 >> iter 29000, loss: 4.824674
 >> iter 30000, loss: 4.897981
   Number of active neurons: 2
 >> iter 31000, loss: 4.929388
 >> iter 32000, loss: 4.478857
 >> iter 33000, loss: 4.536491
 >> iter 34000, loss: 4.665572
 >> iter 35000, loss: 4.751370
 >> iter 36000, loss: 4.674968
 >> iter 37000, loss: 4.752489
 >> iter 38000, loss: 4.812523
 >> iter 39000, loss: 5.019958
 >> iter 40000, loss: 4.853856
   Number of active neurons: 2
 >> iter 41000, loss: 4.755926
 >> iter 42000, loss: 4.646824
 >> iter 43000, loss: 4.630867
 >> iter 44000, loss: 4.709074
 >> iter 45000, loss: 4.447353
 >> iter 46000, loss: 4.358897
 >> iter 47000, loss: 4.514305
 >> iter 48000, loss: 4.454377
 >> iter 49000, loss: 4.577965
 >> iter 50000, loss: 4.668176
   Number of active neurons: 2
 >> iter 51000, loss: 4.638998
 >> iter 52000, loss: 4.688902
 >> iter 53000, loss: 4.672297
 >> iter 54000, loss: 4.345500
 >> iter 55000, loss: 4.322415
 >> iter 56000, loss: 4.448846
 >> iter 57000, loss: 4.060173
 >> iter 58000, loss: 4.535944
 >> iter 59000, loss: 4.349697
 >> iter 60000, loss: 4.243831
   Number of active neurons: 2
 >> iter 61000, loss: 4.426711
 >> iter 62000, loss: 4.390943
 >> iter 63000, loss: 4.677683
 >> iter 64000, loss: 4.487709
 >> iter 65000, loss: 4.185552
 >> iter 66000, loss: 4.222487
 >> iter 67000, loss: 4.423343
 >> iter 68000, loss: 4.108005
 >> iter 69000, loss: 4.377864
 >> iter 70000, loss: 4.679622
   Number of active neurons: 2
 >> iter 71000, loss: 3.879253
 >> iter 72000, loss: 4.189523
 >> iter 73000, loss: 4.474339
 >> iter 74000, loss: 4.848990
 >> iter 75000, loss: 4.645138
 >> iter 76000, loss: 4.620859
 >> iter 77000, loss: 4.497510
 >> iter 78000, loss: 4.101052
 >> iter 79000, loss: 4.056211
 >> iter 80000, loss: 4.254369
   Number of active neurons: 2
 >> iter 81000, loss: 4.157043
 >> iter 82000, loss: 4.131749
 >> iter 83000, loss: 4.055493
 >> iter 84000, loss: 4.626114
 >> iter 85000, loss: 4.010747
 >> iter 86000, loss: 4.535180
 >> iter 87000, loss: 4.189455
 >> iter 88000, loss: 3.771605
 >> iter 89000, loss: 4.005000
 >> iter 90000, loss: 4.289850
   Number of active neurons: 2
 >> iter 91000, loss: 4.305905
 >> iter 92000, loss: 4.196912
 >> iter 93000, loss: 4.204418
 >> iter 94000, loss: 4.414286
 >> iter 95000, loss: 4.078565
 >> iter 96000, loss: 3.902235
 >> iter 97000, loss: 4.358744
 >> iter 98000, loss: 4.703098
 >> iter 99000, loss: 4.599491
 >> iter 100000, loss: 4.565861
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.957630
 >> iter 2000, loss: 12.408960
 >> iter 3000, loss: 9.157023
 >> iter 4000, loss: 7.731411
 >> iter 5000, loss: 6.922785
 >> iter 6000, loss: 6.688109
 >> iter 7000, loss: 6.491536
 >> iter 8000, loss: 6.092233
 >> iter 9000, loss: 5.669230
 >> iter 10000, loss: 5.128205
   Number of active neurons: 2
 >> iter 11000, loss: 5.112165
 >> iter 12000, loss: 5.231709
 >> iter 13000, loss: 4.929501
 >> iter 14000, loss: 4.919990
 >> iter 15000, loss: 4.958864
 >> iter 16000, loss: 5.192359
 >> iter 17000, loss: 4.794770
 >> iter 18000, loss: 4.398899
 >> iter 19000, loss: 4.022851
 >> iter 20000, loss: 4.084397
   Number of active neurons: 2
 >> iter 21000, loss: 4.557271
 >> iter 22000, loss: 4.447125
 >> iter 23000, loss: 4.400687
 >> iter 24000, loss: 4.111877
 >> iter 25000, loss: 3.897847
 >> iter 26000, loss: 4.140763
 >> iter 27000, loss: 4.547438
 >> iter 28000, loss: 4.627725
 >> iter 29000, loss: 4.251832
 >> iter 30000, loss: 3.931644
   Number of active neurons: 2
 >> iter 31000, loss: 4.191438
 >> iter 32000, loss: 3.927509
 >> iter 33000, loss: 3.882605
 >> iter 34000, loss: 3.765665
 >> iter 35000, loss: 3.458355
 >> iter 36000, loss: 3.977038
 >> iter 37000, loss: 3.857561
 >> iter 38000, loss: 3.677246
 >> iter 39000, loss: 3.830491
 >> iter 40000, loss: 3.882538
   Number of active neurons: 2
 >> iter 41000, loss: 3.823282
 >> iter 42000, loss: 3.609224
 >> iter 43000, loss: 3.468370
 >> iter 44000, loss: 3.774246
 >> iter 45000, loss: 3.599375
 >> iter 46000, loss: 3.606111
 >> iter 47000, loss: 3.899102
 >> iter 48000, loss: 3.699431
 >> iter 49000, loss: 3.722453
 >> iter 50000, loss: 3.696896
   Number of active neurons: 2
 >> iter 51000, loss: 3.782090
 >> iter 52000, loss: 3.893159
 >> iter 53000, loss: 3.565490
 >> iter 54000, loss: 3.857530
 >> iter 55000, loss: 3.991246
 >> iter 56000, loss: 3.529599
 >> iter 57000, loss: 3.411276
 >> iter 58000, loss: 3.833548
 >> iter 59000, loss: 3.647263
 >> iter 60000, loss: 3.397197
   Number of active neurons: 2
 >> iter 61000, loss: 3.334178
 >> iter 62000, loss: 3.311922
 >> iter 63000, loss: 3.491100
 >> iter 64000, loss: 3.821714
 >> iter 65000, loss: 3.961341
 >> iter 66000, loss: 3.484331
 >> iter 67000, loss: 3.060285
 >> iter 68000, loss: 3.162690
 >> iter 69000, loss: 2.985816
 >> iter 70000, loss: 3.327092
   Number of active neurons: 2
 >> iter 71000, loss: 3.423505
 >> iter 72000, loss: 3.175418
 >> iter 73000, loss: 3.560500
 >> iter 74000, loss: 3.553421
 >> iter 75000, loss: 3.160879
 >> iter 76000, loss: 3.031600
 >> iter 77000, loss: 3.799088
 >> iter 78000, loss: 3.381788
 >> iter 79000, loss: 3.322008
 >> iter 80000, loss: 3.309812
   Number of active neurons: 2
 >> iter 81000, loss: 3.058293
 >> iter 82000, loss: 3.351150
 >> iter 83000, loss: 3.459373
 >> iter 84000, loss: 3.448286
 >> iter 85000, loss: 3.548032
 >> iter 86000, loss: 3.341785
 >> iter 87000, loss: 3.621067
 >> iter 88000, loss: 3.283095
 >> iter 89000, loss: 3.435516
 >> iter 90000, loss: 3.121988
   Number of active neurons: 2
 >> iter 91000, loss: 3.087185
 >> iter 92000, loss: 3.389288
 >> iter 93000, loss: 2.871018
 >> iter 94000, loss: 3.483614
 >> iter 95000, loss: 3.093326
 >> iter 96000, loss: 3.084271
 >> iter 97000, loss: 3.100119
 >> iter 98000, loss: 3.412536
 >> iter 99000, loss: 3.386707
 >> iter 100000, loss: 3.349770
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524759
 >> iter 2000, loss: 18.054279
 >> iter 3000, loss: 17.068461
 >> iter 4000, loss: 16.779365
 >> iter 5000, loss: 16.602168
 >> iter 6000, loss: 16.105151
 >> iter 7000, loss: 11.349933
 >> iter 8000, loss: 8.439097
 >> iter 9000, loss: 7.323239
 >> iter 10000, loss: 6.530294
   Number of active neurons: 2
 >> iter 11000, loss: 6.590234
 >> iter 12000, loss: 6.191222
 >> iter 13000, loss: 6.088348
 >> iter 14000, loss: 5.956009
 >> iter 15000, loss: 5.669827
 >> iter 16000, loss: 5.315281
 >> iter 17000, loss: 5.327970
 >> iter 18000, loss: 5.167510
 >> iter 19000, loss: 5.232234
 >> iter 20000, loss: 4.940305
   Number of active neurons: 2
 >> iter 21000, loss: 5.093601
 >> iter 22000, loss: 5.011032
 >> iter 23000, loss: 4.635134
 >> iter 24000, loss: 5.008672
 >> iter 25000, loss: 5.027875
 >> iter 26000, loss: 5.039468
 >> iter 27000, loss: 4.835843
 >> iter 28000, loss: 4.844939
 >> iter 29000, loss: 4.688704
 >> iter 30000, loss: 4.812366
   Number of active neurons: 2
 >> iter 31000, loss: 5.055364
 >> iter 32000, loss: 5.243010
 >> iter 33000, loss: 4.900648
 >> iter 34000, loss: 5.112673
 >> iter 35000, loss: 4.322408
 >> iter 36000, loss: 4.814851
 >> iter 37000, loss: 4.511925
 >> iter 38000, loss: 4.550550
 >> iter 39000, loss: 4.964743
 >> iter 40000, loss: 5.181430
   Number of active neurons: 2
 >> iter 41000, loss: 5.082903
 >> iter 42000, loss: 4.816545
 >> iter 43000, loss: 5.037647
 >> iter 44000, loss: 4.861109
 >> iter 45000, loss: 4.423897
 >> iter 46000, loss: 4.393103
 >> iter 47000, loss: 4.591214
 >> iter 48000, loss: 4.590466
 >> iter 49000, loss: 4.534756
 >> iter 50000, loss: 5.131981
   Number of active neurons: 2
 >> iter 51000, loss: 4.693250
 >> iter 52000, loss: 4.739410
 >> iter 53000, loss: 4.386407
 >> iter 54000, loss: 4.639368
 >> iter 55000, loss: 4.761702
 >> iter 56000, loss: 4.648771
 >> iter 57000, loss: 4.443888
 >> iter 58000, loss: 4.381207
 >> iter 59000, loss: 4.320720
 >> iter 60000, loss: 4.512474
   Number of active neurons: 2
 >> iter 61000, loss: 4.981078
 >> iter 62000, loss: 5.040376
 >> iter 63000, loss: 4.580080
 >> iter 64000, loss: 4.554004
 >> iter 65000, loss: 4.766978
 >> iter 66000, loss: 4.661882
 >> iter 67000, loss: 4.385949
 >> iter 68000, loss: 4.391036
 >> iter 69000, loss: 4.227731
 >> iter 70000, loss: 4.577163
   Number of active neurons: 2
 >> iter 71000, loss: 4.472897
 >> iter 72000, loss: 4.109558
 >> iter 73000, loss: 4.260993
 >> iter 74000, loss: 4.645071
 >> iter 75000, loss: 3.980615
 >> iter 76000, loss: 4.246331
 >> iter 77000, loss: 4.705776
 >> iter 78000, loss: 4.654346
 >> iter 79000, loss: 4.479929
 >> iter 80000, loss: 4.233528
   Number of active neurons: 2
 >> iter 81000, loss: 4.477639
 >> iter 82000, loss: 4.299413
 >> iter 83000, loss: 4.201266
 >> iter 84000, loss: 4.645617
 >> iter 85000, loss: 4.374454
 >> iter 86000, loss: 4.625416
 >> iter 87000, loss: 4.626229
 >> iter 88000, loss: 4.849377
 >> iter 89000, loss: 4.218770
 >> iter 90000, loss: 4.663993
   Number of active neurons: 2
 >> iter 91000, loss: 4.592461
 >> iter 92000, loss: 4.318667
 >> iter 93000, loss: 4.145730
 >> iter 94000, loss: 4.573014
 >> iter 95000, loss: 4.285906
 >> iter 96000, loss: 4.458737
 >> iter 97000, loss: 4.525829
 >> iter 98000, loss: 4.443583
 >> iter 99000, loss: 4.113996
 >> iter 100000, loss: 4.527748
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.385893
 >> iter 2000, loss: 12.429672
 >> iter 3000, loss: 9.131191
 >> iter 4000, loss: 7.342531
 >> iter 5000, loss: 6.590271
 >> iter 6000, loss: 6.261062
 >> iter 7000, loss: 6.192666
 >> iter 8000, loss: 5.815764
 >> iter 9000, loss: 5.845921
 >> iter 10000, loss: 5.283542
   Number of active neurons: 2
 >> iter 11000, loss: 4.862891
 >> iter 12000, loss: 5.277749
 >> iter 13000, loss: 4.944026
 >> iter 14000, loss: 4.871555
 >> iter 15000, loss: 5.032939
 >> iter 16000, loss: 4.853747
 >> iter 17000, loss: 4.968730
 >> iter 18000, loss: 4.820799
 >> iter 19000, loss: 5.121779
 >> iter 20000, loss: 4.999820
   Number of active neurons: 2
 >> iter 21000, loss: 4.821635
 >> iter 22000, loss: 4.724332
 >> iter 23000, loss: 4.638840
 >> iter 24000, loss: 4.593794
 >> iter 25000, loss: 4.570589
 >> iter 26000, loss: 5.248647
 >> iter 27000, loss: 5.033740
 >> iter 28000, loss: 4.663650
 >> iter 29000, loss: 4.583369
 >> iter 30000, loss: 4.811239
   Number of active neurons: 2
 >> iter 31000, loss: 4.647851
 >> iter 32000, loss: 4.649325
 >> iter 33000, loss: 4.928426
 >> iter 34000, loss: 4.752085
 >> iter 35000, loss: 4.749159
 >> iter 36000, loss: 4.628598
 >> iter 37000, loss: 4.289397
 >> iter 38000, loss: 4.335866
 >> iter 39000, loss: 4.218617
 >> iter 40000, loss: 4.641302
   Number of active neurons: 2
 >> iter 41000, loss: 4.524476
 >> iter 42000, loss: 4.939149
 >> iter 43000, loss: 4.876371
 >> iter 44000, loss: 4.808446
 >> iter 45000, loss: 4.316902
 >> iter 46000, loss: 4.567551
 >> iter 47000, loss: 4.615955
 >> iter 48000, loss: 4.876719
 >> iter 49000, loss: 4.683926
 >> iter 50000, loss: 4.415064
   Number of active neurons: 2
 >> iter 51000, loss: 4.437862
 >> iter 52000, loss: 4.665654
 >> iter 53000, loss: 4.693279
 >> iter 54000, loss: 4.535209
 >> iter 55000, loss: 4.486404
 >> iter 56000, loss: 4.595048
 >> iter 57000, loss: 4.554982
 >> iter 58000, loss: 4.764535
 >> iter 59000, loss: 4.493990
 >> iter 60000, loss: 4.325048
   Number of active neurons: 2
 >> iter 61000, loss: 4.462457
 >> iter 62000, loss: 4.816532
 >> iter 63000, loss: 4.431259
 >> iter 64000, loss: 4.198891
 >> iter 65000, loss: 4.308013
 >> iter 66000, loss: 4.510419
 >> iter 67000, loss: 4.676221
 >> iter 68000, loss: 4.419424
 >> iter 69000, loss: 4.499183
 >> iter 70000, loss: 4.320607
   Number of active neurons: 2
 >> iter 71000, loss: 4.595607
 >> iter 72000, loss: 4.453405
 >> iter 73000, loss: 4.108604
 >> iter 74000, loss: 4.306972
 >> iter 75000, loss: 4.458632
 >> iter 76000, loss: 4.175801
 >> iter 77000, loss: 4.347710
 >> iter 78000, loss: 4.380372
 >> iter 79000, loss: 4.216320
 >> iter 80000, loss: 4.460920
   Number of active neurons: 2
 >> iter 81000, loss: 4.544522
 >> iter 82000, loss: 4.565076
 >> iter 83000, loss: 4.204681
 >> iter 84000, loss: 4.495144
 >> iter 85000, loss: 4.285130
 >> iter 86000, loss: 3.863338
 >> iter 87000, loss: 4.299779
 >> iter 88000, loss: 4.092969
 >> iter 89000, loss: 3.961664
 >> iter 90000, loss: 3.751563
   Number of active neurons: 2
 >> iter 91000, loss: 3.692074
 >> iter 92000, loss: 3.728953
 >> iter 93000, loss: 4.120013
 >> iter 94000, loss: 4.227914
 >> iter 95000, loss: 3.969864
 >> iter 96000, loss: 4.217479
 >> iter 97000, loss: 4.345560
 >> iter 98000, loss: 4.087676
 >> iter 99000, loss: 4.110866
 >> iter 100000, loss: 4.207122
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524753
 >> iter 2000, loss: 18.054277
 >> iter 3000, loss: 17.068460
 >> iter 4000, loss: 15.951118
 >> iter 5000, loss: 12.119621
 >> iter 6000, loss: 9.186851
 >> iter 7000, loss: 7.462903
 >> iter 8000, loss: 6.616661
 >> iter 9000, loss: 6.038684
 >> iter 10000, loss: 6.101207
   Number of active neurons: 2
 >> iter 11000, loss: 5.638297
 >> iter 12000, loss: 5.806547
 >> iter 13000, loss: 5.421107
 >> iter 14000, loss: 5.631203
 >> iter 15000, loss: 5.247127
 >> iter 16000, loss: 5.082345
 >> iter 17000, loss: 4.968028
 >> iter 18000, loss: 4.858302
 >> iter 19000, loss: 5.207677
 >> iter 20000, loss: 5.103044
   Number of active neurons: 2
 >> iter 21000, loss: 5.114392
 >> iter 22000, loss: 5.166290
 >> iter 23000, loss: 5.188379
 >> iter 24000, loss: 4.970251
 >> iter 25000, loss: 4.840791
 >> iter 26000, loss: 4.824093
 >> iter 27000, loss: 5.118842
 >> iter 28000, loss: 4.918351
 >> iter 29000, loss: 5.032820
 >> iter 30000, loss: 4.744796
   Number of active neurons: 2
 >> iter 31000, loss: 4.648670
 >> iter 32000, loss: 4.807814
 >> iter 33000, loss: 4.545695
 >> iter 34000, loss: 4.657175
 >> iter 35000, loss: 4.610425
 >> iter 36000, loss: 4.690734
 >> iter 37000, loss: 5.114553
 >> iter 38000, loss: 5.052417
 >> iter 39000, loss: 4.876140
 >> iter 40000, loss: 5.088029
   Number of active neurons: 2
 >> iter 41000, loss: 4.792724
 >> iter 42000, loss: 4.827870
 >> iter 43000, loss: 4.857019
 >> iter 44000, loss: 4.702028
 >> iter 45000, loss: 4.508576
 >> iter 46000, loss: 4.684980
 >> iter 47000, loss: 4.474057
 >> iter 48000, loss: 4.937949
 >> iter 49000, loss: 4.925303
 >> iter 50000, loss: 4.871451
   Number of active neurons: 2
 >> iter 51000, loss: 4.752262
 >> iter 52000, loss: 4.953287
 >> iter 53000, loss: 4.521609
 >> iter 54000, loss: 4.260656
 >> iter 55000, loss: 4.402995
 >> iter 56000, loss: 4.545370
 >> iter 57000, loss: 4.723162
 >> iter 58000, loss: 4.646480
 >> iter 59000, loss: 4.692774
 >> iter 60000, loss: 4.639295
   Number of active neurons: 2
 >> iter 61000, loss: 4.221115
 >> iter 62000, loss: 4.959219
 >> iter 63000, loss: 4.494727
 >> iter 64000, loss: 4.031346
 >> iter 65000, loss: 4.444085
 >> iter 66000, loss: 4.521103
 >> iter 67000, loss: 4.433139
 >> iter 68000, loss: 4.542530
 >> iter 69000, loss: 4.212581
 >> iter 70000, loss: 4.359576
   Number of active neurons: 2
 >> iter 71000, loss: 4.463819
 >> iter 72000, loss: 4.643833
 >> iter 73000, loss: 4.510969
 >> iter 74000, loss: 4.499238
 >> iter 75000, loss: 4.440104
 >> iter 76000, loss: 4.384599
 >> iter 77000, loss: 4.186147
 >> iter 78000, loss: 4.300549
 >> iter 79000, loss: 4.054764
 >> iter 80000, loss: 4.273803
   Number of active neurons: 2
 >> iter 81000, loss: 4.118098
 >> iter 82000, loss: 4.851729
 >> iter 83000, loss: 4.540441
 >> iter 84000, loss: 4.718839
 >> iter 85000, loss: 4.204206
 >> iter 86000, loss: 4.300057
 >> iter 87000, loss: 4.477946
 >> iter 88000, loss: 4.507368
 >> iter 89000, loss: 4.194508
 >> iter 90000, loss: 4.200488
   Number of active neurons: 2
 >> iter 91000, loss: 3.866316
 >> iter 92000, loss: 4.057949
 >> iter 93000, loss: 3.726624
 >> iter 94000, loss: 4.027610
 >> iter 95000, loss: 3.966087
 >> iter 96000, loss: 4.108125
 >> iter 97000, loss: 3.873201
 >> iter 98000, loss: 4.327650
 >> iter 99000, loss: 4.289285
 >> iter 100000, loss: 4.202338
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524759
 >> iter 2000, loss: 18.054275
 >> iter 3000, loss: 17.068459
 >> iter 4000, loss: 16.779360
 >> iter 5000, loss: 16.602167
 >> iter 6000, loss: 16.598203
 >> iter 7000, loss: 16.539953
 >> iter 8000, loss: 16.570974
 >> iter 9000, loss: 16.532184
 >> iter 10000, loss: 15.843448
   Number of active neurons: 2
 >> iter 11000, loss: 11.430852
 >> iter 12000, loss: 8.865799
 >> iter 13000, loss: 7.655585
 >> iter 14000, loss: 6.659530
 >> iter 15000, loss: 6.115648
 >> iter 16000, loss: 5.737553
 >> iter 17000, loss: 5.782377
 >> iter 18000, loss: 5.651388
 >> iter 19000, loss: 5.537218
 >> iter 20000, loss: 5.057037
   Number of active neurons: 2
 >> iter 21000, loss: 5.083366
 >> iter 22000, loss: 5.046453
 >> iter 23000, loss: 4.663388
 >> iter 24000, loss: 5.149444
 >> iter 25000, loss: 4.930359
 >> iter 26000, loss: 5.155524
 >> iter 27000, loss: 5.123029
 >> iter 28000, loss: 4.983107
 >> iter 29000, loss: 5.100723
 >> iter 30000, loss: 4.821558
   Number of active neurons: 2
 >> iter 31000, loss: 4.394153
 >> iter 32000, loss: 4.634874
 >> iter 33000, loss: 4.786497
 >> iter 34000, loss: 4.709784
 >> iter 35000, loss: 4.987364
 >> iter 36000, loss: 4.651821
 >> iter 37000, loss: 4.552530
 >> iter 38000, loss: 4.841531
 >> iter 39000, loss: 4.752347
 >> iter 40000, loss: 4.727812
   Number of active neurons: 2
 >> iter 41000, loss: 4.702113
 >> iter 42000, loss: 4.464664
 >> iter 43000, loss: 4.461683
 >> iter 44000, loss: 4.561899
 >> iter 45000, loss: 4.341665
 >> iter 46000, loss: 4.347912
 >> iter 47000, loss: 4.483823
 >> iter 48000, loss: 4.565810
 >> iter 49000, loss: 4.381981
 >> iter 50000, loss: 4.690344
   Number of active neurons: 2
 >> iter 51000, loss: 4.253728
 >> iter 52000, loss: 4.299470
 >> iter 53000, loss: 4.373645
 >> iter 54000, loss: 4.374019
 >> iter 55000, loss: 4.202746
 >> iter 56000, loss: 4.172208
 >> iter 57000, loss: 4.253414
 >> iter 58000, loss: 4.388691
 >> iter 59000, loss: 4.176431
 >> iter 60000, loss: 4.065544
   Number of active neurons: 2
 >> iter 61000, loss: 4.106383
 >> iter 62000, loss: 4.422511
 >> iter 63000, loss: 4.287796
 >> iter 64000, loss: 4.400788
 >> iter 65000, loss: 4.423117
 >> iter 66000, loss: 4.041629
 >> iter 67000, loss: 4.062028
 >> iter 68000, loss: 4.283685
 >> iter 69000, loss: 4.184929
 >> iter 70000, loss: 4.248088
   Number of active neurons: 2
 >> iter 71000, loss: 4.355038
 >> iter 72000, loss: 4.361627
 >> iter 73000, loss: 4.164419
 >> iter 74000, loss: 4.363399
 >> iter 75000, loss: 4.383481
 >> iter 76000, loss: 4.739248
 >> iter 77000, loss: 4.253590
 >> iter 78000, loss: 4.510807
 >> iter 79000, loss: 4.223618
 >> iter 80000, loss: 4.337506
   Number of active neurons: 2
 >> iter 81000, loss: 3.952751
 >> iter 82000, loss: 4.008072
 >> iter 83000, loss: 4.187870
 >> iter 84000, loss: 4.222668
 >> iter 85000, loss: 4.063861
 >> iter 86000, loss: 4.080025
 >> iter 87000, loss: 4.078969
 >> iter 88000, loss: 4.299969
 >> iter 89000, loss: 4.211971
 >> iter 90000, loss: 3.968025
   Number of active neurons: 2
 >> iter 91000, loss: 4.143110
 >> iter 92000, loss: 4.295058
 >> iter 93000, loss: 3.916323
 >> iter 94000, loss: 4.205646
 >> iter 95000, loss: 4.216128
 >> iter 96000, loss: 4.238667
 >> iter 97000, loss: 4.314140
 >> iter 98000, loss: 4.746672
 >> iter 99000, loss: 4.194765
 >> iter 100000, loss: 3.918613
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.438349
 >> iter 2000, loss: 11.671673
 >> iter 3000, loss: 8.689660
 >> iter 4000, loss: 7.064259
 >> iter 5000, loss: 6.048072
 >> iter 6000, loss: 5.706707
 >> iter 7000, loss: 5.792302
 >> iter 8000, loss: 5.476373
 >> iter 9000, loss: 5.506781
 >> iter 10000, loss: 5.336549
   Number of active neurons: 2
 >> iter 11000, loss: 5.254225
 >> iter 12000, loss: 5.352260
 >> iter 13000, loss: 5.594089
 >> iter 14000, loss: 5.005580
 >> iter 15000, loss: 5.246582
 >> iter 16000, loss: 5.336702
 >> iter 17000, loss: 5.029321
 >> iter 18000, loss: 5.234436
 >> iter 19000, loss: 5.155182
 >> iter 20000, loss: 5.444859
   Number of active neurons: 2
 >> iter 21000, loss: 5.596771
 >> iter 22000, loss: 5.131239
 >> iter 23000, loss: 5.541946
 >> iter 24000, loss: 4.782893
 >> iter 25000, loss: 4.730136
 >> iter 26000, loss: 4.704781
 >> iter 27000, loss: 4.347396
 >> iter 28000, loss: 4.992349
 >> iter 29000, loss: 4.732002
 >> iter 30000, loss: 4.977908
   Number of active neurons: 2
 >> iter 31000, loss: 4.839953
 >> iter 32000, loss: 5.127108
 >> iter 33000, loss: 4.702356
 >> iter 34000, loss: 4.846111
 >> iter 35000, loss: 4.830166
 >> iter 36000, loss: 4.487032
 >> iter 37000, loss: 4.506199
 >> iter 38000, loss: 4.910799
 >> iter 39000, loss: 4.708751
 >> iter 40000, loss: 4.950027
   Number of active neurons: 2
 >> iter 41000, loss: 4.831077
 >> iter 42000, loss: 4.489904
 >> iter 43000, loss: 4.612729
 >> iter 44000, loss: 4.737615
 >> iter 45000, loss: 4.461788
 >> iter 46000, loss: 4.630989
 >> iter 47000, loss: 4.877480
 >> iter 48000, loss: 4.749063
 >> iter 49000, loss: 5.074597
 >> iter 50000, loss: 4.707326
   Number of active neurons: 2
 >> iter 51000, loss: 4.619210
 >> iter 52000, loss: 4.998944
 >> iter 53000, loss: 4.377023
 >> iter 54000, loss: 4.065473
 >> iter 55000, loss: 4.072647
 >> iter 56000, loss: 4.364599
 >> iter 57000, loss: 4.533460
 >> iter 58000, loss: 4.620721
 >> iter 59000, loss: 4.860167
 >> iter 60000, loss: 4.519760
   Number of active neurons: 2
 >> iter 61000, loss: 4.476558
 >> iter 62000, loss: 4.279164
 >> iter 63000, loss: 4.229133
 >> iter 64000, loss: 4.475829
 >> iter 65000, loss: 4.288727
 >> iter 66000, loss: 4.112376
 >> iter 67000, loss: 4.172105
 >> iter 68000, loss: 4.649505
 >> iter 69000, loss: 4.449428
 >> iter 70000, loss: 4.323747
   Number of active neurons: 2
 >> iter 71000, loss: 4.111454
 >> iter 72000, loss: 4.391165
 >> iter 73000, loss: 4.366138
 >> iter 74000, loss: 4.406311
 >> iter 75000, loss: 4.358983
 >> iter 76000, loss: 4.585477
 >> iter 77000, loss: 4.483802
 >> iter 78000, loss: 4.642122
 >> iter 79000, loss: 4.537928
 >> iter 80000, loss: 4.258017
   Number of active neurons: 2
 >> iter 81000, loss: 4.473978
 >> iter 82000, loss: 4.358134
 >> iter 83000, loss: 3.840892
 >> iter 84000, loss: 4.517472
 >> iter 85000, loss: 4.084491
 >> iter 86000, loss: 4.406498
 >> iter 87000, loss: 4.283344
 >> iter 88000, loss: 4.156721
 >> iter 89000, loss: 4.208110
 >> iter 90000, loss: 4.538832
   Number of active neurons: 2
 >> iter 91000, loss: 4.424885
 >> iter 92000, loss: 4.535603
 >> iter 93000, loss: 4.405490
 >> iter 94000, loss: 4.172096
 >> iter 95000, loss: 4.228376
 >> iter 96000, loss: 4.436412
 >> iter 97000, loss: 4.383670
 >> iter 98000, loss: 4.318368
 >> iter 99000, loss: 4.232080
 >> iter 100000, loss: 4.181468
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 20.524761
 >> iter 2000, loss: 18.054276
 >> iter 3000, loss: 17.068460
 >> iter 4000, loss: 15.774676
 >> iter 5000, loss: 11.544887
 >> iter 6000, loss: 8.762167
 >> iter 7000, loss: 7.558590
 >> iter 8000, loss: 7.030887
 >> iter 9000, loss: 6.426162
 >> iter 10000, loss: 6.026831
   Number of active neurons: 2
 >> iter 11000, loss: 5.775807
 >> iter 12000, loss: 5.702366
 >> iter 13000, loss: 5.477493
 >> iter 14000, loss: 5.308023
 >> iter 15000, loss: 5.426992
 >> iter 16000, loss: 5.254758
 >> iter 17000, loss: 5.218064
 >> iter 18000, loss: 4.847009
 >> iter 19000, loss: 4.902967
 >> iter 20000, loss: 4.708237
   Number of active neurons: 2
 >> iter 21000, loss: 5.322981
 >> iter 22000, loss: 5.038279
 >> iter 23000, loss: 4.960734
 >> iter 24000, loss: 4.741713
 >> iter 25000, loss: 4.798332
 >> iter 26000, loss: 4.755185
 >> iter 27000, loss: 4.717745
 >> iter 28000, loss: 4.477436
 >> iter 29000, loss: 4.550079
 >> iter 30000, loss: 4.592007
   Number of active neurons: 2
 >> iter 31000, loss: 4.534064
 >> iter 32000, loss: 4.559130
 >> iter 33000, loss: 4.510051
 >> iter 34000, loss: 4.975260
 >> iter 35000, loss: 4.804255
 >> iter 36000, loss: 4.390826
 >> iter 37000, loss: 4.328764
 >> iter 38000, loss: 3.912646
 >> iter 39000, loss: 4.346340
 >> iter 40000, loss: 4.524686
   Number of active neurons: 2
 >> iter 41000, loss: 4.450682
 >> iter 42000, loss: 4.347326
 >> iter 43000, loss: 4.812890
 >> iter 44000, loss: 4.509950
 >> iter 45000, loss: 3.836602
 >> iter 46000, loss: 4.634835
 >> iter 47000, loss: 3.903536
 >> iter 48000, loss: 4.235888
 >> iter 49000, loss: 4.311486
 >> iter 50000, loss: 4.673513
   Number of active neurons: 2
 >> iter 51000, loss: 3.952887
 >> iter 52000, loss: 4.198236
 >> iter 53000, loss: 4.523659
 >> iter 54000, loss: 4.765058
 >> iter 55000, loss: 4.978406
 >> iter 56000, loss: 4.927066
 >> iter 57000, loss: 4.295590
 >> iter 58000, loss: 4.405485
 >> iter 59000, loss: 4.353340
 >> iter 60000, loss: 4.333374
   Number of active neurons: 2
 >> iter 61000, loss: 4.384300
 >> iter 62000, loss: 4.461691
 >> iter 63000, loss: 4.109794
 >> iter 64000, loss: 4.139809
 >> iter 65000, loss: 4.035161
 >> iter 66000, loss: 4.232292
 >> iter 67000, loss: 4.204529
 >> iter 68000, loss: 4.366831
 >> iter 69000, loss: 4.063720
 >> iter 70000, loss: 3.962059
   Number of active neurons: 2
 >> iter 71000, loss: 4.021499
 >> iter 72000, loss: 4.358247
 >> iter 73000, loss: 3.935374
 >> iter 74000, loss: 3.787823
 >> iter 75000, loss: 3.941632
 >> iter 76000, loss: 4.401981
 >> iter 77000, loss: 4.381827
 >> iter 78000, loss: 4.257707
 >> iter 79000, loss: 4.008955
 >> iter 80000, loss: 4.164814
   Number of active neurons: 2
 >> iter 81000, loss: 4.280806
 >> iter 82000, loss: 4.314215
 >> iter 83000, loss: 4.162141
 >> iter 84000, loss: 3.917578
 >> iter 85000, loss: 3.931397
 >> iter 86000, loss: 4.337417
 >> iter 87000, loss: 3.658643
 >> iter 88000, loss: 4.379946
 >> iter 89000, loss: 3.992618
 >> iter 90000, loss: 4.170092
   Number of active neurons: 2
 >> iter 91000, loss: 4.132202
 >> iter 92000, loss: 4.079190
 >> iter 93000, loss: 4.149226
 >> iter 94000, loss: 3.961408
 >> iter 95000, loss: 3.822844
 >> iter 96000, loss: 4.199692
 >> iter 97000, loss: 4.626997
 >> iter 98000, loss: 4.303482
 >> iter 99000, loss: 4.265408
 >> iter 100000, loss: 3.931749
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 20.524760
 >> iter 2000, loss: 18.054283
 >> iter 3000, loss: 17.068463
 >> iter 4000, loss: 16.082630
 >> iter 5000, loss: 11.726027
 >> iter 6000, loss: 8.899786
 >> iter 7000, loss: 7.750094
 >> iter 8000, loss: 6.887499
 >> iter 9000, loss: 6.505113
 >> iter 10000, loss: 5.862780
   Number of active neurons: 2
 >> iter 11000, loss: 5.871798
 >> iter 12000, loss: 5.478724
 >> iter 13000, loss: 5.840470
 >> iter 14000, loss: 5.537290
 >> iter 15000, loss: 5.181999
 >> iter 16000, loss: 5.328464
 >> iter 17000, loss: 5.178900
 >> iter 18000, loss: 5.054248
 >> iter 19000, loss: 5.287033
 >> iter 20000, loss: 4.798436
   Number of active neurons: 2
 >> iter 21000, loss: 5.052441
 >> iter 22000, loss: 4.850615
 >> iter 23000, loss: 4.584433
 >> iter 24000, loss: 4.692835
 >> iter 25000, loss: 4.551327
 >> iter 26000, loss: 4.599083
 >> iter 27000, loss: 4.326427
 >> iter 28000, loss: 4.702914
 >> iter 29000, loss: 4.437905
 >> iter 30000, loss: 4.190275
   Number of active neurons: 2
 >> iter 31000, loss: 3.986077
 >> iter 32000, loss: 4.520997
 >> iter 33000, loss: 4.279937
 >> iter 34000, loss: 4.331704
 >> iter 35000, loss: 4.402380
 >> iter 36000, loss: 4.781648
 >> iter 37000, loss: 4.449775
 >> iter 38000, loss: 3.984307
 >> iter 39000, loss: 4.619794
 >> iter 40000, loss: 4.430698
   Number of active neurons: 2
 >> iter 41000, loss: 3.943607
 >> iter 42000, loss: 4.341426
 >> iter 43000, loss: 3.981511
 >> iter 44000, loss: 3.920605
 >> iter 45000, loss: 3.843710
 >> iter 46000, loss: 4.066448
 >> iter 47000, loss: 3.695126
 >> iter 48000, loss: 4.078837
 >> iter 49000, loss: 3.594998
 >> iter 50000, loss: 3.797954
   Number of active neurons: 2
 >> iter 51000, loss: 3.815300
 >> iter 52000, loss: 4.178355
 >> iter 53000, loss: 4.354688
 >> iter 54000, loss: 3.998991
 >> iter 55000, loss: 3.591701
 >> iter 56000, loss: 3.983238
 >> iter 57000, loss: 3.884112
 >> iter 58000, loss: 3.903788
 >> iter 59000, loss: 4.030246
 >> iter 60000, loss: 4.161024
   Number of active neurons: 2
 >> iter 61000, loss: 3.708729
 >> iter 62000, loss: 4.204436
 >> iter 63000, loss: 3.847352
 >> iter 64000, loss: 3.964526
 >> iter 65000, loss: 3.595659
 >> iter 66000, loss: 3.351286
 >> iter 67000, loss: 3.360143
 >> iter 68000, loss: 3.764831
 >> iter 69000, loss: 3.633490
 >> iter 70000, loss: 3.671153
   Number of active neurons: 2
 >> iter 71000, loss: 3.753078
 >> iter 72000, loss: 3.631038
 >> iter 73000, loss: 3.485039
 >> iter 74000, loss: 3.677523
 >> iter 75000, loss: 3.196258
 >> iter 76000, loss: 3.480952
 >> iter 77000, loss: 3.603362
 >> iter 78000, loss: 3.577863
 >> iter 79000, loss: 3.505784
 >> iter 80000, loss: 3.223242
   Number of active neurons: 2
 >> iter 81000, loss: 3.409514
 >> iter 82000, loss: 3.139169
 >> iter 83000, loss: 3.448793
 >> iter 84000, loss: 3.678280
 >> iter 85000, loss: 3.589725
 >> iter 86000, loss: 3.194347
 >> iter 87000, loss: 3.214494
 >> iter 88000, loss: 3.389100
 >> iter 89000, loss: 3.331500
 >> iter 90000, loss: 3.394822
   Number of active neurons: 2
 >> iter 91000, loss: 3.210248
 >> iter 92000, loss: 3.126462
 >> iter 93000, loss: 3.276421
 >> iter 94000, loss: 3.219680
 >> iter 95000, loss: 3.408972
 >> iter 96000, loss: 3.595678
 >> iter 97000, loss: 3.420686
 >> iter 98000, loss: 3.675503
 >> iter 99000, loss: 3.419892
 >> iter 100000, loss: 3.568423
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.327795
 >> iter 2000, loss: 12.107855
 >> iter 3000, loss: 8.614166
 >> iter 4000, loss: 7.471433
 >> iter 5000, loss: 6.350071
 >> iter 6000, loss: 6.356201
 >> iter 7000, loss: 5.894657
 >> iter 8000, loss: 5.684306
 >> iter 9000, loss: 5.749816
 >> iter 10000, loss: 5.702104
   Number of active neurons: 2
 >> iter 11000, loss: 5.746232
 >> iter 12000, loss: 5.641853
 >> iter 13000, loss: 5.238604
 >> iter 14000, loss: 4.867867
 >> iter 15000, loss: 4.614340
 >> iter 16000, loss: 4.648715
 >> iter 17000, loss: 4.591947
 >> iter 18000, loss: 4.798055
 >> iter 19000, loss: 4.832903
 >> iter 20000, loss: 4.699993
   Number of active neurons: 2
 >> iter 21000, loss: 4.811308
 >> iter 22000, loss: 4.812536
 >> iter 23000, loss: 4.777605
 >> iter 24000, loss: 4.216594
 >> iter 25000, loss: 4.530502
 >> iter 26000, loss: 4.650651
 >> iter 27000, loss: 4.198442
 >> iter 28000, loss: 4.035469
 >> iter 29000, loss: 4.179041
 >> iter 30000, loss: 4.124368
   Number of active neurons: 2
 >> iter 31000, loss: 4.029887
 >> iter 32000, loss: 3.900655
 >> iter 33000, loss: 4.240547
 >> iter 34000, loss: 3.884818
 >> iter 35000, loss: 3.957637
 >> iter 36000, loss: 4.148790
 >> iter 37000, loss: 3.982173
 >> iter 38000, loss: 3.937241
 >> iter 39000, loss: 4.028339
 >> iter 40000, loss: 4.179279
   Number of active neurons: 2
 >> iter 41000, loss: 4.072631
 >> iter 42000, loss: 3.924571
 >> iter 43000, loss: 3.738840
 >> iter 44000, loss: 4.047454
 >> iter 45000, loss: 3.854093
 >> iter 46000, loss: 3.526524
 >> iter 47000, loss: 3.716766
 >> iter 48000, loss: 3.723936
 >> iter 49000, loss: 3.468912
 >> iter 50000, loss: 3.343338
   Number of active neurons: 2
 >> iter 51000, loss: 3.498424
 >> iter 52000, loss: 3.497389
 >> iter 53000, loss: 3.577015
 >> iter 54000, loss: 3.753661
 >> iter 55000, loss: 3.607795
 >> iter 56000, loss: 3.576285
 >> iter 57000, loss: 3.692724
 >> iter 58000, loss: 3.585392
 >> iter 59000, loss: 3.356950
 >> iter 60000, loss: 3.702894
   Number of active neurons: 2
 >> iter 61000, loss: 3.203730
 >> iter 62000, loss: 3.517608
 >> iter 63000, loss: 3.327888
 >> iter 64000, loss: 3.384269
 >> iter 65000, loss: 3.271317
 >> iter 66000, loss: 3.719129
 >> iter 67000, loss: 3.818361
 >> iter 68000, loss: 3.869092
 >> iter 69000, loss: 3.499316
 >> iter 70000, loss: 3.538420
   Number of active neurons: 2
 >> iter 71000, loss: 3.446616
 >> iter 72000, loss: 3.515152
 >> iter 73000, loss: 3.358819
 >> iter 74000, loss: 3.456620
 >> iter 75000, loss: 3.422906
 >> iter 76000, loss: 3.681412
 >> iter 77000, loss: 3.458351
 >> iter 78000, loss: 3.406980
 >> iter 79000, loss: 3.346206
 >> iter 80000, loss: 3.185774
   Number of active neurons: 2
 >> iter 81000, loss: 3.166243
 >> iter 82000, loss: 3.813370
 >> iter 83000, loss: 3.673357
 >> iter 84000, loss: 3.393617
 >> iter 85000, loss: 3.168021
 >> iter 86000, loss: 3.516128
 >> iter 87000, loss: 3.376168
 >> iter 88000, loss: 3.310076
 >> iter 89000, loss: 3.336965
 >> iter 90000, loss: 3.295580
   Number of active neurons: 2
 >> iter 91000, loss: 3.099160
 >> iter 92000, loss: 3.156484
 >> iter 93000, loss: 3.016502
 >> iter 94000, loss: 3.092909
 >> iter 95000, loss: 2.939664
 >> iter 96000, loss: 2.882577
 >> iter 97000, loss: 3.309883
 >> iter 98000, loss: 3.139933
 >> iter 99000, loss: 3.081692
 >> iter 100000, loss: 3.452264
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.591566
 >> iter 2000, loss: 11.140217
 >> iter 3000, loss: 8.108246
 >> iter 4000, loss: 6.849059
 >> iter 5000, loss: 6.668848
 >> iter 6000, loss: 6.467992
 >> iter 7000, loss: 6.173436
 >> iter 8000, loss: 5.657229
 >> iter 9000, loss: 5.812514
 >> iter 10000, loss: 6.000955
   Number of active neurons: 2
 >> iter 11000, loss: 5.538673
 >> iter 12000, loss: 5.531579
 >> iter 13000, loss: 5.305777
 >> iter 14000, loss: 5.431817
 >> iter 15000, loss: 4.833579
 >> iter 16000, loss: 5.357721
 >> iter 17000, loss: 4.953489
 >> iter 18000, loss: 4.504667
 >> iter 19000, loss: 4.801883
 >> iter 20000, loss: 5.086133
   Number of active neurons: 2
 >> iter 21000, loss: 4.656517
 >> iter 22000, loss: 4.533588
 >> iter 23000, loss: 4.051911
 >> iter 24000, loss: 3.931816
 >> iter 25000, loss: 4.411589
 >> iter 26000, loss: 4.550010
 >> iter 27000, loss: 4.449213
 >> iter 28000, loss: 4.516071
 >> iter 29000, loss: 3.996826
 >> iter 30000, loss: 4.188639
   Number of active neurons: 2
 >> iter 31000, loss: 4.007698
 >> iter 32000, loss: 4.312390
 >> iter 33000, loss: 3.670807
 >> iter 34000, loss: 3.955599
 >> iter 35000, loss: 3.740630
 >> iter 36000, loss: 3.920284
 >> iter 37000, loss: 3.993085
 >> iter 38000, loss: 4.113464
 >> iter 39000, loss: 4.160921
 >> iter 40000, loss: 3.943628
   Number of active neurons: 2
 >> iter 41000, loss: 3.812002
 >> iter 42000, loss: 3.865982
 >> iter 43000, loss: 3.730405
 >> iter 44000, loss: 4.097563
 >> iter 45000, loss: 4.160799
 >> iter 46000, loss: 3.789520
 >> iter 47000, loss: 3.810579
 >> iter 48000, loss: 3.724147
 >> iter 49000, loss: 4.007606
 >> iter 50000, loss: 3.741557
   Number of active neurons: 2
 >> iter 51000, loss: 3.748266
 >> iter 52000, loss: 3.728301
 >> iter 53000, loss: 3.731520
 >> iter 54000, loss: 4.207375
 >> iter 55000, loss: 4.332552
 >> iter 56000, loss: 4.103958
 >> iter 57000, loss: 3.797502
 >> iter 58000, loss: 3.756873
 >> iter 59000, loss: 3.694907
 >> iter 60000, loss: 4.362334
   Number of active neurons: 2
 >> iter 61000, loss: 3.896950
 >> iter 62000, loss: 3.489946
 >> iter 63000, loss: 4.054849
 >> iter 64000, loss: 3.953042
 >> iter 65000, loss: 3.858267
 >> iter 66000, loss: 3.924892
 >> iter 67000, loss: 3.601380
 >> iter 68000, loss: 3.583934
 >> iter 69000, loss: 3.811250
 >> iter 70000, loss: 4.081812
   Number of active neurons: 2
 >> iter 71000, loss: 3.817384
 >> iter 72000, loss: 4.007064
 >> iter 73000, loss: 3.933472
 >> iter 74000, loss: 3.926211
 >> iter 75000, loss: 3.539717
 >> iter 76000, loss: 3.567561
 >> iter 77000, loss: 3.776008
 >> iter 78000, loss: 3.774518
 >> iter 79000, loss: 4.051624
 >> iter 80000, loss: 4.023665
   Number of active neurons: 2
 >> iter 81000, loss: 3.858428
 >> iter 82000, loss: 3.902628
 >> iter 83000, loss: 3.825349
 >> iter 84000, loss: 3.556100
 >> iter 85000, loss: 3.669090
 >> iter 86000, loss: 3.751385
 >> iter 87000, loss: 3.499047
 >> iter 88000, loss: 3.661305
 >> iter 89000, loss: 3.653323
 >> iter 90000, loss: 3.697939
   Number of active neurons: 2
 >> iter 91000, loss: 3.508941
 >> iter 92000, loss: 3.535876
 >> iter 93000, loss: 3.669686
 >> iter 94000, loss: 3.890815
 >> iter 95000, loss: 3.392545
 >> iter 96000, loss: 3.323774
 >> iter 97000, loss: 3.459971
 >> iter 98000, loss: 3.850643
 >> iter 99000, loss: 3.773587
 >> iter 100000, loss: 3.705591
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.466658
 >> iter 2000, loss: 12.048505
 >> iter 3000, loss: 8.833673
 >> iter 4000, loss: 6.852265
 >> iter 5000, loss: 6.429154
 >> iter 6000, loss: 6.437029
 >> iter 7000, loss: 5.917912
 >> iter 8000, loss: 5.688595
 >> iter 9000, loss: 5.622966
 >> iter 10000, loss: 5.236385
   Number of active neurons: 2
 >> iter 11000, loss: 5.349383
 >> iter 12000, loss: 5.597195
 >> iter 13000, loss: 5.077260
 >> iter 14000, loss: 5.438544
 >> iter 15000, loss: 5.337231
 >> iter 16000, loss: 5.110605
 >> iter 17000, loss: 5.020339
 >> iter 18000, loss: 5.046439
 >> iter 19000, loss: 4.964869
 >> iter 20000, loss: 4.972081
   Number of active neurons: 2
 >> iter 21000, loss: 4.850499
 >> iter 22000, loss: 4.863397
 >> iter 23000, loss: 5.082164
 >> iter 24000, loss: 4.799491
 >> iter 25000, loss: 4.571971
 >> iter 26000, loss: 4.892518
 >> iter 27000, loss: 5.016344
 >> iter 28000, loss: 4.780238
 >> iter 29000, loss: 4.812066
 >> iter 30000, loss: 4.569329
   Number of active neurons: 2
 >> iter 31000, loss: 4.977043
 >> iter 32000, loss: 5.152384
 >> iter 33000, loss: 4.689149
 >> iter 34000, loss: 5.082665
 >> iter 35000, loss: 5.030014
 >> iter 36000, loss: 4.947188
 >> iter 37000, loss: 4.882123
 >> iter 38000, loss: 5.016063
 >> iter 39000, loss: 4.606023
 >> iter 40000, loss: 5.031465
   Number of active neurons: 2
 >> iter 41000, loss: 4.874040
 >> iter 42000, loss: 4.507182
 >> iter 43000, loss: 4.541467
 >> iter 44000, loss: 4.834185
 >> iter 45000, loss: 4.701790
 >> iter 46000, loss: 4.745537
 >> iter 47000, loss: 4.545797
 >> iter 48000, loss: 4.450482
 >> iter 49000, loss: 4.716669
 >> iter 50000, loss: 4.894309
   Number of active neurons: 2
 >> iter 51000, loss: 4.909567
 >> iter 52000, loss: 5.012451
 >> iter 53000, loss: 4.849761
 >> iter 54000, loss: 4.956346
 >> iter 55000, loss: 4.811660
 >> iter 56000, loss: 4.560601
 >> iter 57000, loss: 4.552800
 >> iter 58000, loss: 4.720086
 >> iter 59000, loss: 4.288541
 >> iter 60000, loss: 4.618907
   Number of active neurons: 2
 >> iter 61000, loss: 4.550428
 >> iter 62000, loss: 4.486828
 >> iter 63000, loss: 4.403433
 >> iter 64000, loss: 4.568367
 >> iter 65000, loss: 4.782900
 >> iter 66000, loss: 4.348335
 >> iter 67000, loss: 4.165220
 >> iter 68000, loss: 4.427378
 >> iter 69000, loss: 4.366118
 >> iter 70000, loss: 4.579597
   Number of active neurons: 2
 >> iter 71000, loss: 4.231143
 >> iter 72000, loss: 4.410642
 >> iter 73000, loss: 4.771748
 >> iter 74000, loss: 4.580125
 >> iter 75000, loss: 4.367021
 >> iter 76000, loss: 4.688185
 >> iter 77000, loss: 4.857984
 >> iter 78000, loss: 4.437899
 >> iter 79000, loss: 4.483520
 >> iter 80000, loss: 4.339796
   Number of active neurons: 2
 >> iter 81000, loss: 4.621569
 >> iter 82000, loss: 4.250864
 >> iter 83000, loss: 4.250044
 >> iter 84000, loss: 4.287677
 >> iter 85000, loss: 4.009996
 >> iter 86000, loss: 4.203928
 >> iter 87000, loss: 3.948588
 >> iter 88000, loss: 4.086900
 >> iter 89000, loss: 4.261419
 >> iter 90000, loss: 4.188901
   Number of active neurons: 2
 >> iter 91000, loss: 4.037929
 >> iter 92000, loss: 3.869411
 >> iter 93000, loss: 3.853300
 >> iter 94000, loss: 3.990696
 >> iter 95000, loss: 3.980979
 >> iter 96000, loss: 4.104808
 >> iter 97000, loss: 4.292397
 >> iter 98000, loss: 4.445312
 >> iter 99000, loss: 4.099713
 >> iter 100000, loss: 4.166305
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 20.524758
 >> iter 2000, loss: 18.054278
 >> iter 3000, loss: 17.068461
 >> iter 4000, loss: 16.779365
 >> iter 5000, loss: 16.602169
 >> iter 6000, loss: 16.598189
 >> iter 7000, loss: 16.539947
 >> iter 8000, loss: 16.570969
 >> iter 9000, loss: 16.532182
 >> iter 10000, loss: 16.581924
   Number of active neurons: 0
 >> iter 11000, loss: 16.532516
 >> iter 12000, loss: 16.591974
 >> iter 13000, loss: 16.533415
 >> iter 14000, loss: 16.598199
 >> iter 15000, loss: 16.533569
 >> iter 16000, loss: 16.603667
 >> iter 17000, loss: 16.535595
 >> iter 18000, loss: 16.598710
 >> iter 19000, loss: 16.535932
 >> iter 20000, loss: 15.877938
   Number of active neurons: 1
 >> iter 21000, loss: 11.247206
 >> iter 22000, loss: 8.354290
 >> iter 23000, loss: 7.128127
 >> iter 24000, loss: 6.694699
 >> iter 25000, loss: 6.492046
 >> iter 26000, loss: 6.132611
 >> iter 27000, loss: 5.702015
 >> iter 28000, loss: 5.366770
 >> iter 29000, loss: 5.220783
 >> iter 30000, loss: 5.436622
   Number of active neurons: 2
 >> iter 31000, loss: 5.388549
 >> iter 32000, loss: 5.273456
 >> iter 33000, loss: 5.033568
 >> iter 34000, loss: 4.824350
 >> iter 35000, loss: 5.295844
 >> iter 36000, loss: 4.821373
 >> iter 37000, loss: 4.730513
 >> iter 38000, loss: 4.517079
 >> iter 39000, loss: 4.265160
 >> iter 40000, loss: 4.195020
   Number of active neurons: 2
 >> iter 41000, loss: 3.799267
 >> iter 42000, loss: 4.100520
 >> iter 43000, loss: 3.980576
 >> iter 44000, loss: 4.357320
 >> iter 45000, loss: 4.183563
 >> iter 46000, loss: 4.418860
 >> iter 47000, loss: 3.778616
 >> iter 48000, loss: 3.895533
 >> iter 49000, loss: 4.093810
 >> iter 50000, loss: 4.202797
   Number of active neurons: 2
 >> iter 51000, loss: 3.820655
 >> iter 52000, loss: 4.008038
 >> iter 53000, loss: 4.177036
 >> iter 54000, loss: 4.340404
 >> iter 55000, loss: 4.113833
 >> iter 56000, loss: 4.078320
 >> iter 57000, loss: 3.972158
 >> iter 58000, loss: 4.176623
 >> iter 59000, loss: 3.806376
 >> iter 60000, loss: 3.829226
   Number of active neurons: 2
 >> iter 61000, loss: 3.836318
 >> iter 62000, loss: 3.930064
 >> iter 63000, loss: 3.714998
 >> iter 64000, loss: 3.893259
 >> iter 65000, loss: 3.634037
 >> iter 66000, loss: 3.554160
 >> iter 67000, loss: 3.865005
 >> iter 68000, loss: 3.753251
 >> iter 69000, loss: 3.623564
 >> iter 70000, loss: 3.817786
   Number of active neurons: 2
 >> iter 71000, loss: 4.184339
 >> iter 72000, loss: 3.591043
 >> iter 73000, loss: 3.562091
 >> iter 74000, loss: 3.283412
 >> iter 75000, loss: 3.546036
 >> iter 76000, loss: 3.258677
 >> iter 77000, loss: 3.267411
 >> iter 78000, loss: 2.975329
 >> iter 79000, loss: 3.482867
 >> iter 80000, loss: 3.569606
   Number of active neurons: 2
 >> iter 81000, loss: 3.520546
 >> iter 82000, loss: 3.685157
 >> iter 83000, loss: 3.295504
 >> iter 84000, loss: 3.273854
 >> iter 85000, loss: 3.363795
 >> iter 86000, loss: 3.422982
 >> iter 87000, loss: 3.026625
 >> iter 88000, loss: 3.172610
 >> iter 89000, loss: 3.206257
 >> iter 90000, loss: 3.957067
   Number of active neurons: 2
 >> iter 91000, loss: 3.622832
 >> iter 92000, loss: 3.447202
 >> iter 93000, loss: 3.598606
 >> iter 94000, loss: 3.488932
 >> iter 95000, loss: 3.083001
 >> iter 96000, loss: 2.895397
 >> iter 97000, loss: 3.132051
 >> iter 98000, loss: 3.260085
 >> iter 99000, loss: 3.041564
 >> iter 100000, loss: 3.339115
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

