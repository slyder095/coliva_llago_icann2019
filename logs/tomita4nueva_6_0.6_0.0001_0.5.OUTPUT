 > Problema: tomita4nueva
 > Args:
   - Hidden size: 6
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.387206
 >> iter 2000, loss: 11.695335
 >> iter 3000, loss: 6.642061
 >> iter 4000, loss: 3.223114
 >> iter 5000, loss: 1.961736
 >> iter 6000, loss: 1.269777
 >> iter 7000, loss: 0.889193
 >> iter 8000, loss: 0.838402
 >> iter 9000, loss: 0.567533
 >> iter 10000, loss: 0.515094
   Number of active neurons: 6
 >> iter 11000, loss: 0.383330
 >> iter 12000, loss: 0.414896
 >> iter 13000, loss: 0.355707
 >> iter 14000, loss: 0.366909
 >> iter 15000, loss: 0.619022
 >> iter 16000, loss: 0.465563
 >> iter 17000, loss: 0.447112
 >> iter 18000, loss: 0.467113
 >> iter 19000, loss: 0.388708
 >> iter 20000, loss: 0.372985
   Number of active neurons: 6
 >> iter 21000, loss: 0.547251
 >> iter 22000, loss: 0.444767
 >> iter 23000, loss: 0.432914
 >> iter 24000, loss: 0.611868
 >> iter 25000, loss: 0.448787
 >> iter 26000, loss: 0.453358
 >> iter 27000, loss: 0.575400
 >> iter 28000, loss: 0.540205
 >> iter 29000, loss: 0.571837
 >> iter 30000, loss: 0.656219
   Number of active neurons: 6
 >> iter 31000, loss: 0.473054
 >> iter 32000, loss: 0.421154
 >> iter 33000, loss: 0.593577
 >> iter 34000, loss: 0.509335
 >> iter 35000, loss: 0.553072
 >> iter 36000, loss: 0.370506
 >> iter 37000, loss: 0.486017
 >> iter 38000, loss: 0.507200
 >> iter 39000, loss: 0.612178
 >> iter 40000, loss: 0.463993
   Number of active neurons: 6
 >> iter 41000, loss: 0.646585
 >> iter 42000, loss: 0.468408
 >> iter 43000, loss: 0.378628
 >> iter 44000, loss: 0.668777
 >> iter 45000, loss: 0.509113
 >> iter 46000, loss: 0.604447
 >> iter 47000, loss: 0.504445
 >> iter 48000, loss: 0.456718
 >> iter 49000, loss: 0.449700
 >> iter 50000, loss: 0.411711
   Number of active neurons: 6
 >> iter 51000, loss: 0.551960
 >> iter 52000, loss: 0.434329
 >> iter 53000, loss: 0.506923
 >> iter 54000, loss: 0.307986
 >> iter 55000, loss: 0.480414
 >> iter 56000, loss: 0.431935
 >> iter 57000, loss: 0.293098
 >> iter 58000, loss: 0.426178
 >> iter 59000, loss: 0.380002
 >> iter 60000, loss: 0.550696
   Number of active neurons: 6
 >> iter 61000, loss: 0.463613
 >> iter 62000, loss: 0.319731
 >> iter 63000, loss: 0.337715
 >> iter 64000, loss: 0.615087
 >> iter 65000, loss: 0.548711
 >> iter 66000, loss: 0.536093
 >> iter 67000, loss: 0.373434
 >> iter 68000, loss: 0.338549
 >> iter 69000, loss: 0.362401
 >> iter 70000, loss: 0.341886
   Number of active neurons: 6
 >> iter 71000, loss: 0.348807
 >> iter 72000, loss: 0.245064
 >> iter 73000, loss: 0.212021
 >> iter 74000, loss: 0.502752
 >> iter 75000, loss: 0.478705
 >> iter 76000, loss: 0.305275
 >> iter 77000, loss: 0.555532
 >> iter 78000, loss: 0.500898
 >> iter 79000, loss: 0.432694
 >> iter 80000, loss: 0.426518
   Number of active neurons: 6
 >> iter 81000, loss: 0.502199
 >> iter 82000, loss: 0.403317
 >> iter 83000, loss: 0.337497
 >> iter 84000, loss: 0.356790
 >> iter 85000, loss: 0.434380
 >> iter 86000, loss: 0.441502
 >> iter 87000, loss: 0.356833
 >> iter 88000, loss: 0.623839
 >> iter 89000, loss: 0.453367
 >> iter 90000, loss: 0.394201
   Number of active neurons: 6
 >> iter 91000, loss: 0.375470
 >> iter 92000, loss: 0.262379
 >> iter 93000, loss: 0.340810
 >> iter 94000, loss: 0.273643
 >> iter 95000, loss: 0.388276
 >> iter 96000, loss: 0.290671
 >> iter 97000, loss: 0.291185
 >> iter 98000, loss: 0.335011
 >> iter 99000, loss: 0.199046
 >> iter 100000, loss: 0.215576
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.051510
 >> iter 2000, loss: 9.925860
 >> iter 3000, loss: 4.946085
 >> iter 4000, loss: 2.624203
 >> iter 5000, loss: 1.328181
 >> iter 6000, loss: 0.840059
 >> iter 7000, loss: 0.951926
 >> iter 8000, loss: 0.621987
 >> iter 9000, loss: 0.483578
 >> iter 10000, loss: 0.543586
   Number of active neurons: 6
 >> iter 11000, loss: 0.681494
 >> iter 12000, loss: 0.631959
 >> iter 13000, loss: 0.544265
 >> iter 14000, loss: 0.588660
 >> iter 15000, loss: 0.470008
 >> iter 16000, loss: 0.411922
 >> iter 17000, loss: 0.583189
 >> iter 18000, loss: 0.643792
 >> iter 19000, loss: 0.409557
 >> iter 20000, loss: 0.545151
   Number of active neurons: 5
 >> iter 21000, loss: 0.630253
 >> iter 22000, loss: 0.631568
 >> iter 23000, loss: 0.437757
 >> iter 24000, loss: 0.489054
 >> iter 25000, loss: 0.442416
 >> iter 26000, loss: 0.490788
 >> iter 27000, loss: 0.412638
 >> iter 28000, loss: 0.280510
 >> iter 29000, loss: 0.341292
 >> iter 30000, loss: 0.582779
   Number of active neurons: 5
 >> iter 31000, loss: 0.463576
 >> iter 32000, loss: 0.313431
 >> iter 33000, loss: 0.502866
 >> iter 34000, loss: 0.391853
 >> iter 35000, loss: 0.541220
 >> iter 36000, loss: 0.475081
 >> iter 37000, loss: 0.475237
 >> iter 38000, loss: 0.368581
 >> iter 39000, loss: 0.485028
 >> iter 40000, loss: 0.475442
   Number of active neurons: 5
 >> iter 41000, loss: 0.350169
 >> iter 42000, loss: 0.548295
 >> iter 43000, loss: 0.346368
 >> iter 44000, loss: 0.482367
 >> iter 45000, loss: 0.479183
 >> iter 46000, loss: 0.522490
 >> iter 47000, loss: 0.465964
 >> iter 48000, loss: 0.675342
 >> iter 49000, loss: 0.467783
 >> iter 50000, loss: 0.727540
   Number of active neurons: 5
 >> iter 51000, loss: 0.449485
 >> iter 52000, loss: 0.701747
 >> iter 53000, loss: 0.592278
 >> iter 54000, loss: 0.343321
 >> iter 55000, loss: 0.443617
 >> iter 56000, loss: 0.567899
 >> iter 57000, loss: 0.548727
 >> iter 58000, loss: 0.562578
 >> iter 59000, loss: 0.529071
 >> iter 60000, loss: 0.393237
   Number of active neurons: 5
 >> iter 61000, loss: 0.383294
 >> iter 62000, loss: 0.375868
 >> iter 63000, loss: 0.347679
 >> iter 64000, loss: 0.473534
 >> iter 65000, loss: 0.343882
 >> iter 66000, loss: 0.516411
 >> iter 67000, loss: 0.573115
 >> iter 68000, loss: 0.652333
 >> iter 69000, loss: 0.526053
 >> iter 70000, loss: 0.469591
   Number of active neurons: 5
 >> iter 71000, loss: 0.384331
 >> iter 72000, loss: 0.411788
 >> iter 73000, loss: 0.357786
 >> iter 74000, loss: 0.425555
 >> iter 75000, loss: 0.479025
 >> iter 76000, loss: 0.322970
 >> iter 77000, loss: 0.327248
 >> iter 78000, loss: 0.450680
 >> iter 79000, loss: 0.579992
 >> iter 80000, loss: 0.553871
   Number of active neurons: 5
 >> iter 81000, loss: 0.666651
 >> iter 82000, loss: 0.345690
 >> iter 83000, loss: 0.365857
 >> iter 84000, loss: 0.568298
 >> iter 85000, loss: 0.463753
 >> iter 86000, loss: 0.406403
 >> iter 87000, loss: 0.559692
 >> iter 88000, loss: 0.425325
 >> iter 89000, loss: 0.554300
 >> iter 90000, loss: 0.668352
   Number of active neurons: 5
 >> iter 91000, loss: 0.626940
 >> iter 92000, loss: 0.424463
 >> iter 93000, loss: 0.427836
 >> iter 94000, loss: 0.470890
 >> iter 95000, loss: 0.298641
 >> iter 96000, loss: 0.399646
 >> iter 97000, loss: 0.362201
 >> iter 98000, loss: 0.473743
 >> iter 99000, loss: 0.380265
 >> iter 100000, loss: 0.194071
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.046402
 >> iter 2000, loss: 11.904947
 >> iter 3000, loss: 6.864673
 >> iter 4000, loss: 3.376370
 >> iter 5000, loss: 1.491832
 >> iter 6000, loss: 0.799816
 >> iter 7000, loss: 0.585977
 >> iter 8000, loss: 0.361396
 >> iter 9000, loss: 0.330851
 >> iter 10000, loss: 0.188840
   Number of active neurons: 4
 >> iter 11000, loss: 0.207812
 >> iter 12000, loss: 0.312081
 >> iter 13000, loss: 0.293781
 >> iter 14000, loss: 0.378828
 >> iter 15000, loss: 0.488034
 >> iter 16000, loss: 0.264942
 >> iter 17000, loss: 0.248585
 >> iter 18000, loss: 0.231893
 >> iter 19000, loss: 0.480717
 >> iter 20000, loss: 0.363190
   Number of active neurons: 3
 >> iter 21000, loss: 0.305503
 >> iter 22000, loss: 0.166980
 >> iter 23000, loss: 0.306410
 >> iter 24000, loss: 0.331567
 >> iter 25000, loss: 0.298476
 >> iter 26000, loss: 0.207204
 >> iter 27000, loss: 0.194382
 >> iter 28000, loss: 0.218221
 >> iter 29000, loss: 0.237301
 >> iter 30000, loss: 0.251672
   Number of active neurons: 3
 >> iter 31000, loss: 0.261059
 >> iter 32000, loss: 0.222433
 >> iter 33000, loss: 0.256360
 >> iter 34000, loss: 0.379118
 >> iter 35000, loss: 0.287421
 >> iter 36000, loss: 0.208260
 >> iter 37000, loss: 0.192305
 >> iter 38000, loss: 0.249297
 >> iter 39000, loss: 0.279626
 >> iter 40000, loss: 0.411060
   Number of active neurons: 3
 >> iter 41000, loss: 0.190355
 >> iter 42000, loss: 0.212099
 >> iter 43000, loss: 0.200517
 >> iter 44000, loss: 0.235945
 >> iter 45000, loss: 0.176737
 >> iter 46000, loss: 0.341444
 >> iter 47000, loss: 0.198515
 >> iter 48000, loss: 0.173685
 >> iter 49000, loss: 0.252034
 >> iter 50000, loss: 0.345239
   Number of active neurons: 3
 >> iter 51000, loss: 0.375159
 >> iter 52000, loss: 0.220557
 >> iter 53000, loss: 0.155555
 >> iter 54000, loss: 0.231245
 >> iter 55000, loss: 0.270984
 >> iter 56000, loss: 0.269299
 >> iter 57000, loss: 0.209003
 >> iter 58000, loss: 0.183855
 >> iter 59000, loss: 0.116105
 >> iter 60000, loss: 0.081760
   Number of active neurons: 3
 >> iter 61000, loss: 0.208468
 >> iter 62000, loss: 0.256270
 >> iter 63000, loss: 0.334399
 >> iter 64000, loss: 0.199455
 >> iter 65000, loss: 0.167946
 >> iter 66000, loss: 0.225154
 >> iter 67000, loss: 0.165202
 >> iter 68000, loss: 0.164077
 >> iter 69000, loss: 0.209321
 >> iter 70000, loss: 0.134503
   Number of active neurons: 3
 >> iter 71000, loss: 0.165413
 >> iter 72000, loss: 0.155738
 >> iter 73000, loss: 0.151589
 >> iter 74000, loss: 0.197816
 >> iter 75000, loss: 0.462284
 >> iter 76000, loss: 0.281603
 >> iter 77000, loss: 0.225691
 >> iter 78000, loss: 0.142410
 >> iter 79000, loss: 0.220990
 >> iter 80000, loss: 0.248675
   Number of active neurons: 3
 >> iter 81000, loss: 0.215768
 >> iter 82000, loss: 0.267668
 >> iter 83000, loss: 0.245823
 >> iter 84000, loss: 0.156162
 >> iter 85000, loss: 0.241499
 >> iter 86000, loss: 0.237234
 >> iter 87000, loss: 0.198322
 >> iter 88000, loss: 0.143854
 >> iter 89000, loss: 0.153300
 >> iter 90000, loss: 0.298389
   Number of active neurons: 3
 >> iter 91000, loss: 0.157841
 >> iter 92000, loss: 0.426406
 >> iter 93000, loss: 0.269305
 >> iter 94000, loss: 0.349865
 >> iter 95000, loss: 0.316834
 >> iter 96000, loss: 0.327132
 >> iter 97000, loss: 0.269680
 >> iter 98000, loss: 0.218917
 >> iter 99000, loss: 0.163730
 >> iter 100000, loss: 0.150592
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.344383
 >> iter 2000, loss: 10.962553
 >> iter 3000, loss: 5.286201
 >> iter 4000, loss: 2.941686
 >> iter 5000, loss: 1.643118
 >> iter 6000, loss: 1.115038
 >> iter 7000, loss: 0.712273
 >> iter 8000, loss: 0.672274
 >> iter 9000, loss: 0.636291
 >> iter 10000, loss: 0.380946
   Number of active neurons: 6
 >> iter 11000, loss: 0.461711
 >> iter 12000, loss: 0.501827
 >> iter 13000, loss: 0.540831
 >> iter 14000, loss: 0.445476
 >> iter 15000, loss: 0.450592
 >> iter 16000, loss: 0.389772
 >> iter 17000, loss: 0.449758
 >> iter 18000, loss: 0.425551
 >> iter 19000, loss: 0.357147
 >> iter 20000, loss: 0.367973
   Number of active neurons: 6
 >> iter 21000, loss: 0.560544
 >> iter 22000, loss: 0.395373
 >> iter 23000, loss: 0.329855
 >> iter 24000, loss: 0.561104
 >> iter 25000, loss: 0.614300
 >> iter 26000, loss: 0.570920
 >> iter 27000, loss: 0.815433
 >> iter 28000, loss: 0.556335
 >> iter 29000, loss: 0.479508
 >> iter 30000, loss: 0.559656
   Number of active neurons: 5
 >> iter 31000, loss: 0.553493
 >> iter 32000, loss: 0.586228
 >> iter 33000, loss: 0.344531
 >> iter 34000, loss: 0.408954
 >> iter 35000, loss: 0.409309
 >> iter 36000, loss: 0.540159
 >> iter 37000, loss: 0.513435
 >> iter 38000, loss: 0.562318
 >> iter 39000, loss: 0.505118
 >> iter 40000, loss: 0.655098
   Number of active neurons: 4
 >> iter 41000, loss: 0.678129
 >> iter 42000, loss: 0.422829
 >> iter 43000, loss: 0.578735
 >> iter 44000, loss: 0.503014
 >> iter 45000, loss: 0.409134
 >> iter 46000, loss: 0.318827
 >> iter 47000, loss: 0.428458
 >> iter 48000, loss: 0.450784
 >> iter 49000, loss: 0.427977
 >> iter 50000, loss: 0.709976
   Number of active neurons: 6
 >> iter 51000, loss: 0.496684
 >> iter 52000, loss: 0.565555
 >> iter 53000, loss: 0.681691
 >> iter 54000, loss: 0.573214
 >> iter 55000, loss: 0.476255
 >> iter 56000, loss: 0.636815
 >> iter 57000, loss: 0.362418
 >> iter 58000, loss: 0.401643
 >> iter 59000, loss: 0.426955
 >> iter 60000, loss: 0.423320
   Number of active neurons: 6
 >> iter 61000, loss: 0.689124
 >> iter 62000, loss: 0.628817
 >> iter 63000, loss: 0.756391
 >> iter 64000, loss: 0.674432
 >> iter 65000, loss: 0.478815
 >> iter 66000, loss: 0.358070
 >> iter 67000, loss: 0.423174
 >> iter 68000, loss: 0.318601
 >> iter 69000, loss: 0.251383
 >> iter 70000, loss: 0.520092
   Number of active neurons: 5
 >> iter 71000, loss: 0.425753
 >> iter 72000, loss: 0.267607
 >> iter 73000, loss: 0.469358
 >> iter 74000, loss: 0.678170
 >> iter 75000, loss: 0.431171
 >> iter 76000, loss: 0.482238
 >> iter 77000, loss: 0.433705
 >> iter 78000, loss: 0.354319
 >> iter 79000, loss: 0.303871
 >> iter 80000, loss: 0.401042
   Number of active neurons: 6
 >> iter 81000, loss: 0.460053
 >> iter 82000, loss: 0.292765
 >> iter 83000, loss: 0.405736
 >> iter 84000, loss: 0.523031
 >> iter 85000, loss: 0.379303
 >> iter 86000, loss: 0.293551
 >> iter 87000, loss: 0.482550
 >> iter 88000, loss: 0.389286
 >> iter 89000, loss: 0.345672
 >> iter 90000, loss: 0.318562
   Number of active neurons: 6
 >> iter 91000, loss: 0.446918
 >> iter 92000, loss: 0.520039
 >> iter 93000, loss: 0.319778
 >> iter 94000, loss: 0.450161
 >> iter 95000, loss: 0.295628
 >> iter 96000, loss: 0.452865
 >> iter 97000, loss: 0.437453
 >> iter 98000, loss: 0.352848
 >> iter 99000, loss: 0.193262
 >> iter 100000, loss: 0.193298
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.741655
 >> iter 2000, loss: 9.791207
 >> iter 3000, loss: 4.940208
 >> iter 4000, loss: 2.697182
 >> iter 5000, loss: 1.559872
 >> iter 6000, loss: 0.904479
 >> iter 7000, loss: 0.819396
 >> iter 8000, loss: 0.577111
 >> iter 9000, loss: 0.402100
 >> iter 10000, loss: 0.576804
   Number of active neurons: 4
 >> iter 11000, loss: 0.450762
 >> iter 12000, loss: 0.386701
 >> iter 13000, loss: 0.350858
 >> iter 14000, loss: 0.428057
 >> iter 15000, loss: 0.363482
 >> iter 16000, loss: 0.418736
 >> iter 17000, loss: 0.503969
 >> iter 18000, loss: 0.354593
 >> iter 19000, loss: 0.245422
 >> iter 20000, loss: 0.207136
   Number of active neurons: 4
 >> iter 21000, loss: 0.380827
 >> iter 22000, loss: 0.239978
 >> iter 23000, loss: 0.415835
 >> iter 24000, loss: 0.258470
 >> iter 25000, loss: 0.300350
 >> iter 26000, loss: 0.379129
 >> iter 27000, loss: 0.335586
 >> iter 28000, loss: 0.485967
 >> iter 29000, loss: 0.612610
 >> iter 30000, loss: 0.486013
   Number of active neurons: 3
 >> iter 31000, loss: 0.402158
 >> iter 32000, loss: 0.318511
 >> iter 33000, loss: 0.455230
 >> iter 34000, loss: 0.228781
 >> iter 35000, loss: 0.277802
 >> iter 36000, loss: 0.249271
 >> iter 37000, loss: 0.287796
 >> iter 38000, loss: 0.412739
 >> iter 39000, loss: 0.308489
 >> iter 40000, loss: 0.328992
   Number of active neurons: 3
 >> iter 41000, loss: 0.211768
 >> iter 42000, loss: 0.371029
 >> iter 43000, loss: 0.261630
 >> iter 44000, loss: 0.440922
 >> iter 45000, loss: 0.429559
 >> iter 46000, loss: 0.273978
 >> iter 47000, loss: 0.400709
 >> iter 48000, loss: 0.349266
 >> iter 49000, loss: 0.437983
 >> iter 50000, loss: 0.283897
   Number of active neurons: 3
 >> iter 51000, loss: 0.280259
 >> iter 52000, loss: 0.307531
 >> iter 53000, loss: 0.222142
 >> iter 54000, loss: 0.319347
 >> iter 55000, loss: 0.252625
 >> iter 56000, loss: 0.352241
 >> iter 57000, loss: 0.311870
 >> iter 58000, loss: 0.292504
 >> iter 59000, loss: 0.333596
 >> iter 60000, loss: 0.244241
   Number of active neurons: 3
 >> iter 61000, loss: 0.256378
 >> iter 62000, loss: 0.203202
 >> iter 63000, loss: 0.179637
 >> iter 64000, loss: 0.501182
 >> iter 65000, loss: 0.430939
 >> iter 66000, loss: 0.367116
 >> iter 67000, loss: 0.203723
 >> iter 68000, loss: 0.399020
 >> iter 69000, loss: 0.439529
 >> iter 70000, loss: 0.529727
   Number of active neurons: 3
 >> iter 71000, loss: 0.417262
 >> iter 72000, loss: 0.312686
 >> iter 73000, loss: 0.354383
 >> iter 74000, loss: 0.364777
 >> iter 75000, loss: 0.217078
 >> iter 76000, loss: 0.360342
 >> iter 77000, loss: 0.284246
 >> iter 78000, loss: 0.340067
 >> iter 79000, loss: 0.327157
 >> iter 80000, loss: 0.324085
   Number of active neurons: 3
 >> iter 81000, loss: 0.392152
 >> iter 82000, loss: 0.425510
 >> iter 83000, loss: 0.299119
 >> iter 84000, loss: 0.539171
 >> iter 85000, loss: 0.310605
 >> iter 86000, loss: 0.280606
 >> iter 87000, loss: 0.319340
 >> iter 88000, loss: 0.275897
 >> iter 89000, loss: 0.256269
 >> iter 90000, loss: 0.289929
   Number of active neurons: 3
 >> iter 91000, loss: 0.370930
 >> iter 92000, loss: 0.375075
 >> iter 93000, loss: 0.300532
 >> iter 94000, loss: 0.311497
 >> iter 95000, loss: 0.243799
 >> iter 96000, loss: 0.317571
 >> iter 97000, loss: 0.434763
 >> iter 98000, loss: 0.401325
 >> iter 99000, loss: 0.343360
 >> iter 100000, loss: 0.333623
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.116423
 >> iter 2000, loss: 10.611523
 >> iter 3000, loss: 5.081718
 >> iter 4000, loss: 2.395322
 >> iter 5000, loss: 1.343764
 >> iter 6000, loss: 0.663944
 >> iter 7000, loss: 0.462619
 >> iter 8000, loss: 0.336188
 >> iter 9000, loss: 0.345160
 >> iter 10000, loss: 0.542555
   Number of active neurons: 6
 >> iter 11000, loss: 0.336368
 >> iter 12000, loss: 0.368405
 >> iter 13000, loss: 0.429325
 >> iter 14000, loss: 0.500304
 >> iter 15000, loss: 0.614506
 >> iter 16000, loss: 0.362331
 >> iter 17000, loss: 0.237804
 >> iter 18000, loss: 0.155807
 >> iter 19000, loss: 0.183986
 >> iter 20000, loss: 0.102496
   Number of active neurons: 5
 >> iter 21000, loss: 0.083933
 >> iter 22000, loss: 0.108638
 >> iter 23000, loss: 0.301400
 >> iter 24000, loss: 0.207004
 >> iter 25000, loss: 0.234815
 >> iter 26000, loss: 0.361648
 >> iter 27000, loss: 0.303862
 >> iter 28000, loss: 0.261729
 >> iter 29000, loss: 0.298412
 >> iter 30000, loss: 0.339678
   Number of active neurons: 5
 >> iter 31000, loss: 0.242538
 >> iter 32000, loss: 0.392552
 >> iter 33000, loss: 0.276895
 >> iter 34000, loss: 0.210252
 >> iter 35000, loss: 0.289670
 >> iter 36000, loss: 0.267859
 >> iter 37000, loss: 0.176512
 >> iter 38000, loss: 0.158930
 >> iter 39000, loss: 0.394569
 >> iter 40000, loss: 0.219482
   Number of active neurons: 4
 >> iter 41000, loss: 0.313562
 >> iter 42000, loss: 0.243964
 >> iter 43000, loss: 0.267127
 >> iter 44000, loss: 0.168535
 >> iter 45000, loss: 0.131833
 >> iter 46000, loss: 0.170710
 >> iter 47000, loss: 0.278779
 >> iter 48000, loss: 0.227708
 >> iter 49000, loss: 0.202268
 >> iter 50000, loss: 0.234644
   Number of active neurons: 4
 >> iter 51000, loss: 0.179221
 >> iter 52000, loss: 0.363277
 >> iter 53000, loss: 0.318037
 >> iter 54000, loss: 0.317798
 >> iter 55000, loss: 0.447520
 >> iter 56000, loss: 0.355689
 >> iter 57000, loss: 0.212844
 >> iter 58000, loss: 0.384286
 >> iter 59000, loss: 0.240904
 >> iter 60000, loss: 0.190929
   Number of active neurons: 4
 >> iter 61000, loss: 0.217436
 >> iter 62000, loss: 0.312089
 >> iter 63000, loss: 0.287504
 >> iter 64000, loss: 0.175420
 >> iter 65000, loss: 0.145528
 >> iter 66000, loss: 0.365269
 >> iter 67000, loss: 0.293618
 >> iter 68000, loss: 0.299604
 >> iter 69000, loss: 0.282440
 >> iter 70000, loss: 0.229185
   Number of active neurons: 4
 >> iter 71000, loss: 0.149423
 >> iter 72000, loss: 0.309135
 >> iter 73000, loss: 0.178803
 >> iter 74000, loss: 0.257345
 >> iter 75000, loss: 0.264436
 >> iter 76000, loss: 0.346214
 >> iter 77000, loss: 0.293668
 >> iter 78000, loss: 0.224258
 >> iter 79000, loss: 0.235897
 >> iter 80000, loss: 0.158877
   Number of active neurons: 4
 >> iter 81000, loss: 0.193469
 >> iter 82000, loss: 0.342027
 >> iter 83000, loss: 0.385730
 >> iter 84000, loss: 0.222300
 >> iter 85000, loss: 0.364239
 >> iter 86000, loss: 0.309656
 >> iter 87000, loss: 0.322350
 >> iter 88000, loss: 0.168257
 >> iter 89000, loss: 0.211652
 >> iter 90000, loss: 0.171838
   Number of active neurons: 3
 >> iter 91000, loss: 0.144906
 >> iter 92000, loss: 0.147460
 >> iter 93000, loss: 0.139144
 >> iter 94000, loss: 0.220361
 >> iter 95000, loss: 0.260121
 >> iter 96000, loss: 0.188837
 >> iter 97000, loss: 0.214809
 >> iter 98000, loss: 0.278306
 >> iter 99000, loss: 0.246536
 >> iter 100000, loss: 0.391736
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.437534
 >> iter 2000, loss: 8.482283
 >> iter 3000, loss: 4.192832
 >> iter 4000, loss: 2.077452
 >> iter 5000, loss: 1.455618
 >> iter 6000, loss: 0.781327
 >> iter 7000, loss: 0.511439
 >> iter 8000, loss: 0.838249
 >> iter 9000, loss: 0.611407
 >> iter 10000, loss: 0.651441
   Number of active neurons: 5
 >> iter 11000, loss: 0.700904
 >> iter 12000, loss: 0.364981
 >> iter 13000, loss: 0.485816
 >> iter 14000, loss: 0.328315
 >> iter 15000, loss: 0.393660
 >> iter 16000, loss: 0.320862
 >> iter 17000, loss: 0.339931
 >> iter 18000, loss: 0.579514
 >> iter 19000, loss: 0.653967
 >> iter 20000, loss: 1.056664
   Number of active neurons: 4
 >> iter 21000, loss: 0.718471
 >> iter 22000, loss: 0.501503
 >> iter 23000, loss: 0.453867
 >> iter 24000, loss: 0.429829
 >> iter 25000, loss: 0.558748
 >> iter 26000, loss: 0.349143
 >> iter 27000, loss: 0.358966
 >> iter 28000, loss: 0.371072
 >> iter 29000, loss: 0.375171
 >> iter 30000, loss: 0.548041
   Number of active neurons: 4
 >> iter 31000, loss: 0.381795
 >> iter 32000, loss: 0.332733
 >> iter 33000, loss: 0.626880
 >> iter 34000, loss: 0.545940
 >> iter 35000, loss: 0.564155
 >> iter 36000, loss: 0.480220
 >> iter 37000, loss: 0.329345
 >> iter 38000, loss: 0.532726
 >> iter 39000, loss: 0.437332
 >> iter 40000, loss: 0.359098
   Number of active neurons: 4
 >> iter 41000, loss: 0.302663
 >> iter 42000, loss: 0.444535
 >> iter 43000, loss: 0.479272
 >> iter 44000, loss: 0.593189
 >> iter 45000, loss: 0.490621
 >> iter 46000, loss: 0.509781
 >> iter 47000, loss: 0.382950
 >> iter 48000, loss: 0.335508
 >> iter 49000, loss: 0.422421
 >> iter 50000, loss: 0.482879
   Number of active neurons: 4
 >> iter 51000, loss: 0.454073
 >> iter 52000, loss: 0.498302
 >> iter 53000, loss: 0.596711
 >> iter 54000, loss: 0.352388
 >> iter 55000, loss: 0.365609
 >> iter 56000, loss: 0.289162
 >> iter 57000, loss: 0.343765
 >> iter 58000, loss: 0.383240
 >> iter 59000, loss: 0.355205
 >> iter 60000, loss: 0.352828
   Number of active neurons: 4
 >> iter 61000, loss: 0.369308
 >> iter 62000, loss: 0.376109
 >> iter 63000, loss: 0.313317
 >> iter 64000, loss: 0.251440
 >> iter 65000, loss: 0.425065
 >> iter 66000, loss: 0.484722
 >> iter 67000, loss: 0.488437
 >> iter 68000, loss: 0.896201
 >> iter 69000, loss: 0.764725
 >> iter 70000, loss: 0.834319
   Number of active neurons: 4
 >> iter 71000, loss: 0.412784
 >> iter 72000, loss: 0.487529
 >> iter 73000, loss: 0.671112
 >> iter 74000, loss: 0.645652
 >> iter 75000, loss: 0.490704
 >> iter 76000, loss: 0.364772
 >> iter 77000, loss: 0.430226
 >> iter 78000, loss: 0.261949
 >> iter 79000, loss: 0.172383
 >> iter 80000, loss: 0.457341
   Number of active neurons: 4
 >> iter 81000, loss: 0.696149
 >> iter 82000, loss: 0.444634
 >> iter 83000, loss: 0.284838
 >> iter 84000, loss: 0.295096
 >> iter 85000, loss: 0.403175
 >> iter 86000, loss: 0.452464
 >> iter 87000, loss: 0.401627
 >> iter 88000, loss: 0.326555
 >> iter 89000, loss: 0.275686
 >> iter 90000, loss: 0.230571
   Number of active neurons: 4
 >> iter 91000, loss: 0.481680
 >> iter 92000, loss: 0.464041
 >> iter 93000, loss: 0.512325
 >> iter 94000, loss: 0.393225
 >> iter 95000, loss: 0.258327
 >> iter 96000, loss: 0.294479
 >> iter 97000, loss: 0.552751
 >> iter 98000, loss: 0.380176
 >> iter 99000, loss: 0.389620
 >> iter 100000, loss: 0.663840
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.694265
 >> iter 2000, loss: 8.477785
 >> iter 3000, loss: 3.567454
 >> iter 4000, loss: 1.703788
 >> iter 5000, loss: 0.922206
 >> iter 6000, loss: 0.489055
 >> iter 7000, loss: 0.349889
 >> iter 8000, loss: 0.207444
 >> iter 9000, loss: 0.255953
 >> iter 10000, loss: 0.388658
   Number of active neurons: 3
 >> iter 11000, loss: 0.229063
 >> iter 12000, loss: 0.294371
 >> iter 13000, loss: 0.211985
 >> iter 14000, loss: 0.261927
 >> iter 15000, loss: 0.161538
 >> iter 16000, loss: 0.239726
 >> iter 17000, loss: 0.490474
 >> iter 18000, loss: 0.521380
 >> iter 19000, loss: 0.376405
 >> iter 20000, loss: 0.352641
   Number of active neurons: 3
 >> iter 21000, loss: 0.242948
 >> iter 22000, loss: 0.229227
 >> iter 23000, loss: 0.305735
 >> iter 24000, loss: 0.225244
 >> iter 25000, loss: 0.407513
 >> iter 26000, loss: 0.318809
 >> iter 27000, loss: 0.415044
 >> iter 28000, loss: 0.324712
 >> iter 29000, loss: 0.494319
 >> iter 30000, loss: 0.401407
   Number of active neurons: 3
 >> iter 31000, loss: 0.275510
 >> iter 32000, loss: 0.285741
 >> iter 33000, loss: 0.296297
 >> iter 34000, loss: 0.199854
 >> iter 35000, loss: 0.212802
 >> iter 36000, loss: 0.255304
 >> iter 37000, loss: 0.365598
 >> iter 38000, loss: 0.200926
 >> iter 39000, loss: 0.318290
 >> iter 40000, loss: 0.205499
   Number of active neurons: 3
 >> iter 41000, loss: 0.265019
 >> iter 42000, loss: 0.226034
 >> iter 43000, loss: 0.208962
 >> iter 44000, loss: 0.206296
 >> iter 45000, loss: 0.316465
 >> iter 46000, loss: 0.351666
 >> iter 47000, loss: 0.239136
 >> iter 48000, loss: 0.153924
 >> iter 49000, loss: 0.166476
 >> iter 50000, loss: 0.223343
   Number of active neurons: 3
 >> iter 51000, loss: 0.227920
 >> iter 52000, loss: 0.225443
 >> iter 53000, loss: 0.216384
 >> iter 54000, loss: 0.182731
 >> iter 55000, loss: 0.500219
 >> iter 56000, loss: 0.258582
 >> iter 57000, loss: 0.341233
 >> iter 58000, loss: 0.372272
 >> iter 59000, loss: 0.390520
 >> iter 60000, loss: 0.499448
   Number of active neurons: 3
 >> iter 61000, loss: 0.361517
 >> iter 62000, loss: 0.317054
 >> iter 63000, loss: 0.332190
 >> iter 64000, loss: 0.287462
 >> iter 65000, loss: 0.238446
 >> iter 66000, loss: 0.145400
 >> iter 67000, loss: 0.177580
 >> iter 68000, loss: 0.278915
 >> iter 69000, loss: 0.341767
 >> iter 70000, loss: 0.320843
   Number of active neurons: 3
 >> iter 71000, loss: 0.234187
 >> iter 72000, loss: 0.253840
 >> iter 73000, loss: 0.157092
 >> iter 74000, loss: 0.259938
 >> iter 75000, loss: 0.285988
 >> iter 76000, loss: 0.396553
 >> iter 77000, loss: 0.227660
 >> iter 78000, loss: 0.329313
 >> iter 79000, loss: 0.477387
 >> iter 80000, loss: 0.417086
   Number of active neurons: 3
 >> iter 81000, loss: 0.263507
 >> iter 82000, loss: 0.300776
 >> iter 83000, loss: 0.320821
 >> iter 84000, loss: 0.207852
 >> iter 85000, loss: 0.180494
 >> iter 86000, loss: 0.109785
 >> iter 87000, loss: 0.238381
 >> iter 88000, loss: 0.272783
 >> iter 89000, loss: 0.511179
 >> iter 90000, loss: 0.360790
   Number of active neurons: 3
 >> iter 91000, loss: 0.324875
 >> iter 92000, loss: 0.259669
 >> iter 93000, loss: 0.283564
 >> iter 94000, loss: 0.186032
 >> iter 95000, loss: 0.154701
 >> iter 96000, loss: 0.164595
 >> iter 97000, loss: 0.207945
 >> iter 98000, loss: 0.283779
 >> iter 99000, loss: 0.173586
 >> iter 100000, loss: 0.164939
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.953541
 >> iter 2000, loss: 9.426848
 >> iter 3000, loss: 4.474122
 >> iter 4000, loss: 1.996747
 >> iter 5000, loss: 1.113948
 >> iter 6000, loss: 0.761650
 >> iter 7000, loss: 0.696298
 >> iter 8000, loss: 0.508525
 >> iter 9000, loss: 0.525451
 >> iter 10000, loss: 0.516185
   Number of active neurons: 6
 >> iter 11000, loss: 0.617897
 >> iter 12000, loss: 0.561478
 >> iter 13000, loss: 0.439085
 >> iter 14000, loss: 0.610594
 >> iter 15000, loss: 0.610570
 >> iter 16000, loss: 0.414123
 >> iter 17000, loss: 0.249140
 >> iter 18000, loss: 0.488799
 >> iter 19000, loss: 0.276863
 >> iter 20000, loss: 0.386695
   Number of active neurons: 6
 >> iter 21000, loss: 0.468222
 >> iter 22000, loss: 0.554150
 >> iter 23000, loss: 0.418334
 >> iter 24000, loss: 0.464994
 >> iter 25000, loss: 0.560449
 >> iter 26000, loss: 0.541195
 >> iter 27000, loss: 0.549758
 >> iter 28000, loss: 0.677764
 >> iter 29000, loss: 0.620946
 >> iter 30000, loss: 0.478041
   Number of active neurons: 5
 >> iter 31000, loss: 0.426966
 >> iter 32000, loss: 0.604508
 >> iter 33000, loss: 0.594532
 >> iter 34000, loss: 0.359018
 >> iter 35000, loss: 0.319097
 >> iter 36000, loss: 0.491123
 >> iter 37000, loss: 0.320381
 >> iter 38000, loss: 0.297638
 >> iter 39000, loss: 0.430414
 >> iter 40000, loss: 0.600333
   Number of active neurons: 4
 >> iter 41000, loss: 0.607376
 >> iter 42000, loss: 0.516137
 >> iter 43000, loss: 0.386532
 >> iter 44000, loss: 0.416257
 >> iter 45000, loss: 0.470753
 >> iter 46000, loss: 0.418712
 >> iter 47000, loss: 0.330908
 >> iter 48000, loss: 0.636951
 >> iter 49000, loss: 0.468548
 >> iter 50000, loss: 0.463974
   Number of active neurons: 4
 >> iter 51000, loss: 0.439208
 >> iter 52000, loss: 0.381556
 >> iter 53000, loss: 0.840713
 >> iter 54000, loss: 0.659232
 >> iter 55000, loss: 0.509122
 >> iter 56000, loss: 0.376830
 >> iter 57000, loss: 0.356445
 >> iter 58000, loss: 0.469255
 >> iter 59000, loss: 0.471402
 >> iter 60000, loss: 0.598326
   Number of active neurons: 4
 >> iter 61000, loss: 0.463485
 >> iter 62000, loss: 0.397699
 >> iter 63000, loss: 0.415777
 >> iter 64000, loss: 0.461942
 >> iter 65000, loss: 0.469232
 >> iter 66000, loss: 0.438095
 >> iter 67000, loss: 0.381974
 >> iter 68000, loss: 0.415813
 >> iter 69000, loss: 0.687701
 >> iter 70000, loss: 0.500015
   Number of active neurons: 4
 >> iter 71000, loss: 0.440009
 >> iter 72000, loss: 0.414080
 >> iter 73000, loss: 0.319596
 >> iter 74000, loss: 0.206773
 >> iter 75000, loss: 0.662950
 >> iter 76000, loss: 0.531422
 >> iter 77000, loss: 0.592341
 >> iter 78000, loss: 0.668991
 >> iter 79000, loss: 0.492465
 >> iter 80000, loss: 0.549108
   Number of active neurons: 4
 >> iter 81000, loss: 0.441385
 >> iter 82000, loss: 0.499735
 >> iter 83000, loss: 0.573039
 >> iter 84000, loss: 0.495289
 >> iter 85000, loss: 0.446471
 >> iter 86000, loss: 0.527288
 >> iter 87000, loss: 0.369368
 >> iter 88000, loss: 0.395420
 >> iter 89000, loss: 0.306613
 >> iter 90000, loss: 0.566609
   Number of active neurons: 4
 >> iter 91000, loss: 0.595594
 >> iter 92000, loss: 0.485189
 >> iter 93000, loss: 0.421759
 >> iter 94000, loss: 0.345593
 >> iter 95000, loss: 0.369372
 >> iter 96000, loss: 0.318461
 >> iter 97000, loss: 0.543438
 >> iter 98000, loss: 0.540080
 >> iter 99000, loss: 0.594436
 >> iter 100000, loss: 0.580043
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 20.524750
 >> iter 2000, loss: 17.213450
 >> iter 3000, loss: 11.340947
 >> iter 4000, loss: 5.852859
 >> iter 5000, loss: 2.902313
 >> iter 6000, loss: 1.516905
 >> iter 7000, loss: 0.781713
 >> iter 8000, loss: 0.693833
 >> iter 9000, loss: 0.413938
 >> iter 10000, loss: 0.425762
   Number of active neurons: 5
 >> iter 11000, loss: 0.360518
 >> iter 12000, loss: 0.405029
 >> iter 13000, loss: 0.531818
 >> iter 14000, loss: 0.653837
 >> iter 15000, loss: 0.561669
 >> iter 16000, loss: 0.535093
 >> iter 17000, loss: 0.358104
 >> iter 18000, loss: 0.318364
 >> iter 19000, loss: 0.492427
 >> iter 20000, loss: 0.417359
   Number of active neurons: 5
 >> iter 21000, loss: 0.211676
 >> iter 22000, loss: 0.487130
 >> iter 23000, loss: 0.341314
 >> iter 24000, loss: 0.349262
 >> iter 25000, loss: 0.244137
 >> iter 26000, loss: 0.308262
 >> iter 27000, loss: 0.469803
 >> iter 28000, loss: 0.276990
 >> iter 29000, loss: 0.366269
 >> iter 30000, loss: 0.238636
   Number of active neurons: 4
 >> iter 31000, loss: 0.311779
 >> iter 32000, loss: 0.549954
 >> iter 33000, loss: 0.414685
 >> iter 34000, loss: 0.233539
 >> iter 35000, loss: 0.205274
 >> iter 36000, loss: 0.268164
 >> iter 37000, loss: 0.278088
 >> iter 38000, loss: 0.291447
 >> iter 39000, loss: 0.295267
 >> iter 40000, loss: 0.251535
   Number of active neurons: 4
 >> iter 41000, loss: 0.332501
 >> iter 42000, loss: 0.340379
 >> iter 43000, loss: 0.310053
 >> iter 44000, loss: 0.322780
 >> iter 45000, loss: 0.290135
 >> iter 46000, loss: 0.378280
 >> iter 47000, loss: 0.207870
 >> iter 48000, loss: 0.189051
 >> iter 49000, loss: 0.431133
 >> iter 50000, loss: 0.367769
   Number of active neurons: 4
 >> iter 51000, loss: 0.416417
 >> iter 52000, loss: 0.294109
 >> iter 53000, loss: 0.278672
 >> iter 54000, loss: 0.310193
 >> iter 55000, loss: 0.315048
 >> iter 56000, loss: 0.351718
 >> iter 57000, loss: 0.446417
 >> iter 58000, loss: 0.470167
 >> iter 59000, loss: 0.224841
 >> iter 60000, loss: 0.402748
   Number of active neurons: 4
 >> iter 61000, loss: 0.344190
 >> iter 62000, loss: 0.309364
 >> iter 63000, loss: 0.225895
 >> iter 64000, loss: 0.164645
 >> iter 65000, loss: 0.317720
 >> iter 66000, loss: 0.287345
 >> iter 67000, loss: 0.185451
 >> iter 68000, loss: 0.181578
 >> iter 69000, loss: 0.305378
 >> iter 70000, loss: 0.184929
   Number of active neurons: 4
 >> iter 71000, loss: 0.094014
 >> iter 72000, loss: 0.236798
 >> iter 73000, loss: 0.377301
 >> iter 74000, loss: 0.436309
 >> iter 75000, loss: 0.257544
 >> iter 76000, loss: 0.184325
 >> iter 77000, loss: 0.201659
 >> iter 78000, loss: 0.318983
 >> iter 79000, loss: 0.399203
 >> iter 80000, loss: 0.262948
   Number of active neurons: 4
 >> iter 81000, loss: 0.143080
 >> iter 82000, loss: 0.213414
 >> iter 83000, loss: 0.293876
 >> iter 84000, loss: 0.253872
 >> iter 85000, loss: 0.214576
 >> iter 86000, loss: 0.156601
 >> iter 87000, loss: 0.286824
 >> iter 88000, loss: 0.419508
 >> iter 89000, loss: 0.361860
 >> iter 90000, loss: 0.209972
   Number of active neurons: 3
 >> iter 91000, loss: 0.130251
 >> iter 92000, loss: 0.195399
 >> iter 93000, loss: 0.284626
 >> iter 94000, loss: 0.216356
 >> iter 95000, loss: 0.182424
 >> iter 96000, loss: 0.295336
 >> iter 97000, loss: 0.262473
 >> iter 98000, loss: 0.244070
 >> iter 99000, loss: 0.232072
 >> iter 100000, loss: 0.210909
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.314941
 >> iter 2000, loss: 8.184655
 >> iter 3000, loss: 3.822565
 >> iter 4000, loss: 1.895924
 >> iter 5000, loss: 0.883714
 >> iter 6000, loss: 0.590927
 >> iter 7000, loss: 0.533765
 >> iter 8000, loss: 0.434186
 >> iter 9000, loss: 0.314597
 >> iter 10000, loss: 0.455172
   Number of active neurons: 3
 >> iter 11000, loss: 0.510626
 >> iter 12000, loss: 0.505224
 >> iter 13000, loss: 0.546711
 >> iter 14000, loss: 0.356373
 >> iter 15000, loss: 0.257886
 >> iter 16000, loss: 0.403849
 >> iter 17000, loss: 0.533142
 >> iter 18000, loss: 0.370054
 >> iter 19000, loss: 0.344037
 >> iter 20000, loss: 0.406230
   Number of active neurons: 3
 >> iter 21000, loss: 0.325925
 >> iter 22000, loss: 0.302208
 >> iter 23000, loss: 0.228738
 >> iter 24000, loss: 0.182885
 >> iter 25000, loss: 0.274204
 >> iter 26000, loss: 0.500750
 >> iter 27000, loss: 0.245327
 >> iter 28000, loss: 0.251052
 >> iter 29000, loss: 0.191843
 >> iter 30000, loss: 0.306122
   Number of active neurons: 3
 >> iter 31000, loss: 0.279569
 >> iter 32000, loss: 0.242668
 >> iter 33000, loss: 0.345038
 >> iter 34000, loss: 0.343788
 >> iter 35000, loss: 0.221792
 >> iter 36000, loss: 0.215303
 >> iter 37000, loss: 0.253531
 >> iter 38000, loss: 0.252072
 >> iter 39000, loss: 0.376249
 >> iter 40000, loss: 0.281895
   Number of active neurons: 3
 >> iter 41000, loss: 0.200388
 >> iter 42000, loss: 0.211165
 >> iter 43000, loss: 0.183201
 >> iter 44000, loss: 0.150925
 >> iter 45000, loss: 0.252360
 >> iter 46000, loss: 0.402048
 >> iter 47000, loss: 0.308601
 >> iter 48000, loss: 0.402248
 >> iter 49000, loss: 0.301432
 >> iter 50000, loss: 0.211515
   Number of active neurons: 3
 >> iter 51000, loss: 0.406577
 >> iter 52000, loss: 0.298709
 >> iter 53000, loss: 0.388292
 >> iter 54000, loss: 0.376407
 >> iter 55000, loss: 0.487378
 >> iter 56000, loss: 0.357872
 >> iter 57000, loss: 0.451181
 >> iter 58000, loss: 0.324700
 >> iter 59000, loss: 0.206835
 >> iter 60000, loss: 0.361579
   Number of active neurons: 3
 >> iter 61000, loss: 0.381734
 >> iter 62000, loss: 0.225549
 >> iter 63000, loss: 0.177777
 >> iter 64000, loss: 0.136571
 >> iter 65000, loss: 0.307334
 >> iter 66000, loss: 0.359890
 >> iter 67000, loss: 0.331412
 >> iter 68000, loss: 0.184776
 >> iter 69000, loss: 0.110771
 >> iter 70000, loss: 0.114356
   Number of active neurons: 3
 >> iter 71000, loss: 0.153441
 >> iter 72000, loss: 0.165445
 >> iter 73000, loss: 0.233254
 >> iter 74000, loss: 0.502149
 >> iter 75000, loss: 0.273041
 >> iter 76000, loss: 0.262869
 >> iter 77000, loss: 0.247855
 >> iter 78000, loss: 0.296194
 >> iter 79000, loss: 0.281114
 >> iter 80000, loss: 0.381493
   Number of active neurons: 3
 >> iter 81000, loss: 0.315285
 >> iter 82000, loss: 0.223111
 >> iter 83000, loss: 0.256299
 >> iter 84000, loss: 0.255336
 >> iter 85000, loss: 0.256202
 >> iter 86000, loss: 0.304743
 >> iter 87000, loss: 0.171995
 >> iter 88000, loss: 0.136235
 >> iter 89000, loss: 0.222947
 >> iter 90000, loss: 0.333605
   Number of active neurons: 3
 >> iter 91000, loss: 0.189385
 >> iter 92000, loss: 0.160733
 >> iter 93000, loss: 0.348398
 >> iter 94000, loss: 0.320222
 >> iter 95000, loss: 0.309483
 >> iter 96000, loss: 0.286167
 >> iter 97000, loss: 0.336136
 >> iter 98000, loss: 0.228254
 >> iter 99000, loss: 0.185451
 >> iter 100000, loss: 0.258928
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 20.524751
 >> iter 2000, loss: 18.054282
 >> iter 3000, loss: 17.068464
 >> iter 4000, loss: 16.118168
 >> iter 5000, loss: 10.792294
 >> iter 6000, loss: 5.411603
 >> iter 7000, loss: 2.590382
 >> iter 8000, loss: 1.336662
 >> iter 9000, loss: 0.930388
 >> iter 10000, loss: 0.581312
   Number of active neurons: 3
 >> iter 11000, loss: 0.657114
 >> iter 12000, loss: 0.378432
 >> iter 13000, loss: 0.334862
 >> iter 14000, loss: 0.345647
 >> iter 15000, loss: 0.404841
 >> iter 16000, loss: 0.350064
 >> iter 17000, loss: 0.397195
 >> iter 18000, loss: 0.481865
 >> iter 19000, loss: 0.377676
 >> iter 20000, loss: 0.189985
   Number of active neurons: 3
 >> iter 21000, loss: 0.285542
 >> iter 22000, loss: 0.205481
 >> iter 23000, loss: 0.124340
 >> iter 24000, loss: 0.143092
 >> iter 25000, loss: 0.306245
 >> iter 26000, loss: 0.243916
 >> iter 27000, loss: 0.223194
 >> iter 28000, loss: 0.482480
 >> iter 29000, loss: 0.348498
 >> iter 30000, loss: 0.279546
   Number of active neurons: 3
 >> iter 31000, loss: 0.402564
 >> iter 32000, loss: 0.211825
 >> iter 33000, loss: 0.155178
 >> iter 34000, loss: 0.200868
 >> iter 35000, loss: 0.235004
 >> iter 36000, loss: 0.300479
 >> iter 37000, loss: 0.277483
 >> iter 38000, loss: 0.200183
 >> iter 39000, loss: 0.119570
 >> iter 40000, loss: 0.144875
   Number of active neurons: 3
 >> iter 41000, loss: 0.308168
 >> iter 42000, loss: 0.197644
 >> iter 43000, loss: 0.489031
 >> iter 44000, loss: 0.336903
 >> iter 45000, loss: 0.363333
 >> iter 46000, loss: 0.227855
 >> iter 47000, loss: 0.129024
 >> iter 48000, loss: 0.192195
 >> iter 49000, loss: 0.144793
 >> iter 50000, loss: 0.121985
   Number of active neurons: 3
 >> iter 51000, loss: 0.122248
 >> iter 52000, loss: 0.157277
 >> iter 53000, loss: 0.232459
 >> iter 54000, loss: 0.206555
 >> iter 55000, loss: 0.304819
 >> iter 56000, loss: 0.147635
 >> iter 57000, loss: 0.133534
 >> iter 58000, loss: 0.137681
 >> iter 59000, loss: 0.166518
 >> iter 60000, loss: 0.147249
   Number of active neurons: 3
 >> iter 61000, loss: 0.266554
 >> iter 62000, loss: 0.511784
 >> iter 63000, loss: 0.263802
 >> iter 64000, loss: 0.159587
 >> iter 65000, loss: 0.273212
 >> iter 66000, loss: 0.212896
 >> iter 67000, loss: 0.220057
 >> iter 68000, loss: 0.297191
 >> iter 69000, loss: 0.172680
 >> iter 70000, loss: 0.369210
   Number of active neurons: 3
 >> iter 71000, loss: 0.289356
 >> iter 72000, loss: 0.216470
 >> iter 73000, loss: 0.271492
 >> iter 74000, loss: 0.263280
 >> iter 75000, loss: 0.195493
 >> iter 76000, loss: 0.308430
 >> iter 77000, loss: 0.235230
 >> iter 78000, loss: 0.150085
 >> iter 79000, loss: 0.286380
 >> iter 80000, loss: 0.254934
   Number of active neurons: 3
 >> iter 81000, loss: 0.343479
 >> iter 82000, loss: 0.353730
 >> iter 83000, loss: 0.302317
 >> iter 84000, loss: 0.249766
 >> iter 85000, loss: 0.283754
 >> iter 86000, loss: 0.386989
 >> iter 87000, loss: 0.285863
 >> iter 88000, loss: 0.292322
 >> iter 89000, loss: 0.224235
 >> iter 90000, loss: 0.264219
   Number of active neurons: 3
 >> iter 91000, loss: 0.225040
 >> iter 92000, loss: 0.329421
 >> iter 93000, loss: 0.407661
 >> iter 94000, loss: 0.262748
 >> iter 95000, loss: 0.313787
 >> iter 96000, loss: 0.304076
 >> iter 97000, loss: 0.313451
 >> iter 98000, loss: 0.219461
 >> iter 99000, loss: 0.106629
 >> iter 100000, loss: 0.242072
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 20.524750
 >> iter 2000, loss: 18.054280
 >> iter 3000, loss: 17.068462
 >> iter 4000, loss: 16.779368
 >> iter 5000, loss: 16.602171
 >> iter 6000, loss: 15.152572
 >> iter 7000, loss: 10.557392
 >> iter 8000, loss: 5.343203
 >> iter 9000, loss: 2.376094
 >> iter 10000, loss: 1.362669
   Number of active neurons: 6
 >> iter 11000, loss: 0.955950
 >> iter 12000, loss: 0.593964
 >> iter 13000, loss: 0.406727
 >> iter 14000, loss: 0.461675
 >> iter 15000, loss: 0.415843
 >> iter 16000, loss: 0.632697
 >> iter 17000, loss: 0.474444
 >> iter 18000, loss: 0.454126
 >> iter 19000, loss: 0.562215
 >> iter 20000, loss: 0.424711
   Number of active neurons: 6
 >> iter 21000, loss: 0.363548
 >> iter 22000, loss: 0.346321
 >> iter 23000, loss: 0.309757
 >> iter 24000, loss: 0.383704
 >> iter 25000, loss: 0.634373
 >> iter 26000, loss: 0.587012
 >> iter 27000, loss: 0.767929
 >> iter 28000, loss: 0.481928
 >> iter 29000, loss: 0.408610
 >> iter 30000, loss: 0.342075
   Number of active neurons: 5
 >> iter 31000, loss: 0.176283
 >> iter 32000, loss: 0.300951
 >> iter 33000, loss: 0.305046
 >> iter 34000, loss: 0.363763
 >> iter 35000, loss: 0.300644
 >> iter 36000, loss: 0.289864
 >> iter 37000, loss: 0.448567
 >> iter 38000, loss: 0.354241
 >> iter 39000, loss: 0.414527
 >> iter 40000, loss: 0.322488
   Number of active neurons: 4
 >> iter 41000, loss: 0.221379
 >> iter 42000, loss: 0.423462
 >> iter 43000, loss: 0.427754
 >> iter 44000, loss: 0.288793
 >> iter 45000, loss: 0.273543
 >> iter 46000, loss: 0.266333
 >> iter 47000, loss: 0.277989
 >> iter 48000, loss: 0.252375
 >> iter 49000, loss: 0.202422
 >> iter 50000, loss: 0.304767
   Number of active neurons: 4
 >> iter 51000, loss: 0.282573
 >> iter 52000, loss: 0.577591
 >> iter 53000, loss: 0.540183
 >> iter 54000, loss: 0.285411
 >> iter 55000, loss: 0.406368
 >> iter 56000, loss: 0.192670
 >> iter 57000, loss: 0.400272
 >> iter 58000, loss: 0.347994
 >> iter 59000, loss: 0.254093
 >> iter 60000, loss: 0.218078
   Number of active neurons: 4
 >> iter 61000, loss: 0.301381
 >> iter 62000, loss: 0.369350
 >> iter 63000, loss: 0.592222
 >> iter 64000, loss: 0.455122
 >> iter 65000, loss: 0.308160
 >> iter 66000, loss: 0.479608
 >> iter 67000, loss: 0.585218
 >> iter 68000, loss: 0.360927
 >> iter 69000, loss: 0.329717
 >> iter 70000, loss: 0.328318
   Number of active neurons: 4
 >> iter 71000, loss: 0.369311
 >> iter 72000, loss: 0.364842
 >> iter 73000, loss: 0.342486
 >> iter 74000, loss: 0.280093
 >> iter 75000, loss: 0.327318
 >> iter 76000, loss: 0.455487
 >> iter 77000, loss: 0.218213
 >> iter 78000, loss: 0.475255
 >> iter 79000, loss: 0.406798
 >> iter 80000, loss: 0.193755
   Number of active neurons: 4
 >> iter 81000, loss: 0.479796
 >> iter 82000, loss: 0.258292
 >> iter 83000, loss: 0.222985
 >> iter 84000, loss: 0.291347
 >> iter 85000, loss: 0.270935
 >> iter 86000, loss: 0.218394
 >> iter 87000, loss: 0.317921
 >> iter 88000, loss: 0.344483
 >> iter 89000, loss: 0.349150
 >> iter 90000, loss: 0.455548
   Number of active neurons: 4
 >> iter 91000, loss: 0.211707
 >> iter 92000, loss: 0.194446
 >> iter 93000, loss: 0.224562
 >> iter 94000, loss: 0.333249
 >> iter 95000, loss: 0.357192
 >> iter 96000, loss: 0.171835
 >> iter 97000, loss: 0.183426
 >> iter 98000, loss: 0.328937
 >> iter 99000, loss: 0.386599
 >> iter 100000, loss: 0.268203
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.845029
 >> iter 2000, loss: 11.828472
 >> iter 3000, loss: 6.241058
 >> iter 4000, loss: 3.123888
 >> iter 5000, loss: 1.839807
 >> iter 6000, loss: 1.001968
 >> iter 7000, loss: 0.700404
 >> iter 8000, loss: 0.474282
 >> iter 9000, loss: 0.533013
 >> iter 10000, loss: 0.538610
   Number of active neurons: 6
 >> iter 11000, loss: 0.348107
 >> iter 12000, loss: 0.491122
 >> iter 13000, loss: 0.556462
 >> iter 14000, loss: 0.525366
 >> iter 15000, loss: 0.475869
 >> iter 16000, loss: 0.379144
 >> iter 17000, loss: 0.528657
 >> iter 18000, loss: 0.721512
 >> iter 19000, loss: 0.425703
 >> iter 20000, loss: 0.366159
   Number of active neurons: 6
 >> iter 21000, loss: 0.451412
 >> iter 22000, loss: 0.345391
 >> iter 23000, loss: 0.326520
 >> iter 24000, loss: 0.346174
 >> iter 25000, loss: 0.350027
 >> iter 26000, loss: 0.307949
 >> iter 27000, loss: 0.431731
 >> iter 28000, loss: 0.357839
 >> iter 29000, loss: 0.356161
 >> iter 30000, loss: 0.360270
   Number of active neurons: 4
 >> iter 31000, loss: 0.305824
 >> iter 32000, loss: 0.509288
 >> iter 33000, loss: 0.268453
 >> iter 34000, loss: 0.337290
 >> iter 35000, loss: 0.455574
 >> iter 36000, loss: 0.402257
 >> iter 37000, loss: 0.426697
 >> iter 38000, loss: 0.321863
 >> iter 39000, loss: 0.542570
 >> iter 40000, loss: 0.784880
   Number of active neurons: 6
 >> iter 41000, loss: 0.510188
 >> iter 42000, loss: 0.600743
 >> iter 43000, loss: 0.504612
 >> iter 44000, loss: 0.593622
 >> iter 45000, loss: 0.423469
 >> iter 46000, loss: 0.540152
 >> iter 47000, loss: 0.637017
 >> iter 48000, loss: 0.587849
 >> iter 49000, loss: 0.604896
 >> iter 50000, loss: 0.404065
   Number of active neurons: 6
 >> iter 51000, loss: 0.332442
 >> iter 52000, loss: 0.288822
 >> iter 53000, loss: 0.272732
 >> iter 54000, loss: 0.226926
 >> iter 55000, loss: 0.366008
 >> iter 56000, loss: 0.364186
 >> iter 57000, loss: 0.384769
 >> iter 58000, loss: 0.397475
 >> iter 59000, loss: 0.526858
 >> iter 60000, loss: 0.555958
   Number of active neurons: 6
 >> iter 61000, loss: 0.519086
 >> iter 62000, loss: 0.629032
 >> iter 63000, loss: 0.526153
 >> iter 64000, loss: 0.317938
 >> iter 65000, loss: 0.540470
 >> iter 66000, loss: 0.474282
 >> iter 67000, loss: 0.423748
 >> iter 68000, loss: 0.270269
 >> iter 69000, loss: 0.355810
 >> iter 70000, loss: 0.281339
   Number of active neurons: 6
 >> iter 71000, loss: 0.350878
 >> iter 72000, loss: 0.205960
 >> iter 73000, loss: 0.445937
 >> iter 74000, loss: 0.301098
 >> iter 75000, loss: 0.308373
 >> iter 76000, loss: 0.336432
 >> iter 77000, loss: 0.344684
 >> iter 78000, loss: 0.358859
 >> iter 79000, loss: 0.328922
 >> iter 80000, loss: 0.384443
   Number of active neurons: 6
 >> iter 81000, loss: 0.256235
 >> iter 82000, loss: 0.330267
 >> iter 83000, loss: 0.227251
 >> iter 84000, loss: 0.284350
 >> iter 85000, loss: 0.286194
 >> iter 86000, loss: 0.428290
 >> iter 87000, loss: 0.389629
 >> iter 88000, loss: 0.381123
 >> iter 89000, loss: 0.526110
 >> iter 90000, loss: 0.500709
   Number of active neurons: 6
 >> iter 91000, loss: 0.600440
 >> iter 92000, loss: 0.445555
 >> iter 93000, loss: 0.359581
 >> iter 94000, loss: 0.383887
 >> iter 95000, loss: 0.255086
 >> iter 96000, loss: 0.284472
 >> iter 97000, loss: 0.288291
 >> iter 98000, loss: 0.437178
 >> iter 99000, loss: 0.544769
 >> iter 100000, loss: 0.402995
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.514901
 >> iter 2000, loss: 12.010179
 >> iter 3000, loss: 6.823381
 >> iter 4000, loss: 3.136691
 >> iter 5000, loss: 1.435728
 >> iter 6000, loss: 0.876155
 >> iter 7000, loss: 0.545188
 >> iter 8000, loss: 0.397968
 >> iter 9000, loss: 0.353208
 >> iter 10000, loss: 0.272604
   Number of active neurons: 4
 >> iter 11000, loss: 0.239959
 >> iter 12000, loss: 0.206644
 >> iter 13000, loss: 0.265191
 >> iter 14000, loss: 0.216262
 >> iter 15000, loss: 0.347585
 >> iter 16000, loss: 0.327006
 >> iter 17000, loss: 0.437885
 >> iter 18000, loss: 0.234439
 >> iter 19000, loss: 0.268706
 >> iter 20000, loss: 0.131286
   Number of active neurons: 3
 >> iter 21000, loss: 0.202508
 >> iter 22000, loss: 0.183915
 >> iter 23000, loss: 0.193669
 >> iter 24000, loss: 0.357428
 >> iter 25000, loss: 0.320726
 >> iter 26000, loss: 0.314781
 >> iter 27000, loss: 0.242857
 >> iter 28000, loss: 0.230564
 >> iter 29000, loss: 0.317620
 >> iter 30000, loss: 0.203362
   Number of active neurons: 3
 >> iter 31000, loss: 0.323817
 >> iter 32000, loss: 0.270474
 >> iter 33000, loss: 0.236237
 >> iter 34000, loss: 0.113522
 >> iter 35000, loss: 0.137037
 >> iter 36000, loss: 0.169074
 >> iter 37000, loss: 0.300466
 >> iter 38000, loss: 0.200151
 >> iter 39000, loss: 0.304451
 >> iter 40000, loss: 0.372322
   Number of active neurons: 3
 >> iter 41000, loss: 0.170866
 >> iter 42000, loss: 0.130925
 >> iter 43000, loss: 0.251666
 >> iter 44000, loss: 0.121271
 >> iter 45000, loss: 0.201119
 >> iter 46000, loss: 0.211649
 >> iter 47000, loss: 0.191713
 >> iter 48000, loss: 0.211756
 >> iter 49000, loss: 0.327341
 >> iter 50000, loss: 0.240949
   Number of active neurons: 3
 >> iter 51000, loss: 0.239329
 >> iter 52000, loss: 0.397255
 >> iter 53000, loss: 0.250691
 >> iter 54000, loss: 0.168801
 >> iter 55000, loss: 0.164741
 >> iter 56000, loss: 0.233040
 >> iter 57000, loss: 0.190791
 >> iter 58000, loss: 0.137660
 >> iter 59000, loss: 0.163259
 >> iter 60000, loss: 0.165968
   Number of active neurons: 3
 >> iter 61000, loss: 0.342962
 >> iter 62000, loss: 0.366893
 >> iter 63000, loss: 0.233036
 >> iter 64000, loss: 0.142136
 >> iter 65000, loss: 0.285548
 >> iter 66000, loss: 0.239422
 >> iter 67000, loss: 0.360441
 >> iter 68000, loss: 0.214029
 >> iter 69000, loss: 0.209133
 >> iter 70000, loss: 0.238727
   Number of active neurons: 3
 >> iter 71000, loss: 0.195051
 >> iter 72000, loss: 0.242894
 >> iter 73000, loss: 0.181170
 >> iter 74000, loss: 0.295755
 >> iter 75000, loss: 0.263198
 >> iter 76000, loss: 0.194082
 >> iter 77000, loss: 0.281213
 >> iter 78000, loss: 0.344170
 >> iter 79000, loss: 0.265676
 >> iter 80000, loss: 0.365539
   Number of active neurons: 3
 >> iter 81000, loss: 0.299714
 >> iter 82000, loss: 0.281981
 >> iter 83000, loss: 0.313957
 >> iter 84000, loss: 0.241926
 >> iter 85000, loss: 0.178764
 >> iter 86000, loss: 0.452104
 >> iter 87000, loss: 0.595221
 >> iter 88000, loss: 0.402271
 >> iter 89000, loss: 0.373065
 >> iter 90000, loss: 0.390520
   Number of active neurons: 3
 >> iter 91000, loss: 0.322633
 >> iter 92000, loss: 0.346022
 >> iter 93000, loss: 0.258491
 >> iter 94000, loss: 0.150389
 >> iter 95000, loss: 0.108741
 >> iter 96000, loss: 0.239281
 >> iter 97000, loss: 0.345844
 >> iter 98000, loss: 0.228476
 >> iter 99000, loss: 0.154228
 >> iter 100000, loss: 0.261557
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.443193
 >> iter 2000, loss: 8.734448
 >> iter 3000, loss: 3.805024
 >> iter 4000, loss: 1.976857
 >> iter 5000, loss: 1.241837
 >> iter 6000, loss: 0.630261
 >> iter 7000, loss: 0.391348
 >> iter 8000, loss: 0.373458
 >> iter 9000, loss: 0.315318
 >> iter 10000, loss: 0.403871
   Number of active neurons: 4
 >> iter 11000, loss: 0.317858
 >> iter 12000, loss: 0.554427
 >> iter 13000, loss: 0.276423
 >> iter 14000, loss: 0.257677
 >> iter 15000, loss: 0.236977
 >> iter 16000, loss: 0.268232
 >> iter 17000, loss: 0.451373
 >> iter 18000, loss: 0.228204
 >> iter 19000, loss: 0.187094
 >> iter 20000, loss: 0.193683
   Number of active neurons: 4
 >> iter 21000, loss: 0.257287
 >> iter 22000, loss: 0.285337
 >> iter 23000, loss: 0.222638
 >> iter 24000, loss: 0.243158
 >> iter 25000, loss: 0.321211
 >> iter 26000, loss: 0.290445
 >> iter 27000, loss: 0.242409
 >> iter 28000, loss: 0.161833
 >> iter 29000, loss: 0.383121
 >> iter 30000, loss: 0.253062
   Number of active neurons: 4
 >> iter 31000, loss: 0.244102
 >> iter 32000, loss: 0.614327
 >> iter 33000, loss: 0.423509
 >> iter 34000, loss: 0.351705
 >> iter 35000, loss: 0.224483
 >> iter 36000, loss: 0.525219
 >> iter 37000, loss: 0.242554
 >> iter 38000, loss: 0.285042
 >> iter 39000, loss: 0.194893
 >> iter 40000, loss: 0.375973
   Number of active neurons: 4
 >> iter 41000, loss: 0.401654
 >> iter 42000, loss: 0.209066
 >> iter 43000, loss: 0.203717
 >> iter 44000, loss: 0.150813
 >> iter 45000, loss: 0.095140
 >> iter 46000, loss: 0.139733
 >> iter 47000, loss: 0.116292
 >> iter 48000, loss: 0.346277
 >> iter 49000, loss: 0.243497
 >> iter 50000, loss: 0.221571
   Number of active neurons: 3
 >> iter 51000, loss: 0.391784
 >> iter 52000, loss: 0.294284
 >> iter 53000, loss: 0.312048
 >> iter 54000, loss: 0.231047
 >> iter 55000, loss: 0.394176
 >> iter 56000, loss: 0.419276
 >> iter 57000, loss: 0.231167
 >> iter 58000, loss: 0.244169
 >> iter 59000, loss: 0.301120
 >> iter 60000, loss: 0.258515
   Number of active neurons: 3
 >> iter 61000, loss: 0.383252
 >> iter 62000, loss: 0.358092
 >> iter 63000, loss: 0.365293
 >> iter 64000, loss: 0.257398
 >> iter 65000, loss: 0.264942
 >> iter 66000, loss: 0.280051
 >> iter 67000, loss: 0.245033
 >> iter 68000, loss: 0.218371
 >> iter 69000, loss: 0.216486
 >> iter 70000, loss: 0.249079
   Number of active neurons: 3
 >> iter 71000, loss: 0.388178
 >> iter 72000, loss: 0.249761
 >> iter 73000, loss: 0.257691
 >> iter 74000, loss: 0.212903
 >> iter 75000, loss: 0.256572
 >> iter 76000, loss: 0.179386
 >> iter 77000, loss: 0.289810
 >> iter 78000, loss: 0.177001
 >> iter 79000, loss: 0.215076
 >> iter 80000, loss: 0.209328
   Number of active neurons: 3
 >> iter 81000, loss: 0.100819
 >> iter 82000, loss: 0.421874
 >> iter 83000, loss: 0.335258
 >> iter 84000, loss: 0.462489
 >> iter 85000, loss: 0.329519
 >> iter 86000, loss: 0.156606
 >> iter 87000, loss: 0.165981
 >> iter 88000, loss: 0.117537
 >> iter 89000, loss: 0.166584
 >> iter 90000, loss: 0.111042
   Number of active neurons: 3
 >> iter 91000, loss: 0.161887
 >> iter 92000, loss: 0.271229
 >> iter 93000, loss: 0.261855
 >> iter 94000, loss: 0.210160
 >> iter 95000, loss: 0.302446
 >> iter 96000, loss: 0.169129
 >> iter 97000, loss: 0.231724
 >> iter 98000, loss: 0.403724
 >> iter 99000, loss: 0.353397
 >> iter 100000, loss: 0.164176
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.318274
 >> iter 2000, loss: 10.748290
 >> iter 3000, loss: 5.000120
 >> iter 4000, loss: 2.468849
 >> iter 5000, loss: 1.440653
 >> iter 6000, loss: 0.832453
 >> iter 7000, loss: 0.736326
 >> iter 8000, loss: 0.424284
 >> iter 9000, loss: 0.426963
 >> iter 10000, loss: 0.384764
   Number of active neurons: 4
 >> iter 11000, loss: 0.488301
 >> iter 12000, loss: 0.302587
 >> iter 13000, loss: 0.288191
 >> iter 14000, loss: 0.263662
 >> iter 15000, loss: 0.313815
 >> iter 16000, loss: 0.657755
 >> iter 17000, loss: 0.389475
 >> iter 18000, loss: 0.283130
 >> iter 19000, loss: 0.181785
 >> iter 20000, loss: 0.288023
   Number of active neurons: 4
 >> iter 21000, loss: 0.369743
 >> iter 22000, loss: 0.245585
 >> iter 23000, loss: 0.215185
 >> iter 24000, loss: 0.248351
 >> iter 25000, loss: 0.326458
 >> iter 26000, loss: 0.219030
 >> iter 27000, loss: 0.195675
 >> iter 28000, loss: 0.365578
 >> iter 29000, loss: 0.364506
 >> iter 30000, loss: 0.319902
   Number of active neurons: 4
 >> iter 31000, loss: 0.204050
 >> iter 32000, loss: 0.200168
 >> iter 33000, loss: 0.237305
 >> iter 34000, loss: 0.235022
 >> iter 35000, loss: 0.215274
 >> iter 36000, loss: 0.306490
 >> iter 37000, loss: 0.230765
 >> iter 38000, loss: 0.147301
 >> iter 39000, loss: 0.265432
 >> iter 40000, loss: 0.276378
   Number of active neurons: 4
 >> iter 41000, loss: 0.256469
 >> iter 42000, loss: 0.325233
 >> iter 43000, loss: 0.242684
 >> iter 44000, loss: 0.222710
 >> iter 45000, loss: 0.437518
 >> iter 46000, loss: 0.293596
 >> iter 47000, loss: 0.253183
 >> iter 48000, loss: 0.220080
 >> iter 49000, loss: 0.121464
 >> iter 50000, loss: 0.143574
   Number of active neurons: 3
 >> iter 51000, loss: 0.160497
 >> iter 52000, loss: 0.153769
 >> iter 53000, loss: 0.228078
 >> iter 54000, loss: 0.350977
 >> iter 55000, loss: 0.299764
 >> iter 56000, loss: 0.247487
 >> iter 57000, loss: 0.210016
 >> iter 58000, loss: 0.221701
 >> iter 59000, loss: 0.179966
 >> iter 60000, loss: 0.239996
   Number of active neurons: 3
 >> iter 61000, loss: 0.283892
 >> iter 62000, loss: 0.233457
 >> iter 63000, loss: 0.178503
 >> iter 64000, loss: 0.171237
 >> iter 65000, loss: 0.125725
 >> iter 66000, loss: 0.201715
 >> iter 67000, loss: 0.228059
 >> iter 68000, loss: 0.172109
 >> iter 69000, loss: 0.146017
 >> iter 70000, loss: 0.243942
   Number of active neurons: 3
 >> iter 71000, loss: 0.145620
 >> iter 72000, loss: 0.149302
 >> iter 73000, loss: 0.299453
 >> iter 74000, loss: 0.202142
 >> iter 75000, loss: 0.174889
 >> iter 76000, loss: 0.495027
 >> iter 77000, loss: 0.230907
 >> iter 78000, loss: 0.378540
 >> iter 79000, loss: 0.330293
 >> iter 80000, loss: 0.255042
   Number of active neurons: 3
 >> iter 81000, loss: 0.187697
 >> iter 82000, loss: 0.236676
 >> iter 83000, loss: 0.135225
 >> iter 84000, loss: 0.229058
 >> iter 85000, loss: 0.236783
 >> iter 86000, loss: 0.306221
 >> iter 87000, loss: 0.206296
 >> iter 88000, loss: 0.232627
 >> iter 89000, loss: 0.190413
 >> iter 90000, loss: 0.261183
   Number of active neurons: 3
 >> iter 91000, loss: 0.309998
 >> iter 92000, loss: 0.232044
 >> iter 93000, loss: 0.252098
 >> iter 94000, loss: 0.177745
 >> iter 95000, loss: 0.198878
 >> iter 96000, loss: 0.202660
 >> iter 97000, loss: 0.290683
 >> iter 98000, loss: 0.270104
 >> iter 99000, loss: 0.207444
 >> iter 100000, loss: 0.180387
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.617832
 >> iter 2000, loss: 11.563281
 >> iter 3000, loss: 5.620795
 >> iter 4000, loss: 2.619978
 >> iter 5000, loss: 1.303242
 >> iter 6000, loss: 0.678231
 >> iter 7000, loss: 0.539891
 >> iter 8000, loss: 0.513614
 >> iter 9000, loss: 0.469379
 >> iter 10000, loss: 0.267810
   Number of active neurons: 5
 >> iter 11000, loss: 0.173127
 >> iter 12000, loss: 0.181315
 >> iter 13000, loss: 0.175967
 >> iter 14000, loss: 0.206855
 >> iter 15000, loss: 0.192211
 >> iter 16000, loss: 0.412673
 >> iter 17000, loss: 0.283685
 >> iter 18000, loss: 0.209759
 >> iter 19000, loss: 0.285786
 >> iter 20000, loss: 0.277238
   Number of active neurons: 5
 >> iter 21000, loss: 0.398410
 >> iter 22000, loss: 0.300476
 >> iter 23000, loss: 0.603454
 >> iter 24000, loss: 0.596387
 >> iter 25000, loss: 0.396926
 >> iter 26000, loss: 0.279433
 >> iter 27000, loss: 0.263367
 >> iter 28000, loss: 0.224452
 >> iter 29000, loss: 0.326168
 >> iter 30000, loss: 0.451132
   Number of active neurons: 4
 >> iter 31000, loss: 0.336875
 >> iter 32000, loss: 0.197843
 >> iter 33000, loss: 0.237069
 >> iter 34000, loss: 0.233991
 >> iter 35000, loss: 0.208771
 >> iter 36000, loss: 0.227261
 >> iter 37000, loss: 0.308631
 >> iter 38000, loss: 0.161468
 >> iter 39000, loss: 0.159266
 >> iter 40000, loss: 0.208375
   Number of active neurons: 4
 >> iter 41000, loss: 0.300548
 >> iter 42000, loss: 0.254809
 >> iter 43000, loss: 0.293525
 >> iter 44000, loss: 0.247681
 >> iter 45000, loss: 0.195238
 >> iter 46000, loss: 0.190770
 >> iter 47000, loss: 0.201763
 >> iter 48000, loss: 0.181791
 >> iter 49000, loss: 0.213771
 >> iter 50000, loss: 0.151235
   Number of active neurons: 3
 >> iter 51000, loss: 0.152933
 >> iter 52000, loss: 0.305227
 >> iter 53000, loss: 0.173384
 >> iter 54000, loss: 0.206043
 >> iter 55000, loss: 0.170769
 >> iter 56000, loss: 0.192073
 >> iter 57000, loss: 0.221270
 >> iter 58000, loss: 0.208817
 >> iter 59000, loss: 0.152863
 >> iter 60000, loss: 0.173342
   Number of active neurons: 3
 >> iter 61000, loss: 0.252506
 >> iter 62000, loss: 0.166135
 >> iter 63000, loss: 0.194732
 >> iter 64000, loss: 0.175044
 >> iter 65000, loss: 0.190491
 >> iter 66000, loss: 0.361061
 >> iter 67000, loss: 0.518237
 >> iter 68000, loss: 0.401193
 >> iter 69000, loss: 0.438765
 >> iter 70000, loss: 0.565162
   Number of active neurons: 3
 >> iter 71000, loss: 0.318281
 >> iter 72000, loss: 0.171111
 >> iter 73000, loss: 0.134452
 >> iter 74000, loss: 0.252556
 >> iter 75000, loss: 0.256936
 >> iter 76000, loss: 0.279214
 >> iter 77000, loss: 0.234029
 >> iter 78000, loss: 0.147678
 >> iter 79000, loss: 0.185770
 >> iter 80000, loss: 0.121929
   Number of active neurons: 3
 >> iter 81000, loss: 0.166542
 >> iter 82000, loss: 0.182117
 >> iter 83000, loss: 0.231058
 >> iter 84000, loss: 0.251151
 >> iter 85000, loss: 0.131502
 >> iter 86000, loss: 0.174957
 >> iter 87000, loss: 0.221808
 >> iter 88000, loss: 0.173328
 >> iter 89000, loss: 0.096765
 >> iter 90000, loss: 0.454948
   Number of active neurons: 3
 >> iter 91000, loss: 0.429348
 >> iter 92000, loss: 0.282448
 >> iter 93000, loss: 0.229515
 >> iter 94000, loss: 0.271315
 >> iter 95000, loss: 0.404256
 >> iter 96000, loss: 0.230333
 >> iter 97000, loss: 0.209877
 >> iter 98000, loss: 0.136983
 >> iter 99000, loss: 0.231266
 >> iter 100000, loss: 0.235870
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.823066
 >> iter 2000, loss: 9.928407
 >> iter 3000, loss: 4.364487
 >> iter 4000, loss: 2.179523
 >> iter 5000, loss: 1.127968
 >> iter 6000, loss: 0.792948
 >> iter 7000, loss: 0.505975
 >> iter 8000, loss: 0.441913
 >> iter 9000, loss: 0.505628
 >> iter 10000, loss: 0.319083
   Number of active neurons: 4
 >> iter 11000, loss: 0.200489
 >> iter 12000, loss: 0.241520
 >> iter 13000, loss: 0.283142
 >> iter 14000, loss: 0.293494
 >> iter 15000, loss: 0.352458
 >> iter 16000, loss: 0.419987
 >> iter 17000, loss: 0.299681
 >> iter 18000, loss: 0.296729
 >> iter 19000, loss: 0.196041
 >> iter 20000, loss: 0.153477
   Number of active neurons: 4
 >> iter 21000, loss: 0.157574
 >> iter 22000, loss: 0.274250
 >> iter 23000, loss: 0.292249
 >> iter 24000, loss: 0.244436
 >> iter 25000, loss: 0.207845
 >> iter 26000, loss: 0.279081
 >> iter 27000, loss: 0.387093
 >> iter 28000, loss: 0.204417
 >> iter 29000, loss: 0.229952
 >> iter 30000, loss: 0.197611
   Number of active neurons: 3
 >> iter 31000, loss: 0.172010
 >> iter 32000, loss: 0.157882
 >> iter 33000, loss: 0.110836
 >> iter 34000, loss: 0.289837
 >> iter 35000, loss: 0.317560
 >> iter 36000, loss: 0.210412
 >> iter 37000, loss: 0.109933
 >> iter 38000, loss: 0.195230
 >> iter 39000, loss: 0.138632
 >> iter 40000, loss: 0.120452
   Number of active neurons: 3
 >> iter 41000, loss: 0.300933
 >> iter 42000, loss: 0.289495
 >> iter 43000, loss: 0.216850
 >> iter 44000, loss: 0.238759
 >> iter 45000, loss: 0.202205
 >> iter 46000, loss: 0.210968
 >> iter 47000, loss: 0.201543
 >> iter 48000, loss: 0.452908
 >> iter 49000, loss: 0.263286
 >> iter 50000, loss: 0.164165
   Number of active neurons: 3
 >> iter 51000, loss: 0.155428
 >> iter 52000, loss: 0.218943
 >> iter 53000, loss: 0.150412
 >> iter 54000, loss: 0.155395
 >> iter 55000, loss: 0.297394
 >> iter 56000, loss: 0.448516
 >> iter 57000, loss: 0.376426
 >> iter 58000, loss: 0.218984
 >> iter 59000, loss: 0.274087
 >> iter 60000, loss: 0.498713
   Number of active neurons: 3
 >> iter 61000, loss: 0.327745
 >> iter 62000, loss: 0.307813
 >> iter 63000, loss: 0.245425
 >> iter 64000, loss: 0.200396
 >> iter 65000, loss: 0.136834
 >> iter 66000, loss: 0.149386
 >> iter 67000, loss: 0.250420
 >> iter 68000, loss: 0.162620
 >> iter 69000, loss: 0.162741
 >> iter 70000, loss: 0.246367
   Number of active neurons: 3
 >> iter 71000, loss: 0.316761
 >> iter 72000, loss: 0.229647
 >> iter 73000, loss: 0.230329
 >> iter 74000, loss: 0.252571
 >> iter 75000, loss: 0.379969
 >> iter 76000, loss: 0.251482
 >> iter 77000, loss: 0.189376
 >> iter 78000, loss: 0.168967
 >> iter 79000, loss: 0.243276
 >> iter 80000, loss: 0.153750
   Number of active neurons: 3
 >> iter 81000, loss: 0.227839
 >> iter 82000, loss: 0.310817
 >> iter 83000, loss: 0.304235
 >> iter 84000, loss: 0.242770
 >> iter 85000, loss: 0.176048
 >> iter 86000, loss: 0.339617
 >> iter 87000, loss: 0.239377
 >> iter 88000, loss: 0.167881
 >> iter 89000, loss: 0.104614
 >> iter 90000, loss: 0.223180
   Number of active neurons: 3
 >> iter 91000, loss: 0.134734
 >> iter 92000, loss: 0.194268
 >> iter 93000, loss: 0.110411
 >> iter 94000, loss: 0.186934
 >> iter 95000, loss: 0.293037
 >> iter 96000, loss: 0.216303
 >> iter 97000, loss: 0.329459
 >> iter 98000, loss: 0.360876
 >> iter 99000, loss: 0.255503
 >> iter 100000, loss: 0.279444
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.101641
 >> iter 2000, loss: 9.734863
 >> iter 3000, loss: 4.142548
 >> iter 4000, loss: 2.115920
 >> iter 5000, loss: 1.175707
 >> iter 6000, loss: 0.752630
 >> iter 7000, loss: 0.498627
 >> iter 8000, loss: 0.506501
 >> iter 9000, loss: 0.278190
 >> iter 10000, loss: 0.409199
   Number of active neurons: 3
 >> iter 11000, loss: 0.344369
 >> iter 12000, loss: 0.303159
 >> iter 13000, loss: 0.263624
 >> iter 14000, loss: 0.437358
 >> iter 15000, loss: 0.312940
 >> iter 16000, loss: 0.223101
 >> iter 17000, loss: 0.301244
 >> iter 18000, loss: 0.270257
 >> iter 19000, loss: 0.338172
 >> iter 20000, loss: 0.238418
   Number of active neurons: 3
 >> iter 21000, loss: 0.311958
 >> iter 22000, loss: 0.315128
 >> iter 23000, loss: 0.214018
 >> iter 24000, loss: 0.167608
 >> iter 25000, loss: 0.275858
 >> iter 26000, loss: 0.363780
 >> iter 27000, loss: 0.223715
 >> iter 28000, loss: 0.285158
 >> iter 29000, loss: 0.324172
 >> iter 30000, loss: 0.332348
   Number of active neurons: 3
 >> iter 31000, loss: 0.343102
 >> iter 32000, loss: 0.205832
 >> iter 33000, loss: 0.235377
 >> iter 34000, loss: 0.191546
 >> iter 35000, loss: 0.410620
 >> iter 36000, loss: 0.367053
 >> iter 37000, loss: 0.375688
 >> iter 38000, loss: 0.312442
 >> iter 39000, loss: 0.194812
 >> iter 40000, loss: 0.230708
   Number of active neurons: 3
 >> iter 41000, loss: 0.125835
 >> iter 42000, loss: 0.253345
 >> iter 43000, loss: 0.322816
 >> iter 44000, loss: 0.338219
 >> iter 45000, loss: 0.393685
 >> iter 46000, loss: 0.516271
 >> iter 47000, loss: 0.471943
 >> iter 48000, loss: 0.335133
 >> iter 49000, loss: 0.237989
 >> iter 50000, loss: 0.227520
   Number of active neurons: 3
 >> iter 51000, loss: 0.236426
 >> iter 52000, loss: 0.270053
 >> iter 53000, loss: 0.232845
 >> iter 54000, loss: 0.451890
 >> iter 55000, loss: 0.228360
 >> iter 56000, loss: 0.227121
 >> iter 57000, loss: 0.266474
 >> iter 58000, loss: 0.354600
 >> iter 59000, loss: 0.334209
 >> iter 60000, loss: 0.288405
   Number of active neurons: 3
 >> iter 61000, loss: 0.421618
 >> iter 62000, loss: 0.280830
 >> iter 63000, loss: 0.186751
 >> iter 64000, loss: 0.103234
 >> iter 65000, loss: 0.100305
 >> iter 66000, loss: 0.155371
 >> iter 67000, loss: 0.133662
 >> iter 68000, loss: 0.227569
 >> iter 69000, loss: 0.297100
 >> iter 70000, loss: 0.221893
   Number of active neurons: 3
 >> iter 71000, loss: 0.260575
 >> iter 72000, loss: 0.227799
 >> iter 73000, loss: 0.215670
 >> iter 74000, loss: 0.234226
 >> iter 75000, loss: 0.286701
 >> iter 76000, loss: 0.180318
 >> iter 77000, loss: 0.350921
 >> iter 78000, loss: 0.272044
 >> iter 79000, loss: 0.234174
 >> iter 80000, loss: 0.219635
   Number of active neurons: 3
 >> iter 81000, loss: 0.142174
 >> iter 82000, loss: 0.166607
 >> iter 83000, loss: 0.172954
 >> iter 84000, loss: 0.161915
 >> iter 85000, loss: 0.242384
 >> iter 86000, loss: 0.451373
 >> iter 87000, loss: 0.235411
 >> iter 88000, loss: 0.163663
 >> iter 89000, loss: 0.217366
 >> iter 90000, loss: 0.192339
   Number of active neurons: 3
 >> iter 91000, loss: 0.168431
 >> iter 92000, loss: 0.329037
 >> iter 93000, loss: 0.338085
 >> iter 94000, loss: 0.228101
 >> iter 95000, loss: 0.243167
 >> iter 96000, loss: 0.316440
 >> iter 97000, loss: 0.366166
 >> iter 98000, loss: 0.194321
 >> iter 99000, loss: 0.265004
 >> iter 100000, loss: 0.256748
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

