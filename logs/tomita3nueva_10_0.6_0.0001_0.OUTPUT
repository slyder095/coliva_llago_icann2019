 > Problema: tomita3nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.259965
 >> iter 2000, loss: 13.255807
 >> iter 3000, loss: 7.721164
 >> iter 4000, loss: 3.698593
 >> iter 5000, loss: 2.045110
 >> iter 6000, loss: 1.237696
 >> iter 7000, loss: 0.863614
 >> iter 8000, loss: 0.706238
 >> iter 9000, loss: 0.673558
 >> iter 10000, loss: 0.539580
   Number of active neurons: 5
 >> iter 11000, loss: 0.635002
 >> iter 12000, loss: 0.576506
 >> iter 13000, loss: 0.453650
 >> iter 14000, loss: 0.380458
 >> iter 15000, loss: 0.455954
 >> iter 16000, loss: 0.386418
 >> iter 17000, loss: 0.248789
 >> iter 18000, loss: 0.289618
 >> iter 19000, loss: 0.378660
 >> iter 20000, loss: 0.416412
   Number of active neurons: 4
 >> iter 21000, loss: 0.388052
 >> iter 22000, loss: 0.397913
 >> iter 23000, loss: 0.420037
 >> iter 24000, loss: 0.448519
 >> iter 25000, loss: 0.294515
 >> iter 26000, loss: 0.253262
 >> iter 27000, loss: 0.237807
 >> iter 28000, loss: 0.222929
 >> iter 29000, loss: 0.377233
 >> iter 30000, loss: 0.482949
   Number of active neurons: 4
 >> iter 31000, loss: 0.417574
 >> iter 32000, loss: 0.424980
 >> iter 33000, loss: 0.435088
 >> iter 34000, loss: 0.340881
 >> iter 35000, loss: 0.330970
 >> iter 36000, loss: 0.225400
 >> iter 37000, loss: 0.272834
 >> iter 38000, loss: 0.334120
 >> iter 39000, loss: 0.337342
 >> iter 40000, loss: 0.296966
   Number of active neurons: 4
 >> iter 41000, loss: 0.443361
 >> iter 42000, loss: 0.305956
 >> iter 43000, loss: 0.266461
 >> iter 44000, loss: 0.281737
 >> iter 45000, loss: 0.495646
 >> iter 46000, loss: 0.450406
 >> iter 47000, loss: 0.433128
 >> iter 48000, loss: 0.330626
 >> iter 49000, loss: 0.388219
 >> iter 50000, loss: 0.361842
   Number of active neurons: 4
 >> iter 51000, loss: 0.277543
 >> iter 52000, loss: 0.228074
 >> iter 53000, loss: 0.263182
 >> iter 54000, loss: 0.310129
 >> iter 55000, loss: 0.332015
 >> iter 56000, loss: 0.521327
 >> iter 57000, loss: 0.385427
 >> iter 58000, loss: 0.470701
 >> iter 59000, loss: 0.247552
 >> iter 60000, loss: 0.156624
   Number of active neurons: 4
 >> iter 61000, loss: 0.427871
 >> iter 62000, loss: 0.417642
 >> iter 63000, loss: 0.430052
 >> iter 64000, loss: 0.380697
 >> iter 65000, loss: 0.364327
 >> iter 66000, loss: 0.589793
 >> iter 67000, loss: 0.345009
 >> iter 68000, loss: 0.311708
 >> iter 69000, loss: 0.214453
 >> iter 70000, loss: 0.322158
   Number of active neurons: 4
 >> iter 71000, loss: 0.223101
 >> iter 72000, loss: 0.349583
 >> iter 73000, loss: 0.372934
 >> iter 74000, loss: 0.437114
 >> iter 75000, loss: 0.462137
 >> iter 76000, loss: 0.329968
 >> iter 77000, loss: 0.342065
 >> iter 78000, loss: 0.367039
 >> iter 79000, loss: 0.360441
 >> iter 80000, loss: 0.392052
   Number of active neurons: 4
 >> iter 81000, loss: 0.443868
 >> iter 82000, loss: 0.345741
 >> iter 83000, loss: 0.542579
 >> iter 84000, loss: 0.460434
 >> iter 85000, loss: 0.389587
 >> iter 86000, loss: 0.284973
 >> iter 87000, loss: 0.266537
 >> iter 88000, loss: 0.208749
 >> iter 89000, loss: 0.213043
 >> iter 90000, loss: 0.250480
   Number of active neurons: 4
 >> iter 91000, loss: 0.265794
 >> iter 92000, loss: 0.340214
 >> iter 93000, loss: 0.369624
 >> iter 94000, loss: 0.206311
 >> iter 95000, loss: 0.294583
 >> iter 96000, loss: 0.356266
 >> iter 97000, loss: 0.384215
 >> iter 98000, loss: 0.317948
 >> iter 99000, loss: 0.399236
 >> iter 100000, loss: 0.293710
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.119816
 >> iter 2000, loss: 12.449852
 >> iter 3000, loss: 6.145050
 >> iter 4000, loss: 2.865056
 >> iter 5000, loss: 1.766072
 >> iter 6000, loss: 0.965574
 >> iter 7000, loss: 0.720352
 >> iter 8000, loss: 0.454161
 >> iter 9000, loss: 0.462031
 >> iter 10000, loss: 0.319207
   Number of active neurons: 6
 >> iter 11000, loss: 0.593281
 >> iter 12000, loss: 0.375235
 >> iter 13000, loss: 0.351768
 >> iter 14000, loss: 0.314393
 >> iter 15000, loss: 0.299979
 >> iter 16000, loss: 0.430571
 >> iter 17000, loss: 0.345730
 >> iter 18000, loss: 0.348283
 >> iter 19000, loss: 0.418753
 >> iter 20000, loss: 0.264426
   Number of active neurons: 6
 >> iter 21000, loss: 0.281633
 >> iter 22000, loss: 0.383458
 >> iter 23000, loss: 0.471592
 >> iter 24000, loss: 0.347075
 >> iter 25000, loss: 0.244748
 >> iter 26000, loss: 0.309972
 >> iter 27000, loss: 0.264448
 >> iter 28000, loss: 0.262099
 >> iter 29000, loss: 0.199358
 >> iter 30000, loss: 0.326760
   Number of active neurons: 6
 >> iter 31000, loss: 0.353120
 >> iter 32000, loss: 0.320158
 >> iter 33000, loss: 0.349506
 >> iter 34000, loss: 0.443992
 >> iter 35000, loss: 0.440691
 >> iter 36000, loss: 0.611582
 >> iter 37000, loss: 0.516617
 >> iter 38000, loss: 0.489799
 >> iter 39000, loss: 0.385125
 >> iter 40000, loss: 0.371822
   Number of active neurons: 5
 >> iter 41000, loss: 0.381535
 >> iter 42000, loss: 0.305505
 >> iter 43000, loss: 0.521666
 >> iter 44000, loss: 0.491254
 >> iter 45000, loss: 0.438589
 >> iter 46000, loss: 0.426409
 >> iter 47000, loss: 0.393187
 >> iter 48000, loss: 0.406285
 >> iter 49000, loss: 0.328611
 >> iter 50000, loss: 0.342426
   Number of active neurons: 5
 >> iter 51000, loss: 0.352684
 >> iter 52000, loss: 0.342444
 >> iter 53000, loss: 0.354037
 >> iter 54000, loss: 0.381724
 >> iter 55000, loss: 0.327683
 >> iter 56000, loss: 0.548201
 >> iter 57000, loss: 0.654666
 >> iter 58000, loss: 0.431568
 >> iter 59000, loss: 0.479181
 >> iter 60000, loss: 0.343255
   Number of active neurons: 4
 >> iter 61000, loss: 0.375302
 >> iter 62000, loss: 0.344847
 >> iter 63000, loss: 0.312293
 >> iter 64000, loss: 0.444351
 >> iter 65000, loss: 0.526530
 >> iter 66000, loss: 0.407321
 >> iter 67000, loss: 0.428441
 >> iter 68000, loss: 0.350911
 >> iter 69000, loss: 0.430882
 >> iter 70000, loss: 0.501857
   Number of active neurons: 4
 >> iter 71000, loss: 0.467483
 >> iter 72000, loss: 0.530464
 >> iter 73000, loss: 0.341621
 >> iter 74000, loss: 0.422072
 >> iter 75000, loss: 0.391208
 >> iter 76000, loss: 0.386666
 >> iter 77000, loss: 0.554001
 >> iter 78000, loss: 0.337782
 >> iter 79000, loss: 0.298608
 >> iter 80000, loss: 0.351131
   Number of active neurons: 4
 >> iter 81000, loss: 0.380062
 >> iter 82000, loss: 0.358751
 >> iter 83000, loss: 0.305803
 >> iter 84000, loss: 0.336563
 >> iter 85000, loss: 0.292779
 >> iter 86000, loss: 0.535682
 >> iter 87000, loss: 0.362750
 >> iter 88000, loss: 0.385784
 >> iter 89000, loss: 0.342122
 >> iter 90000, loss: 0.284073
   Number of active neurons: 4
 >> iter 91000, loss: 0.429564
 >> iter 92000, loss: 0.386153
 >> iter 93000, loss: 0.445187
 >> iter 94000, loss: 0.466006
 >> iter 95000, loss: 0.416637
 >> iter 96000, loss: 0.359853
 >> iter 97000, loss: 0.378191
 >> iter 98000, loss: 0.399610
 >> iter 99000, loss: 0.309038
 >> iter 100000, loss: 0.266642
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 12.6124925005
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.247329
 >> iter 2000, loss: 13.084226
 >> iter 3000, loss: 6.600369
 >> iter 4000, loss: 3.237944
 >> iter 5000, loss: 1.761619
 >> iter 6000, loss: 1.050159
 >> iter 7000, loss: 0.774304
 >> iter 8000, loss: 0.576111
 >> iter 9000, loss: 0.479320
 >> iter 10000, loss: 0.578856
   Number of active neurons: 5
 >> iter 11000, loss: 0.529404
 >> iter 12000, loss: 0.556292
 >> iter 13000, loss: 0.453545
 >> iter 14000, loss: 0.505786
 >> iter 15000, loss: 0.388932
 >> iter 16000, loss: 0.526937
 >> iter 17000, loss: 0.523554
 >> iter 18000, loss: 0.465849
 >> iter 19000, loss: 0.441280
 >> iter 20000, loss: 0.522714
   Number of active neurons: 5
 >> iter 21000, loss: 0.446182
 >> iter 22000, loss: 0.550188
 >> iter 23000, loss: 0.420297
 >> iter 24000, loss: 0.331493
 >> iter 25000, loss: 0.310056
 >> iter 26000, loss: 0.583346
 >> iter 27000, loss: 0.366688
 >> iter 28000, loss: 0.329011
 >> iter 29000, loss: 0.375993
 >> iter 30000, loss: 0.308238
   Number of active neurons: 5
 >> iter 31000, loss: 0.298976
 >> iter 32000, loss: 0.549562
 >> iter 33000, loss: 0.365597
 >> iter 34000, loss: 0.483070
 >> iter 35000, loss: 0.385535
 >> iter 36000, loss: 0.515177
 >> iter 37000, loss: 0.385896
 >> iter 38000, loss: 0.492131
 >> iter 39000, loss: 0.592296
 >> iter 40000, loss: 0.495399
   Number of active neurons: 5
 >> iter 41000, loss: 0.492577
 >> iter 42000, loss: 0.407481
 >> iter 43000, loss: 0.537824
 >> iter 44000, loss: 0.527405
 >> iter 45000, loss: 0.364602
 >> iter 46000, loss: 0.462962
 >> iter 47000, loss: 0.378665
 >> iter 48000, loss: 0.384956
 >> iter 49000, loss: 0.287014
 >> iter 50000, loss: 0.445941
   Number of active neurons: 5
 >> iter 51000, loss: 0.511841
 >> iter 52000, loss: 0.382199
 >> iter 53000, loss: 0.361409
 >> iter 54000, loss: 0.364276
 >> iter 55000, loss: 0.347672
 >> iter 56000, loss: 0.407380
 >> iter 57000, loss: 0.271840
 >> iter 58000, loss: 0.445668
 >> iter 59000, loss: 0.373546
 >> iter 60000, loss: 0.298291
   Number of active neurons: 5
 >> iter 61000, loss: 0.313527
 >> iter 62000, loss: 0.397165
 >> iter 63000, loss: 0.377472
 >> iter 64000, loss: 0.276913
 >> iter 65000, loss: 0.273466
 >> iter 66000, loss: 0.280061
 >> iter 67000, loss: 0.298506
 >> iter 68000, loss: 0.406003
 >> iter 69000, loss: 0.412677
 >> iter 70000, loss: 0.385271
   Number of active neurons: 5
 >> iter 71000, loss: 0.571503
 >> iter 72000, loss: 0.519461
 >> iter 73000, loss: 0.304970
 >> iter 74000, loss: 0.626490
 >> iter 75000, loss: 0.594138
 >> iter 76000, loss: 0.401068
 >> iter 77000, loss: 0.586093
 >> iter 78000, loss: 0.501747
 >> iter 79000, loss: 0.604673
 >> iter 80000, loss: 0.561257
   Number of active neurons: 5
 >> iter 81000, loss: 0.529696
 >> iter 82000, loss: 0.480481
 >> iter 83000, loss: 0.551179
 >> iter 84000, loss: 0.330125
 >> iter 85000, loss: 0.438602
 >> iter 86000, loss: 0.513209
 >> iter 87000, loss: 0.515480
 >> iter 88000, loss: 0.425033
 >> iter 89000, loss: 0.446627
 >> iter 90000, loss: 0.547653
   Number of active neurons: 4
 >> iter 91000, loss: 0.428517
 >> iter 92000, loss: 0.465173
 >> iter 93000, loss: 0.428548
 >> iter 94000, loss: 0.487097
 >> iter 95000, loss: 0.376063
 >> iter 96000, loss: 0.690713
 >> iter 97000, loss: 0.511176
 >> iter 98000, loss: 0.466397
 >> iter 99000, loss: 0.341633
 >> iter 100000, loss: 0.338732
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.074975
 >> iter 2000, loss: 12.136041
 >> iter 3000, loss: 5.882126
 >> iter 4000, loss: 2.683442
 >> iter 5000, loss: 1.508603
 >> iter 6000, loss: 0.921943
 >> iter 7000, loss: 0.874220
 >> iter 8000, loss: 0.759959
 >> iter 9000, loss: 0.601067
 >> iter 10000, loss: 0.549087
   Number of active neurons: 8
 >> iter 11000, loss: 0.591683
 >> iter 12000, loss: 0.325736
 >> iter 13000, loss: 0.276665
 >> iter 14000, loss: 0.256665
 >> iter 15000, loss: 0.260702
 >> iter 16000, loss: 0.273745
 >> iter 17000, loss: 0.278023
 >> iter 18000, loss: 0.292881
 >> iter 19000, loss: 0.359733
 >> iter 20000, loss: 0.328087
   Number of active neurons: 8
 >> iter 21000, loss: 0.271255
 >> iter 22000, loss: 0.288964
 >> iter 23000, loss: 0.222157
 >> iter 24000, loss: 0.152357
 >> iter 25000, loss: 0.154320
 >> iter 26000, loss: 0.259045
 >> iter 27000, loss: 0.279597
 >> iter 28000, loss: 0.286819
 >> iter 29000, loss: 0.161139
 >> iter 30000, loss: 0.128341
   Number of active neurons: 8
 >> iter 31000, loss: 0.175749
 >> iter 32000, loss: 0.144883
 >> iter 33000, loss: 0.219070
 >> iter 34000, loss: 0.244690
 >> iter 35000, loss: 0.253910
 >> iter 36000, loss: 0.159104
 >> iter 37000, loss: 0.327257
 >> iter 38000, loss: 0.439610
 >> iter 39000, loss: 0.358223
 >> iter 40000, loss: 0.236714
   Number of active neurons: 7
 >> iter 41000, loss: 0.199301
 >> iter 42000, loss: 0.201610
 >> iter 43000, loss: 0.211979
 >> iter 44000, loss: 0.258920
 >> iter 45000, loss: 0.227336
 >> iter 46000, loss: 0.298213
 >> iter 47000, loss: 0.195332
 >> iter 48000, loss: 0.246599
 >> iter 49000, loss: 0.292372
 >> iter 50000, loss: 0.312846
   Number of active neurons: 7
 >> iter 51000, loss: 0.306456
 >> iter 52000, loss: 0.402943
 >> iter 53000, loss: 0.356271
 >> iter 54000, loss: 0.201416
 >> iter 55000, loss: 0.180035
 >> iter 56000, loss: 0.235652
 >> iter 57000, loss: 0.252760
 >> iter 58000, loss: 0.136599
 >> iter 59000, loss: 0.190538
 >> iter 60000, loss: 0.292882
   Number of active neurons: 6
 >> iter 61000, loss: 0.190402
 >> iter 62000, loss: 0.161640
 >> iter 63000, loss: 0.173779
 >> iter 64000, loss: 0.238847
 >> iter 65000, loss: 0.344640
 >> iter 66000, loss: 0.227392
 >> iter 67000, loss: 0.213052
 >> iter 68000, loss: 0.174777
 >> iter 69000, loss: 0.206038
 >> iter 70000, loss: 0.368516
   Number of active neurons: 5
 >> iter 71000, loss: 0.278881
 >> iter 72000, loss: 0.245044
 >> iter 73000, loss: 0.208801
 >> iter 74000, loss: 0.254694
 >> iter 75000, loss: 0.211522
 >> iter 76000, loss: 0.228327
 >> iter 77000, loss: 0.310326
 >> iter 78000, loss: 0.367707
 >> iter 79000, loss: 0.204075
 >> iter 80000, loss: 0.255127
   Number of active neurons: 4
 >> iter 81000, loss: 0.180896
 >> iter 82000, loss: 0.168342
 >> iter 83000, loss: 0.207256
 >> iter 84000, loss: 0.176869
 >> iter 85000, loss: 0.201735
 >> iter 86000, loss: 0.274705
 >> iter 87000, loss: 0.231184
 >> iter 88000, loss: 0.155534
 >> iter 89000, loss: 0.097030
 >> iter 90000, loss: 0.147679
   Number of active neurons: 4
 >> iter 91000, loss: 0.211380
 >> iter 92000, loss: 0.201355
 >> iter 93000, loss: 0.168032
 >> iter 94000, loss: 0.190313
 >> iter 95000, loss: 0.340374
 >> iter 96000, loss: 0.273232
 >> iter 97000, loss: 0.201359
 >> iter 98000, loss: 0.136629
 >> iter 99000, loss: 0.185736
 >> iter 100000, loss: 0.155283
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.023604
 >> iter 2000, loss: 11.257744
 >> iter 3000, loss: 5.271797
 >> iter 4000, loss: 2.652447
 >> iter 5000, loss: 1.234655
 >> iter 6000, loss: 0.755195
 >> iter 7000, loss: 0.477208
 >> iter 8000, loss: 0.556676
 >> iter 9000, loss: 0.319519
 >> iter 10000, loss: 0.356097
   Number of active neurons: 5
 >> iter 11000, loss: 0.303037
 >> iter 12000, loss: 0.276256
 >> iter 13000, loss: 0.203051
 >> iter 14000, loss: 0.174699
 >> iter 15000, loss: 0.185466
 >> iter 16000, loss: 0.135261
 >> iter 17000, loss: 0.163252
 >> iter 18000, loss: 0.383743
 >> iter 19000, loss: 0.398780
 >> iter 20000, loss: 0.267900
   Number of active neurons: 5
 >> iter 21000, loss: 0.282317
 >> iter 22000, loss: 0.374536
 >> iter 23000, loss: 0.416052
 >> iter 24000, loss: 0.340227
 >> iter 25000, loss: 0.371460
 >> iter 26000, loss: 0.271763
 >> iter 27000, loss: 0.369720
 >> iter 28000, loss: 0.255546
 >> iter 29000, loss: 0.339197
 >> iter 30000, loss: 0.397925
   Number of active neurons: 5
 >> iter 31000, loss: 0.496701
 >> iter 32000, loss: 0.359710
 >> iter 33000, loss: 0.341086
 >> iter 34000, loss: 0.464003
 >> iter 35000, loss: 0.400759
 >> iter 36000, loss: 0.287304
 >> iter 37000, loss: 0.295150
 >> iter 38000, loss: 0.232104
 >> iter 39000, loss: 0.507536
 >> iter 40000, loss: 0.316309
   Number of active neurons: 5
 >> iter 41000, loss: 0.471236
 >> iter 42000, loss: 0.341990
 >> iter 43000, loss: 0.410136
 >> iter 44000, loss: 0.390090
 >> iter 45000, loss: 0.358837
 >> iter 46000, loss: 0.284402
 >> iter 47000, loss: 0.215988
 >> iter 48000, loss: 0.228990
 >> iter 49000, loss: 0.149679
 >> iter 50000, loss: 0.222534
   Number of active neurons: 5
 >> iter 51000, loss: 0.298082
 >> iter 52000, loss: 0.344284
 >> iter 53000, loss: 0.290825
 >> iter 54000, loss: 0.215408
 >> iter 55000, loss: 0.404930
 >> iter 56000, loss: 0.318196
 >> iter 57000, loss: 0.237008
 >> iter 58000, loss: 0.308887
 >> iter 59000, loss: 0.216501
 >> iter 60000, loss: 0.168836
   Number of active neurons: 5
 >> iter 61000, loss: 0.292493
 >> iter 62000, loss: 0.406527
 >> iter 63000, loss: 0.319739
 >> iter 64000, loss: 0.237483
 >> iter 65000, loss: 0.239760
 >> iter 66000, loss: 0.208110
 >> iter 67000, loss: 0.228661
 >> iter 68000, loss: 0.195060
 >> iter 69000, loss: 0.272966
 >> iter 70000, loss: 0.479473
   Number of active neurons: 5
 >> iter 71000, loss: 0.370323
 >> iter 72000, loss: 0.176787
 >> iter 73000, loss: 0.340207
 >> iter 74000, loss: 0.289589
 >> iter 75000, loss: 0.370175
 >> iter 76000, loss: 0.304909
 >> iter 77000, loss: 0.354873
 >> iter 78000, loss: 0.297812
 >> iter 79000, loss: 0.215739
 >> iter 80000, loss: 0.240473
   Number of active neurons: 5
 >> iter 81000, loss: 0.292192
 >> iter 82000, loss: 0.289869
 >> iter 83000, loss: 0.218339
 >> iter 84000, loss: 0.157192
 >> iter 85000, loss: 0.118432
 >> iter 86000, loss: 0.138245
 >> iter 87000, loss: 0.235246
 >> iter 88000, loss: 0.275586
 >> iter 89000, loss: 0.245598
 >> iter 90000, loss: 0.189255
   Number of active neurons: 5
 >> iter 91000, loss: 0.208317
 >> iter 92000, loss: 0.274951
 >> iter 93000, loss: 0.182857
 >> iter 94000, loss: 0.213691
 >> iter 95000, loss: 0.188511
 >> iter 96000, loss: 0.190209
 >> iter 97000, loss: 0.184464
 >> iter 98000, loss: 0.125354
 >> iter 99000, loss: 0.238044
 >> iter 100000, loss: 0.212079
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 19.128531
 >> iter 2000, loss: 13.014896
 >> iter 3000, loss: 9.615069
 >> iter 4000, loss: 7.663699
 >> iter 5000, loss: 5.416378
 >> iter 6000, loss: 3.235532
 >> iter 7000, loss: 2.344347
 >> iter 8000, loss: 1.589380
 >> iter 9000, loss: 1.101512
 >> iter 10000, loss: 1.041612
   Number of active neurons: 8
 >> iter 11000, loss: 0.776449
 >> iter 12000, loss: 0.744942
 >> iter 13000, loss: 0.587906
 >> iter 14000, loss: 0.618699
 >> iter 15000, loss: 0.558498
 >> iter 16000, loss: 0.442271
 >> iter 17000, loss: 0.337871
 >> iter 18000, loss: 0.511252
 >> iter 19000, loss: 0.485704
 >> iter 20000, loss: 0.369234
   Number of active neurons: 8
 >> iter 21000, loss: 0.547514
 >> iter 22000, loss: 0.392622
 >> iter 23000, loss: 0.584889
 >> iter 24000, loss: 0.395373
 >> iter 25000, loss: 0.541889
 >> iter 26000, loss: 0.622396
 >> iter 27000, loss: 0.527636
 >> iter 28000, loss: 0.420850
 >> iter 29000, loss: 0.466463
 >> iter 30000, loss: 0.403909
   Number of active neurons: 8
 >> iter 31000, loss: 0.446703
 >> iter 32000, loss: 0.370464
 >> iter 33000, loss: 0.346755
 >> iter 34000, loss: 0.479793
 >> iter 35000, loss: 0.557911
 >> iter 36000, loss: 0.541009
 >> iter 37000, loss: 0.579651
 >> iter 38000, loss: 0.515348
 >> iter 39000, loss: 0.553333
 >> iter 40000, loss: 0.385925
   Number of active neurons: 7
 >> iter 41000, loss: 0.490823
 >> iter 42000, loss: 0.394403
 >> iter 43000, loss: 0.563656
 >> iter 44000, loss: 0.446490
 >> iter 45000, loss: 0.539184
 >> iter 46000, loss: 0.338815
 >> iter 47000, loss: 0.350949
 >> iter 48000, loss: 0.308365
 >> iter 49000, loss: 0.349370
 >> iter 50000, loss: 0.350267
   Number of active neurons: 7
 >> iter 51000, loss: 0.476158
 >> iter 52000, loss: 0.379219
 >> iter 53000, loss: 0.414440
 >> iter 54000, loss: 0.262767
 >> iter 55000, loss: 0.332463
 >> iter 56000, loss: 0.259493
 >> iter 57000, loss: 0.274912
 >> iter 58000, loss: 0.357272
 >> iter 59000, loss: 0.364937
 >> iter 60000, loss: 0.393861
   Number of active neurons: 5
 >> iter 61000, loss: 0.410349
 >> iter 62000, loss: 0.390241
 >> iter 63000, loss: 0.429722
 >> iter 64000, loss: 0.412206
 >> iter 65000, loss: 0.400116
 >> iter 66000, loss: 0.385829
 >> iter 67000, loss: 0.430910
 >> iter 68000, loss: 0.454264
 >> iter 69000, loss: 0.325364
 >> iter 70000, loss: 0.321946
   Number of active neurons: 5
 >> iter 71000, loss: 0.453507
 >> iter 72000, loss: 0.428347
 >> iter 73000, loss: 0.458402
 >> iter 74000, loss: 0.384809
 >> iter 75000, loss: 0.312078
 >> iter 76000, loss: 0.403501
 >> iter 77000, loss: 0.432974
 >> iter 78000, loss: 0.421277
 >> iter 79000, loss: 0.460840
 >> iter 80000, loss: 0.375653
   Number of active neurons: 5
 >> iter 81000, loss: 0.456819
 >> iter 82000, loss: 0.331630
 >> iter 83000, loss: 0.470088
 >> iter 84000, loss: 0.457335
 >> iter 85000, loss: 0.367563
 >> iter 86000, loss: 0.321332
 >> iter 87000, loss: 0.457447
 >> iter 88000, loss: 0.415255
 >> iter 89000, loss: 0.402953
 >> iter 90000, loss: 0.464908
   Number of active neurons: 5
 >> iter 91000, loss: 0.368490
 >> iter 92000, loss: 0.385334
 >> iter 93000, loss: 0.379527
 >> iter 94000, loss: 0.505870
 >> iter 95000, loss: 0.430928
 >> iter 96000, loss: 0.361282
 >> iter 97000, loss: 0.484184
 >> iter 98000, loss: 0.419014
 >> iter 99000, loss: 0.385189
 >> iter 100000, loss: 0.295607
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.419680
 >> iter 2000, loss: 11.504965
 >> iter 3000, loss: 4.892681
 >> iter 4000, loss: 2.107143
 >> iter 5000, loss: 0.941470
 >> iter 6000, loss: 0.497525
 >> iter 7000, loss: 0.341124
 >> iter 8000, loss: 0.219307
 >> iter 9000, loss: 0.275458
 >> iter 10000, loss: 0.246702
   Number of active neurons: 7
 >> iter 11000, loss: 0.409010
 >> iter 12000, loss: 0.397643
 >> iter 13000, loss: 0.368998
 >> iter 14000, loss: 0.333882
 >> iter 15000, loss: 0.340103
 >> iter 16000, loss: 0.246015
 >> iter 17000, loss: 0.262623
 >> iter 18000, loss: 0.322122
 >> iter 19000, loss: 0.248440
 >> iter 20000, loss: 0.301175
   Number of active neurons: 7
 >> iter 21000, loss: 0.443997
 >> iter 22000, loss: 0.263386
 >> iter 23000, loss: 0.208410
 >> iter 24000, loss: 0.311784
 >> iter 25000, loss: 0.240977
 >> iter 26000, loss: 0.225048
 >> iter 27000, loss: 0.232122
 >> iter 28000, loss: 0.176310
 >> iter 29000, loss: 0.289604
 >> iter 30000, loss: 0.262598
   Number of active neurons: 7
 >> iter 31000, loss: 0.242598
 >> iter 32000, loss: 0.241125
 >> iter 33000, loss: 0.248550
 >> iter 34000, loss: 0.444031
 >> iter 35000, loss: 0.331549
 >> iter 36000, loss: 0.314307
 >> iter 37000, loss: 0.370679
 >> iter 38000, loss: 0.319553
 >> iter 39000, loss: 0.402902
 >> iter 40000, loss: 0.271724
   Number of active neurons: 7
 >> iter 41000, loss: 0.220210
 >> iter 42000, loss: 0.331784
 >> iter 43000, loss: 0.240553
 >> iter 44000, loss: 0.266423
 >> iter 45000, loss: 0.199172
 >> iter 46000, loss: 0.344250
 >> iter 47000, loss: 0.252877
 >> iter 48000, loss: 0.242169
 >> iter 49000, loss: 0.180160
 >> iter 50000, loss: 0.141683
   Number of active neurons: 7
 >> iter 51000, loss: 0.137347
 >> iter 52000, loss: 0.195948
 >> iter 53000, loss: 0.302995
 >> iter 54000, loss: 0.205407
 >> iter 55000, loss: 0.167643
 >> iter 56000, loss: 0.320561
 >> iter 57000, loss: 0.230766
 >> iter 58000, loss: 0.201728
 >> iter 59000, loss: 0.235531
 >> iter 60000, loss: 0.215047
   Number of active neurons: 7
 >> iter 61000, loss: 0.306938
 >> iter 62000, loss: 0.270355
 >> iter 63000, loss: 0.326300
 >> iter 64000, loss: 0.228481
 >> iter 65000, loss: 0.178490
 >> iter 66000, loss: 0.204289
 >> iter 67000, loss: 0.198885
 >> iter 68000, loss: 0.164299
 >> iter 69000, loss: 0.394588
 >> iter 70000, loss: 0.348634
   Number of active neurons: 7
 >> iter 71000, loss: 0.256469
 >> iter 72000, loss: 0.336042
 >> iter 73000, loss: 0.277571
 >> iter 74000, loss: 0.252536
 >> iter 75000, loss: 0.223971
 >> iter 76000, loss: 0.266771
 >> iter 77000, loss: 0.202030
 >> iter 78000, loss: 0.177756
 >> iter 79000, loss: 0.304207
 >> iter 80000, loss: 0.373957
   Number of active neurons: 6
 >> iter 81000, loss: 0.249198
 >> iter 82000, loss: 0.263285
 >> iter 83000, loss: 0.259212
 >> iter 84000, loss: 0.165025
 >> iter 85000, loss: 0.154755
 >> iter 86000, loss: 0.287600
 >> iter 87000, loss: 0.335686
 >> iter 88000, loss: 0.264793
 >> iter 89000, loss: 0.284306
 >> iter 90000, loss: 0.192995
   Number of active neurons: 6
 >> iter 91000, loss: 0.125943
 >> iter 92000, loss: 0.327882
 >> iter 93000, loss: 0.180775
 >> iter 94000, loss: 0.287546
 >> iter 95000, loss: 0.268195
 >> iter 96000, loss: 0.334684
 >> iter 97000, loss: 0.345823
 >> iter 98000, loss: 0.328899
 >> iter 99000, loss: 0.186873
 >> iter 100000, loss: 0.276575
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 19.173038
 >> iter 2000, loss: 12.123823
 >> iter 3000, loss: 6.286262
 >> iter 4000, loss: 3.042315
 >> iter 5000, loss: 1.936207
 >> iter 6000, loss: 1.086364
 >> iter 7000, loss: 0.938432
 >> iter 8000, loss: 0.658877
 >> iter 9000, loss: 0.569482
 >> iter 10000, loss: 0.679359
   Number of active neurons: 6
 >> iter 11000, loss: 0.580817
 >> iter 12000, loss: 0.525474
 >> iter 13000, loss: 0.568461
 >> iter 14000, loss: 0.481263
 >> iter 15000, loss: 0.537007
 >> iter 16000, loss: 0.424389
 >> iter 17000, loss: 0.405587
 >> iter 18000, loss: 0.410095
 >> iter 19000, loss: 0.490357
 >> iter 20000, loss: 0.628099
   Number of active neurons: 6
 >> iter 21000, loss: 0.396367
 >> iter 22000, loss: 0.395858
 >> iter 23000, loss: 0.313415
 >> iter 24000, loss: 0.320800
 >> iter 25000, loss: 0.430290
 >> iter 26000, loss: 0.326730
 >> iter 27000, loss: 0.320797
 >> iter 28000, loss: 0.407138
 >> iter 29000, loss: 0.313710
 >> iter 30000, loss: 0.508694
   Number of active neurons: 6
 >> iter 31000, loss: 0.348298
 >> iter 32000, loss: 0.310643
 >> iter 33000, loss: 0.429008
 >> iter 34000, loss: 0.525963
 >> iter 35000, loss: 0.397861
 >> iter 36000, loss: 0.337472
 >> iter 37000, loss: 0.510561
 >> iter 38000, loss: 0.524738
 >> iter 39000, loss: 0.432184
 >> iter 40000, loss: 0.369071
   Number of active neurons: 6
 >> iter 41000, loss: 0.361116
 >> iter 42000, loss: 0.293575
 >> iter 43000, loss: 0.391981
 >> iter 44000, loss: 0.344574
 >> iter 45000, loss: 0.347672
 >> iter 46000, loss: 0.300485
 >> iter 47000, loss: 0.351929
 >> iter 48000, loss: 0.306729
 >> iter 49000, loss: 0.411226
 >> iter 50000, loss: 0.411794
   Number of active neurons: 4
 >> iter 51000, loss: 0.408773
 >> iter 52000, loss: 0.352394
 >> iter 53000, loss: 0.434434
 >> iter 54000, loss: 0.388975
 >> iter 55000, loss: 0.271904
 >> iter 56000, loss: 0.312640
 >> iter 57000, loss: 0.263830
 >> iter 58000, loss: 0.341350
 >> iter 59000, loss: 0.400886
 >> iter 60000, loss: 0.288144
   Number of active neurons: 4
 >> iter 61000, loss: 0.502716
 >> iter 62000, loss: 0.393958
 >> iter 63000, loss: 0.293397
 >> iter 64000, loss: 0.394579
 >> iter 65000, loss: 0.370743
 >> iter 66000, loss: 0.475357
 >> iter 67000, loss: 0.439882
 >> iter 68000, loss: 0.419597
 >> iter 69000, loss: 0.480612
 >> iter 70000, loss: 0.387273
   Number of active neurons: 4
 >> iter 71000, loss: 0.295593
 >> iter 72000, loss: 0.329848
 >> iter 73000, loss: 0.420383
 >> iter 74000, loss: 0.335644
 >> iter 75000, loss: 0.485229
 >> iter 76000, loss: 0.597622
 >> iter 77000, loss: 0.389063
 >> iter 78000, loss: 0.394524
 >> iter 79000, loss: 0.309724
 >> iter 80000, loss: 0.456921
   Number of active neurons: 4
 >> iter 81000, loss: 0.317899
 >> iter 82000, loss: 0.342566
 >> iter 83000, loss: 0.373456
 >> iter 84000, loss: 0.348892
 >> iter 85000, loss: 0.336399
 >> iter 86000, loss: 0.298517
 >> iter 87000, loss: 0.237908
 >> iter 88000, loss: 0.323556
 >> iter 89000, loss: 0.408241
 >> iter 90000, loss: 0.301333
   Number of active neurons: 4
 >> iter 91000, loss: 0.344110
 >> iter 92000, loss: 0.282925
 >> iter 93000, loss: 0.360593
 >> iter 94000, loss: 0.259031
 >> iter 95000, loss: 0.209964
 >> iter 96000, loss: 0.277773
 >> iter 97000, loss: 0.491408
 >> iter 98000, loss: 0.348295
 >> iter 99000, loss: 0.427342
 >> iter 100000, loss: 0.423443
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 10.6126258249
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.109667
 >> iter 2000, loss: 11.125600
 >> iter 3000, loss: 5.217450
 >> iter 4000, loss: 2.645824
 >> iter 5000, loss: 1.505336
 >> iter 6000, loss: 1.063254
 >> iter 7000, loss: 0.913962
 >> iter 8000, loss: 0.616902
 >> iter 9000, loss: 0.637810
 >> iter 10000, loss: 0.445607
   Number of active neurons: 6
 >> iter 11000, loss: 0.442455
 >> iter 12000, loss: 0.392440
 >> iter 13000, loss: 0.527518
 >> iter 14000, loss: 0.632718
 >> iter 15000, loss: 0.523498
 >> iter 16000, loss: 0.507962
 >> iter 17000, loss: 0.591451
 >> iter 18000, loss: 0.569856
 >> iter 19000, loss: 0.441705
 >> iter 20000, loss: 0.655250
   Number of active neurons: 6
 >> iter 21000, loss: 0.670070
 >> iter 22000, loss: 0.408816
 >> iter 23000, loss: 0.401180
 >> iter 24000, loss: 0.395201
 >> iter 25000, loss: 0.416702
 >> iter 26000, loss: 0.587516
 >> iter 27000, loss: 0.369723
 >> iter 28000, loss: 0.463986
 >> iter 29000, loss: 0.689315
 >> iter 30000, loss: 0.471629
   Number of active neurons: 6
 >> iter 31000, loss: 0.381557
 >> iter 32000, loss: 0.338993
 >> iter 33000, loss: 0.365378
 >> iter 34000, loss: 0.520463
 >> iter 35000, loss: 0.488531
 >> iter 36000, loss: 0.345969
 >> iter 37000, loss: 0.566407
 >> iter 38000, loss: 0.608681
 >> iter 39000, loss: 0.624691
 >> iter 40000, loss: 0.654662
   Number of active neurons: 6
 >> iter 41000, loss: 0.550771
 >> iter 42000, loss: 0.414168
 >> iter 43000, loss: 0.473343
 >> iter 44000, loss: 0.470318
 >> iter 45000, loss: 0.521888
 >> iter 46000, loss: 0.516936
 >> iter 47000, loss: 0.547860
 >> iter 48000, loss: 0.469051
 >> iter 49000, loss: 0.398080
 >> iter 50000, loss: 0.344957
   Number of active neurons: 6
 >> iter 51000, loss: 0.477923
 >> iter 52000, loss: 0.341468
 >> iter 53000, loss: 0.406270
 >> iter 54000, loss: 0.482581
 >> iter 55000, loss: 0.537495
 >> iter 56000, loss: 0.486670
 >> iter 57000, loss: 0.543409
 >> iter 58000, loss: 0.559672
 >> iter 59000, loss: 0.283510
 >> iter 60000, loss: 0.464608
   Number of active neurons: 6
 >> iter 61000, loss: 0.429453
 >> iter 62000, loss: 0.412381
 >> iter 63000, loss: 0.488729
 >> iter 64000, loss: 0.449577
 >> iter 65000, loss: 0.516949
 >> iter 66000, loss: 0.598286
 >> iter 67000, loss: 0.420389
 >> iter 68000, loss: 0.316747
 >> iter 69000, loss: 0.348127
 >> iter 70000, loss: 0.385646
   Number of active neurons: 6
 >> iter 71000, loss: 0.551420
 >> iter 72000, loss: 0.474746
 >> iter 73000, loss: 0.469891
 >> iter 74000, loss: 0.376135
 >> iter 75000, loss: 0.398890
 >> iter 76000, loss: 0.374863
 >> iter 77000, loss: 0.410653
 >> iter 78000, loss: 0.499320
 >> iter 79000, loss: 0.476475
 >> iter 80000, loss: 0.483952
   Number of active neurons: 6
 >> iter 81000, loss: 0.710673
 >> iter 82000, loss: 0.595146
 >> iter 83000, loss: 0.476030
 >> iter 84000, loss: 0.523450
 >> iter 85000, loss: 0.427045
 >> iter 86000, loss: 0.628246
 >> iter 87000, loss: 0.624497
 >> iter 88000, loss: 0.559727
 >> iter 89000, loss: 0.447792
 >> iter 90000, loss: 0.302928
   Number of active neurons: 6
 >> iter 91000, loss: 0.708254
 >> iter 92000, loss: 0.518677
 >> iter 93000, loss: 0.534704
 >> iter 94000, loss: 0.378003
 >> iter 95000, loss: 0.457241
 >> iter 96000, loss: 0.528255
 >> iter 97000, loss: 0.699264
 >> iter 98000, loss: 0.571960
 >> iter 99000, loss: 0.485942
 >> iter 100000, loss: 0.482798
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.444235
 >> iter 2000, loss: 14.536339
 >> iter 3000, loss: 11.149305
 >> iter 4000, loss: 9.048487
 >> iter 5000, loss: 8.161863
 >> iter 6000, loss: 7.239956
 >> iter 7000, loss: 6.983332
 >> iter 8000, loss: 6.780340
 >> iter 9000, loss: 6.625571
 >> iter 10000, loss: 5.496306
   Number of active neurons: 4
 >> iter 11000, loss: 2.713132
 >> iter 12000, loss: 1.421849
 >> iter 13000, loss: 0.906639
 >> iter 14000, loss: 0.758216
 >> iter 15000, loss: 0.684101
 >> iter 16000, loss: 0.553174
 >> iter 17000, loss: 0.622471
 >> iter 18000, loss: 0.560478
 >> iter 19000, loss: 0.712689
 >> iter 20000, loss: 0.513309
   Number of active neurons: 4
 >> iter 21000, loss: 0.314417
 >> iter 22000, loss: 0.284534
 >> iter 23000, loss: 0.467350
 >> iter 24000, loss: 0.413398
 >> iter 25000, loss: 0.540805
 >> iter 26000, loss: 0.417141
 >> iter 27000, loss: 0.379538
 >> iter 28000, loss: 0.380056
 >> iter 29000, loss: 0.365785
 >> iter 30000, loss: 0.446186
   Number of active neurons: 4
 >> iter 31000, loss: 0.499915
 >> iter 32000, loss: 0.430059
 >> iter 33000, loss: 0.295688
 >> iter 34000, loss: 0.329942
 >> iter 35000, loss: 0.422604
 >> iter 36000, loss: 0.433456
 >> iter 37000, loss: 0.339262
 >> iter 38000, loss: 0.357532
 >> iter 39000, loss: 0.615746
 >> iter 40000, loss: 0.591123
   Number of active neurons: 4
 >> iter 41000, loss: 0.374221
 >> iter 42000, loss: 0.406684
 >> iter 43000, loss: 0.434382
 >> iter 44000, loss: 0.315970
 >> iter 45000, loss: 0.427491
 >> iter 46000, loss: 0.351012
 >> iter 47000, loss: 0.337490
 >> iter 48000, loss: 0.302899
 >> iter 49000, loss: 0.350555
 >> iter 50000, loss: 0.346848
   Number of active neurons: 4
 >> iter 51000, loss: 0.293739
 >> iter 52000, loss: 0.303775
 >> iter 53000, loss: 0.251220
 >> iter 54000, loss: 0.220485
 >> iter 55000, loss: 0.368603
 >> iter 56000, loss: 0.335220
 >> iter 57000, loss: 0.359264
 >> iter 58000, loss: 0.341764
 >> iter 59000, loss: 0.371611
 >> iter 60000, loss: 0.249222
   Number of active neurons: 4
 >> iter 61000, loss: 0.367685
 >> iter 62000, loss: 0.345145
 >> iter 63000, loss: 0.421082
 >> iter 64000, loss: 0.376088
 >> iter 65000, loss: 0.338406
 >> iter 66000, loss: 0.361986
 >> iter 67000, loss: 0.388533
 >> iter 68000, loss: 0.339170
 >> iter 69000, loss: 0.281589
 >> iter 70000, loss: 0.291160
   Number of active neurons: 4
 >> iter 71000, loss: 0.381250
 >> iter 72000, loss: 0.535884
 >> iter 73000, loss: 0.419603
 >> iter 74000, loss: 0.488204
 >> iter 75000, loss: 0.377535
 >> iter 76000, loss: 0.363442
 >> iter 77000, loss: 0.358177
 >> iter 78000, loss: 0.375716
 >> iter 79000, loss: 0.378539
 >> iter 80000, loss: 0.446621
   Number of active neurons: 4
 >> iter 81000, loss: 0.352878
 >> iter 82000, loss: 0.273286
 >> iter 83000, loss: 0.370739
 >> iter 84000, loss: 0.359834
 >> iter 85000, loss: 0.425183
 >> iter 86000, loss: 0.449608
 >> iter 87000, loss: 0.413334
 >> iter 88000, loss: 0.292775
 >> iter 89000, loss: 0.362747
 >> iter 90000, loss: 0.275370
   Number of active neurons: 4
 >> iter 91000, loss: 0.310338
 >> iter 92000, loss: 0.316341
 >> iter 93000, loss: 0.332473
 >> iter 94000, loss: 0.297124
 >> iter 95000, loss: 0.286742
 >> iter 96000, loss: 0.330610
 >> iter 97000, loss: 0.361155
 >> iter 98000, loss: 0.279308
 >> iter 99000, loss: 0.294167
 >> iter 100000, loss: 0.282930
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.300442
 >> iter 2000, loss: 15.383288
 >> iter 3000, loss: 13.356691
 >> iter 4000, loss: 8.258657
 >> iter 5000, loss: 4.258093
 >> iter 6000, loss: 2.123068
 >> iter 7000, loss: 1.316450
 >> iter 8000, loss: 0.798613
 >> iter 9000, loss: 0.660454
 >> iter 10000, loss: 0.486074
   Number of active neurons: 7
 >> iter 11000, loss: 0.304628
 >> iter 12000, loss: 0.255649
 >> iter 13000, loss: 0.297588
 >> iter 14000, loss: 0.342586
 >> iter 15000, loss: 0.262914
 >> iter 16000, loss: 0.236525
 >> iter 17000, loss: 0.234899
 >> iter 18000, loss: 0.199398
 >> iter 19000, loss: 0.239877
 >> iter 20000, loss: 0.276687
   Number of active neurons: 6
 >> iter 21000, loss: 0.352234
 >> iter 22000, loss: 0.240054
 >> iter 23000, loss: 0.330818
 >> iter 24000, loss: 0.499072
 >> iter 25000, loss: 0.460207
 >> iter 26000, loss: 0.267285
 >> iter 27000, loss: 0.157660
 >> iter 28000, loss: 0.305833
 >> iter 29000, loss: 0.261175
 >> iter 30000, loss: 0.289655
   Number of active neurons: 6
 >> iter 31000, loss: 0.286314
 >> iter 32000, loss: 0.296107
 >> iter 33000, loss: 0.294903
 >> iter 34000, loss: 0.264342
 >> iter 35000, loss: 0.310514
 >> iter 36000, loss: 0.310933
 >> iter 37000, loss: 0.236803
 >> iter 38000, loss: 0.319088
 >> iter 39000, loss: 0.398287
 >> iter 40000, loss: 0.367924
   Number of active neurons: 6
 >> iter 41000, loss: 0.428700
 >> iter 42000, loss: 0.327652
 >> iter 43000, loss: 0.268147
 >> iter 44000, loss: 0.354471
 >> iter 45000, loss: 0.324730
 >> iter 46000, loss: 0.261804
 >> iter 47000, loss: 0.229750
 >> iter 48000, loss: 0.203637
 >> iter 49000, loss: 0.291159
 >> iter 50000, loss: 0.400735
   Number of active neurons: 6
 >> iter 51000, loss: 0.304678
 >> iter 52000, loss: 0.276521
 >> iter 53000, loss: 0.452062
 >> iter 54000, loss: 0.318547
 >> iter 55000, loss: 0.366260
 >> iter 56000, loss: 0.227457
 >> iter 57000, loss: 0.232140
 >> iter 58000, loss: 0.370185
 >> iter 59000, loss: 0.229035
 >> iter 60000, loss: 0.250762
   Number of active neurons: 6
 >> iter 61000, loss: 0.222561
 >> iter 62000, loss: 0.218098
 >> iter 63000, loss: 0.239753
 >> iter 64000, loss: 0.279087
 >> iter 65000, loss: 0.278505
 >> iter 66000, loss: 0.499444
 >> iter 67000, loss: 0.296847
 >> iter 68000, loss: 0.226758
 >> iter 69000, loss: 0.354495
 >> iter 70000, loss: 0.446119
   Number of active neurons: 6
 >> iter 71000, loss: 0.411204
 >> iter 72000, loss: 0.318409
 >> iter 73000, loss: 0.204439
 >> iter 74000, loss: 0.162985
 >> iter 75000, loss: 0.305758
 >> iter 76000, loss: 0.214535
 >> iter 77000, loss: 0.291850
 >> iter 78000, loss: 0.223533
 >> iter 79000, loss: 0.181399
 >> iter 80000, loss: 0.235849
   Number of active neurons: 5
 >> iter 81000, loss: 0.191499
 >> iter 82000, loss: 0.178398
 >> iter 83000, loss: 0.395200
 >> iter 84000, loss: 0.261040
 >> iter 85000, loss: 0.248956
 >> iter 86000, loss: 0.137823
 >> iter 87000, loss: 0.239338
 >> iter 88000, loss: 0.209062
 >> iter 89000, loss: 0.203460
 >> iter 90000, loss: 0.128052
   Number of active neurons: 4
 >> iter 91000, loss: 0.254478
 >> iter 92000, loss: 0.207459
 >> iter 93000, loss: 0.295379
 >> iter 94000, loss: 0.283096
 >> iter 95000, loss: 0.400887
 >> iter 96000, loss: 0.321143
 >> iter 97000, loss: 0.368155
 >> iter 98000, loss: 0.231775
 >> iter 99000, loss: 0.213127
 >> iter 100000, loss: 0.232481
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.926507
 >> iter 2000, loss: 10.908704
 >> iter 3000, loss: 4.902339
 >> iter 4000, loss: 2.378748
 >> iter 5000, loss: 1.256357
 >> iter 6000, loss: 0.657424
 >> iter 7000, loss: 0.492422
 >> iter 8000, loss: 0.518968
 >> iter 9000, loss: 0.301873
 >> iter 10000, loss: 0.367918
   Number of active neurons: 6
 >> iter 11000, loss: 0.545505
 >> iter 12000, loss: 0.433707
 >> iter 13000, loss: 0.452303
 >> iter 14000, loss: 0.436738
 >> iter 15000, loss: 0.339010
 >> iter 16000, loss: 0.226785
 >> iter 17000, loss: 0.697627
 >> iter 18000, loss: 0.529686
 >> iter 19000, loss: 0.423996
 >> iter 20000, loss: 0.264359
   Number of active neurons: 6
 >> iter 21000, loss: 0.240368
 >> iter 22000, loss: 0.324811
 >> iter 23000, loss: 0.311710
 >> iter 24000, loss: 0.322045
 >> iter 25000, loss: 0.452537
 >> iter 26000, loss: 0.403468
 >> iter 27000, loss: 0.290450
 >> iter 28000, loss: 0.331231
 >> iter 29000, loss: 0.340894
 >> iter 30000, loss: 0.323962
   Number of active neurons: 6
 >> iter 31000, loss: 0.323234
 >> iter 32000, loss: 0.298504
 >> iter 33000, loss: 0.318667
 >> iter 34000, loss: 0.193099
 >> iter 35000, loss: 0.260803
 >> iter 36000, loss: 0.282933
 >> iter 37000, loss: 0.239813
 >> iter 38000, loss: 0.212338
 >> iter 39000, loss: 0.260588
 >> iter 40000, loss: 0.176176
   Number of active neurons: 5
 >> iter 41000, loss: 0.135075
 >> iter 42000, loss: 0.158257
 >> iter 43000, loss: 0.253444
 >> iter 44000, loss: 0.204577
 >> iter 45000, loss: 0.191804
 >> iter 46000, loss: 0.184626
 >> iter 47000, loss: 0.158181
 >> iter 48000, loss: 0.177587
 >> iter 49000, loss: 0.390345
 >> iter 50000, loss: 0.198311
   Number of active neurons: 5
 >> iter 51000, loss: 0.257138
 >> iter 52000, loss: 0.362120
 >> iter 53000, loss: 0.305194
 >> iter 54000, loss: 0.186334
 >> iter 55000, loss: 0.181835
 >> iter 56000, loss: 0.217088
 >> iter 57000, loss: 0.141481
 >> iter 58000, loss: 0.210006
 >> iter 59000, loss: 0.291087
 >> iter 60000, loss: 0.275586
   Number of active neurons: 4
 >> iter 61000, loss: 0.241076
 >> iter 62000, loss: 0.212502
 >> iter 63000, loss: 0.147446
 >> iter 64000, loss: 0.171035
 >> iter 65000, loss: 0.246863
 >> iter 66000, loss: 0.178813
 >> iter 67000, loss: 0.322727
 >> iter 68000, loss: 0.295197
 >> iter 69000, loss: 0.213109
 >> iter 70000, loss: 0.158607
   Number of active neurons: 4
 >> iter 71000, loss: 0.134731
 >> iter 72000, loss: 0.194297
 >> iter 73000, loss: 0.255585
 >> iter 74000, loss: 0.262567
 >> iter 75000, loss: 0.253075
 >> iter 76000, loss: 0.270487
 >> iter 77000, loss: 0.190414
 >> iter 78000, loss: 0.168638
 >> iter 79000, loss: 0.117292
 >> iter 80000, loss: 0.219419
   Number of active neurons: 4
 >> iter 81000, loss: 0.396036
 >> iter 82000, loss: 0.259228
 >> iter 83000, loss: 0.194559
 >> iter 84000, loss: 0.186609
 >> iter 85000, loss: 0.192214
 >> iter 86000, loss: 0.203978
 >> iter 87000, loss: 0.271055
 >> iter 88000, loss: 0.286857
 >> iter 89000, loss: 0.273232
 >> iter 90000, loss: 0.239099
   Number of active neurons: 4
 >> iter 91000, loss: 0.141497
 >> iter 92000, loss: 0.162957
 >> iter 93000, loss: 0.240170
 >> iter 94000, loss: 0.226950
 >> iter 95000, loss: 0.261244
 >> iter 96000, loss: 0.229731
 >> iter 97000, loss: 0.130540
 >> iter 98000, loss: 0.128824
 >> iter 99000, loss: 0.184329
 >> iter 100000, loss: 0.233296
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.235065
 >> iter 2000, loss: 12.284373
 >> iter 3000, loss: 6.225401
 >> iter 4000, loss: 3.435948
 >> iter 5000, loss: 1.774063
 >> iter 6000, loss: 1.003064
 >> iter 7000, loss: 0.588820
 >> iter 8000, loss: 0.403405
 >> iter 9000, loss: 0.499813
 >> iter 10000, loss: 0.520767
   Number of active neurons: 6
 >> iter 11000, loss: 0.478502
 >> iter 12000, loss: 0.523044
 >> iter 13000, loss: 0.522642
 >> iter 14000, loss: 0.344282
 >> iter 15000, loss: 0.449309
 >> iter 16000, loss: 0.630894
 >> iter 17000, loss: 0.327063
 >> iter 18000, loss: 0.269861
 >> iter 19000, loss: 0.506420
 >> iter 20000, loss: 0.342733
   Number of active neurons: 6
 >> iter 21000, loss: 0.479064
 >> iter 22000, loss: 0.508154
 >> iter 23000, loss: 0.382368
 >> iter 24000, loss: 0.519615
 >> iter 25000, loss: 0.421046
 >> iter 26000, loss: 0.344350
 >> iter 27000, loss: 0.386604
 >> iter 28000, loss: 0.371532
 >> iter 29000, loss: 0.359518
 >> iter 30000, loss: 0.221858
   Number of active neurons: 6
 >> iter 31000, loss: 0.213606
 >> iter 32000, loss: 0.170206
 >> iter 33000, loss: 0.254650
 >> iter 34000, loss: 0.303030
 >> iter 35000, loss: 0.237883
 >> iter 36000, loss: 0.353417
 >> iter 37000, loss: 0.240249
 >> iter 38000, loss: 0.331066
 >> iter 39000, loss: 0.317396
 >> iter 40000, loss: 0.297585
   Number of active neurons: 6
 >> iter 41000, loss: 0.298254
 >> iter 42000, loss: 0.229775
 >> iter 43000, loss: 0.188335
 >> iter 44000, loss: 0.241138
 >> iter 45000, loss: 0.256444
 >> iter 46000, loss: 0.465476
 >> iter 47000, loss: 0.311206
 >> iter 48000, loss: 0.279887
 >> iter 49000, loss: 0.352826
 >> iter 50000, loss: 0.244296
   Number of active neurons: 5
 >> iter 51000, loss: 0.377281
 >> iter 52000, loss: 0.209646
 >> iter 53000, loss: 0.284597
 >> iter 54000, loss: 0.210207
 >> iter 55000, loss: 0.234974
 >> iter 56000, loss: 0.227880
 >> iter 57000, loss: 0.293525
 >> iter 58000, loss: 0.303765
 >> iter 59000, loss: 0.269614
 >> iter 60000, loss: 0.382061
   Number of active neurons: 5
 >> iter 61000, loss: 0.381842
 >> iter 62000, loss: 0.324548
 >> iter 63000, loss: 0.295096
 >> iter 64000, loss: 0.235349
 >> iter 65000, loss: 0.261406
 >> iter 66000, loss: 0.208138
 >> iter 67000, loss: 0.307119
 >> iter 68000, loss: 0.327511
 >> iter 69000, loss: 0.251769
 >> iter 70000, loss: 0.174711
   Number of active neurons: 5
 >> iter 71000, loss: 0.257214
 >> iter 72000, loss: 0.180200
 >> iter 73000, loss: 0.153412
 >> iter 74000, loss: 0.159575
 >> iter 75000, loss: 0.229955
 >> iter 76000, loss: 0.241861
 >> iter 77000, loss: 0.224673
 >> iter 78000, loss: 0.194422
 >> iter 79000, loss: 0.403722
 >> iter 80000, loss: 0.234152
   Number of active neurons: 5
 >> iter 81000, loss: 0.287502
 >> iter 82000, loss: 0.166923
 >> iter 83000, loss: 0.147267
 >> iter 84000, loss: 0.214731
 >> iter 85000, loss: 0.240990
 >> iter 86000, loss: 0.406632
 >> iter 87000, loss: 0.315308
 >> iter 88000, loss: 0.307735
 >> iter 89000, loss: 0.199261
 >> iter 90000, loss: 0.178234
   Number of active neurons: 5
 >> iter 91000, loss: 0.482830
 >> iter 92000, loss: 0.372350
 >> iter 93000, loss: 0.280205
 >> iter 94000, loss: 0.273046
 >> iter 95000, loss: 0.192179
 >> iter 96000, loss: 0.172747
 >> iter 97000, loss: 0.192987
 >> iter 98000, loss: 0.195565
 >> iter 99000, loss: 0.183028
 >> iter 100000, loss: 0.237696
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.957955
 >> iter 2000, loss: 11.408345
 >> iter 3000, loss: 5.535264
 >> iter 4000, loss: 2.868512
 >> iter 5000, loss: 1.802947
 >> iter 6000, loss: 1.061861
 >> iter 7000, loss: 0.779365
 >> iter 8000, loss: 0.627581
 >> iter 9000, loss: 0.563268
 >> iter 10000, loss: 0.514573
   Number of active neurons: 5
 >> iter 11000, loss: 0.462622
 >> iter 12000, loss: 0.329122
 >> iter 13000, loss: 0.478132
 >> iter 14000, loss: 0.425878
 >> iter 15000, loss: 0.491454
 >> iter 16000, loss: 0.471164
 >> iter 17000, loss: 0.475620
 >> iter 18000, loss: 0.407864
 >> iter 19000, loss: 0.544870
 >> iter 20000, loss: 0.410326
   Number of active neurons: 5
 >> iter 21000, loss: 0.323677
 >> iter 22000, loss: 0.619087
 >> iter 23000, loss: 0.467907
 >> iter 24000, loss: 0.422194
 >> iter 25000, loss: 0.291765
 >> iter 26000, loss: 0.193483
 >> iter 27000, loss: 0.305431
 >> iter 28000, loss: 0.207945
 >> iter 29000, loss: 0.183930
 >> iter 30000, loss: 0.180377
   Number of active neurons: 5
 >> iter 31000, loss: 0.151237
 >> iter 32000, loss: 0.217287
 >> iter 33000, loss: 0.272973
 >> iter 34000, loss: 0.262531
 >> iter 35000, loss: 0.311601
 >> iter 36000, loss: 0.263887
 >> iter 37000, loss: 0.300152
 >> iter 38000, loss: 0.183595
 >> iter 39000, loss: 0.190736
 >> iter 40000, loss: 0.213013
   Number of active neurons: 5
 >> iter 41000, loss: 0.385730
 >> iter 42000, loss: 0.267679
 >> iter 43000, loss: 0.200140
 >> iter 44000, loss: 0.160505
 >> iter 45000, loss: 0.240196
 >> iter 46000, loss: 0.225944
 >> iter 47000, loss: 0.211530
 >> iter 48000, loss: 0.279037
 >> iter 49000, loss: 0.354395
 >> iter 50000, loss: 0.288644
   Number of active neurons: 5
 >> iter 51000, loss: 0.355993
 >> iter 52000, loss: 0.251693
 >> iter 53000, loss: 0.321501
 >> iter 54000, loss: 0.202600
 >> iter 55000, loss: 0.237802
 >> iter 56000, loss: 0.177684
 >> iter 57000, loss: 0.306295
 >> iter 58000, loss: 0.193623
 >> iter 59000, loss: 0.125968
 >> iter 60000, loss: 0.142134
   Number of active neurons: 5
 >> iter 61000, loss: 0.265853
 >> iter 62000, loss: 0.300212
 >> iter 63000, loss: 0.326797
 >> iter 64000, loss: 0.264798
 >> iter 65000, loss: 0.228087
 >> iter 66000, loss: 0.207526
 >> iter 67000, loss: 0.270495
 >> iter 68000, loss: 0.268565
 >> iter 69000, loss: 0.200573
 >> iter 70000, loss: 0.305351
   Number of active neurons: 5
 >> iter 71000, loss: 0.259955
 >> iter 72000, loss: 0.256959
 >> iter 73000, loss: 0.198695
 >> iter 74000, loss: 0.141435
 >> iter 75000, loss: 0.163743
 >> iter 76000, loss: 0.199269
 >> iter 77000, loss: 0.270081
 >> iter 78000, loss: 0.321777
 >> iter 79000, loss: 0.174539
 >> iter 80000, loss: 0.295870
   Number of active neurons: 5
 >> iter 81000, loss: 0.235026
 >> iter 82000, loss: 0.159406
 >> iter 83000, loss: 0.164395
 >> iter 84000, loss: 0.216454
 >> iter 85000, loss: 0.251368
 >> iter 86000, loss: 0.167440
 >> iter 87000, loss: 0.260468
 >> iter 88000, loss: 0.211217
 >> iter 89000, loss: 0.294992
 >> iter 90000, loss: 0.256116
   Number of active neurons: 4
 >> iter 91000, loss: 0.203356
 >> iter 92000, loss: 0.285984
 >> iter 93000, loss: 0.235807
 >> iter 94000, loss: 0.193866
 >> iter 95000, loss: 0.179015
 >> iter 96000, loss: 0.144680
 >> iter 97000, loss: 0.230383
 >> iter 98000, loss: 0.216269
 >> iter 99000, loss: 0.213020
 >> iter 100000, loss: 0.150287
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.242901
 >> iter 2000, loss: 14.093387
 >> iter 3000, loss: 10.214172
 >> iter 4000, loss: 8.379127
 >> iter 5000, loss: 7.562058
 >> iter 6000, loss: 7.176202
 >> iter 7000, loss: 7.282641
 >> iter 8000, loss: 7.022884
 >> iter 9000, loss: 7.061356
 >> iter 10000, loss: 6.870795
   Number of active neurons: 5
 >> iter 11000, loss: 6.847965
 >> iter 12000, loss: 6.607412
 >> iter 13000, loss: 6.601132
 >> iter 14000, loss: 4.611409
 >> iter 15000, loss: 2.334870
 >> iter 16000, loss: 1.381888
 >> iter 17000, loss: 0.925406
 >> iter 18000, loss: 0.763519
 >> iter 19000, loss: 0.699353
 >> iter 20000, loss: 0.603642
   Number of active neurons: 7
 >> iter 21000, loss: 0.635723
 >> iter 22000, loss: 0.426684
 >> iter 23000, loss: 0.487579
 >> iter 24000, loss: 0.382866
 >> iter 25000, loss: 0.569477
 >> iter 26000, loss: 0.618824
 >> iter 27000, loss: 0.532401
 >> iter 28000, loss: 0.558436
 >> iter 29000, loss: 0.477360
 >> iter 30000, loss: 0.361464
   Number of active neurons: 7
 >> iter 31000, loss: 0.504313
 >> iter 32000, loss: 0.765633
 >> iter 33000, loss: 0.572366
 >> iter 34000, loss: 0.606893
 >> iter 35000, loss: 0.527943
 >> iter 36000, loss: 0.425910
 >> iter 37000, loss: 0.514557
 >> iter 38000, loss: 0.495379
 >> iter 39000, loss: 0.527722
 >> iter 40000, loss: 0.451039
   Number of active neurons: 6
 >> iter 41000, loss: 0.408849
 >> iter 42000, loss: 0.448265
 >> iter 43000, loss: 0.463876
 >> iter 44000, loss: 0.561680
 >> iter 45000, loss: 0.748925
 >> iter 46000, loss: 0.499748
 >> iter 47000, loss: 0.626459
 >> iter 48000, loss: 0.444509
 >> iter 49000, loss: 0.503456
 >> iter 50000, loss: 0.370127
   Number of active neurons: 6
 >> iter 51000, loss: 0.491699
 >> iter 52000, loss: 0.511888
 >> iter 53000, loss: 0.503696
 >> iter 54000, loss: 0.527890
 >> iter 55000, loss: 0.509242
 >> iter 56000, loss: 0.418411
 >> iter 57000, loss: 0.316779
 >> iter 58000, loss: 0.474084
 >> iter 59000, loss: 0.434343
 >> iter 60000, loss: 0.486516
   Number of active neurons: 6
 >> iter 61000, loss: 0.473040
 >> iter 62000, loss: 0.400454
 >> iter 63000, loss: 0.499411
 >> iter 64000, loss: 0.535800
 >> iter 65000, loss: 0.542510
 >> iter 66000, loss: 0.522771
 >> iter 67000, loss: 0.602216
 >> iter 68000, loss: 0.578714
 >> iter 69000, loss: 0.484576
 >> iter 70000, loss: 0.404918
   Number of active neurons: 6
 >> iter 71000, loss: 0.410190
 >> iter 72000, loss: 0.365797
 >> iter 73000, loss: 0.369245
 >> iter 74000, loss: 0.397329
 >> iter 75000, loss: 0.733613
 >> iter 76000, loss: 0.526108
 >> iter 77000, loss: 0.576592
 >> iter 78000, loss: 0.424011
 >> iter 79000, loss: 0.403448
 >> iter 80000, loss: 0.392066
   Number of active neurons: 6
 >> iter 81000, loss: 0.401849
 >> iter 82000, loss: 0.497591
 >> iter 83000, loss: 0.453092
 >> iter 84000, loss: 0.440814
 >> iter 85000, loss: 0.421108
 >> iter 86000, loss: 0.570444
 >> iter 87000, loss: 0.504668
 >> iter 88000, loss: 0.502263
 >> iter 89000, loss: 0.421521
 >> iter 90000, loss: 0.396571
   Number of active neurons: 6
 >> iter 91000, loss: 0.400373
 >> iter 92000, loss: 0.501314
 >> iter 93000, loss: 0.502006
 >> iter 94000, loss: 0.479350
 >> iter 95000, loss: 0.440169
 >> iter 96000, loss: 0.336889
 >> iter 97000, loss: 0.560929
 >> iter 98000, loss: 0.407722
 >> iter 99000, loss: 0.299959
 >> iter 100000, loss: 0.440645
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.087193
 >> iter 2000, loss: 12.017322
 >> iter 3000, loss: 5.943525
 >> iter 4000, loss: 3.004998
 >> iter 5000, loss: 1.632791
 >> iter 6000, loss: 0.969239
 >> iter 7000, loss: 0.674759
 >> iter 8000, loss: 0.496828
 >> iter 9000, loss: 0.427668
 >> iter 10000, loss: 0.416803
   Number of active neurons: 6
 >> iter 11000, loss: 0.399221
 >> iter 12000, loss: 0.314569
 >> iter 13000, loss: 0.338712
 >> iter 14000, loss: 0.343134
 >> iter 15000, loss: 0.344763
 >> iter 16000, loss: 0.366116
 >> iter 17000, loss: 0.320339
 >> iter 18000, loss: 0.414621
 >> iter 19000, loss: 0.337632
 >> iter 20000, loss: 0.442035
   Number of active neurons: 6
 >> iter 21000, loss: 0.439143
 >> iter 22000, loss: 0.400175
 >> iter 23000, loss: 0.511211
 >> iter 24000, loss: 0.447848
 >> iter 25000, loss: 0.394365
 >> iter 26000, loss: 0.423144
 >> iter 27000, loss: 0.314171
 >> iter 28000, loss: 0.385242
 >> iter 29000, loss: 0.378241
 >> iter 30000, loss: 0.345907
   Number of active neurons: 6
 >> iter 31000, loss: 0.391782
 >> iter 32000, loss: 0.456482
 >> iter 33000, loss: 0.494339
 >> iter 34000, loss: 0.511481
 >> iter 35000, loss: 0.407668
 >> iter 36000, loss: 0.557947
 >> iter 37000, loss: 0.373395
 >> iter 38000, loss: 0.358341
 >> iter 39000, loss: 0.474694
 >> iter 40000, loss: 0.448857
   Number of active neurons: 6
 >> iter 41000, loss: 0.451273
 >> iter 42000, loss: 0.423949
 >> iter 43000, loss: 0.480437
 >> iter 44000, loss: 0.422278
 >> iter 45000, loss: 0.549681
 >> iter 46000, loss: 0.415204
 >> iter 47000, loss: 0.456504
 >> iter 48000, loss: 0.252520
 >> iter 49000, loss: 0.293938
 >> iter 50000, loss: 0.396863
   Number of active neurons: 5
 >> iter 51000, loss: 0.305236
 >> iter 52000, loss: 0.373241
 >> iter 53000, loss: 0.311199
 >> iter 54000, loss: 0.222897
 >> iter 55000, loss: 0.282253
 >> iter 56000, loss: 0.351231
 >> iter 57000, loss: 0.385320
 >> iter 58000, loss: 0.492877
 >> iter 59000, loss: 0.469412
 >> iter 60000, loss: 0.340896
   Number of active neurons: 5
 >> iter 61000, loss: 0.303678
 >> iter 62000, loss: 0.327534
 >> iter 63000, loss: 0.268070
 >> iter 64000, loss: 0.388896
 >> iter 65000, loss: 0.340772
 >> iter 66000, loss: 0.307677
 >> iter 67000, loss: 0.279223
 >> iter 68000, loss: 0.356002
 >> iter 69000, loss: 0.244743
 >> iter 70000, loss: 0.461405
   Number of active neurons: 5
 >> iter 71000, loss: 0.409050
 >> iter 72000, loss: 0.300260
 >> iter 73000, loss: 0.341553
 >> iter 74000, loss: 0.430797
 >> iter 75000, loss: 0.415555
 >> iter 76000, loss: 0.342109
 >> iter 77000, loss: 0.257395
 >> iter 78000, loss: 0.249319
 >> iter 79000, loss: 0.486098
 >> iter 80000, loss: 0.430798
   Number of active neurons: 5
 >> iter 81000, loss: 0.480390
 >> iter 82000, loss: 0.348888
 >> iter 83000, loss: 0.327387
 >> iter 84000, loss: 0.266724
 >> iter 85000, loss: 0.206458
 >> iter 86000, loss: 0.172521
 >> iter 87000, loss: 0.267601
 >> iter 88000, loss: 0.296256
 >> iter 89000, loss: 0.266913
 >> iter 90000, loss: 0.272482
   Number of active neurons: 5
 >> iter 91000, loss: 0.261259
 >> iter 92000, loss: 0.317085
 >> iter 93000, loss: 0.237494
 >> iter 94000, loss: 0.442059
 >> iter 95000, loss: 0.353701
 >> iter 96000, loss: 0.421112
 >> iter 97000, loss: 0.411419
 >> iter 98000, loss: 0.299886
 >> iter 99000, loss: 0.330448
 >> iter 100000, loss: 0.296250
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.278058
 >> iter 2000, loss: 12.018069
 >> iter 3000, loss: 6.276013
 >> iter 4000, loss: 3.565211
 >> iter 5000, loss: 1.945564
 >> iter 6000, loss: 1.278351
 >> iter 7000, loss: 0.990076
 >> iter 8000, loss: 0.980616
 >> iter 9000, loss: 0.915250
 >> iter 10000, loss: 0.903100
   Number of active neurons: 6
 >> iter 11000, loss: 0.956573
 >> iter 12000, loss: 0.676550
 >> iter 13000, loss: 0.689900
 >> iter 14000, loss: 0.478941
 >> iter 15000, loss: 0.407343
 >> iter 16000, loss: 0.552583
 >> iter 17000, loss: 0.363899
 >> iter 18000, loss: 0.435915
 >> iter 19000, loss: 0.654038
 >> iter 20000, loss: 0.572203
   Number of active neurons: 6
 >> iter 21000, loss: 0.640987
 >> iter 22000, loss: 0.436973
 >> iter 23000, loss: 0.446198
 >> iter 24000, loss: 0.548376
 >> iter 25000, loss: 0.626230
 >> iter 26000, loss: 0.691957
 >> iter 27000, loss: 0.470945
 >> iter 28000, loss: 0.445606
 >> iter 29000, loss: 0.598226
 >> iter 30000, loss: 0.600639
   Number of active neurons: 6
 >> iter 31000, loss: 0.605877
 >> iter 32000, loss: 0.463131
 >> iter 33000, loss: 0.577255
 >> iter 34000, loss: 0.658980
 >> iter 35000, loss: 0.719606
 >> iter 36000, loss: 0.483287
 >> iter 37000, loss: 0.348447
 >> iter 38000, loss: 0.431814
 >> iter 39000, loss: 0.371116
 >> iter 40000, loss: 0.414295
   Number of active neurons: 6
 >> iter 41000, loss: 0.310434
 >> iter 42000, loss: 0.580715
 >> iter 43000, loss: 0.630316
 >> iter 44000, loss: 0.609315
 >> iter 45000, loss: 0.750859
 >> iter 46000, loss: 0.497053
 >> iter 47000, loss: 0.437423
 >> iter 48000, loss: 0.307777
 >> iter 49000, loss: 0.325811
 >> iter 50000, loss: 0.365607
   Number of active neurons: 6
 >> iter 51000, loss: 0.416441
 >> iter 52000, loss: 0.402048
 >> iter 53000, loss: 0.454462
 >> iter 54000, loss: 0.547171
 >> iter 55000, loss: 0.547037
 >> iter 56000, loss: 0.724756
 >> iter 57000, loss: 0.565561
 >> iter 58000, loss: 0.406124
 >> iter 59000, loss: 0.453658
 >> iter 60000, loss: 0.601243
   Number of active neurons: 6
 >> iter 61000, loss: 0.397496
 >> iter 62000, loss: 0.423585
 >> iter 63000, loss: 0.478625
 >> iter 64000, loss: 0.469401
 >> iter 65000, loss: 0.541379
 >> iter 66000, loss: 0.534393
 >> iter 67000, loss: 0.572704
 >> iter 68000, loss: 0.483696
 >> iter 69000, loss: 0.435710
 >> iter 70000, loss: 0.494180
   Number of active neurons: 6
 >> iter 71000, loss: 0.514296
 >> iter 72000, loss: 0.462727
 >> iter 73000, loss: 0.431815
 >> iter 74000, loss: 0.403474
 >> iter 75000, loss: 0.409440
 >> iter 76000, loss: 0.528864
 >> iter 77000, loss: 0.522639
 >> iter 78000, loss: 0.430081
 >> iter 79000, loss: 0.412777
 >> iter 80000, loss: 0.384047
   Number of active neurons: 6
 >> iter 81000, loss: 0.461556
 >> iter 82000, loss: 0.445724
 >> iter 83000, loss: 0.397740
 >> iter 84000, loss: 0.518120
 >> iter 85000, loss: 0.491848
 >> iter 86000, loss: 0.421828
 >> iter 87000, loss: 0.342669
 >> iter 88000, loss: 0.359103
 >> iter 89000, loss: 0.520319
 >> iter 90000, loss: 0.569993
   Number of active neurons: 6
 >> iter 91000, loss: 0.547533
 >> iter 92000, loss: 0.349972
 >> iter 93000, loss: 0.384260
 >> iter 94000, loss: 0.375958
 >> iter 95000, loss: 0.310776
 >> iter 96000, loss: 0.534825
 >> iter 97000, loss: 0.416911
 >> iter 98000, loss: 0.374252
 >> iter 99000, loss: 0.393148
 >> iter 100000, loss: 0.377348
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.409865
 >> iter 2000, loss: 14.498592
 >> iter 3000, loss: 9.820501
 >> iter 4000, loss: 5.945731
 >> iter 5000, loss: 3.645478
 >> iter 6000, loss: 2.421179
 >> iter 7000, loss: 1.927040
 >> iter 8000, loss: 1.833743
 >> iter 9000, loss: 1.729608
 >> iter 10000, loss: 1.376192
   Number of active neurons: 8
 >> iter 11000, loss: 1.188846
 >> iter 12000, loss: 1.105177
 >> iter 13000, loss: 0.861839
 >> iter 14000, loss: 0.826890
 >> iter 15000, loss: 0.870605
 >> iter 16000, loss: 0.752540
 >> iter 17000, loss: 0.583292
 >> iter 18000, loss: 0.655453
 >> iter 19000, loss: 0.989051
 >> iter 20000, loss: 0.757088
   Number of active neurons: 8
 >> iter 21000, loss: 0.964375
 >> iter 22000, loss: 0.640999
 >> iter 23000, loss: 0.777990
 >> iter 24000, loss: 0.548128
 >> iter 25000, loss: 0.568895
 >> iter 26000, loss: 0.624697
 >> iter 27000, loss: 0.805513
 >> iter 28000, loss: 0.601069
 >> iter 29000, loss: 0.651696
 >> iter 30000, loss: 0.651733
   Number of active neurons: 6
 >> iter 31000, loss: 0.515460
 >> iter 32000, loss: 0.719151
 >> iter 33000, loss: 0.526649
 >> iter 34000, loss: 0.539511
 >> iter 35000, loss: 0.524285
 >> iter 36000, loss: 0.651033
 >> iter 37000, loss: 0.705653
 >> iter 38000, loss: 0.557157
 >> iter 39000, loss: 0.608654
 >> iter 40000, loss: 0.483778
   Number of active neurons: 6
 >> iter 41000, loss: 0.519762
 >> iter 42000, loss: 0.544123
 >> iter 43000, loss: 0.527182
 >> iter 44000, loss: 0.518960
 >> iter 45000, loss: 0.673758
 >> iter 46000, loss: 0.581685
 >> iter 47000, loss: 0.570639
 >> iter 48000, loss: 0.624218
 >> iter 49000, loss: 0.683484
 >> iter 50000, loss: 0.650073
   Number of active neurons: 6
 >> iter 51000, loss: 0.386923
 >> iter 52000, loss: 0.533471
 >> iter 53000, loss: 0.546322
 >> iter 54000, loss: 0.495040
 >> iter 55000, loss: 0.587122
 >> iter 56000, loss: 0.614586
 >> iter 57000, loss: 0.508412
 >> iter 58000, loss: 0.507685
 >> iter 59000, loss: 0.366303
 >> iter 60000, loss: 0.267533
   Number of active neurons: 6
 >> iter 61000, loss: 0.351148
 >> iter 62000, loss: 0.235615
 >> iter 63000, loss: 0.318426
 >> iter 64000, loss: 0.486936
 >> iter 65000, loss: 0.603381
 >> iter 66000, loss: 0.607780
 >> iter 67000, loss: 0.495974
 >> iter 68000, loss: 0.586083
 >> iter 69000, loss: 0.370931
 >> iter 70000, loss: 0.291370
   Number of active neurons: 6
 >> iter 71000, loss: 0.324157
 >> iter 72000, loss: 0.501794
 >> iter 73000, loss: 0.591150
 >> iter 74000, loss: 0.420734
 >> iter 75000, loss: 0.414741
 >> iter 76000, loss: 0.354629
 >> iter 77000, loss: 0.269582
 >> iter 78000, loss: 0.620392
 >> iter 79000, loss: 0.644927
 >> iter 80000, loss: 0.514649
   Number of active neurons: 5
 >> iter 81000, loss: 0.390389
 >> iter 82000, loss: 0.326730
 >> iter 83000, loss: 0.337680
 >> iter 84000, loss: 0.361172
 >> iter 85000, loss: 0.433069
 >> iter 86000, loss: 0.385520
 >> iter 87000, loss: 0.354000
 >> iter 88000, loss: 0.409460
 >> iter 89000, loss: 0.446271
 >> iter 90000, loss: 0.280149
   Number of active neurons: 5
 >> iter 91000, loss: 0.465590
 >> iter 92000, loss: 0.479338
 >> iter 93000, loss: 0.462765
 >> iter 94000, loss: 0.386312
 >> iter 95000, loss: 0.537544
 >> iter 96000, loss: 0.432721
 >> iter 97000, loss: 0.424471
 >> iter 98000, loss: 0.453997
 >> iter 99000, loss: 0.520066
 >> iter 100000, loss: 0.325371
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.176561
 >> iter 2000, loss: 13.236494
 >> iter 3000, loss: 10.282194
 >> iter 4000, loss: 8.884551
 >> iter 5000, loss: 8.560603
 >> iter 6000, loss: 8.058221
 >> iter 7000, loss: 7.597766
 >> iter 8000, loss: 5.184712
 >> iter 9000, loss: 3.973693
 >> iter 10000, loss: 3.131420
   Number of active neurons: 4
 >> iter 11000, loss: 2.721681
 >> iter 12000, loss: 2.580272
 >> iter 13000, loss: 2.689454
 >> iter 14000, loss: 2.538911
 >> iter 15000, loss: 2.428659
 >> iter 16000, loss: 2.376096
 >> iter 17000, loss: 2.390035
 >> iter 18000, loss: 2.421504
 >> iter 19000, loss: 2.396565
 >> iter 20000, loss: 2.247846
   Number of active neurons: 7
 >> iter 21000, loss: 2.297548
 >> iter 22000, loss: 2.301460
 >> iter 23000, loss: 2.283141
 >> iter 24000, loss: 2.232904
 >> iter 25000, loss: 2.411154
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 26000, loss: 2.435370
 >> iter 27000, loss: 2.395777
 >> iter 28000, loss: 2.282059
 >> iter 29000, loss: 2.333395
 >> iter 30000, loss: 2.313232
   Number of active neurons: 9
 >> iter 31000, loss: 2.566143
 >> iter 32000, loss: 2.660220
 >> iter 33000, loss: 2.678740
 >> iter 34000, loss: 1.629882
 >> iter 35000, loss: 0.982912
 >> iter 36000, loss: 0.572164
 >> iter 37000, loss: 0.655123
 >> iter 38000, loss: 0.506431
 >> iter 39000, loss: 0.417643
 >> iter 40000, loss: 0.435884
   Number of active neurons: 8
 >> iter 41000, loss: 0.429252
 >> iter 42000, loss: 0.310931
 >> iter 43000, loss: 0.405091
 >> iter 44000, loss: 0.312392
 >> iter 45000, loss: 0.432722
 >> iter 46000, loss: 0.514295
 >> iter 47000, loss: 0.374322
 >> iter 48000, loss: 0.392182
 >> iter 49000, loss: 0.448916
 >> iter 50000, loss: 0.407966
   Number of active neurons: 6
 >> iter 51000, loss: 0.438942
 >> iter 52000, loss: 0.419143
 >> iter 53000, loss: 0.419911
 >> iter 54000, loss: 0.423253
 >> iter 55000, loss: 0.442253
 >> iter 56000, loss: 0.408739
 >> iter 57000, loss: 0.364569
 >> iter 58000, loss: 0.322709
 >> iter 59000, loss: 0.363335
 >> iter 60000, loss: 0.395992
   Number of active neurons: 5
 >> iter 61000, loss: 0.469320
 >> iter 62000, loss: 0.516748
 >> iter 63000, loss: 0.358955
 >> iter 64000, loss: 0.290933
 >> iter 65000, loss: 0.411829
 >> iter 66000, loss: 0.457798
 >> iter 67000, loss: 0.510182
 >> iter 68000, loss: 0.550202
 >> iter 69000, loss: 0.520902
 >> iter 70000, loss: 0.457648
   Number of active neurons: 5
 >> iter 71000, loss: 0.469799
 >> iter 72000, loss: 0.434916
 >> iter 73000, loss: 0.388931
 >> iter 74000, loss: 0.485849
 >> iter 75000, loss: 0.380276
 >> iter 76000, loss: 0.504481
 >> iter 77000, loss: 0.501797
 >> iter 78000, loss: 0.591683
 >> iter 79000, loss: 0.548627
 >> iter 80000, loss: 0.325329
   Number of active neurons: 5
 >> iter 81000, loss: 0.285747
 >> iter 82000, loss: 0.388565
 >> iter 83000, loss: 0.394848
 >> iter 84000, loss: 0.369073
 >> iter 85000, loss: 0.454201
 >> iter 86000, loss: 0.519470
 >> iter 87000, loss: 0.502137
 >> iter 88000, loss: 0.442838
 >> iter 89000, loss: 0.316723
 >> iter 90000, loss: 0.481689
   Number of active neurons: 5
 >> iter 91000, loss: 0.315385
 >> iter 92000, loss: 0.231586
 >> iter 93000, loss: 0.348105
 >> iter 94000, loss: 0.290602
 >> iter 95000, loss: 0.368573
 >> iter 96000, loss: 0.463178
 >> iter 97000, loss: 0.668305
 >> iter 98000, loss: 0.395718
 >> iter 99000, loss: 0.457163
 >> iter 100000, loss: 0.347401
   Number of active neurons: 5
 >> iter 101000, loss: 0.464203
 >> iter 102000, loss: 0.315699
 >> iter 103000, loss: 0.447084
 >> iter 104000, loss: 0.394063
 >> iter 105000, loss: 0.443212
 >> iter 106000, loss: 0.421330
 >> iter 107000, loss: 0.301856
 >> iter 108000, loss: 0.336408
 >> iter 109000, loss: 0.347645
 >> iter 110000, loss: 0.482672
   Number of active neurons: 5
 >> iter 111000, loss: 0.440797
 >> iter 112000, loss: 0.429918
 >> iter 113000, loss: 0.324789
 >> iter 114000, loss: 0.343436
 >> iter 115000, loss: 0.292112
 >> iter 116000, loss: 0.327747
 >> iter 117000, loss: 0.376233
 >> iter 118000, loss: 0.257739
 >> iter 119000, loss: 0.401035
 >> iter 120000, loss: 0.356179
   Number of active neurons: 4
 >> iter 121000, loss: 0.456210
 >> iter 122000, loss: 0.506051
 >> iter 123000, loss: 0.411428
 >> iter 124000, loss: 0.582433
 >> iter 125000, loss: 0.427897
 >> iter 126000, loss: 0.424483
 >> iter 127000, loss: 0.444830
 >> iter 128000, loss: 0.583421
 >> iter 129000, loss: 0.525418
 >> iter 130000, loss: 0.431627
   Number of active neurons: 4
 >> iter 131000, loss: 0.348006
 >> iter 132000, loss: 0.283736
 >> iter 133000, loss: 0.327417
 >> iter 134000, loss: 0.315170
 >> iter 135000, loss: 0.404519
 >> iter 136000, loss: 0.250620
 >> iter 137000, loss: 0.656748
 >> iter 138000, loss: 0.532465
 >> iter 139000, loss: 0.417404
 >> iter 140000, loss: 0.339968
   Number of active neurons: 4
 >> iter 141000, loss: 0.256160
 >> iter 142000, loss: 0.245088
 >> iter 143000, loss: 0.219603
 >> iter 144000, loss: 0.145196
 >> iter 145000, loss: 0.325432
 >> iter 146000, loss: 0.396239
 >> iter 147000, loss: 0.372708
 >> iter 148000, loss: 0.322977
 >> iter 149000, loss: 0.389134
 >> iter 150000, loss: 0.447655
   Number of active neurons: 4
 >> iter 151000, loss: 0.354689
 >> iter 152000, loss: 0.276166
 >> iter 153000, loss: 0.354043
 >> iter 154000, loss: 0.351100
 >> iter 155000, loss: 0.560010
 >> iter 156000, loss: 0.510076
 >> iter 157000, loss: 0.324021
 >> iter 158000, loss: 0.331107
 >> iter 159000, loss: 0.380443
 >> iter 160000, loss: 0.377702
   Number of active neurons: 4
 >> iter 161000, loss: 0.441005
 >> iter 162000, loss: 0.642603
 >> iter 163000, loss: 0.517709
 >> iter 164000, loss: 0.442953
 >> iter 165000, loss: 0.337663
 >> iter 166000, loss: 0.287335
 >> iter 167000, loss: 0.324555
 >> iter 168000, loss: 0.228952
 >> iter 169000, loss: 0.386096
 >> iter 170000, loss: 0.428573
   Number of active neurons: 4
 >> iter 171000, loss: 0.308754
 >> iter 172000, loss: 0.370209
 >> iter 173000, loss: 0.357732
 >> iter 174000, loss: 0.344499
 >> iter 175000, loss: 0.556551
 >> iter 176000, loss: 0.378377
 >> iter 177000, loss: 0.341906
 >> iter 178000, loss: 0.316869
 >> iter 179000, loss: 0.260674
 >> iter 180000, loss: 0.240848
   Number of active neurons: 4
 >> iter 181000, loss: 0.353188
 >> iter 182000, loss: 0.352311
 >> iter 183000, loss: 0.434970
 >> iter 184000, loss: 0.327156
 >> iter 185000, loss: 0.316651
 >> iter 186000, loss: 0.366448
 >> iter 187000, loss: 0.401467
 >> iter 188000, loss: 0.375778
 >> iter 189000, loss: 0.382191
 >> iter 190000, loss: 0.464312
   Number of active neurons: 4
 >> iter 191000, loss: 0.365444
 >> iter 192000, loss: 0.378057
 >> iter 193000, loss: 0.357025
 >> iter 194000, loss: 0.397886
 >> iter 195000, loss: 0.355569
 >> iter 196000, loss: 0.319569
 >> iter 197000, loss: 0.399030
 >> iter 198000, loss: 0.409574
 >> iter 199000, loss: 0.393538
 >> iter 200000, loss: 0.297178
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.230023
 >> iter 2000, loss: 12.955259
 >> iter 3000, loss: 9.509982
 >> iter 4000, loss: 5.816590
 >> iter 5000, loss: 3.482829
 >> iter 6000, loss: 2.262311
 >> iter 7000, loss: 1.369665
 >> iter 8000, loss: 1.077460
 >> iter 9000, loss: 0.641885
 >> iter 10000, loss: 0.505431
   Number of active neurons: 4
 >> iter 11000, loss: 0.396496
 >> iter 12000, loss: 0.351966
 >> iter 13000, loss: 0.231107
 >> iter 14000, loss: 0.359112
 >> iter 15000, loss: 0.311733
 >> iter 16000, loss: 0.428286
 >> iter 17000, loss: 0.427046
 >> iter 18000, loss: 0.309785
 >> iter 19000, loss: 0.186326
 >> iter 20000, loss: 0.263176
   Number of active neurons: 4
 >> iter 21000, loss: 0.294600
 >> iter 22000, loss: 0.293529
 >> iter 23000, loss: 0.385560
 >> iter 24000, loss: 0.275835
 >> iter 25000, loss: 0.315846
 >> iter 26000, loss: 0.294740
 >> iter 27000, loss: 0.395168
 >> iter 28000, loss: 0.413084
 >> iter 29000, loss: 0.497887
 >> iter 30000, loss: 0.405564
   Number of active neurons: 4
 >> iter 31000, loss: 0.294793
 >> iter 32000, loss: 0.267008
 >> iter 33000, loss: 0.313327
 >> iter 34000, loss: 0.200465
 >> iter 35000, loss: 0.186614
 >> iter 36000, loss: 0.390783
 >> iter 37000, loss: 0.412696
 >> iter 38000, loss: 0.430264
 >> iter 39000, loss: 0.310463
 >> iter 40000, loss: 0.331858
   Number of active neurons: 4
 >> iter 41000, loss: 0.458873
 >> iter 42000, loss: 0.394512
 >> iter 43000, loss: 0.501834
 >> iter 44000, loss: 0.599075
 >> iter 45000, loss: 0.404214
 >> iter 46000, loss: 0.349518
 >> iter 47000, loss: 0.302031
 >> iter 48000, loss: 0.197532
 >> iter 49000, loss: 0.264356
 >> iter 50000, loss: 0.321481
   Number of active neurons: 4
 >> iter 51000, loss: 0.304353
 >> iter 52000, loss: 0.300205
 >> iter 53000, loss: 0.485247
 >> iter 54000, loss: 0.445217
 >> iter 55000, loss: 0.343488
 >> iter 56000, loss: 0.267062
 >> iter 57000, loss: 0.358106
 >> iter 58000, loss: 0.452762
 >> iter 59000, loss: 0.443696
 >> iter 60000, loss: 0.429265
   Number of active neurons: 4
 >> iter 61000, loss: 0.353070
 >> iter 62000, loss: 0.421913
 >> iter 63000, loss: 0.374861
 >> iter 64000, loss: 0.383027
 >> iter 65000, loss: 0.281624
 >> iter 66000, loss: 0.260616
 >> iter 67000, loss: 0.459738
 >> iter 68000, loss: 0.367450
 >> iter 69000, loss: 0.290871
 >> iter 70000, loss: 0.428149
   Number of active neurons: 4
 >> iter 71000, loss: 0.354049
 >> iter 72000, loss: 0.384101
 >> iter 73000, loss: 0.283784
 >> iter 74000, loss: 0.300797
 >> iter 75000, loss: 0.347584
 >> iter 76000, loss: 0.341786
 >> iter 77000, loss: 0.327347
 >> iter 78000, loss: 0.491466
 >> iter 79000, loss: 0.451090
 >> iter 80000, loss: 0.506060
   Number of active neurons: 4
 >> iter 81000, loss: 0.472946
 >> iter 82000, loss: 0.469120
 >> iter 83000, loss: 0.499223
 >> iter 84000, loss: 0.490727
 >> iter 85000, loss: 0.382418
 >> iter 86000, loss: 0.302236
 >> iter 87000, loss: 0.424663
 >> iter 88000, loss: 0.312232
 >> iter 89000, loss: 0.279659
 >> iter 90000, loss: 0.257706
   Number of active neurons: 4
 >> iter 91000, loss: 0.279547
 >> iter 92000, loss: 0.338470
 >> iter 93000, loss: 0.413758
 >> iter 94000, loss: 0.397455
 >> iter 95000, loss: 0.412577
 >> iter 96000, loss: 0.420494
 >> iter 97000, loss: 0.311966
 >> iter 98000, loss: 0.290244
 >> iter 99000, loss: 0.463748
 >> iter 100000, loss: 0.574838
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 11.3392440504

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

