 > Problema: tomita7nueva
 > Args:
   - Hidden size: 20
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 16.764071
 >> iter 2000, loss: 11.370689
 >> iter 3000, loss: 6.576812
 >> iter 4000, loss: 3.327142
 >> iter 5000, loss: 1.625537
 >> iter 6000, loss: 0.863262
 >> iter 7000, loss: 0.709453
 >> iter 8000, loss: 0.536060
 >> iter 9000, loss: 0.461477
 >> iter 10000, loss: 0.349780
   Number of active neurons: 11
 >> iter 11000, loss: 0.361976
 >> iter 12000, loss: 0.330508
 >> iter 13000, loss: 0.269770
 >> iter 14000, loss: 0.229859
 >> iter 15000, loss: 0.297636
 >> iter 16000, loss: 0.343152
 >> iter 17000, loss: 0.393342
 >> iter 18000, loss: 0.352021
 >> iter 19000, loss: 0.350643
 >> iter 20000, loss: 0.393732
   Number of active neurons: 9
 >> iter 21000, loss: 0.369037
 >> iter 22000, loss: 0.337531
 >> iter 23000, loss: 0.301758
 >> iter 24000, loss: 0.230875
 >> iter 25000, loss: 0.258954
 >> iter 26000, loss: 0.269156
 >> iter 27000, loss: 0.319832
 >> iter 28000, loss: 0.305323
 >> iter 29000, loss: 0.333444
 >> iter 30000, loss: 0.344002
   Number of active neurons: 8
 >> iter 31000, loss: 0.227983
 >> iter 32000, loss: 0.282566
 >> iter 33000, loss: 0.370875
 >> iter 34000, loss: 0.344156
 >> iter 35000, loss: 0.461609
 >> iter 36000, loss: 0.356708
 >> iter 37000, loss: 0.417069
 >> iter 38000, loss: 0.319931
 >> iter 39000, loss: 0.283607
 >> iter 40000, loss: 0.255805
   Number of active neurons: 8
 >> iter 41000, loss: 0.249694
 >> iter 42000, loss: 0.307136
 >> iter 43000, loss: 0.326886
 >> iter 44000, loss: 0.281693
 >> iter 45000, loss: 0.280038
 >> iter 46000, loss: 0.289625
 >> iter 47000, loss: 0.374076
 >> iter 48000, loss: 0.381627
 >> iter 49000, loss: 0.293944
 >> iter 50000, loss: 0.265292
   Number of active neurons: 7
 >> iter 51000, loss: 0.320038
 >> iter 52000, loss: 0.320580
 >> iter 53000, loss: 0.382155
 >> iter 54000, loss: 0.380703
 >> iter 55000, loss: 0.292091
 >> iter 56000, loss: 0.288058
 >> iter 57000, loss: 0.309568
 >> iter 58000, loss: 0.176467
 >> iter 59000, loss: 0.274398
 >> iter 60000, loss: 0.350066
   Number of active neurons: 7
 >> iter 61000, loss: 0.331086
 >> iter 62000, loss: 0.213712
 >> iter 63000, loss: 0.247355
 >> iter 64000, loss: 0.241446
 >> iter 65000, loss: 0.300050
 >> iter 66000, loss: 0.262588
 >> iter 67000, loss: 0.369981
 >> iter 68000, loss: 0.324877
 >> iter 69000, loss: 0.247482
 >> iter 70000, loss: 0.278693
   Number of active neurons: 7
 >> iter 71000, loss: 0.311800
 >> iter 72000, loss: 0.293855
 >> iter 73000, loss: 0.396898
 >> iter 74000, loss: 0.350192
 >> iter 75000, loss: 0.348540
 >> iter 76000, loss: 0.343232
 >> iter 77000, loss: 0.236856
 >> iter 78000, loss: 0.381938
 >> iter 79000, loss: 0.314614
 >> iter 80000, loss: 0.306710
   Number of active neurons: 7
 >> iter 81000, loss: 0.231597
 >> iter 82000, loss: 0.234794
 >> iter 83000, loss: 0.195900
 >> iter 84000, loss: 0.255642
 >> iter 85000, loss: 0.224060
 >> iter 86000, loss: 0.193139
 >> iter 87000, loss: 0.217104
 >> iter 88000, loss: 0.288179
 >> iter 89000, loss: 0.227988
 >> iter 90000, loss: 0.312555
   Number of active neurons: 7
 >> iter 91000, loss: 0.419875
 >> iter 92000, loss: 0.271387
 >> iter 93000, loss: 0.456097
 >> iter 94000, loss: 0.293543
 >> iter 95000, loss: 0.274942
 >> iter 96000, loss: 0.298141
 >> iter 97000, loss: 0.327096
 >> iter 98000, loss: 0.293648
 >> iter 99000, loss: 0.275350
 >> iter 100000, loss: 0.259912
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455162
   Number of active neurons: 0
 >> iter 1000, loss: 16.695490
 >> iter 2000, loss: 10.064571
 >> iter 3000, loss: 6.286339
 >> iter 4000, loss: 2.787838
 >> iter 5000, loss: 1.239637
 >> iter 6000, loss: 0.622784
 >> iter 7000, loss: 0.534558
 >> iter 8000, loss: 0.352126
 >> iter 9000, loss: 0.205060
 >> iter 10000, loss: 0.231402
   Number of active neurons: 12
 >> iter 11000, loss: 0.222794
 >> iter 12000, loss: 0.170359
 >> iter 13000, loss: 0.246773
 >> iter 14000, loss: 0.197723
 >> iter 15000, loss: 0.245000
 >> iter 16000, loss: 0.238133
 >> iter 17000, loss: 0.254405
 >> iter 18000, loss: 0.281898
 >> iter 19000, loss: 0.314227
 >> iter 20000, loss: 0.275698
   Number of active neurons: 11
 >> iter 21000, loss: 0.197724
 >> iter 22000, loss: 0.201699
 >> iter 23000, loss: 0.240070
 >> iter 24000, loss: 0.194597
 >> iter 25000, loss: 0.322983
 >> iter 26000, loss: 0.328910
 >> iter 27000, loss: 0.316301
 >> iter 28000, loss: 0.219980
 >> iter 29000, loss: 0.309973
 >> iter 30000, loss: 0.256078
   Number of active neurons: 11
 >> iter 31000, loss: 0.232420
 >> iter 32000, loss: 0.206808
 >> iter 33000, loss: 0.227029
 >> iter 34000, loss: 0.139180
 >> iter 35000, loss: 0.259154
 >> iter 36000, loss: 0.211190
 >> iter 37000, loss: 0.241484
 >> iter 38000, loss: 0.184864
 >> iter 39000, loss: 0.213027
 >> iter 40000, loss: 0.274441
   Number of active neurons: 11
 >> iter 41000, loss: 0.173795
 >> iter 42000, loss: 0.207136
 >> iter 43000, loss: 0.204173
 >> iter 44000, loss: 0.223532
 >> iter 45000, loss: 0.277241
 >> iter 46000, loss: 0.188599
 >> iter 47000, loss: 0.159027
 >> iter 48000, loss: 0.148444
 >> iter 49000, loss: 0.222262
 >> iter 50000, loss: 0.156021
   Number of active neurons: 10
 >> iter 51000, loss: 0.115175
 >> iter 52000, loss: 0.254292
 >> iter 53000, loss: 0.164674
 >> iter 54000, loss: 0.138229
 >> iter 55000, loss: 0.161581
 >> iter 56000, loss: 0.275419
 >> iter 57000, loss: 0.200592
 >> iter 58000, loss: 0.292679
 >> iter 59000, loss: 0.301635
 >> iter 60000, loss: 0.279255
   Number of active neurons: 10
 >> iter 61000, loss: 0.174182
 >> iter 62000, loss: 0.252991
 >> iter 63000, loss: 0.149900
 >> iter 64000, loss: 0.141514
 >> iter 65000, loss: 0.253066
 >> iter 66000, loss: 0.340302
 >> iter 67000, loss: 0.248768
 >> iter 68000, loss: 0.208914
 >> iter 69000, loss: 0.278042
 >> iter 70000, loss: 0.179606
   Number of active neurons: 10
 >> iter 71000, loss: 0.225070
 >> iter 72000, loss: 0.188924
 >> iter 73000, loss: 0.196153
 >> iter 74000, loss: 0.154385
 >> iter 75000, loss: 0.164090
 >> iter 76000, loss: 0.207731
 >> iter 77000, loss: 0.167027
 >> iter 78000, loss: 0.143996
 >> iter 79000, loss: 0.186533
 >> iter 80000, loss: 0.215885
   Number of active neurons: 10
 >> iter 81000, loss: 0.192305
 >> iter 82000, loss: 0.203086
 >> iter 83000, loss: 0.171315
 >> iter 84000, loss: 0.216371
 >> iter 85000, loss: 0.243063
 >> iter 86000, loss: 0.236875
 >> iter 87000, loss: 0.189676
 >> iter 88000, loss: 0.306078
 >> iter 89000, loss: 0.219560
 >> iter 90000, loss: 0.234866
   Number of active neurons: 10
 >> iter 91000, loss: 0.241093
 >> iter 92000, loss: 0.338801
 >> iter 93000, loss: 0.222518
 >> iter 94000, loss: 0.221357
 >> iter 95000, loss: 0.194693
 >> iter 96000, loss: 0.268607
 >> iter 97000, loss: 0.239960
 >> iter 98000, loss: 0.209540
 >> iter 99000, loss: 0.223361
 >> iter 100000, loss: 0.238767
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.625781
 >> iter 2000, loss: 10.221336
 >> iter 3000, loss: 6.872690
 >> iter 4000, loss: 4.697527
 >> iter 5000, loss: 3.382412
 >> iter 6000, loss: 2.761619
 >> iter 7000, loss: 2.371982
 >> iter 8000, loss: 2.011086
 >> iter 9000, loss: 1.519541
 >> iter 10000, loss: 1.193935
   Number of active neurons: 7
 >> iter 11000, loss: 0.744503
 >> iter 12000, loss: 0.534894
 >> iter 13000, loss: 0.523246
 >> iter 14000, loss: 0.548881
 >> iter 15000, loss: 0.435982
 >> iter 16000, loss: 0.358824
 >> iter 17000, loss: 0.426621
 >> iter 18000, loss: 0.303051
 >> iter 19000, loss: 0.333673
 >> iter 20000, loss: 0.294863
   Number of active neurons: 6
 >> iter 21000, loss: 0.378159
 >> iter 22000, loss: 0.395627
 >> iter 23000, loss: 0.365876
 >> iter 24000, loss: 0.344022
 >> iter 25000, loss: 0.290966
 >> iter 26000, loss: 0.294039
 >> iter 27000, loss: 0.304059
 >> iter 28000, loss: 0.431217
 >> iter 29000, loss: 0.420440
 >> iter 30000, loss: 0.298395
   Number of active neurons: 6
 >> iter 31000, loss: 0.211582
 >> iter 32000, loss: 0.264158
 >> iter 33000, loss: 0.209559
 >> iter 34000, loss: 0.204995
 >> iter 35000, loss: 0.302070
 >> iter 36000, loss: 0.258226
 >> iter 37000, loss: 0.374128
 >> iter 38000, loss: 0.284146
 >> iter 39000, loss: 0.254955
 >> iter 40000, loss: 0.269797
   Number of active neurons: 6
 >> iter 41000, loss: 0.302445
 >> iter 42000, loss: 0.246863
 >> iter 43000, loss: 0.248626
 >> iter 44000, loss: 0.250503
 >> iter 45000, loss: 0.191183
 >> iter 46000, loss: 0.204727
 >> iter 47000, loss: 0.181137
 >> iter 48000, loss: 0.309505
 >> iter 49000, loss: 0.288721
 >> iter 50000, loss: 0.195389
   Number of active neurons: 6
 >> iter 51000, loss: 0.260045
 >> iter 52000, loss: 0.304179
 >> iter 53000, loss: 0.276578
 >> iter 54000, loss: 0.237631
 >> iter 55000, loss: 0.236469
 >> iter 56000, loss: 0.216104
 >> iter 57000, loss: 0.277226
 >> iter 58000, loss: 0.352619
 >> iter 59000, loss: 0.275890
 >> iter 60000, loss: 0.309868
   Number of active neurons: 6
 >> iter 61000, loss: 0.280609
 >> iter 62000, loss: 0.245653
 >> iter 63000, loss: 0.227280
 >> iter 64000, loss: 0.240140
 >> iter 65000, loss: 0.233651
 >> iter 66000, loss: 0.224631
 >> iter 67000, loss: 0.283207
 >> iter 68000, loss: 0.239205
 >> iter 69000, loss: 0.238681
 >> iter 70000, loss: 0.301767
   Number of active neurons: 5
 >> iter 71000, loss: 0.356079
 >> iter 72000, loss: 0.241270
 >> iter 73000, loss: 0.260817
 >> iter 74000, loss: 0.254174
 >> iter 75000, loss: 0.355035
 >> iter 76000, loss: 0.270244
 >> iter 77000, loss: 0.371585
 >> iter 78000, loss: 0.405189
 >> iter 79000, loss: 0.392116
 >> iter 80000, loss: 0.263581
   Number of active neurons: 5
 >> iter 81000, loss: 0.257460
 >> iter 82000, loss: 0.263893
 >> iter 83000, loss: 0.274067
 >> iter 84000, loss: 0.292228
 >> iter 85000, loss: 0.342337
 >> iter 86000, loss: 0.368436
 >> iter 87000, loss: 0.352447
 >> iter 88000, loss: 0.372075
 >> iter 89000, loss: 0.274873
 >> iter 90000, loss: 0.316740
   Number of active neurons: 5
 >> iter 91000, loss: 0.442955
 >> iter 92000, loss: 0.315225
 >> iter 93000, loss: 0.219125
 >> iter 94000, loss: 0.234435
 >> iter 95000, loss: 0.389636
 >> iter 96000, loss: 0.267051
 >> iter 97000, loss: 0.318822
 >> iter 98000, loss: 0.296308
 >> iter 99000, loss: 0.343280
 >> iter 100000, loss: 0.253267
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 16.640380
 >> iter 2000, loss: 9.086441
 >> iter 3000, loss: 4.189418
 >> iter 4000, loss: 1.895306
 >> iter 5000, loss: 0.951936
 >> iter 6000, loss: 0.504161
 >> iter 7000, loss: 0.455374
 >> iter 8000, loss: 0.349985
 >> iter 9000, loss: 0.317767
 >> iter 10000, loss: 0.325084
   Number of active neurons: 10
 >> iter 11000, loss: 0.327095
 >> iter 12000, loss: 0.347738
 >> iter 13000, loss: 0.260890
 >> iter 14000, loss: 0.260177
 >> iter 15000, loss: 0.239113
 >> iter 16000, loss: 0.238239
 >> iter 17000, loss: 0.435267
 >> iter 18000, loss: 0.459100
 >> iter 19000, loss: 0.467655
 >> iter 20000, loss: 0.383125
   Number of active neurons: 10
 >> iter 21000, loss: 0.466507
 >> iter 22000, loss: 0.431811
 >> iter 23000, loss: 0.385462
 >> iter 24000, loss: 0.297622
 >> iter 25000, loss: 0.257118
 >> iter 26000, loss: 0.198105
 >> iter 27000, loss: 0.199314
 >> iter 28000, loss: 0.336759
 >> iter 29000, loss: 0.313632
 >> iter 30000, loss: 0.262945
   Number of active neurons: 10
 >> iter 31000, loss: 0.369464
 >> iter 32000, loss: 0.314138
 >> iter 33000, loss: 0.315977
 >> iter 34000, loss: 0.288940
 >> iter 35000, loss: 0.350740
 >> iter 36000, loss: 0.374812
 >> iter 37000, loss: 0.376198
 >> iter 38000, loss: 0.281205
 >> iter 39000, loss: 0.217481
 >> iter 40000, loss: 0.222706
   Number of active neurons: 10
 >> iter 41000, loss: 0.267240
 >> iter 42000, loss: 0.360229
 >> iter 43000, loss: 0.404447
 >> iter 44000, loss: 0.225006
 >> iter 45000, loss: 0.290184
 >> iter 46000, loss: 0.173531
 >> iter 47000, loss: 0.187902
 >> iter 48000, loss: 0.173784
 >> iter 49000, loss: 0.125888
 >> iter 50000, loss: 0.266912
   Number of active neurons: 10
 >> iter 51000, loss: 0.310735
 >> iter 52000, loss: 0.292148
 >> iter 53000, loss: 0.269839
 >> iter 54000, loss: 0.198448
 >> iter 55000, loss: 0.269430
 >> iter 56000, loss: 0.195266
 >> iter 57000, loss: 0.153657
 >> iter 58000, loss: 0.236226
 >> iter 59000, loss: 0.276224
 >> iter 60000, loss: 0.290644
   Number of active neurons: 10
 >> iter 61000, loss: 0.329326
 >> iter 62000, loss: 0.236728
 >> iter 63000, loss: 0.244249
 >> iter 64000, loss: 0.224054
 >> iter 65000, loss: 0.213240
 >> iter 66000, loss: 0.387215
 >> iter 67000, loss: 0.269435
 >> iter 68000, loss: 0.297708
 >> iter 69000, loss: 0.365189
 >> iter 70000, loss: 0.244701
   Number of active neurons: 9
 >> iter 71000, loss: 0.303762
 >> iter 72000, loss: 0.268313
 >> iter 73000, loss: 0.236034
 >> iter 74000, loss: 0.210485
 >> iter 75000, loss: 0.257450
 >> iter 76000, loss: 0.240322
 >> iter 77000, loss: 0.199102
 >> iter 78000, loss: 0.222813
 >> iter 79000, loss: 0.273762
 >> iter 80000, loss: 0.261103
   Number of active neurons: 9
 >> iter 81000, loss: 0.354472
 >> iter 82000, loss: 0.293035
 >> iter 83000, loss: 0.248259
 >> iter 84000, loss: 0.282904
 >> iter 85000, loss: 0.301740
 >> iter 86000, loss: 0.235565
 >> iter 87000, loss: 0.301027
 >> iter 88000, loss: 0.360643
 >> iter 89000, loss: 0.237194
 >> iter 90000, loss: 0.221269
   Number of active neurons: 9
 >> iter 91000, loss: 0.234929
 >> iter 92000, loss: 0.218858
 >> iter 93000, loss: 0.323941
 >> iter 94000, loss: 0.278392
 >> iter 95000, loss: 0.285130
 >> iter 96000, loss: 0.286864
 >> iter 97000, loss: 0.212872
 >> iter 98000, loss: 0.331396
 >> iter 99000, loss: 0.224269
 >> iter 100000, loss: 0.267472
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 16.804567
 >> iter 2000, loss: 10.006443
 >> iter 3000, loss: 6.420587
 >> iter 4000, loss: 3.913582
 >> iter 5000, loss: 2.279938
 >> iter 6000, loss: 1.345937
 >> iter 7000, loss: 0.832740
 >> iter 8000, loss: 0.719458
 >> iter 9000, loss: 0.619818
 >> iter 10000, loss: 0.471244
   Number of active neurons: 10
 >> iter 11000, loss: 0.508882
 >> iter 12000, loss: 0.310361
 >> iter 13000, loss: 0.265646
 >> iter 14000, loss: 0.437473
 >> iter 15000, loss: 0.304883
 >> iter 16000, loss: 0.331503
 >> iter 17000, loss: 0.280820
 >> iter 18000, loss: 0.275629
 >> iter 19000, loss: 0.316213
 >> iter 20000, loss: 0.279064
   Number of active neurons: 10
 >> iter 21000, loss: 0.304438
 >> iter 22000, loss: 0.405914
 >> iter 23000, loss: 0.431342
 >> iter 24000, loss: 0.412458
 >> iter 25000, loss: 0.348451
 >> iter 26000, loss: 0.219612
 >> iter 27000, loss: 0.310912
 >> iter 28000, loss: 0.329906
 >> iter 29000, loss: 0.229337
 >> iter 30000, loss: 0.372475
   Number of active neurons: 10
 >> iter 31000, loss: 0.368121
 >> iter 32000, loss: 0.354017
 >> iter 33000, loss: 0.448052
 >> iter 34000, loss: 0.349219
 >> iter 35000, loss: 0.287412
 >> iter 36000, loss: 0.323894
 >> iter 37000, loss: 0.263878
 >> iter 38000, loss: 0.360693
 >> iter 39000, loss: 0.355498
 >> iter 40000, loss: 0.380857
   Number of active neurons: 9
 >> iter 41000, loss: 0.357839
 >> iter 42000, loss: 0.285589
 >> iter 43000, loss: 0.279097
 >> iter 44000, loss: 0.319736
 >> iter 45000, loss: 0.409156
 >> iter 46000, loss: 0.334948
 >> iter 47000, loss: 0.431406
 >> iter 48000, loss: 0.386839
 >> iter 49000, loss: 0.325570
 >> iter 50000, loss: 0.261149
   Number of active neurons: 9
 >> iter 51000, loss: 0.255429
 >> iter 52000, loss: 0.180602
 >> iter 53000, loss: 0.401159
 >> iter 54000, loss: 0.327782
 >> iter 55000, loss: 0.316600
 >> iter 56000, loss: 0.349315
 >> iter 57000, loss: 0.427206
 >> iter 58000, loss: 0.473752
 >> iter 59000, loss: 0.340206
 >> iter 60000, loss: 0.333135
   Number of active neurons: 8
 >> iter 61000, loss: 0.399139
 >> iter 62000, loss: 0.259704
 >> iter 63000, loss: 0.269394
 >> iter 64000, loss: 0.268959
 >> iter 65000, loss: 0.355710
 >> iter 66000, loss: 0.371171
 >> iter 67000, loss: 0.383551
 >> iter 68000, loss: 0.245952
 >> iter 69000, loss: 0.305763
 >> iter 70000, loss: 0.377654
   Number of active neurons: 8
 >> iter 71000, loss: 0.438468
 >> iter 72000, loss: 0.360929
 >> iter 73000, loss: 0.345519
 >> iter 74000, loss: 0.359639
 >> iter 75000, loss: 0.329663
 >> iter 76000, loss: 0.353142
 >> iter 77000, loss: 0.366090
 >> iter 78000, loss: 0.273221
 >> iter 79000, loss: 0.205207
 >> iter 80000, loss: 0.152432
   Number of active neurons: 8
 >> iter 81000, loss: 0.305670
 >> iter 82000, loss: 0.262309
 >> iter 83000, loss: 0.325084
 >> iter 84000, loss: 0.290056
 >> iter 85000, loss: 0.236738
 >> iter 86000, loss: 0.263759
 >> iter 87000, loss: 0.217289
 >> iter 88000, loss: 0.285893
 >> iter 89000, loss: 0.256118
 >> iter 90000, loss: 0.224182
   Number of active neurons: 7
 >> iter 91000, loss: 0.289432
 >> iter 92000, loss: 0.290590
 >> iter 93000, loss: 0.391896
 >> iter 94000, loss: 0.290894
 >> iter 95000, loss: 0.238054
 >> iter 96000, loss: 0.318033
 >> iter 97000, loss: 0.300574
 >> iter 98000, loss: 0.305278
 >> iter 99000, loss: 0.260722
 >> iter 100000, loss: 0.248138
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 16.479451
 >> iter 2000, loss: 9.603218
 >> iter 3000, loss: 6.136970
 >> iter 4000, loss: 3.418884
 >> iter 5000, loss: 1.764990
 >> iter 6000, loss: 0.976424
 >> iter 7000, loss: 0.738530
 >> iter 8000, loss: 0.630747
 >> iter 9000, loss: 0.544858
 >> iter 10000, loss: 0.391784
   Number of active neurons: 10
 >> iter 11000, loss: 0.416086
 >> iter 12000, loss: 0.342836
 >> iter 13000, loss: 0.218471
 >> iter 14000, loss: 0.303900
 >> iter 15000, loss: 0.437738
 >> iter 16000, loss: 0.514862
 >> iter 17000, loss: 0.351904
 >> iter 18000, loss: 0.327947
 >> iter 19000, loss: 0.366555
 >> iter 20000, loss: 0.318594
   Number of active neurons: 9
 >> iter 21000, loss: 0.385455
 >> iter 22000, loss: 0.496848
 >> iter 23000, loss: 0.412966
 >> iter 24000, loss: 0.396567
 >> iter 25000, loss: 0.293934
 >> iter 26000, loss: 0.291869
 >> iter 27000, loss: 0.283621
 >> iter 28000, loss: 0.478367
 >> iter 29000, loss: 0.457377
 >> iter 30000, loss: 0.412903
   Number of active neurons: 8
 >> iter 31000, loss: 0.388816
 >> iter 32000, loss: 0.362704
 >> iter 33000, loss: 0.503536
 >> iter 34000, loss: 0.343015
 >> iter 35000, loss: 0.299309
 >> iter 36000, loss: 0.435118
 >> iter 37000, loss: 0.361657
 >> iter 38000, loss: 0.349185
 >> iter 39000, loss: 0.325355
 >> iter 40000, loss: 0.300792
   Number of active neurons: 8
 >> iter 41000, loss: 0.307879
 >> iter 42000, loss: 0.400313
 >> iter 43000, loss: 0.361669
 >> iter 44000, loss: 0.362308
 >> iter 45000, loss: 0.401837
 >> iter 46000, loss: 0.429890
 >> iter 47000, loss: 0.328275
 >> iter 48000, loss: 0.320137
 >> iter 49000, loss: 0.203822
 >> iter 50000, loss: 0.228795
   Number of active neurons: 6
 >> iter 51000, loss: 0.253567
 >> iter 52000, loss: 0.350732
 >> iter 53000, loss: 0.420610
 >> iter 54000, loss: 0.348733
 >> iter 55000, loss: 0.357484
 >> iter 56000, loss: 0.277808
 >> iter 57000, loss: 0.237426
 >> iter 58000, loss: 0.307730
 >> iter 59000, loss: 0.296631
 >> iter 60000, loss: 0.372952
   Number of active neurons: 5
 >> iter 61000, loss: 0.258414
 >> iter 62000, loss: 0.227034
 >> iter 63000, loss: 0.240555
 >> iter 64000, loss: 0.307982
 >> iter 65000, loss: 0.294869
 >> iter 66000, loss: 0.322215
 >> iter 67000, loss: 0.242417
 >> iter 68000, loss: 0.213204
 >> iter 69000, loss: 0.342498
 >> iter 70000, loss: 0.427714
   Number of active neurons: 5
 >> iter 71000, loss: 0.455243
 >> iter 72000, loss: 0.426596
 >> iter 73000, loss: 0.470169
 >> iter 74000, loss: 0.355902
 >> iter 75000, loss: 0.408052
 >> iter 76000, loss: 0.398359
 >> iter 77000, loss: 0.421232
 >> iter 78000, loss: 0.487387
 >> iter 79000, loss: 0.535940
 >> iter 80000, loss: 0.357576
   Number of active neurons: 5
 >> iter 81000, loss: 0.389353
 >> iter 82000, loss: 0.386050
 >> iter 83000, loss: 0.398905
 >> iter 84000, loss: 0.280734
 >> iter 85000, loss: 0.368785
 >> iter 86000, loss: 0.297259
 >> iter 87000, loss: 0.252179
 >> iter 88000, loss: 0.253206
 >> iter 89000, loss: 0.305271
 >> iter 90000, loss: 0.319014
   Number of active neurons: 5
 >> iter 91000, loss: 0.320875
 >> iter 92000, loss: 0.272768
 >> iter 93000, loss: 0.374449
 >> iter 94000, loss: 0.359821
 >> iter 95000, loss: 0.337616
 >> iter 96000, loss: 0.405606
 >> iter 97000, loss: 0.298726
 >> iter 98000, loss: 0.348007
 >> iter 99000, loss: 0.438928
 >> iter 100000, loss: 0.337775
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.472080
 >> iter 2000, loss: 9.926372
 >> iter 3000, loss: 5.644616
 >> iter 4000, loss: 2.570945
 >> iter 5000, loss: 1.315130
 >> iter 6000, loss: 0.814107
 >> iter 7000, loss: 0.633596
 >> iter 8000, loss: 0.446913
 >> iter 9000, loss: 0.368535
 >> iter 10000, loss: 0.531696
   Number of active neurons: 12
 >> iter 11000, loss: 0.648788
 >> iter 12000, loss: 0.542980
 >> iter 13000, loss: 0.363566
 >> iter 14000, loss: 0.274093
 >> iter 15000, loss: 0.284268
 >> iter 16000, loss: 0.314984
 >> iter 17000, loss: 0.379627
 >> iter 18000, loss: 0.472141
 >> iter 19000, loss: 0.347950
 >> iter 20000, loss: 0.473799
   Number of active neurons: 12
 >> iter 21000, loss: 0.327331
 >> iter 22000, loss: 0.397185
 >> iter 23000, loss: 0.363258
 >> iter 24000, loss: 0.296346
 >> iter 25000, loss: 0.385408
 >> iter 26000, loss: 0.330487
 >> iter 27000, loss: 0.416924
 >> iter 28000, loss: 0.438068
 >> iter 29000, loss: 0.390943
 >> iter 30000, loss: 0.332000
   Number of active neurons: 11
 >> iter 31000, loss: 0.407317
 >> iter 32000, loss: 0.454910
 >> iter 33000, loss: 0.363451
 >> iter 34000, loss: 0.316397
 >> iter 35000, loss: 0.344100
 >> iter 36000, loss: 0.347263
 >> iter 37000, loss: 0.349986
 >> iter 38000, loss: 0.304686
 >> iter 39000, loss: 0.294149
 >> iter 40000, loss: 0.346109
   Number of active neurons: 10
 >> iter 41000, loss: 0.354936
 >> iter 42000, loss: 0.262735
 >> iter 43000, loss: 0.317815
 >> iter 44000, loss: 0.351892
 >> iter 45000, loss: 0.422719
 >> iter 46000, loss: 0.406417
 >> iter 47000, loss: 0.326485
 >> iter 48000, loss: 0.253559
 >> iter 49000, loss: 0.300747
 >> iter 50000, loss: 0.248021
   Number of active neurons: 9
 >> iter 51000, loss: 0.249295
 >> iter 52000, loss: 0.428148
 >> iter 53000, loss: 0.364039
 >> iter 54000, loss: 0.310855
 >> iter 55000, loss: 0.295917
 >> iter 56000, loss: 0.243481
 >> iter 57000, loss: 0.323341
 >> iter 58000, loss: 0.323190
 >> iter 59000, loss: 0.285489
 >> iter 60000, loss: 0.207978
   Number of active neurons: 9
 >> iter 61000, loss: 0.159033
 >> iter 62000, loss: 0.190911
 >> iter 63000, loss: 0.165530
 >> iter 64000, loss: 0.447814
 >> iter 65000, loss: 0.302132
 >> iter 66000, loss: 0.320827
 >> iter 67000, loss: 0.228384
 >> iter 68000, loss: 0.250136
 >> iter 69000, loss: 0.284817
 >> iter 70000, loss: 0.291628
   Number of active neurons: 9
 >> iter 71000, loss: 0.250756
 >> iter 72000, loss: 0.304252
 >> iter 73000, loss: 0.316487
 >> iter 74000, loss: 0.254057
 >> iter 75000, loss: 0.329502
 >> iter 76000, loss: 0.340013
 >> iter 77000, loss: 0.478910
 >> iter 78000, loss: 0.381816
 >> iter 79000, loss: 0.361072
 >> iter 80000, loss: 0.312117
   Number of active neurons: 9
 >> iter 81000, loss: 0.277215
 >> iter 82000, loss: 0.289344
 >> iter 83000, loss: 0.355098
 >> iter 84000, loss: 0.391714
 >> iter 85000, loss: 0.296108
 >> iter 86000, loss: 0.202799
 >> iter 87000, loss: 0.249324
 >> iter 88000, loss: 0.289290
 >> iter 89000, loss: 0.274820
 >> iter 90000, loss: 0.233862
   Number of active neurons: 9
 >> iter 91000, loss: 0.243312
 >> iter 92000, loss: 0.183682
 >> iter 93000, loss: 0.248218
 >> iter 94000, loss: 0.227092
 >> iter 95000, loss: 0.162453
 >> iter 96000, loss: 0.233893
 >> iter 97000, loss: 0.220146
 >> iter 98000, loss: 0.294752
 >> iter 99000, loss: 0.291479
 >> iter 100000, loss: 0.246311
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.504016
 >> iter 2000, loss: 9.896030
 >> iter 3000, loss: 6.783866
 >> iter 4000, loss: 4.314128
 >> iter 5000, loss: 2.391859
 >> iter 6000, loss: 1.438117
 >> iter 7000, loss: 0.871752
 >> iter 8000, loss: 0.546559
 >> iter 9000, loss: 0.440264
 >> iter 10000, loss: 0.464139
   Number of active neurons: 8
 >> iter 11000, loss: 0.428127
 >> iter 12000, loss: 0.299899
 >> iter 13000, loss: 0.310838
 >> iter 14000, loss: 0.357066
 >> iter 15000, loss: 0.322034
 >> iter 16000, loss: 0.294777
 >> iter 17000, loss: 0.257763
 >> iter 18000, loss: 0.189233
 >> iter 19000, loss: 0.367363
 >> iter 20000, loss: 0.281038
   Number of active neurons: 8
 >> iter 21000, loss: 0.207439
 >> iter 22000, loss: 0.283341
 >> iter 23000, loss: 0.224002
 >> iter 24000, loss: 0.232451
 >> iter 25000, loss: 0.235988
 >> iter 26000, loss: 0.232732
 >> iter 27000, loss: 0.278487
 >> iter 28000, loss: 0.288179
 >> iter 29000, loss: 0.246313
 >> iter 30000, loss: 0.359706
   Number of active neurons: 8
 >> iter 31000, loss: 0.340302
 >> iter 32000, loss: 0.244794
 >> iter 33000, loss: 0.247441
 >> iter 34000, loss: 0.197975
 >> iter 35000, loss: 0.317205
 >> iter 36000, loss: 0.399994
 >> iter 37000, loss: 0.354211
 >> iter 38000, loss: 0.365657
 >> iter 39000, loss: 0.226046
 >> iter 40000, loss: 0.199334
   Number of active neurons: 8
 >> iter 41000, loss: 0.228407
 >> iter 42000, loss: 0.200857
 >> iter 43000, loss: 0.214732
 >> iter 44000, loss: 0.255039
 >> iter 45000, loss: 0.260300
 >> iter 46000, loss: 0.254849
 >> iter 47000, loss: 0.220738
 >> iter 48000, loss: 0.244865
 >> iter 49000, loss: 0.272241
 >> iter 50000, loss: 0.229752
   Number of active neurons: 8
 >> iter 51000, loss: 0.257191
 >> iter 52000, loss: 0.259118
 >> iter 53000, loss: 0.250273
 >> iter 54000, loss: 0.244171
 >> iter 55000, loss: 0.237292
 >> iter 56000, loss: 0.258784
 >> iter 57000, loss: 0.316618
 >> iter 58000, loss: 0.260770
 >> iter 59000, loss: 0.356498
 >> iter 60000, loss: 0.221434
   Number of active neurons: 8
 >> iter 61000, loss: 0.214535
 >> iter 62000, loss: 0.249820
 >> iter 63000, loss: 0.250574
 >> iter 64000, loss: 0.251173
 >> iter 65000, loss: 0.315867
 >> iter 66000, loss: 0.240646
 >> iter 67000, loss: 0.363294
 >> iter 68000, loss: 0.347757
 >> iter 69000, loss: 0.333319
 >> iter 70000, loss: 0.310079
   Number of active neurons: 8
 >> iter 71000, loss: 0.238513
 >> iter 72000, loss: 0.158517
 >> iter 73000, loss: 0.347914
 >> iter 74000, loss: 0.299069
 >> iter 75000, loss: 0.324987
 >> iter 76000, loss: 0.312088
 >> iter 77000, loss: 0.258763
 >> iter 78000, loss: 0.205040
 >> iter 79000, loss: 0.213444
 >> iter 80000, loss: 0.324218
   Number of active neurons: 8
 >> iter 81000, loss: 0.368229
 >> iter 82000, loss: 0.238302
 >> iter 83000, loss: 0.263243
 >> iter 84000, loss: 0.372555
 >> iter 85000, loss: 0.302587
 >> iter 86000, loss: 0.243990
 >> iter 87000, loss: 0.278501
 >> iter 88000, loss: 0.299922
 >> iter 89000, loss: 0.270947
 >> iter 90000, loss: 0.239649
   Number of active neurons: 7
 >> iter 91000, loss: 0.201493
 >> iter 92000, loss: 0.366404
 >> iter 93000, loss: 0.294810
 >> iter 94000, loss: 0.262465
 >> iter 95000, loss: 0.245638
 >> iter 96000, loss: 0.224079
 >> iter 97000, loss: 0.209816
 >> iter 98000, loss: 0.158995
 >> iter 99000, loss: 0.341890
 >> iter 100000, loss: 0.237196
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 16.436252
 >> iter 2000, loss: 9.949568
 >> iter 3000, loss: 6.670166
 >> iter 4000, loss: 3.613586
 >> iter 5000, loss: 1.788698
 >> iter 6000, loss: 1.011346
 >> iter 7000, loss: 0.808541
 >> iter 8000, loss: 0.641686
 >> iter 9000, loss: 0.437231
 >> iter 10000, loss: 0.260598
   Number of active neurons: 11
 >> iter 11000, loss: 0.281519
 >> iter 12000, loss: 0.309643
 >> iter 13000, loss: 0.222794
 >> iter 14000, loss: 0.355147
 >> iter 15000, loss: 0.242614
 >> iter 16000, loss: 0.233663
 >> iter 17000, loss: 0.356138
 >> iter 18000, loss: 0.321768
 >> iter 19000, loss: 0.319150
 >> iter 20000, loss: 0.223466
   Number of active neurons: 11
 >> iter 21000, loss: 0.258056
 >> iter 22000, loss: 0.312361
 >> iter 23000, loss: 0.234025
 >> iter 24000, loss: 0.288761
 >> iter 25000, loss: 0.300482
 >> iter 26000, loss: 0.215872
 >> iter 27000, loss: 0.284327
 >> iter 28000, loss: 0.240481
 >> iter 29000, loss: 0.192055
 >> iter 30000, loss: 0.192648
   Number of active neurons: 10
 >> iter 31000, loss: 0.198704
 >> iter 32000, loss: 0.292397
 >> iter 33000, loss: 0.434498
 >> iter 34000, loss: 0.266505
 >> iter 35000, loss: 0.203303
 >> iter 36000, loss: 0.171714
 >> iter 37000, loss: 0.201973
 >> iter 38000, loss: 0.222212
 >> iter 39000, loss: 0.402334
 >> iter 40000, loss: 0.322709
   Number of active neurons: 9
 >> iter 41000, loss: 0.211539
 >> iter 42000, loss: 0.201341
 >> iter 43000, loss: 0.169838
 >> iter 44000, loss: 0.193886
 >> iter 45000, loss: 0.192029
 >> iter 46000, loss: 0.236979
 >> iter 47000, loss: 0.204362
 >> iter 48000, loss: 0.174456
 >> iter 49000, loss: 0.174443
 >> iter 50000, loss: 0.248085
   Number of active neurons: 9
 >> iter 51000, loss: 0.211880
 >> iter 52000, loss: 0.319527
 >> iter 53000, loss: 0.269553
 >> iter 54000, loss: 0.334554
 >> iter 55000, loss: 0.261610
 >> iter 56000, loss: 0.210120
 >> iter 57000, loss: 0.193916
 >> iter 58000, loss: 0.325804
 >> iter 59000, loss: 0.197174
 >> iter 60000, loss: 0.200386
   Number of active neurons: 9
 >> iter 61000, loss: 0.232093
 >> iter 62000, loss: 0.209239
 >> iter 63000, loss: 0.182583
 >> iter 64000, loss: 0.158366
 >> iter 65000, loss: 0.167193
 >> iter 66000, loss: 0.145513
 >> iter 67000, loss: 0.248833
 >> iter 68000, loss: 0.251771
 >> iter 69000, loss: 0.202204
 >> iter 70000, loss: 0.150675
   Number of active neurons: 9
 >> iter 71000, loss: 0.159411
 >> iter 72000, loss: 0.139822
 >> iter 73000, loss: 0.180795
 >> iter 74000, loss: 0.143642
 >> iter 75000, loss: 0.170087
 >> iter 76000, loss: 0.196463
 >> iter 77000, loss: 0.262864
 >> iter 78000, loss: 0.230940
 >> iter 79000, loss: 0.267285
 >> iter 80000, loss: 0.205322
   Number of active neurons: 9
 >> iter 81000, loss: 0.208472
 >> iter 82000, loss: 0.159564
 >> iter 83000, loss: 0.174333
 >> iter 84000, loss: 0.219715
 >> iter 85000, loss: 0.327789
 >> iter 86000, loss: 0.177604
 >> iter 87000, loss: 0.148531
 >> iter 88000, loss: 0.207907
 >> iter 89000, loss: 0.213549
 >> iter 90000, loss: 0.175255
   Number of active neurons: 9
 >> iter 91000, loss: 0.171214
 >> iter 92000, loss: 0.166186
 >> iter 93000, loss: 0.187628
 >> iter 94000, loss: 0.184495
 >> iter 95000, loss: 0.187949
 >> iter 96000, loss: 0.279702
 >> iter 97000, loss: 0.243490
 >> iter 98000, loss: 0.218941
 >> iter 99000, loss: 0.201273
 >> iter 100000, loss: 0.270018
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 16.488739
 >> iter 2000, loss: 9.518685
 >> iter 3000, loss: 4.583397
 >> iter 4000, loss: 2.018149
 >> iter 5000, loss: 0.885203
 >> iter 6000, loss: 0.580485
 >> iter 7000, loss: 0.388667
 >> iter 8000, loss: 0.301259
 >> iter 9000, loss: 0.339700
 >> iter 10000, loss: 0.331124
   Number of active neurons: 12
 >> iter 11000, loss: 0.300636
 >> iter 12000, loss: 0.350881
 >> iter 13000, loss: 0.250844
 >> iter 14000, loss: 0.210305
 >> iter 15000, loss: 0.344002
 >> iter 16000, loss: 0.225386
 >> iter 17000, loss: 0.252922
 >> iter 18000, loss: 0.385919
 >> iter 19000, loss: 0.299045
 >> iter 20000, loss: 0.310243
   Number of active neurons: 11
 >> iter 21000, loss: 0.349317
 >> iter 22000, loss: 0.327923
 >> iter 23000, loss: 0.460253
 >> iter 24000, loss: 0.344571
 >> iter 25000, loss: 0.379476
 >> iter 26000, loss: 0.293015
 >> iter 27000, loss: 0.279134
 >> iter 28000, loss: 0.478850
 >> iter 29000, loss: 0.525231
 >> iter 30000, loss: 0.300097
   Number of active neurons: 11
 >> iter 31000, loss: 0.410055
 >> iter 32000, loss: 0.366100
 >> iter 33000, loss: 0.223390
 >> iter 34000, loss: 0.332856
 >> iter 35000, loss: 0.278043
 >> iter 36000, loss: 0.362470
 >> iter 37000, loss: 0.343401
 >> iter 38000, loss: 0.335660
 >> iter 39000, loss: 0.321286
 >> iter 40000, loss: 0.373145
   Number of active neurons: 10
 >> iter 41000, loss: 0.319307
 >> iter 42000, loss: 0.293784
 >> iter 43000, loss: 0.426420
 >> iter 44000, loss: 0.226696
 >> iter 45000, loss: 0.193075
 >> iter 46000, loss: 0.172157
 >> iter 47000, loss: 0.320175
 >> iter 48000, loss: 0.339026
 >> iter 49000, loss: 0.330687
 >> iter 50000, loss: 0.326312
   Number of active neurons: 10
 >> iter 51000, loss: 0.310567
 >> iter 52000, loss: 0.285894
 >> iter 53000, loss: 0.225625
 >> iter 54000, loss: 0.260276
 >> iter 55000, loss: 0.316781
 >> iter 56000, loss: 0.266670
 >> iter 57000, loss: 0.280085
 >> iter 58000, loss: 0.290968
 >> iter 59000, loss: 0.310348
 >> iter 60000, loss: 0.202614
   Number of active neurons: 10
 >> iter 61000, loss: 0.298213
 >> iter 62000, loss: 0.329570
 >> iter 63000, loss: 0.352970
 >> iter 64000, loss: 0.309793
 >> iter 65000, loss: 0.291671
 >> iter 66000, loss: 0.260047
 >> iter 67000, loss: 0.237555
 >> iter 68000, loss: 0.383191
 >> iter 69000, loss: 0.525705
 >> iter 70000, loss: 0.412692
   Number of active neurons: 10
 >> iter 71000, loss: 0.422108
 >> iter 72000, loss: 0.293189
 >> iter 73000, loss: 0.287030
 >> iter 74000, loss: 0.294531
 >> iter 75000, loss: 0.285629
 >> iter 76000, loss: 0.214376
 >> iter 77000, loss: 0.258853
 >> iter 78000, loss: 0.364530
 >> iter 79000, loss: 0.281670
 >> iter 80000, loss: 0.310807
   Number of active neurons: 10
 >> iter 81000, loss: 0.382312
 >> iter 82000, loss: 0.277953
 >> iter 83000, loss: 0.281870
 >> iter 84000, loss: 0.188011
 >> iter 85000, loss: 0.278293
 >> iter 86000, loss: 0.332093
 >> iter 87000, loss: 0.379530
 >> iter 88000, loss: 0.530980
 >> iter 89000, loss: 0.392999
 >> iter 90000, loss: 0.443926
   Number of active neurons: 10
 >> iter 91000, loss: 0.270672
 >> iter 92000, loss: 0.197229
 >> iter 93000, loss: 0.392175
 >> iter 94000, loss: 0.349391
 >> iter 95000, loss: 0.411641
 >> iter 96000, loss: 0.382911
 >> iter 97000, loss: 0.258072
 >> iter 98000, loss: 0.291490
 >> iter 99000, loss: 0.291545
 >> iter 100000, loss: 0.299098
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 16.869684
 >> iter 2000, loss: 9.869213
 >> iter 3000, loss: 5.614691
 >> iter 4000, loss: 3.242106
 >> iter 5000, loss: 1.897234
 >> iter 6000, loss: 1.122208
 >> iter 7000, loss: 1.022686
 >> iter 8000, loss: 0.743280
 >> iter 9000, loss: 0.638991
 >> iter 10000, loss: 0.709433
   Number of active neurons: 9
 >> iter 11000, loss: 0.488074
 >> iter 12000, loss: 0.434872
 >> iter 13000, loss: 0.296789
 >> iter 14000, loss: 0.481152
 >> iter 15000, loss: 0.464105
 >> iter 16000, loss: 0.674922
 >> iter 17000, loss: 0.589939
 >> iter 18000, loss: 0.483011
 >> iter 19000, loss: 0.647150
 >> iter 20000, loss: 0.614789
   Number of active neurons: 9
 >> iter 21000, loss: 0.601952
 >> iter 22000, loss: 0.697921
 >> iter 23000, loss: 0.458845
 >> iter 24000, loss: 0.546244
 >> iter 25000, loss: 0.413269
 >> iter 26000, loss: 0.404786
 >> iter 27000, loss: 0.465887
 >> iter 28000, loss: 0.561417
 >> iter 29000, loss: 0.726787
 >> iter 30000, loss: 0.552732
   Number of active neurons: 7
 >> iter 31000, loss: 0.526265
 >> iter 32000, loss: 0.526789
 >> iter 33000, loss: 0.700647
 >> iter 34000, loss: 0.676891
 >> iter 35000, loss: 0.585814
 >> iter 36000, loss: 0.483409
 >> iter 37000, loss: 0.634424
 >> iter 38000, loss: 0.474283
 >> iter 39000, loss: 0.468307
 >> iter 40000, loss: 0.580130
   Number of active neurons: 7
 >> iter 41000, loss: 0.424484
 >> iter 42000, loss: 0.476048
 >> iter 43000, loss: 0.445535
 >> iter 44000, loss: 0.434856
 >> iter 45000, loss: 0.402860
 >> iter 46000, loss: 0.496119
 >> iter 47000, loss: 0.470371
 >> iter 48000, loss: 0.522145
 >> iter 49000, loss: 0.688256
 >> iter 50000, loss: 0.666100
   Number of active neurons: 7
 >> iter 51000, loss: 0.473703
 >> iter 52000, loss: 0.488925
 >> iter 53000, loss: 0.550004
 >> iter 54000, loss: 0.333035
 >> iter 55000, loss: 0.427967
 >> iter 56000, loss: 0.447371
 >> iter 57000, loss: 0.381053
 >> iter 58000, loss: 0.437847
 >> iter 59000, loss: 0.570229
 >> iter 60000, loss: 0.608935
   Number of active neurons: 7
 >> iter 61000, loss: 0.535393
 >> iter 62000, loss: 0.554422
 >> iter 63000, loss: 0.487915
 >> iter 64000, loss: 0.625106
 >> iter 65000, loss: 0.587597
 >> iter 66000, loss: 0.548420
 >> iter 67000, loss: 0.519611
 >> iter 68000, loss: 0.563952
 >> iter 69000, loss: 0.560129
 >> iter 70000, loss: 0.475078
   Number of active neurons: 6
 >> iter 71000, loss: 0.555852
 >> iter 72000, loss: 0.470393
 >> iter 73000, loss: 0.362958
 >> iter 74000, loss: 0.493127
 >> iter 75000, loss: 0.587105
 >> iter 76000, loss: 0.457069
 >> iter 77000, loss: 0.582064
 >> iter 78000, loss: 0.577324
 >> iter 79000, loss: 0.488621
 >> iter 80000, loss: 0.524476
   Number of active neurons: 6
 >> iter 81000, loss: 0.416934
 >> iter 82000, loss: 0.572750
 >> iter 83000, loss: 0.833106
 >> iter 84000, loss: 0.689973
 >> iter 85000, loss: 0.502832
 >> iter 86000, loss: 0.407628
 >> iter 87000, loss: 0.449778
 >> iter 88000, loss: 0.595771
 >> iter 89000, loss: 0.555643
 >> iter 90000, loss: 0.490458
   Number of active neurons: 6
 >> iter 91000, loss: 0.496544
 >> iter 92000, loss: 0.420168
 >> iter 93000, loss: 0.366179
 >> iter 94000, loss: 0.315062
 >> iter 95000, loss: 0.487935
 >> iter 96000, loss: 0.371066
 >> iter 97000, loss: 0.456658
 >> iter 98000, loss: 0.584275
 >> iter 99000, loss: 0.568093
 >> iter 100000, loss: 0.565351
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455161
   Number of active neurons: 0
 >> iter 1000, loss: 16.743289
 >> iter 2000, loss: 9.712892
 >> iter 3000, loss: 5.936537
 >> iter 4000, loss: 3.036157
 >> iter 5000, loss: 1.465604
 >> iter 6000, loss: 0.887418
 >> iter 7000, loss: 0.539740
 >> iter 8000, loss: 0.402558
 >> iter 9000, loss: 0.293483
 >> iter 10000, loss: 0.242925
   Number of active neurons: 8
 >> iter 11000, loss: 0.337025
 >> iter 12000, loss: 0.240297
 >> iter 13000, loss: 0.377921
 >> iter 14000, loss: 0.300754
 >> iter 15000, loss: 0.222896
 >> iter 16000, loss: 0.246940
 >> iter 17000, loss: 0.413298
 >> iter 18000, loss: 0.298841
 >> iter 19000, loss: 0.280886
 >> iter 20000, loss: 0.216045
   Number of active neurons: 8
 >> iter 21000, loss: 0.208663
 >> iter 22000, loss: 0.200791
 >> iter 23000, loss: 0.251418
 >> iter 24000, loss: 0.258998
 >> iter 25000, loss: 0.297312
 >> iter 26000, loss: 0.278404
 >> iter 27000, loss: 0.248031
 >> iter 28000, loss: 0.198085
 >> iter 29000, loss: 0.282427
 >> iter 30000, loss: 0.230660
   Number of active neurons: 8
 >> iter 31000, loss: 0.288848
 >> iter 32000, loss: 0.226784
 >> iter 33000, loss: 0.355088
 >> iter 34000, loss: 0.321909
 >> iter 35000, loss: 0.203915
 >> iter 36000, loss: 0.284772
 >> iter 37000, loss: 0.309203
 >> iter 38000, loss: 0.202014
 >> iter 39000, loss: 0.241331
 >> iter 40000, loss: 0.231039
   Number of active neurons: 8
 >> iter 41000, loss: 0.216131
 >> iter 42000, loss: 0.320903
 >> iter 43000, loss: 0.259186
 >> iter 44000, loss: 0.192647
 >> iter 45000, loss: 0.192467
 >> iter 46000, loss: 0.273639
 >> iter 47000, loss: 0.224937
 >> iter 48000, loss: 0.233167
 >> iter 49000, loss: 0.206297
 >> iter 50000, loss: 0.244973
   Number of active neurons: 7
 >> iter 51000, loss: 0.302815
 >> iter 52000, loss: 0.337671
 >> iter 53000, loss: 0.255227
 >> iter 54000, loss: 0.267004
 >> iter 55000, loss: 0.313231
 >> iter 56000, loss: 0.211332
 >> iter 57000, loss: 0.282490
 >> iter 58000, loss: 0.285684
 >> iter 59000, loss: 0.202132
 >> iter 60000, loss: 0.225344
   Number of active neurons: 5
 >> iter 61000, loss: 0.248539
 >> iter 62000, loss: 0.279406
 >> iter 63000, loss: 0.273113
 >> iter 64000, loss: 0.168106
 >> iter 65000, loss: 0.239705
 >> iter 66000, loss: 0.171052
 >> iter 67000, loss: 0.213996
 >> iter 68000, loss: 0.165301
 >> iter 69000, loss: 0.215872
 >> iter 70000, loss: 0.244949
   Number of active neurons: 5
 >> iter 71000, loss: 0.177620
 >> iter 72000, loss: 0.210711
 >> iter 73000, loss: 0.222809
 >> iter 74000, loss: 0.218765
 >> iter 75000, loss: 0.337900
 >> iter 76000, loss: 0.282298
 >> iter 77000, loss: 0.223382
 >> iter 78000, loss: 0.146858
 >> iter 79000, loss: 0.243203
 >> iter 80000, loss: 0.180848
   Number of active neurons: 5
 >> iter 81000, loss: 0.179013
 >> iter 82000, loss: 0.147093
 >> iter 83000, loss: 0.159809
 >> iter 84000, loss: 0.248080
 >> iter 85000, loss: 0.272815
 >> iter 86000, loss: 0.259087
 >> iter 87000, loss: 0.270833
 >> iter 88000, loss: 0.265482
 >> iter 89000, loss: 0.194433
 >> iter 90000, loss: 0.195381
   Number of active neurons: 5
 >> iter 91000, loss: 0.223195
 >> iter 92000, loss: 0.223471
 >> iter 93000, loss: 0.161081
 >> iter 94000, loss: 0.309437
 >> iter 95000, loss: 0.346352
 >> iter 96000, loss: 0.319215
 >> iter 97000, loss: 0.289707
 >> iter 98000, loss: 0.271285
 >> iter 99000, loss: 0.197919
 >> iter 100000, loss: 0.149064
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.822979
 >> iter 2000, loss: 9.990715
 >> iter 3000, loss: 6.186113
 >> iter 4000, loss: 2.998637
 >> iter 5000, loss: 1.480985
 >> iter 6000, loss: 0.834986
 >> iter 7000, loss: 0.508151
 >> iter 8000, loss: 0.384156
 >> iter 9000, loss: 0.395832
 >> iter 10000, loss: 0.323741
   Number of active neurons: 10
 >> iter 11000, loss: 0.401391
 >> iter 12000, loss: 0.301611
 >> iter 13000, loss: 0.479393
 >> iter 14000, loss: 0.378480
 >> iter 15000, loss: 0.354501
 >> iter 16000, loss: 0.392489
 >> iter 17000, loss: 0.236991
 >> iter 18000, loss: 0.246130
 >> iter 19000, loss: 0.207831
 >> iter 20000, loss: 0.245867
   Number of active neurons: 10
 >> iter 21000, loss: 0.209146
 >> iter 22000, loss: 0.261655
 >> iter 23000, loss: 0.304209
 >> iter 24000, loss: 0.254551
 >> iter 25000, loss: 0.255191
 >> iter 26000, loss: 0.255946
 >> iter 27000, loss: 0.224779
 >> iter 28000, loss: 0.138876
 >> iter 29000, loss: 0.201012
 >> iter 30000, loss: 0.180900
   Number of active neurons: 9
 >> iter 31000, loss: 0.287596
 >> iter 32000, loss: 0.383655
 >> iter 33000, loss: 0.261205
 >> iter 34000, loss: 0.203971
 >> iter 35000, loss: 0.212659
 >> iter 36000, loss: 0.238173
 >> iter 37000, loss: 0.255141
 >> iter 38000, loss: 0.272019
 >> iter 39000, loss: 0.280200
 >> iter 40000, loss: 0.262770
   Number of active neurons: 8
 >> iter 41000, loss: 0.250924
 >> iter 42000, loss: 0.165353
 >> iter 43000, loss: 0.240563
 >> iter 44000, loss: 0.282826
 >> iter 45000, loss: 0.253118
 >> iter 46000, loss: 0.266780
 >> iter 47000, loss: 0.207335
 >> iter 48000, loss: 0.272923
 >> iter 49000, loss: 0.235681
 >> iter 50000, loss: 0.361493
   Number of active neurons: 8
 >> iter 51000, loss: 0.323842
 >> iter 52000, loss: 0.265517
 >> iter 53000, loss: 0.188179
 >> iter 54000, loss: 0.196595
 >> iter 55000, loss: 0.225266
 >> iter 56000, loss: 0.212746
 >> iter 57000, loss: 0.204095
 >> iter 58000, loss: 0.378111
 >> iter 59000, loss: 0.210265
 >> iter 60000, loss: 0.267696
   Number of active neurons: 7
 >> iter 61000, loss: 0.424865
 >> iter 62000, loss: 0.365155
 >> iter 63000, loss: 0.358947
 >> iter 64000, loss: 0.352076
 >> iter 65000, loss: 0.268363
 >> iter 66000, loss: 0.225188
 >> iter 67000, loss: 0.196966
 >> iter 68000, loss: 0.321787
 >> iter 69000, loss: 0.214452
 >> iter 70000, loss: 0.189862
   Number of active neurons: 7
 >> iter 71000, loss: 0.273689
 >> iter 72000, loss: 0.220197
 >> iter 73000, loss: 0.143547
 >> iter 74000, loss: 0.168057
 >> iter 75000, loss: 0.195079
 >> iter 76000, loss: 0.232476
 >> iter 77000, loss: 0.228768
 >> iter 78000, loss: 0.196198
 >> iter 79000, loss: 0.161497
 >> iter 80000, loss: 0.136119
   Number of active neurons: 7
 >> iter 81000, loss: 0.219452
 >> iter 82000, loss: 0.272617
 >> iter 83000, loss: 0.199276
 >> iter 84000, loss: 0.326106
 >> iter 85000, loss: 0.260687
 >> iter 86000, loss: 0.223524
 >> iter 87000, loss: 0.271087
 >> iter 88000, loss: 0.252799
 >> iter 89000, loss: 0.197775
 >> iter 90000, loss: 0.209637
   Number of active neurons: 7
 >> iter 91000, loss: 0.153810
 >> iter 92000, loss: 0.161084
 >> iter 93000, loss: 0.188434
 >> iter 94000, loss: 0.276545
 >> iter 95000, loss: 0.211700
 >> iter 96000, loss: 0.189128
 >> iter 97000, loss: 0.172149
 >> iter 98000, loss: 0.275101
 >> iter 99000, loss: 0.243963
 >> iter 100000, loss: 0.212717
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.056041
 >> iter 2000, loss: 10.689810
 >> iter 3000, loss: 6.714114
 >> iter 4000, loss: 3.264338
 >> iter 5000, loss: 1.461588
 >> iter 6000, loss: 0.761604
 >> iter 7000, loss: 0.432580
 >> iter 8000, loss: 0.567291
 >> iter 9000, loss: 0.416036
 >> iter 10000, loss: 0.278215
   Number of active neurons: 12
 >> iter 11000, loss: 0.260397
 >> iter 12000, loss: 0.336867
 >> iter 13000, loss: 0.423058
 >> iter 14000, loss: 0.321278
 >> iter 15000, loss: 0.379339
 >> iter 16000, loss: 0.307532
 >> iter 17000, loss: 0.305676
 >> iter 18000, loss: 0.376117
 >> iter 19000, loss: 0.289151
 >> iter 20000, loss: 0.381939
   Number of active neurons: 9
 >> iter 21000, loss: 0.307406
 >> iter 22000, loss: 0.416964
 >> iter 23000, loss: 0.286918
 >> iter 24000, loss: 0.331972
 >> iter 25000, loss: 0.361529
 >> iter 26000, loss: 0.328331
 >> iter 27000, loss: 0.331225
 >> iter 28000, loss: 0.397044
 >> iter 29000, loss: 0.365146
 >> iter 30000, loss: 0.367854
   Number of active neurons: 9
 >> iter 31000, loss: 0.327383
 >> iter 32000, loss: 0.320579
 >> iter 33000, loss: 0.317212
 >> iter 34000, loss: 0.389676
 >> iter 35000, loss: 0.283254
 >> iter 36000, loss: 0.308648
 >> iter 37000, loss: 0.343012
 >> iter 38000, loss: 0.335736
 >> iter 39000, loss: 0.389055
 >> iter 40000, loss: 0.433602
   Number of active neurons: 8
 >> iter 41000, loss: 0.368903
 >> iter 42000, loss: 0.458349
 >> iter 43000, loss: 0.286778
 >> iter 44000, loss: 0.371803
 >> iter 45000, loss: 0.306653
 >> iter 46000, loss: 0.336272
 >> iter 47000, loss: 0.454887
 >> iter 48000, loss: 0.366186
 >> iter 49000, loss: 0.357349
 >> iter 50000, loss: 0.405039
   Number of active neurons: 8
 >> iter 51000, loss: 0.254903
 >> iter 52000, loss: 0.254213
 >> iter 53000, loss: 0.291152
 >> iter 54000, loss: 0.256023
 >> iter 55000, loss: 0.217352
 >> iter 56000, loss: 0.271603
 >> iter 57000, loss: 0.269876
 >> iter 58000, loss: 0.309072
 >> iter 59000, loss: 0.268020
 >> iter 60000, loss: 0.266625
   Number of active neurons: 7
 >> iter 61000, loss: 0.350547
 >> iter 62000, loss: 0.326291
 >> iter 63000, loss: 0.383302
 >> iter 64000, loss: 0.337141
 >> iter 65000, loss: 0.402335
 >> iter 66000, loss: 0.431595
 >> iter 67000, loss: 0.246580
 >> iter 68000, loss: 0.214908
 >> iter 69000, loss: 0.275674
 >> iter 70000, loss: 0.225029
   Number of active neurons: 6
 >> iter 71000, loss: 0.346347
 >> iter 72000, loss: 0.373659
 >> iter 73000, loss: 0.417342
 >> iter 74000, loss: 0.344122
 >> iter 75000, loss: 0.325968
 >> iter 76000, loss: 0.232735
 >> iter 77000, loss: 0.342464
 >> iter 78000, loss: 0.269437
 >> iter 79000, loss: 0.304182
 >> iter 80000, loss: 0.290654
   Number of active neurons: 6
 >> iter 81000, loss: 0.365729
 >> iter 82000, loss: 0.263588
 >> iter 83000, loss: 0.279496
 >> iter 84000, loss: 0.292543
 >> iter 85000, loss: 0.296203
 >> iter 86000, loss: 0.235934
 >> iter 87000, loss: 0.346272
 >> iter 88000, loss: 0.336019
 >> iter 89000, loss: 0.410041
 >> iter 90000, loss: 0.358405
   Number of active neurons: 6
 >> iter 91000, loss: 0.286211
 >> iter 92000, loss: 0.272093
 >> iter 93000, loss: 0.306060
 >> iter 94000, loss: 0.304793
 >> iter 95000, loss: 0.311190
 >> iter 96000, loss: 0.296392
 >> iter 97000, loss: 0.333579
 >> iter 98000, loss: 0.317455
 >> iter 99000, loss: 0.415888
 >> iter 100000, loss: 0.454508
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.611916
 >> iter 2000, loss: 9.699169
 >> iter 3000, loss: 5.151635
 >> iter 4000, loss: 2.336445
 >> iter 5000, loss: 1.192556
 >> iter 6000, loss: 0.804150
 >> iter 7000, loss: 0.531688
 >> iter 8000, loss: 0.436654
 >> iter 9000, loss: 0.331394
 >> iter 10000, loss: 0.407616
   Number of active neurons: 7
 >> iter 11000, loss: 0.368982
 >> iter 12000, loss: 0.446058
 >> iter 13000, loss: 0.411252
 >> iter 14000, loss: 0.287882
 >> iter 15000, loss: 0.401128
 >> iter 16000, loss: 0.287597
 >> iter 17000, loss: 0.371377
 >> iter 18000, loss: 0.305433
 >> iter 19000, loss: 0.345908
 >> iter 20000, loss: 0.303814
   Number of active neurons: 7
 >> iter 21000, loss: 0.329623
 >> iter 22000, loss: 0.405219
 >> iter 23000, loss: 0.408445
 >> iter 24000, loss: 0.467807
 >> iter 25000, loss: 0.529219
 >> iter 26000, loss: 0.466514
 >> iter 27000, loss: 0.379495
 >> iter 28000, loss: 0.383533
 >> iter 29000, loss: 0.400113
 >> iter 30000, loss: 0.354554
   Number of active neurons: 7
 >> iter 31000, loss: 0.467016
 >> iter 32000, loss: 0.305267
 >> iter 33000, loss: 0.338642
 >> iter 34000, loss: 0.442552
 >> iter 35000, loss: 0.337821
 >> iter 36000, loss: 0.438385
 >> iter 37000, loss: 0.507755
 >> iter 38000, loss: 0.460473
 >> iter 39000, loss: 0.337761
 >> iter 40000, loss: 0.461104
   Number of active neurons: 9
 >> iter 41000, loss: 0.423790
 >> iter 42000, loss: 0.326788
 >> iter 43000, loss: 0.415382
 >> iter 44000, loss: 0.334541
 >> iter 45000, loss: 0.368054
 >> iter 46000, loss: 0.387364
 >> iter 47000, loss: 0.276182
 >> iter 48000, loss: 0.415856
 >> iter 49000, loss: 0.340451
 >> iter 50000, loss: 0.305208
   Number of active neurons: 7
 >> iter 51000, loss: 0.260979
 >> iter 52000, loss: 0.365081
 >> iter 53000, loss: 0.409888
 >> iter 54000, loss: 0.433274
 >> iter 55000, loss: 0.402937
 >> iter 56000, loss: 0.375215
 >> iter 57000, loss: 0.322738
 >> iter 58000, loss: 0.289874
 >> iter 59000, loss: 0.247556
 >> iter 60000, loss: 0.266606
   Number of active neurons: 7
 >> iter 61000, loss: 0.316884
 >> iter 62000, loss: 0.334599
 >> iter 63000, loss: 0.404605
 >> iter 64000, loss: 0.296972
 >> iter 65000, loss: 0.299292
 >> iter 66000, loss: 0.330360
 >> iter 67000, loss: 0.291010
 >> iter 68000, loss: 0.338143
 >> iter 69000, loss: 0.302528
 >> iter 70000, loss: 0.458643
   Number of active neurons: 7
 >> iter 71000, loss: 0.379043
 >> iter 72000, loss: 0.354259
 >> iter 73000, loss: 0.362458
 >> iter 74000, loss: 0.288158
 >> iter 75000, loss: 0.314498
 >> iter 76000, loss: 0.269673
 >> iter 77000, loss: 0.259402
 >> iter 78000, loss: 0.351021
 >> iter 79000, loss: 0.366967
 >> iter 80000, loss: 0.396640
   Number of active neurons: 7
 >> iter 81000, loss: 0.295484
 >> iter 82000, loss: 0.342978
 >> iter 83000, loss: 0.327312
 >> iter 84000, loss: 0.211694
 >> iter 85000, loss: 0.228906
 >> iter 86000, loss: 0.297385
 >> iter 87000, loss: 0.338294
 >> iter 88000, loss: 0.396603
 >> iter 89000, loss: 0.402270
 >> iter 90000, loss: 0.360255
   Number of active neurons: 7
 >> iter 91000, loss: 0.334552
 >> iter 92000, loss: 0.434056
 >> iter 93000, loss: 0.364902
 >> iter 94000, loss: 0.366948
 >> iter 95000, loss: 0.344230
 >> iter 96000, loss: 0.367483
 >> iter 97000, loss: 0.330746
 >> iter 98000, loss: 0.329400
 >> iter 99000, loss: 0.345001
 >> iter 100000, loss: 0.309302
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.870326
 >> iter 2000, loss: 9.575085
 >> iter 3000, loss: 5.493576
 >> iter 4000, loss: 3.173039
 >> iter 5000, loss: 2.026472
 >> iter 6000, loss: 1.313203
 >> iter 7000, loss: 1.015301
 >> iter 8000, loss: 0.926041
 >> iter 9000, loss: 0.719832
 >> iter 10000, loss: 0.738318
   Number of active neurons: 8
 >> iter 11000, loss: 0.715357
 >> iter 12000, loss: 0.860871
 >> iter 13000, loss: 0.634922
 >> iter 14000, loss: 0.538988
 >> iter 15000, loss: 0.487314
 >> iter 16000, loss: 0.593431
 >> iter 17000, loss: 0.475506
 >> iter 18000, loss: 0.643501
 >> iter 19000, loss: 0.686767
 >> iter 20000, loss: 0.476179
   Number of active neurons: 6
 >> iter 21000, loss: 0.509698
 >> iter 22000, loss: 0.478054
 >> iter 23000, loss: 0.449939
 >> iter 24000, loss: 0.371682
 >> iter 25000, loss: 0.407242
 >> iter 26000, loss: 0.347666
 >> iter 27000, loss: 0.541816
 >> iter 28000, loss: 0.632462
 >> iter 29000, loss: 0.698508
 >> iter 30000, loss: 0.585591
   Number of active neurons: 6
 >> iter 31000, loss: 0.561061
 >> iter 32000, loss: 0.359266
 >> iter 33000, loss: 0.442901
 >> iter 34000, loss: 0.467101
 >> iter 35000, loss: 0.510679
 >> iter 36000, loss: 0.495171
 >> iter 37000, loss: 0.480314
 >> iter 38000, loss: 0.509673
 >> iter 39000, loss: 0.519975
 >> iter 40000, loss: 0.527841
   Number of active neurons: 7
 >> iter 41000, loss: 0.418204
 >> iter 42000, loss: 0.454591
 >> iter 43000, loss: 0.430543
 >> iter 44000, loss: 0.378259
 >> iter 45000, loss: 0.427508
 >> iter 46000, loss: 0.576792
 >> iter 47000, loss: 0.594538
 >> iter 48000, loss: 0.591415
 >> iter 49000, loss: 0.445313
 >> iter 50000, loss: 0.544109
   Number of active neurons: 6
 >> iter 51000, loss: 0.489009
 >> iter 52000, loss: 0.462286
 >> iter 53000, loss: 0.511488
 >> iter 54000, loss: 0.577374
 >> iter 55000, loss: 0.467029
 >> iter 56000, loss: 0.411144
 >> iter 57000, loss: 0.365324
 >> iter 58000, loss: 0.464758
 >> iter 59000, loss: 0.483550
 >> iter 60000, loss: 0.567507
   Number of active neurons: 6
 >> iter 61000, loss: 0.445561
 >> iter 62000, loss: 0.606985
 >> iter 63000, loss: 0.500390
 >> iter 64000, loss: 0.459476
 >> iter 65000, loss: 0.625464
 >> iter 66000, loss: 0.528835
 >> iter 67000, loss: 0.593934
 >> iter 68000, loss: 0.734512
 >> iter 69000, loss: 0.494762
 >> iter 70000, loss: 0.429994
   Number of active neurons: 6
 >> iter 71000, loss: 0.648623
 >> iter 72000, loss: 0.640967
 >> iter 73000, loss: 0.665658
 >> iter 74000, loss: 0.711801
 >> iter 75000, loss: 0.491507
 >> iter 76000, loss: 0.568186
 >> iter 77000, loss: 0.596470
 >> iter 78000, loss: 0.573124
 >> iter 79000, loss: 0.614016
 >> iter 80000, loss: 0.569869
   Number of active neurons: 6
 >> iter 81000, loss: 0.528515
 >> iter 82000, loss: 0.379727
 >> iter 83000, loss: 0.516446
 >> iter 84000, loss: 0.439243
 >> iter 85000, loss: 0.466743
 >> iter 86000, loss: 0.631060
 >> iter 87000, loss: 0.498233
 >> iter 88000, loss: 0.570548
 >> iter 89000, loss: 0.627458
 >> iter 90000, loss: 0.589321
   Number of active neurons: 5
 >> iter 91000, loss: 0.457011
 >> iter 92000, loss: 0.566008
 >> iter 93000, loss: 0.551450
 >> iter 94000, loss: 0.461731
 >> iter 95000, loss: 0.564819
 >> iter 96000, loss: 0.507758
 >> iter 97000, loss: 0.596728
 >> iter 98000, loss: 0.603240
 >> iter 99000, loss: 0.604719
 >> iter 100000, loss: 0.418934
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.086005
 >> iter 2000, loss: 9.936031
 >> iter 3000, loss: 6.143910
 >> iter 4000, loss: 3.169921
 >> iter 5000, loss: 1.668935
 >> iter 6000, loss: 1.216617
 >> iter 7000, loss: 0.757786
 >> iter 8000, loss: 0.459484
 >> iter 9000, loss: 0.416806
 >> iter 10000, loss: 0.387248
   Number of active neurons: 8
 >> iter 11000, loss: 0.502325
 >> iter 12000, loss: 0.542605
 >> iter 13000, loss: 0.422443
 >> iter 14000, loss: 0.477651
 >> iter 15000, loss: 0.556912
 >> iter 16000, loss: 0.410990
 >> iter 17000, loss: 0.276383
 >> iter 18000, loss: 0.235731
 >> iter 19000, loss: 0.362054
 >> iter 20000, loss: 0.332900
   Number of active neurons: 8
 >> iter 21000, loss: 0.387306
 >> iter 22000, loss: 0.372195
 >> iter 23000, loss: 0.293007
 >> iter 24000, loss: 0.391881
 >> iter 25000, loss: 0.399387
 >> iter 26000, loss: 0.334554
 >> iter 27000, loss: 0.429982
 >> iter 28000, loss: 0.291810
 >> iter 29000, loss: 0.364064
 >> iter 30000, loss: 0.390391
   Number of active neurons: 8
 >> iter 31000, loss: 0.430305
 >> iter 32000, loss: 0.390154
 >> iter 33000, loss: 0.408643
 >> iter 34000, loss: 0.393794
 >> iter 35000, loss: 0.342199
 >> iter 36000, loss: 0.453893
 >> iter 37000, loss: 0.371825
 >> iter 38000, loss: 0.383406
 >> iter 39000, loss: 0.431232
 >> iter 40000, loss: 0.334841
   Number of active neurons: 8
 >> iter 41000, loss: 0.214971
 >> iter 42000, loss: 0.385472
 >> iter 43000, loss: 0.369341
 >> iter 44000, loss: 0.335763
 >> iter 45000, loss: 0.458517
 >> iter 46000, loss: 0.411002
 >> iter 47000, loss: 0.332508
 >> iter 48000, loss: 0.345909
 >> iter 49000, loss: 0.368310
 >> iter 50000, loss: 0.256583
   Number of active neurons: 8
 >> iter 51000, loss: 0.341330
 >> iter 52000, loss: 0.370875
 >> iter 53000, loss: 0.460866
 >> iter 54000, loss: 0.435530
 >> iter 55000, loss: 0.359014
 >> iter 56000, loss: 0.409207
 >> iter 57000, loss: 0.414989
 >> iter 58000, loss: 0.341617
 >> iter 59000, loss: 0.428594
 >> iter 60000, loss: 0.559148
   Number of active neurons: 8
 >> iter 61000, loss: 0.482052
 >> iter 62000, loss: 0.529396
 >> iter 63000, loss: 0.354229
 >> iter 64000, loss: 0.489922
 >> iter 65000, loss: 0.439391
 >> iter 66000, loss: 0.446266
 >> iter 67000, loss: 0.383457
 >> iter 68000, loss: 0.448676
 >> iter 69000, loss: 0.375650
 >> iter 70000, loss: 0.339934
   Number of active neurons: 8
 >> iter 71000, loss: 0.430570
 >> iter 72000, loss: 0.513746
 >> iter 73000, loss: 0.386603
 >> iter 74000, loss: 0.312235
 >> iter 75000, loss: 0.371480
 >> iter 76000, loss: 0.294790
 >> iter 77000, loss: 0.354264
 >> iter 78000, loss: 0.319210
 >> iter 79000, loss: 0.458329
 >> iter 80000, loss: 0.346958
   Number of active neurons: 7
 >> iter 81000, loss: 0.306155
 >> iter 82000, loss: 0.380264
 >> iter 83000, loss: 0.424878
 >> iter 84000, loss: 0.276914
 >> iter 85000, loss: 0.392445
 >> iter 86000, loss: 0.367453
 >> iter 87000, loss: 0.319959
 >> iter 88000, loss: 0.355945
 >> iter 89000, loss: 0.319580
 >> iter 90000, loss: 0.401482
   Number of active neurons: 7
 >> iter 91000, loss: 0.333096
 >> iter 92000, loss: 0.443407
 >> iter 93000, loss: 0.366890
 >> iter 94000, loss: 0.453690
 >> iter 95000, loss: 0.416654
 >> iter 96000, loss: 0.351675
 >> iter 97000, loss: 0.329479
 >> iter 98000, loss: 0.373485
 >> iter 99000, loss: 0.252101
 >> iter 100000, loss: 0.266725
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.189827
 >> iter 2000, loss: 9.966573
 >> iter 3000, loss: 5.551600
 >> iter 4000, loss: 3.284303
 >> iter 5000, loss: 2.177162
 >> iter 6000, loss: 1.568693
 >> iter 7000, loss: 1.292626
 >> iter 8000, loss: 0.965237
 >> iter 9000, loss: 0.898074
 >> iter 10000, loss: 0.704656
   Number of active neurons: 4
 >> iter 11000, loss: 0.648687
 >> iter 12000, loss: 0.619787
 >> iter 13000, loss: 0.643729
 >> iter 14000, loss: 0.660295
 >> iter 15000, loss: 0.525244
 >> iter 16000, loss: 0.694162
 >> iter 17000, loss: 0.723725
 >> iter 18000, loss: 0.497331
 >> iter 19000, loss: 0.457848
 >> iter 20000, loss: 0.528277
   Number of active neurons: 5
 >> iter 21000, loss: 0.572977
 >> iter 22000, loss: 0.545939
 >> iter 23000, loss: 0.496687
 >> iter 24000, loss: 0.533314
 >> iter 25000, loss: 0.476193
 >> iter 26000, loss: 0.478261
 >> iter 27000, loss: 0.551392
 >> iter 28000, loss: 0.596105
 >> iter 29000, loss: 0.576133
 >> iter 30000, loss: 0.467691
   Number of active neurons: 4
 >> iter 31000, loss: 0.481101
 >> iter 32000, loss: 0.368558
 >> iter 33000, loss: 0.414615
 >> iter 34000, loss: 0.361682
 >> iter 35000, loss: 0.382642
 >> iter 36000, loss: 0.477342
 >> iter 37000, loss: 0.526696
 >> iter 38000, loss: 0.684821
 >> iter 39000, loss: 0.537574
 >> iter 40000, loss: 0.481816
   Number of active neurons: 4
 >> iter 41000, loss: 0.425844
 >> iter 42000, loss: 0.430726
 >> iter 43000, loss: 0.587785
 >> iter 44000, loss: 0.428925
 >> iter 45000, loss: 0.472281
 >> iter 46000, loss: 0.413234
 >> iter 47000, loss: 0.464464
 >> iter 48000, loss: 0.456455
 >> iter 49000, loss: 0.381482
 >> iter 50000, loss: 0.528004
   Number of active neurons: 4
 >> iter 51000, loss: 0.451585
 >> iter 52000, loss: 0.459621
 >> iter 53000, loss: 0.472772
 >> iter 54000, loss: 0.524041
 >> iter 55000, loss: 0.460528
 >> iter 56000, loss: 0.526583
 >> iter 57000, loss: 0.424351
 >> iter 58000, loss: 0.363313
 >> iter 59000, loss: 0.449237
 >> iter 60000, loss: 0.364309
   Number of active neurons: 4
 >> iter 61000, loss: 0.349858
 >> iter 62000, loss: 0.390755
 >> iter 63000, loss: 0.620591
 >> iter 64000, loss: 0.457914
 >> iter 65000, loss: 0.491424
 >> iter 66000, loss: 0.548320
 >> iter 67000, loss: 0.583456
 >> iter 68000, loss: 0.530737
 >> iter 69000, loss: 0.556938
 >> iter 70000, loss: 0.596544
   Number of active neurons: 4
 >> iter 71000, loss: 0.460179
 >> iter 72000, loss: 0.482096
 >> iter 73000, loss: 0.694334
 >> iter 74000, loss: 0.707084
 >> iter 75000, loss: 0.484411
 >> iter 76000, loss: 0.482457
 >> iter 77000, loss: 0.468715
 >> iter 78000, loss: 0.463525
 >> iter 79000, loss: 0.529219
 >> iter 80000, loss: 0.553379
   Number of active neurons: 4
 >> iter 81000, loss: 0.423680
 >> iter 82000, loss: 0.347685
 >> iter 83000, loss: 0.450087
 >> iter 84000, loss: 0.565904
 >> iter 85000, loss: 0.673392
 >> iter 86000, loss: 0.817973
 >> iter 87000, loss: 0.790472
 >> iter 88000, loss: 0.611935
 >> iter 89000, loss: 0.472658
 >> iter 90000, loss: 0.555729
   Number of active neurons: 4
 >> iter 91000, loss: 0.492136
 >> iter 92000, loss: 0.559663
 >> iter 93000, loss: 0.539233
 >> iter 94000, loss: 0.579605
 >> iter 95000, loss: 0.553696
 >> iter 96000, loss: 0.499148
 >> iter 97000, loss: 0.549581
 >> iter 98000, loss: 0.462719
 >> iter 99000, loss: 0.631345
 >> iter 100000, loss: 0.612418
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 17.765781
 >> iter 2000, loss: 10.252192
 >> iter 3000, loss: 5.201624
 >> iter 4000, loss: 2.194145
 >> iter 5000, loss: 1.191757
 >> iter 6000, loss: 0.650805
 >> iter 7000, loss: 0.490859
 >> iter 8000, loss: 0.321164
 >> iter 9000, loss: 0.314886
 >> iter 10000, loss: 0.325146
   Number of active neurons: 12
 >> iter 11000, loss: 0.205632
 >> iter 12000, loss: 0.276093
 >> iter 13000, loss: 0.244054
 >> iter 14000, loss: 0.221841
 >> iter 15000, loss: 0.316376
 >> iter 16000, loss: 0.427608
 >> iter 17000, loss: 0.284706
 >> iter 18000, loss: 0.316134
 >> iter 19000, loss: 0.311463
 >> iter 20000, loss: 0.343472
   Number of active neurons: 11
 >> iter 21000, loss: 0.270620
 >> iter 22000, loss: 0.414014
 >> iter 23000, loss: 0.241612
 >> iter 24000, loss: 0.258994
 >> iter 25000, loss: 0.238126
 >> iter 26000, loss: 0.280513
 >> iter 27000, loss: 0.211059
 >> iter 28000, loss: 0.359904
 >> iter 29000, loss: 0.357641
 >> iter 30000, loss: 0.271784
   Number of active neurons: 10
 >> iter 31000, loss: 0.180030
 >> iter 32000, loss: 0.295945
 >> iter 33000, loss: 0.292636
 >> iter 34000, loss: 0.254365
 >> iter 35000, loss: 0.267389
 >> iter 36000, loss: 0.333066
 >> iter 37000, loss: 0.285125
 >> iter 38000, loss: 0.261426
 >> iter 39000, loss: 0.289457
 >> iter 40000, loss: 0.272453
   Number of active neurons: 10
 >> iter 41000, loss: 0.215895
 >> iter 42000, loss: 0.253251
 >> iter 43000, loss: 0.311265
 >> iter 44000, loss: 0.220809
 >> iter 45000, loss: 0.288687
 >> iter 46000, loss: 0.340517
 >> iter 47000, loss: 0.284826
 >> iter 48000, loss: 0.338261
 >> iter 49000, loss: 0.372213
 >> iter 50000, loss: 0.350941
   Number of active neurons: 10
 >> iter 51000, loss: 0.240128
 >> iter 52000, loss: 0.307809
 >> iter 53000, loss: 0.297942
 >> iter 54000, loss: 0.207025
 >> iter 55000, loss: 0.264718
 >> iter 56000, loss: 0.240081
 >> iter 57000, loss: 0.291443
 >> iter 58000, loss: 0.375159
 >> iter 59000, loss: 0.378971
 >> iter 60000, loss: 0.282087
   Number of active neurons: 9
 >> iter 61000, loss: 0.240935
 >> iter 62000, loss: 0.325025
 >> iter 63000, loss: 0.202953
 >> iter 64000, loss: 0.396020
 >> iter 65000, loss: 0.273570
 >> iter 66000, loss: 0.178020
 >> iter 67000, loss: 0.259937
 >> iter 68000, loss: 0.272039
 >> iter 69000, loss: 0.264155
 >> iter 70000, loss: 0.352570
   Number of active neurons: 9
 >> iter 71000, loss: 0.396404
 >> iter 72000, loss: 0.308991
 >> iter 73000, loss: 0.190390
 >> iter 74000, loss: 0.300400
 >> iter 75000, loss: 0.369503
 >> iter 76000, loss: 0.249168
 >> iter 77000, loss: 0.378977
 >> iter 78000, loss: 0.348850
 >> iter 79000, loss: 0.446223
 >> iter 80000, loss: 0.325984
   Number of active neurons: 7
 >> iter 81000, loss: 0.393963
 >> iter 82000, loss: 0.333538
 >> iter 83000, loss: 0.306261
 >> iter 84000, loss: 0.363223
 >> iter 85000, loss: 0.361378
 >> iter 86000, loss: 0.290940
 >> iter 87000, loss: 0.241220
 >> iter 88000, loss: 0.290272
 >> iter 89000, loss: 0.261158
 >> iter 90000, loss: 0.246666
   Number of active neurons: 7
 >> iter 91000, loss: 0.248078
 >> iter 92000, loss: 0.244153
 >> iter 93000, loss: 0.300833
 >> iter 94000, loss: 0.244703
 >> iter 95000, loss: 0.289998
 >> iter 96000, loss: 0.263997
 >> iter 97000, loss: 0.191264
 >> iter 98000, loss: 0.244599
 >> iter 99000, loss: 0.354291
 >> iter 100000, loss: 0.369298
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.716351
 >> iter 2000, loss: 9.803683
 >> iter 3000, loss: 6.569343
 >> iter 4000, loss: 4.194386
 >> iter 5000, loss: 2.038229
 >> iter 6000, loss: 1.078673
 >> iter 7000, loss: 0.675660
 >> iter 8000, loss: 0.524571
 >> iter 9000, loss: 0.416653
 >> iter 10000, loss: 0.238511
   Number of active neurons: 9
 >> iter 11000, loss: 0.278978
 >> iter 12000, loss: 0.226912
 >> iter 13000, loss: 0.272082
 >> iter 14000, loss: 0.252425
 >> iter 15000, loss: 0.312775
 >> iter 16000, loss: 0.371059
 >> iter 17000, loss: 0.264313
 >> iter 18000, loss: 0.313072
 >> iter 19000, loss: 0.298776
 >> iter 20000, loss: 0.308323
   Number of active neurons: 9
 >> iter 21000, loss: 0.264555
 >> iter 22000, loss: 0.186608
 >> iter 23000, loss: 0.250700
 >> iter 24000, loss: 0.314980
 >> iter 25000, loss: 0.223108
 >> iter 26000, loss: 0.174695
 >> iter 27000, loss: 0.298624
 >> iter 28000, loss: 0.352703
 >> iter 29000, loss: 0.403123
 >> iter 30000, loss: 0.271404
   Number of active neurons: 9
 >> iter 31000, loss: 0.245964
 >> iter 32000, loss: 0.383022
 >> iter 33000, loss: 0.346472
 >> iter 34000, loss: 0.307339
 >> iter 35000, loss: 0.235282
 >> iter 36000, loss: 0.262278
 >> iter 37000, loss: 0.259487
 >> iter 38000, loss: 0.186307
 >> iter 39000, loss: 0.257049
 >> iter 40000, loss: 0.235373
   Number of active neurons: 9
 >> iter 41000, loss: 0.269746
 >> iter 42000, loss: 0.345081
 >> iter 43000, loss: 0.324922
 >> iter 44000, loss: 0.310609
 >> iter 45000, loss: 0.314899
 >> iter 46000, loss: 0.276002
 >> iter 47000, loss: 0.324558
 >> iter 48000, loss: 0.345122
 >> iter 49000, loss: 0.326245
 >> iter 50000, loss: 0.307150
   Number of active neurons: 9
 >> iter 51000, loss: 0.335272
 >> iter 52000, loss: 0.332975
 >> iter 53000, loss: 0.273449
 >> iter 54000, loss: 0.333969
 >> iter 55000, loss: 0.353453
 >> iter 56000, loss: 0.219265
 >> iter 57000, loss: 0.239611
 >> iter 58000, loss: 0.252857
 >> iter 59000, loss: 0.263119
 >> iter 60000, loss: 0.320870
   Number of active neurons: 9
 >> iter 61000, loss: 0.319025
 >> iter 62000, loss: 0.425297
 >> iter 63000, loss: 0.368175
 >> iter 64000, loss: 0.268920
 >> iter 65000, loss: 0.258392
 >> iter 66000, loss: 0.249773
 >> iter 67000, loss: 0.220212
 >> iter 68000, loss: 0.333058
 >> iter 69000, loss: 0.366250
 >> iter 70000, loss: 0.284674
   Number of active neurons: 8
 >> iter 71000, loss: 0.363631
 >> iter 72000, loss: 0.308106
 >> iter 73000, loss: 0.294683
 >> iter 74000, loss: 0.303801
 >> iter 75000, loss: 0.310515
 >> iter 76000, loss: 0.280511
 >> iter 77000, loss: 0.221577
 >> iter 78000, loss: 0.302761
 >> iter 79000, loss: 0.228636
 >> iter 80000, loss: 0.283995
   Number of active neurons: 7
 >> iter 81000, loss: 0.322768
 >> iter 82000, loss: 0.276906
 >> iter 83000, loss: 0.283068
 >> iter 84000, loss: 0.312353
 >> iter 85000, loss: 0.355607
 >> iter 86000, loss: 0.358456
 >> iter 87000, loss: 0.247034
 >> iter 88000, loss: 0.276775
 >> iter 89000, loss: 0.306680
 >> iter 90000, loss: 0.355409
   Number of active neurons: 6
 >> iter 91000, loss: 0.328210
 >> iter 92000, loss: 0.350613
 >> iter 93000, loss: 0.266206
 >> iter 94000, loss: 0.275600
 >> iter 95000, loss: 0.295345
 >> iter 96000, loss: 0.221252
 >> iter 97000, loss: 0.206367
 >> iter 98000, loss: 0.341374
 >> iter 99000, loss: 0.265899
 >> iter 100000, loss: 0.326994
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

