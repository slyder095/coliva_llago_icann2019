 > Problema: tomita6nueva
 > Args:
   - Hidden size: 2
   - Noise level: 0.0
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.675872
 >> iter 2000, loss: 15.072983
 >> iter 3000, loss: 13.720046
 >> iter 4000, loss: 13.226421
 >> iter 5000, loss: 13.032725
 >> iter 6000, loss: 12.967830
 >> iter 7000, loss: 12.933881
 >> iter 8000, loss: 12.930439
 >> iter 9000, loss: 12.918829
 >> iter 10000, loss: 12.926531
   Number of active neurons: 2
 >> iter 11000, loss: 12.915804
 >> iter 12000, loss: 12.923042
 >> iter 13000, loss: 12.912360
 >> iter 14000, loss: 12.921729
 >> iter 15000, loss: 12.913503
 >> iter 16000, loss: 12.921109
 >> iter 17000, loss: 12.914267
 >> iter 18000, loss: 12.919624
 >> iter 19000, loss: 12.910973
 >> iter 20000, loss: 12.921606
   Number of active neurons: 2
 >> iter 21000, loss: 12.909082
 >> iter 22000, loss: 12.920660
 >> iter 23000, loss: 12.909104
 >> iter 24000, loss: 12.920446
 >> iter 25000, loss: 12.908314
 >> iter 26000, loss: 12.917676
 >> iter 27000, loss: 12.907642
 >> iter 28000, loss: 12.917257
 >> iter 29000, loss: 12.907417
 >> iter 30000, loss: 12.918697
   Number of active neurons: 2
 >> iter 31000, loss: 12.907867
 >> iter 32000, loss: 12.918411
 >> iter 33000, loss: 12.910960
 >> iter 34000, loss: 12.918177
 >> iter 35000, loss: 12.909935
 >> iter 36000, loss: 12.915316
 >> iter 37000, loss: 12.908350
 >> iter 38000, loss: 12.916209
 >> iter 39000, loss: 12.906421
 >> iter 40000, loss: 12.916450
   Number of active neurons: 2
 >> iter 41000, loss: 12.905031
 >> iter 42000, loss: 12.916390
 >> iter 43000, loss: 12.903604
 >> iter 44000, loss: 12.919303
 >> iter 45000, loss: 12.903265
 >> iter 46000, loss: 12.923841
 >> iter 47000, loss: 12.903101
 >> iter 48000, loss: 12.923759
 >> iter 49000, loss: 12.904145
 >> iter 50000, loss: 12.925729
   Number of active neurons: 2
 >> iter 51000, loss: 12.904450
 >> iter 52000, loss: 12.923491
 >> iter 53000, loss: 12.900153
 >> iter 54000, loss: 12.922824
 >> iter 55000, loss: 12.896569
 >> iter 56000, loss: 12.922227
 >> iter 57000, loss: 12.899481
 >> iter 58000, loss: 12.922308
 >> iter 59000, loss: 12.900922
 >> iter 60000, loss: 12.922246
   Number of active neurons: 2
 >> iter 61000, loss: 12.901636
 >> iter 62000, loss: 12.925187
 >> iter 63000, loss: 12.902663
 >> iter 64000, loss: 12.925273
 >> iter 65000, loss: 12.902872
 >> iter 66000, loss: 12.926352
 >> iter 67000, loss: 12.902987
 >> iter 68000, loss: 12.924497
 >> iter 69000, loss: 12.903123
 >> iter 70000, loss: 12.926490
   Number of active neurons: 2
 >> iter 71000, loss: 12.902460
 >> iter 72000, loss: 12.926126
 >> iter 73000, loss: 12.903218
 >> iter 74000, loss: 12.926588
 >> iter 75000, loss: 12.902176
 >> iter 76000, loss: 12.925134
 >> iter 77000, loss: 12.904880
 >> iter 78000, loss: 12.925078
 >> iter 79000, loss: 12.900469
 >> iter 80000, loss: 12.922887
   Number of active neurons: 2
 >> iter 81000, loss: 12.899415
 >> iter 82000, loss: 12.926689
 >> iter 83000, loss: 12.902503
 >> iter 84000, loss: 12.928906
 >> iter 85000, loss: 12.904069
 >> iter 86000, loss: 12.929904
 >> iter 87000, loss: 12.905585
 >> iter 88000, loss: 12.931062
 >> iter 89000, loss: 12.907609
 >> iter 90000, loss: 12.935174
   Number of active neurons: 2
 >> iter 91000, loss: 12.907518
 >> iter 92000, loss: 12.934475
 >> iter 93000, loss: 12.906311
 >> iter 94000, loss: 12.934168
 >> iter 95000, loss: 12.908777
 >> iter 96000, loss: 12.932383
 >> iter 97000, loss: 12.907572
 >> iter 98000, loss: 12.934828
 >> iter 99000, loss: 12.909176
 >> iter 100000, loss: 12.932270
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.735991
 >> iter 2000, loss: 15.105201
 >> iter 3000, loss: 13.736899
 >> iter 4000, loss: 13.235633
 >> iter 5000, loss: 13.038778
 >> iter 6000, loss: 12.972332
 >> iter 7000, loss: 12.937497
 >> iter 8000, loss: 12.933662
 >> iter 9000, loss: 12.921622
 >> iter 10000, loss: 12.929322
   Number of active neurons: 2
 >> iter 11000, loss: 12.918089
 >> iter 12000, loss: 12.925521
 >> iter 13000, loss: 12.914251
 >> iter 14000, loss: 12.923886
 >> iter 15000, loss: 12.915102
 >> iter 16000, loss: 12.923026
 >> iter 17000, loss: 12.915628
 >> iter 18000, loss: 12.921313
 >> iter 19000, loss: 12.912111
 >> iter 20000, loss: 12.923096
   Number of active neurons: 2
 >> iter 21000, loss: 12.910059
 >> iter 22000, loss: 12.921944
 >> iter 23000, loss: 12.909936
 >> iter 24000, loss: 12.921583
 >> iter 25000, loss: 12.909042
 >> iter 26000, loss: 12.918724
 >> iter 27000, loss: 12.908279
 >> iter 28000, loss: 12.918159
 >> iter 29000, loss: 12.907963
 >> iter 30000, loss: 12.919511
   Number of active neurons: 2
 >> iter 31000, loss: 12.908356
 >> iter 32000, loss: 12.919174
 >> iter 33000, loss: 12.911394
 >> iter 34000, loss: 12.918889
 >> iter 35000, loss: 12.910327
 >> iter 36000, loss: 12.915989
 >> iter 37000, loss: 12.908711
 >> iter 38000, loss: 12.916831
 >> iter 39000, loss: 12.906753
 >> iter 40000, loss: 12.917026
   Number of active neurons: 2
 >> iter 41000, loss: 12.905332
 >> iter 42000, loss: 12.916908
 >> iter 43000, loss: 12.903885
 >> iter 44000, loss: 12.919779
 >> iter 45000, loss: 12.903523
 >> iter 46000, loss: 12.924214
 >> iter 47000, loss: 12.903340
 >> iter 48000, loss: 12.924111
 >> iter 49000, loss: 12.904376
 >> iter 50000, loss: 12.926055
   Number of active neurons: 2
 >> iter 51000, loss: 12.904659
 >> iter 52000, loss: 12.923796
 >> iter 53000, loss: 12.900343
 >> iter 54000, loss: 12.923125
 >> iter 55000, loss: 12.896750
 >> iter 56000, loss: 12.922517
 >> iter 57000, loss: 12.899654
 >> iter 58000, loss: 12.922577
 >> iter 59000, loss: 12.901092
 >> iter 60000, loss: 12.922516
   Number of active neurons: 2
 >> iter 61000, loss: 12.901798
 >> iter 62000, loss: 12.925416
 >> iter 63000, loss: 12.902815
 >> iter 64000, loss: 12.925504
 >> iter 65000, loss: 12.903020
 >> iter 66000, loss: 12.926578
 >> iter 67000, loss: 12.903128
 >> iter 68000, loss: 12.924714
 >> iter 69000, loss: 12.903260
 >> iter 70000, loss: 12.926694
   Number of active neurons: 2
 >> iter 71000, loss: 12.902590
 >> iter 72000, loss: 12.926321
 >> iter 73000, loss: 12.903342
 >> iter 74000, loss: 12.926778
 >> iter 75000, loss: 12.902292
 >> iter 76000, loss: 12.925315
 >> iter 77000, loss: 12.904991
 >> iter 78000, loss: 12.925261
 >> iter 79000, loss: 12.900572
 >> iter 80000, loss: 12.923064
   Number of active neurons: 2
 >> iter 81000, loss: 12.899512
 >> iter 82000, loss: 12.926832
 >> iter 83000, loss: 12.902597
 >> iter 84000, loss: 12.929043
 >> iter 85000, loss: 12.904158
 >> iter 86000, loss: 12.930033
 >> iter 87000, loss: 12.905671
 >> iter 88000, loss: 12.931186
 >> iter 89000, loss: 12.907691
 >> iter 90000, loss: 12.935295
   Number of active neurons: 2
 >> iter 91000, loss: 12.907599
 >> iter 92000, loss: 12.934593
 >> iter 93000, loss: 12.906393
 >> iter 94000, loss: 12.934286
 >> iter 95000, loss: 12.908859
 >> iter 96000, loss: 12.932496
 >> iter 97000, loss: 12.907651
 >> iter 98000, loss: 12.934937
 >> iter 99000, loss: 12.909253
 >> iter 100000, loss: 12.932372
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.728762
 >> iter 2000, loss: 15.117434
 >> iter 3000, loss: 13.745789
 >> iter 4000, loss: 13.240934
 >> iter 5000, loss: 13.042267
 >> iter 6000, loss: 12.974634
 >> iter 7000, loss: 12.939276
 >> iter 8000, loss: 12.935020
 >> iter 9000, loss: 12.922821
 >> iter 10000, loss: 12.930363
   Number of active neurons: 2
 >> iter 11000, loss: 12.919013
 >> iter 12000, loss: 12.926418
 >> iter 13000, loss: 12.915005
 >> iter 14000, loss: 12.924682
 >> iter 15000, loss: 12.915737
 >> iter 16000, loss: 12.923732
 >> iter 17000, loss: 12.916161
 >> iter 18000, loss: 12.921939
 >> iter 19000, loss: 12.912548
 >> iter 20000, loss: 12.923650
   Number of active neurons: 2
 >> iter 21000, loss: 12.910427
 >> iter 22000, loss: 12.922423
 >> iter 23000, loss: 12.910239
 >> iter 24000, loss: 12.922001
 >> iter 25000, loss: 12.909294
 >> iter 26000, loss: 12.919104
 >> iter 27000, loss: 12.908488
 >> iter 28000, loss: 12.918482
 >> iter 29000, loss: 12.908130
 >> iter 30000, loss: 12.919799
   Number of active neurons: 2
 >> iter 31000, loss: 12.908499
 >> iter 32000, loss: 12.919445
 >> iter 33000, loss: 12.911514
 >> iter 34000, loss: 12.919140
 >> iter 35000, loss: 12.910432
 >> iter 36000, loss: 12.916223
 >> iter 37000, loss: 12.908804
 >> iter 38000, loss: 12.917046
 >> iter 39000, loss: 12.906836
 >> iter 40000, loss: 12.917225
   Number of active neurons: 2
 >> iter 41000, loss: 12.905405
 >> iter 42000, loss: 12.917085
 >> iter 43000, loss: 12.903950
 >> iter 44000, loss: 12.919936
 >> iter 45000, loss: 12.903580
 >> iter 46000, loss: 12.924320
 >> iter 47000, loss: 12.903391
 >> iter 48000, loss: 12.924208
 >> iter 49000, loss: 12.904425
 >> iter 50000, loss: 12.926145
   Number of active neurons: 2
 >> iter 51000, loss: 12.904703
 >> iter 52000, loss: 12.923880
 >> iter 53000, loss: 12.900380
 >> iter 54000, loss: 12.923208
 >> iter 55000, loss: 12.896785
 >> iter 56000, loss: 12.922597
 >> iter 57000, loss: 12.899688
 >> iter 58000, loss: 12.922648
 >> iter 59000, loss: 12.901126
 >> iter 60000, loss: 12.922590
   Number of active neurons: 2
 >> iter 61000, loss: 12.901829
 >> iter 62000, loss: 12.925472
 >> iter 63000, loss: 12.902845
 >> iter 64000, loss: 12.925562
 >> iter 65000, loss: 12.903049
 >> iter 66000, loss: 12.926638
 >> iter 67000, loss: 12.903155
 >> iter 68000, loss: 12.924771
 >> iter 69000, loss: 12.903287
 >> iter 70000, loss: 12.926747
   Number of active neurons: 2
 >> iter 71000, loss: 12.902616
 >> iter 72000, loss: 12.926370
 >> iter 73000, loss: 12.903366
 >> iter 74000, loss: 12.926824
 >> iter 75000, loss: 12.902313
 >> iter 76000, loss: 12.925359
 >> iter 77000, loss: 12.905011
 >> iter 78000, loss: 12.925306
 >> iter 79000, loss: 12.900590
 >> iter 80000, loss: 12.923106
   Number of active neurons: 2
 >> iter 81000, loss: 12.899527
 >> iter 82000, loss: 12.926862
 >> iter 83000, loss: 12.902612
 >> iter 84000, loss: 12.929071
 >> iter 85000, loss: 12.904171
 >> iter 86000, loss: 12.930059
 >> iter 87000, loss: 12.905685
 >> iter 88000, loss: 12.931211
 >> iter 89000, loss: 12.907704
 >> iter 90000, loss: 12.935319
   Number of active neurons: 2
 >> iter 91000, loss: 12.907611
 >> iter 92000, loss: 12.934617
 >> iter 93000, loss: 12.906406
 >> iter 94000, loss: 12.934312
 >> iter 95000, loss: 12.908873
 >> iter 96000, loss: 12.932521
 >> iter 97000, loss: 12.907665
 >> iter 98000, loss: 12.934960
 >> iter 99000, loss: 12.909266
 >> iter 100000, loss: 12.932392
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.711425
 >> iter 2000, loss: 15.081515
 >> iter 3000, loss: 13.723391
 >> iter 4000, loss: 13.228311
 >> iter 5000, loss: 13.034064
 >> iter 6000, loss: 12.969154
 >> iter 7000, loss: 12.934962
 >> iter 8000, loss: 12.931610
 >> iter 9000, loss: 12.919772
 >> iter 10000, loss: 12.927605
   Number of active neurons: 2
 >> iter 11000, loss: 12.916605
 >> iter 12000, loss: 12.923999
 >> iter 13000, loss: 12.913034
 >> iter 14000, loss: 12.922560
 >> iter 15000, loss: 12.914080
 >> iter 16000, loss: 12.921851
 >> iter 17000, loss: 12.914761
 >> iter 18000, loss: 12.920277
 >> iter 19000, loss: 12.911394
 >> iter 20000, loss: 12.922185
   Number of active neurons: 2
 >> iter 21000, loss: 12.909450
 >> iter 22000, loss: 12.921164
 >> iter 23000, loss: 12.909424
 >> iter 24000, loss: 12.920896
 >> iter 25000, loss: 12.908600
 >> iter 26000, loss: 12.918093
 >> iter 27000, loss: 12.907896
 >> iter 28000, loss: 12.917619
 >> iter 29000, loss: 12.907639
 >> iter 30000, loss: 12.919029
   Number of active neurons: 2
 >> iter 31000, loss: 12.908068
 >> iter 32000, loss: 12.918724
 >> iter 33000, loss: 12.911140
 >> iter 34000, loss: 12.918470
 >> iter 35000, loss: 12.910100
 >> iter 36000, loss: 12.915595
 >> iter 37000, loss: 12.908503
 >> iter 38000, loss: 12.916468
 >> iter 39000, loss: 12.906563
 >> iter 40000, loss: 12.916691
   Number of active neurons: 2
 >> iter 41000, loss: 12.905160
 >> iter 42000, loss: 12.916610
 >> iter 43000, loss: 12.903725
 >> iter 44000, loss: 12.919506
 >> iter 45000, loss: 12.903377
 >> iter 46000, loss: 12.924000
 >> iter 47000, loss: 12.903206
 >> iter 48000, loss: 12.923909
 >> iter 49000, loss: 12.904246
 >> iter 50000, loss: 12.925868
   Number of active neurons: 2
 >> iter 51000, loss: 12.904542
 >> iter 52000, loss: 12.923623
 >> iter 53000, loss: 12.900237
 >> iter 54000, loss: 12.922954
 >> iter 55000, loss: 12.896649
 >> iter 56000, loss: 12.922354
 >> iter 57000, loss: 12.899557
 >> iter 58000, loss: 12.922426
 >> iter 59000, loss: 12.900997
 >> iter 60000, loss: 12.922364
   Number of active neurons: 2
 >> iter 61000, loss: 12.901707
 >> iter 62000, loss: 12.925287
 >> iter 63000, loss: 12.902730
 >> iter 64000, loss: 12.925374
 >> iter 65000, loss: 12.902936
 >> iter 66000, loss: 12.926451
 >> iter 67000, loss: 12.903049
 >> iter 68000, loss: 12.924593
 >> iter 69000, loss: 12.903183
 >> iter 70000, loss: 12.926580
   Number of active neurons: 2
 >> iter 71000, loss: 12.902517
 >> iter 72000, loss: 12.926212
 >> iter 73000, loss: 12.903272
 >> iter 74000, loss: 12.926672
 >> iter 75000, loss: 12.902227
 >> iter 76000, loss: 12.925214
 >> iter 77000, loss: 12.904928
 >> iter 78000, loss: 12.925159
 >> iter 79000, loss: 12.900514
 >> iter 80000, loss: 12.922965
   Number of active neurons: 2
 >> iter 81000, loss: 12.899457
 >> iter 82000, loss: 12.926753
 >> iter 83000, loss: 12.902544
 >> iter 84000, loss: 12.928967
 >> iter 85000, loss: 12.904108
 >> iter 86000, loss: 12.929962
 >> iter 87000, loss: 12.905623
 >> iter 88000, loss: 12.931118
 >> iter 89000, loss: 12.907645
 >> iter 90000, loss: 12.935228
   Number of active neurons: 2
 >> iter 91000, loss: 12.907553
 >> iter 92000, loss: 12.934528
 >> iter 93000, loss: 12.906346
 >> iter 94000, loss: 12.934221
 >> iter 95000, loss: 12.908812
 >> iter 96000, loss: 12.932434
 >> iter 97000, loss: 12.907606
 >> iter 98000, loss: 12.934877
 >> iter 99000, loss: 12.909209
 >> iter 100000, loss: 12.932316
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.646360
 >> iter 2000, loss: 15.060531
 >> iter 3000, loss: 13.717057
 >> iter 4000, loss: 13.226735
 >> iter 5000, loss: 13.034212
 >> iter 6000, loss: 12.969784
 >> iter 7000, loss: 12.935740
 >> iter 8000, loss: 12.932384
 >> iter 9000, loss: 12.920514
 >> iter 10000, loss: 12.928349
   Number of active neurons: 2
 >> iter 11000, loss: 12.917234
 >> iter 12000, loss: 12.924673
 >> iter 13000, loss: 12.913556
 >> iter 14000, loss: 12.923146
 >> iter 15000, loss: 12.914522
 >> iter 16000, loss: 12.922374
 >> iter 17000, loss: 12.915138
 >> iter 18000, loss: 12.920738
 >> iter 19000, loss: 12.911706
 >> iter 20000, loss: 12.922588
   Number of active neurons: 2
 >> iter 21000, loss: 12.909717
 >> iter 22000, loss: 12.921511
 >> iter 23000, loss: 12.909651
 >> iter 24000, loss: 12.921204
 >> iter 25000, loss: 12.908799
 >> iter 26000, loss: 12.918377
 >> iter 27000, loss: 12.908070
 >> iter 28000, loss: 12.917863
 >> iter 29000, loss: 12.907787
 >> iter 30000, loss: 12.919246
   Number of active neurons: 2
 >> iter 31000, loss: 12.908201
 >> iter 32000, loss: 12.918927
 >> iter 33000, loss: 12.911259
 >> iter 34000, loss: 12.918660
 >> iter 35000, loss: 12.910207
 >> iter 36000, loss: 12.915774
 >> iter 37000, loss: 12.908601
 >> iter 38000, loss: 12.916634
 >> iter 39000, loss: 12.906653
 >> iter 40000, loss: 12.916844
   Number of active neurons: 2
 >> iter 41000, loss: 12.905242
 >> iter 42000, loss: 12.916746
 >> iter 43000, loss: 12.903802
 >> iter 44000, loss: 12.919631
 >> iter 45000, loss: 12.903448
 >> iter 46000, loss: 12.924100
 >> iter 47000, loss: 12.903271
 >> iter 48000, loss: 12.924004
 >> iter 49000, loss: 12.904309
 >> iter 50000, loss: 12.925957
   Number of active neurons: 2
 >> iter 51000, loss: 12.904599
 >> iter 52000, loss: 12.923705
 >> iter 53000, loss: 12.900289
 >> iter 54000, loss: 12.923035
 >> iter 55000, loss: 12.896698
 >> iter 56000, loss: 12.922431
 >> iter 57000, loss: 12.899605
 >> iter 58000, loss: 12.922497
 >> iter 59000, loss: 12.901043
 >> iter 60000, loss: 12.922436
   Number of active neurons: 2
 >> iter 61000, loss: 12.901752
 >> iter 62000, loss: 12.925349
 >> iter 63000, loss: 12.902772
 >> iter 64000, loss: 12.925436
 >> iter 65000, loss: 12.902977
 >> iter 66000, loss: 12.926511
 >> iter 67000, loss: 12.903088
 >> iter 68000, loss: 12.924651
 >> iter 69000, loss: 12.903221
 >> iter 70000, loss: 12.926635
   Number of active neurons: 2
 >> iter 71000, loss: 12.902553
 >> iter 72000, loss: 12.926265
 >> iter 73000, loss: 12.903306
 >> iter 74000, loss: 12.926723
 >> iter 75000, loss: 12.902259
 >> iter 76000, loss: 12.925262
 >> iter 77000, loss: 12.904959
 >> iter 78000, loss: 12.925208
 >> iter 79000, loss: 12.900543
 >> iter 80000, loss: 12.923013
   Number of active neurons: 2
 >> iter 81000, loss: 12.899484
 >> iter 82000, loss: 12.926792
 >> iter 83000, loss: 12.902570
 >> iter 84000, loss: 12.929004
 >> iter 85000, loss: 12.904133
 >> iter 86000, loss: 12.929997
 >> iter 87000, loss: 12.905647
 >> iter 88000, loss: 12.931152
 >> iter 89000, loss: 12.907668
 >> iter 90000, loss: 12.935261
   Number of active neurons: 2
 >> iter 91000, loss: 12.907576
 >> iter 92000, loss: 12.934560
 >> iter 93000, loss: 12.906370
 >> iter 94000, loss: 12.934253
 >> iter 95000, loss: 12.908835
 >> iter 96000, loss: 12.932464
 >> iter 97000, loss: 12.907629
 >> iter 98000, loss: 12.934907
 >> iter 99000, loss: 12.909231
 >> iter 100000, loss: 12.932344
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.638463
 >> iter 2000, loss: 15.063816
 >> iter 3000, loss: 13.717230
 >> iter 4000, loss: 13.225420
 >> iter 5000, loss: 13.032330
 >> iter 6000, loss: 12.967541
 >> iter 7000, loss: 12.933697
 >> iter 8000, loss: 12.930212
 >> iter 9000, loss: 12.918667
 >> iter 10000, loss: 12.926318
   Number of active neurons: 2
 >> iter 11000, loss: 12.915658
 >> iter 12000, loss: 12.922849
 >> iter 13000, loss: 12.912233
 >> iter 14000, loss: 12.921557
 >> iter 15000, loss: 12.913391
 >> iter 16000, loss: 12.920953
 >> iter 17000, loss: 12.914169
 >> iter 18000, loss: 12.919486
 >> iter 19000, loss: 12.910887
 >> iter 20000, loss: 12.921482
   Number of active neurons: 2
 >> iter 21000, loss: 12.909006
 >> iter 22000, loss: 12.920550
 >> iter 23000, loss: 12.909037
 >> iter 24000, loss: 12.920347
 >> iter 25000, loss: 12.908253
 >> iter 26000, loss: 12.917585
 >> iter 27000, loss: 12.907588
 >> iter 28000, loss: 12.917176
 >> iter 29000, loss: 12.907370
 >> iter 30000, loss: 12.918622
   Number of active neurons: 2
 >> iter 31000, loss: 12.907824
 >> iter 32000, loss: 12.918339
 >> iter 33000, loss: 12.910920
 >> iter 34000, loss: 12.918109
 >> iter 35000, loss: 12.909898
 >> iter 36000, loss: 12.915251
 >> iter 37000, loss: 12.908316
 >> iter 38000, loss: 12.916149
 >> iter 39000, loss: 12.906390
 >> iter 40000, loss: 12.916393
   Number of active neurons: 2
 >> iter 41000, loss: 12.905002
 >> iter 42000, loss: 12.916337
 >> iter 43000, loss: 12.903577
 >> iter 44000, loss: 12.919255
 >> iter 45000, loss: 12.903240
 >> iter 46000, loss: 12.923806
 >> iter 47000, loss: 12.903078
 >> iter 48000, loss: 12.923726
 >> iter 49000, loss: 12.904123
 >> iter 50000, loss: 12.925697
   Number of active neurons: 2
 >> iter 51000, loss: 12.904430
 >> iter 52000, loss: 12.923461
 >> iter 53000, loss: 12.900135
 >> iter 54000, loss: 12.922794
 >> iter 55000, loss: 12.896552
 >> iter 56000, loss: 12.922197
 >> iter 57000, loss: 12.899464
 >> iter 58000, loss: 12.922281
 >> iter 59000, loss: 12.900906
 >> iter 60000, loss: 12.922219
   Number of active neurons: 2
 >> iter 61000, loss: 12.901621
 >> iter 62000, loss: 12.925165
 >> iter 63000, loss: 12.902648
 >> iter 64000, loss: 12.925250
 >> iter 65000, loss: 12.902858
 >> iter 66000, loss: 12.926328
 >> iter 67000, loss: 12.902974
 >> iter 68000, loss: 12.924475
 >> iter 69000, loss: 12.903111
 >> iter 70000, loss: 12.926468
   Number of active neurons: 2
 >> iter 71000, loss: 12.902447
 >> iter 72000, loss: 12.926106
 >> iter 73000, loss: 12.903206
 >> iter 74000, loss: 12.926569
 >> iter 75000, loss: 12.902165
 >> iter 76000, loss: 12.925115
 >> iter 77000, loss: 12.904870
 >> iter 78000, loss: 12.925059
 >> iter 79000, loss: 12.900459
 >> iter 80000, loss: 12.922870
   Number of active neurons: 2
 >> iter 81000, loss: 12.899407
 >> iter 82000, loss: 12.926674
 >> iter 83000, loss: 12.902494
 >> iter 84000, loss: 12.928892
 >> iter 85000, loss: 12.904062
 >> iter 86000, loss: 12.929891
 >> iter 87000, loss: 12.905578
 >> iter 88000, loss: 12.931049
 >> iter 89000, loss: 12.907601
 >> iter 90000, loss: 12.935161
   Number of active neurons: 2
 >> iter 91000, loss: 12.907511
 >> iter 92000, loss: 12.934463
 >> iter 93000, loss: 12.906304
 >> iter 94000, loss: 12.934155
 >> iter 95000, loss: 12.908770
 >> iter 96000, loss: 12.932370
 >> iter 97000, loss: 12.907565
 >> iter 98000, loss: 12.934817
 >> iter 99000, loss: 12.909169
 >> iter 100000, loss: 12.932259
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.832545
 >> iter 2000, loss: 15.155257
 >> iter 3000, loss: 13.753807
 >> iter 4000, loss: 13.239682
 >> iter 5000, loss: 13.037903
 >> iter 6000, loss: 12.969613
 >> iter 7000, loss: 12.934500
 >> iter 8000, loss: 12.930403
 >> iter 9000, loss: 12.918710
 >> iter 10000, loss: 12.926196
   Number of active neurons: 2
 >> iter 11000, loss: 12.915573
 >> iter 12000, loss: 12.922677
 >> iter 13000, loss: 12.912129
 >> iter 14000, loss: 12.921389
 >> iter 15000, loss: 12.913289
 >> iter 16000, loss: 12.920791
 >> iter 17000, loss: 12.914074
 >> iter 18000, loss: 12.919336
 >> iter 19000, loss: 12.910801
 >> iter 20000, loss: 12.921347
   Number of active neurons: 2
 >> iter 21000, loss: 12.908927
 >> iter 22000, loss: 12.920430
 >> iter 23000, loss: 12.908967
 >> iter 24000, loss: 12.920239
 >> iter 25000, loss: 12.908189
 >> iter 26000, loss: 12.917482
 >> iter 27000, loss: 12.907530
 >> iter 28000, loss: 12.917087
 >> iter 29000, loss: 12.907319
 >> iter 30000, loss: 12.918539
   Number of active neurons: 2
 >> iter 31000, loss: 12.907777
 >> iter 32000, loss: 12.918259
 >> iter 33000, loss: 12.910878
 >> iter 34000, loss: 12.918034
 >> iter 35000, loss: 12.909860
 >> iter 36000, loss: 12.915178
 >> iter 37000, loss: 12.908280
 >> iter 38000, loss: 12.916081
 >> iter 39000, loss: 12.906356
 >> iter 40000, loss: 12.916329
   Number of active neurons: 2
 >> iter 41000, loss: 12.904971
 >> iter 42000, loss: 12.916278
 >> iter 43000, loss: 12.903547
 >> iter 44000, loss: 12.919201
 >> iter 45000, loss: 12.903214
 >> iter 46000, loss: 12.923765
 >> iter 47000, loss: 12.903053
 >> iter 48000, loss: 12.923687
 >> iter 49000, loss: 12.904099
 >> iter 50000, loss: 12.925661
   Number of active neurons: 2
 >> iter 51000, loss: 12.904408
 >> iter 52000, loss: 12.923427
 >> iter 53000, loss: 12.900115
 >> iter 54000, loss: 12.922759
 >> iter 55000, loss: 12.896534
 >> iter 56000, loss: 12.922164
 >> iter 57000, loss: 12.899447
 >> iter 58000, loss: 12.922250
 >> iter 59000, loss: 12.900888
 >> iter 60000, loss: 12.922187
   Number of active neurons: 2
 >> iter 61000, loss: 12.901605
 >> iter 62000, loss: 12.925139
 >> iter 63000, loss: 12.902633
 >> iter 64000, loss: 12.925224
 >> iter 65000, loss: 12.902843
 >> iter 66000, loss: 12.926302
 >> iter 67000, loss: 12.902960
 >> iter 68000, loss: 12.924449
 >> iter 69000, loss: 12.903097
 >> iter 70000, loss: 12.926444
   Number of active neurons: 2
 >> iter 71000, loss: 12.902435
 >> iter 72000, loss: 12.926083
 >> iter 73000, loss: 12.903194
 >> iter 74000, loss: 12.926547
 >> iter 75000, loss: 12.902154
 >> iter 76000, loss: 12.925094
 >> iter 77000, loss: 12.904859
 >> iter 78000, loss: 12.925038
 >> iter 79000, loss: 12.900450
 >> iter 80000, loss: 12.922851
   Number of active neurons: 2
 >> iter 81000, loss: 12.899398
 >> iter 82000, loss: 12.926658
 >> iter 83000, loss: 12.902486
 >> iter 84000, loss: 12.928876
 >> iter 85000, loss: 12.904054
 >> iter 86000, loss: 12.929876
 >> iter 87000, loss: 12.905570
 >> iter 88000, loss: 12.931035
 >> iter 89000, loss: 12.907594
 >> iter 90000, loss: 12.935147
   Number of active neurons: 2
 >> iter 91000, loss: 12.907504
 >> iter 92000, loss: 12.934449
 >> iter 93000, loss: 12.906297
 >> iter 94000, loss: 12.934141
 >> iter 95000, loss: 12.908763
 >> iter 96000, loss: 12.932357
 >> iter 97000, loss: 12.907559
 >> iter 98000, loss: 12.934804
 >> iter 99000, loss: 12.909163
 >> iter 100000, loss: 12.932248
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.663764
 >> iter 2000, loss: 15.067589
 >> iter 3000, loss: 13.719876
 >> iter 4000, loss: 13.227875
 >> iter 5000, loss: 13.034729
 >> iter 6000, loss: 12.970037
 >> iter 7000, loss: 12.935901
 >> iter 8000, loss: 12.932491
 >> iter 9000, loss: 12.920608
 >> iter 10000, loss: 12.928429
   Number of active neurons: 2
 >> iter 11000, loss: 12.917308
 >> iter 12000, loss: 12.924743
 >> iter 13000, loss: 12.913616
 >> iter 14000, loss: 12.923208
 >> iter 15000, loss: 12.914573
 >> iter 16000, loss: 12.922428
 >> iter 17000, loss: 12.915182
 >> iter 18000, loss: 12.920787
 >> iter 19000, loss: 12.911743
 >> iter 20000, loss: 12.922631
   Number of active neurons: 2
 >> iter 21000, loss: 12.909749
 >> iter 22000, loss: 12.921548
 >> iter 23000, loss: 12.909678
 >> iter 24000, loss: 12.921236
 >> iter 25000, loss: 12.908822
 >> iter 26000, loss: 12.918407
 >> iter 27000, loss: 12.908090
 >> iter 28000, loss: 12.917888
 >> iter 29000, loss: 12.907805
 >> iter 30000, loss: 12.919269
   Number of active neurons: 2
 >> iter 31000, loss: 12.908217
 >> iter 32000, loss: 12.918948
 >> iter 33000, loss: 12.911273
 >> iter 34000, loss: 12.918679
 >> iter 35000, loss: 12.910219
 >> iter 36000, loss: 12.915792
 >> iter 37000, loss: 12.908612
 >> iter 38000, loss: 12.916650
 >> iter 39000, loss: 12.906664
 >> iter 40000, loss: 12.916859
   Number of active neurons: 2
 >> iter 41000, loss: 12.905251
 >> iter 42000, loss: 12.916759
 >> iter 43000, loss: 12.903811
 >> iter 44000, loss: 12.919643
 >> iter 45000, loss: 12.903456
 >> iter 46000, loss: 12.924111
 >> iter 47000, loss: 12.903279
 >> iter 48000, loss: 12.924015
 >> iter 49000, loss: 12.904316
 >> iter 50000, loss: 12.925966
   Number of active neurons: 2
 >> iter 51000, loss: 12.904606
 >> iter 52000, loss: 12.923714
 >> iter 53000, loss: 12.900295
 >> iter 54000, loss: 12.923044
 >> iter 55000, loss: 12.896704
 >> iter 56000, loss: 12.922438
 >> iter 57000, loss: 12.899610
 >> iter 58000, loss: 12.922505
 >> iter 59000, loss: 12.901049
 >> iter 60000, loss: 12.922443
   Number of active neurons: 2
 >> iter 61000, loss: 12.901757
 >> iter 62000, loss: 12.925356
 >> iter 63000, loss: 12.902776
 >> iter 64000, loss: 12.925443
 >> iter 65000, loss: 12.902982
 >> iter 66000, loss: 12.926517
 >> iter 67000, loss: 12.903092
 >> iter 68000, loss: 12.924656
 >> iter 69000, loss: 12.903225
 >> iter 70000, loss: 12.926640
   Number of active neurons: 2
 >> iter 71000, loss: 12.902557
 >> iter 72000, loss: 12.926270
 >> iter 73000, loss: 12.903310
 >> iter 74000, loss: 12.926728
 >> iter 75000, loss: 12.902262
 >> iter 76000, loss: 12.925267
 >> iter 77000, loss: 12.904962
 >> iter 78000, loss: 12.925212
 >> iter 79000, loss: 12.900546
 >> iter 80000, loss: 12.923017
   Number of active neurons: 2
 >> iter 81000, loss: 12.899487
 >> iter 82000, loss: 12.926796
 >> iter 83000, loss: 12.902573
 >> iter 84000, loss: 12.929008
 >> iter 85000, loss: 12.904136
 >> iter 86000, loss: 12.930000
 >> iter 87000, loss: 12.905650
 >> iter 88000, loss: 12.931155
 >> iter 89000, loss: 12.907670
 >> iter 90000, loss: 12.935264
   Number of active neurons: 2
 >> iter 91000, loss: 12.907579
 >> iter 92000, loss: 12.934563
 >> iter 93000, loss: 12.906372
 >> iter 94000, loss: 12.934256
 >> iter 95000, loss: 12.908838
 >> iter 96000, loss: 12.932467
 >> iter 97000, loss: 12.907631
 >> iter 98000, loss: 12.934910
 >> iter 99000, loss: 12.909233
 >> iter 100000, loss: 12.932347
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.678882
 >> iter 2000, loss: 15.080319
 >> iter 3000, loss: 13.723578
 >> iter 4000, loss: 13.227876
 >> iter 5000, loss: 13.033305
 >> iter 6000, loss: 12.967953
 >> iter 7000, loss: 12.933887
 >> iter 8000, loss: 12.930318
 >> iter 9000, loss: 12.918731
 >> iter 10000, loss: 12.926370
   Number of active neurons: 2
 >> iter 11000, loss: 12.915696
 >> iter 12000, loss: 12.922885
 >> iter 13000, loss: 12.912260
 >> iter 14000, loss: 12.921587
 >> iter 15000, loss: 12.913414
 >> iter 16000, loss: 12.920979
 >> iter 17000, loss: 12.914188
 >> iter 18000, loss: 12.919507
 >> iter 19000, loss: 12.910903
 >> iter 20000, loss: 12.921501
   Number of active neurons: 2
 >> iter 21000, loss: 12.909019
 >> iter 22000, loss: 12.920567
 >> iter 23000, loss: 12.909049
 >> iter 24000, loss: 12.920362
 >> iter 25000, loss: 12.908264
 >> iter 26000, loss: 12.917598
 >> iter 27000, loss: 12.907597
 >> iter 28000, loss: 12.917188
 >> iter 29000, loss: 12.907378
 >> iter 30000, loss: 12.918633
   Number of active neurons: 2
 >> iter 31000, loss: 12.907832
 >> iter 32000, loss: 12.918349
 >> iter 33000, loss: 12.910927
 >> iter 34000, loss: 12.918119
 >> iter 35000, loss: 12.909905
 >> iter 36000, loss: 12.915260
 >> iter 37000, loss: 12.908322
 >> iter 38000, loss: 12.916157
 >> iter 39000, loss: 12.906396
 >> iter 40000, loss: 12.916401
   Number of active neurons: 2
 >> iter 41000, loss: 12.905007
 >> iter 42000, loss: 12.916344
 >> iter 43000, loss: 12.903581
 >> iter 44000, loss: 12.919262
 >> iter 45000, loss: 12.903245
 >> iter 46000, loss: 12.923812
 >> iter 47000, loss: 12.903082
 >> iter 48000, loss: 12.923731
 >> iter 49000, loss: 12.904127
 >> iter 50000, loss: 12.925702
   Number of active neurons: 2
 >> iter 51000, loss: 12.904434
 >> iter 52000, loss: 12.923466
 >> iter 53000, loss: 12.900138
 >> iter 54000, loss: 12.922798
 >> iter 55000, loss: 12.896555
 >> iter 56000, loss: 12.922202
 >> iter 57000, loss: 12.899467
 >> iter 58000, loss: 12.922285
 >> iter 59000, loss: 12.900908
 >> iter 60000, loss: 12.922223
   Number of active neurons: 2
 >> iter 61000, loss: 12.901624
 >> iter 62000, loss: 12.925168
 >> iter 63000, loss: 12.902651
 >> iter 64000, loss: 12.925254
 >> iter 65000, loss: 12.902860
 >> iter 66000, loss: 12.926332
 >> iter 67000, loss: 12.902976
 >> iter 68000, loss: 12.924478
 >> iter 69000, loss: 12.903113
 >> iter 70000, loss: 12.926471
   Number of active neurons: 2
 >> iter 71000, loss: 12.902450
 >> iter 72000, loss: 12.926109
 >> iter 73000, loss: 12.903208
 >> iter 74000, loss: 12.926572
 >> iter 75000, loss: 12.902167
 >> iter 76000, loss: 12.925118
 >> iter 77000, loss: 12.904872
 >> iter 78000, loss: 12.925062
 >> iter 79000, loss: 12.900461
 >> iter 80000, loss: 12.922873
   Number of active neurons: 2
 >> iter 81000, loss: 12.899408
 >> iter 82000, loss: 12.926677
 >> iter 83000, loss: 12.902496
 >> iter 84000, loss: 12.928894
 >> iter 85000, loss: 12.904063
 >> iter 86000, loss: 12.929893
 >> iter 87000, loss: 12.905579
 >> iter 88000, loss: 12.931051
 >> iter 89000, loss: 12.907603
 >> iter 90000, loss: 12.935163
   Number of active neurons: 2
 >> iter 91000, loss: 12.907513
 >> iter 92000, loss: 12.934465
 >> iter 93000, loss: 12.906305
 >> iter 94000, loss: 12.934157
 >> iter 95000, loss: 12.908771
 >> iter 96000, loss: 12.932372
 >> iter 97000, loss: 12.907567
 >> iter 98000, loss: 12.934818
 >> iter 99000, loss: 12.909171
 >> iter 100000, loss: 12.932261
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.676692
 >> iter 2000, loss: 15.070219
 >> iter 3000, loss: 13.718651
 >> iter 4000, loss: 13.225888
 >> iter 5000, loss: 13.032548
 >> iter 6000, loss: 12.967876
 >> iter 7000, loss: 12.933956
 >> iter 8000, loss: 12.930588
 >> iter 9000, loss: 12.918944
 >> iter 10000, loss: 12.926690
   Number of active neurons: 2
 >> iter 11000, loss: 12.915913
 >> iter 12000, loss: 12.923191
 >> iter 13000, loss: 12.912456
 >> iter 14000, loss: 12.921860
 >> iter 15000, loss: 12.913588
 >> iter 16000, loss: 12.921228
 >> iter 17000, loss: 12.914341
 >> iter 18000, loss: 12.919731
 >> iter 19000, loss: 12.911038
 >> iter 20000, loss: 12.921701
   Number of active neurons: 2
 >> iter 21000, loss: 12.909139
 >> iter 22000, loss: 12.920744
 >> iter 23000, loss: 12.909154
 >> iter 24000, loss: 12.920521
 >> iter 25000, loss: 12.908359
 >> iter 26000, loss: 12.917746
 >> iter 27000, loss: 12.907683
 >> iter 28000, loss: 12.917318
 >> iter 29000, loss: 12.907453
 >> iter 30000, loss: 12.918755
   Number of active neurons: 2
 >> iter 31000, loss: 12.907900
 >> iter 32000, loss: 12.918465
 >> iter 33000, loss: 12.910989
 >> iter 34000, loss: 12.918229
 >> iter 35000, loss: 12.909962
 >> iter 36000, loss: 12.915365
 >> iter 37000, loss: 12.908375
 >> iter 38000, loss: 12.916255
 >> iter 39000, loss: 12.906445
 >> iter 40000, loss: 12.916493
   Number of active neurons: 2
 >> iter 41000, loss: 12.905052
 >> iter 42000, loss: 12.916430
 >> iter 43000, loss: 12.903624
 >> iter 44000, loss: 12.919340
 >> iter 45000, loss: 12.903284
 >> iter 46000, loss: 12.923868
 >> iter 47000, loss: 12.903119
 >> iter 48000, loss: 12.923785
 >> iter 49000, loss: 12.904162
 >> iter 50000, loss: 12.925752
   Number of active neurons: 2
 >> iter 51000, loss: 12.904466
 >> iter 52000, loss: 12.923514
 >> iter 53000, loss: 12.900167
 >> iter 54000, loss: 12.922846
 >> iter 55000, loss: 12.896582
 >> iter 56000, loss: 12.922250
 >> iter 57000, loss: 12.899493
 >> iter 58000, loss: 12.922329
 >> iter 59000, loss: 12.900935
 >> iter 60000, loss: 12.922267
   Number of active neurons: 2
 >> iter 61000, loss: 12.901648
 >> iter 62000, loss: 12.925204
 >> iter 63000, loss: 12.902674
 >> iter 64000, loss: 12.925290
 >> iter 65000, loss: 12.902882
 >> iter 66000, loss: 12.926370
 >> iter 67000, loss: 12.902997
 >> iter 68000, loss: 12.924515
 >> iter 69000, loss: 12.903133
 >> iter 70000, loss: 12.926506
   Number of active neurons: 2
 >> iter 71000, loss: 12.902469
 >> iter 72000, loss: 12.926142
 >> iter 73000, loss: 12.903227
 >> iter 74000, loss: 12.926603
 >> iter 75000, loss: 12.902184
 >> iter 76000, loss: 12.925148
 >> iter 77000, loss: 12.904888
 >> iter 78000, loss: 12.925092
 >> iter 79000, loss: 12.900476
 >> iter 80000, loss: 12.922901
   Number of active neurons: 2
 >> iter 81000, loss: 12.899422
 >> iter 82000, loss: 12.926700
 >> iter 83000, loss: 12.902509
 >> iter 84000, loss: 12.928917
 >> iter 85000, loss: 12.904076
 >> iter 86000, loss: 12.929915
 >> iter 87000, loss: 12.905591
 >> iter 88000, loss: 12.931072
 >> iter 89000, loss: 12.907614
 >> iter 90000, loss: 12.935183
   Number of active neurons: 2
 >> iter 91000, loss: 12.907524
 >> iter 92000, loss: 12.934485
 >> iter 93000, loss: 12.906317
 >> iter 94000, loss: 12.934178
 >> iter 95000, loss: 12.908783
 >> iter 96000, loss: 12.932392
 >> iter 97000, loss: 12.907578
 >> iter 98000, loss: 12.934837
 >> iter 99000, loss: 12.909181
 >> iter 100000, loss: 12.932278
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.758448
 >> iter 2000, loss: 15.101410
 >> iter 3000, loss: 13.731637
 >> iter 4000, loss: 13.231835
 >> iter 5000, loss: 13.035787
 >> iter 6000, loss: 12.970129
 >> iter 7000, loss: 12.935627
 >> iter 8000, loss: 12.932135
 >> iter 9000, loss: 12.920214
 >> iter 10000, loss: 12.928030
   Number of active neurons: 2
 >> iter 11000, loss: 12.916951
 >> iter 12000, loss: 12.924367
 >> iter 13000, loss: 12.913316
 >> iter 14000, loss: 12.922876
 >> iter 15000, loss: 12.914318
 >> iter 16000, loss: 12.922131
 >> iter 17000, loss: 12.914963
 >> iter 18000, loss: 12.920523
 >> iter 19000, loss: 12.911562
 >> iter 20000, loss: 12.922400
   Number of active neurons: 2
 >> iter 21000, loss: 12.909595
 >> iter 22000, loss: 12.921350
 >> iter 23000, loss: 12.909548
 >> iter 24000, loss: 12.921061
 >> iter 25000, loss: 12.908709
 >> iter 26000, loss: 12.918245
 >> iter 27000, loss: 12.907992
 >> iter 28000, loss: 12.917750
 >> iter 29000, loss: 12.907721
 >> iter 30000, loss: 12.919146
   Number of active neurons: 2
 >> iter 31000, loss: 12.908143
 >> iter 32000, loss: 12.918833
 >> iter 33000, loss: 12.911207
 >> iter 34000, loss: 12.918572
 >> iter 35000, loss: 12.910160
 >> iter 36000, loss: 12.915692
 >> iter 37000, loss: 12.908558
 >> iter 38000, loss: 12.916557
 >> iter 39000, loss: 12.906614
 >> iter 40000, loss: 12.916774
   Number of active neurons: 2
 >> iter 41000, loss: 12.905206
 >> iter 42000, loss: 12.916684
 >> iter 43000, loss: 12.903769
 >> iter 44000, loss: 12.919574
 >> iter 45000, loss: 12.903418
 >> iter 46000, loss: 12.924055
 >> iter 47000, loss: 12.903243
 >> iter 48000, loss: 12.923962
 >> iter 49000, loss: 12.904282
 >> iter 50000, loss: 12.925917
   Number of active neurons: 2
 >> iter 51000, loss: 12.904575
 >> iter 52000, loss: 12.923669
 >> iter 53000, loss: 12.900267
 >> iter 54000, loss: 12.922999
 >> iter 55000, loss: 12.896677
 >> iter 56000, loss: 12.922396
 >> iter 57000, loss: 12.899585
 >> iter 58000, loss: 12.922466
 >> iter 59000, loss: 12.901024
 >> iter 60000, loss: 12.922404
   Number of active neurons: 2
 >> iter 61000, loss: 12.901733
 >> iter 62000, loss: 12.925321
 >> iter 63000, loss: 12.902754
 >> iter 64000, loss: 12.925409
 >> iter 65000, loss: 12.902960
 >> iter 66000, loss: 12.926485
 >> iter 67000, loss: 12.903071
 >> iter 68000, loss: 12.924625
 >> iter 69000, loss: 12.903205
 >> iter 70000, loss: 12.926611
   Number of active neurons: 2
 >> iter 71000, loss: 12.902537
 >> iter 72000, loss: 12.926242
 >> iter 73000, loss: 12.903292
 >> iter 74000, loss: 12.926701
 >> iter 75000, loss: 12.902245
 >> iter 76000, loss: 12.925241
 >> iter 77000, loss: 12.904946
 >> iter 78000, loss: 12.925186
 >> iter 79000, loss: 12.900531
 >> iter 80000, loss: 12.922991
   Number of active neurons: 2
 >> iter 81000, loss: 12.899473
 >> iter 82000, loss: 12.926775
 >> iter 83000, loss: 12.902559
 >> iter 84000, loss: 12.928989
 >> iter 85000, loss: 12.904123
 >> iter 86000, loss: 12.929982
 >> iter 87000, loss: 12.905637
 >> iter 88000, loss: 12.931137
 >> iter 89000, loss: 12.907658
 >> iter 90000, loss: 12.935247
   Number of active neurons: 2
 >> iter 91000, loss: 12.907567
 >> iter 92000, loss: 12.934546
 >> iter 93000, loss: 12.906360
 >> iter 94000, loss: 12.934239
 >> iter 95000, loss: 12.908826
 >> iter 96000, loss: 12.932451
 >> iter 97000, loss: 12.907619
 >> iter 98000, loss: 12.934894
 >> iter 99000, loss: 12.909222
 >> iter 100000, loss: 12.932332
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.701426
 >> iter 2000, loss: 15.092169
 >> iter 3000, loss: 13.732199
 >> iter 4000, loss: 13.233956
 >> iter 5000, loss: 13.038247
 >> iter 6000, loss: 12.972186
 >> iter 7000, loss: 12.937512
 >> iter 8000, loss: 12.933709
 >> iter 9000, loss: 12.921700
 >> iter 10000, loss: 12.929394
   Number of active neurons: 2
 >> iter 11000, loss: 12.918166
 >> iter 12000, loss: 12.925594
 >> iter 13000, loss: 12.914320
 >> iter 14000, loss: 12.923956
 >> iter 15000, loss: 12.915162
 >> iter 16000, loss: 12.923090
 >> iter 17000, loss: 12.915681
 >> iter 18000, loss: 12.921371
 >> iter 19000, loss: 12.912155
 >> iter 20000, loss: 12.923147
   Number of active neurons: 2
 >> iter 21000, loss: 12.910097
 >> iter 22000, loss: 12.921988
 >> iter 23000, loss: 12.909967
 >> iter 24000, loss: 12.921621
 >> iter 25000, loss: 12.909069
 >> iter 26000, loss: 12.918759
 >> iter 27000, loss: 12.908302
 >> iter 28000, loss: 12.918189
 >> iter 29000, loss: 12.907981
 >> iter 30000, loss: 12.919536
   Number of active neurons: 2
 >> iter 31000, loss: 12.908372
 >> iter 32000, loss: 12.919198
 >> iter 33000, loss: 12.911407
 >> iter 34000, loss: 12.918910
 >> iter 35000, loss: 12.910339
 >> iter 36000, loss: 12.916009
 >> iter 37000, loss: 12.908721
 >> iter 38000, loss: 12.916850
 >> iter 39000, loss: 12.906763
 >> iter 40000, loss: 12.917042
   Number of active neurons: 2
 >> iter 41000, loss: 12.905340
 >> iter 42000, loss: 12.916923
 >> iter 43000, loss: 12.903892
 >> iter 44000, loss: 12.919792
 >> iter 45000, loss: 12.903529
 >> iter 46000, loss: 12.924225
 >> iter 47000, loss: 12.903346
 >> iter 48000, loss: 12.924121
 >> iter 49000, loss: 12.904381
 >> iter 50000, loss: 12.926064
   Number of active neurons: 2
 >> iter 51000, loss: 12.904664
 >> iter 52000, loss: 12.923805
 >> iter 53000, loss: 12.900348
 >> iter 54000, loss: 12.923133
 >> iter 55000, loss: 12.896754
 >> iter 56000, loss: 12.922524
 >> iter 57000, loss: 12.899658
 >> iter 58000, loss: 12.922583
 >> iter 59000, loss: 12.901096
 >> iter 60000, loss: 12.922523
   Number of active neurons: 2
 >> iter 61000, loss: 12.901801
 >> iter 62000, loss: 12.925422
 >> iter 63000, loss: 12.902819
 >> iter 64000, loss: 12.925510
 >> iter 65000, loss: 12.903023
 >> iter 66000, loss: 12.926583
 >> iter 67000, loss: 12.903131
 >> iter 68000, loss: 12.924719
 >> iter 69000, loss: 12.903263
 >> iter 70000, loss: 12.926699
   Number of active neurons: 2
 >> iter 71000, loss: 12.902593
 >> iter 72000, loss: 12.926326
 >> iter 73000, loss: 12.903344
 >> iter 74000, loss: 12.926782
 >> iter 75000, loss: 12.902294
 >> iter 76000, loss: 12.925319
 >> iter 77000, loss: 12.904993
 >> iter 78000, loss: 12.925265
 >> iter 79000, loss: 12.900574
 >> iter 80000, loss: 12.923068
   Number of active neurons: 2
 >> iter 81000, loss: 12.899513
 >> iter 82000, loss: 12.926835
 >> iter 83000, loss: 12.902599
 >> iter 84000, loss: 12.929046
 >> iter 85000, loss: 12.904159
 >> iter 86000, loss: 12.930035
 >> iter 87000, loss: 12.905673
 >> iter 88000, loss: 12.931189
 >> iter 89000, loss: 12.907693
 >> iter 90000, loss: 12.935297
   Number of active neurons: 2
 >> iter 91000, loss: 12.907600
 >> iter 92000, loss: 12.934595
 >> iter 93000, loss: 12.906394
 >> iter 94000, loss: 12.934289
 >> iter 95000, loss: 12.908860
 >> iter 96000, loss: 12.932498
 >> iter 97000, loss: 12.907653
 >> iter 98000, loss: 12.934939
 >> iter 99000, loss: 12.909254
 >> iter 100000, loss: 12.932374
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.737745
 >> iter 2000, loss: 15.091189
 >> iter 3000, loss: 13.726791
 >> iter 4000, loss: 13.229431
 >> iter 5000, loss: 13.034353
 >> iter 6000, loss: 12.969131
 >> iter 7000, loss: 12.934851
 >> iter 8000, loss: 12.931453
 >> iter 9000, loss: 12.919627
 >> iter 10000, loss: 12.927440
   Number of active neurons: 2
 >> iter 11000, loss: 12.916477
 >> iter 12000, loss: 12.923850
 >> iter 13000, loss: 12.912927
 >> iter 14000, loss: 12.922429
 >> iter 15000, loss: 12.913988
 >> iter 16000, loss: 12.921734
 >> iter 17000, loss: 12.914683
 >> iter 18000, loss: 12.920175
 >> iter 19000, loss: 12.911329
 >> iter 20000, loss: 12.922095
   Number of active neurons: 2
 >> iter 21000, loss: 12.909394
 >> iter 22000, loss: 12.921087
 >> iter 23000, loss: 12.909376
 >> iter 24000, loss: 12.920827
 >> iter 25000, loss: 12.908557
 >> iter 26000, loss: 12.918029
 >> iter 27000, loss: 12.907858
 >> iter 28000, loss: 12.917564
 >> iter 29000, loss: 12.907606
 >> iter 30000, loss: 12.918978
   Number of active neurons: 2
 >> iter 31000, loss: 12.908039
 >> iter 32000, loss: 12.918676
 >> iter 33000, loss: 12.911114
 >> iter 34000, loss: 12.918426
 >> iter 35000, loss: 12.910076
 >> iter 36000, loss: 12.915552
 >> iter 37000, loss: 12.908481
 >> iter 38000, loss: 12.916428
 >> iter 39000, loss: 12.906543
 >> iter 40000, loss: 12.916655
   Number of active neurons: 2
 >> iter 41000, loss: 12.905141
 >> iter 42000, loss: 12.916577
 >> iter 43000, loss: 12.903708
 >> iter 44000, loss: 12.919475
 >> iter 45000, loss: 12.903361
 >> iter 46000, loss: 12.923976
 >> iter 47000, loss: 12.903191
 >> iter 48000, loss: 12.923887
 >> iter 49000, loss: 12.904232
 >> iter 50000, loss: 12.925848
   Number of active neurons: 2
 >> iter 51000, loss: 12.904529
 >> iter 52000, loss: 12.923604
 >> iter 53000, loss: 12.900225
 >> iter 54000, loss: 12.922935
 >> iter 55000, loss: 12.896637
 >> iter 56000, loss: 12.922335
 >> iter 57000, loss: 12.899546
 >> iter 58000, loss: 12.922408
 >> iter 59000, loss: 12.900986
 >> iter 60000, loss: 12.922347
   Number of active neurons: 2
 >> iter 61000, loss: 12.901697
 >> iter 62000, loss: 12.925272
 >> iter 63000, loss: 12.902720
 >> iter 64000, loss: 12.925359
 >> iter 65000, loss: 12.902927
 >> iter 66000, loss: 12.926437
 >> iter 67000, loss: 12.903040
 >> iter 68000, loss: 12.924579
 >> iter 69000, loss: 12.903174
 >> iter 70000, loss: 12.926567
   Number of active neurons: 2
 >> iter 71000, loss: 12.902508
 >> iter 72000, loss: 12.926200
 >> iter 73000, loss: 12.903264
 >> iter 74000, loss: 12.926660
 >> iter 75000, loss: 12.902219
 >> iter 76000, loss: 12.925202
 >> iter 77000, loss: 12.904921
 >> iter 78000, loss: 12.925147
 >> iter 79000, loss: 12.900507
 >> iter 80000, loss: 12.922953
   Number of active neurons: 2
 >> iter 81000, loss: 12.899451
 >> iter 82000, loss: 12.926744
 >> iter 83000, loss: 12.902538
 >> iter 84000, loss: 12.928958
 >> iter 85000, loss: 12.904102
 >> iter 86000, loss: 12.929954
 >> iter 87000, loss: 12.905617
 >> iter 88000, loss: 12.931110
 >> iter 89000, loss: 12.907639
 >> iter 90000, loss: 12.935220
   Number of active neurons: 2
 >> iter 91000, loss: 12.907548
 >> iter 92000, loss: 12.934521
 >> iter 93000, loss: 12.906341
 >> iter 94000, loss: 12.934214
 >> iter 95000, loss: 12.908807
 >> iter 96000, loss: 12.932427
 >> iter 97000, loss: 12.907601
 >> iter 98000, loss: 12.934870
 >> iter 99000, loss: 12.909204
 >> iter 100000, loss: 12.932309
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.766867
 >> iter 2000, loss: 15.133785
 >> iter 3000, loss: 13.752297
 >> iter 4000, loss: 13.243504
 >> iter 5000, loss: 13.043339
 >> iter 6000, loss: 12.975093
 >> iter 7000, loss: 12.939513
 >> iter 8000, loss: 12.935144
 >> iter 9000, loss: 12.922917
 >> iter 10000, loss: 12.930427
   Number of active neurons: 2
 >> iter 11000, loss: 12.919075
 >> iter 12000, loss: 12.926469
 >> iter 13000, loss: 12.915055
 >> iter 14000, loss: 12.924727
 >> iter 15000, loss: 12.915780
 >> iter 16000, loss: 12.923771
 >> iter 17000, loss: 12.916199
 >> iter 18000, loss: 12.921974
 >> iter 19000, loss: 12.912579
 >> iter 20000, loss: 12.923682
   Number of active neurons: 2
 >> iter 21000, loss: 12.910455
 >> iter 22000, loss: 12.922451
 >> iter 23000, loss: 12.910262
 >> iter 24000, loss: 12.922026
 >> iter 25000, loss: 12.909313
 >> iter 26000, loss: 12.919126
 >> iter 27000, loss: 12.908504
 >> iter 28000, loss: 12.918501
 >> iter 29000, loss: 12.908143
 >> iter 30000, loss: 12.919815
   Number of active neurons: 2
 >> iter 31000, loss: 12.908510
 >> iter 32000, loss: 12.919460
 >> iter 33000, loss: 12.911524
 >> iter 34000, loss: 12.919153
 >> iter 35000, loss: 12.910440
 >> iter 36000, loss: 12.916235
 >> iter 37000, loss: 12.908811
 >> iter 38000, loss: 12.917057
 >> iter 39000, loss: 12.906842
 >> iter 40000, loss: 12.917234
   Number of active neurons: 2
 >> iter 41000, loss: 12.905410
 >> iter 42000, loss: 12.917093
 >> iter 43000, loss: 12.903955
 >> iter 44000, loss: 12.919944
 >> iter 45000, loss: 12.903584
 >> iter 46000, loss: 12.924327
 >> iter 47000, loss: 12.903394
 >> iter 48000, loss: 12.924214
 >> iter 49000, loss: 12.904428
 >> iter 50000, loss: 12.926150
   Number of active neurons: 2
 >> iter 51000, loss: 12.904705
 >> iter 52000, loss: 12.923884
 >> iter 53000, loss: 12.900382
 >> iter 54000, loss: 12.923212
 >> iter 55000, loss: 12.896787
 >> iter 56000, loss: 12.922601
 >> iter 57000, loss: 12.899690
 >> iter 58000, loss: 12.922652
 >> iter 59000, loss: 12.901128
 >> iter 60000, loss: 12.922594
   Number of active neurons: 2
 >> iter 61000, loss: 12.901831
 >> iter 62000, loss: 12.925476
 >> iter 63000, loss: 12.902847
 >> iter 64000, loss: 12.925565
 >> iter 65000, loss: 12.903050
 >> iter 66000, loss: 12.926641
 >> iter 67000, loss: 12.903156
 >> iter 68000, loss: 12.924773
 >> iter 69000, loss: 12.903288
 >> iter 70000, loss: 12.926749
   Number of active neurons: 2
 >> iter 71000, loss: 12.902617
 >> iter 72000, loss: 12.926372
 >> iter 73000, loss: 12.903367
 >> iter 74000, loss: 12.926826
 >> iter 75000, loss: 12.902314
 >> iter 76000, loss: 12.925361
 >> iter 77000, loss: 12.905011
 >> iter 78000, loss: 12.925308
 >> iter 79000, loss: 12.900590
 >> iter 80000, loss: 12.923108
   Number of active neurons: 2
 >> iter 81000, loss: 12.899527
 >> iter 82000, loss: 12.926863
 >> iter 83000, loss: 12.902613
 >> iter 84000, loss: 12.929072
 >> iter 85000, loss: 12.904172
 >> iter 86000, loss: 12.930060
 >> iter 87000, loss: 12.905685
 >> iter 88000, loss: 12.931212
 >> iter 89000, loss: 12.907704
 >> iter 90000, loss: 12.935320
   Number of active neurons: 2
 >> iter 91000, loss: 12.907611
 >> iter 92000, loss: 12.934618
 >> iter 93000, loss: 12.906406
 >> iter 94000, loss: 12.934313
 >> iter 95000, loss: 12.908873
 >> iter 96000, loss: 12.932521
 >> iter 97000, loss: 12.907665
 >> iter 98000, loss: 12.934961
 >> iter 99000, loss: 12.909266
 >> iter 100000, loss: 12.932393
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.658117
 >> iter 2000, loss: 15.060392
 >> iter 3000, loss: 13.714896
 >> iter 4000, loss: 13.224708
 >> iter 5000, loss: 13.032348
 >> iter 6000, loss: 12.968142
 >> iter 7000, loss: 12.934297
 >> iter 8000, loss: 12.931043
 >> iter 9000, loss: 12.919325
 >> iter 10000, loss: 12.927143
   Number of active neurons: 2
 >> iter 11000, loss: 12.916253
 >> iter 12000, loss: 12.923602
 >> iter 13000, loss: 12.912746
 >> iter 14000, loss: 12.922219
 >> iter 15000, loss: 12.913837
 >> iter 16000, loss: 12.921549
 >> iter 17000, loss: 12.914556
 >> iter 18000, loss: 12.920014
 >> iter 19000, loss: 12.911222
 >> iter 20000, loss: 12.921953
   Number of active neurons: 2
 >> iter 21000, loss: 12.909301
 >> iter 22000, loss: 12.920964
 >> iter 23000, loss: 12.909296
 >> iter 24000, loss: 12.920717
 >> iter 25000, loss: 12.908486
 >> iter 26000, loss: 12.917928
 >> iter 27000, loss: 12.907796
 >> iter 28000, loss: 12.917476
 >> iter 29000, loss: 12.907552
 >> iter 30000, loss: 12.918899
   Number of active neurons: 2
 >> iter 31000, loss: 12.907990
 >> iter 32000, loss: 12.918602
 >> iter 33000, loss: 12.911070
 >> iter 34000, loss: 12.918356
 >> iter 35000, loss: 12.910036
 >> iter 36000, loss: 12.915486
 >> iter 37000, loss: 12.908444
 >> iter 38000, loss: 12.916367
 >> iter 39000, loss: 12.906509
 >> iter 40000, loss: 12.916598
   Number of active neurons: 2
 >> iter 41000, loss: 12.905110
 >> iter 42000, loss: 12.916525
 >> iter 43000, loss: 12.903679
 >> iter 44000, loss: 12.919428
 >> iter 45000, loss: 12.903335
 >> iter 46000, loss: 12.923939
 >> iter 47000, loss: 12.903166
 >> iter 48000, loss: 12.923851
 >> iter 49000, loss: 12.904208
 >> iter 50000, loss: 12.925815
   Number of active neurons: 2
 >> iter 51000, loss: 12.904507
 >> iter 52000, loss: 12.923573
 >> iter 53000, loss: 12.900205
 >> iter 54000, loss: 12.922904
 >> iter 55000, loss: 12.896618
 >> iter 56000, loss: 12.922306
 >> iter 57000, loss: 12.899528
 >> iter 58000, loss: 12.922381
 >> iter 59000, loss: 12.900968
 >> iter 60000, loss: 12.922319
   Number of active neurons: 2
 >> iter 61000, loss: 12.901680
 >> iter 62000, loss: 12.925249
 >> iter 63000, loss: 12.902704
 >> iter 64000, loss: 12.925335
 >> iter 65000, loss: 12.902912
 >> iter 66000, loss: 12.926414
 >> iter 67000, loss: 12.903025
 >> iter 68000, loss: 12.924557
 >> iter 69000, loss: 12.903160
 >> iter 70000, loss: 12.926546
   Number of active neurons: 2
 >> iter 71000, loss: 12.902495
 >> iter 72000, loss: 12.926180
 >> iter 73000, loss: 12.903251
 >> iter 74000, loss: 12.926640
 >> iter 75000, loss: 12.902207
 >> iter 76000, loss: 12.925184
 >> iter 77000, loss: 12.904910
 >> iter 78000, loss: 12.925128
 >> iter 79000, loss: 12.900497
 >> iter 80000, loss: 12.922935
   Number of active neurons: 2
 >> iter 81000, loss: 12.899441
 >> iter 82000, loss: 12.926729
 >> iter 83000, loss: 12.902528
 >> iter 84000, loss: 12.928944
 >> iter 85000, loss: 12.904093
 >> iter 86000, loss: 12.929941
 >> iter 87000, loss: 12.905608
 >> iter 88000, loss: 12.931097
 >> iter 89000, loss: 12.907631
 >> iter 90000, loss: 12.935208
   Number of active neurons: 2
 >> iter 91000, loss: 12.907540
 >> iter 92000, loss: 12.934508
 >> iter 93000, loss: 12.906333
 >> iter 94000, loss: 12.934201
 >> iter 95000, loss: 12.908798
 >> iter 96000, loss: 12.932415
 >> iter 97000, loss: 12.907593
 >> iter 98000, loss: 12.934859
 >> iter 99000, loss: 12.909196
 >> iter 100000, loss: 12.932299
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.693416
 >> iter 2000, loss: 15.088145
 >> iter 3000, loss: 13.730334
 >> iter 4000, loss: 13.233108
 >> iter 5000, loss: 13.037770
 >> iter 6000, loss: 12.971920
 >> iter 7000, loss: 12.937301
 >> iter 8000, loss: 12.933566
 >> iter 9000, loss: 12.921555
 >> iter 10000, loss: 12.929278
   Number of active neurons: 2
 >> iter 11000, loss: 12.918048
 >> iter 12000, loss: 12.925488
 >> iter 13000, loss: 12.914219
 >> iter 14000, loss: 12.923858
 >> iter 15000, loss: 12.915075
 >> iter 16000, loss: 12.923002
 >> iter 17000, loss: 12.915604
 >> iter 18000, loss: 12.921292
 >> iter 19000, loss: 12.912091
 >> iter 20000, loss: 12.923077
   Number of active neurons: 2
 >> iter 21000, loss: 12.910042
 >> iter 22000, loss: 12.921927
 >> iter 23000, loss: 12.909921
 >> iter 24000, loss: 12.921568
 >> iter 25000, loss: 12.909030
 >> iter 26000, loss: 12.918711
 >> iter 27000, loss: 12.908268
 >> iter 28000, loss: 12.918148
 >> iter 29000, loss: 12.907953
 >> iter 30000, loss: 12.919501
   Number of active neurons: 2
 >> iter 31000, loss: 12.908348
 >> iter 32000, loss: 12.919166
 >> iter 33000, loss: 12.911387
 >> iter 34000, loss: 12.918881
 >> iter 35000, loss: 12.910321
 >> iter 36000, loss: 12.915983
 >> iter 37000, loss: 12.908705
 >> iter 38000, loss: 12.916825
 >> iter 39000, loss: 12.906748
 >> iter 40000, loss: 12.917021
   Number of active neurons: 2
 >> iter 41000, loss: 12.905327
 >> iter 42000, loss: 12.916904
 >> iter 43000, loss: 12.903881
 >> iter 44000, loss: 12.919775
 >> iter 45000, loss: 12.903519
 >> iter 46000, loss: 12.924209
 >> iter 47000, loss: 12.903337
 >> iter 48000, loss: 12.924106
 >> iter 49000, loss: 12.904373
 >> iter 50000, loss: 12.926051
   Number of active neurons: 2
 >> iter 51000, loss: 12.904657
 >> iter 52000, loss: 12.923793
 >> iter 53000, loss: 12.900341
 >> iter 54000, loss: 12.923121
 >> iter 55000, loss: 12.896748
 >> iter 56000, loss: 12.922514
 >> iter 57000, loss: 12.899652
 >> iter 58000, loss: 12.922574
 >> iter 59000, loss: 12.901090
 >> iter 60000, loss: 12.922513
   Number of active neurons: 2
 >> iter 61000, loss: 12.901796
 >> iter 62000, loss: 12.925413
 >> iter 63000, loss: 12.902814
 >> iter 64000, loss: 12.925502
 >> iter 65000, loss: 12.903018
 >> iter 66000, loss: 12.926576
 >> iter 67000, loss: 12.903127
 >> iter 68000, loss: 12.924712
 >> iter 69000, loss: 12.903259
 >> iter 70000, loss: 12.926692
   Number of active neurons: 2
 >> iter 71000, loss: 12.902589
 >> iter 72000, loss: 12.926320
 >> iter 73000, loss: 12.903341
 >> iter 74000, loss: 12.926776
 >> iter 75000, loss: 12.902291
 >> iter 76000, loss: 12.925313
 >> iter 77000, loss: 12.904990
 >> iter 78000, loss: 12.925259
 >> iter 79000, loss: 12.900571
 >> iter 80000, loss: 12.923062
   Number of active neurons: 2
 >> iter 81000, loss: 12.899511
 >> iter 82000, loss: 12.926831
 >> iter 83000, loss: 12.902596
 >> iter 84000, loss: 12.929042
 >> iter 85000, loss: 12.904157
 >> iter 86000, loss: 12.930032
 >> iter 87000, loss: 12.905671
 >> iter 88000, loss: 12.931185
 >> iter 89000, loss: 12.907690
 >> iter 90000, loss: 12.935293
   Number of active neurons: 2
 >> iter 91000, loss: 12.907598
 >> iter 92000, loss: 12.934592
 >> iter 93000, loss: 12.906392
 >> iter 94000, loss: 12.934285
 >> iter 95000, loss: 12.908858
 >> iter 96000, loss: 12.932495
 >> iter 97000, loss: 12.907651
 >> iter 98000, loss: 12.934936
 >> iter 99000, loss: 12.909252
 >> iter 100000, loss: 12.932372
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.745360
 >> iter 2000, loss: 15.128315
 >> iter 3000, loss: 13.751191
 >> iter 4000, loss: 13.243578
 >> iter 5000, loss: 13.043728
 >> iter 6000, loss: 12.975494
 >> iter 7000, loss: 12.939881
 >> iter 8000, loss: 12.935461
 >> iter 9000, loss: 12.923198
 >> iter 10000, loss: 12.930683
   Number of active neurons: 2
 >> iter 11000, loss: 12.919296
 >> iter 12000, loss: 12.926689
 >> iter 13000, loss: 12.915235
 >> iter 14000, loss: 12.924922
 >> iter 15000, loss: 12.915932
 >> iter 16000, loss: 12.923946
 >> iter 17000, loss: 12.916327
 >> iter 18000, loss: 12.922130
 >> iter 19000, loss: 12.912685
 >> iter 20000, loss: 12.923821
   Number of active neurons: 2
 >> iter 21000, loss: 12.910543
 >> iter 22000, loss: 12.922573
 >> iter 23000, loss: 12.910335
 >> iter 24000, loss: 12.922133
 >> iter 25000, loss: 12.909374
 >> iter 26000, loss: 12.919224
 >> iter 27000, loss: 12.908554
 >> iter 28000, loss: 12.918584
 >> iter 29000, loss: 12.908183
 >> iter 30000, loss: 12.919891
   Number of active neurons: 2
 >> iter 31000, loss: 12.908543
 >> iter 32000, loss: 12.919532
 >> iter 33000, loss: 12.911552
 >> iter 34000, loss: 12.919220
 >> iter 35000, loss: 12.910465
 >> iter 36000, loss: 12.916298
 >> iter 37000, loss: 12.908833
 >> iter 38000, loss: 12.917114
 >> iter 39000, loss: 12.906861
 >> iter 40000, loss: 12.917288
   Number of active neurons: 2
 >> iter 41000, loss: 12.905427
 >> iter 42000, loss: 12.917142
 >> iter 43000, loss: 12.903970
 >> iter 44000, loss: 12.919987
 >> iter 45000, loss: 12.903597
 >> iter 46000, loss: 12.924353
 >> iter 47000, loss: 12.903405
 >> iter 48000, loss: 12.924238
 >> iter 49000, loss: 12.904440
 >> iter 50000, loss: 12.926172
   Number of active neurons: 2
 >> iter 51000, loss: 12.904715
 >> iter 52000, loss: 12.923905
 >> iter 53000, loss: 12.900391
 >> iter 54000, loss: 12.923233
 >> iter 55000, loss: 12.896794
 >> iter 56000, loss: 12.922622
 >> iter 57000, loss: 12.899697
 >> iter 58000, loss: 12.922670
 >> iter 59000, loss: 12.901136
 >> iter 60000, loss: 12.922613
   Number of active neurons: 2
 >> iter 61000, loss: 12.901838
 >> iter 62000, loss: 12.925489
 >> iter 63000, loss: 12.902854
 >> iter 64000, loss: 12.925579
 >> iter 65000, loss: 12.903057
 >> iter 66000, loss: 12.926656
 >> iter 67000, loss: 12.903163
 >> iter 68000, loss: 12.924788
 >> iter 69000, loss: 12.903295
 >> iter 70000, loss: 12.926763
   Number of active neurons: 2
 >> iter 71000, loss: 12.902623
 >> iter 72000, loss: 12.926385
 >> iter 73000, loss: 12.903373
 >> iter 74000, loss: 12.926838
 >> iter 75000, loss: 12.902319
 >> iter 76000, loss: 12.925372
 >> iter 77000, loss: 12.905016
 >> iter 78000, loss: 12.925320
 >> iter 79000, loss: 12.900594
 >> iter 80000, loss: 12.923119
   Number of active neurons: 2
 >> iter 81000, loss: 12.899531
 >> iter 82000, loss: 12.926870
 >> iter 83000, loss: 12.902616
 >> iter 84000, loss: 12.929079
 >> iter 85000, loss: 12.904175
 >> iter 86000, loss: 12.930067
 >> iter 87000, loss: 12.905689
 >> iter 88000, loss: 12.931218
 >> iter 89000, loss: 12.907707
 >> iter 90000, loss: 12.935325
   Number of active neurons: 2
 >> iter 91000, loss: 12.907614
 >> iter 92000, loss: 12.934624
 >> iter 93000, loss: 12.906410
 >> iter 94000, loss: 12.934319
 >> iter 95000, loss: 12.908877
 >> iter 96000, loss: 12.932528
 >> iter 97000, loss: 12.907668
 >> iter 98000, loss: 12.934966
 >> iter 99000, loss: 12.909269
 >> iter 100000, loss: 12.932398
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.807712
 >> iter 2000, loss: 15.122595
 >> iter 3000, loss: 13.740517
 >> iter 4000, loss: 13.235615
 >> iter 5000, loss: 13.037674
 >> iter 6000, loss: 12.971161
 >> iter 7000, loss: 12.936360
 >> iter 8000, loss: 12.932674
 >> iter 9000, loss: 12.920705
 >> iter 10000, loss: 12.928471
   Number of active neurons: 2
 >> iter 11000, loss: 12.917345
 >> iter 12000, loss: 12.924761
 >> iter 13000, loss: 12.913641
 >> iter 14000, loss: 12.923219
 >> iter 15000, loss: 12.914593
 >> iter 16000, loss: 12.922436
 >> iter 17000, loss: 12.915200
 >> iter 18000, loss: 12.920793
 >> iter 19000, loss: 12.911759
 >> iter 20000, loss: 12.922637
   Number of active neurons: 2
 >> iter 21000, loss: 12.909764
 >> iter 22000, loss: 12.921553
 >> iter 23000, loss: 12.909693
 >> iter 24000, loss: 12.921241
 >> iter 25000, loss: 12.908835
 >> iter 26000, loss: 12.918411
 >> iter 27000, loss: 12.908103
 >> iter 28000, loss: 12.917892
 >> iter 29000, loss: 12.907817
 >> iter 30000, loss: 12.919271
   Number of active neurons: 2
 >> iter 31000, loss: 12.908228
 >> iter 32000, loss: 12.918949
 >> iter 33000, loss: 12.911283
 >> iter 34000, loss: 12.918679
 >> iter 35000, loss: 12.910228
 >> iter 36000, loss: 12.915792
 >> iter 37000, loss: 12.908620
 >> iter 38000, loss: 12.916650
 >> iter 39000, loss: 12.906671
 >> iter 40000, loss: 12.916858
   Number of active neurons: 2
 >> iter 41000, loss: 12.905258
 >> iter 42000, loss: 12.916759
 >> iter 43000, loss: 12.903818
 >> iter 44000, loss: 12.919644
 >> iter 45000, loss: 12.903462
 >> iter 46000, loss: 12.924116
 >> iter 47000, loss: 12.903285
 >> iter 48000, loss: 12.924019
 >> iter 49000, loss: 12.904322
 >> iter 50000, loss: 12.925970
   Number of active neurons: 2
 >> iter 51000, loss: 12.904611
 >> iter 52000, loss: 12.923718
 >> iter 53000, loss: 12.900300
 >> iter 54000, loss: 12.923047
 >> iter 55000, loss: 12.896709
 >> iter 56000, loss: 12.922441
 >> iter 57000, loss: 12.899615
 >> iter 58000, loss: 12.922507
 >> iter 59000, loss: 12.901052
 >> iter 60000, loss: 12.922445
   Number of active neurons: 2
 >> iter 61000, loss: 12.901760
 >> iter 62000, loss: 12.925359
 >> iter 63000, loss: 12.902780
 >> iter 64000, loss: 12.925446
 >> iter 65000, loss: 12.902985
 >> iter 66000, loss: 12.926519
 >> iter 67000, loss: 12.903095
 >> iter 68000, loss: 12.924658
 >> iter 69000, loss: 12.903228
 >> iter 70000, loss: 12.926642
   Number of active neurons: 2
 >> iter 71000, loss: 12.902559
 >> iter 72000, loss: 12.926272
 >> iter 73000, loss: 12.903312
 >> iter 74000, loss: 12.926730
 >> iter 75000, loss: 12.902265
 >> iter 76000, loss: 12.925269
 >> iter 77000, loss: 12.904965
 >> iter 78000, loss: 12.925214
 >> iter 79000, loss: 12.900548
 >> iter 80000, loss: 12.923019
   Number of active neurons: 2
 >> iter 81000, loss: 12.899490
 >> iter 82000, loss: 12.926798
 >> iter 83000, loss: 12.902576
 >> iter 84000, loss: 12.929011
 >> iter 85000, loss: 12.904138
 >> iter 86000, loss: 12.930002
 >> iter 87000, loss: 12.905652
 >> iter 88000, loss: 12.931157
 >> iter 89000, loss: 12.907673
 >> iter 90000, loss: 12.935266
   Number of active neurons: 2
 >> iter 91000, loss: 12.907581
 >> iter 92000, loss: 12.934565
 >> iter 93000, loss: 12.906374
 >> iter 94000, loss: 12.934258
 >> iter 95000, loss: 12.908840
 >> iter 96000, loss: 12.932469
 >> iter 97000, loss: 12.907633
 >> iter 98000, loss: 12.934911
 >> iter 99000, loss: 12.909235
 >> iter 100000, loss: 12.932349
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.723919
 >> iter 2000, loss: 15.094387
 >> iter 3000, loss: 13.728443
 >> iter 4000, loss: 13.229626
 >> iter 5000, loss: 13.033944
 >> iter 6000, loss: 12.968239
 >> iter 7000, loss: 12.934016
 >> iter 8000, loss: 12.930426
 >> iter 9000, loss: 12.918798
 >> iter 10000, loss: 12.926453
   Number of active neurons: 2
 >> iter 11000, loss: 12.915751
 >> iter 12000, loss: 12.922960
 >> iter 13000, loss: 12.912308
 >> iter 14000, loss: 12.921653
 >> iter 15000, loss: 12.913456
 >> iter 16000, loss: 12.921038
 >> iter 17000, loss: 12.914225
 >> iter 18000, loss: 12.919561
 >> iter 19000, loss: 12.910936
 >> iter 20000, loss: 12.921549
   Number of active neurons: 2
 >> iter 21000, loss: 12.909048
 >> iter 22000, loss: 12.920609
 >> iter 23000, loss: 12.909074
 >> iter 24000, loss: 12.920400
 >> iter 25000, loss: 12.908287
 >> iter 26000, loss: 12.917633
 >> iter 27000, loss: 12.907618
 >> iter 28000, loss: 12.917219
 >> iter 29000, loss: 12.907396
 >> iter 30000, loss: 12.918662
   Number of active neurons: 2
 >> iter 31000, loss: 12.907848
 >> iter 32000, loss: 12.918377
 >> iter 33000, loss: 12.910942
 >> iter 34000, loss: 12.918145
 >> iter 35000, loss: 12.909918
 >> iter 36000, loss: 12.915285
 >> iter 37000, loss: 12.908334
 >> iter 38000, loss: 12.916180
 >> iter 39000, loss: 12.906407
 >> iter 40000, loss: 12.916422
   Number of active neurons: 2
 >> iter 41000, loss: 12.905017
 >> iter 42000, loss: 12.916364
 >> iter 43000, loss: 12.903591
 >> iter 44000, loss: 12.919280
 >> iter 45000, loss: 12.903254
 >> iter 46000, loss: 12.923825
 >> iter 47000, loss: 12.903090
 >> iter 48000, loss: 12.923744
 >> iter 49000, loss: 12.904135
 >> iter 50000, loss: 12.925714
   Number of active neurons: 2
 >> iter 51000, loss: 12.904441
 >> iter 52000, loss: 12.923477
 >> iter 53000, loss: 12.900144
 >> iter 54000, loss: 12.922809
 >> iter 55000, loss: 12.896561
 >> iter 56000, loss: 12.922213
 >> iter 57000, loss: 12.899473
 >> iter 58000, loss: 12.922295
 >> iter 59000, loss: 12.900914
 >> iter 60000, loss: 12.922233
   Number of active neurons: 2
 >> iter 61000, loss: 12.901629
 >> iter 62000, loss: 12.925176
 >> iter 63000, loss: 12.902656
 >> iter 64000, loss: 12.925262
 >> iter 65000, loss: 12.902865
 >> iter 66000, loss: 12.926340
 >> iter 67000, loss: 12.902980
 >> iter 68000, loss: 12.924486
 >> iter 69000, loss: 12.903117
 >> iter 70000, loss: 12.926479
   Number of active neurons: 2
 >> iter 71000, loss: 12.902453
 >> iter 72000, loss: 12.926116
 >> iter 73000, loss: 12.903212
 >> iter 74000, loss: 12.926579
 >> iter 75000, loss: 12.902170
 >> iter 76000, loss: 12.925124
 >> iter 77000, loss: 12.904875
 >> iter 78000, loss: 12.925069
 >> iter 79000, loss: 12.900464
 >> iter 80000, loss: 12.922879
   Number of active neurons: 2
 >> iter 81000, loss: 12.899411
 >> iter 82000, loss: 12.926682
 >> iter 83000, loss: 12.902498
 >> iter 84000, loss: 12.928899
 >> iter 85000, loss: 12.904065
 >> iter 86000, loss: 12.929898
 >> iter 87000, loss: 12.905581
 >> iter 88000, loss: 12.931056
 >> iter 89000, loss: 12.907605
 >> iter 90000, loss: 12.935168
   Number of active neurons: 2
 >> iter 91000, loss: 12.907515
 >> iter 92000, loss: 12.934469
 >> iter 93000, loss: 12.906307
 >> iter 94000, loss: 12.934162
 >> iter 95000, loss: 12.908773
 >> iter 96000, loss: 12.932377
 >> iter 97000, loss: 12.907569
 >> iter 98000, loss: 12.934823
 >> iter 99000, loss: 12.909172
 >> iter 100000, loss: 12.932265
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.696323
 >> iter 2000, loss: 15.076603
 >> iter 3000, loss: 13.721882
 >> iter 4000, loss: 13.227925
 >> iter 5000, loss: 13.034079
 >> iter 6000, loss: 12.969292
 >> iter 7000, loss: 12.935131
 >> iter 8000, loss: 12.931787
 >> iter 9000, loss: 12.919935
 >> iter 10000, loss: 12.927773
   Number of active neurons: 2
 >> iter 11000, loss: 12.916742
 >> iter 12000, loss: 12.924149
 >> iter 13000, loss: 12.913147
 >> iter 14000, loss: 12.922689
 >> iter 15000, loss: 12.914175
 >> iter 16000, loss: 12.921966
 >> iter 17000, loss: 12.914842
 >> iter 18000, loss: 12.920378
 >> iter 19000, loss: 12.911461
 >> iter 20000, loss: 12.922273
   Number of active neurons: 2
 >> iter 21000, loss: 12.909508
 >> iter 22000, loss: 12.921241
 >> iter 23000, loss: 12.909474
 >> iter 24000, loss: 12.920964
 >> iter 25000, loss: 12.908644
 >> iter 26000, loss: 12.918157
 >> iter 27000, loss: 12.907935
 >> iter 28000, loss: 12.917674
 >> iter 29000, loss: 12.907672
 >> iter 30000, loss: 12.919078
   Number of active neurons: 2
 >> iter 31000, loss: 12.908099
 >> iter 32000, loss: 12.918770
 >> iter 33000, loss: 12.911168
 >> iter 34000, loss: 12.918513
 >> iter 35000, loss: 12.910125
 >> iter 36000, loss: 12.915636
 >> iter 37000, loss: 12.908526
 >> iter 38000, loss: 12.916506
 >> iter 39000, loss: 12.906584
 >> iter 40000, loss: 12.916726
   Number of active neurons: 2
 >> iter 41000, loss: 12.905179
 >> iter 42000, loss: 12.916641
 >> iter 43000, loss: 12.903744
 >> iter 44000, loss: 12.919535
 >> iter 45000, loss: 12.903394
 >> iter 46000, loss: 12.924023
 >> iter 47000, loss: 12.903222
 >> iter 48000, loss: 12.923931
 >> iter 49000, loss: 12.904261
 >> iter 50000, loss: 12.925889
   Number of active neurons: 2
 >> iter 51000, loss: 12.904556
 >> iter 52000, loss: 12.923642
 >> iter 53000, loss: 12.900249
 >> iter 54000, loss: 12.922973
 >> iter 55000, loss: 12.896661
 >> iter 56000, loss: 12.922372
 >> iter 57000, loss: 12.899569
 >> iter 58000, loss: 12.922442
 >> iter 59000, loss: 12.901008
 >> iter 60000, loss: 12.922381
   Number of active neurons: 2
 >> iter 61000, loss: 12.901718
 >> iter 62000, loss: 12.925301
 >> iter 63000, loss: 12.902740
 >> iter 64000, loss: 12.925388
 >> iter 65000, loss: 12.902947
 >> iter 66000, loss: 12.926466
 >> iter 67000, loss: 12.903058
 >> iter 68000, loss: 12.924607
 >> iter 69000, loss: 12.903193
 >> iter 70000, loss: 12.926593
   Number of active neurons: 2
 >> iter 71000, loss: 12.902526
 >> iter 72000, loss: 12.926225
 >> iter 73000, loss: 12.903281
 >> iter 74000, loss: 12.926684
 >> iter 75000, loss: 12.902235
 >> iter 76000, loss: 12.925226
 >> iter 77000, loss: 12.904936
 >> iter 78000, loss: 12.925170
 >> iter 79000, loss: 12.900521
 >> iter 80000, loss: 12.922976
   Number of active neurons: 2
 >> iter 81000, loss: 12.899464
 >> iter 82000, loss: 12.926762
 >> iter 83000, loss: 12.902551
 >> iter 84000, loss: 12.928976
 >> iter 85000, loss: 12.904114
 >> iter 86000, loss: 12.929971
 >> iter 87000, loss: 12.905629
 >> iter 88000, loss: 12.931126
 >> iter 89000, loss: 12.907651
 >> iter 90000, loss: 12.935236
   Number of active neurons: 2
 >> iter 91000, loss: 12.907559
 >> iter 92000, loss: 12.934536
 >> iter 93000, loss: 12.906352
 >> iter 94000, loss: 12.934229
 >> iter 95000, loss: 12.908818
 >> iter 96000, loss: 12.932441
 >> iter 97000, loss: 12.907612
 >> iter 98000, loss: 12.934885
 >> iter 99000, loss: 12.909215
 >> iter 100000, loss: 12.932323
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 27.7434451311
   - Test - Long: 32.7683615819
   - Test - Big: 28.0217197828
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

