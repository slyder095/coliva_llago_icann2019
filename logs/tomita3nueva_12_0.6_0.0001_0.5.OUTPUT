 > Problema: tomita3nueva
 > Args:
   - Hidden size: 12
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.131832
 >> iter 2000, loss: 12.706991
 >> iter 3000, loss: 6.369172
 >> iter 4000, loss: 3.230702
 >> iter 5000, loss: 2.138328
 >> iter 6000, loss: 1.168358
 >> iter 7000, loss: 0.815537
 >> iter 8000, loss: 0.698259
 >> iter 9000, loss: 0.475016
 >> iter 10000, loss: 0.642044
   Number of active neurons: 7
 >> iter 11000, loss: 0.686591
 >> iter 12000, loss: 0.486120
 >> iter 13000, loss: 0.357930
 >> iter 14000, loss: 0.520041
 >> iter 15000, loss: 0.618452
 >> iter 16000, loss: 0.458741
 >> iter 17000, loss: 0.399738
 >> iter 18000, loss: 0.437588
 >> iter 19000, loss: 0.369528
 >> iter 20000, loss: 0.288981
   Number of active neurons: 6
 >> iter 21000, loss: 0.360705
 >> iter 22000, loss: 0.345744
 >> iter 23000, loss: 0.307612
 >> iter 24000, loss: 0.286304
 >> iter 25000, loss: 0.305390
 >> iter 26000, loss: 0.394309
 >> iter 27000, loss: 0.469639
 >> iter 28000, loss: 0.327361
 >> iter 29000, loss: 0.406672
 >> iter 30000, loss: 0.288433
   Number of active neurons: 6
 >> iter 31000, loss: 0.277957
 >> iter 32000, loss: 0.307341
 >> iter 33000, loss: 0.192208
 >> iter 34000, loss: 0.238392
 >> iter 35000, loss: 0.326584
 >> iter 36000, loss: 0.402340
 >> iter 37000, loss: 0.287824
 >> iter 38000, loss: 0.244843
 >> iter 39000, loss: 0.356967
 >> iter 40000, loss: 0.392698
   Number of active neurons: 6
 >> iter 41000, loss: 0.537235
 >> iter 42000, loss: 0.292678
 >> iter 43000, loss: 0.260314
 >> iter 44000, loss: 0.267538
 >> iter 45000, loss: 0.302365
 >> iter 46000, loss: 0.268430
 >> iter 47000, loss: 0.611004
 >> iter 48000, loss: 0.377919
 >> iter 49000, loss: 0.384721
 >> iter 50000, loss: 0.284064
   Number of active neurons: 6
 >> iter 51000, loss: 0.251813
 >> iter 52000, loss: 0.362874
 >> iter 53000, loss: 0.247412
 >> iter 54000, loss: 0.227788
 >> iter 55000, loss: 0.321353
 >> iter 56000, loss: 0.334955
 >> iter 57000, loss: 0.263266
 >> iter 58000, loss: 0.348850
 >> iter 59000, loss: 0.251922
 >> iter 60000, loss: 0.216495
   Number of active neurons: 6
 >> iter 61000, loss: 0.232001
 >> iter 62000, loss: 0.209117
 >> iter 63000, loss: 0.401848
 >> iter 64000, loss: 0.225698
 >> iter 65000, loss: 0.354057
 >> iter 66000, loss: 0.374597
 >> iter 67000, loss: 0.411142
 >> iter 68000, loss: 0.315227
 >> iter 69000, loss: 0.573041
 >> iter 70000, loss: 0.426060
   Number of active neurons: 6
 >> iter 71000, loss: 0.341807
 >> iter 72000, loss: 0.301317
 >> iter 73000, loss: 0.358019
 >> iter 74000, loss: 0.383125
 >> iter 75000, loss: 0.371639
 >> iter 76000, loss: 0.268525
 >> iter 77000, loss: 0.341320
 >> iter 78000, loss: 0.208133
 >> iter 79000, loss: 0.264979
 >> iter 80000, loss: 0.332197
   Number of active neurons: 6
 >> iter 81000, loss: 0.460618
 >> iter 82000, loss: 0.423225
 >> iter 83000, loss: 0.377191
 >> iter 84000, loss: 0.304864
 >> iter 85000, loss: 0.215963
 >> iter 86000, loss: 0.212958
 >> iter 87000, loss: 0.534666
 >> iter 88000, loss: 0.393946
 >> iter 89000, loss: 0.323213
 >> iter 90000, loss: 0.477102
   Number of active neurons: 6
 >> iter 91000, loss: 0.498250
 >> iter 92000, loss: 0.338356
 >> iter 93000, loss: 0.371878
 >> iter 94000, loss: 0.273458
 >> iter 95000, loss: 0.165697
 >> iter 96000, loss: 0.299461
 >> iter 97000, loss: 0.335129
 >> iter 98000, loss: 0.351918
 >> iter 99000, loss: 0.488005
 >> iter 100000, loss: 0.325702
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.975992
 >> iter 2000, loss: 14.236634
 >> iter 3000, loss: 8.913418
 >> iter 4000, loss: 5.829387
 >> iter 5000, loss: 4.045423
 >> iter 6000, loss: 2.458730
 >> iter 7000, loss: 1.436618
 >> iter 8000, loss: 1.015255
 >> iter 9000, loss: 0.743601
 >> iter 10000, loss: 0.487008
   Number of active neurons: 7
 >> iter 11000, loss: 0.456162
 >> iter 12000, loss: 0.413715
 >> iter 13000, loss: 0.376489
 >> iter 14000, loss: 0.267665
 >> iter 15000, loss: 0.205946
 >> iter 16000, loss: 0.289485
 >> iter 17000, loss: 0.332862
 >> iter 18000, loss: 0.268943
 >> iter 19000, loss: 0.312524
 >> iter 20000, loss: 0.253494
   Number of active neurons: 6
 >> iter 21000, loss: 0.361432
 >> iter 22000, loss: 0.257640
 >> iter 23000, loss: 0.214978
 >> iter 24000, loss: 0.227685
 >> iter 25000, loss: 0.247985
 >> iter 26000, loss: 0.353349
 >> iter 27000, loss: 0.268961
 >> iter 28000, loss: 0.181552
 >> iter 29000, loss: 0.335415
 >> iter 30000, loss: 0.271374
   Number of active neurons: 5
 >> iter 31000, loss: 0.363304
 >> iter 32000, loss: 0.245249
 >> iter 33000, loss: 0.238156
 >> iter 34000, loss: 0.251054
 >> iter 35000, loss: 0.283520
 >> iter 36000, loss: 0.321177
 >> iter 37000, loss: 0.193466
 >> iter 38000, loss: 0.223120
 >> iter 39000, loss: 0.377126
 >> iter 40000, loss: 0.350627
   Number of active neurons: 5
 >> iter 41000, loss: 0.294511
 >> iter 42000, loss: 0.242374
 >> iter 43000, loss: 0.189351
 >> iter 44000, loss: 0.171523
 >> iter 45000, loss: 0.328385
 >> iter 46000, loss: 0.329751
 >> iter 47000, loss: 0.303951
 >> iter 48000, loss: 0.257329
 >> iter 49000, loss: 0.305081
 >> iter 50000, loss: 0.243927
   Number of active neurons: 5
 >> iter 51000, loss: 0.281237
 >> iter 52000, loss: 0.352381
 >> iter 53000, loss: 0.233478
 >> iter 54000, loss: 0.213009
 >> iter 55000, loss: 0.221459
 >> iter 56000, loss: 0.358073
 >> iter 57000, loss: 0.215802
 >> iter 58000, loss: 0.375510
 >> iter 59000, loss: 0.241279
 >> iter 60000, loss: 0.244036
   Number of active neurons: 5
 >> iter 61000, loss: 0.250679
 >> iter 62000, loss: 0.243820
 >> iter 63000, loss: 0.282083
 >> iter 64000, loss: 0.251190
 >> iter 65000, loss: 0.357203
 >> iter 66000, loss: 0.232328
 >> iter 67000, loss: 0.238620
 >> iter 68000, loss: 0.209961
 >> iter 69000, loss: 0.243722
 >> iter 70000, loss: 0.245009
   Number of active neurons: 5
 >> iter 71000, loss: 0.223527
 >> iter 72000, loss: 0.262766
 >> iter 73000, loss: 0.294185
 >> iter 74000, loss: 0.210611
 >> iter 75000, loss: 0.354362
 >> iter 76000, loss: 0.268435
 >> iter 77000, loss: 0.266295
 >> iter 78000, loss: 0.218085
 >> iter 79000, loss: 0.225754
 >> iter 80000, loss: 0.159191
   Number of active neurons: 5
 >> iter 81000, loss: 0.394516
 >> iter 82000, loss: 0.311212
 >> iter 83000, loss: 0.215982
 >> iter 84000, loss: 0.283319
 >> iter 85000, loss: 0.179546
 >> iter 86000, loss: 0.135699
 >> iter 87000, loss: 0.442074
 >> iter 88000, loss: 0.242090
 >> iter 89000, loss: 0.277850
 >> iter 90000, loss: 0.260000
   Number of active neurons: 4
 >> iter 91000, loss: 0.233697
 >> iter 92000, loss: 0.199465
 >> iter 93000, loss: 0.211762
 >> iter 94000, loss: 0.187803
 >> iter 95000, loss: 0.146875
 >> iter 96000, loss: 0.148899
 >> iter 97000, loss: 0.343802
 >> iter 98000, loss: 0.229461
 >> iter 99000, loss: 0.230830
 >> iter 100000, loss: 0.207068
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.930575
 >> iter 2000, loss: 10.642956
 >> iter 3000, loss: 5.343287
 >> iter 4000, loss: 2.649913
 >> iter 5000, loss: 1.441777
 >> iter 6000, loss: 0.846961
 >> iter 7000, loss: 0.762911
 >> iter 8000, loss: 0.627263
 >> iter 9000, loss: 0.508780
 >> iter 10000, loss: 0.523052
   Number of active neurons: 5
 >> iter 11000, loss: 0.415620
 >> iter 12000, loss: 0.344642
 >> iter 13000, loss: 0.443050
 >> iter 14000, loss: 0.611221
 >> iter 15000, loss: 0.538239
 >> iter 16000, loss: 0.341442
 >> iter 17000, loss: 0.409688
 >> iter 18000, loss: 0.429890
 >> iter 19000, loss: 0.509816
 >> iter 20000, loss: 0.407180
   Number of active neurons: 5
 >> iter 21000, loss: 0.389763
 >> iter 22000, loss: 0.489110
 >> iter 23000, loss: 0.350156
 >> iter 24000, loss: 0.281229
 >> iter 25000, loss: 0.327491
 >> iter 26000, loss: 0.252048
 >> iter 27000, loss: 0.267672
 >> iter 28000, loss: 0.456376
 >> iter 29000, loss: 0.324569
 >> iter 30000, loss: 0.304858
   Number of active neurons: 5
 >> iter 31000, loss: 0.251694
 >> iter 32000, loss: 0.242453
 >> iter 33000, loss: 0.369782
 >> iter 34000, loss: 0.277830
 >> iter 35000, loss: 0.336053
 >> iter 36000, loss: 0.257470
 >> iter 37000, loss: 0.426368
 >> iter 38000, loss: 0.332884
 >> iter 39000, loss: 0.265681
 >> iter 40000, loss: 0.279663
   Number of active neurons: 5
 >> iter 41000, loss: 0.301605
 >> iter 42000, loss: 0.292780
 >> iter 43000, loss: 0.220930
 >> iter 44000, loss: 0.269795
 >> iter 45000, loss: 0.310213
 >> iter 46000, loss: 0.248822
 >> iter 47000, loss: 0.216553
 >> iter 48000, loss: 0.182654
 >> iter 49000, loss: 0.145021
 >> iter 50000, loss: 0.152811
   Number of active neurons: 5
 >> iter 51000, loss: 0.298676
 >> iter 52000, loss: 0.187664
 >> iter 53000, loss: 0.145834
 >> iter 54000, loss: 0.263424
 >> iter 55000, loss: 0.183150
 >> iter 56000, loss: 0.145798
 >> iter 57000, loss: 0.198269
 >> iter 58000, loss: 0.395978
 >> iter 59000, loss: 0.192787
 >> iter 60000, loss: 0.227742
   Number of active neurons: 5
 >> iter 61000, loss: 0.164718
 >> iter 62000, loss: 0.130612
 >> iter 63000, loss: 0.153696
 >> iter 64000, loss: 0.207390
 >> iter 65000, loss: 0.158020
 >> iter 66000, loss: 0.186844
 >> iter 67000, loss: 0.179530
 >> iter 68000, loss: 0.145099
 >> iter 69000, loss: 0.195497
 >> iter 70000, loss: 0.174137
   Number of active neurons: 5
 >> iter 71000, loss: 0.390526
 >> iter 72000, loss: 0.269171
 >> iter 73000, loss: 0.217001
 >> iter 74000, loss: 0.242748
 >> iter 75000, loss: 0.207233
 >> iter 76000, loss: 0.153476
 >> iter 77000, loss: 0.305144
 >> iter 78000, loss: 0.368517
 >> iter 79000, loss: 0.342138
 >> iter 80000, loss: 0.196580
   Number of active neurons: 4
 >> iter 81000, loss: 0.174192
 >> iter 82000, loss: 0.132257
 >> iter 83000, loss: 0.134934
 >> iter 84000, loss: 0.097889
 >> iter 85000, loss: 0.231086
 >> iter 86000, loss: 0.168882
 >> iter 87000, loss: 0.248147
 >> iter 88000, loss: 0.275025
 >> iter 89000, loss: 0.249223
 >> iter 90000, loss: 0.325027
   Number of active neurons: 4
 >> iter 91000, loss: 0.340478
 >> iter 92000, loss: 0.262624
 >> iter 93000, loss: 0.298584
 >> iter 94000, loss: 0.212290
 >> iter 95000, loss: 0.120471
 >> iter 96000, loss: 0.153122
 >> iter 97000, loss: 0.117302
 >> iter 98000, loss: 0.090446
 >> iter 99000, loss: 0.201464
 >> iter 100000, loss: 0.133396
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.266034
 >> iter 2000, loss: 11.904536
 >> iter 3000, loss: 5.449711
 >> iter 4000, loss: 2.457224
 >> iter 5000, loss: 1.409154
 >> iter 6000, loss: 0.788452
 >> iter 7000, loss: 0.737824
 >> iter 8000, loss: 0.448583
 >> iter 9000, loss: 0.360093
 >> iter 10000, loss: 0.236775
   Number of active neurons: 6
 >> iter 11000, loss: 0.273482
 >> iter 12000, loss: 0.193041
 >> iter 13000, loss: 0.276472
 >> iter 14000, loss: 0.495200
 >> iter 15000, loss: 0.337735
 >> iter 16000, loss: 0.381421
 >> iter 17000, loss: 0.245591
 >> iter 18000, loss: 0.307222
 >> iter 19000, loss: 0.268478
 >> iter 20000, loss: 0.183020
   Number of active neurons: 6
 >> iter 21000, loss: 0.255439
 >> iter 22000, loss: 0.219425
 >> iter 23000, loss: 0.315505
 >> iter 24000, loss: 0.270591
 >> iter 25000, loss: 0.367398
 >> iter 26000, loss: 0.238276
 >> iter 27000, loss: 0.207950
 >> iter 28000, loss: 0.303979
 >> iter 29000, loss: 0.177499
 >> iter 30000, loss: 0.164397
   Number of active neurons: 6
 >> iter 31000, loss: 0.178353
 >> iter 32000, loss: 0.230586
 >> iter 33000, loss: 0.347914
 >> iter 34000, loss: 0.276154
 >> iter 35000, loss: 0.322338
 >> iter 36000, loss: 0.300810
 >> iter 37000, loss: 0.355488
 >> iter 38000, loss: 0.230285
 >> iter 39000, loss: 0.301509
 >> iter 40000, loss: 0.335099
   Number of active neurons: 6
 >> iter 41000, loss: 0.255527
 >> iter 42000, loss: 0.219554
 >> iter 43000, loss: 0.284459
 >> iter 44000, loss: 0.316374
 >> iter 45000, loss: 0.233303
 >> iter 46000, loss: 0.181241
 >> iter 47000, loss: 0.146825
 >> iter 48000, loss: 0.225563
 >> iter 49000, loss: 0.136369
 >> iter 50000, loss: 0.141512
   Number of active neurons: 6
 >> iter 51000, loss: 0.137246
 >> iter 52000, loss: 0.219350
 >> iter 53000, loss: 0.144319
 >> iter 54000, loss: 0.205790
 >> iter 55000, loss: 0.210436
 >> iter 56000, loss: 0.260417
 >> iter 57000, loss: 0.260480
 >> iter 58000, loss: 0.303014
 >> iter 59000, loss: 0.297813
 >> iter 60000, loss: 0.390335
   Number of active neurons: 6
 >> iter 61000, loss: 0.405909
 >> iter 62000, loss: 0.712894
 >> iter 63000, loss: 0.570861
 >> iter 64000, loss: 0.351828
 >> iter 65000, loss: 0.200189
 >> iter 66000, loss: 0.183038
 >> iter 67000, loss: 0.206816
 >> iter 68000, loss: 0.147707
 >> iter 69000, loss: 0.180059
 >> iter 70000, loss: 0.271080
   Number of active neurons: 6
 >> iter 71000, loss: 0.265162
 >> iter 72000, loss: 0.175411
 >> iter 73000, loss: 0.189064
 >> iter 74000, loss: 0.172552
 >> iter 75000, loss: 0.303826
 >> iter 76000, loss: 0.377448
 >> iter 77000, loss: 0.471159
 >> iter 78000, loss: 0.284350
 >> iter 79000, loss: 0.171342
 >> iter 80000, loss: 0.163491
   Number of active neurons: 6
 >> iter 81000, loss: 0.312905
 >> iter 82000, loss: 0.279051
 >> iter 83000, loss: 0.301493
 >> iter 84000, loss: 0.185249
 >> iter 85000, loss: 0.146237
 >> iter 86000, loss: 0.184595
 >> iter 87000, loss: 0.274339
 >> iter 88000, loss: 0.302578
 >> iter 89000, loss: 0.217622
 >> iter 90000, loss: 0.360938
   Number of active neurons: 6
 >> iter 91000, loss: 0.339391
 >> iter 92000, loss: 0.255541
 >> iter 93000, loss: 0.246832
 >> iter 94000, loss: 0.223385
 >> iter 95000, loss: 0.173808
 >> iter 96000, loss: 0.167983
 >> iter 97000, loss: 0.202978
 >> iter 98000, loss: 0.211078
 >> iter 99000, loss: 0.209233
 >> iter 100000, loss: 0.254685
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.709267
 >> iter 2000, loss: 10.474386
 >> iter 3000, loss: 4.449658
 >> iter 4000, loss: 2.051871
 >> iter 5000, loss: 0.906595
 >> iter 6000, loss: 0.492196
 >> iter 7000, loss: 0.421281
 >> iter 8000, loss: 0.397644
 >> iter 9000, loss: 0.427251
 >> iter 10000, loss: 0.352624
   Number of active neurons: 8
 >> iter 11000, loss: 0.255517
 >> iter 12000, loss: 0.210253
 >> iter 13000, loss: 0.363787
 >> iter 14000, loss: 0.285991
 >> iter 15000, loss: 0.463540
 >> iter 16000, loss: 0.320173
 >> iter 17000, loss: 0.300090
 >> iter 18000, loss: 0.364676
 >> iter 19000, loss: 0.515414
 >> iter 20000, loss: 0.349617
   Number of active neurons: 8
 >> iter 21000, loss: 0.370354
 >> iter 22000, loss: 0.230156
 >> iter 23000, loss: 0.291021
 >> iter 24000, loss: 0.360799
 >> iter 25000, loss: 0.374549
 >> iter 26000, loss: 0.254060
 >> iter 27000, loss: 0.259733
 >> iter 28000, loss: 0.238178
 >> iter 29000, loss: 0.304083
 >> iter 30000, loss: 0.168620
   Number of active neurons: 7
 >> iter 31000, loss: 0.198156
 >> iter 32000, loss: 0.208520
 >> iter 33000, loss: 0.387732
 >> iter 34000, loss: 0.317235
 >> iter 35000, loss: 0.253224
 >> iter 36000, loss: 0.233096
 >> iter 37000, loss: 0.229842
 >> iter 38000, loss: 0.229882
 >> iter 39000, loss: 0.288402
 >> iter 40000, loss: 0.231754
   Number of active neurons: 6
 >> iter 41000, loss: 0.395462
 >> iter 42000, loss: 0.217938
 >> iter 43000, loss: 0.264867
 >> iter 44000, loss: 0.274403
 >> iter 45000, loss: 0.297581
 >> iter 46000, loss: 0.334786
 >> iter 47000, loss: 0.356567
 >> iter 48000, loss: 0.247675
 >> iter 49000, loss: 0.214755
 >> iter 50000, loss: 0.238889
   Number of active neurons: 6
 >> iter 51000, loss: 0.179391
 >> iter 52000, loss: 0.198688
 >> iter 53000, loss: 0.179216
 >> iter 54000, loss: 0.154244
 >> iter 55000, loss: 0.141076
 >> iter 56000, loss: 0.127157
 >> iter 57000, loss: 0.390707
 >> iter 58000, loss: 0.267895
 >> iter 59000, loss: 0.314854
 >> iter 60000, loss: 0.300741
   Number of active neurons: 5
 >> iter 61000, loss: 0.253013
 >> iter 62000, loss: 0.227008
 >> iter 63000, loss: 0.157699
 >> iter 64000, loss: 0.245864
 >> iter 65000, loss: 0.197595
 >> iter 66000, loss: 0.171328
 >> iter 67000, loss: 0.153272
 >> iter 68000, loss: 0.173425
 >> iter 69000, loss: 0.210057
 >> iter 70000, loss: 0.342309
   Number of active neurons: 5
 >> iter 71000, loss: 0.205408
 >> iter 72000, loss: 0.254074
 >> iter 73000, loss: 0.156201
 >> iter 74000, loss: 0.240313
 >> iter 75000, loss: 0.267417
 >> iter 76000, loss: 0.223460
 >> iter 77000, loss: 0.158740
 >> iter 78000, loss: 0.240356
 >> iter 79000, loss: 0.178256
 >> iter 80000, loss: 0.159048
   Number of active neurons: 4
 >> iter 81000, loss: 0.237699
 >> iter 82000, loss: 0.146248
 >> iter 83000, loss: 0.267149
 >> iter 84000, loss: 0.182263
 >> iter 85000, loss: 0.185128
 >> iter 86000, loss: 0.174499
 >> iter 87000, loss: 0.150262
 >> iter 88000, loss: 0.218925
 >> iter 89000, loss: 0.217814
 >> iter 90000, loss: 0.315144
   Number of active neurons: 4
 >> iter 91000, loss: 0.242097
 >> iter 92000, loss: 0.244901
 >> iter 93000, loss: 0.337190
 >> iter 94000, loss: 0.300912
 >> iter 95000, loss: 0.204599
 >> iter 96000, loss: 0.241836
 >> iter 97000, loss: 0.238024
 >> iter 98000, loss: 0.170299
 >> iter 99000, loss: 0.195285
 >> iter 100000, loss: 0.265763
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.124213
 >> iter 2000, loss: 10.470560
 >> iter 3000, loss: 4.866437
 >> iter 4000, loss: 2.272221
 >> iter 5000, loss: 1.040359
 >> iter 6000, loss: 0.719863
 >> iter 7000, loss: 0.474308
 >> iter 8000, loss: 0.470451
 >> iter 9000, loss: 0.472038
 >> iter 10000, loss: 0.267582
   Number of active neurons: 8
 >> iter 11000, loss: 0.300103
 >> iter 12000, loss: 0.356620
 >> iter 13000, loss: 0.315254
 >> iter 14000, loss: 0.466863
 >> iter 15000, loss: 0.448440
 >> iter 16000, loss: 0.304562
 >> iter 17000, loss: 0.342256
 >> iter 18000, loss: 0.413202
 >> iter 19000, loss: 0.394857
 >> iter 20000, loss: 0.436123
   Number of active neurons: 8
 >> iter 21000, loss: 0.324282
 >> iter 22000, loss: 0.349982
 >> iter 23000, loss: 0.463560
 >> iter 24000, loss: 0.294789
 >> iter 25000, loss: 0.345591
 >> iter 26000, loss: 0.263695
 >> iter 27000, loss: 0.379493
 >> iter 28000, loss: 0.399440
 >> iter 29000, loss: 0.488153
 >> iter 30000, loss: 0.353783
   Number of active neurons: 7
 >> iter 31000, loss: 0.303138
 >> iter 32000, loss: 0.191124
 >> iter 33000, loss: 0.295995
 >> iter 34000, loss: 0.427184
 >> iter 35000, loss: 0.489724
 >> iter 36000, loss: 0.339095
 >> iter 37000, loss: 0.531385
 >> iter 38000, loss: 0.457371
 >> iter 39000, loss: 0.414439
 >> iter 40000, loss: 0.348958
   Number of active neurons: 7
 >> iter 41000, loss: 0.302975
 >> iter 42000, loss: 0.357066
 >> iter 43000, loss: 0.497955
 >> iter 44000, loss: 0.256114
 >> iter 45000, loss: 0.199094
 >> iter 46000, loss: 0.313801
 >> iter 47000, loss: 0.221141
 >> iter 48000, loss: 0.229530
 >> iter 49000, loss: 0.310442
 >> iter 50000, loss: 0.351539
   Number of active neurons: 7
 >> iter 51000, loss: 0.317463
 >> iter 52000, loss: 0.383696
 >> iter 53000, loss: 0.398491
 >> iter 54000, loss: 0.360381
 >> iter 55000, loss: 0.345545
 >> iter 56000, loss: 0.309093
 >> iter 57000, loss: 0.327296
 >> iter 58000, loss: 0.259656
 >> iter 59000, loss: 0.315308
 >> iter 60000, loss: 0.404691
   Number of active neurons: 7
 >> iter 61000, loss: 0.403938
 >> iter 62000, loss: 0.406235
 >> iter 63000, loss: 0.436490
 >> iter 64000, loss: 0.327863
 >> iter 65000, loss: 0.220434
 >> iter 66000, loss: 0.258056
 >> iter 67000, loss: 0.166888
 >> iter 68000, loss: 0.237123
 >> iter 69000, loss: 0.399792
 >> iter 70000, loss: 0.322676
   Number of active neurons: 7
 >> iter 71000, loss: 0.215113
 >> iter 72000, loss: 0.247198
 >> iter 73000, loss: 0.450385
 >> iter 74000, loss: 0.409535
 >> iter 75000, loss: 0.371246
 >> iter 76000, loss: 0.272354
 >> iter 77000, loss: 0.300747
 >> iter 78000, loss: 0.228887
 >> iter 79000, loss: 0.383131
 >> iter 80000, loss: 0.294624
   Number of active neurons: 7
 >> iter 81000, loss: 0.277418
 >> iter 82000, loss: 0.193366
 >> iter 83000, loss: 0.143600
 >> iter 84000, loss: 0.226229
 >> iter 85000, loss: 0.336251
 >> iter 86000, loss: 0.216027
 >> iter 87000, loss: 0.246715
 >> iter 88000, loss: 0.180122
 >> iter 89000, loss: 0.131636
 >> iter 90000, loss: 0.155713
   Number of active neurons: 7
 >> iter 91000, loss: 0.155409
 >> iter 92000, loss: 0.311624
 >> iter 93000, loss: 0.236172
 >> iter 94000, loss: 0.364863
 >> iter 95000, loss: 0.348064
 >> iter 96000, loss: 0.399635
 >> iter 97000, loss: 0.416514
 >> iter 98000, loss: 0.277975
 >> iter 99000, loss: 0.229810
 >> iter 100000, loss: 0.188674
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.178916
 >> iter 2000, loss: 12.264899
 >> iter 3000, loss: 5.938478
 >> iter 4000, loss: 2.901621
 >> iter 5000, loss: 1.580716
 >> iter 6000, loss: 0.879649
 >> iter 7000, loss: 0.671256
 >> iter 8000, loss: 0.448231
 >> iter 9000, loss: 0.493874
 >> iter 10000, loss: 0.389823
   Number of active neurons: 4
 >> iter 11000, loss: 0.376232
 >> iter 12000, loss: 0.317997
 >> iter 13000, loss: 0.503607
 >> iter 14000, loss: 0.497633
 >> iter 15000, loss: 0.533801
 >> iter 16000, loss: 0.567419
 >> iter 17000, loss: 0.481560
 >> iter 18000, loss: 0.329249
 >> iter 19000, loss: 0.394078
 >> iter 20000, loss: 0.465553
   Number of active neurons: 4
 >> iter 21000, loss: 0.428555
 >> iter 22000, loss: 0.332534
 >> iter 23000, loss: 0.405095
 >> iter 24000, loss: 0.355625
 >> iter 25000, loss: 0.460196
 >> iter 26000, loss: 0.328901
 >> iter 27000, loss: 0.289307
 >> iter 28000, loss: 0.292505
 >> iter 29000, loss: 0.233966
 >> iter 30000, loss: 0.297876
   Number of active neurons: 4
 >> iter 31000, loss: 0.437532
 >> iter 32000, loss: 0.448335
 >> iter 33000, loss: 0.366067
 >> iter 34000, loss: 0.391015
 >> iter 35000, loss: 0.350835
 >> iter 36000, loss: 0.385068
 >> iter 37000, loss: 0.472032
 >> iter 38000, loss: 0.393006
 >> iter 39000, loss: 0.417126
 >> iter 40000, loss: 0.408454
   Number of active neurons: 4
 >> iter 41000, loss: 0.386784
 >> iter 42000, loss: 0.445501
 >> iter 43000, loss: 0.509028
 >> iter 44000, loss: 0.410219
 >> iter 45000, loss: 0.337964
 >> iter 46000, loss: 0.404664
 >> iter 47000, loss: 0.409680
 >> iter 48000, loss: 0.507239
 >> iter 49000, loss: 0.423246
 >> iter 50000, loss: 0.427308
   Number of active neurons: 4
 >> iter 51000, loss: 0.402552
 >> iter 52000, loss: 0.353958
 >> iter 53000, loss: 0.299672
 >> iter 54000, loss: 0.251587
 >> iter 55000, loss: 0.281990
 >> iter 56000, loss: 0.266112
 >> iter 57000, loss: 0.321481
 >> iter 58000, loss: 0.323572
 >> iter 59000, loss: 0.227560
 >> iter 60000, loss: 0.262066
   Number of active neurons: 4
 >> iter 61000, loss: 0.334547
 >> iter 62000, loss: 0.506094
 >> iter 63000, loss: 0.456191
 >> iter 64000, loss: 0.361336
 >> iter 65000, loss: 0.339796
 >> iter 66000, loss: 0.285057
 >> iter 67000, loss: 0.206095
 >> iter 68000, loss: 0.390163
 >> iter 69000, loss: 0.307119
 >> iter 70000, loss: 0.257514
   Number of active neurons: 4
 >> iter 71000, loss: 0.210170
 >> iter 72000, loss: 0.291730
 >> iter 73000, loss: 0.346156
 >> iter 74000, loss: 0.345237
 >> iter 75000, loss: 0.308336
 >> iter 76000, loss: 0.229544
 >> iter 77000, loss: 0.224621
 >> iter 78000, loss: 0.262272
 >> iter 79000, loss: 0.279017
 >> iter 80000, loss: 0.331832
   Number of active neurons: 4
 >> iter 81000, loss: 0.443547
 >> iter 82000, loss: 0.322887
 >> iter 83000, loss: 0.290076
 >> iter 84000, loss: 0.397883
 >> iter 85000, loss: 0.312154
 >> iter 86000, loss: 0.351796
 >> iter 87000, loss: 0.333522
 >> iter 88000, loss: 0.394628
 >> iter 89000, loss: 0.348642
 >> iter 90000, loss: 0.387143
   Number of active neurons: 4
 >> iter 91000, loss: 0.393293
 >> iter 92000, loss: 0.292935
 >> iter 93000, loss: 0.325043
 >> iter 94000, loss: 0.316710
 >> iter 95000, loss: 0.339176
 >> iter 96000, loss: 0.432431
 >> iter 97000, loss: 0.341560
 >> iter 98000, loss: 0.330711
 >> iter 99000, loss: 0.294656
 >> iter 100000, loss: 0.252352
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0139997200056
   - Test - Long: 0.0
   - Test - Big: 0.0189998100019
   - Test - A: 0.0
   - Test - B: 13.4524365042
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.913495
 >> iter 2000, loss: 14.316909
 >> iter 3000, loss: 11.394560
 >> iter 4000, loss: 9.389783
 >> iter 5000, loss: 8.415350
 >> iter 6000, loss: 7.590575
 >> iter 7000, loss: 6.822252
 >> iter 8000, loss: 4.370320
 >> iter 9000, loss: 2.502737
 >> iter 10000, loss: 1.489281
   Number of active neurons: 11
 >> iter 11000, loss: 0.852992
 >> iter 12000, loss: 0.850404
 >> iter 13000, loss: 0.688550
 >> iter 14000, loss: 0.481510
 >> iter 15000, loss: 0.324594
 >> iter 16000, loss: 0.243355
 >> iter 17000, loss: 0.238630
 >> iter 18000, loss: 0.318283
 >> iter 19000, loss: 0.214802
 >> iter 20000, loss: 0.268704
   Number of active neurons: 8
 >> iter 21000, loss: 0.218748
 >> iter 22000, loss: 0.311754
 >> iter 23000, loss: 0.472366
 >> iter 24000, loss: 0.357193
 >> iter 25000, loss: 0.332519
 >> iter 26000, loss: 0.281771
 >> iter 27000, loss: 0.306965
 >> iter 28000, loss: 0.494501
 >> iter 29000, loss: 0.426719
 >> iter 30000, loss: 0.326446
   Number of active neurons: 7
 >> iter 31000, loss: 0.338612
 >> iter 32000, loss: 0.357222
 >> iter 33000, loss: 0.436636
 >> iter 34000, loss: 0.363809
 >> iter 35000, loss: 0.397255
 >> iter 36000, loss: 0.315951
 >> iter 37000, loss: 0.230608
 >> iter 38000, loss: 0.488562
 >> iter 39000, loss: 0.328428
 >> iter 40000, loss: 0.200503
   Number of active neurons: 5
 >> iter 41000, loss: 0.259047
 >> iter 42000, loss: 0.258993
 >> iter 43000, loss: 0.233945
 >> iter 44000, loss: 0.312625
 >> iter 45000, loss: 0.253506
 >> iter 46000, loss: 0.197211
 >> iter 47000, loss: 0.293328
 >> iter 48000, loss: 0.238790
 >> iter 49000, loss: 0.231823
 >> iter 50000, loss: 0.231657
   Number of active neurons: 5
 >> iter 51000, loss: 0.206706
 >> iter 52000, loss: 0.245525
 >> iter 53000, loss: 0.331285
 >> iter 54000, loss: 0.296240
 >> iter 55000, loss: 0.176916
 >> iter 56000, loss: 0.239290
 >> iter 57000, loss: 0.275980
 >> iter 58000, loss: 0.226980
 >> iter 59000, loss: 0.358947
 >> iter 60000, loss: 0.271453
   Number of active neurons: 5
 >> iter 61000, loss: 0.174188
 >> iter 62000, loss: 0.181145
 >> iter 63000, loss: 0.223494
 >> iter 64000, loss: 0.279265
 >> iter 65000, loss: 0.263884
 >> iter 66000, loss: 0.221130
 >> iter 67000, loss: 0.267497
 >> iter 68000, loss: 0.216582
 >> iter 69000, loss: 0.233479
 >> iter 70000, loss: 0.256745
   Number of active neurons: 5
 >> iter 71000, loss: 0.275989
 >> iter 72000, loss: 0.189815
 >> iter 73000, loss: 0.196293
 >> iter 74000, loss: 0.193872
 >> iter 75000, loss: 0.259859
 >> iter 76000, loss: 0.248980
 >> iter 77000, loss: 0.195885
 >> iter 78000, loss: 0.142544
 >> iter 79000, loss: 0.125014
 >> iter 80000, loss: 0.280155
   Number of active neurons: 5
 >> iter 81000, loss: 0.198603
 >> iter 82000, loss: 0.296452
 >> iter 83000, loss: 0.243103
 >> iter 84000, loss: 0.184700
 >> iter 85000, loss: 0.134133
 >> iter 86000, loss: 0.166754
 >> iter 87000, loss: 0.142214
 >> iter 88000, loss: 0.236233
 >> iter 89000, loss: 0.317216
 >> iter 90000, loss: 0.213152
   Number of active neurons: 5
 >> iter 91000, loss: 0.220065
 >> iter 92000, loss: 0.262247
 >> iter 93000, loss: 0.150219
 >> iter 94000, loss: 0.182434
 >> iter 95000, loss: 0.221841
 >> iter 96000, loss: 0.200308
 >> iter 97000, loss: 0.432834
 >> iter 98000, loss: 0.250916
 >> iter 99000, loss: 0.193495
 >> iter 100000, loss: 0.155900
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.973744
 >> iter 2000, loss: 11.745024
 >> iter 3000, loss: 5.350656
 >> iter 4000, loss: 2.428042
 >> iter 5000, loss: 1.134924
 >> iter 6000, loss: 0.737371
 >> iter 7000, loss: 0.449707
 >> iter 8000, loss: 0.377363
 >> iter 9000, loss: 0.569944
 >> iter 10000, loss: 0.394340
   Number of active neurons: 7
 >> iter 11000, loss: 0.501496
 >> iter 12000, loss: 0.510250
 >> iter 13000, loss: 0.451115
 >> iter 14000, loss: 0.405257
 >> iter 15000, loss: 0.406010
 >> iter 16000, loss: 0.403651
 >> iter 17000, loss: 0.375861
 >> iter 18000, loss: 0.344089
 >> iter 19000, loss: 0.325329
 >> iter 20000, loss: 0.236344
   Number of active neurons: 7
 >> iter 21000, loss: 0.308987
 >> iter 22000, loss: 0.383547
 >> iter 23000, loss: 0.425254
 >> iter 24000, loss: 0.322154
 >> iter 25000, loss: 0.314968
 >> iter 26000, loss: 0.365978
 >> iter 27000, loss: 0.373579
 >> iter 28000, loss: 0.357856
 >> iter 29000, loss: 0.325989
 >> iter 30000, loss: 0.375748
   Number of active neurons: 7
 >> iter 31000, loss: 0.394366
 >> iter 32000, loss: 0.264136
 >> iter 33000, loss: 0.375731
 >> iter 34000, loss: 0.442230
 >> iter 35000, loss: 0.385542
 >> iter 36000, loss: 0.428612
 >> iter 37000, loss: 0.230846
 >> iter 38000, loss: 0.230730
 >> iter 39000, loss: 0.269044
 >> iter 40000, loss: 0.221211
   Number of active neurons: 7
 >> iter 41000, loss: 0.241372
 >> iter 42000, loss: 0.240209
 >> iter 43000, loss: 0.244461
 >> iter 44000, loss: 0.334500
 >> iter 45000, loss: 0.308739
 >> iter 46000, loss: 0.185493
 >> iter 47000, loss: 0.264817
 >> iter 48000, loss: 0.158016
 >> iter 49000, loss: 0.259300
 >> iter 50000, loss: 0.241070
   Number of active neurons: 6
 >> iter 51000, loss: 0.233202
 >> iter 52000, loss: 0.249531
 >> iter 53000, loss: 0.211818
 >> iter 54000, loss: 0.408989
 >> iter 55000, loss: 0.320083
 >> iter 56000, loss: 0.250734
 >> iter 57000, loss: 0.260319
 >> iter 58000, loss: 0.251391
 >> iter 59000, loss: 0.178926
 >> iter 60000, loss: 0.139934
   Number of active neurons: 6
 >> iter 61000, loss: 0.162090
 >> iter 62000, loss: 0.136057
 >> iter 63000, loss: 0.229396
 >> iter 64000, loss: 0.331025
 >> iter 65000, loss: 0.176120
 >> iter 66000, loss: 0.163297
 >> iter 67000, loss: 0.284692
 >> iter 68000, loss: 0.215629
 >> iter 69000, loss: 0.192841
 >> iter 70000, loss: 0.125803
   Number of active neurons: 6
 >> iter 71000, loss: 0.165394
 >> iter 72000, loss: 0.224382
 >> iter 73000, loss: 0.249821
 >> iter 74000, loss: 0.196554
 >> iter 75000, loss: 0.115486
 >> iter 76000, loss: 0.123423
 >> iter 77000, loss: 0.127680
 >> iter 78000, loss: 0.088735
 >> iter 79000, loss: 0.329658
 >> iter 80000, loss: 0.294734
   Number of active neurons: 5
 >> iter 81000, loss: 0.232425
 >> iter 82000, loss: 0.255151
 >> iter 83000, loss: 0.390141
 >> iter 84000, loss: 0.214270
 >> iter 85000, loss: 0.253167
 >> iter 86000, loss: 0.262025
 >> iter 87000, loss: 0.227142
 >> iter 88000, loss: 0.204912
 >> iter 89000, loss: 0.313532
 >> iter 90000, loss: 0.217070
   Number of active neurons: 5
 >> iter 91000, loss: 0.184170
 >> iter 92000, loss: 0.237099
 >> iter 93000, loss: 0.221258
 >> iter 94000, loss: 0.165935
 >> iter 95000, loss: 0.193654
 >> iter 96000, loss: 0.186041
 >> iter 97000, loss: 0.304322
 >> iter 98000, loss: 0.230332
 >> iter 99000, loss: 0.152281
 >> iter 100000, loss: 0.204847
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.290866
 >> iter 2000, loss: 12.802689
 >> iter 3000, loss: 5.697992
 >> iter 4000, loss: 2.497967
 >> iter 5000, loss: 1.247845
 >> iter 6000, loss: 0.836382
 >> iter 7000, loss: 0.640805
 >> iter 8000, loss: 0.473699
 >> iter 9000, loss: 0.284059
 >> iter 10000, loss: 0.525066
   Number of active neurons: 9
 >> iter 11000, loss: 0.372181
 >> iter 12000, loss: 0.489667
 >> iter 13000, loss: 0.483780
 >> iter 14000, loss: 0.345707
 >> iter 15000, loss: 0.408141
 >> iter 16000, loss: 0.301200
 >> iter 17000, loss: 0.297016
 >> iter 18000, loss: 0.230390
 >> iter 19000, loss: 0.342235
 >> iter 20000, loss: 0.206862
   Number of active neurons: 9
 >> iter 21000, loss: 0.250811
 >> iter 22000, loss: 0.356646
 >> iter 23000, loss: 0.334067
 >> iter 24000, loss: 0.249348
 >> iter 25000, loss: 0.352306
 >> iter 26000, loss: 0.263768
 >> iter 27000, loss: 0.430579
 >> iter 28000, loss: 0.287878
 >> iter 29000, loss: 0.287218
 >> iter 30000, loss: 0.200755
   Number of active neurons: 8
 >> iter 31000, loss: 0.339047
 >> iter 32000, loss: 0.327578
 >> iter 33000, loss: 0.188515
 >> iter 34000, loss: 0.282765
 >> iter 35000, loss: 0.283214
 >> iter 36000, loss: 0.188371
 >> iter 37000, loss: 0.130268
 >> iter 38000, loss: 0.249877
 >> iter 39000, loss: 0.290507
 >> iter 40000, loss: 0.147379
   Number of active neurons: 8
 >> iter 41000, loss: 0.267211
 >> iter 42000, loss: 0.266692
 >> iter 43000, loss: 0.169959
 >> iter 44000, loss: 0.228017
 >> iter 45000, loss: 0.281743
 >> iter 46000, loss: 0.295452
 >> iter 47000, loss: 0.231613
 >> iter 48000, loss: 0.174955
 >> iter 49000, loss: 0.125950
 >> iter 50000, loss: 0.093608
   Number of active neurons: 7
 >> iter 51000, loss: 0.273466
 >> iter 52000, loss: 0.252081
 >> iter 53000, loss: 0.211942
 >> iter 54000, loss: 0.169070
 >> iter 55000, loss: 0.254831
 >> iter 56000, loss: 0.215775
 >> iter 57000, loss: 0.432310
 >> iter 58000, loss: 0.287647
 >> iter 59000, loss: 0.205912
 >> iter 60000, loss: 0.169462
   Number of active neurons: 6
 >> iter 61000, loss: 0.116745
 >> iter 62000, loss: 0.157622
 >> iter 63000, loss: 0.199611
 >> iter 64000, loss: 0.214678
 >> iter 65000, loss: 0.197229
 >> iter 66000, loss: 0.219469
 >> iter 67000, loss: 0.192602
 >> iter 68000, loss: 0.127298
 >> iter 69000, loss: 0.154821
 >> iter 70000, loss: 0.121415
   Number of active neurons: 6
 >> iter 71000, loss: 0.368065
 >> iter 72000, loss: 0.288607
 >> iter 73000, loss: 0.361874
 >> iter 74000, loss: 0.262482
 >> iter 75000, loss: 0.189138
 >> iter 76000, loss: 0.198204
 >> iter 77000, loss: 0.232028
 >> iter 78000, loss: 0.142946
 >> iter 79000, loss: 0.193697
 >> iter 80000, loss: 0.181699
   Number of active neurons: 6
 >> iter 81000, loss: 0.167847
 >> iter 82000, loss: 0.198595
 >> iter 83000, loss: 0.231670
 >> iter 84000, loss: 0.209928
 >> iter 85000, loss: 0.289958
 >> iter 86000, loss: 0.224378
 >> iter 87000, loss: 0.329654
 >> iter 88000, loss: 0.170421
 >> iter 89000, loss: 0.265601
 >> iter 90000, loss: 0.206070
   Number of active neurons: 6
 >> iter 91000, loss: 0.136782
 >> iter 92000, loss: 0.328072
 >> iter 93000, loss: 0.166681
 >> iter 94000, loss: 0.157534
 >> iter 95000, loss: 0.345879
 >> iter 96000, loss: 0.250493
 >> iter 97000, loss: 0.171319
 >> iter 98000, loss: 0.172505
 >> iter 99000, loss: 0.217514
 >> iter 100000, loss: 0.237796
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.297128
 >> iter 2000, loss: 11.776491
 >> iter 3000, loss: 6.310644
 >> iter 4000, loss: 3.388148
 >> iter 5000, loss: 1.915204
 >> iter 6000, loss: 1.037219
 >> iter 7000, loss: 0.784119
 >> iter 8000, loss: 0.623216
 >> iter 9000, loss: 0.483864
 >> iter 10000, loss: 0.514382
   Number of active neurons: 6
 >> iter 11000, loss: 0.371495
 >> iter 12000, loss: 0.259508
 >> iter 13000, loss: 0.323659
 >> iter 14000, loss: 0.486065
 >> iter 15000, loss: 0.372881
 >> iter 16000, loss: 0.385945
 >> iter 17000, loss: 0.394625
 >> iter 18000, loss: 0.312721
 >> iter 19000, loss: 0.484625
 >> iter 20000, loss: 0.308164
   Number of active neurons: 6
 >> iter 21000, loss: 0.523572
 >> iter 22000, loss: 0.320432
 >> iter 23000, loss: 0.375371
 >> iter 24000, loss: 0.424697
 >> iter 25000, loss: 0.349023
 >> iter 26000, loss: 0.525777
 >> iter 27000, loss: 0.543570
 >> iter 28000, loss: 0.558494
 >> iter 29000, loss: 0.447537
 >> iter 30000, loss: 0.388113
   Number of active neurons: 6
 >> iter 31000, loss: 0.416366
 >> iter 32000, loss: 0.383162
 >> iter 33000, loss: 0.369867
 >> iter 34000, loss: 0.395570
 >> iter 35000, loss: 0.571912
 >> iter 36000, loss: 0.529604
 >> iter 37000, loss: 0.577706
 >> iter 38000, loss: 0.365866
 >> iter 39000, loss: 0.282627
 >> iter 40000, loss: 0.273463
   Number of active neurons: 6
 >> iter 41000, loss: 0.214244
 >> iter 42000, loss: 0.348085
 >> iter 43000, loss: 0.307383
 >> iter 44000, loss: 0.270781
 >> iter 45000, loss: 0.216360
 >> iter 46000, loss: 0.168857
 >> iter 47000, loss: 0.289645
 >> iter 48000, loss: 0.270428
 >> iter 49000, loss: 0.224042
 >> iter 50000, loss: 0.295601
   Number of active neurons: 6
 >> iter 51000, loss: 0.369731
 >> iter 52000, loss: 0.260032
 >> iter 53000, loss: 0.173242
 >> iter 54000, loss: 0.274515
 >> iter 55000, loss: 0.394946
 >> iter 56000, loss: 0.332201
 >> iter 57000, loss: 0.388276
 >> iter 58000, loss: 0.523800
 >> iter 59000, loss: 0.497968
 >> iter 60000, loss: 0.461455
   Number of active neurons: 6
 >> iter 61000, loss: 0.338192
 >> iter 62000, loss: 0.317981
 >> iter 63000, loss: 0.266466
 >> iter 64000, loss: 0.274870
 >> iter 65000, loss: 0.261806
 >> iter 66000, loss: 0.212189
 >> iter 67000, loss: 0.251259
 >> iter 68000, loss: 0.347800
 >> iter 69000, loss: 0.402639
 >> iter 70000, loss: 0.409475
   Number of active neurons: 6
 >> iter 71000, loss: 0.294546
 >> iter 72000, loss: 0.202541
 >> iter 73000, loss: 0.304126
 >> iter 74000, loss: 0.196900
 >> iter 75000, loss: 0.250419
 >> iter 76000, loss: 0.299561
 >> iter 77000, loss: 0.235414
 >> iter 78000, loss: 0.221960
 >> iter 79000, loss: 0.277401
 >> iter 80000, loss: 0.320669
   Number of active neurons: 6
 >> iter 81000, loss: 0.197713
 >> iter 82000, loss: 0.229464
 >> iter 83000, loss: 0.283709
 >> iter 84000, loss: 0.218848
 >> iter 85000, loss: 0.316223
 >> iter 86000, loss: 0.258841
 >> iter 87000, loss: 0.278041
 >> iter 88000, loss: 0.242762
 >> iter 89000, loss: 0.179657
 >> iter 90000, loss: 0.100368
   Number of active neurons: 6
 >> iter 91000, loss: 0.238157
 >> iter 92000, loss: 0.162718
 >> iter 93000, loss: 0.313576
 >> iter 94000, loss: 0.448352
 >> iter 95000, loss: 0.253950
 >> iter 96000, loss: 0.322393
 >> iter 97000, loss: 0.181453
 >> iter 98000, loss: 0.236940
 >> iter 99000, loss: 0.180907
 >> iter 100000, loss: 0.285767
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.164192
 >> iter 2000, loss: 11.321250
 >> iter 3000, loss: 6.290605
 >> iter 4000, loss: 3.238674
 >> iter 5000, loss: 1.861496
 >> iter 6000, loss: 0.942120
 >> iter 7000, loss: 0.605184
 >> iter 8000, loss: 0.511441
 >> iter 9000, loss: 0.600464
 >> iter 10000, loss: 0.519788
   Number of active neurons: 7
 >> iter 11000, loss: 0.561126
 >> iter 12000, loss: 0.480751
 >> iter 13000, loss: 0.360123
 >> iter 14000, loss: 0.431268
 >> iter 15000, loss: 0.538196
 >> iter 16000, loss: 0.539020
 >> iter 17000, loss: 0.357563
 >> iter 18000, loss: 0.305192
 >> iter 19000, loss: 0.365321
 >> iter 20000, loss: 0.331307
   Number of active neurons: 7
 >> iter 21000, loss: 0.510778
 >> iter 22000, loss: 0.363119
 >> iter 23000, loss: 0.378256
 >> iter 24000, loss: 0.441572
 >> iter 25000, loss: 0.522356
 >> iter 26000, loss: 0.516666
 >> iter 27000, loss: 0.519256
 >> iter 28000, loss: 0.459686
 >> iter 29000, loss: 0.457811
 >> iter 30000, loss: 0.393687
   Number of active neurons: 7
 >> iter 31000, loss: 0.266192
 >> iter 32000, loss: 0.327025
 >> iter 33000, loss: 0.311371
 >> iter 34000, loss: 0.239561
 >> iter 35000, loss: 0.270808
 >> iter 36000, loss: 0.378748
 >> iter 37000, loss: 0.392133
 >> iter 38000, loss: 0.343873
 >> iter 39000, loss: 0.601098
 >> iter 40000, loss: 0.463329
   Number of active neurons: 7
 >> iter 41000, loss: 0.387297
 >> iter 42000, loss: 0.479560
 >> iter 43000, loss: 0.574750
 >> iter 44000, loss: 0.520238
 >> iter 45000, loss: 0.305225
 >> iter 46000, loss: 0.584332
 >> iter 47000, loss: 0.355673
 >> iter 48000, loss: 0.301969
 >> iter 49000, loss: 0.466932
 >> iter 50000, loss: 0.608287
   Number of active neurons: 7
 >> iter 51000, loss: 0.624704
 >> iter 52000, loss: 0.503820
 >> iter 53000, loss: 0.519307
 >> iter 54000, loss: 0.583937
 >> iter 55000, loss: 0.452755
 >> iter 56000, loss: 0.645950
 >> iter 57000, loss: 0.522219
 >> iter 58000, loss: 0.500995
 >> iter 59000, loss: 0.499317
 >> iter 60000, loss: 0.434904
   Number of active neurons: 7
 >> iter 61000, loss: 0.475733
 >> iter 62000, loss: 0.285646
 >> iter 63000, loss: 0.346559
 >> iter 64000, loss: 0.652381
 >> iter 65000, loss: 0.712779
 >> iter 66000, loss: 0.525472
 >> iter 67000, loss: 0.456911
 >> iter 68000, loss: 0.578481
 >> iter 69000, loss: 0.547287
 >> iter 70000, loss: 0.583712
   Number of active neurons: 7
 >> iter 71000, loss: 0.672779
 >> iter 72000, loss: 0.601028
 >> iter 73000, loss: 0.547262
 >> iter 74000, loss: 0.380702
 >> iter 75000, loss: 0.505500
 >> iter 76000, loss: 0.384602
 >> iter 77000, loss: 0.406804
 >> iter 78000, loss: 0.247977
 >> iter 79000, loss: 0.353295
 >> iter 80000, loss: 0.560592
   Number of active neurons: 7
 >> iter 81000, loss: 0.393968
 >> iter 82000, loss: 0.507030
 >> iter 83000, loss: 0.553607
 >> iter 84000, loss: 0.397065
 >> iter 85000, loss: 0.352033
 >> iter 86000, loss: 0.302126
 >> iter 87000, loss: 0.431923
 >> iter 88000, loss: 0.422959
 >> iter 89000, loss: 0.559506
 >> iter 90000, loss: 0.524000
   Number of active neurons: 7
 >> iter 91000, loss: 0.397196
 >> iter 92000, loss: 0.363572
 >> iter 93000, loss: 0.262521
 >> iter 94000, loss: 0.428493
 >> iter 95000, loss: 0.295051
 >> iter 96000, loss: 0.304247
 >> iter 97000, loss: 0.317429
 >> iter 98000, loss: 0.366227
 >> iter 99000, loss: 0.411743
 >> iter 100000, loss: 0.476433
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 19.149120
 >> iter 2000, loss: 11.661354
 >> iter 3000, loss: 5.990821
 >> iter 4000, loss: 3.007261
 >> iter 5000, loss: 1.828130
 >> iter 6000, loss: 1.161965
 >> iter 7000, loss: 1.071232
 >> iter 8000, loss: 0.717176
 >> iter 9000, loss: 0.626082
 >> iter 10000, loss: 0.617408
   Number of active neurons: 8
 >> iter 11000, loss: 0.610353
 >> iter 12000, loss: 0.625007
 >> iter 13000, loss: 0.510135
 >> iter 14000, loss: 0.766164
 >> iter 15000, loss: 0.493832
 >> iter 16000, loss: 0.421893
 >> iter 17000, loss: 0.272084
 >> iter 18000, loss: 0.295452
 >> iter 19000, loss: 0.463057
 >> iter 20000, loss: 0.506880
   Number of active neurons: 8
 >> iter 21000, loss: 0.495295
 >> iter 22000, loss: 0.326478
 >> iter 23000, loss: 0.270842
 >> iter 24000, loss: 0.459096
 >> iter 25000, loss: 0.298345
 >> iter 26000, loss: 0.476504
 >> iter 27000, loss: 0.517213
 >> iter 28000, loss: 0.319922
 >> iter 29000, loss: 0.475014
 >> iter 30000, loss: 0.327025
   Number of active neurons: 8
 >> iter 31000, loss: 0.481837
 >> iter 32000, loss: 0.412522
 >> iter 33000, loss: 0.601175
 >> iter 34000, loss: 0.584713
 >> iter 35000, loss: 0.400961
 >> iter 36000, loss: 0.610189
 >> iter 37000, loss: 0.509149
 >> iter 38000, loss: 0.378001
 >> iter 39000, loss: 0.378474
 >> iter 40000, loss: 0.327485
   Number of active neurons: 8
 >> iter 41000, loss: 0.408592
 >> iter 42000, loss: 0.374192
 >> iter 43000, loss: 0.229293
 >> iter 44000, loss: 0.166114
 >> iter 45000, loss: 0.255367
 >> iter 46000, loss: 0.181251
 >> iter 47000, loss: 0.296560
 >> iter 48000, loss: 0.261893
 >> iter 49000, loss: 0.226735
 >> iter 50000, loss: 0.311965
   Number of active neurons: 8
 >> iter 51000, loss: 0.381752
 >> iter 52000, loss: 0.411742
 >> iter 53000, loss: 0.300399
 >> iter 54000, loss: 0.259912
 >> iter 55000, loss: 0.312107
 >> iter 56000, loss: 0.238069
 >> iter 57000, loss: 0.334046
 >> iter 58000, loss: 0.199752
 >> iter 59000, loss: 0.145415
 >> iter 60000, loss: 0.142623
   Number of active neurons: 8
 >> iter 61000, loss: 0.198275
 >> iter 62000, loss: 0.252764
 >> iter 63000, loss: 0.222479
 >> iter 64000, loss: 0.371271
 >> iter 65000, loss: 0.268994
 >> iter 66000, loss: 0.248800
 >> iter 67000, loss: 0.211664
 >> iter 68000, loss: 0.173370
 >> iter 69000, loss: 0.364435
 >> iter 70000, loss: 0.252858
   Number of active neurons: 8
 >> iter 71000, loss: 0.293978
 >> iter 72000, loss: 0.210317
 >> iter 73000, loss: 0.246875
 >> iter 74000, loss: 0.250073
 >> iter 75000, loss: 0.298085
 >> iter 76000, loss: 0.241848
 >> iter 77000, loss: 0.394109
 >> iter 78000, loss: 0.369426
 >> iter 79000, loss: 0.320726
 >> iter 80000, loss: 0.369081
   Number of active neurons: 8
 >> iter 81000, loss: 0.257680
 >> iter 82000, loss: 0.173833
 >> iter 83000, loss: 0.234260
 >> iter 84000, loss: 0.287460
 >> iter 85000, loss: 0.298511
 >> iter 86000, loss: 0.499760
 >> iter 87000, loss: 0.364141
 >> iter 88000, loss: 0.304024
 >> iter 89000, loss: 0.213159
 >> iter 90000, loss: 0.203073
   Number of active neurons: 8
 >> iter 91000, loss: 0.255760
 >> iter 92000, loss: 0.182736
 >> iter 93000, loss: 0.340853
 >> iter 94000, loss: 0.200728
 >> iter 95000, loss: 0.373608
 >> iter 96000, loss: 0.283450
 >> iter 97000, loss: 0.296222
 >> iter 98000, loss: 0.336828
 >> iter 99000, loss: 0.304151
 >> iter 100000, loss: 0.191469
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.256443
 >> iter 2000, loss: 10.718304
 >> iter 3000, loss: 5.002632
 >> iter 4000, loss: 2.426589
 >> iter 5000, loss: 1.511659
 >> iter 6000, loss: 0.961524
 >> iter 7000, loss: 0.649090
 >> iter 8000, loss: 0.469377
 >> iter 9000, loss: 0.396468
 >> iter 10000, loss: 0.341597
   Number of active neurons: 8
 >> iter 11000, loss: 0.435038
 >> iter 12000, loss: 0.606003
 >> iter 13000, loss: 0.561463
 >> iter 14000, loss: 0.452741
 >> iter 15000, loss: 0.326420
 >> iter 16000, loss: 0.312641
 >> iter 17000, loss: 0.305224
 >> iter 18000, loss: 0.328232
 >> iter 19000, loss: 0.444505
 >> iter 20000, loss: 0.364427
   Number of active neurons: 8
 >> iter 21000, loss: 0.242471
 >> iter 22000, loss: 0.416676
 >> iter 23000, loss: 0.392201
 >> iter 24000, loss: 0.356123
 >> iter 25000, loss: 0.349484
 >> iter 26000, loss: 0.305237
 >> iter 27000, loss: 0.221329
 >> iter 28000, loss: 0.246367
 >> iter 29000, loss: 0.257300
 >> iter 30000, loss: 0.182280
   Number of active neurons: 8
 >> iter 31000, loss: 0.227844
 >> iter 32000, loss: 0.310364
 >> iter 33000, loss: 0.304464
 >> iter 34000, loss: 0.361439
 >> iter 35000, loss: 0.493149
 >> iter 36000, loss: 0.405117
 >> iter 37000, loss: 0.285264
 >> iter 38000, loss: 0.238304
 >> iter 39000, loss: 0.347870
 >> iter 40000, loss: 0.309533
   Number of active neurons: 8
 >> iter 41000, loss: 0.326622
 >> iter 42000, loss: 0.313934
 >> iter 43000, loss: 0.308655
 >> iter 44000, loss: 0.312214
 >> iter 45000, loss: 0.391056
 >> iter 46000, loss: 0.312566
 >> iter 47000, loss: 0.346997
 >> iter 48000, loss: 0.330503
 >> iter 49000, loss: 0.253666
 >> iter 50000, loss: 0.334424
   Number of active neurons: 7
 >> iter 51000, loss: 0.298595
 >> iter 52000, loss: 0.358613
 >> iter 53000, loss: 0.331188
 >> iter 54000, loss: 0.299956
 >> iter 55000, loss: 0.227725
 >> iter 56000, loss: 0.331330
 >> iter 57000, loss: 0.355742
 >> iter 58000, loss: 0.434777
 >> iter 59000, loss: 0.399787
 >> iter 60000, loss: 0.278555
   Number of active neurons: 7
 >> iter 61000, loss: 0.350504
 >> iter 62000, loss: 0.285050
 >> iter 63000, loss: 0.283716
 >> iter 64000, loss: 0.466452
 >> iter 65000, loss: 0.279000
 >> iter 66000, loss: 0.270182
 >> iter 67000, loss: 0.226673
 >> iter 68000, loss: 0.199462
 >> iter 69000, loss: 0.311193
 >> iter 70000, loss: 0.368514
   Number of active neurons: 7
 >> iter 71000, loss: 0.467690
 >> iter 72000, loss: 0.444765
 >> iter 73000, loss: 0.231960
 >> iter 74000, loss: 0.223379
 >> iter 75000, loss: 0.374347
 >> iter 76000, loss: 0.323027
 >> iter 77000, loss: 0.296880
 >> iter 78000, loss: 0.435097
 >> iter 79000, loss: 0.350946
 >> iter 80000, loss: 0.364644
   Number of active neurons: 7
 >> iter 81000, loss: 0.416517
 >> iter 82000, loss: 0.251178
 >> iter 83000, loss: 0.248695
 >> iter 84000, loss: 0.341675
 >> iter 85000, loss: 0.272940
 >> iter 86000, loss: 0.340034
 >> iter 87000, loss: 0.223464
 >> iter 88000, loss: 0.228535
 >> iter 89000, loss: 0.228629
 >> iter 90000, loss: 0.336756
   Number of active neurons: 7
 >> iter 91000, loss: 0.257203
 >> iter 92000, loss: 0.378321
 >> iter 93000, loss: 0.453225
 >> iter 94000, loss: 0.318404
 >> iter 95000, loss: 0.330633
 >> iter 96000, loss: 0.353688
 >> iter 97000, loss: 0.330355
 >> iter 98000, loss: 0.261333
 >> iter 99000, loss: 0.175014
 >> iter 100000, loss: 0.247593
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 9.00606626225
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.112006
 >> iter 2000, loss: 11.897086
 >> iter 3000, loss: 5.403958
 >> iter 4000, loss: 2.578799
 >> iter 5000, loss: 1.472778
 >> iter 6000, loss: 0.801557
 >> iter 7000, loss: 0.530675
 >> iter 8000, loss: 0.644681
 >> iter 9000, loss: 0.464804
 >> iter 10000, loss: 0.490745
   Number of active neurons: 8
 >> iter 11000, loss: 0.423785
 >> iter 12000, loss: 0.474200
 >> iter 13000, loss: 0.549542
 >> iter 14000, loss: 0.472165
 >> iter 15000, loss: 0.425520
 >> iter 16000, loss: 0.531358
 >> iter 17000, loss: 0.517856
 >> iter 18000, loss: 0.323895
 >> iter 19000, loss: 0.376336
 >> iter 20000, loss: 0.362397
   Number of active neurons: 8
 >> iter 21000, loss: 0.357315
 >> iter 22000, loss: 0.558018
 >> iter 23000, loss: 0.521834
 >> iter 24000, loss: 0.312175
 >> iter 25000, loss: 0.338385
 >> iter 26000, loss: 0.405321
 >> iter 27000, loss: 0.316244
 >> iter 28000, loss: 0.474429
 >> iter 29000, loss: 0.370477
 >> iter 30000, loss: 0.289604
   Number of active neurons: 8
 >> iter 31000, loss: 0.469099
 >> iter 32000, loss: 0.332587
 >> iter 33000, loss: 0.284003
 >> iter 34000, loss: 0.536959
 >> iter 35000, loss: 0.426557
 >> iter 36000, loss: 0.365940
 >> iter 37000, loss: 0.281492
 >> iter 38000, loss: 0.238391
 >> iter 39000, loss: 0.276725
 >> iter 40000, loss: 0.175577
   Number of active neurons: 8
 >> iter 41000, loss: 0.243154
 >> iter 42000, loss: 0.429997
 >> iter 43000, loss: 0.262191
 >> iter 44000, loss: 0.297802
 >> iter 45000, loss: 0.355242
 >> iter 46000, loss: 0.205812
 >> iter 47000, loss: 0.375671
 >> iter 48000, loss: 0.418868
 >> iter 49000, loss: 0.301402
 >> iter 50000, loss: 0.262746
   Number of active neurons: 8
 >> iter 51000, loss: 0.205459
 >> iter 52000, loss: 0.267490
 >> iter 53000, loss: 0.293522
 >> iter 54000, loss: 0.251998
 >> iter 55000, loss: 0.432398
 >> iter 56000, loss: 0.365560
 >> iter 57000, loss: 0.267341
 >> iter 58000, loss: 0.212172
 >> iter 59000, loss: 0.283782
 >> iter 60000, loss: 0.279664
   Number of active neurons: 7
 >> iter 61000, loss: 0.208574
 >> iter 62000, loss: 0.370076
 >> iter 63000, loss: 0.329534
 >> iter 64000, loss: 0.260047
 >> iter 65000, loss: 0.368729
 >> iter 66000, loss: 0.421617
 >> iter 67000, loss: 0.280024
 >> iter 68000, loss: 0.235112
 >> iter 69000, loss: 0.162691
 >> iter 70000, loss: 0.121151
   Number of active neurons: 7
 >> iter 71000, loss: 0.393495
 >> iter 72000, loss: 0.419668
 >> iter 73000, loss: 0.332176
 >> iter 74000, loss: 0.244424
 >> iter 75000, loss: 0.175179
 >> iter 76000, loss: 0.192549
 >> iter 77000, loss: 0.281625
 >> iter 78000, loss: 0.235042
 >> iter 79000, loss: 0.168425
 >> iter 80000, loss: 0.288317
   Number of active neurons: 7
 >> iter 81000, loss: 0.230568
 >> iter 82000, loss: 0.237802
 >> iter 83000, loss: 0.185085
 >> iter 84000, loss: 0.250695
 >> iter 85000, loss: 0.277860
 >> iter 86000, loss: 0.292279
 >> iter 87000, loss: 0.243601
 >> iter 88000, loss: 0.254742
 >> iter 89000, loss: 0.202826
 >> iter 90000, loss: 0.138794
   Number of active neurons: 7
 >> iter 91000, loss: 0.195723
 >> iter 92000, loss: 0.187548
 >> iter 93000, loss: 0.284394
 >> iter 94000, loss: 0.225211
 >> iter 95000, loss: 0.171085
 >> iter 96000, loss: 0.143226
 >> iter 97000, loss: 0.189191
 >> iter 98000, loss: 0.232945
 >> iter 99000, loss: 0.309099
 >> iter 100000, loss: 0.254662
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.233899
 >> iter 2000, loss: 11.145368
 >> iter 3000, loss: 5.103015
 >> iter 4000, loss: 2.428677
 >> iter 5000, loss: 1.523091
 >> iter 6000, loss: 0.946570
 >> iter 7000, loss: 0.572227
 >> iter 8000, loss: 0.365283
 >> iter 9000, loss: 0.242192
 >> iter 10000, loss: 0.271457
   Number of active neurons: 8
 >> iter 11000, loss: 0.522153
 >> iter 12000, loss: 0.325534
 >> iter 13000, loss: 0.203943
 >> iter 14000, loss: 0.250188
 >> iter 15000, loss: 0.449304
 >> iter 16000, loss: 0.354756
 >> iter 17000, loss: 0.528109
 >> iter 18000, loss: 0.387943
 >> iter 19000, loss: 0.273345
 >> iter 20000, loss: 0.338551
   Number of active neurons: 8
 >> iter 21000, loss: 0.347256
 >> iter 22000, loss: 0.454669
 >> iter 23000, loss: 0.286594
 >> iter 24000, loss: 0.304758
 >> iter 25000, loss: 0.248438
 >> iter 26000, loss: 0.212305
 >> iter 27000, loss: 0.283975
 >> iter 28000, loss: 0.226365
 >> iter 29000, loss: 0.290591
 >> iter 30000, loss: 0.283773
   Number of active neurons: 8
 >> iter 31000, loss: 0.308228
 >> iter 32000, loss: 0.345014
 >> iter 33000, loss: 0.229507
 >> iter 34000, loss: 0.319919
 >> iter 35000, loss: 0.400552
 >> iter 36000, loss: 0.342979
 >> iter 37000, loss: 0.423531
 >> iter 38000, loss: 0.401667
 >> iter 39000, loss: 0.454025
 >> iter 40000, loss: 0.421584
   Number of active neurons: 7
 >> iter 41000, loss: 0.309083
 >> iter 42000, loss: 0.314763
 >> iter 43000, loss: 0.538014
 >> iter 44000, loss: 0.369318
 >> iter 45000, loss: 0.541461
 >> iter 46000, loss: 0.385244
 >> iter 47000, loss: 0.451837
 >> iter 48000, loss: 0.495324
 >> iter 49000, loss: 0.577538
 >> iter 50000, loss: 0.324508
   Number of active neurons: 7
 >> iter 51000, loss: 0.384653
 >> iter 52000, loss: 0.443984
 >> iter 53000, loss: 0.454200
 >> iter 54000, loss: 0.333874
 >> iter 55000, loss: 0.338264
 >> iter 56000, loss: 0.267193
 >> iter 57000, loss: 0.348410
 >> iter 58000, loss: 0.288427
 >> iter 59000, loss: 0.251648
 >> iter 60000, loss: 0.241073
   Number of active neurons: 7
 >> iter 61000, loss: 0.415362
 >> iter 62000, loss: 0.341299
 >> iter 63000, loss: 0.388022
 >> iter 64000, loss: 0.341110
 >> iter 65000, loss: 0.452022
 >> iter 66000, loss: 0.388769
 >> iter 67000, loss: 0.339441
 >> iter 68000, loss: 0.369114
 >> iter 69000, loss: 0.398425
 >> iter 70000, loss: 0.350021
   Number of active neurons: 7
 >> iter 71000, loss: 0.311838
 >> iter 72000, loss: 0.352832
 >> iter 73000, loss: 0.353357
 >> iter 74000, loss: 0.248424
 >> iter 75000, loss: 0.229222
 >> iter 76000, loss: 0.394983
 >> iter 77000, loss: 0.358845
 >> iter 78000, loss: 0.210678
 >> iter 79000, loss: 0.366016
 >> iter 80000, loss: 0.222712
   Number of active neurons: 7
 >> iter 81000, loss: 0.269679
 >> iter 82000, loss: 0.231877
 >> iter 83000, loss: 0.321585
 >> iter 84000, loss: 0.296254
 >> iter 85000, loss: 0.438600
 >> iter 86000, loss: 0.473309
 >> iter 87000, loss: 0.326278
 >> iter 88000, loss: 0.414910
 >> iter 89000, loss: 0.392806
 >> iter 90000, loss: 0.256614
   Number of active neurons: 7
 >> iter 91000, loss: 0.136601
 >> iter 92000, loss: 0.139536
 >> iter 93000, loss: 0.402906
 >> iter 94000, loss: 0.259672
 >> iter 95000, loss: 0.254005
 >> iter 96000, loss: 0.274500
 >> iter 97000, loss: 0.177503
 >> iter 98000, loss: 0.277018
 >> iter 99000, loss: 0.367406
 >> iter 100000, loss: 0.389936
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.009859
 >> iter 2000, loss: 13.983650
 >> iter 3000, loss: 9.505671
 >> iter 4000, loss: 6.094035
 >> iter 5000, loss: 3.857766
 >> iter 6000, loss: 2.644683
 >> iter 7000, loss: 1.572923
 >> iter 8000, loss: 1.028406
 >> iter 9000, loss: 0.717492
 >> iter 10000, loss: 1.085379
   Number of active neurons: 9
 >> iter 11000, loss: 1.040589
 >> iter 12000, loss: 0.541688
 >> iter 13000, loss: 0.604722
 >> iter 14000, loss: 0.574393
 >> iter 15000, loss: 0.621118
 >> iter 16000, loss: 0.572867
 >> iter 17000, loss: 0.689134
 >> iter 18000, loss: 0.611864
 >> iter 19000, loss: 0.506682
 >> iter 20000, loss: 0.470254
   Number of active neurons: 9
 >> iter 21000, loss: 0.336280
 >> iter 22000, loss: 0.347867
 >> iter 23000, loss: 0.244252
 >> iter 24000, loss: 0.345548
 >> iter 25000, loss: 0.453467
 >> iter 26000, loss: 0.430584
 >> iter 27000, loss: 0.360505
 >> iter 28000, loss: 0.563639
 >> iter 29000, loss: 0.550211
 >> iter 30000, loss: 0.476190
   Number of active neurons: 8
 >> iter 31000, loss: 0.597496
 >> iter 32000, loss: 0.536186
 >> iter 33000, loss: 0.432650
 >> iter 34000, loss: 0.779481
 >> iter 35000, loss: 0.542016
 >> iter 36000, loss: 0.391541
 >> iter 37000, loss: 0.363373
 >> iter 38000, loss: 0.416090
 >> iter 39000, loss: 0.443024
 >> iter 40000, loss: 0.320620
   Number of active neurons: 8
 >> iter 41000, loss: 0.457263
 >> iter 42000, loss: 0.475214
 >> iter 43000, loss: 0.492453
 >> iter 44000, loss: 0.346308
 >> iter 45000, loss: 0.308051
 >> iter 46000, loss: 0.499697
 >> iter 47000, loss: 0.378969
 >> iter 48000, loss: 0.259114
 >> iter 49000, loss: 0.467433
 >> iter 50000, loss: 0.404092
   Number of active neurons: 8
 >> iter 51000, loss: 0.339228
 >> iter 52000, loss: 0.265575
 >> iter 53000, loss: 0.288618
 >> iter 54000, loss: 0.459476
 >> iter 55000, loss: 0.397800
 >> iter 56000, loss: 0.472712
 >> iter 57000, loss: 0.448568
 >> iter 58000, loss: 0.693640
 >> iter 59000, loss: 0.474311
 >> iter 60000, loss: 0.498934
   Number of active neurons: 7
 >> iter 61000, loss: 0.363416
 >> iter 62000, loss: 0.290819
 >> iter 63000, loss: 0.352254
 >> iter 64000, loss: 0.390967
 >> iter 65000, loss: 0.406095
 >> iter 66000, loss: 0.411286
 >> iter 67000, loss: 0.382655
 >> iter 68000, loss: 0.335582
 >> iter 69000, loss: 0.410091
 >> iter 70000, loss: 0.421146
   Number of active neurons: 7
 >> iter 71000, loss: 0.336530
 >> iter 72000, loss: 0.505281
 >> iter 73000, loss: 0.600548
 >> iter 74000, loss: 0.582703
 >> iter 75000, loss: 0.596192
 >> iter 76000, loss: 0.513724
 >> iter 77000, loss: 0.766689
 >> iter 78000, loss: 0.624441
 >> iter 79000, loss: 0.556044
 >> iter 80000, loss: 0.659951
   Number of active neurons: 8
 >> iter 81000, loss: 0.499453
 >> iter 82000, loss: 0.391709
 >> iter 83000, loss: 0.471219
 >> iter 84000, loss: 0.309205
 >> iter 85000, loss: 0.504367
 >> iter 86000, loss: 0.366006
 >> iter 87000, loss: 0.722286
 >> iter 88000, loss: 0.594625
 >> iter 89000, loss: 0.387596
 >> iter 90000, loss: 0.594001
   Number of active neurons: 7
 >> iter 91000, loss: 0.494398
 >> iter 92000, loss: 0.371955
 >> iter 93000, loss: 0.588657
 >> iter 94000, loss: 0.443378
 >> iter 95000, loss: 0.270218
 >> iter 96000, loss: 0.417219
 >> iter 97000, loss: 0.470790
 >> iter 98000, loss: 0.415411
 >> iter 99000, loss: 0.465951
 >> iter 100000, loss: 0.347467
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 19.062004
 >> iter 2000, loss: 11.351446
 >> iter 3000, loss: 5.148323
 >> iter 4000, loss: 2.322979
 >> iter 5000, loss: 1.189718
 >> iter 6000, loss: 0.796871
 >> iter 7000, loss: 0.479560
 >> iter 8000, loss: 0.293080
 >> iter 9000, loss: 0.370381
 >> iter 10000, loss: 0.397617
   Number of active neurons: 7
 >> iter 11000, loss: 0.244114
 >> iter 12000, loss: 0.288955
 >> iter 13000, loss: 0.283857
 >> iter 14000, loss: 0.215617
 >> iter 15000, loss: 0.274289
 >> iter 16000, loss: 0.241942
 >> iter 17000, loss: 0.236548
 >> iter 18000, loss: 0.362118
 >> iter 19000, loss: 0.424086
 >> iter 20000, loss: 0.266867
   Number of active neurons: 7
 >> iter 21000, loss: 0.410947
 >> iter 22000, loss: 0.325718
 >> iter 23000, loss: 0.288465
 >> iter 24000, loss: 0.217436
 >> iter 25000, loss: 0.324672
 >> iter 26000, loss: 0.436847
 >> iter 27000, loss: 0.332650
 >> iter 28000, loss: 0.232146
 >> iter 29000, loss: 0.260816
 >> iter 30000, loss: 0.216516
   Number of active neurons: 7
 >> iter 31000, loss: 0.201146
 >> iter 32000, loss: 0.161835
 >> iter 33000, loss: 0.299395
 >> iter 34000, loss: 0.247710
 >> iter 35000, loss: 0.241902
 >> iter 36000, loss: 0.155782
 >> iter 37000, loss: 0.181988
 >> iter 38000, loss: 0.195752
 >> iter 39000, loss: 0.317043
 >> iter 40000, loss: 0.214586
   Number of active neurons: 7
 >> iter 41000, loss: 0.195121
 >> iter 42000, loss: 0.309822
 >> iter 43000, loss: 0.264676
 >> iter 44000, loss: 0.177378
 >> iter 45000, loss: 0.189816
 >> iter 46000, loss: 0.213504
 >> iter 47000, loss: 0.164243
 >> iter 48000, loss: 0.219148
 >> iter 49000, loss: 0.198173
 >> iter 50000, loss: 0.181430
   Number of active neurons: 7
 >> iter 51000, loss: 0.256675
 >> iter 52000, loss: 0.229338
 >> iter 53000, loss: 0.157627
 >> iter 54000, loss: 0.251767
 >> iter 55000, loss: 0.179067
 >> iter 56000, loss: 0.267328
 >> iter 57000, loss: 0.217596
 >> iter 58000, loss: 0.219842
 >> iter 59000, loss: 0.224450
 >> iter 60000, loss: 0.292050
   Number of active neurons: 7
 >> iter 61000, loss: 0.366475
 >> iter 62000, loss: 0.279788
 >> iter 63000, loss: 0.227423
 >> iter 64000, loss: 0.235389
 >> iter 65000, loss: 0.346932
 >> iter 66000, loss: 0.235306
 >> iter 67000, loss: 0.205037
 >> iter 68000, loss: 0.170363
 >> iter 69000, loss: 0.262832
 >> iter 70000, loss: 0.264143
   Number of active neurons: 7
 >> iter 71000, loss: 0.206691
 >> iter 72000, loss: 0.234666
 >> iter 73000, loss: 0.333258
 >> iter 74000, loss: 0.315565
 >> iter 75000, loss: 0.321858
 >> iter 76000, loss: 0.218806
 >> iter 77000, loss: 0.280475
 >> iter 78000, loss: 0.302571
 >> iter 79000, loss: 0.187602
 >> iter 80000, loss: 0.247637
   Number of active neurons: 7
 >> iter 81000, loss: 0.225466
 >> iter 82000, loss: 0.212015
 >> iter 83000, loss: 0.199760
 >> iter 84000, loss: 0.282449
 >> iter 85000, loss: 0.275211
 >> iter 86000, loss: 0.196510
 >> iter 87000, loss: 0.220662
 >> iter 88000, loss: 0.202813
 >> iter 89000, loss: 0.347653
 >> iter 90000, loss: 0.220110
   Number of active neurons: 6
 >> iter 91000, loss: 0.258296
 >> iter 92000, loss: 0.209690
 >> iter 93000, loss: 0.307089
 >> iter 94000, loss: 0.165505
 >> iter 95000, loss: 0.178709
 >> iter 96000, loss: 0.122099
 >> iter 97000, loss: 0.129566
 >> iter 98000, loss: 0.186015
 >> iter 99000, loss: 0.182111
 >> iter 100000, loss: 0.169683
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.106131
 >> iter 2000, loss: 10.769501
 >> iter 3000, loss: 4.637239
 >> iter 4000, loss: 2.222724
 >> iter 5000, loss: 1.029644
 >> iter 6000, loss: 0.650787
 >> iter 7000, loss: 0.331208
 >> iter 8000, loss: 0.454205
 >> iter 9000, loss: 0.303545
 >> iter 10000, loss: 0.211957
   Number of active neurons: 7
 >> iter 11000, loss: 0.184160
 >> iter 12000, loss: 0.282544
 >> iter 13000, loss: 0.483700
 >> iter 14000, loss: 0.311685
 >> iter 15000, loss: 0.306866
 >> iter 16000, loss: 0.457092
 >> iter 17000, loss: 0.369505
 >> iter 18000, loss: 0.290917
 >> iter 19000, loss: 0.293274
 >> iter 20000, loss: 0.322363
   Number of active neurons: 7
 >> iter 21000, loss: 0.419757
 >> iter 22000, loss: 0.376033
 >> iter 23000, loss: 0.310490
 >> iter 24000, loss: 0.268558
 >> iter 25000, loss: 0.297510
 >> iter 26000, loss: 0.197415
 >> iter 27000, loss: 0.337679
 >> iter 28000, loss: 0.480104
 >> iter 29000, loss: 0.303711
 >> iter 30000, loss: 0.324278
   Number of active neurons: 7
 >> iter 31000, loss: 0.231783
 >> iter 32000, loss: 0.280689
 >> iter 33000, loss: 0.294421
 >> iter 34000, loss: 0.321442
 >> iter 35000, loss: 0.452422
 >> iter 36000, loss: 0.343353
 >> iter 37000, loss: 0.295269
 >> iter 38000, loss: 0.265675
 >> iter 39000, loss: 0.315514
 >> iter 40000, loss: 0.194770
   Number of active neurons: 6
 >> iter 41000, loss: 0.209413
 >> iter 42000, loss: 0.200087
 >> iter 43000, loss: 0.383359
 >> iter 44000, loss: 0.303677
 >> iter 45000, loss: 0.218592
 >> iter 46000, loss: 0.222667
 >> iter 47000, loss: 0.153409
 >> iter 48000, loss: 0.249655
 >> iter 49000, loss: 0.285017
 >> iter 50000, loss: 0.246761
   Number of active neurons: 5
 >> iter 51000, loss: 0.342450
 >> iter 52000, loss: 0.333915
 >> iter 53000, loss: 0.393053
 >> iter 54000, loss: 0.214460
 >> iter 55000, loss: 0.273225
 >> iter 56000, loss: 0.295113
 >> iter 57000, loss: 0.259532
 >> iter 58000, loss: 0.328583
 >> iter 59000, loss: 0.374656
 >> iter 60000, loss: 0.237404
   Number of active neurons: 5
 >> iter 61000, loss: 0.199849
 >> iter 62000, loss: 0.219106
 >> iter 63000, loss: 0.162503
 >> iter 64000, loss: 0.283590
 >> iter 65000, loss: 0.300188
 >> iter 66000, loss: 0.264164
 >> iter 67000, loss: 0.275784
 >> iter 68000, loss: 0.233979
 >> iter 69000, loss: 0.371404
 >> iter 70000, loss: 0.233050
   Number of active neurons: 5
 >> iter 71000, loss: 0.269330
 >> iter 72000, loss: 0.185830
 >> iter 73000, loss: 0.228773
 >> iter 74000, loss: 0.243681
 >> iter 75000, loss: 0.189423
 >> iter 76000, loss: 0.181197
 >> iter 77000, loss: 0.317832
 >> iter 78000, loss: 0.417227
 >> iter 79000, loss: 0.405186
 >> iter 80000, loss: 0.337622
   Number of active neurons: 5
 >> iter 81000, loss: 0.260642
 >> iter 82000, loss: 0.233670
 >> iter 83000, loss: 0.169646
 >> iter 84000, loss: 0.167809
 >> iter 85000, loss: 0.159048
 >> iter 86000, loss: 0.199631
 >> iter 87000, loss: 0.302904
 >> iter 88000, loss: 0.356874
 >> iter 89000, loss: 0.304262
 >> iter 90000, loss: 0.283736
   Number of active neurons: 5
 >> iter 91000, loss: 0.339036
 >> iter 92000, loss: 0.267781
 >> iter 93000, loss: 0.253151
 >> iter 94000, loss: 0.196396
 >> iter 95000, loss: 0.265464
 >> iter 96000, loss: 0.209075
 >> iter 97000, loss: 0.141651
 >> iter 98000, loss: 0.255763
 >> iter 99000, loss: 0.221021
 >> iter 100000, loss: 0.184326
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.277629
 >> iter 2000, loss: 11.663047
 >> iter 3000, loss: 5.838207
 >> iter 4000, loss: 2.969793
 >> iter 5000, loss: 1.927894
 >> iter 6000, loss: 1.163102
 >> iter 7000, loss: 0.821479
 >> iter 8000, loss: 0.675160
 >> iter 9000, loss: 0.649856
 >> iter 10000, loss: 0.467750
   Number of active neurons: 6
 >> iter 11000, loss: 0.343908
 >> iter 12000, loss: 0.489817
 >> iter 13000, loss: 0.456513
 >> iter 14000, loss: 0.689403
 >> iter 15000, loss: 0.731479
 >> iter 16000, loss: 0.739113
 >> iter 17000, loss: 0.600632
 >> iter 18000, loss: 0.517786
 >> iter 19000, loss: 0.544334
 >> iter 20000, loss: 0.338991
   Number of active neurons: 6
 >> iter 21000, loss: 0.425454
 >> iter 22000, loss: 0.404827
 >> iter 23000, loss: 0.377426
 >> iter 24000, loss: 0.681754
 >> iter 25000, loss: 0.895315
 >> iter 26000, loss: 0.685430
 >> iter 27000, loss: 0.629137
 >> iter 28000, loss: 0.484872
 >> iter 29000, loss: 0.454045
 >> iter 30000, loss: 0.327158
   Number of active neurons: 6
 >> iter 31000, loss: 0.302498
 >> iter 32000, loss: 0.284950
 >> iter 33000, loss: 0.478335
 >> iter 34000, loss: 0.406980
 >> iter 35000, loss: 0.507659
 >> iter 36000, loss: 0.469532
 >> iter 37000, loss: 0.503986
 >> iter 38000, loss: 0.420705
 >> iter 39000, loss: 0.639783
 >> iter 40000, loss: 0.779135
   Number of active neurons: 6
 >> iter 41000, loss: 0.779928
 >> iter 42000, loss: 0.413053
 >> iter 43000, loss: 0.512374
 >> iter 44000, loss: 0.396187
 >> iter 45000, loss: 0.367103
 >> iter 46000, loss: 0.347560
 >> iter 47000, loss: 0.341330
 >> iter 48000, loss: 0.322117
 >> iter 49000, loss: 0.308352
 >> iter 50000, loss: 0.446213
   Number of active neurons: 6
 >> iter 51000, loss: 0.477115
 >> iter 52000, loss: 0.415635
 >> iter 53000, loss: 0.408968
 >> iter 54000, loss: 0.292649
 >> iter 55000, loss: 0.473555
 >> iter 56000, loss: 0.492457
 >> iter 57000, loss: 0.526726
 >> iter 58000, loss: 0.421651
 >> iter 59000, loss: 0.391777
 >> iter 60000, loss: 0.426011
   Number of active neurons: 6
 >> iter 61000, loss: 0.563000
 >> iter 62000, loss: 0.556711
 >> iter 63000, loss: 0.617231
 >> iter 64000, loss: 0.431143
 >> iter 65000, loss: 0.614817
 >> iter 66000, loss: 0.519866
 >> iter 67000, loss: 0.526179
 >> iter 68000, loss: 0.409869
 >> iter 69000, loss: 0.506982
 >> iter 70000, loss: 0.580335
   Number of active neurons: 5
 >> iter 71000, loss: 0.776130
 >> iter 72000, loss: 0.395843
 >> iter 73000, loss: 0.516647
 >> iter 74000, loss: 0.457710
 >> iter 75000, loss: 0.418007
 >> iter 76000, loss: 0.296019
 >> iter 77000, loss: 0.367884
 >> iter 78000, loss: 0.449675
 >> iter 79000, loss: 0.553962
 >> iter 80000, loss: 0.534676
   Number of active neurons: 5
 >> iter 81000, loss: 0.428098
 >> iter 82000, loss: 0.471437
 >> iter 83000, loss: 0.489832
 >> iter 84000, loss: 0.491523
 >> iter 85000, loss: 0.415225
 >> iter 86000, loss: 0.410168
 >> iter 87000, loss: 0.458939
 >> iter 88000, loss: 0.421960
 >> iter 89000, loss: 0.497330
 >> iter 90000, loss: 0.440017
   Number of active neurons: 5
 >> iter 91000, loss: 0.598999
 >> iter 92000, loss: 0.441595
 >> iter 93000, loss: 0.327348
 >> iter 94000, loss: 0.377665
 >> iter 95000, loss: 0.495998
 >> iter 96000, loss: 0.444315
 >> iter 97000, loss: 0.488797
 >> iter 98000, loss: 0.469564
 >> iter 99000, loss: 0.374664
 >> iter 100000, loss: 0.441845
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

