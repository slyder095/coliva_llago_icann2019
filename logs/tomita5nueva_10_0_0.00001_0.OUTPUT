 > Problema: tomita5nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 1e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.585921
 >> iter 2000, loss: 10.512291
 >> iter 3000, loss: 8.642676
 >> iter 4000, loss: 7.936943
 >> iter 5000, loss: 7.686463
 >> iter 6000, loss: 7.566622
 >> iter 7000, loss: 7.461885
 >> iter 8000, loss: 6.868023
 >> iter 9000, loss: 5.919781
 >> iter 10000, loss: 2.347918
   Number of active neurons: 8
 >> iter 11000, loss: 0.889410
 >> iter 12000, loss: 0.344336
 >> iter 13000, loss: 0.140061
 >> iter 14000, loss: 0.062596
 >> iter 15000, loss: 0.032698
 >> iter 16000, loss: 0.020559
 >> iter 17000, loss: 0.015381
 >> iter 18000, loss: 0.012778
 >> iter 19000, loss: 0.011399
 >> iter 20000, loss: 0.010410
   Number of active neurons: 8
 >> iter 21000, loss: 0.009774
 >> iter 22000, loss: 0.009183
 >> iter 23000, loss: 0.008775
 >> iter 24000, loss: 0.008348
 >> iter 25000, loss: 0.008056
 >> iter 26000, loss: 0.007713
 >> iter 27000, loss: 0.007486
 >> iter 28000, loss: 0.007182
 >> iter 29000, loss: 0.006988
 >> iter 30000, loss: 0.006705
   Number of active neurons: 8
 >> iter 31000, loss: 0.006547
 >> iter 32000, loss: 0.006262
 >> iter 33000, loss: 0.006122
 >> iter 34000, loss: 0.005796
 >> iter 35000, loss: 0.005711
 >> iter 36000, loss: 0.005386
 >> iter 37000, loss: 0.005303
 >> iter 38000, loss: 0.005083
 >> iter 39000, loss: 0.005013
 >> iter 40000, loss: 0.004909
   Number of active neurons: 8
 >> iter 41000, loss: 0.004878
 >> iter 42000, loss: 0.004821
 >> iter 43000, loss: 0.004811
 >> iter 44000, loss: 0.004779
 >> iter 45000, loss: 0.004781
 >> iter 46000, loss: 0.004761
 >> iter 47000, loss: 0.004767
 >> iter 48000, loss: 0.004750
 >> iter 49000, loss: 0.004760
 >> iter 50000, loss: 0.004748
   Number of active neurons: 8
 >> iter 51000, loss: 0.004759
 >> iter 52000, loss: 0.004747
 >> iter 53000, loss: 0.004758
 >> iter 54000, loss: 0.004749
 >> iter 55000, loss: 0.004757
 >> iter 56000, loss: 0.004748
 >> iter 57000, loss: 0.004755
 >> iter 58000, loss: 0.004744
 >> iter 59000, loss: 0.004749
 >> iter 60000, loss: 0.004743
   Number of active neurons: 8
 >> iter 61000, loss: 0.004749
 >> iter 62000, loss: 0.004744
 >> iter 63000, loss: 0.004751
 >> iter 64000, loss: 0.004749
 >> iter 65000, loss: 0.004756
 >> iter 66000, loss: 0.004753
 >> iter 67000, loss: 0.004759
 >> iter 68000, loss: 0.004757
 >> iter 69000, loss: 0.004761
 >> iter 70000, loss: 0.004760
   Number of active neurons: 8
 >> iter 71000, loss: 0.004764
 >> iter 72000, loss: 0.004764
 >> iter 73000, loss: 0.004767
 >> iter 74000, loss: 0.004767
 >> iter 75000, loss: 0.004771
 >> iter 76000, loss: 0.004772
 >> iter 77000, loss: 0.004775
 >> iter 78000, loss: 0.004777
 >> iter 79000, loss: 0.004780
 >> iter 80000, loss: 0.004783
   Number of active neurons: 8
 >> iter 81000, loss: 0.004785
 >> iter 82000, loss: 0.004790
 >> iter 83000, loss: 0.004792
 >> iter 84000, loss: 0.004797
 >> iter 85000, loss: 0.004798
 >> iter 86000, loss: 0.004807
 >> iter 87000, loss: 0.004806
 >> iter 88000, loss: 0.004816
 >> iter 89000, loss: 0.004817
 >> iter 90000, loss: 0.004829
   Number of active neurons: 8
 >> iter 91000, loss: 0.004829
 >> iter 92000, loss: 0.004841
 >> iter 93000, loss: 0.004839
 >> iter 94000, loss: 0.004849
 >> iter 95000, loss: 0.004848
 >> iter 96000, loss: 0.004856
 >> iter 97000, loss: 0.004856
 >> iter 98000, loss: 0.004863
 >> iter 99000, loss: 0.004860
 >> iter 100000, loss: 0.004868
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.528852
 >> iter 2000, loss: 10.499269
 >> iter 3000, loss: 8.645175
 >> iter 4000, loss: 7.936964
 >> iter 5000, loss: 7.683158
 >> iter 6000, loss: 7.395966
 >> iter 7000, loss: 6.757377
 >> iter 8000, loss: 2.874869
 >> iter 9000, loss: 1.098330
 >> iter 10000, loss: 0.427769
   Number of active neurons: 10
 >> iter 11000, loss: 0.174847
 >> iter 12000, loss: 0.078021
 >> iter 13000, loss: 0.040411
 >> iter 14000, loss: 0.024925
 >> iter 15000, loss: 0.018288
 >> iter 16000, loss: 0.014915
 >> iter 17000, loss: 0.013152
 >> iter 18000, loss: 0.011907
 >> iter 19000, loss: 0.011127
 >> iter 20000, loss: 0.010422
   Number of active neurons: 10
 >> iter 21000, loss: 0.009964
 >> iter 22000, loss: 0.009490
 >> iter 23000, loss: 0.009181
 >> iter 24000, loss: 0.008822
 >> iter 25000, loss: 0.008602
 >> iter 26000, loss: 0.008320
 >> iter 27000, loss: 0.008159
 >> iter 28000, loss: 0.007928
 >> iter 29000, loss: 0.007815
 >> iter 30000, loss: 0.007631
   Number of active neurons: 10
 >> iter 31000, loss: 0.007556
 >> iter 32000, loss: 0.007406
 >> iter 33000, loss: 0.007352
 >> iter 34000, loss: 0.007226
 >> iter 35000, loss: 0.007192
 >> iter 36000, loss: 0.007081
 >> iter 37000, loss: 0.007052
 >> iter 38000, loss: 0.006951
 >> iter 39000, loss: 0.006930
 >> iter 40000, loss: 0.006836
   Number of active neurons: 10
 >> iter 41000, loss: 0.006820
 >> iter 42000, loss: 0.006728
 >> iter 43000, loss: 0.006711
 >> iter 44000, loss: 0.006626
 >> iter 45000, loss: 0.006612
 >> iter 46000, loss: 0.006538
 >> iter 47000, loss: 0.006525
 >> iter 48000, loss: 0.006453
 >> iter 49000, loss: 0.006446
 >> iter 50000, loss: 0.006378
   Number of active neurons: 8
 >> iter 51000, loss: 0.006373
 >> iter 52000, loss: 0.006315
 >> iter 53000, loss: 0.006323
 >> iter 54000, loss: 0.006269
 >> iter 55000, loss: 0.006282
 >> iter 56000, loss: 0.006230
 >> iter 57000, loss: 0.006244
 >> iter 58000, loss: 0.006192
 >> iter 59000, loss: 0.006203
 >> iter 60000, loss: 0.006154
   Number of active neurons: 8
 >> iter 61000, loss: 0.006164
 >> iter 62000, loss: 0.006116
 >> iter 63000, loss: 0.006124
 >> iter 64000, loss: 0.006079
 >> iter 65000, loss: 0.006084
 >> iter 66000, loss: 0.006037
 >> iter 67000, loss: 0.006039
 >> iter 68000, loss: 0.005994
 >> iter 69000, loss: 0.005995
 >> iter 70000, loss: 0.005948
   Number of active neurons: 8
 >> iter 71000, loss: 0.005944
 >> iter 72000, loss: 0.005896
 >> iter 73000, loss: 0.005888
 >> iter 74000, loss: 0.005838
 >> iter 75000, loss: 0.005829
 >> iter 76000, loss: 0.005777
 >> iter 77000, loss: 0.005765
 >> iter 78000, loss: 0.005713
 >> iter 79000, loss: 0.005697
 >> iter 80000, loss: 0.005648
   Number of active neurons: 8
 >> iter 81000, loss: 0.005631
 >> iter 82000, loss: 0.005588
 >> iter 83000, loss: 0.005573
 >> iter 84000, loss: 0.005534
 >> iter 85000, loss: 0.005520
 >> iter 86000, loss: 0.005485
 >> iter 87000, loss: 0.005471
 >> iter 88000, loss: 0.005438
 >> iter 89000, loss: 0.005423
 >> iter 90000, loss: 0.005394
   Number of active neurons: 8
 >> iter 91000, loss: 0.005378
 >> iter 92000, loss: 0.005352
 >> iter 93000, loss: 0.005336
 >> iter 94000, loss: 0.005314
 >> iter 95000, loss: 0.005301
 >> iter 96000, loss: 0.005284
 >> iter 97000, loss: 0.005273
 >> iter 98000, loss: 0.005259
 >> iter 99000, loss: 0.005249
 >> iter 100000, loss: 0.005238
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.553580
 >> iter 2000, loss: 10.491563
 >> iter 3000, loss: 8.625334
 >> iter 4000, loss: 7.917368
 >> iter 5000, loss: 7.664942
 >> iter 6000, loss: 7.545252
 >> iter 7000, loss: 7.516356
 >> iter 8000, loss: 7.295243
 >> iter 9000, loss: 6.605083
 >> iter 10000, loss: 5.837051
   Number of active neurons: 7
 >> iter 11000, loss: 4.873303
 >> iter 12000, loss: 1.971996
 >> iter 13000, loss: 0.786390
 >> iter 14000, loss: 0.354241
 >> iter 15000, loss: 0.161214
 >> iter 16000, loss: 0.083024
 >> iter 17000, loss: 0.049880
 >> iter 18000, loss: 0.034831
 >> iter 19000, loss: 0.026899
 >> iter 20000, loss: 0.022511
   Number of active neurons: 7
 >> iter 21000, loss: 0.019514
 >> iter 22000, loss: 0.017596
 >> iter 23000, loss: 0.016045
 >> iter 24000, loss: 0.014956
 >> iter 25000, loss: 0.014001
 >> iter 26000, loss: 0.013287
 >> iter 27000, loss: 0.012633
 >> iter 28000, loss: 0.012128
 >> iter 29000, loss: 0.011652
 >> iter 30000, loss: 0.011273
   Number of active neurons: 7
 >> iter 31000, loss: 0.010908
 >> iter 32000, loss: 0.010621
 >> iter 33000, loss: 0.010331
 >> iter 34000, loss: 0.010108
 >> iter 35000, loss: 0.009874
 >> iter 36000, loss: 0.009698
 >> iter 37000, loss: 0.009507
 >> iter 38000, loss: 0.009362
 >> iter 39000, loss: 0.009203
 >> iter 40000, loss: 0.009088
   Number of active neurons: 7
 >> iter 41000, loss: 0.008958
 >> iter 42000, loss: 0.008884
 >> iter 43000, loss: 0.008770
 >> iter 44000, loss: 0.008711
 >> iter 45000, loss: 0.008611
 >> iter 46000, loss: 0.008566
 >> iter 47000, loss: 0.008476
 >> iter 48000, loss: 0.008440
 >> iter 49000, loss: 0.008357
 >> iter 50000, loss: 0.008322
   Number of active neurons: 7
 >> iter 51000, loss: 0.008250
 >> iter 52000, loss: 0.008216
 >> iter 53000, loss: 0.008153
 >> iter 54000, loss: 0.008122
 >> iter 55000, loss: 0.008062
 >> iter 56000, loss: 0.008032
 >> iter 57000, loss: 0.007981
 >> iter 58000, loss: 0.007951
 >> iter 59000, loss: 0.007912
 >> iter 60000, loss: 0.007880
   Number of active neurons: 7
 >> iter 61000, loss: 0.007844
 >> iter 62000, loss: 0.007814
 >> iter 63000, loss: 0.007782
 >> iter 64000, loss: 0.007753
 >> iter 65000, loss: 0.007722
 >> iter 66000, loss: 0.007694
 >> iter 67000, loss: 0.007664
 >> iter 68000, loss: 0.007640
 >> iter 69000, loss: 0.007616
 >> iter 70000, loss: 0.007595
   Number of active neurons: 7
 >> iter 71000, loss: 0.007573
 >> iter 72000, loss: 0.007552
 >> iter 73000, loss: 0.007534
 >> iter 74000, loss: 0.007512
 >> iter 75000, loss: 0.007499
 >> iter 76000, loss: 0.007477
 >> iter 77000, loss: 0.007469
 >> iter 78000, loss: 0.007443
 >> iter 79000, loss: 0.007439
 >> iter 80000, loss: 0.007412
   Number of active neurons: 7
 >> iter 81000, loss: 0.007408
 >> iter 82000, loss: 0.007382
 >> iter 83000, loss: 0.007381
 >> iter 84000, loss: 0.007354
 >> iter 85000, loss: 0.007355
 >> iter 86000, loss: 0.007325
 >> iter 87000, loss: 0.007329
 >> iter 88000, loss: 0.007303
 >> iter 89000, loss: 0.007307
 >> iter 90000, loss: 0.007281
   Number of active neurons: 7
 >> iter 91000, loss: 0.007284
 >> iter 92000, loss: 0.007257
 >> iter 93000, loss: 0.007262
 >> iter 94000, loss: 0.007232
 >> iter 95000, loss: 0.007233
 >> iter 96000, loss: 0.007203
 >> iter 97000, loss: 0.007208
 >> iter 98000, loss: 0.007175
 >> iter 99000, loss: 0.007176
 >> iter 100000, loss: 0.007143
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 3.7930804613
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.535176
 >> iter 2000, loss: 10.483071
 >> iter 3000, loss: 8.620815
 >> iter 4000, loss: 7.913373
 >> iter 5000, loss: 7.618323
 >> iter 6000, loss: 6.856309
 >> iter 7000, loss: 5.895626
 >> iter 8000, loss: 2.560913
 >> iter 9000, loss: 0.975136
 >> iter 10000, loss: 0.379850
   Number of active neurons: 7
 >> iter 11000, loss: 0.155766
 >> iter 12000, loss: 0.070339
 >> iter 13000, loss: 0.037056
 >> iter 14000, loss: 0.023449
 >> iter 15000, loss: 0.017505
 >> iter 16000, loss: 0.014555
 >> iter 17000, loss: 0.012913
 >> iter 18000, loss: 0.011827
 >> iter 19000, loss: 0.011063
 >> iter 20000, loss: 0.010451
   Number of active neurons: 7
 >> iter 21000, loss: 0.009967
 >> iter 22000, loss: 0.009558
 >> iter 23000, loss: 0.009214
 >> iter 24000, loss: 0.008917
 >> iter 25000, loss: 0.008662
 >> iter 26000, loss: 0.008437
 >> iter 27000, loss: 0.008241
 >> iter 28000, loss: 0.008067
 >> iter 29000, loss: 0.007913
 >> iter 30000, loss: 0.007772
   Number of active neurons: 7
 >> iter 31000, loss: 0.007650
 >> iter 32000, loss: 0.007539
 >> iter 33000, loss: 0.007438
 >> iter 34000, loss: 0.007346
 >> iter 35000, loss: 0.007264
 >> iter 36000, loss: 0.007188
 >> iter 37000, loss: 0.007120
 >> iter 38000, loss: 0.007059
 >> iter 39000, loss: 0.006996
 >> iter 40000, loss: 0.006947
   Number of active neurons: 7
 >> iter 41000, loss: 0.006890
 >> iter 42000, loss: 0.006851
 >> iter 43000, loss: 0.006797
 >> iter 44000, loss: 0.006765
 >> iter 45000, loss: 0.006713
 >> iter 46000, loss: 0.006691
 >> iter 47000, loss: 0.006644
 >> iter 48000, loss: 0.006624
 >> iter 49000, loss: 0.006584
 >> iter 50000, loss: 0.006568
   Number of active neurons: 7
 >> iter 51000, loss: 0.006531
 >> iter 52000, loss: 0.006519
 >> iter 53000, loss: 0.006485
 >> iter 54000, loss: 0.006472
 >> iter 55000, loss: 0.006440
 >> iter 56000, loss: 0.006430
 >> iter 57000, loss: 0.006401
 >> iter 58000, loss: 0.006393
 >> iter 59000, loss: 0.006364
 >> iter 60000, loss: 0.006361
   Number of active neurons: 7
 >> iter 61000, loss: 0.006333
 >> iter 62000, loss: 0.006328
 >> iter 63000, loss: 0.006301
 >> iter 64000, loss: 0.006296
 >> iter 65000, loss: 0.006269
 >> iter 66000, loss: 0.006263
 >> iter 67000, loss: 0.006237
 >> iter 68000, loss: 0.006234
 >> iter 69000, loss: 0.006210
 >> iter 70000, loss: 0.006211
   Number of active neurons: 7
 >> iter 71000, loss: 0.006189
 >> iter 72000, loss: 0.006191
 >> iter 73000, loss: 0.006171
 >> iter 74000, loss: 0.006172
 >> iter 75000, loss: 0.006154
 >> iter 76000, loss: 0.006156
 >> iter 77000, loss: 0.006138
 >> iter 78000, loss: 0.006140
 >> iter 79000, loss: 0.006124
 >> iter 80000, loss: 0.006125
   Number of active neurons: 7
 >> iter 81000, loss: 0.006107
 >> iter 82000, loss: 0.006111
 >> iter 83000, loss: 0.006094
 >> iter 84000, loss: 0.006095
 >> iter 85000, loss: 0.006079
 >> iter 86000, loss: 0.006082
 >> iter 87000, loss: 0.006066
 >> iter 88000, loss: 0.006069
 >> iter 89000, loss: 0.006050
 >> iter 90000, loss: 0.006055
   Number of active neurons: 7
 >> iter 91000, loss: 0.006036
 >> iter 92000, loss: 0.006042
 >> iter 93000, loss: 0.006022
 >> iter 94000, loss: 0.006026
 >> iter 95000, loss: 0.006007
 >> iter 96000, loss: 0.006012
 >> iter 97000, loss: 0.005994
 >> iter 98000, loss: 0.005997
 >> iter 99000, loss: 0.005977
 >> iter 100000, loss: 0.005985
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.564367
 >> iter 2000, loss: 10.487511
 >> iter 3000, loss: 8.618978
 >> iter 4000, loss: 7.914894
 >> iter 5000, loss: 7.666563
 >> iter 6000, loss: 7.552892
 >> iter 7000, loss: 7.575368
 >> iter 8000, loss: 7.350048
 >> iter 9000, loss: 3.540177
 >> iter 10000, loss: 1.337006
   Number of active neurons: 9
 >> iter 11000, loss: 0.512143
 >> iter 12000, loss: 0.203071
 >> iter 13000, loss: 0.086535
 >> iter 14000, loss: 0.041778
 >> iter 15000, loss: 0.024153
 >> iter 16000, loss: 0.016731
 >> iter 17000, loss: 0.013396
 >> iter 18000, loss: 0.011603
 >> iter 19000, loss: 0.010593
 >> iter 20000, loss: 0.009844
   Number of active neurons: 9
 >> iter 21000, loss: 0.009351
 >> iter 22000, loss: 0.008899
 >> iter 23000, loss: 0.008592
 >> iter 24000, loss: 0.008272
 >> iter 25000, loss: 0.008064
 >> iter 26000, loss: 0.007818
 >> iter 27000, loss: 0.007671
 >> iter 28000, loss: 0.007474
 >> iter 29000, loss: 0.007366
 >> iter 30000, loss: 0.007203
   Number of active neurons: 9
 >> iter 31000, loss: 0.007123
 >> iter 32000, loss: 0.006987
 >> iter 33000, loss: 0.006929
 >> iter 34000, loss: 0.006811
 >> iter 35000, loss: 0.006769
 >> iter 36000, loss: 0.006669
 >> iter 37000, loss: 0.006636
 >> iter 38000, loss: 0.006546
 >> iter 39000, loss: 0.006522
 >> iter 40000, loss: 0.006435
   Number of active neurons: 9
 >> iter 41000, loss: 0.006415
 >> iter 42000, loss: 0.006337
 >> iter 43000, loss: 0.006326
 >> iter 44000, loss: 0.006255
 >> iter 45000, loss: 0.006251
 >> iter 46000, loss: 0.006187
 >> iter 47000, loss: 0.006186
 >> iter 48000, loss: 0.006122
 >> iter 49000, loss: 0.006125
 >> iter 50000, loss: 0.006065
   Number of active neurons: 9
 >> iter 51000, loss: 0.006073
 >> iter 52000, loss: 0.006017
 >> iter 53000, loss: 0.006027
 >> iter 54000, loss: 0.005976
 >> iter 55000, loss: 0.005987
 >> iter 56000, loss: 0.005940
 >> iter 57000, loss: 0.005952
 >> iter 58000, loss: 0.005908
 >> iter 59000, loss: 0.005919
 >> iter 60000, loss: 0.005879
   Number of active neurons: 9
 >> iter 61000, loss: 0.005891
 >> iter 62000, loss: 0.005852
 >> iter 63000, loss: 0.005864
 >> iter 64000, loss: 0.005830
 >> iter 65000, loss: 0.005842
 >> iter 66000, loss: 0.005811
 >> iter 67000, loss: 0.005823
 >> iter 68000, loss: 0.005793
 >> iter 69000, loss: 0.005806
 >> iter 70000, loss: 0.005779
   Number of active neurons: 9
 >> iter 71000, loss: 0.005791
 >> iter 72000, loss: 0.005765
 >> iter 73000, loss: 0.005779
 >> iter 74000, loss: 0.005755
 >> iter 75000, loss: 0.005768
 >> iter 76000, loss: 0.005744
 >> iter 77000, loss: 0.005756
 >> iter 78000, loss: 0.005733
 >> iter 79000, loss: 0.005744
 >> iter 80000, loss: 0.005721
   Number of active neurons: 9
 >> iter 81000, loss: 0.005731
 >> iter 82000, loss: 0.005710
 >> iter 83000, loss: 0.005719
 >> iter 84000, loss: 0.005698
 >> iter 85000, loss: 0.005704
 >> iter 86000, loss: 0.005685
 >> iter 87000, loss: 0.005686
 >> iter 88000, loss: 0.005665
 >> iter 89000, loss: 0.005663
 >> iter 90000, loss: 0.005643
   Number of active neurons: 9
 >> iter 91000, loss: 0.005640
 >> iter 92000, loss: 0.005625
 >> iter 93000, loss: 0.005623
 >> iter 94000, loss: 0.005610
 >> iter 95000, loss: 0.005610
 >> iter 96000, loss: 0.005598
 >> iter 97000, loss: 0.005598
 >> iter 98000, loss: 0.005588
 >> iter 99000, loss: 0.005589
 >> iter 100000, loss: 0.005578
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.551164
 >> iter 2000, loss: 10.502795
 >> iter 3000, loss: 8.636970
 >> iter 4000, loss: 7.887131
 >> iter 5000, loss: 6.142415
 >> iter 6000, loss: 2.348647
 >> iter 7000, loss: 0.899176
 >> iter 8000, loss: 0.353582
 >> iter 9000, loss: 0.147379
 >> iter 10000, loss: 0.068217
   Number of active neurons: 9
 >> iter 11000, loss: 0.037047
 >> iter 12000, loss: 0.024044
 >> iter 13000, loss: 0.018209
 >> iter 14000, loss: 0.015171
 >> iter 15000, loss: 0.013411
 >> iter 16000, loss: 0.012183
 >> iter 17000, loss: 0.011309
 >> iter 18000, loss: 0.010583
 >> iter 19000, loss: 0.010025
 >> iter 20000, loss: 0.009528
   Number of active neurons: 9
 >> iter 21000, loss: 0.009143
 >> iter 22000, loss: 0.008785
 >> iter 23000, loss: 0.008509
 >> iter 24000, loss: 0.008240
 >> iter 25000, loss: 0.008040
 >> iter 26000, loss: 0.007832
 >> iter 27000, loss: 0.007681
 >> iter 28000, loss: 0.007514
 >> iter 29000, loss: 0.007400
 >> iter 30000, loss: 0.007265
   Number of active neurons: 9
 >> iter 31000, loss: 0.007178
 >> iter 32000, loss: 0.007067
 >> iter 33000, loss: 0.007002
 >> iter 34000, loss: 0.006906
 >> iter 35000, loss: 0.006855
 >> iter 36000, loss: 0.006772
 >> iter 37000, loss: 0.006728
 >> iter 38000, loss: 0.006656
 >> iter 39000, loss: 0.006623
 >> iter 40000, loss: 0.006560
   Number of active neurons: 9
 >> iter 41000, loss: 0.006535
 >> iter 42000, loss: 0.006478
 >> iter 43000, loss: 0.006459
 >> iter 44000, loss: 0.006409
 >> iter 45000, loss: 0.006395
 >> iter 46000, loss: 0.006352
 >> iter 47000, loss: 0.006342
 >> iter 48000, loss: 0.006302
 >> iter 49000, loss: 0.006296
 >> iter 50000, loss: 0.006260
   Number of active neurons: 9
 >> iter 51000, loss: 0.006258
 >> iter 52000, loss: 0.006226
 >> iter 53000, loss: 0.006226
 >> iter 54000, loss: 0.006195
 >> iter 55000, loss: 0.006196
 >> iter 56000, loss: 0.006169
 >> iter 57000, loss: 0.006170
 >> iter 58000, loss: 0.006143
 >> iter 59000, loss: 0.006142
 >> iter 60000, loss: 0.006118
   Number of active neurons: 9
 >> iter 61000, loss: 0.006115
 >> iter 62000, loss: 0.006091
 >> iter 63000, loss: 0.006089
 >> iter 64000, loss: 0.006066
 >> iter 65000, loss: 0.006063
 >> iter 66000, loss: 0.006039
 >> iter 67000, loss: 0.006032
 >> iter 68000, loss: 0.006007
 >> iter 69000, loss: 0.006000
 >> iter 70000, loss: 0.005973
   Number of active neurons: 9
 >> iter 71000, loss: 0.005964
 >> iter 72000, loss: 0.005937
 >> iter 73000, loss: 0.005928
 >> iter 74000, loss: 0.005901
 >> iter 75000, loss: 0.005891
 >> iter 76000, loss: 0.005867
 >> iter 77000, loss: 0.005858
 >> iter 78000, loss: 0.005837
 >> iter 79000, loss: 0.005831
 >> iter 80000, loss: 0.005812
   Number of active neurons: 9
 >> iter 81000, loss: 0.005802
 >> iter 82000, loss: 0.005784
 >> iter 83000, loss: 0.005772
 >> iter 84000, loss: 0.005756
 >> iter 85000, loss: 0.005744
 >> iter 86000, loss: 0.005731
 >> iter 87000, loss: 0.005719
 >> iter 88000, loss: 0.005708
 >> iter 89000, loss: 0.005695
 >> iter 90000, loss: 0.005687
   Number of active neurons: 8
 >> iter 91000, loss: 0.005675
 >> iter 92000, loss: 0.005670
 >> iter 93000, loss: 0.005656
 >> iter 94000, loss: 0.005650
 >> iter 95000, loss: 0.005636
 >> iter 96000, loss: 0.005630
 >> iter 97000, loss: 0.005616
 >> iter 98000, loss: 0.005612
 >> iter 99000, loss: 0.005601
 >> iter 100000, loss: 0.005597
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.550642
 >> iter 2000, loss: 10.511595
 >> iter 3000, loss: 8.656123
 >> iter 4000, loss: 7.951350
 >> iter 5000, loss: 7.697431
 >> iter 6000, loss: 7.294757
 >> iter 7000, loss: 4.517863
 >> iter 8000, loss: 1.739703
 >> iter 9000, loss: 0.677366
 >> iter 10000, loss: 0.274085
   Number of active neurons: 8
 >> iter 11000, loss: 0.120077
 >> iter 12000, loss: 0.059815
 >> iter 13000, loss: 0.035507
 >> iter 14000, loss: 0.024859
 >> iter 15000, loss: 0.019856
 >> iter 16000, loss: 0.017011
 >> iter 17000, loss: 0.015326
 >> iter 18000, loss: 0.014038
 >> iter 19000, loss: 0.013151
 >> iter 20000, loss: 0.012346
   Number of active neurons: 8
 >> iter 21000, loss: 0.011773
 >> iter 22000, loss: 0.011200
 >> iter 23000, loss: 0.010796
 >> iter 24000, loss: 0.010357
 >> iter 25000, loss: 0.010062
 >> iter 26000, loss: 0.009716
 >> iter 27000, loss: 0.009497
 >> iter 28000, loss: 0.009223
 >> iter 29000, loss: 0.009060
 >> iter 30000, loss: 0.008834
   Number of active neurons: 8
 >> iter 31000, loss: 0.008710
 >> iter 32000, loss: 0.008522
 >> iter 33000, loss: 0.008427
 >> iter 34000, loss: 0.008267
 >> iter 35000, loss: 0.008199
 >> iter 36000, loss: 0.008062
 >> iter 37000, loss: 0.008009
 >> iter 38000, loss: 0.007893
 >> iter 39000, loss: 0.007855
 >> iter 40000, loss: 0.007755
   Number of active neurons: 8
 >> iter 41000, loss: 0.007727
 >> iter 42000, loss: 0.007639
 >> iter 43000, loss: 0.007615
 >> iter 44000, loss: 0.007539
 >> iter 45000, loss: 0.007516
 >> iter 46000, loss: 0.007453
 >> iter 47000, loss: 0.007434
 >> iter 48000, loss: 0.007378
 >> iter 49000, loss: 0.007364
 >> iter 50000, loss: 0.007315
   Number of active neurons: 8
 >> iter 51000, loss: 0.007309
 >> iter 52000, loss: 0.007262
 >> iter 53000, loss: 0.007259
 >> iter 54000, loss: 0.007214
 >> iter 55000, loss: 0.007214
 >> iter 56000, loss: 0.007174
 >> iter 57000, loss: 0.007173
 >> iter 58000, loss: 0.007134
 >> iter 59000, loss: 0.007134
 >> iter 60000, loss: 0.007098
   Number of active neurons: 8
 >> iter 61000, loss: 0.007098
 >> iter 62000, loss: 0.007064
 >> iter 63000, loss: 0.007064
 >> iter 64000, loss: 0.007029
 >> iter 65000, loss: 0.007028
 >> iter 66000, loss: 0.006994
 >> iter 67000, loss: 0.006993
 >> iter 68000, loss: 0.006960
 >> iter 69000, loss: 0.006959
 >> iter 70000, loss: 0.006926
   Number of active neurons: 8
 >> iter 71000, loss: 0.006924
 >> iter 72000, loss: 0.006897
 >> iter 73000, loss: 0.006911
 >> iter 74000, loss: 0.006893
 >> iter 75000, loss: 0.006907
 >> iter 76000, loss: 0.006890
 >> iter 77000, loss: 0.006905
 >> iter 78000, loss: 0.006885
 >> iter 79000, loss: 0.006896
 >> iter 80000, loss: 0.006877
   Number of active neurons: 8
 >> iter 81000, loss: 0.006885
 >> iter 82000, loss: 0.006862
 >> iter 83000, loss: 0.006866
 >> iter 84000, loss: 0.006842
 >> iter 85000, loss: 0.006841
 >> iter 86000, loss: 0.006817
 >> iter 87000, loss: 0.006812
 >> iter 88000, loss: 0.006790
 >> iter 89000, loss: 0.006783
 >> iter 90000, loss: 0.006765
   Number of active neurons: 8
 >> iter 91000, loss: 0.006752
 >> iter 92000, loss: 0.006735
 >> iter 93000, loss: 0.006720
 >> iter 94000, loss: 0.006704
 >> iter 95000, loss: 0.006687
 >> iter 96000, loss: 0.006671
 >> iter 97000, loss: 0.006654
 >> iter 98000, loss: 0.006640
 >> iter 99000, loss: 0.006623
 >> iter 100000, loss: 0.006610
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 25.1849876675
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.539458
 >> iter 2000, loss: 10.489004
 >> iter 3000, loss: 8.626613
 >> iter 4000, loss: 7.918617
 >> iter 5000, loss: 7.683236
 >> iter 6000, loss: 7.474186
 >> iter 7000, loss: 6.569404
 >> iter 8000, loss: 2.487490
 >> iter 9000, loss: 0.940216
 >> iter 10000, loss: 0.362276
   Number of active neurons: 9
 >> iter 11000, loss: 0.145815
 >> iter 12000, loss: 0.063949
 >> iter 13000, loss: 0.032439
 >> iter 14000, loss: 0.019850
 >> iter 15000, loss: 0.014532
 >> iter 16000, loss: 0.012012
 >> iter 17000, loss: 0.010689
 >> iter 18000, loss: 0.009837
 >> iter 19000, loss: 0.009276
 >> iter 20000, loss: 0.008816
   Number of active neurons: 9
 >> iter 21000, loss: 0.008481
 >> iter 22000, loss: 0.008169
 >> iter 23000, loss: 0.007936
 >> iter 24000, loss: 0.007703
 >> iter 25000, loss: 0.007535
 >> iter 26000, loss: 0.007356
 >> iter 27000, loss: 0.007235
 >> iter 28000, loss: 0.007094
 >> iter 29000, loss: 0.007004
 >> iter 30000, loss: 0.006891
   Number of active neurons: 6
 >> iter 31000, loss: 0.006825
 >> iter 32000, loss: 0.006733
 >> iter 33000, loss: 0.006686
 >> iter 34000, loss: 0.006604
 >> iter 35000, loss: 0.006566
 >> iter 36000, loss: 0.006493
 >> iter 37000, loss: 0.006464
 >> iter 38000, loss: 0.006399
 >> iter 39000, loss: 0.006374
 >> iter 40000, loss: 0.006309
   Number of active neurons: 6
 >> iter 41000, loss: 0.006285
 >> iter 42000, loss: 0.006223
 >> iter 43000, loss: 0.006203
 >> iter 44000, loss: 0.006143
 >> iter 45000, loss: 0.006127
 >> iter 46000, loss: 0.006070
 >> iter 47000, loss: 0.006055
 >> iter 48000, loss: 0.005999
 >> iter 49000, loss: 0.005987
 >> iter 50000, loss: 0.005930
   Number of active neurons: 6
 >> iter 51000, loss: 0.005914
 >> iter 52000, loss: 0.005857
 >> iter 53000, loss: 0.005838
 >> iter 54000, loss: 0.005783
 >> iter 55000, loss: 0.005759
 >> iter 56000, loss: 0.005708
 >> iter 57000, loss: 0.005687
 >> iter 58000, loss: 0.005643
 >> iter 59000, loss: 0.005622
 >> iter 60000, loss: 0.005583
   Number of active neurons: 6
 >> iter 61000, loss: 0.005564
 >> iter 62000, loss: 0.005527
 >> iter 63000, loss: 0.005510
 >> iter 64000, loss: 0.005477
 >> iter 65000, loss: 0.005459
 >> iter 66000, loss: 0.005427
 >> iter 67000, loss: 0.005408
 >> iter 68000, loss: 0.005376
 >> iter 69000, loss: 0.005353
 >> iter 70000, loss: 0.005321
   Number of active neurons: 6
 >> iter 71000, loss: 0.005299
 >> iter 72000, loss: 0.005270
 >> iter 73000, loss: 0.005249
 >> iter 74000, loss: 0.005224
 >> iter 75000, loss: 0.005204
 >> iter 76000, loss: 0.005182
 >> iter 77000, loss: 0.005162
 >> iter 78000, loss: 0.005141
 >> iter 79000, loss: 0.005122
 >> iter 80000, loss: 0.005104
   Number of active neurons: 6
 >> iter 81000, loss: 0.005086
 >> iter 82000, loss: 0.005070
 >> iter 83000, loss: 0.005050
 >> iter 84000, loss: 0.005035
 >> iter 85000, loss: 0.005013
 >> iter 86000, loss: 0.005002
 >> iter 87000, loss: 0.004979
 >> iter 88000, loss: 0.004967
 >> iter 89000, loss: 0.004943
 >> iter 90000, loss: 0.004933
   Number of active neurons: 6
 >> iter 91000, loss: 0.004908
 >> iter 92000, loss: 0.004902
 >> iter 93000, loss: 0.004878
 >> iter 94000, loss: 0.004873
 >> iter 95000, loss: 0.004853
 >> iter 96000, loss: 0.004849
 >> iter 97000, loss: 0.004830
 >> iter 98000, loss: 0.004827
 >> iter 99000, loss: 0.004809
 >> iter 100000, loss: 0.004807
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.511406
 >> iter 2000, loss: 10.463175
 >> iter 3000, loss: 8.602830
 >> iter 4000, loss: 7.898595
 >> iter 5000, loss: 7.649876
 >> iter 6000, loss: 7.521883
 >> iter 7000, loss: 7.380066
 >> iter 8000, loss: 6.881778
 >> iter 9000, loss: 6.198250
 >> iter 10000, loss: 5.380303
   Number of active neurons: 10
 >> iter 11000, loss: 4.627134
 >> iter 12000, loss: 1.938564
 >> iter 13000, loss: 0.935426
 >> iter 14000, loss: 0.382678
 >> iter 15000, loss: 0.295301
 >> iter 16000, loss: 0.132896
 >> iter 17000, loss: 0.083146
 >> iter 18000, loss: 0.047101
 >> iter 19000, loss: 0.031438
 >> iter 20000, loss: 0.023793
   Number of active neurons: 10
 >> iter 21000, loss: 0.020079
 >> iter 22000, loss: 0.017556
 >> iter 23000, loss: 0.016893
 >> iter 24000, loss: 0.015371
 >> iter 25000, loss: 0.014328
 >> iter 26000, loss: 0.013340
 >> iter 27000, loss: 0.012800
 >> iter 28000, loss: 0.012122
 >> iter 29000, loss: 0.011821
 >> iter 30000, loss: 0.011320
   Number of active neurons: 10
 >> iter 31000, loss: 0.011092
 >> iter 32000, loss: 0.010695
 >> iter 33000, loss: 0.010543
 >> iter 34000, loss: 0.010219
 >> iter 35000, loss: 0.010105
 >> iter 36000, loss: 0.009840
 >> iter 37000, loss: 0.009754
 >> iter 38000, loss: 0.009529
 >> iter 39000, loss: 0.009474
 >> iter 40000, loss: 0.009282
   Number of active neurons: 10
 >> iter 41000, loss: 0.009252
 >> iter 42000, loss: 0.009088
 >> iter 43000, loss: 0.009064
 >> iter 44000, loss: 0.008920
 >> iter 45000, loss: 0.008909
 >> iter 46000, loss: 0.008784
 >> iter 47000, loss: 0.008779
 >> iter 48000, loss: 0.008665
 >> iter 49000, loss: 0.008667
 >> iter 50000, loss: 0.008567
   Number of active neurons: 10
 >> iter 51000, loss: 0.008572
 >> iter 52000, loss: 0.008480
 >> iter 53000, loss: 0.008489
 >> iter 54000, loss: 0.008406
 >> iter 55000, loss: 0.008428
 >> iter 56000, loss: 0.008347
 >> iter 57000, loss: 0.008371
 >> iter 58000, loss: 0.008299
 >> iter 59000, loss: 0.008319
 >> iter 60000, loss: 0.008257
   Number of active neurons: 10
 >> iter 61000, loss: 0.008279
 >> iter 62000, loss: 0.008214
 >> iter 63000, loss: 0.008238
 >> iter 64000, loss: 0.008181
 >> iter 65000, loss: 0.008202
 >> iter 66000, loss: 0.008144
 >> iter 67000, loss: 0.008169
 >> iter 68000, loss: 0.008112
 >> iter 69000, loss: 0.008141
 >> iter 70000, loss: 0.008084
   Number of active neurons: 10
 >> iter 71000, loss: 0.008112
 >> iter 72000, loss: 0.008055
 >> iter 73000, loss: 0.008084
 >> iter 74000, loss: 0.008026
 >> iter 75000, loss: 0.008054
 >> iter 76000, loss: 0.008000
 >> iter 77000, loss: 0.008032
 >> iter 78000, loss: 0.007974
 >> iter 79000, loss: 0.008002
 >> iter 80000, loss: 0.007951
   Number of active neurons: 10
 >> iter 81000, loss: 0.007973
 >> iter 82000, loss: 0.007919
 >> iter 83000, loss: 0.007942
 >> iter 84000, loss: 0.007885
 >> iter 85000, loss: 0.007910
 >> iter 86000, loss: 0.007853
 >> iter 87000, loss: 0.007876
 >> iter 88000, loss: 0.007821
 >> iter 89000, loss: 0.007846
 >> iter 90000, loss: 0.007791
   Number of active neurons: 9
 >> iter 91000, loss: 0.007814
 >> iter 92000, loss: 0.007762
 >> iter 93000, loss: 0.007782
 >> iter 94000, loss: 0.007728
 >> iter 95000, loss: 0.007752
 >> iter 96000, loss: 0.007703
 >> iter 97000, loss: 0.007725
 >> iter 98000, loss: 0.007683
 >> iter 99000, loss: 0.007698
 >> iter 100000, loss: 0.007658
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.566474
 >> iter 2000, loss: 10.486429
 >> iter 3000, loss: 8.612096
 >> iter 4000, loss: 7.902039
 >> iter 5000, loss: 7.650861
 >> iter 6000, loss: 7.542007
 >> iter 7000, loss: 7.512206
 >> iter 8000, loss: 7.484753
 >> iter 9000, loss: 7.487916
 >> iter 10000, loss: 7.471457
   Number of active neurons: 4
 >> iter 11000, loss: 7.501932
 >> iter 12000, loss: 7.160966
 >> iter 13000, loss: 6.201835
 >> iter 14000, loss: 3.917306
 >> iter 15000, loss: 1.531666
 >> iter 16000, loss: 0.610586
 >> iter 17000, loss: 0.256712
 >> iter 18000, loss: 0.119872
 >> iter 19000, loss: 0.064256
 >> iter 20000, loss: 0.042089
   Number of active neurons: 8
 >> iter 21000, loss: 0.030622
 >> iter 22000, loss: 0.026940
 >> iter 23000, loss: 0.022928
 >> iter 24000, loss: 0.020974
 >> iter 25000, loss: 0.018444
 >> iter 26000, loss: 0.017582
 >> iter 27000, loss: 0.015860
 >> iter 28000, loss: 0.014645
 >> iter 29000, loss: 0.013708
 >> iter 30000, loss: 0.013013
   Number of active neurons: 8
 >> iter 31000, loss: 0.012480
 >> iter 32000, loss: 0.012036
 >> iter 33000, loss: 0.011670
 >> iter 34000, loss: 0.011342
 >> iter 35000, loss: 0.011069
 >> iter 36000, loss: 0.010815
 >> iter 37000, loss: 0.010588
 >> iter 38000, loss: 0.010396
 >> iter 39000, loss: 0.010202
 >> iter 40000, loss: 0.010059
   Number of active neurons: 8
 >> iter 41000, loss: 0.009880
 >> iter 42000, loss: 0.009765
 >> iter 43000, loss: 0.009605
 >> iter 44000, loss: 0.009508
 >> iter 45000, loss: 0.009358
 >> iter 46000, loss: 0.009280
 >> iter 47000, loss: 0.009142
 >> iter 48000, loss: 0.009079
 >> iter 49000, loss: 0.008952
 >> iter 50000, loss: 0.008903
   Number of active neurons: 8
 >> iter 51000, loss: 0.008787
 >> iter 52000, loss: 0.008747
 >> iter 53000, loss: 0.008642
 >> iter 54000, loss: 0.008605
 >> iter 55000, loss: 0.008512
 >> iter 56000, loss: 0.008481
 >> iter 57000, loss: 0.008397
 >> iter 58000, loss: 0.008368
 >> iter 59000, loss: 0.008289
 >> iter 60000, loss: 0.008263
   Number of active neurons: 7
 >> iter 61000, loss: 0.008187
 >> iter 62000, loss: 0.008166
 >> iter 63000, loss: 0.008092
 >> iter 64000, loss: 0.008076
 >> iter 65000, loss: 0.008004
 >> iter 66000, loss: 0.007990
 >> iter 67000, loss: 0.007923
 >> iter 68000, loss: 0.007914
 >> iter 69000, loss: 0.007855
 >> iter 70000, loss: 0.007852
   Number of active neurons: 7
 >> iter 71000, loss: 0.007793
 >> iter 72000, loss: 0.007792
 >> iter 73000, loss: 0.007735
 >> iter 74000, loss: 0.007735
 >> iter 75000, loss: 0.007682
 >> iter 76000, loss: 0.007682
 >> iter 77000, loss: 0.007633
 >> iter 78000, loss: 0.007637
 >> iter 79000, loss: 0.007588
 >> iter 80000, loss: 0.007596
   Number of active neurons: 7
 >> iter 81000, loss: 0.007545
 >> iter 82000, loss: 0.007554
 >> iter 83000, loss: 0.007503
 >> iter 84000, loss: 0.007512
 >> iter 85000, loss: 0.007461
 >> iter 86000, loss: 0.007472
 >> iter 87000, loss: 0.007419
 >> iter 88000, loss: 0.007431
 >> iter 89000, loss: 0.007374
 >> iter 90000, loss: 0.007389
   Number of active neurons: 7
 >> iter 91000, loss: 0.007326
 >> iter 92000, loss: 0.007342
 >> iter 93000, loss: 0.007275
 >> iter 94000, loss: 0.007293
 >> iter 95000, loss: 0.007222
 >> iter 96000, loss: 0.007244
 >> iter 97000, loss: 0.007171
 >> iter 98000, loss: 0.007196
 >> iter 99000, loss: 0.007119
 >> iter 100000, loss: 0.007147
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.560677
 >> iter 2000, loss: 10.508440
 >> iter 3000, loss: 8.647719
 >> iter 4000, loss: 7.949234
 >> iter 5000, loss: 7.700943
 >> iter 6000, loss: 7.584873
 >> iter 7000, loss: 7.502733
 >> iter 8000, loss: 7.030039
 >> iter 9000, loss: 4.643377
 >> iter 10000, loss: 1.777968
   Number of active neurons: 9
 >> iter 11000, loss: 0.687689
 >> iter 12000, loss: 0.274973
 >> iter 13000, loss: 0.118248
 >> iter 14000, loss: 0.057153
 >> iter 15000, loss: 0.032876
 >> iter 16000, loss: 0.022276
 >> iter 17000, loss: 0.017476
 >> iter 18000, loss: 0.014722
 >> iter 19000, loss: 0.013191
 >> iter 20000, loss: 0.011975
   Number of active neurons: 9
 >> iter 21000, loss: 0.011224
 >> iter 22000, loss: 0.010488
 >> iter 23000, loss: 0.010033
 >> iter 24000, loss: 0.009519
 >> iter 25000, loss: 0.009225
 >> iter 26000, loss: 0.008844
 >> iter 27000, loss: 0.008653
 >> iter 28000, loss: 0.008360
 >> iter 29000, loss: 0.008239
 >> iter 30000, loss: 0.008000
   Number of active neurons: 9
 >> iter 31000, loss: 0.007914
 >> iter 32000, loss: 0.007717
 >> iter 33000, loss: 0.007658
 >> iter 34000, loss: 0.007494
 >> iter 35000, loss: 0.007457
 >> iter 36000, loss: 0.007320
 >> iter 37000, loss: 0.007297
 >> iter 38000, loss: 0.007178
 >> iter 39000, loss: 0.007166
 >> iter 40000, loss: 0.007061
   Number of active neurons: 9
 >> iter 41000, loss: 0.007060
 >> iter 42000, loss: 0.006969
 >> iter 43000, loss: 0.006974
 >> iter 44000, loss: 0.006893
 >> iter 45000, loss: 0.006901
 >> iter 46000, loss: 0.006833
 >> iter 47000, loss: 0.006843
 >> iter 48000, loss: 0.006779
 >> iter 49000, loss: 0.006795
 >> iter 50000, loss: 0.006740
   Number of active neurons: 9
 >> iter 51000, loss: 0.006757
 >> iter 52000, loss: 0.006703
 >> iter 53000, loss: 0.006722
 >> iter 54000, loss: 0.006664
 >> iter 55000, loss: 0.006682
 >> iter 56000, loss: 0.006628
 >> iter 57000, loss: 0.006648
 >> iter 58000, loss: 0.006597
 >> iter 59000, loss: 0.006613
 >> iter 60000, loss: 0.006568
   Number of active neurons: 9
 >> iter 61000, loss: 0.006581
 >> iter 62000, loss: 0.006537
 >> iter 63000, loss: 0.006549
 >> iter 64000, loss: 0.006509
 >> iter 65000, loss: 0.006519
 >> iter 66000, loss: 0.006479
 >> iter 67000, loss: 0.006488
 >> iter 68000, loss: 0.006451
 >> iter 69000, loss: 0.006461
 >> iter 70000, loss: 0.006426
   Number of active neurons: 9
 >> iter 71000, loss: 0.006437
 >> iter 72000, loss: 0.006403
 >> iter 73000, loss: 0.006419
 >> iter 74000, loss: 0.006384
 >> iter 75000, loss: 0.006404
 >> iter 76000, loss: 0.006370
 >> iter 77000, loss: 0.006393
 >> iter 78000, loss: 0.006360
 >> iter 79000, loss: 0.006384
 >> iter 80000, loss: 0.006349
   Number of active neurons: 9
 >> iter 81000, loss: 0.006371
 >> iter 82000, loss: 0.006340
 >> iter 83000, loss: 0.006365
 >> iter 84000, loss: 0.006332
 >> iter 85000, loss: 0.006360
 >> iter 86000, loss: 0.006327
 >> iter 87000, loss: 0.006359
 >> iter 88000, loss: 0.006326
 >> iter 89000, loss: 0.006356
 >> iter 90000, loss: 0.006325
   Number of active neurons: 9
 >> iter 91000, loss: 0.006353
 >> iter 92000, loss: 0.006324
 >> iter 93000, loss: 0.006352
 >> iter 94000, loss: 0.006322
 >> iter 95000, loss: 0.006351
 >> iter 96000, loss: 0.006325
 >> iter 97000, loss: 0.006349
 >> iter 98000, loss: 0.006324
 >> iter 99000, loss: 0.006342
 >> iter 100000, loss: 0.006324
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.571753
 >> iter 2000, loss: 10.506299
 >> iter 3000, loss: 8.639100
 >> iter 4000, loss: 7.934126
 >> iter 5000, loss: 7.681910
 >> iter 6000, loss: 7.663766
 >> iter 7000, loss: 7.490965
 >> iter 8000, loss: 6.996883
 >> iter 9000, loss: 3.005462
 >> iter 10000, loss: 1.127439
   Number of active neurons: 9
 >> iter 11000, loss: 0.428590
 >> iter 12000, loss: 0.168131
 >> iter 13000, loss: 0.070522
 >> iter 14000, loss: 0.033414
 >> iter 15000, loss: 0.019001
 >> iter 16000, loss: 0.013085
 >> iter 17000, loss: 0.010510
 >> iter 18000, loss: 0.009191
 >> iter 19000, loss: 0.008475
 >> iter 20000, loss: 0.007965
   Number of active neurons: 9
 >> iter 21000, loss: 0.007633
 >> iter 22000, loss: 0.007333
 >> iter 23000, loss: 0.007127
 >> iter 24000, loss: 0.006915
 >> iter 25000, loss: 0.006774
 >> iter 26000, loss: 0.006613
 >> iter 27000, loss: 0.006514
 >> iter 28000, loss: 0.006389
 >> iter 29000, loss: 0.006318
 >> iter 30000, loss: 0.006218
   Number of active neurons: 9
 >> iter 31000, loss: 0.006166
 >> iter 32000, loss: 0.006082
 >> iter 33000, loss: 0.006043
 >> iter 34000, loss: 0.005971
 >> iter 35000, loss: 0.005942
 >> iter 36000, loss: 0.005879
 >> iter 37000, loss: 0.005857
 >> iter 38000, loss: 0.005802
 >> iter 39000, loss: 0.005785
 >> iter 40000, loss: 0.005734
   Number of active neurons: 9
 >> iter 41000, loss: 0.005722
 >> iter 42000, loss: 0.005678
 >> iter 43000, loss: 0.005670
 >> iter 44000, loss: 0.005630
 >> iter 45000, loss: 0.005627
 >> iter 46000, loss: 0.005591
 >> iter 47000, loss: 0.005589
 >> iter 48000, loss: 0.005554
 >> iter 49000, loss: 0.005555
 >> iter 50000, loss: 0.005522
   Number of active neurons: 9
 >> iter 51000, loss: 0.005525
 >> iter 52000, loss: 0.005490
 >> iter 53000, loss: 0.005488
 >> iter 54000, loss: 0.005458
 >> iter 55000, loss: 0.005455
 >> iter 56000, loss: 0.005429
 >> iter 57000, loss: 0.005427
 >> iter 58000, loss: 0.005404
 >> iter 59000, loss: 0.005401
 >> iter 60000, loss: 0.005381
   Number of active neurons: 9
 >> iter 61000, loss: 0.005380
 >> iter 62000, loss: 0.005363
 >> iter 63000, loss: 0.005366
 >> iter 64000, loss: 0.005353
 >> iter 65000, loss: 0.005355
 >> iter 66000, loss: 0.005343
 >> iter 67000, loss: 0.005347
 >> iter 68000, loss: 0.005335
 >> iter 69000, loss: 0.005335
 >> iter 70000, loss: 0.005322
   Number of active neurons: 9
 >> iter 71000, loss: 0.005322
 >> iter 72000, loss: 0.005310
 >> iter 73000, loss: 0.005308
 >> iter 74000, loss: 0.005296
 >> iter 75000, loss: 0.005292
 >> iter 76000, loss: 0.005283
 >> iter 77000, loss: 0.005279
 >> iter 78000, loss: 0.005274
 >> iter 79000, loss: 0.005271
 >> iter 80000, loss: 0.005268
   Number of active neurons: 9
 >> iter 81000, loss: 0.005265
 >> iter 82000, loss: 0.005263
 >> iter 83000, loss: 0.005258
 >> iter 84000, loss: 0.005256
 >> iter 85000, loss: 0.005250
 >> iter 86000, loss: 0.005251
 >> iter 87000, loss: 0.005244
 >> iter 88000, loss: 0.005246
 >> iter 89000, loss: 0.005239
 >> iter 90000, loss: 0.005241
   Number of active neurons: 9
 >> iter 91000, loss: 0.005231
 >> iter 92000, loss: 0.005234
 >> iter 93000, loss: 0.005222
 >> iter 94000, loss: 0.005227
 >> iter 95000, loss: 0.005218
 >> iter 96000, loss: 0.005221
 >> iter 97000, loss: 0.005212
 >> iter 98000, loss: 0.005215
 >> iter 99000, loss: 0.005206
 >> iter 100000, loss: 0.005209
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.538858
 >> iter 2000, loss: 10.497551
 >> iter 3000, loss: 8.636569
 >> iter 4000, loss: 7.932573
 >> iter 5000, loss: 7.681785
 >> iter 6000, loss: 7.572700
 >> iter 7000, loss: 7.539655
 >> iter 8000, loss: 7.455946
 >> iter 9000, loss: 6.934236
 >> iter 10000, loss: 6.026636
   Number of active neurons: 7
 >> iter 11000, loss: 4.815115
 >> iter 12000, loss: 1.851089
 >> iter 13000, loss: 0.717104
 >> iter 14000, loss: 0.288206
 >> iter 15000, loss: 0.125103
 >> iter 16000, loss: 0.061551
 >> iter 17000, loss: 0.036098
 >> iter 18000, loss: 0.025063
 >> iter 19000, loss: 0.019932
 >> iter 20000, loss: 0.017082
   Number of active neurons: 9
 >> iter 21000, loss: 0.015392
 >> iter 22000, loss: 0.014147
 >> iter 23000, loss: 0.013264
 >> iter 24000, loss: 0.012502
 >> iter 25000, loss: 0.011934
 >> iter 26000, loss: 0.011400
 >> iter 27000, loss: 0.011004
 >> iter 28000, loss: 0.010609
 >> iter 29000, loss: 0.010320
 >> iter 30000, loss: 0.010011
   Number of active neurons: 9
 >> iter 31000, loss: 0.009792
 >> iter 32000, loss: 0.009548
 >> iter 33000, loss: 0.009381
 >> iter 34000, loss: 0.009180
 >> iter 35000, loss: 0.009053
 >> iter 36000, loss: 0.008883
 >> iter 37000, loss: 0.008780
 >> iter 38000, loss: 0.008639
 >> iter 39000, loss: 0.008554
 >> iter 40000, loss: 0.008433
   Number of active neurons: 9
 >> iter 41000, loss: 0.008360
 >> iter 42000, loss: 0.008254
 >> iter 43000, loss: 0.008194
 >> iter 44000, loss: 0.008102
 >> iter 45000, loss: 0.008048
 >> iter 46000, loss: 0.007967
 >> iter 47000, loss: 0.007919
 >> iter 48000, loss: 0.007839
 >> iter 49000, loss: 0.007799
 >> iter 50000, loss: 0.007724
   Number of active neurons: 9
 >> iter 51000, loss: 0.007691
 >> iter 52000, loss: 0.007619
 >> iter 53000, loss: 0.007593
 >> iter 54000, loss: 0.007522
 >> iter 55000, loss: 0.007505
 >> iter 56000, loss: 0.007440
 >> iter 57000, loss: 0.007431
 >> iter 58000, loss: 0.007370
 >> iter 59000, loss: 0.007362
 >> iter 60000, loss: 0.007310
   Number of active neurons: 9
 >> iter 61000, loss: 0.007305
 >> iter 62000, loss: 0.007252
 >> iter 63000, loss: 0.007250
 >> iter 64000, loss: 0.007199
 >> iter 65000, loss: 0.007199
 >> iter 66000, loss: 0.007149
 >> iter 67000, loss: 0.007148
 >> iter 68000, loss: 0.007101
 >> iter 69000, loss: 0.007102
 >> iter 70000, loss: 0.007059
   Number of active neurons: 9
 >> iter 71000, loss: 0.007059
 >> iter 72000, loss: 0.007017
 >> iter 73000, loss: 0.007017
 >> iter 74000, loss: 0.006975
 >> iter 75000, loss: 0.006978
 >> iter 76000, loss: 0.006938
 >> iter 77000, loss: 0.006943
 >> iter 78000, loss: 0.006904
 >> iter 79000, loss: 0.006911
 >> iter 80000, loss: 0.006871
   Number of active neurons: 9
 >> iter 81000, loss: 0.006874
 >> iter 82000, loss: 0.006837
 >> iter 83000, loss: 0.006844
 >> iter 84000, loss: 0.006808
 >> iter 85000, loss: 0.006815
 >> iter 86000, loss: 0.006782
 >> iter 87000, loss: 0.006788
 >> iter 88000, loss: 0.006758
 >> iter 89000, loss: 0.006760
 >> iter 90000, loss: 0.006733
   Number of active neurons: 8
 >> iter 91000, loss: 0.006730
 >> iter 92000, loss: 0.006699
 >> iter 93000, loss: 0.006695
 >> iter 94000, loss: 0.006666
 >> iter 95000, loss: 0.006662
 >> iter 96000, loss: 0.006632
 >> iter 97000, loss: 0.006630
 >> iter 98000, loss: 0.006600
 >> iter 99000, loss: 0.006595
 >> iter 100000, loss: 0.006570
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.584992
 >> iter 2000, loss: 10.513520
 >> iter 3000, loss: 8.643974
 >> iter 4000, loss: 7.928422
 >> iter 5000, loss: 7.928892
 >> iter 6000, loss: 7.520003
 >> iter 7000, loss: 6.112133
 >> iter 8000, loss: 2.302428
 >> iter 9000, loss: 0.866323
 >> iter 10000, loss: 0.331341
   Number of active neurons: 8
 >> iter 11000, loss: 0.131636
 >> iter 12000, loss: 0.056465
 >> iter 13000, loss: 0.027764
 >> iter 14000, loss: 0.016439
 >> iter 15000, loss: 0.011749
 >> iter 16000, loss: 0.009595
 >> iter 17000, loss: 0.008495
 >> iter 18000, loss: 0.007817
 >> iter 19000, loss: 0.007371
 >> iter 20000, loss: 0.007021
   Number of active neurons: 8
 >> iter 21000, loss: 0.006757
 >> iter 22000, loss: 0.006529
 >> iter 23000, loss: 0.006348
 >> iter 24000, loss: 0.006183
 >> iter 25000, loss: 0.006051
 >> iter 26000, loss: 0.005927
 >> iter 27000, loss: 0.005829
 >> iter 28000, loss: 0.005734
 >> iter 29000, loss: 0.005659
 >> iter 30000, loss: 0.005585
   Number of active neurons: 8
 >> iter 31000, loss: 0.005527
 >> iter 32000, loss: 0.005465
 >> iter 33000, loss: 0.005417
 >> iter 34000, loss: 0.005365
 >> iter 35000, loss: 0.005328
 >> iter 36000, loss: 0.005286
 >> iter 37000, loss: 0.005258
 >> iter 38000, loss: 0.005224
 >> iter 39000, loss: 0.005203
 >> iter 40000, loss: 0.005174
   Number of active neurons: 7
 >> iter 41000, loss: 0.005157
 >> iter 42000, loss: 0.005133
 >> iter 43000, loss: 0.005119
 >> iter 44000, loss: 0.005095
 >> iter 45000, loss: 0.005083
 >> iter 46000, loss: 0.005062
 >> iter 47000, loss: 0.005053
 >> iter 48000, loss: 0.005031
 >> iter 49000, loss: 0.005024
 >> iter 50000, loss: 0.005002
   Number of active neurons: 7
 >> iter 51000, loss: 0.004997
 >> iter 52000, loss: 0.004977
 >> iter 53000, loss: 0.004971
 >> iter 54000, loss: 0.004952
 >> iter 55000, loss: 0.004943
 >> iter 56000, loss: 0.004926
 >> iter 57000, loss: 0.004918
 >> iter 58000, loss: 0.004903
 >> iter 59000, loss: 0.004896
 >> iter 60000, loss: 0.004883
   Number of active neurons: 7
 >> iter 61000, loss: 0.004877
 >> iter 62000, loss: 0.004864
 >> iter 63000, loss: 0.004859
 >> iter 64000, loss: 0.004849
 >> iter 65000, loss: 0.004844
 >> iter 66000, loss: 0.004834
 >> iter 67000, loss: 0.004830
 >> iter 68000, loss: 0.004821
 >> iter 69000, loss: 0.004817
 >> iter 70000, loss: 0.004809
   Number of active neurons: 7
 >> iter 71000, loss: 0.004805
 >> iter 72000, loss: 0.004797
 >> iter 73000, loss: 0.004792
 >> iter 74000, loss: 0.004784
 >> iter 75000, loss: 0.004779
 >> iter 76000, loss: 0.004772
 >> iter 77000, loss: 0.004768
 >> iter 78000, loss: 0.004761
 >> iter 79000, loss: 0.004756
 >> iter 80000, loss: 0.004748
   Number of active neurons: 7
 >> iter 81000, loss: 0.004743
 >> iter 82000, loss: 0.004737
 >> iter 83000, loss: 0.004733
 >> iter 84000, loss: 0.004728
 >> iter 85000, loss: 0.004724
 >> iter 86000, loss: 0.004722
 >> iter 87000, loss: 0.004718
 >> iter 88000, loss: 0.004716
 >> iter 89000, loss: 0.004712
 >> iter 90000, loss: 0.004711
   Number of active neurons: 7
 >> iter 91000, loss: 0.004706
 >> iter 92000, loss: 0.004706
 >> iter 93000, loss: 0.004700
 >> iter 94000, loss: 0.004700
 >> iter 95000, loss: 0.004695
 >> iter 96000, loss: 0.004694
 >> iter 97000, loss: 0.004688
 >> iter 98000, loss: 0.004685
 >> iter 99000, loss: 0.004680
 >> iter 100000, loss: 0.004678
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.567958
 >> iter 2000, loss: 10.514605
 >> iter 3000, loss: 8.645972
 >> iter 4000, loss: 7.939433
 >> iter 5000, loss: 7.688319
 >> iter 6000, loss: 7.571742
 >> iter 7000, loss: 7.505197
 >> iter 8000, loss: 7.096450
 >> iter 9000, loss: 6.493446
 >> iter 10000, loss: 3.997529
   Number of active neurons: 10
 >> iter 11000, loss: 1.517967
 >> iter 12000, loss: 0.580335
 >> iter 13000, loss: 0.228899
 >> iter 14000, loss: 0.096058
 >> iter 15000, loss: 0.045426
 >> iter 16000, loss: 0.025347
 >> iter 17000, loss: 0.017196
 >> iter 18000, loss: 0.013406
 >> iter 19000, loss: 0.011600
 >> iter 20000, loss: 0.010427
   Number of active neurons: 10
 >> iter 21000, loss: 0.009745
 >> iter 22000, loss: 0.009139
 >> iter 23000, loss: 0.008747
 >> iter 24000, loss: 0.008333
 >> iter 25000, loss: 0.008052
 >> iter 26000, loss: 0.007727
 >> iter 27000, loss: 0.007492
 >> iter 28000, loss: 0.007214
 >> iter 29000, loss: 0.007006
 >> iter 30000, loss: 0.006778
   Number of active neurons: 10
 >> iter 31000, loss: 0.006607
 >> iter 32000, loss: 0.006432
 >> iter 33000, loss: 0.006304
 >> iter 34000, loss: 0.006166
 >> iter 35000, loss: 0.006064
 >> iter 36000, loss: 0.005953
 >> iter 37000, loss: 0.005872
 >> iter 38000, loss: 0.005781
 >> iter 39000, loss: 0.005718
 >> iter 40000, loss: 0.005645
   Number of active neurons: 10
 >> iter 41000, loss: 0.005597
 >> iter 42000, loss: 0.005537
 >> iter 43000, loss: 0.005502
 >> iter 44000, loss: 0.005452
 >> iter 45000, loss: 0.005429
 >> iter 46000, loss: 0.005387
 >> iter 47000, loss: 0.005371
 >> iter 48000, loss: 0.005330
 >> iter 49000, loss: 0.005321
 >> iter 50000, loss: 0.005285
   Number of active neurons: 10
 >> iter 51000, loss: 0.005277
 >> iter 52000, loss: 0.005245
 >> iter 53000, loss: 0.005238
 >> iter 54000, loss: 0.005206
 >> iter 55000, loss: 0.005198
 >> iter 56000, loss: 0.005170
 >> iter 57000, loss: 0.005164
 >> iter 58000, loss: 0.005141
 >> iter 59000, loss: 0.005137
 >> iter 60000, loss: 0.005118
   Number of active neurons: 10
 >> iter 61000, loss: 0.005114
 >> iter 62000, loss: 0.005100
 >> iter 63000, loss: 0.005098
 >> iter 64000, loss: 0.005090
 >> iter 65000, loss: 0.005087
 >> iter 66000, loss: 0.005080
 >> iter 67000, loss: 0.005078
 >> iter 68000, loss: 0.005075
 >> iter 69000, loss: 0.005076
 >> iter 70000, loss: 0.005077
   Number of active neurons: 10
 >> iter 71000, loss: 0.005078
 >> iter 72000, loss: 0.005082
 >> iter 73000, loss: 0.005083
 >> iter 74000, loss: 0.005089
 >> iter 75000, loss: 0.005087
 >> iter 76000, loss: 0.005093
 >> iter 77000, loss: 0.005092
 >> iter 78000, loss: 0.005099
 >> iter 79000, loss: 0.005095
 >> iter 80000, loss: 0.005102
   Number of active neurons: 10
 >> iter 81000, loss: 0.005097
 >> iter 82000, loss: 0.005104
 >> iter 83000, loss: 0.005095
 >> iter 84000, loss: 0.005101
 >> iter 85000, loss: 0.005091
 >> iter 86000, loss: 0.005096
 >> iter 87000, loss: 0.005084
 >> iter 88000, loss: 0.005086
 >> iter 89000, loss: 0.005072
 >> iter 90000, loss: 0.005075
   Number of active neurons: 10
 >> iter 91000, loss: 0.005060
 >> iter 92000, loss: 0.005065
 >> iter 93000, loss: 0.005050
 >> iter 94000, loss: 0.005056
 >> iter 95000, loss: 0.005046
 >> iter 96000, loss: 0.005051
 >> iter 97000, loss: 0.005042
 >> iter 98000, loss: 0.005048
 >> iter 99000, loss: 0.005041
 >> iter 100000, loss: 0.005049
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 15.568061
 >> iter 2000, loss: 10.509227
 >> iter 3000, loss: 8.643709
 >> iter 4000, loss: 7.934263
 >> iter 5000, loss: 7.699278
 >> iter 6000, loss: 7.609857
 >> iter 7000, loss: 7.146726
 >> iter 8000, loss: 3.277028
 >> iter 9000, loss: 1.237269
 >> iter 10000, loss: 0.473616
   Number of active neurons: 10
 >> iter 11000, loss: 0.187774
 >> iter 12000, loss: 0.079968
 >> iter 13000, loss: 0.038706
 >> iter 14000, loss: 0.022410
 >> iter 15000, loss: 0.015640
 >> iter 16000, loss: 0.012542
 >> iter 17000, loss: 0.010961
 >> iter 18000, loss: 0.009995
 >> iter 19000, loss: 0.009357
 >> iter 20000, loss: 0.008853
   Number of active neurons: 10
 >> iter 21000, loss: 0.008468
 >> iter 22000, loss: 0.008124
 >> iter 23000, loss: 0.007850
 >> iter 24000, loss: 0.007589
 >> iter 25000, loss: 0.007377
 >> iter 26000, loss: 0.007174
 >> iter 27000, loss: 0.007008
 >> iter 28000, loss: 0.006845
 >> iter 29000, loss: 0.006715
 >> iter 30000, loss: 0.006587
   Number of active neurons: 10
 >> iter 31000, loss: 0.006488
 >> iter 32000, loss: 0.006384
 >> iter 33000, loss: 0.006308
 >> iter 34000, loss: 0.006227
 >> iter 35000, loss: 0.006168
 >> iter 36000, loss: 0.006102
 >> iter 37000, loss: 0.006060
 >> iter 38000, loss: 0.006010
 >> iter 39000, loss: 0.005979
 >> iter 40000, loss: 0.005938
   Number of active neurons: 9
 >> iter 41000, loss: 0.005916
 >> iter 42000, loss: 0.005881
 >> iter 43000, loss: 0.005864
 >> iter 44000, loss: 0.005829
 >> iter 45000, loss: 0.005817
 >> iter 46000, loss: 0.005784
 >> iter 47000, loss: 0.005771
 >> iter 48000, loss: 0.005734
 >> iter 49000, loss: 0.005722
 >> iter 50000, loss: 0.005686
   Number of active neurons: 9
 >> iter 51000, loss: 0.005678
 >> iter 52000, loss: 0.005644
 >> iter 53000, loss: 0.005637
 >> iter 54000, loss: 0.005607
 >> iter 55000, loss: 0.005600
 >> iter 56000, loss: 0.005575
 >> iter 57000, loss: 0.005574
 >> iter 58000, loss: 0.005559
 >> iter 59000, loss: 0.005561
 >> iter 60000, loss: 0.005548
   Number of active neurons: 9
 >> iter 61000, loss: 0.005548
 >> iter 62000, loss: 0.005535
 >> iter 63000, loss: 0.005535
 >> iter 64000, loss: 0.005523
 >> iter 65000, loss: 0.005517
 >> iter 66000, loss: 0.005503
 >> iter 67000, loss: 0.005497
 >> iter 68000, loss: 0.005486
 >> iter 69000, loss: 0.005480
 >> iter 70000, loss: 0.005470
   Number of active neurons: 8
 >> iter 71000, loss: 0.005465
 >> iter 72000, loss: 0.005458
 >> iter 73000, loss: 0.005454
 >> iter 74000, loss: 0.005448
 >> iter 75000, loss: 0.005446
 >> iter 76000, loss: 0.005441
 >> iter 77000, loss: 0.005438
 >> iter 78000, loss: 0.005433
 >> iter 79000, loss: 0.005428
 >> iter 80000, loss: 0.005423
   Number of active neurons: 8
 >> iter 81000, loss: 0.005416
 >> iter 82000, loss: 0.005413
 >> iter 83000, loss: 0.005405
 >> iter 84000, loss: 0.005402
 >> iter 85000, loss: 0.005394
 >> iter 86000, loss: 0.005395
 >> iter 87000, loss: 0.005387
 >> iter 88000, loss: 0.005389
 >> iter 89000, loss: 0.005380
 >> iter 90000, loss: 0.005382
   Number of active neurons: 8
 >> iter 91000, loss: 0.005371
 >> iter 92000, loss: 0.005376
 >> iter 93000, loss: 0.005363
 >> iter 94000, loss: 0.005368
 >> iter 95000, loss: 0.005358
 >> iter 96000, loss: 0.005362
 >> iter 97000, loss: 0.005353
 >> iter 98000, loss: 0.005357
 >> iter 99000, loss: 0.005345
 >> iter 100000, loss: 0.005348
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 15.642475
 >> iter 2000, loss: 10.526671
 >> iter 3000, loss: 8.637189
 >> iter 4000, loss: 7.923070
 >> iter 5000, loss: 7.669741
 >> iter 6000, loss: 7.552296
 >> iter 7000, loss: 7.471493
 >> iter 8000, loss: 6.833079
 >> iter 9000, loss: 5.919292
 >> iter 10000, loss: 2.719889
   Number of active neurons: 8
 >> iter 11000, loss: 1.047108
 >> iter 12000, loss: 0.413215
 >> iter 13000, loss: 0.173093
 >> iter 14000, loss: 0.080335
 >> iter 15000, loss: 0.043817
 >> iter 16000, loss: 0.028374
 >> iter 17000, loss: 0.021530
 >> iter 18000, loss: 0.017863
 >> iter 19000, loss: 0.015847
 >> iter 20000, loss: 0.014355
   Number of active neurons: 8
 >> iter 21000, loss: 0.013387
 >> iter 22000, loss: 0.012501
 >> iter 23000, loss: 0.011893
 >> iter 24000, loss: 0.011270
 >> iter 25000, loss: 0.010856
 >> iter 26000, loss: 0.010384
 >> iter 27000, loss: 0.010088
 >> iter 28000, loss: 0.009719
 >> iter 29000, loss: 0.009501
 >> iter 30000, loss: 0.009200
   Number of active neurons: 8
 >> iter 31000, loss: 0.009036
 >> iter 32000, loss: 0.008790
 >> iter 33000, loss: 0.008662
 >> iter 34000, loss: 0.008448
 >> iter 35000, loss: 0.008355
 >> iter 36000, loss: 0.008170
 >> iter 37000, loss: 0.008099
 >> iter 38000, loss: 0.007936
 >> iter 39000, loss: 0.007887
 >> iter 40000, loss: 0.007739
   Number of active neurons: 7
 >> iter 41000, loss: 0.007704
 >> iter 42000, loss: 0.007569
 >> iter 43000, loss: 0.007546
 >> iter 44000, loss: 0.007422
 >> iter 45000, loss: 0.007410
 >> iter 46000, loss: 0.007307
 >> iter 47000, loss: 0.007316
 >> iter 48000, loss: 0.007227
 >> iter 49000, loss: 0.007248
 >> iter 50000, loss: 0.007167
   Number of active neurons: 7
 >> iter 51000, loss: 0.007193
 >> iter 52000, loss: 0.007111
 >> iter 53000, loss: 0.007141
 >> iter 54000, loss: 0.007057
 >> iter 55000, loss: 0.007088
 >> iter 56000, loss: 0.007009
 >> iter 57000, loss: 0.007042
 >> iter 58000, loss: 0.006964
 >> iter 59000, loss: 0.006995
 >> iter 60000, loss: 0.006921
   Number of active neurons: 7
 >> iter 61000, loss: 0.006949
 >> iter 62000, loss: 0.006876
 >> iter 63000, loss: 0.006904
 >> iter 64000, loss: 0.006834
 >> iter 65000, loss: 0.006861
 >> iter 66000, loss: 0.006792
 >> iter 67000, loss: 0.006818
 >> iter 68000, loss: 0.006753
 >> iter 69000, loss: 0.006779
 >> iter 70000, loss: 0.006717
   Number of active neurons: 7
 >> iter 71000, loss: 0.006740
 >> iter 72000, loss: 0.006679
 >> iter 73000, loss: 0.006703
 >> iter 74000, loss: 0.006640
 >> iter 75000, loss: 0.006664
 >> iter 76000, loss: 0.006603
 >> iter 77000, loss: 0.006629
 >> iter 78000, loss: 0.006574
 >> iter 79000, loss: 0.006603
 >> iter 80000, loss: 0.006549
   Number of active neurons: 7
 >> iter 81000, loss: 0.006573
 >> iter 82000, loss: 0.006523
 >> iter 83000, loss: 0.006548
 >> iter 84000, loss: 0.006498
 >> iter 85000, loss: 0.006523
 >> iter 86000, loss: 0.006476
 >> iter 87000, loss: 0.006498
 >> iter 88000, loss: 0.006451
 >> iter 89000, loss: 0.006468
 >> iter 90000, loss: 0.006421
   Number of active neurons: 7
 >> iter 91000, loss: 0.006434
 >> iter 92000, loss: 0.006389
 >> iter 93000, loss: 0.006401
 >> iter 94000, loss: 0.006356
 >> iter 95000, loss: 0.006368
 >> iter 96000, loss: 0.006326
 >> iter 97000, loss: 0.006339
 >> iter 98000, loss: 0.006299
 >> iter 99000, loss: 0.006309
 >> iter 100000, loss: 0.006275
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.516130
 >> iter 2000, loss: 10.475877
 >> iter 3000, loss: 8.618225
 >> iter 4000, loss: 7.915747
 >> iter 5000, loss: 7.662881
 >> iter 6000, loss: 7.538453
 >> iter 7000, loss: 7.291413
 >> iter 8000, loss: 5.948414
 >> iter 9000, loss: 2.247521
 >> iter 10000, loss: 0.850045
   Number of active neurons: 8
 >> iter 11000, loss: 0.328391
 >> iter 12000, loss: 0.132876
 >> iter 13000, loss: 0.058914
 >> iter 14000, loss: 0.030307
 >> iter 15000, loss: 0.018860
 >> iter 16000, loss: 0.013913
 >> iter 17000, loss: 0.011582
 >> iter 18000, loss: 0.010270
 >> iter 19000, loss: 0.009475
 >> iter 20000, loss: 0.008878
   Number of active neurons: 8
 >> iter 21000, loss: 0.008450
 >> iter 22000, loss: 0.008078
 >> iter 23000, loss: 0.007797
 >> iter 24000, loss: 0.007535
 >> iter 25000, loss: 0.007333
 >> iter 26000, loss: 0.007137
 >> iter 27000, loss: 0.006986
 >> iter 28000, loss: 0.006832
 >> iter 29000, loss: 0.006712
 >> iter 30000, loss: 0.006587
   Number of active neurons: 8
 >> iter 31000, loss: 0.006494
 >> iter 32000, loss: 0.006389
 >> iter 33000, loss: 0.006312
 >> iter 34000, loss: 0.006221
 >> iter 35000, loss: 0.006156
 >> iter 36000, loss: 0.006078
 >> iter 37000, loss: 0.006022
 >> iter 38000, loss: 0.005952
 >> iter 39000, loss: 0.005906
 >> iter 40000, loss: 0.005845
   Number of active neurons: 8
 >> iter 41000, loss: 0.005809
 >> iter 42000, loss: 0.005756
 >> iter 43000, loss: 0.005728
 >> iter 44000, loss: 0.005682
 >> iter 45000, loss: 0.005662
 >> iter 46000, loss: 0.005622
 >> iter 47000, loss: 0.005607
 >> iter 48000, loss: 0.005568
 >> iter 49000, loss: 0.005558
 >> iter 50000, loss: 0.005523
   Number of active neurons: 8
 >> iter 51000, loss: 0.005515
 >> iter 52000, loss: 0.005483
 >> iter 53000, loss: 0.005475
 >> iter 54000, loss: 0.005448
 >> iter 55000, loss: 0.005438
 >> iter 56000, loss: 0.005413
 >> iter 57000, loss: 0.005404
 >> iter 58000, loss: 0.005384
 >> iter 59000, loss: 0.005375
 >> iter 60000, loss: 0.005357
   Number of active neurons: 7
 >> iter 61000, loss: 0.005350
 >> iter 62000, loss: 0.005331
 >> iter 63000, loss: 0.005325
 >> iter 64000, loss: 0.005309
 >> iter 65000, loss: 0.005303
 >> iter 66000, loss: 0.005286
 >> iter 67000, loss: 0.005279
 >> iter 68000, loss: 0.005263
 >> iter 69000, loss: 0.005255
 >> iter 70000, loss: 0.005239
   Number of active neurons: 7
 >> iter 71000, loss: 0.005231
 >> iter 72000, loss: 0.005215
 >> iter 73000, loss: 0.005207
 >> iter 74000, loss: 0.005191
 >> iter 75000, loss: 0.005178
 >> iter 76000, loss: 0.005161
 >> iter 77000, loss: 0.005148
 >> iter 78000, loss: 0.005133
 >> iter 79000, loss: 0.005122
 >> iter 80000, loss: 0.005108
   Number of active neurons: 7
 >> iter 81000, loss: 0.005096
 >> iter 82000, loss: 0.005085
 >> iter 83000, loss: 0.005072
 >> iter 84000, loss: 0.005063
 >> iter 85000, loss: 0.005050
 >> iter 86000, loss: 0.005044
 >> iter 87000, loss: 0.005031
 >> iter 88000, loss: 0.005024
 >> iter 89000, loss: 0.005012
 >> iter 90000, loss: 0.005006
   Number of active neurons: 7
 >> iter 91000, loss: 0.004993
 >> iter 92000, loss: 0.004989
 >> iter 93000, loss: 0.004974
 >> iter 94000, loss: 0.004970
 >> iter 95000, loss: 0.004958
 >> iter 96000, loss: 0.004952
 >> iter 97000, loss: 0.004940
 >> iter 98000, loss: 0.004934
 >> iter 99000, loss: 0.004922
 >> iter 100000, loss: 0.004916
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.550835
 >> iter 2000, loss: 10.488672
 >> iter 3000, loss: 8.624861
 >> iter 4000, loss: 7.919851
 >> iter 5000, loss: 7.668167
 >> iter 6000, loss: 7.551799
 >> iter 7000, loss: 7.560935
 >> iter 8000, loss: 7.560681
 >> iter 9000, loss: 7.117489
 >> iter 10000, loss: 3.244524
   Number of active neurons: 10
 >> iter 11000, loss: 1.223717
 >> iter 12000, loss: 0.467881
 >> iter 13000, loss: 0.185233
 >> iter 14000, loss: 0.078646
 >> iter 15000, loss: 0.037939
 >> iter 16000, loss: 0.021838
 >> iter 17000, loss: 0.015216
 >> iter 18000, loss: 0.012154
 >> iter 19000, loss: 0.010644
 >> iter 20000, loss: 0.009692
   Number of active neurons: 10
 >> iter 21000, loss: 0.009113
 >> iter 22000, loss: 0.008626
 >> iter 23000, loss: 0.008303
 >> iter 24000, loss: 0.007978
 >> iter 25000, loss: 0.007769
 >> iter 26000, loss: 0.007531
 >> iter 27000, loss: 0.007389
 >> iter 28000, loss: 0.007203
 >> iter 29000, loss: 0.007105
 >> iter 30000, loss: 0.006954
   Number of active neurons: 10
 >> iter 31000, loss: 0.006882
 >> iter 32000, loss: 0.006749
 >> iter 33000, loss: 0.006695
 >> iter 34000, loss: 0.006580
 >> iter 35000, loss: 0.006543
 >> iter 36000, loss: 0.006445
 >> iter 37000, loss: 0.006417
 >> iter 38000, loss: 0.006334
 >> iter 39000, loss: 0.006313
 >> iter 40000, loss: 0.006238
   Number of active neurons: 10
 >> iter 41000, loss: 0.006226
 >> iter 42000, loss: 0.006158
 >> iter 43000, loss: 0.006153
 >> iter 44000, loss: 0.006090
 >> iter 45000, loss: 0.006086
 >> iter 46000, loss: 0.006026
 >> iter 47000, loss: 0.006025
 >> iter 48000, loss: 0.005967
 >> iter 49000, loss: 0.005969
 >> iter 50000, loss: 0.005915
   Number of active neurons: 10
 >> iter 51000, loss: 0.005920
 >> iter 52000, loss: 0.005869
 >> iter 53000, loss: 0.005876
 >> iter 54000, loss: 0.005826
 >> iter 55000, loss: 0.005833
 >> iter 56000, loss: 0.005786
 >> iter 57000, loss: 0.005790
 >> iter 58000, loss: 0.005745
 >> iter 59000, loss: 0.005748
 >> iter 60000, loss: 0.005710
   Number of active neurons: 10
 >> iter 61000, loss: 0.005714
 >> iter 62000, loss: 0.005679
 >> iter 63000, loss: 0.005684
 >> iter 64000, loss: 0.005653
 >> iter 65000, loss: 0.005656
 >> iter 66000, loss: 0.005624
 >> iter 67000, loss: 0.005625
 >> iter 68000, loss: 0.005595
 >> iter 69000, loss: 0.005595
 >> iter 70000, loss: 0.005564
   Number of active neurons: 10
 >> iter 71000, loss: 0.005563
 >> iter 72000, loss: 0.005532
 >> iter 73000, loss: 0.005527
 >> iter 74000, loss: 0.005495
 >> iter 75000, loss: 0.005488
 >> iter 76000, loss: 0.005455
 >> iter 77000, loss: 0.005446
 >> iter 78000, loss: 0.005417
 >> iter 79000, loss: 0.005409
 >> iter 80000, loss: 0.005380
   Number of active neurons: 10
 >> iter 81000, loss: 0.005369
 >> iter 82000, loss: 0.005340
 >> iter 83000, loss: 0.005328
 >> iter 84000, loss: 0.005300
 >> iter 85000, loss: 0.005287
 >> iter 86000, loss: 0.005264
 >> iter 87000, loss: 0.005253
 >> iter 88000, loss: 0.005233
 >> iter 89000, loss: 0.005224
 >> iter 90000, loss: 0.005206
   Number of active neurons: 10
 >> iter 91000, loss: 0.005197
 >> iter 92000, loss: 0.005182
 >> iter 93000, loss: 0.005171
 >> iter 94000, loss: 0.005157
 >> iter 95000, loss: 0.005149
 >> iter 96000, loss: 0.005135
 >> iter 97000, loss: 0.005125
 >> iter 98000, loss: 0.005111
 >> iter 99000, loss: 0.005101
 >> iter 100000, loss: 0.005086
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.600125
 >> iter 2000, loss: 10.525837
 >> iter 3000, loss: 8.648643
 >> iter 4000, loss: 7.932518
 >> iter 5000, loss: 7.671324
 >> iter 6000, loss: 7.251748
 >> iter 7000, loss: 6.541879
 >> iter 8000, loss: 4.499613
 >> iter 9000, loss: 1.788069
 >> iter 10000, loss: 0.691641
   Number of active neurons: 10
 >> iter 11000, loss: 0.276088
 >> iter 12000, loss: 0.117084
 >> iter 13000, loss: 0.055802
 >> iter 14000, loss: 0.030973
 >> iter 15000, loss: 0.020734
 >> iter 16000, loss: 0.015785
 >> iter 17000, loss: 0.013436
 >> iter 18000, loss: 0.011853
 >> iter 19000, loss: 0.010982
 >> iter 20000, loss: 0.010172
   Number of active neurons: 10
 >> iter 21000, loss: 0.009709
 >> iter 22000, loss: 0.009180
 >> iter 23000, loss: 0.008893
 >> iter 24000, loss: 0.008509
 >> iter 25000, loss: 0.008322
 >> iter 26000, loss: 0.008033
 >> iter 27000, loss: 0.007905
 >> iter 28000, loss: 0.007677
 >> iter 29000, loss: 0.007594
 >> iter 30000, loss: 0.007406
   Number of active neurons: 10
 >> iter 31000, loss: 0.007346
 >> iter 32000, loss: 0.007191
 >> iter 33000, loss: 0.007148
 >> iter 34000, loss: 0.007014
 >> iter 35000, loss: 0.006983
 >> iter 36000, loss: 0.006867
 >> iter 37000, loss: 0.006842
 >> iter 38000, loss: 0.006737
 >> iter 39000, loss: 0.006719
 >> iter 40000, loss: 0.006622
   Number of active neurons: 10
 >> iter 41000, loss: 0.006607
 >> iter 42000, loss: 0.006518
 >> iter 43000, loss: 0.006504
 >> iter 44000, loss: 0.006424
 >> iter 45000, loss: 0.006414
 >> iter 46000, loss: 0.006345
 >> iter 47000, loss: 0.006338
 >> iter 48000, loss: 0.006272
 >> iter 49000, loss: 0.006268
 >> iter 50000, loss: 0.006206
   Number of active neurons: 10
 >> iter 51000, loss: 0.006201
 >> iter 52000, loss: 0.006143
 >> iter 53000, loss: 0.006143
 >> iter 54000, loss: 0.006086
 >> iter 55000, loss: 0.006092
 >> iter 56000, loss: 0.006038
 >> iter 57000, loss: 0.006045
 >> iter 58000, loss: 0.005993
 >> iter 59000, loss: 0.006001
 >> iter 60000, loss: 0.005954
   Number of active neurons: 10
 >> iter 61000, loss: 0.005962
 >> iter 62000, loss: 0.005914
 >> iter 63000, loss: 0.005921
 >> iter 64000, loss: 0.005877
 >> iter 65000, loss: 0.005881
 >> iter 66000, loss: 0.005839
 >> iter 67000, loss: 0.005842
 >> iter 68000, loss: 0.005804
 >> iter 69000, loss: 0.005807
 >> iter 70000, loss: 0.005772
   Number of active neurons: 10
 >> iter 71000, loss: 0.005774
 >> iter 72000, loss: 0.005741
 >> iter 73000, loss: 0.005746
 >> iter 74000, loss: 0.005713
 >> iter 75000, loss: 0.005717
 >> iter 76000, loss: 0.005686
 >> iter 77000, loss: 0.005692
 >> iter 78000, loss: 0.005664
 >> iter 79000, loss: 0.005667
 >> iter 80000, loss: 0.005643
   Number of active neurons: 10
 >> iter 81000, loss: 0.005642
 >> iter 82000, loss: 0.005620
 >> iter 83000, loss: 0.005618
 >> iter 84000, loss: 0.005595
 >> iter 85000, loss: 0.005591
 >> iter 86000, loss: 0.005569
 >> iter 87000, loss: 0.005561
 >> iter 88000, loss: 0.005540
 >> iter 89000, loss: 0.005529
 >> iter 90000, loss: 0.005512
   Number of active neurons: 10
 >> iter 91000, loss: 0.005500
 >> iter 92000, loss: 0.005487
 >> iter 93000, loss: 0.005474
 >> iter 94000, loss: 0.005462
 >> iter 95000, loss: 0.005449
 >> iter 96000, loss: 0.005439
 >> iter 97000, loss: 0.005427
 >> iter 98000, loss: 0.005418
 >> iter 99000, loss: 0.005409
 >> iter 100000, loss: 0.005402
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

