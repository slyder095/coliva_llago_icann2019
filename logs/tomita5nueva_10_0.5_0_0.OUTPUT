 > Problema: tomita5nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.5
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.759908
 >> iter 2000, loss: 10.621040
 >> iter 3000, loss: 8.702382
 >> iter 4000, loss: 7.976172
 >> iter 5000, loss: 7.706295
 >> iter 6000, loss: 7.596192
 >> iter 7000, loss: 7.564189
 >> iter 8000, loss: 7.534252
 >> iter 9000, loss: 7.331752
 >> iter 10000, loss: 7.147571
   Number of active neurons: 9
 >> iter 11000, loss: 6.774009
 >> iter 12000, loss: 6.217095
 >> iter 13000, loss: 5.722206
 >> iter 14000, loss: 5.226652
 >> iter 15000, loss: 4.731787
 >> iter 16000, loss: 4.406913
 >> iter 17000, loss: 4.321655
 >> iter 18000, loss: 2.691651
 >> iter 19000, loss: 1.086147
 >> iter 20000, loss: 0.423576
   Number of active neurons: 10
 >> iter 21000, loss: 0.197060
 >> iter 22000, loss: 0.120680
 >> iter 23000, loss: 0.099756
 >> iter 24000, loss: 0.104896
 >> iter 25000, loss: 0.114713
 >> iter 26000, loss: 0.052725
 >> iter 27000, loss: 0.028130
 >> iter 28000, loss: 0.018406
 >> iter 29000, loss: 0.049236
 >> iter 30000, loss: 0.051928
   Number of active neurons: 10
 >> iter 31000, loss: 0.113592
 >> iter 32000, loss: 0.049074
 >> iter 33000, loss: 0.023994
 >> iter 34000, loss: 0.014031
 >> iter 35000, loss: 0.046341
 >> iter 36000, loss: 0.023940
 >> iter 37000, loss: 0.014204
 >> iter 38000, loss: 0.009352
 >> iter 39000, loss: 0.006995
 >> iter 40000, loss: 0.006253
   Number of active neurons: 10
 >> iter 41000, loss: 0.005570
 >> iter 42000, loss: 0.005041
 >> iter 43000, loss: 0.004629
 >> iter 44000, loss: 0.004526
 >> iter 45000, loss: 0.004382
 >> iter 46000, loss: 0.004131
 >> iter 47000, loss: 0.003824
 >> iter 48000, loss: 0.003562
 >> iter 49000, loss: 0.003802
 >> iter 50000, loss: 0.016082
   Number of active neurons: 10
 >> iter 51000, loss: 0.014743
 >> iter 52000, loss: 0.009405
 >> iter 53000, loss: 0.008337
 >> iter 54000, loss: 0.008817
 >> iter 55000, loss: 0.005613
 >> iter 56000, loss: 0.004032
 >> iter 57000, loss: 0.093348
 >> iter 58000, loss: 0.036502
 >> iter 59000, loss: 0.015444
 >> iter 60000, loss: 0.007518
   Number of active neurons: 10
 >> iter 61000, loss: 0.004593
 >> iter 62000, loss: 0.003395
 >> iter 63000, loss: 0.037535
 >> iter 64000, loss: 0.015679
 >> iter 65000, loss: 0.007613
 >> iter 66000, loss: 0.004556
 >> iter 67000, loss: 0.003239
 >> iter 68000, loss: 0.002824
 >> iter 69000, loss: 0.002511
 >> iter 70000, loss: 0.069588
   Number of active neurons: 10
 >> iter 71000, loss: 0.071524
 >> iter 72000, loss: 0.028553
 >> iter 73000, loss: 0.038662
 >> iter 74000, loss: 0.016626
 >> iter 75000, loss: 0.008116
 >> iter 76000, loss: 0.005148
 >> iter 77000, loss: 0.023987
 >> iter 78000, loss: 0.010752
 >> iter 79000, loss: 0.005832
 >> iter 80000, loss: 0.003705
   Number of active neurons: 10
 >> iter 81000, loss: 0.002969
 >> iter 82000, loss: 0.002521
 >> iter 83000, loss: 0.002922
 >> iter 84000, loss: 0.002610
 >> iter 85000, loss: 0.002279
 >> iter 86000, loss: 0.002138
 >> iter 87000, loss: 0.002047
 >> iter 88000, loss: 0.001948
 >> iter 89000, loss: 0.001905
 >> iter 90000, loss: 0.001918
   Number of active neurons: 10
 >> iter 91000, loss: 0.001831
 >> iter 92000, loss: 0.001759
 >> iter 93000, loss: 0.001778
 >> iter 94000, loss: 0.001800
 >> iter 95000, loss: 0.001704
 >> iter 96000, loss: 0.001814
 >> iter 97000, loss: 0.001670
 >> iter 98000, loss: 0.001573
 >> iter 99000, loss: 0.005382
 >> iter 100000, loss: 0.002988
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.699097
 >> iter 2000, loss: 10.619872
 >> iter 3000, loss: 8.698965
 >> iter 4000, loss: 7.995934
 >> iter 5000, loss: 7.586683
 >> iter 6000, loss: 7.157928
 >> iter 7000, loss: 6.698188
 >> iter 8000, loss: 6.069506
 >> iter 9000, loss: 5.570407
 >> iter 10000, loss: 3.739201
   Number of active neurons: 10
 >> iter 11000, loss: 1.797106
 >> iter 12000, loss: 0.847908
 >> iter 13000, loss: 0.450970
 >> iter 14000, loss: 0.230800
 >> iter 15000, loss: 0.229016
 >> iter 16000, loss: 0.124172
 >> iter 17000, loss: 0.060613
 >> iter 18000, loss: 0.121938
 >> iter 19000, loss: 0.061472
 >> iter 20000, loss: 0.048998
   Number of active neurons: 10
 >> iter 21000, loss: 0.025645
 >> iter 22000, loss: 0.074245
 >> iter 23000, loss: 0.035758
 >> iter 24000, loss: 0.018501
 >> iter 25000, loss: 0.011755
 >> iter 26000, loss: 0.148250
 >> iter 27000, loss: 0.072795
 >> iter 28000, loss: 0.032442
 >> iter 29000, loss: 0.017434
 >> iter 30000, loss: 0.010509
   Number of active neurons: 10
 >> iter 31000, loss: 0.007536
 >> iter 32000, loss: 0.006279
 >> iter 33000, loss: 0.024649
 >> iter 34000, loss: 0.017423
 >> iter 35000, loss: 0.028800
 >> iter 36000, loss: 0.015236
 >> iter 37000, loss: 0.011312
 >> iter 38000, loss: 0.007802
 >> iter 39000, loss: 0.005698
 >> iter 40000, loss: 0.004804
   Number of active neurons: 10
 >> iter 41000, loss: 0.004055
 >> iter 42000, loss: 0.003933
 >> iter 43000, loss: 0.003524
 >> iter 44000, loss: 0.003739
 >> iter 45000, loss: 0.003667
 >> iter 46000, loss: 0.003800
 >> iter 47000, loss: 0.003330
 >> iter 48000, loss: 0.003135
 >> iter 49000, loss: 0.002887
 >> iter 50000, loss: 0.002900
   Number of active neurons: 10
 >> iter 51000, loss: 0.002756
 >> iter 52000, loss: 0.002548
 >> iter 53000, loss: 0.004168
 >> iter 54000, loss: 0.004555
 >> iter 55000, loss: 0.003269
 >> iter 56000, loss: 0.002831
 >> iter 57000, loss: 0.003603
 >> iter 58000, loss: 0.003039
 >> iter 59000, loss: 0.002751
 >> iter 60000, loss: 0.002428
   Number of active neurons: 10
 >> iter 61000, loss: 0.002245
 >> iter 62000, loss: 0.023323
 >> iter 63000, loss: 0.010177
 >> iter 64000, loss: 0.009667
 >> iter 65000, loss: 0.005390
 >> iter 66000, loss: 0.003274
 >> iter 67000, loss: 0.002419
 >> iter 68000, loss: 0.002086
 >> iter 69000, loss: 0.002061
 >> iter 70000, loss: 0.002022
   Number of active neurons: 10
 >> iter 71000, loss: 0.001785
 >> iter 72000, loss: 0.001706
 >> iter 73000, loss: 0.001634
 >> iter 74000, loss: 0.001628
 >> iter 75000, loss: 0.001724
 >> iter 76000, loss: 0.001682
 >> iter 77000, loss: 0.003330
 >> iter 78000, loss: 0.002236
 >> iter 79000, loss: 0.001931
 >> iter 80000, loss: 0.002554
   Number of active neurons: 10
 >> iter 81000, loss: 0.016615
 >> iter 82000, loss: 0.007219
 >> iter 83000, loss: 0.003628
 >> iter 84000, loss: 0.002268
 >> iter 85000, loss: 0.002025
 >> iter 86000, loss: 0.001874
 >> iter 87000, loss: 0.001570
 >> iter 88000, loss: 0.001452
 >> iter 89000, loss: 0.001304
 >> iter 90000, loss: 0.149959
   Number of active neurons: 10
 >> iter 91000, loss: 0.056324
 >> iter 92000, loss: 0.079638
 >> iter 93000, loss: 0.030344
 >> iter 94000, loss: 0.012143
 >> iter 95000, loss: 0.005561
 >> iter 96000, loss: 0.003012
 >> iter 97000, loss: 0.002107
 >> iter 98000, loss: 0.001710
 >> iter 99000, loss: 0.001664
 >> iter 100000, loss: 0.001505
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.726290
 >> iter 2000, loss: 10.621961
 >> iter 3000, loss: 8.737812
 >> iter 4000, loss: 8.021244
 >> iter 5000, loss: 7.793759
 >> iter 6000, loss: 7.679913
 >> iter 7000, loss: 7.616222
 >> iter 8000, loss: 7.586812
 >> iter 9000, loss: 7.579158
 >> iter 10000, loss: 7.455366
   Number of active neurons: 9
 >> iter 11000, loss: 7.153552
 >> iter 12000, loss: 6.727284
 >> iter 13000, loss: 6.329222
 >> iter 14000, loss: 5.927701
 >> iter 15000, loss: 2.947712
 >> iter 16000, loss: 1.202566
 >> iter 17000, loss: 0.466076
 >> iter 18000, loss: 0.191870
 >> iter 19000, loss: 0.083061
 >> iter 20000, loss: 0.069903
   Number of active neurons: 10
 >> iter 21000, loss: 0.036079
 >> iter 22000, loss: 0.021404
 >> iter 23000, loss: 0.014362
 >> iter 24000, loss: 0.183562
 >> iter 25000, loss: 0.076950
 >> iter 26000, loss: 0.035129
 >> iter 27000, loss: 0.019879
 >> iter 28000, loss: 0.013046
 >> iter 29000, loss: 0.009290
 >> iter 30000, loss: 0.007555
   Number of active neurons: 10
 >> iter 31000, loss: 0.006482
 >> iter 32000, loss: 0.005901
 >> iter 33000, loss: 0.005296
 >> iter 34000, loss: 0.004894
 >> iter 35000, loss: 0.016977
 >> iter 36000, loss: 0.009214
 >> iter 37000, loss: 0.006867
 >> iter 38000, loss: 0.005210
 >> iter 39000, loss: 0.004414
 >> iter 40000, loss: 0.004961
   Number of active neurons: 10
 >> iter 41000, loss: 0.004271
 >> iter 42000, loss: 0.004129
 >> iter 43000, loss: 0.003439
 >> iter 44000, loss: 0.003091
 >> iter 45000, loss: 0.002903
 >> iter 46000, loss: 0.002679
 >> iter 47000, loss: 0.002782
 >> iter 48000, loss: 0.002558
 >> iter 49000, loss: 0.002785
 >> iter 50000, loss: 0.002421
   Number of active neurons: 10
 >> iter 51000, loss: 0.002490
 >> iter 52000, loss: 0.002249
 >> iter 53000, loss: 0.002091
 >> iter 54000, loss: 0.002028
 >> iter 55000, loss: 0.001974
 >> iter 56000, loss: 0.001871
 >> iter 57000, loss: 0.001856
 >> iter 58000, loss: 0.001771
 >> iter 59000, loss: 0.001676
 >> iter 60000, loss: 0.001662
   Number of active neurons: 10
 >> iter 61000, loss: 0.001594
 >> iter 62000, loss: 0.001840
 >> iter 63000, loss: 0.001683
 >> iter 64000, loss: 0.001578
 >> iter 65000, loss: 0.001536
 >> iter 66000, loss: 0.001442
 >> iter 67000, loss: 0.001435
 >> iter 68000, loss: 0.001681
 >> iter 69000, loss: 0.001563
 >> iter 70000, loss: 0.047313
   Number of active neurons: 10
 >> iter 71000, loss: 0.018753
 >> iter 72000, loss: 0.008072
 >> iter 73000, loss: 0.004020
 >> iter 74000, loss: 0.002468
 >> iter 75000, loss: 0.001888
 >> iter 76000, loss: 0.001675
 >> iter 77000, loss: 0.001567
 >> iter 78000, loss: 0.001475
 >> iter 79000, loss: 0.001407
 >> iter 80000, loss: 0.001432
   Number of active neurons: 10
 >> iter 81000, loss: 0.001318
 >> iter 82000, loss: 0.001880
 >> iter 83000, loss: 0.001639
 >> iter 84000, loss: 0.001382
 >> iter 85000, loss: 0.001265
 >> iter 86000, loss: 0.001226
 >> iter 87000, loss: 0.001166
 >> iter 88000, loss: 0.001130
 >> iter 89000, loss: 0.001117
 >> iter 90000, loss: 0.001084
   Number of active neurons: 10
 >> iter 91000, loss: 0.001469
 >> iter 92000, loss: 0.001238
 >> iter 93000, loss: 0.001188
 >> iter 94000, loss: 0.001110
 >> iter 95000, loss: 0.001075
 >> iter 96000, loss: 0.001159
 >> iter 97000, loss: 0.001052
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.702920
 >> iter 2000, loss: 10.581646
 >> iter 3000, loss: 8.677427
 >> iter 4000, loss: 7.948755
 >> iter 5000, loss: 7.695637
 >> iter 6000, loss: 7.572700
 >> iter 7000, loss: 7.352468
 >> iter 8000, loss: 6.940521
 >> iter 9000, loss: 6.287907
 >> iter 10000, loss: 5.758478
   Number of active neurons: 10
 >> iter 11000, loss: 5.111237
 >> iter 12000, loss: 2.060856
 >> iter 13000, loss: 0.816360
 >> iter 14000, loss: 0.461545
 >> iter 15000, loss: 0.267461
 >> iter 16000, loss: 0.236610
 >> iter 17000, loss: 0.104139
 >> iter 18000, loss: 0.073280
 >> iter 19000, loss: 0.037768
 >> iter 20000, loss: 0.063307
   Number of active neurons: 10
 >> iter 21000, loss: 0.100702
 >> iter 22000, loss: 0.046098
 >> iter 23000, loss: 0.036123
 >> iter 24000, loss: 0.025712
 >> iter 25000, loss: 0.016309
 >> iter 26000, loss: 0.041149
 >> iter 27000, loss: 0.045343
 >> iter 28000, loss: 0.024850
 >> iter 29000, loss: 0.013892
 >> iter 30000, loss: 0.009133
   Number of active neurons: 10
 >> iter 31000, loss: 0.006981
 >> iter 32000, loss: 0.006358
 >> iter 33000, loss: 0.104388
 >> iter 34000, loss: 0.056409
 >> iter 35000, loss: 0.024639
 >> iter 36000, loss: 0.012687
 >> iter 37000, loss: 0.008672
 >> iter 38000, loss: 0.006396
 >> iter 39000, loss: 0.005200
 >> iter 40000, loss: 0.004658
   Number of active neurons: 10
 >> iter 41000, loss: 0.004392
 >> iter 42000, loss: 0.004081
 >> iter 43000, loss: 0.003904
 >> iter 44000, loss: 0.038279
 >> iter 45000, loss: 0.016620
 >> iter 46000, loss: 0.008795
 >> iter 47000, loss: 0.010192
 >> iter 48000, loss: 0.006118
 >> iter 49000, loss: 0.004677
 >> iter 50000, loss: 0.003908
   Number of active neurons: 10
 >> iter 51000, loss: 0.003359
 >> iter 52000, loss: 0.003275
 >> iter 53000, loss: 0.003104
 >> iter 54000, loss: 0.004652
 >> iter 55000, loss: 0.003571
 >> iter 56000, loss: 0.003033
 >> iter 57000, loss: 0.002809
 >> iter 58000, loss: 0.002648
 >> iter 59000, loss: 0.002614
 >> iter 60000, loss: 0.002471
   Number of active neurons: 10
 >> iter 61000, loss: 0.002333
 >> iter 62000, loss: 0.003412
 >> iter 63000, loss: 0.002924
 >> iter 64000, loss: 0.002536
 >> iter 65000, loss: 0.002265
 >> iter 66000, loss: 0.010216
 >> iter 67000, loss: 0.005275
 >> iter 68000, loss: 0.003253
 >> iter 69000, loss: 0.002473
 >> iter 70000, loss: 0.002216
   Number of active neurons: 10
 >> iter 71000, loss: 0.002042
 >> iter 72000, loss: 0.001857
 >> iter 73000, loss: 0.001833
 >> iter 74000, loss: 0.037089
 >> iter 75000, loss: 0.015478
 >> iter 76000, loss: 0.007175
 >> iter 77000, loss: 0.003892
 >> iter 78000, loss: 0.002707
 >> iter 79000, loss: 0.002134
 >> iter 80000, loss: 0.002038
   Number of active neurons: 10
 >> iter 81000, loss: 0.011845
 >> iter 82000, loss: 0.021151
 >> iter 83000, loss: 0.009054
 >> iter 84000, loss: 0.004394
 >> iter 85000, loss: 0.002763
 >> iter 86000, loss: 0.002341
 >> iter 87000, loss: 0.001866
 >> iter 88000, loss: 0.002139
 >> iter 89000, loss: 0.001718
 >> iter 90000, loss: 0.001608
   Number of active neurons: 10
 >> iter 91000, loss: 0.001539
 >> iter 92000, loss: 0.001631
 >> iter 93000, loss: 0.001442
 >> iter 94000, loss: 0.001492
 >> iter 95000, loss: 0.001453
 >> iter 96000, loss: 0.001412
 >> iter 97000, loss: 0.001283
 >> iter 98000, loss: 0.001286
 >> iter 99000, loss: 0.001222
 >> iter 100000, loss: 0.001457
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.753677
 >> iter 2000, loss: 10.621014
 >> iter 3000, loss: 8.691352
 >> iter 4000, loss: 7.963622
 >> iter 5000, loss: 7.704239
 >> iter 6000, loss: 7.592667
 >> iter 7000, loss: 7.527272
 >> iter 8000, loss: 7.296713
 >> iter 9000, loss: 7.006171
 >> iter 10000, loss: 6.611140
   Number of active neurons: 10
 >> iter 11000, loss: 5.964620
 >> iter 12000, loss: 5.613346
 >> iter 13000, loss: 4.899415
 >> iter 14000, loss: 2.129714
 >> iter 15000, loss: 0.838979
 >> iter 16000, loss: 0.377102
 >> iter 17000, loss: 0.158645
 >> iter 18000, loss: 0.105491
 >> iter 19000, loss: 0.053932
 >> iter 20000, loss: 0.030918
   Number of active neurons: 10
 >> iter 21000, loss: 0.021147
 >> iter 22000, loss: 0.063505
 >> iter 23000, loss: 0.032402
 >> iter 24000, loss: 0.019253
 >> iter 25000, loss: 0.013424
 >> iter 26000, loss: 0.011290
 >> iter 27000, loss: 0.100502
 >> iter 28000, loss: 0.044884
 >> iter 29000, loss: 0.022672
 >> iter 30000, loss: 0.043422
   Number of active neurons: 10
 >> iter 31000, loss: 0.020924
 >> iter 32000, loss: 0.012314
 >> iter 33000, loss: 0.008884
 >> iter 34000, loss: 0.006945
 >> iter 35000, loss: 0.006735
 >> iter 36000, loss: 0.074792
 >> iter 37000, loss: 0.031820
 >> iter 38000, loss: 0.015204
 >> iter 39000, loss: 0.008798
 >> iter 40000, loss: 0.006408
   Number of active neurons: 10
 >> iter 41000, loss: 0.005434
 >> iter 42000, loss: 0.004819
 >> iter 43000, loss: 0.004519
 >> iter 44000, loss: 0.004206
 >> iter 45000, loss: 0.004224
 >> iter 46000, loss: 0.004101
 >> iter 47000, loss: 0.003880
 >> iter 48000, loss: 0.003591
 >> iter 49000, loss: 0.003654
 >> iter 50000, loss: 0.003458
   Number of active neurons: 10
 >> iter 51000, loss: 0.003255
 >> iter 52000, loss: 0.003224
 >> iter 53000, loss: 0.003296
 >> iter 54000, loss: 0.003214
 >> iter 55000, loss: 0.003564
 >> iter 56000, loss: 0.035374
 >> iter 57000, loss: 0.015834
 >> iter 58000, loss: 0.008189
 >> iter 59000, loss: 0.004958
 >> iter 60000, loss: 0.004429
   Number of active neurons: 10
 >> iter 61000, loss: 0.003592
 >> iter 62000, loss: 0.003135
 >> iter 63000, loss: 0.002777
 >> iter 64000, loss: 0.002756
 >> iter 65000, loss: 0.002684
 >> iter 66000, loss: 0.002746
 >> iter 67000, loss: 0.002450
 >> iter 68000, loss: 0.002720
 >> iter 69000, loss: 0.002334
 >> iter 70000, loss: 0.022497
   Number of active neurons: 10
 >> iter 71000, loss: 0.010037
 >> iter 72000, loss: 0.005290
 >> iter 73000, loss: 0.003526
 >> iter 74000, loss: 0.002696
 >> iter 75000, loss: 0.002371
 >> iter 76000, loss: 0.002163
 >> iter 77000, loss: 0.002063
 >> iter 78000, loss: 0.002132
 >> iter 79000, loss: 0.001975
 >> iter 80000, loss: 0.002064
   Number of active neurons: 10
 >> iter 81000, loss: 0.002019
 >> iter 82000, loss: 0.010634
 >> iter 83000, loss: 0.005508
 >> iter 84000, loss: 0.004067
 >> iter 85000, loss: 0.002717
 >> iter 86000, loss: 0.002115
 >> iter 87000, loss: 0.002050
 >> iter 88000, loss: 0.001881
 >> iter 89000, loss: 0.001673
 >> iter 90000, loss: 0.001571
   Number of active neurons: 10
 >> iter 91000, loss: 0.001533
 >> iter 92000, loss: 0.001468
 >> iter 93000, loss: 0.001562
 >> iter 94000, loss: 0.001684
 >> iter 95000, loss: 0.001709
 >> iter 96000, loss: 0.001740
 >> iter 97000, loss: 0.023506
 >> iter 98000, loss: 0.010062
 >> iter 99000, loss: 0.004813
 >> iter 100000, loss: 0.003738
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.814317
 >> iter 2000, loss: 10.657869
 >> iter 3000, loss: 8.707917
 >> iter 4000, loss: 8.039151
 >> iter 5000, loss: 7.717033
 >> iter 6000, loss: 7.600767
 >> iter 7000, loss: 7.550635
 >> iter 8000, loss: 7.319479
 >> iter 9000, loss: 6.988927
 >> iter 10000, loss: 6.661524
   Number of active neurons: 10
 >> iter 11000, loss: 6.056359
 >> iter 12000, loss: 5.659757
 >> iter 13000, loss: 5.426446
 >> iter 14000, loss: 5.098971
 >> iter 15000, loss: 4.737837
 >> iter 16000, loss: 4.398871
 >> iter 17000, loss: 4.184076
 >> iter 18000, loss: 4.076239
 >> iter 19000, loss: 3.949865
 >> iter 20000, loss: 3.646139
   Number of active neurons: 10
 >> iter 21000, loss: 3.690990
 >> iter 22000, loss: 3.155618
 >> iter 23000, loss: 1.638934
 >> iter 24000, loss: 0.772210
 >> iter 25000, loss: 0.464740
 >> iter 26000, loss: 0.246200
 >> iter 27000, loss: 0.227045
 >> iter 28000, loss: 0.165585
 >> iter 29000, loss: 0.114234
 >> iter 30000, loss: 0.135075
   Number of active neurons: 10
 >> iter 31000, loss: 0.065413
 >> iter 32000, loss: 0.081815
 >> iter 33000, loss: 0.040684
 >> iter 34000, loss: 0.023640
 >> iter 35000, loss: 0.193280
 >> iter 36000, loss: 0.088679
 >> iter 37000, loss: 0.126463
 >> iter 38000, loss: 0.075388
 >> iter 39000, loss: 0.035661
 >> iter 40000, loss: 0.027696
   Number of active neurons: 10
 >> iter 41000, loss: 0.016777
 >> iter 42000, loss: 0.013350
 >> iter 43000, loss: 0.009840
 >> iter 44000, loss: 0.018408
 >> iter 45000, loss: 0.011209
 >> iter 46000, loss: 0.008337
 >> iter 47000, loss: 0.007202
 >> iter 48000, loss: 0.006445
 >> iter 49000, loss: 0.005686
 >> iter 50000, loss: 0.005167
   Number of active neurons: 10
 >> iter 51000, loss: 0.004840
 >> iter 52000, loss: 0.004629
 >> iter 53000, loss: 0.004564
 >> iter 54000, loss: 0.049255
 >> iter 55000, loss: 0.021110
 >> iter 56000, loss: 0.039972
 >> iter 57000, loss: 0.017892
 >> iter 58000, loss: 0.009253
 >> iter 59000, loss: 0.022223
 >> iter 60000, loss: 0.018960
   Number of active neurons: 10
 >> iter 61000, loss: 0.095222
 >> iter 62000, loss: 0.038726
 >> iter 63000, loss: 0.017352
 >> iter 64000, loss: 0.010869
 >> iter 65000, loss: 0.006551
 >> iter 66000, loss: 0.004691
 >> iter 67000, loss: 0.003894
 >> iter 68000, loss: 0.003571
 >> iter 69000, loss: 0.003292
 >> iter 70000, loss: 0.003185
   Number of active neurons: 10
 >> iter 71000, loss: 0.024951
 >> iter 72000, loss: 0.011438
 >> iter 73000, loss: 0.006648
 >> iter 74000, loss: 0.004171
 >> iter 75000, loss: 0.003272
 >> iter 76000, loss: 0.002888
 >> iter 77000, loss: 0.052697
 >> iter 78000, loss: 0.028358
 >> iter 79000, loss: 0.012379
 >> iter 80000, loss: 0.102122
   Number of active neurons: 10
 >> iter 81000, loss: 0.040129
 >> iter 82000, loss: 0.017130
 >> iter 83000, loss: 0.008340
 >> iter 84000, loss: 0.004960
 >> iter 85000, loss: 0.044255
 >> iter 86000, loss: 0.018127
 >> iter 87000, loss: 0.008591
 >> iter 88000, loss: 0.006678
 >> iter 89000, loss: 0.033454
 >> iter 90000, loss: 0.023842
   Number of active neurons: 10
 >> iter 91000, loss: 0.010626
 >> iter 92000, loss: 0.057590
 >> iter 93000, loss: 0.024373
 >> iter 94000, loss: 0.022620
 >> iter 95000, loss: 0.010462
 >> iter 96000, loss: 0.005751
 >> iter 97000, loss: 0.004104
 >> iter 98000, loss: 0.013488
 >> iter 99000, loss: 0.006596
 >> iter 100000, loss: 0.004134
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 15.659070
 >> iter 2000, loss: 10.578779
 >> iter 3000, loss: 8.691182
 >> iter 4000, loss: 7.973325
 >> iter 5000, loss: 7.713780
 >> iter 6000, loss: 7.615212
 >> iter 7000, loss: 7.582024
 >> iter 8000, loss: 7.559731
 >> iter 9000, loss: 7.562936
 >> iter 10000, loss: 7.559206
   Number of active neurons: 10
 >> iter 11000, loss: 7.529807
 >> iter 12000, loss: 7.264441
 >> iter 13000, loss: 6.956699
 >> iter 14000, loss: 6.766814
 >> iter 15000, loss: 6.700723
 >> iter 16000, loss: 6.469151
 >> iter 17000, loss: 6.047417
 >> iter 18000, loss: 4.455129
 >> iter 19000, loss: 1.984449
 >> iter 20000, loss: 1.031645
   Number of active neurons: 10
 >> iter 21000, loss: 0.564467
 >> iter 22000, loss: 0.315536
 >> iter 23000, loss: 0.207178
 >> iter 24000, loss: 0.102808
 >> iter 25000, loss: 0.090464
 >> iter 26000, loss: 0.097180
 >> iter 27000, loss: 0.090230
 >> iter 28000, loss: 0.050948
 >> iter 29000, loss: 0.110811
 >> iter 30000, loss: 0.068194
   Number of active neurons: 10
 >> iter 31000, loss: 0.055440
 >> iter 32000, loss: 0.047510
 >> iter 33000, loss: 0.081371
 >> iter 34000, loss: 0.179839
 >> iter 35000, loss: 0.140245
 >> iter 36000, loss: 0.060007
 >> iter 37000, loss: 0.268463
 >> iter 38000, loss: 0.137478
 >> iter 39000, loss: 0.059914
 >> iter 40000, loss: 0.030038
   Number of active neurons: 10
 >> iter 41000, loss: 0.017360
 >> iter 42000, loss: 0.112140
 >> iter 43000, loss: 0.123783
 >> iter 44000, loss: 0.107426
 >> iter 45000, loss: 0.046392
 >> iter 46000, loss: 0.023170
 >> iter 47000, loss: 0.021171
 >> iter 48000, loss: 0.012693
 >> iter 49000, loss: 0.008904
 >> iter 50000, loss: 0.007123
   Number of active neurons: 10
 >> iter 51000, loss: 0.049357
 >> iter 52000, loss: 0.031912
 >> iter 53000, loss: 0.015531
 >> iter 54000, loss: 0.009190
 >> iter 55000, loss: 0.065351
 >> iter 56000, loss: 0.046429
 >> iter 57000, loss: 0.043492
 >> iter 58000, loss: 0.131343
 >> iter 59000, loss: 0.053554
 >> iter 60000, loss: 0.105207
   Number of active neurons: 10
 >> iter 61000, loss: 0.043751
 >> iter 62000, loss: 0.020036
 >> iter 63000, loss: 0.010914
 >> iter 64000, loss: 0.121838
 >> iter 65000, loss: 0.064752
 >> iter 66000, loss: 0.038287
 >> iter 67000, loss: 0.032572
 >> iter 68000, loss: 0.080278
 >> iter 69000, loss: 0.033328
 >> iter 70000, loss: 0.051154
   Number of active neurons: 10
 >> iter 71000, loss: 0.042856
 >> iter 72000, loss: 0.019447
 >> iter 73000, loss: 0.065392
 >> iter 74000, loss: 0.032556
 >> iter 75000, loss: 0.015522
 >> iter 76000, loss: 0.086110
 >> iter 77000, loss: 0.035282
 >> iter 78000, loss: 0.016673
 >> iter 79000, loss: 0.013362
 >> iter 80000, loss: 0.036538
   Number of active neurons: 10
 >> iter 81000, loss: 0.016640
 >> iter 82000, loss: 0.008863
 >> iter 83000, loss: 0.005699
 >> iter 84000, loss: 0.004379
 >> iter 85000, loss: 0.003818
 >> iter 86000, loss: 0.004164
 >> iter 87000, loss: 0.004013
 >> iter 88000, loss: 0.003618
 >> iter 89000, loss: 0.168180
 >> iter 90000, loss: 0.088554
   Number of active neurons: 10
 >> iter 91000, loss: 0.035637
 >> iter 92000, loss: 0.015620
 >> iter 93000, loss: 0.008023
 >> iter 94000, loss: 0.005052
 >> iter 95000, loss: 0.003871
 >> iter 96000, loss: 0.004895
 >> iter 97000, loss: 0.003897
 >> iter 98000, loss: 0.009044
 >> iter 99000, loss: 0.005130
 >> iter 100000, loss: 0.037847
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.787004
 >> iter 2000, loss: 10.647171
 >> iter 3000, loss: 8.734264
 >> iter 4000, loss: 8.000225
 >> iter 5000, loss: 7.844818
 >> iter 6000, loss: 7.257603
 >> iter 7000, loss: 6.630294
 >> iter 8000, loss: 4.050251
 >> iter 9000, loss: 1.659562
 >> iter 10000, loss: 0.641066
   Number of active neurons: 10
 >> iter 11000, loss: 0.253965
 >> iter 12000, loss: 0.117659
 >> iter 13000, loss: 0.054261
 >> iter 14000, loss: 0.029460
 >> iter 15000, loss: 0.021758
 >> iter 16000, loss: 0.066806
 >> iter 17000, loss: 0.031867
 >> iter 18000, loss: 0.027932
 >> iter 19000, loss: 0.016906
 >> iter 20000, loss: 0.011340
   Number of active neurons: 10
 >> iter 21000, loss: 0.009268
 >> iter 22000, loss: 0.008418
 >> iter 23000, loss: 0.006802
 >> iter 24000, loss: 0.005923
 >> iter 25000, loss: 0.005394
 >> iter 26000, loss: 0.004879
 >> iter 27000, loss: 0.004829
 >> iter 28000, loss: 0.004484
 >> iter 29000, loss: 0.004081
 >> iter 30000, loss: 0.003775
   Number of active neurons: 10
 >> iter 31000, loss: 0.003699
 >> iter 32000, loss: 0.004347
 >> iter 33000, loss: 0.003790
 >> iter 34000, loss: 0.004235
 >> iter 35000, loss: 0.060511
 >> iter 36000, loss: 0.024878
 >> iter 37000, loss: 0.011371
 >> iter 38000, loss: 0.006475
 >> iter 39000, loss: 0.004526
 >> iter 40000, loss: 0.003479
   Number of active neurons: 10
 >> iter 41000, loss: 0.003035
 >> iter 42000, loss: 0.002857
 >> iter 43000, loss: 0.002671
 >> iter 44000, loss: 0.002518
 >> iter 45000, loss: 0.005260
 >> iter 46000, loss: 0.006869
 >> iter 47000, loss: 0.004190
 >> iter 48000, loss: 0.003051
 >> iter 49000, loss: 0.002780
 >> iter 50000, loss: 0.002494
   Number of active neurons: 10
 >> iter 51000, loss: 0.002345
 >> iter 52000, loss: 0.002160
 >> iter 53000, loss: 0.003372
 >> iter 54000, loss: 0.002515
 >> iter 55000, loss: 0.002191
 >> iter 56000, loss: 0.002018
 >> iter 57000, loss: 0.001832
 >> iter 58000, loss: 0.001806
 >> iter 59000, loss: 0.001695
 >> iter 60000, loss: 0.001650
   Number of active neurons: 10
 >> iter 61000, loss: 0.001551
 >> iter 62000, loss: 0.001531
 >> iter 63000, loss: 0.001477
 >> iter 64000, loss: 0.001444
 >> iter 65000, loss: 0.001394
 >> iter 66000, loss: 0.002228
 >> iter 67000, loss: 0.001820
 >> iter 68000, loss: 0.001756
 >> iter 69000, loss: 0.001523
 >> iter 70000, loss: 0.001404
   Number of active neurons: 10
 >> iter 71000, loss: 0.001314
 >> iter 72000, loss: 0.001363
 >> iter 73000, loss: 0.001289
 >> iter 74000, loss: 0.001480
 >> iter 75000, loss: 0.001284
 >> iter 76000, loss: 0.001207
 >> iter 77000, loss: 0.001248
 >> iter 78000, loss: 0.001148
 >> iter 79000, loss: 0.001113
 >> iter 80000, loss: 0.001097
   Number of active neurons: 10
 >> iter 81000, loss: 0.001058
 >> iter 82000, loss: 0.001036
 >> iter 83000, loss: 0.001444
 >> iter 84000, loss: 0.001190
 >> iter 85000, loss: 0.002120
 >> iter 86000, loss: 0.073511
 >> iter 87000, loss: 0.133334
 >> iter 88000, loss: 0.050030
 >> iter 89000, loss: 0.019358
 >> iter 90000, loss: 0.008021
   Number of active neurons: 10
 >> iter 91000, loss: 0.003830
 >> iter 92000, loss: 0.002257
 >> iter 93000, loss: 0.001636
 >> iter 94000, loss: 0.001361
 >> iter 95000, loss: 0.001264
 >> iter 96000, loss: 0.001207
 >> iter 97000, loss: 0.001159
 >> iter 98000, loss: 0.001278
 >> iter 99000, loss: 0.001178
 >> iter 100000, loss: 0.001099
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.783374
 >> iter 2000, loss: 10.697836
 >> iter 3000, loss: 8.772827
 >> iter 4000, loss: 8.043302
 >> iter 5000, loss: 7.735848
 >> iter 6000, loss: 7.431323
 >> iter 7000, loss: 7.111495
 >> iter 8000, loss: 6.752606
 >> iter 9000, loss: 6.286006
 >> iter 10000, loss: 5.833798
   Number of active neurons: 10
 >> iter 11000, loss: 5.604638
 >> iter 12000, loss: 5.496475
 >> iter 13000, loss: 5.451357
 >> iter 14000, loss: 5.377969
 >> iter 15000, loss: 5.395469
 >> iter 16000, loss: 5.291516
 >> iter 17000, loss: 5.232767
 >> iter 18000, loss: 5.108064
 >> iter 19000, loss: 4.940105
 >> iter 20000, loss: 4.872845
   Number of active neurons: 10
 >> iter 21000, loss: 4.768784
 >> iter 22000, loss: 4.704166
 >> iter 23000, loss: 4.632612
 >> iter 24000, loss: 4.625306
 >> iter 25000, loss: 4.595972
 >> iter 26000, loss: 4.620797
 >> iter 27000, loss: 4.623714
 >> iter 28000, loss: 4.612684
 >> iter 29000, loss: 4.568489
 >> iter 30000, loss: 4.566262
   Number of active neurons: 10
 >> iter 31000, loss: 4.570430
 >> iter 32000, loss: 4.592092
 >> iter 33000, loss: 4.553509
 >> iter 34000, loss: 4.563129
 >> iter 35000, loss: 4.573756
 >> iter 36000, loss: 4.296737
 >> iter 37000, loss: 4.166396
 >> iter 38000, loss: 3.192096
 >> iter 39000, loss: 1.554973
 >> iter 40000, loss: 0.670731
   Number of active neurons: 10
 >> iter 41000, loss: 0.270020
 >> iter 42000, loss: 0.178729
 >> iter 43000, loss: 0.100556
 >> iter 44000, loss: 0.058565
 >> iter 45000, loss: 0.036918
 >> iter 46000, loss: 0.163114
 >> iter 47000, loss: 0.166022
 >> iter 48000, loss: 0.073217
 >> iter 49000, loss: 0.035767
 >> iter 50000, loss: 0.054339
   Number of active neurons: 10
 >> iter 51000, loss: 0.071010
 >> iter 52000, loss: 0.159793
 >> iter 53000, loss: 0.218795
 >> iter 54000, loss: 0.091735
 >> iter 55000, loss: 0.041065
 >> iter 56000, loss: 0.021207
 >> iter 57000, loss: 0.013104
 >> iter 58000, loss: 0.027289
 >> iter 59000, loss: 0.025003
 >> iter 60000, loss: 0.014194
   Number of active neurons: 10
 >> iter 61000, loss: 0.009582
 >> iter 62000, loss: 0.007774
 >> iter 63000, loss: 0.006511
 >> iter 64000, loss: 0.005687
 >> iter 65000, loss: 0.005399
 >> iter 66000, loss: 0.004937
 >> iter 67000, loss: 0.005242
 >> iter 68000, loss: 0.004495
 >> iter 69000, loss: 0.004007
 >> iter 70000, loss: 0.016535
   Number of active neurons: 10
 >> iter 71000, loss: 0.018372
 >> iter 72000, loss: 0.009133
 >> iter 73000, loss: 0.017033
 >> iter 74000, loss: 0.034914
 >> iter 75000, loss: 0.015182
 >> iter 76000, loss: 0.009336
 >> iter 77000, loss: 0.006320
 >> iter 78000, loss: 0.004597
 >> iter 79000, loss: 0.003746
 >> iter 80000, loss: 0.003367
   Number of active neurons: 10
 >> iter 81000, loss: 0.003687
 >> iter 82000, loss: 0.002951
 >> iter 83000, loss: 0.003990
 >> iter 84000, loss: 0.003060
 >> iter 85000, loss: 0.006636
 >> iter 86000, loss: 0.033249
 >> iter 87000, loss: 0.017632
 >> iter 88000, loss: 0.039534
 >> iter 89000, loss: 0.045503
 >> iter 90000, loss: 0.021945
   Number of active neurons: 10
 >> iter 91000, loss: 0.010249
 >> iter 92000, loss: 0.008724
 >> iter 93000, loss: 0.080942
 >> iter 94000, loss: 0.032248
 >> iter 95000, loss: 0.014042
 >> iter 96000, loss: 0.007069
 >> iter 97000, loss: 0.041660
 >> iter 98000, loss: 0.023488
 >> iter 99000, loss: 0.010665
 >> iter 100000, loss: 0.006021
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.913565
 >> iter 2000, loss: 10.703528
 >> iter 3000, loss: 8.746278
 >> iter 4000, loss: 7.993626
 >> iter 5000, loss: 7.730736
 >> iter 6000, loss: 7.619260
 >> iter 7000, loss: 7.587752
 >> iter 8000, loss: 7.560000
 >> iter 9000, loss: 7.531541
 >> iter 10000, loss: 7.295375
   Number of active neurons: 10
 >> iter 11000, loss: 6.973183
 >> iter 12000, loss: 6.732343
 >> iter 13000, loss: 6.197889
 >> iter 14000, loss: 5.464493
 >> iter 15000, loss: 2.405364
 >> iter 16000, loss: 0.928124
 >> iter 17000, loss: 0.478952
 >> iter 18000, loss: 0.197793
 >> iter 19000, loss: 0.107751
 >> iter 20000, loss: 0.052353
   Number of active neurons: 10
 >> iter 21000, loss: 0.109354
 >> iter 22000, loss: 0.051081
 >> iter 23000, loss: 0.028062
 >> iter 24000, loss: 0.019041
 >> iter 25000, loss: 0.126860
 >> iter 26000, loss: 0.054981
 >> iter 27000, loss: 0.027642
 >> iter 28000, loss: 0.016297
 >> iter 29000, loss: 0.011441
 >> iter 30000, loss: 0.009152
   Number of active neurons: 10
 >> iter 31000, loss: 0.007937
 >> iter 32000, loss: 0.007149
 >> iter 33000, loss: 0.006482
 >> iter 34000, loss: 0.005932
 >> iter 35000, loss: 0.005635
 >> iter 36000, loss: 0.005323
 >> iter 37000, loss: 0.016903
 >> iter 38000, loss: 0.009656
 >> iter 39000, loss: 0.006563
 >> iter 40000, loss: 0.005273
   Number of active neurons: 10
 >> iter 41000, loss: 0.004615
 >> iter 42000, loss: 0.004253
 >> iter 43000, loss: 0.004024
 >> iter 44000, loss: 0.004151
 >> iter 45000, loss: 0.003769
 >> iter 46000, loss: 0.003616
 >> iter 47000, loss: 0.003316
 >> iter 48000, loss: 0.003337
 >> iter 49000, loss: 0.003097
 >> iter 50000, loss: 0.002921
   Number of active neurons: 10
 >> iter 51000, loss: 0.003499
 >> iter 52000, loss: 0.003291
 >> iter 53000, loss: 0.002869
 >> iter 54000, loss: 0.002693
 >> iter 55000, loss: 0.002519
 >> iter 56000, loss: 0.002428
 >> iter 57000, loss: 0.002551
 >> iter 58000, loss: 0.002431
 >> iter 59000, loss: 0.002298
 >> iter 60000, loss: 0.002172
   Number of active neurons: 10
 >> iter 61000, loss: 0.002128
 >> iter 62000, loss: 0.002086
 >> iter 63000, loss: 0.002026
 >> iter 64000, loss: 0.002038
 >> iter 65000, loss: 0.001934
 >> iter 66000, loss: 0.001865
 >> iter 67000, loss: 0.001808
 >> iter 68000, loss: 0.001807
 >> iter 69000, loss: 0.001743
 >> iter 70000, loss: 0.001721
   Number of active neurons: 10
 >> iter 71000, loss: 0.001652
 >> iter 72000, loss: 0.001648
 >> iter 73000, loss: 0.001659
 >> iter 74000, loss: 0.001612
 >> iter 75000, loss: 0.001616
 >> iter 76000, loss: 0.001536
 >> iter 77000, loss: 0.001508
 >> iter 78000, loss: 0.001668
 >> iter 79000, loss: 0.001533
 >> iter 80000, loss: 0.001481
   Number of active neurons: 10
 >> iter 81000, loss: 0.001410
 >> iter 82000, loss: 0.001374
 >> iter 83000, loss: 0.001475
 >> iter 84000, loss: 0.001390
 >> iter 85000, loss: 0.001348
 >> iter 86000, loss: 0.001320
 >> iter 87000, loss: 0.001293
 >> iter 88000, loss: 0.001264
 >> iter 89000, loss: 0.001244
 >> iter 90000, loss: 0.041609
   Number of active neurons: 10
 >> iter 91000, loss: 0.017293
 >> iter 92000, loss: 0.059461
 >> iter 93000, loss: 0.023108
 >> iter 94000, loss: 0.009610
 >> iter 95000, loss: 0.004546
 >> iter 96000, loss: 0.002853
 >> iter 97000, loss: 0.002005
 >> iter 98000, loss: 0.001582
 >> iter 99000, loss: 0.001435
 >> iter 100000, loss: 0.001370
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.704963
 >> iter 2000, loss: 10.624304
 >> iter 3000, loss: 8.734052
 >> iter 4000, loss: 8.019160
 >> iter 5000, loss: 7.767606
 >> iter 6000, loss: 7.661701
 >> iter 7000, loss: 7.611895
 >> iter 8000, loss: 7.500854
 >> iter 9000, loss: 7.162056
 >> iter 10000, loss: 6.870270
   Number of active neurons: 10
 >> iter 11000, loss: 6.410031
 >> iter 12000, loss: 5.905516
 >> iter 13000, loss: 5.617007
 >> iter 14000, loss: 5.537474
 >> iter 15000, loss: 5.431391
 >> iter 16000, loss: 5.341484
 >> iter 17000, loss: 5.278242
 >> iter 18000, loss: 5.096759
 >> iter 19000, loss: 4.889975
 >> iter 20000, loss: 4.654558
   Number of active neurons: 10
 >> iter 21000, loss: 4.458547
 >> iter 22000, loss: 4.278421
 >> iter 23000, loss: 4.261735
 >> iter 24000, loss: 4.147703
 >> iter 25000, loss: 4.163227
 >> iter 26000, loss: 4.127234
 >> iter 27000, loss: 4.154824
 >> iter 28000, loss: 4.219662
 >> iter 29000, loss: 4.163930
 >> iter 30000, loss: 4.067793
   Number of active neurons: 10
 >> iter 31000, loss: 4.084597
 >> iter 32000, loss: 4.025306
 >> iter 33000, loss: 4.048632
 >> iter 34000, loss: 4.029994
 >> iter 35000, loss: 4.027345
 >> iter 36000, loss: 3.972657
 >> iter 37000, loss: 4.013172
 >> iter 38000, loss: 4.117224
 >> iter 39000, loss: 4.090436
 >> iter 40000, loss: 4.087150
   Number of active neurons: 10
 >> iter 41000, loss: 4.024437
 >> iter 42000, loss: 4.002857
 >> iter 43000, loss: 3.987259
 >> iter 44000, loss: 3.955846
 >> iter 45000, loss: 3.996383
 >> iter 46000, loss: 3.933929
 >> iter 47000, loss: 4.151520
 >> iter 48000, loss: 4.015134
 >> iter 49000, loss: 3.729977
 >> iter 50000, loss: 3.820020
   Number of active neurons: 10
 >> iter 51000, loss: 3.557380
 >> iter 52000, loss: 3.392067
 >> iter 53000, loss: 3.428233
 >> iter 54000, loss: 3.063291
 >> iter 55000, loss: 3.078157
 >> iter 56000, loss: 3.154962
 >> iter 57000, loss: 3.215826
 >> iter 58000, loss: 2.868634
 >> iter 59000, loss: 2.819479
 >> iter 60000, loss: 2.956297
   Number of active neurons: 10
 >> iter 61000, loss: 2.616186
 >> iter 62000, loss: 2.380397
 >> iter 63000, loss: 2.259515
 >> iter 64000, loss: 2.205423
 >> iter 65000, loss: 2.758715
 >> iter 66000, loss: 2.561874
 >> iter 67000, loss: 2.603614
 >> iter 68000, loss: 2.406488
 >> iter 69000, loss: 2.909819
 >> iter 70000, loss: 2.615360
   Number of active neurons: 10
 >> iter 71000, loss: 2.353018
 >> iter 72000, loss: 2.328960
 >> iter 73000, loss: 2.099689
 >> iter 74000, loss: 1.972225
 >> iter 75000, loss: 1.909900
 >> iter 76000, loss: 2.395316
 >> iter 77000, loss: 2.397289
 >> iter 78000, loss: 2.373266
 >> iter 79000, loss: 1.907164
 >> iter 80000, loss: 2.239968
   Number of active neurons: 10
 >> iter 81000, loss: 1.921996
 >> iter 82000, loss: 2.033001
 >> iter 83000, loss: 1.962092
 >> iter 84000, loss: 2.008757
 >> iter 85000, loss: 2.186603
 >> iter 86000, loss: 1.811588
 >> iter 87000, loss: 1.314095
 >> iter 88000, loss: 0.897862
 >> iter 89000, loss: 0.525052
 >> iter 90000, loss: 0.385952
   Number of active neurons: 10
 >> iter 91000, loss: 0.309972
 >> iter 92000, loss: 0.320197
 >> iter 93000, loss: 0.201347
 >> iter 94000, loss: 0.229205
 >> iter 95000, loss: 0.279201
 >> iter 96000, loss: 0.291620
 >> iter 97000, loss: 0.179553
 >> iter 98000, loss: 0.212038
 >> iter 99000, loss: 0.319805
 >> iter 100000, loss: 0.782803
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.145997080058
   - Test - Long: 1.05494725264
   - Test - Big: 0.10099899001
   - Test - A: 0.0
   - Test - B: 0.666622225185
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.798269
 >> iter 2000, loss: 10.669385
 >> iter 3000, loss: 8.720237
 >> iter 4000, loss: 7.990518
 >> iter 5000, loss: 7.730986
 >> iter 6000, loss: 7.617972
 >> iter 7000, loss: 7.549883
 >> iter 8000, loss: 7.276249
 >> iter 9000, loss: 6.857184
 >> iter 10000, loss: 6.161730
   Number of active neurons: 10
 >> iter 11000, loss: 5.669912
 >> iter 12000, loss: 5.132220
 >> iter 13000, loss: 4.883174
 >> iter 14000, loss: 4.585802
 >> iter 15000, loss: 4.434852
 >> iter 16000, loss: 4.383696
 >> iter 17000, loss: 4.333931
 >> iter 18000, loss: 4.239298
 >> iter 19000, loss: 4.326061
 >> iter 20000, loss: 4.200466
   Number of active neurons: 10
 >> iter 21000, loss: 4.235601
 >> iter 22000, loss: 4.185116
 >> iter 23000, loss: 4.209798
 >> iter 24000, loss: 4.154185
 >> iter 25000, loss: 4.205955
 >> iter 26000, loss: 4.125708
 >> iter 27000, loss: 4.186544
 >> iter 28000, loss: 4.139913
 >> iter 29000, loss: 4.175599
 >> iter 30000, loss: 4.072667
   Number of active neurons: 10
 >> iter 31000, loss: 4.239352
 >> iter 32000, loss: 4.139074
 >> iter 33000, loss: 4.032312
 >> iter 34000, loss: 3.893821
 >> iter 35000, loss: 3.582545
 >> iter 36000, loss: 3.059770
 >> iter 37000, loss: 2.560912
 >> iter 38000, loss: 1.944275
 >> iter 39000, loss: 2.125380
 >> iter 40000, loss: 1.946883
   Number of active neurons: 10
 >> iter 41000, loss: 1.935804
 >> iter 42000, loss: 1.795636
 >> iter 43000, loss: 1.788551
 >> iter 44000, loss: 1.541314
 >> iter 45000, loss: 1.615077
 >> iter 46000, loss: 1.634791
 >> iter 47000, loss: 1.725656
 >> iter 48000, loss: 1.655828
 >> iter 49000, loss: 1.304760
 >> iter 50000, loss: 0.566344
   Number of active neurons: 10
 >> iter 51000, loss: 0.269431
 >> iter 52000, loss: 0.196385
 >> iter 53000, loss: 0.106130
 >> iter 54000, loss: 0.098753
 >> iter 55000, loss: 0.048859
 >> iter 56000, loss: 0.028522
 >> iter 57000, loss: 0.018539
 >> iter 58000, loss: 0.014172
 >> iter 59000, loss: 0.013533
 >> iter 60000, loss: 0.013078
   Number of active neurons: 10
 >> iter 61000, loss: 0.010974
 >> iter 62000, loss: 0.009437
 >> iter 63000, loss: 0.008194
 >> iter 64000, loss: 0.007497
 >> iter 65000, loss: 0.006796
 >> iter 66000, loss: 0.006277
 >> iter 67000, loss: 0.006964
 >> iter 68000, loss: 0.005838
 >> iter 69000, loss: 0.005964
 >> iter 70000, loss: 0.005080
   Number of active neurons: 10
 >> iter 71000, loss: 0.006533
 >> iter 72000, loss: 0.005584
 >> iter 73000, loss: 0.004706
 >> iter 74000, loss: 0.004417
 >> iter 75000, loss: 0.004141
 >> iter 76000, loss: 0.003783
 >> iter 77000, loss: 0.003692
 >> iter 78000, loss: 0.003748
 >> iter 79000, loss: 0.006094
 >> iter 80000, loss: 0.004745
   Number of active neurons: 10
 >> iter 81000, loss: 0.003651
 >> iter 82000, loss: 0.003340
 >> iter 83000, loss: 0.003466
 >> iter 84000, loss: 0.003114
 >> iter 85000, loss: 0.002813
 >> iter 86000, loss: 0.002772
 >> iter 87000, loss: 0.002799
 >> iter 88000, loss: 0.002576
 >> iter 89000, loss: 0.002769
 >> iter 90000, loss: 0.002690
   Number of active neurons: 10
 >> iter 91000, loss: 0.002501
 >> iter 92000, loss: 0.002281
 >> iter 93000, loss: 0.002162
 >> iter 94000, loss: 0.040438
 >> iter 95000, loss: 0.016478
 >> iter 96000, loss: 0.007790
 >> iter 97000, loss: 0.004452
 >> iter 98000, loss: 0.003394
 >> iter 99000, loss: 0.002812
 >> iter 100000, loss: 0.002374
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.867616
 >> iter 2000, loss: 10.684715
 >> iter 3000, loss: 8.742756
 >> iter 4000, loss: 8.017679
 >> iter 5000, loss: 7.748019
 >> iter 6000, loss: 7.641390
 >> iter 7000, loss: 7.608880
 >> iter 8000, loss: 7.583555
 >> iter 9000, loss: 7.585680
 >> iter 10000, loss: 7.574958
   Number of active neurons: 10
 >> iter 11000, loss: 7.574245
 >> iter 12000, loss: 7.567986
 >> iter 13000, loss: 7.571750
 >> iter 14000, loss: 7.558197
 >> iter 15000, loss: 7.564733
 >> iter 16000, loss: 7.551635
 >> iter 17000, loss: 7.561435
 >> iter 18000, loss: 7.548969
 >> iter 19000, loss: 7.557238
 >> iter 20000, loss: 7.545476
   Number of active neurons: 9
 >> iter 21000, loss: 7.547555
 >> iter 22000, loss: 7.408204
 >> iter 23000, loss: 6.980251
 >> iter 24000, loss: 6.520825
 >> iter 25000, loss: 6.087143
 >> iter 26000, loss: 5.675287
 >> iter 27000, loss: 3.613397
 >> iter 28000, loss: 1.408691
 >> iter 29000, loss: 0.578932
 >> iter 30000, loss: 0.252066
   Number of active neurons: 10
 >> iter 31000, loss: 0.163080
 >> iter 32000, loss: 0.073971
 >> iter 33000, loss: 0.039485
 >> iter 34000, loss: 0.092183
 >> iter 35000, loss: 0.045750
 >> iter 36000, loss: 0.025462
 >> iter 37000, loss: 0.017550
 >> iter 38000, loss: 0.042747
 >> iter 39000, loss: 0.027282
 >> iter 40000, loss: 0.020119
   Number of active neurons: 10
 >> iter 41000, loss: 0.190700
 >> iter 42000, loss: 0.078214
 >> iter 43000, loss: 0.035669
 >> iter 44000, loss: 0.018531
 >> iter 45000, loss: 0.011583
 >> iter 46000, loss: 0.008817
 >> iter 47000, loss: 0.007423
 >> iter 48000, loss: 0.006800
 >> iter 49000, loss: 0.006907
 >> iter 50000, loss: 0.006465
   Number of active neurons: 10
 >> iter 51000, loss: 0.005881
 >> iter 52000, loss: 0.005382
 >> iter 53000, loss: 0.004884
 >> iter 54000, loss: 0.004295
 >> iter 55000, loss: 0.004192
 >> iter 56000, loss: 0.004170
 >> iter 57000, loss: 0.005064
 >> iter 58000, loss: 0.004556
 >> iter 59000, loss: 0.004273
 >> iter 60000, loss: 0.003696
   Number of active neurons: 10
 >> iter 61000, loss: 0.003441
 >> iter 62000, loss: 0.003211
 >> iter 63000, loss: 0.026397
 >> iter 64000, loss: 0.012177
 >> iter 65000, loss: 0.006552
 >> iter 66000, loss: 0.029535
 >> iter 67000, loss: 0.013093
 >> iter 68000, loss: 0.006756
 >> iter 69000, loss: 0.004232
 >> iter 70000, loss: 0.003533
   Number of active neurons: 10
 >> iter 71000, loss: 0.002890
 >> iter 72000, loss: 0.002658
 >> iter 73000, loss: 0.002504
 >> iter 74000, loss: 0.002422
 >> iter 75000, loss: 0.002243
 >> iter 76000, loss: 0.002117
 >> iter 77000, loss: 0.002008
 >> iter 78000, loss: 0.002104
 >> iter 79000, loss: 0.001952
 >> iter 80000, loss: 0.001975
   Number of active neurons: 10
 >> iter 81000, loss: 0.001880
 >> iter 82000, loss: 0.075329
 >> iter 83000, loss: 0.029398
 >> iter 84000, loss: 0.012240
 >> iter 85000, loss: 0.005874
 >> iter 86000, loss: 0.003889
 >> iter 87000, loss: 0.002681
 >> iter 88000, loss: 0.002305
 >> iter 89000, loss: 0.002076
 >> iter 90000, loss: 0.001907
   Number of active neurons: 10
 >> iter 91000, loss: 0.001802
 >> iter 92000, loss: 0.001722
 >> iter 93000, loss: 0.001684
 >> iter 94000, loss: 0.001675
 >> iter 95000, loss: 0.120099
 >> iter 96000, loss: 0.046026
 >> iter 97000, loss: 0.018442
 >> iter 98000, loss: 0.009206
 >> iter 99000, loss: 0.004596
 >> iter 100000, loss: 0.003018
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 15.753375
 >> iter 2000, loss: 10.629667
 >> iter 3000, loss: 8.731496
 >> iter 4000, loss: 8.015276
 >> iter 5000, loss: 7.735097
 >> iter 6000, loss: 7.592221
 >> iter 7000, loss: 7.185198
 >> iter 8000, loss: 6.732177
 >> iter 9000, loss: 6.218312
 >> iter 10000, loss: 5.764702
   Number of active neurons: 10
 >> iter 11000, loss: 5.442630
 >> iter 12000, loss: 4.616814
 >> iter 13000, loss: 1.965705
 >> iter 14000, loss: 0.843166
 >> iter 15000, loss: 0.413866
 >> iter 16000, loss: 0.201466
 >> iter 17000, loss: 0.106376
 >> iter 18000, loss: 0.056440
 >> iter 19000, loss: 0.034998
 >> iter 20000, loss: 0.021550
   Number of active neurons: 10
 >> iter 21000, loss: 0.073897
 >> iter 22000, loss: 0.225566
 >> iter 23000, loss: 0.092682
 >> iter 24000, loss: 0.041166
 >> iter 25000, loss: 0.021889
 >> iter 26000, loss: 0.013487
 >> iter 27000, loss: 0.010082
 >> iter 28000, loss: 0.008389
 >> iter 29000, loss: 0.008851
 >> iter 30000, loss: 0.007186
   Number of active neurons: 10
 >> iter 31000, loss: 0.006248
 >> iter 32000, loss: 0.005591
 >> iter 33000, loss: 0.005218
 >> iter 34000, loss: 0.005063
 >> iter 35000, loss: 0.005245
 >> iter 36000, loss: 0.004841
 >> iter 37000, loss: 0.067528
 >> iter 38000, loss: 0.028374
 >> iter 39000, loss: 0.015685
 >> iter 40000, loss: 0.010903
   Number of active neurons: 10
 >> iter 41000, loss: 0.006746
 >> iter 42000, loss: 0.004940
 >> iter 43000, loss: 0.009010
 >> iter 44000, loss: 0.005745
 >> iter 45000, loss: 0.014296
 >> iter 46000, loss: 0.012458
 >> iter 47000, loss: 0.006735
 >> iter 48000, loss: 0.004384
 >> iter 49000, loss: 0.087919
 >> iter 50000, loss: 0.034700
   Number of active neurons: 10
 >> iter 51000, loss: 0.014672
 >> iter 52000, loss: 0.007271
 >> iter 53000, loss: 0.004746
 >> iter 54000, loss: 0.004317
 >> iter 55000, loss: 0.003371
 >> iter 56000, loss: 0.002857
 >> iter 57000, loss: 0.061826
 >> iter 58000, loss: 0.024525
 >> iter 59000, loss: 0.010750
 >> iter 60000, loss: 0.005601
   Number of active neurons: 10
 >> iter 61000, loss: 0.003544
 >> iter 62000, loss: 0.002719
 >> iter 63000, loss: 0.038404
 >> iter 64000, loss: 0.015921
 >> iter 65000, loss: 0.007465
 >> iter 66000, loss: 0.004287
 >> iter 67000, loss: 0.003364
 >> iter 68000, loss: 0.002722
 >> iter 69000, loss: 0.002448
 >> iter 70000, loss: 0.002233
   Number of active neurons: 10
 >> iter 71000, loss: 0.002166
 >> iter 72000, loss: 0.002006
 >> iter 73000, loss: 0.001965
 >> iter 74000, loss: 0.001933
 >> iter 75000, loss: 0.001831
 >> iter 76000, loss: 0.001875
 >> iter 77000, loss: 0.001807
 >> iter 78000, loss: 0.001709
 >> iter 79000, loss: 0.001634
 >> iter 80000, loss: 0.002261
   Number of active neurons: 10
 >> iter 81000, loss: 0.001890
 >> iter 82000, loss: 0.001682
 >> iter 83000, loss: 0.001730
 >> iter 84000, loss: 0.001592
 >> iter 85000, loss: 0.001479
 >> iter 86000, loss: 0.001460
 >> iter 87000, loss: 0.001392
 >> iter 88000, loss: 0.001419
 >> iter 89000, loss: 0.001368
 >> iter 90000, loss: 0.001327
   Number of active neurons: 10
 >> iter 91000, loss: 0.001291
 >> iter 92000, loss: 0.001570
 >> iter 93000, loss: 0.001444
 >> iter 94000, loss: 0.001322
 >> iter 95000, loss: 0.001658
 >> iter 96000, loss: 0.001364
 >> iter 97000, loss: 0.001270
 >> iter 98000, loss: 0.001353
 >> iter 99000, loss: 0.001217
 >> iter 100000, loss: 0.001214
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.765588
 >> iter 2000, loss: 10.613220
 >> iter 3000, loss: 8.709882
 >> iter 4000, loss: 7.993979
 >> iter 5000, loss: 7.734711
 >> iter 6000, loss: 7.584542
 >> iter 7000, loss: 7.256092
 >> iter 8000, loss: 6.881036
 >> iter 9000, loss: 6.512043
 >> iter 10000, loss: 6.036281
   Number of active neurons: 10
 >> iter 11000, loss: 2.954208
 >> iter 12000, loss: 1.188569
 >> iter 13000, loss: 0.512773
 >> iter 14000, loss: 0.233837
 >> iter 15000, loss: 0.109959
 >> iter 16000, loss: 0.259936
 >> iter 17000, loss: 0.125066
 >> iter 18000, loss: 0.091074
 >> iter 19000, loss: 0.288988
 >> iter 20000, loss: 0.134205
   Number of active neurons: 10
 >> iter 21000, loss: 0.061707
 >> iter 22000, loss: 0.031142
 >> iter 23000, loss: 0.025845
 >> iter 24000, loss: 0.016034
 >> iter 25000, loss: 0.011504
 >> iter 26000, loss: 0.009135
 >> iter 27000, loss: 0.008404
 >> iter 28000, loss: 0.007062
 >> iter 29000, loss: 0.006024
 >> iter 30000, loss: 0.005594
   Number of active neurons: 10
 >> iter 31000, loss: 0.005786
 >> iter 32000, loss: 0.010443
 >> iter 33000, loss: 0.007249
 >> iter 34000, loss: 0.005322
 >> iter 35000, loss: 0.004441
 >> iter 36000, loss: 0.003966
 >> iter 37000, loss: 0.003678
 >> iter 38000, loss: 0.003532
 >> iter 39000, loss: 0.003562
 >> iter 40000, loss: 0.003408
   Number of active neurons: 10
 >> iter 41000, loss: 0.003251
 >> iter 42000, loss: 0.151449
 >> iter 43000, loss: 0.058516
 >> iter 44000, loss: 0.024057
 >> iter 45000, loss: 0.011090
 >> iter 46000, loss: 0.006190
 >> iter 47000, loss: 0.004264
 >> iter 48000, loss: 0.003517
 >> iter 49000, loss: 0.016583
 >> iter 50000, loss: 0.008057
   Number of active neurons: 10
 >> iter 51000, loss: 0.004919
 >> iter 52000, loss: 0.029524
 >> iter 53000, loss: 0.012935
 >> iter 54000, loss: 0.006570
 >> iter 55000, loss: 0.004199
 >> iter 56000, loss: 0.033336
 >> iter 57000, loss: 0.113143
 >> iter 58000, loss: 0.044797
 >> iter 59000, loss: 0.018584
 >> iter 60000, loss: 0.013597
   Number of active neurons: 10
 >> iter 61000, loss: 0.006981
 >> iter 62000, loss: 0.004206
 >> iter 63000, loss: 0.003305
 >> iter 64000, loss: 0.002945
 >> iter 65000, loss: 0.002576
 >> iter 66000, loss: 0.002401
 >> iter 67000, loss: 0.003925
 >> iter 68000, loss: 0.003553
 >> iter 69000, loss: 0.002665
 >> iter 70000, loss: 0.002292
   Number of active neurons: 10
 >> iter 71000, loss: 0.002106
 >> iter 72000, loss: 0.001955
 >> iter 73000, loss: 0.001827
 >> iter 74000, loss: 0.001742
 >> iter 75000, loss: 0.001792
 >> iter 76000, loss: 0.001667
 >> iter 77000, loss: 0.001609
 >> iter 78000, loss: 0.001977
 >> iter 79000, loss: 0.001757
 >> iter 80000, loss: 0.077201
   Number of active neurons: 10
 >> iter 81000, loss: 0.030027
 >> iter 82000, loss: 0.015798
 >> iter 83000, loss: 0.007301
 >> iter 84000, loss: 0.003929
 >> iter 85000, loss: 0.002614
 >> iter 86000, loss: 0.002042
 >> iter 87000, loss: 0.001764
 >> iter 88000, loss: 0.001653
 >> iter 89000, loss: 0.001506
 >> iter 90000, loss: 0.001451
   Number of active neurons: 10
 >> iter 91000, loss: 0.001450
 >> iter 92000, loss: 0.001359
 >> iter 93000, loss: 0.001362
 >> iter 94000, loss: 0.001299
 >> iter 95000, loss: 0.001360
 >> iter 96000, loss: 0.001289
 >> iter 97000, loss: 0.001270
 >> iter 98000, loss: 0.001223
 >> iter 99000, loss: 0.001491
 >> iter 100000, loss: 0.001313
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.703237
 >> iter 2000, loss: 10.600470
 >> iter 3000, loss: 8.702568
 >> iter 4000, loss: 7.980049
 >> iter 5000, loss: 7.718361
 >> iter 6000, loss: 7.614228
 >> iter 7000, loss: 7.583221
 >> iter 8000, loss: 7.525994
 >> iter 9000, loss: 7.050099
 >> iter 10000, loss: 6.522632
   Number of active neurons: 10
 >> iter 11000, loss: 5.928074
 >> iter 12000, loss: 4.933544
 >> iter 13000, loss: 1.951204
 >> iter 14000, loss: 0.786685
 >> iter 15000, loss: 0.415848
 >> iter 16000, loss: 0.227610
 >> iter 17000, loss: 0.098187
 >> iter 18000, loss: 0.048273
 >> iter 19000, loss: 0.028194
 >> iter 20000, loss: 0.018867
   Number of active neurons: 10
 >> iter 21000, loss: 0.014168
 >> iter 22000, loss: 0.011472
 >> iter 23000, loss: 0.010176
 >> iter 24000, loss: 0.008984
 >> iter 25000, loss: 0.017796
 >> iter 26000, loss: 0.011183
 >> iter 27000, loss: 0.016228
 >> iter 28000, loss: 0.010153
 >> iter 29000, loss: 0.007591
 >> iter 30000, loss: 0.038925
   Number of active neurons: 10
 >> iter 31000, loss: 0.018166
 >> iter 32000, loss: 0.009921
 >> iter 33000, loss: 0.007123
 >> iter 34000, loss: 0.006699
 >> iter 35000, loss: 0.043948
 >> iter 36000, loss: 0.020911
 >> iter 37000, loss: 0.010562
 >> iter 38000, loss: 0.006497
 >> iter 39000, loss: 0.005006
 >> iter 40000, loss: 0.057963
   Number of active neurons: 10
 >> iter 41000, loss: 0.025355
 >> iter 42000, loss: 0.012152
 >> iter 43000, loss: 0.006931
 >> iter 44000, loss: 0.004940
 >> iter 45000, loss: 0.004002
 >> iter 46000, loss: 0.003501
 >> iter 47000, loss: 0.003256
 >> iter 48000, loss: 0.003311
 >> iter 49000, loss: 0.003098
 >> iter 50000, loss: 0.002867
   Number of active neurons: 10
 >> iter 51000, loss: 0.002858
 >> iter 52000, loss: 0.002750
 >> iter 53000, loss: 0.002562
 >> iter 54000, loss: 0.002438
 >> iter 55000, loss: 0.002449
 >> iter 56000, loss: 0.002304
 >> iter 57000, loss: 0.002290
 >> iter 58000, loss: 0.002171
 >> iter 59000, loss: 0.002125
 >> iter 60000, loss: 0.002205
   Number of active neurons: 10
 >> iter 61000, loss: 0.002278
 >> iter 62000, loss: 0.002074
 >> iter 63000, loss: 0.001977
 >> iter 64000, loss: 0.001893
 >> iter 65000, loss: 0.002071
 >> iter 66000, loss: 0.002026
 >> iter 67000, loss: 0.001880
 >> iter 68000, loss: 0.001793
 >> iter 69000, loss: 0.001839
 >> iter 70000, loss: 0.001741
   Number of active neurons: 10
 >> iter 71000, loss: 0.001744
 >> iter 72000, loss: 0.001658
 >> iter 73000, loss: 0.001580
 >> iter 74000, loss: 0.001602
 >> iter 75000, loss: 0.001645
 >> iter 76000, loss: 0.001554
 >> iter 77000, loss: 0.001475
 >> iter 78000, loss: 0.001476
 >> iter 79000, loss: 0.001417
 >> iter 80000, loss: 0.001415
   Number of active neurons: 10
 >> iter 81000, loss: 0.001390
 >> iter 82000, loss: 0.001377
 >> iter 83000, loss: 0.001324
 >> iter 84000, loss: 0.001287
 >> iter 85000, loss: 0.001273
 >> iter 86000, loss: 0.001254
 >> iter 87000, loss: 0.001510
 >> iter 88000, loss: 0.001307
 >> iter 89000, loss: 0.001250
 >> iter 90000, loss: 0.001201
   Number of active neurons: 10
 >> iter 91000, loss: 0.001200
 >> iter 92000, loss: 0.001146
 >> iter 93000, loss: 0.001125
 >> iter 94000, loss: 0.001122
 >> iter 95000, loss: 0.001087
 >> iter 96000, loss: 0.001098
 >> iter 97000, loss: 0.003040
 >> iter 98000, loss: 0.002239
 >> iter 99000, loss: 0.001652
 >> iter 100000, loss: 0.001380
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.759608
 >> iter 2000, loss: 10.632420
 >> iter 3000, loss: 8.739044
 >> iter 4000, loss: 8.046981
 >> iter 5000, loss: 7.773549
 >> iter 6000, loss: 7.657993
 >> iter 7000, loss: 7.619087
 >> iter 8000, loss: 7.600440
 >> iter 9000, loss: 7.600768
 >> iter 10000, loss: 7.592167
   Number of active neurons: 9
 >> iter 11000, loss: 7.659803
 >> iter 12000, loss: 7.338829
 >> iter 13000, loss: 6.863432
 >> iter 14000, loss: 6.295747
 >> iter 15000, loss: 5.315349
 >> iter 16000, loss: 2.173491
 >> iter 17000, loss: 0.995667
 >> iter 18000, loss: 0.484377
 >> iter 19000, loss: 0.257797
 >> iter 20000, loss: 0.111716
   Number of active neurons: 10
 >> iter 21000, loss: 0.066889
 >> iter 22000, loss: 0.034947
 >> iter 23000, loss: 0.021191
 >> iter 24000, loss: 0.042759
 >> iter 25000, loss: 0.045128
 >> iter 26000, loss: 0.044132
 >> iter 27000, loss: 0.030395
 >> iter 28000, loss: 0.016731
 >> iter 29000, loss: 0.011211
 >> iter 30000, loss: 0.008776
   Number of active neurons: 10
 >> iter 31000, loss: 0.007396
 >> iter 32000, loss: 0.006297
 >> iter 33000, loss: 0.085988
 >> iter 34000, loss: 0.117128
 >> iter 35000, loss: 0.047082
 >> iter 36000, loss: 0.020758
 >> iter 37000, loss: 0.010938
 >> iter 38000, loss: 0.006923
 >> iter 39000, loss: 0.007833
 >> iter 40000, loss: 0.005513
   Number of active neurons: 10
 >> iter 41000, loss: 0.004567
 >> iter 42000, loss: 0.016071
 >> iter 43000, loss: 0.008212
 >> iter 44000, loss: 0.005221
 >> iter 45000, loss: 0.004168
 >> iter 46000, loss: 0.003555
 >> iter 47000, loss: 0.003604
 >> iter 48000, loss: 0.003310
 >> iter 49000, loss: 0.003053
 >> iter 50000, loss: 0.002925
   Number of active neurons: 10
 >> iter 51000, loss: 0.002884
 >> iter 52000, loss: 0.002855
 >> iter 53000, loss: 0.002631
 >> iter 54000, loss: 0.002489
 >> iter 55000, loss: 0.002430
 >> iter 56000, loss: 0.002369
 >> iter 57000, loss: 0.002374
 >> iter 58000, loss: 0.002182
 >> iter 59000, loss: 0.022292
 >> iter 60000, loss: 0.009653
   Number of active neurons: 10
 >> iter 61000, loss: 0.005209
 >> iter 62000, loss: 0.004239
 >> iter 63000, loss: 0.004610
 >> iter 64000, loss: 0.002899
 >> iter 65000, loss: 0.002276
 >> iter 66000, loss: 0.046132
 >> iter 67000, loss: 0.018488
 >> iter 68000, loss: 0.008231
 >> iter 69000, loss: 0.004467
 >> iter 70000, loss: 0.002895
   Number of active neurons: 10
 >> iter 71000, loss: 0.002296
 >> iter 72000, loss: 0.002024
 >> iter 73000, loss: 0.001895
 >> iter 74000, loss: 0.002717
 >> iter 75000, loss: 0.019826
 >> iter 76000, loss: 0.008574
 >> iter 77000, loss: 0.004309
 >> iter 78000, loss: 0.002691
 >> iter 79000, loss: 0.002281
 >> iter 80000, loss: 0.001865
   Number of active neurons: 10
 >> iter 81000, loss: 0.210424
 >> iter 82000, loss: 0.079617
 >> iter 83000, loss: 0.030969
 >> iter 84000, loss: 0.012999
 >> iter 85000, loss: 0.006294
 >> iter 86000, loss: 0.003798
 >> iter 87000, loss: 0.002717
 >> iter 88000, loss: 0.002315
 >> iter 89000, loss: 0.002076
 >> iter 90000, loss: 0.001941
   Number of active neurons: 10
 >> iter 91000, loss: 0.001940
 >> iter 92000, loss: 0.001921
 >> iter 93000, loss: 0.001828
 >> iter 94000, loss: 0.001751
 >> iter 95000, loss: 0.001700
 >> iter 96000, loss: 0.001630
 >> iter 97000, loss: 0.001625
 >> iter 98000, loss: 0.001585
 >> iter 99000, loss: 0.001532
 >> iter 100000, loss: 0.001451
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 15.923326
 >> iter 2000, loss: 10.720239
 >> iter 3000, loss: 8.785329
 >> iter 4000, loss: 8.040567
 >> iter 5000, loss: 7.762948
 >> iter 6000, loss: 7.532015
 >> iter 7000, loss: 7.190636
 >> iter 8000, loss: 6.859303
 >> iter 9000, loss: 6.585033
 >> iter 10000, loss: 5.437258
   Number of active neurons: 10
 >> iter 11000, loss: 2.593756
 >> iter 12000, loss: 1.102608
 >> iter 13000, loss: 0.547438
 >> iter 14000, loss: 0.339953
 >> iter 15000, loss: 0.472266
 >> iter 16000, loss: 0.269691
 >> iter 17000, loss: 0.120316
 >> iter 18000, loss: 0.102672
 >> iter 19000, loss: 0.077225
 >> iter 20000, loss: 0.072446
   Number of active neurons: 10
 >> iter 21000, loss: 0.038039
 >> iter 22000, loss: 0.093982
 >> iter 23000, loss: 0.105204
 >> iter 24000, loss: 0.134226
 >> iter 25000, loss: 0.059877
 >> iter 26000, loss: 0.030770
 >> iter 27000, loss: 0.018695
 >> iter 28000, loss: 0.013795
 >> iter 29000, loss: 0.011286
 >> iter 30000, loss: 0.009906
   Number of active neurons: 10
 >> iter 31000, loss: 0.008884
 >> iter 32000, loss: 0.008335
 >> iter 33000, loss: 0.007873
 >> iter 34000, loss: 0.007534
 >> iter 35000, loss: 0.048705
 >> iter 36000, loss: 0.063649
 >> iter 37000, loss: 0.201496
 >> iter 38000, loss: 0.080239
 >> iter 39000, loss: 0.034485
 >> iter 40000, loss: 0.017276
   Number of active neurons: 10
 >> iter 41000, loss: 0.010515
 >> iter 42000, loss: 0.008086
 >> iter 43000, loss: 0.009230
 >> iter 44000, loss: 0.007453
 >> iter 45000, loss: 0.006109
 >> iter 46000, loss: 0.006341
 >> iter 47000, loss: 0.005516
 >> iter 48000, loss: 0.005008
 >> iter 49000, loss: 0.004617
 >> iter 50000, loss: 0.004480
   Number of active neurons: 10
 >> iter 51000, loss: 0.004249
 >> iter 52000, loss: 0.004185
 >> iter 53000, loss: 0.003919
 >> iter 54000, loss: 0.003853
 >> iter 55000, loss: 0.003838
 >> iter 56000, loss: 0.029027
 >> iter 57000, loss: 0.105545
 >> iter 58000, loss: 0.041966
 >> iter 59000, loss: 0.023722
 >> iter 60000, loss: 0.011395
   Number of active neurons: 10
 >> iter 61000, loss: 0.006657
 >> iter 62000, loss: 0.004974
 >> iter 63000, loss: 0.004236
 >> iter 64000, loss: 0.004828
 >> iter 65000, loss: 0.042904
 >> iter 66000, loss: 0.018429
 >> iter 67000, loss: 0.023709
 >> iter 68000, loss: 0.013895
 >> iter 69000, loss: 0.007522
 >> iter 70000, loss: 0.004969
   Number of active neurons: 10
 >> iter 71000, loss: 0.003818
 >> iter 72000, loss: 0.003327
 >> iter 73000, loss: 0.003051
 >> iter 74000, loss: 0.002955
 >> iter 75000, loss: 0.002802
 >> iter 76000, loss: 0.002736
 >> iter 77000, loss: 0.002653
 >> iter 78000, loss: 0.002597
 >> iter 79000, loss: 0.002609
 >> iter 80000, loss: 0.042074
   Number of active neurons: 10
 >> iter 81000, loss: 0.017556
 >> iter 82000, loss: 0.008565
 >> iter 83000, loss: 0.004770
 >> iter 84000, loss: 0.003444
 >> iter 85000, loss: 0.002808
 >> iter 86000, loss: 0.013633
 >> iter 87000, loss: 0.006551
 >> iter 88000, loss: 0.004025
 >> iter 89000, loss: 0.003025
 >> iter 90000, loss: 0.003331
   Number of active neurons: 10
 >> iter 91000, loss: 0.002722
 >> iter 92000, loss: 0.002643
 >> iter 93000, loss: 0.002322
 >> iter 94000, loss: 0.002268
 >> iter 95000, loss: 0.002123
 >> iter 96000, loss: 0.002097
 >> iter 97000, loss: 0.001969
 >> iter 98000, loss: 0.001930
 >> iter 99000, loss: 0.001931
 >> iter 100000, loss: 0.001866
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.706899
 >> iter 2000, loss: 10.594386
 >> iter 3000, loss: 8.699679
 >> iter 4000, loss: 7.981785
 >> iter 5000, loss: 7.723517
 >> iter 6000, loss: 7.601651
 >> iter 7000, loss: 7.561808
 >> iter 8000, loss: 7.551413
 >> iter 9000, loss: 7.548454
 >> iter 10000, loss: 7.529148
   Number of active neurons: 7
 >> iter 11000, loss: 7.471129
 >> iter 12000, loss: 7.168205
 >> iter 13000, loss: 6.851117
 >> iter 14000, loss: 6.425562
 >> iter 15000, loss: 5.906353
 >> iter 16000, loss: 5.625232
 >> iter 17000, loss: 4.543541
 >> iter 18000, loss: 2.176902
 >> iter 19000, loss: 0.970493
 >> iter 20000, loss: 0.439423
   Number of active neurons: 10
 >> iter 21000, loss: 0.273247
 >> iter 22000, loss: 0.202541
 >> iter 23000, loss: 0.166932
 >> iter 24000, loss: 0.204211
 >> iter 25000, loss: 0.090220
 >> iter 26000, loss: 0.048368
 >> iter 27000, loss: 0.027635
 >> iter 28000, loss: 0.244424
 >> iter 29000, loss: 0.153609
 >> iter 30000, loss: 0.130879
   Number of active neurons: 10
 >> iter 31000, loss: 0.107662
 >> iter 32000, loss: 0.047870
 >> iter 33000, loss: 0.024883
 >> iter 34000, loss: 0.015052
 >> iter 35000, loss: 0.011650
 >> iter 36000, loss: 0.062872
 >> iter 37000, loss: 0.239947
 >> iter 38000, loss: 0.096002
 >> iter 39000, loss: 0.040825
 >> iter 40000, loss: 0.021626
   Number of active neurons: 10
 >> iter 41000, loss: 0.012765
 >> iter 42000, loss: 0.008930
 >> iter 43000, loss: 0.007212
 >> iter 44000, loss: 0.006195
 >> iter 45000, loss: 0.005765
 >> iter 46000, loss: 0.005229
 >> iter 47000, loss: 0.004877
 >> iter 48000, loss: 0.004613
 >> iter 49000, loss: 0.005700
 >> iter 50000, loss: 0.024502
   Number of active neurons: 10
 >> iter 51000, loss: 0.011550
 >> iter 52000, loss: 0.006765
 >> iter 53000, loss: 0.004833
 >> iter 54000, loss: 0.004265
 >> iter 55000, loss: 0.003822
 >> iter 56000, loss: 0.003634
 >> iter 57000, loss: 0.003253
 >> iter 58000, loss: 0.003294
 >> iter 59000, loss: 0.003068
 >> iter 60000, loss: 0.002895
   Number of active neurons: 10
 >> iter 61000, loss: 0.003296
 >> iter 62000, loss: 0.002931
 >> iter 63000, loss: 0.002782
 >> iter 64000, loss: 0.003673
 >> iter 65000, loss: 0.003164
 >> iter 66000, loss: 0.002902
 >> iter 67000, loss: 0.002514
 >> iter 68000, loss: 0.002421
 >> iter 69000, loss: 0.002337
 >> iter 70000, loss: 0.002341
   Number of active neurons: 10
 >> iter 71000, loss: 0.002206
 >> iter 72000, loss: 0.002136
 >> iter 73000, loss: 0.010109
 >> iter 74000, loss: 0.005137
 >> iter 75000, loss: 0.003359
 >> iter 76000, loss: 0.002908
 >> iter 77000, loss: 0.002270
 >> iter 78000, loss: 0.040573
 >> iter 79000, loss: 0.016489
 >> iter 80000, loss: 0.007547
   Number of active neurons: 10
 >> iter 81000, loss: 0.004025
 >> iter 82000, loss: 0.002718
 >> iter 83000, loss: 0.022392
 >> iter 84000, loss: 0.009565
 >> iter 85000, loss: 0.004743
 >> iter 86000, loss: 0.003016
 >> iter 87000, loss: 0.002418
 >> iter 88000, loss: 0.002034
 >> iter 89000, loss: 0.051415
 >> iter 90000, loss: 0.020468
   Number of active neurons: 10
 >> iter 91000, loss: 0.008762
 >> iter 92000, loss: 0.004468
 >> iter 93000, loss: 0.002728
 >> iter 94000, loss: 0.002138
 >> iter 95000, loss: 0.001884
 >> iter 96000, loss: 0.001744
 >> iter 97000, loss: 0.001728
 >> iter 98000, loss: 0.001637
 >> iter 99000, loss: 0.001602
 >> iter 100000, loss: 0.002220
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.767470
 >> iter 2000, loss: 10.641458
 >> iter 3000, loss: 8.741127
 >> iter 4000, loss: 8.029848
 >> iter 5000, loss: 7.767307
 >> iter 6000, loss: 7.658436
 >> iter 7000, loss: 7.687986
 >> iter 8000, loss: 7.620704
 >> iter 9000, loss: 7.596683
 >> iter 10000, loss: 7.575697
   Number of active neurons: 10
 >> iter 11000, loss: 7.579833
 >> iter 12000, loss: 7.554857
 >> iter 13000, loss: 7.346036
 >> iter 14000, loss: 6.995283
 >> iter 15000, loss: 6.769710
 >> iter 16000, loss: 6.536715
 >> iter 17000, loss: 6.386876
 >> iter 18000, loss: 6.032583
 >> iter 19000, loss: 5.722152
 >> iter 20000, loss: 5.530645
   Number of active neurons: 10
 >> iter 21000, loss: 5.443392
 >> iter 22000, loss: 5.405319
 >> iter 23000, loss: 5.312941
 >> iter 24000, loss: 5.136470
 >> iter 25000, loss: 5.025547
 >> iter 26000, loss: 4.924757
 >> iter 27000, loss: 3.321601
 >> iter 28000, loss: 2.478823
 >> iter 29000, loss: 1.127184
 >> iter 30000, loss: 0.586758
   Number of active neurons: 10
 >> iter 31000, loss: 0.397689
 >> iter 32000, loss: 0.408386
 >> iter 33000, loss: 0.213015
 >> iter 34000, loss: 0.124424
 >> iter 35000, loss: 0.166605
 >> iter 36000, loss: 0.086282
 >> iter 37000, loss: 0.085104
 >> iter 38000, loss: 0.081636
 >> iter 39000, loss: 0.054953
 >> iter 40000, loss: 0.137239
   Number of active neurons: 10
 >> iter 41000, loss: 0.075035
 >> iter 42000, loss: 0.121056
 >> iter 43000, loss: 0.056986
 >> iter 44000, loss: 0.100507
 >> iter 45000, loss: 0.238074
 >> iter 46000, loss: 0.109415
 >> iter 47000, loss: 0.118178
 >> iter 48000, loss: 0.112963
 >> iter 49000, loss: 0.080062
 >> iter 50000, loss: 0.040517
   Number of active neurons: 10
 >> iter 51000, loss: 0.058887
 >> iter 52000, loss: 0.029438
 >> iter 53000, loss: 0.022421
 >> iter 54000, loss: 0.015166
 >> iter 55000, loss: 0.013224
 >> iter 56000, loss: 0.010729
 >> iter 57000, loss: 0.017002
 >> iter 58000, loss: 0.012084
 >> iter 59000, loss: 0.010217
 >> iter 60000, loss: 0.097448
   Number of active neurons: 10
 >> iter 61000, loss: 0.062191
 >> iter 62000, loss: 0.027557
 >> iter 63000, loss: 0.014580
 >> iter 64000, loss: 0.009582
 >> iter 65000, loss: 0.073055
 >> iter 66000, loss: 0.032407
 >> iter 67000, loss: 0.016520
 >> iter 68000, loss: 0.040541
 >> iter 69000, loss: 0.060966
 >> iter 70000, loss: 0.110997
   Number of active neurons: 10
 >> iter 71000, loss: 0.045367
 >> iter 72000, loss: 0.070321
 >> iter 73000, loss: 0.031432
 >> iter 74000, loss: 0.015833
 >> iter 75000, loss: 0.009943
 >> iter 76000, loss: 0.055439
 >> iter 77000, loss: 0.024102
 >> iter 78000, loss: 0.012473
 >> iter 79000, loss: 0.008105
 >> iter 80000, loss: 0.006040
   Number of active neurons: 10
 >> iter 81000, loss: 0.005155
 >> iter 82000, loss: 0.023393
 >> iter 83000, loss: 0.039346
 >> iter 84000, loss: 0.017663
 >> iter 85000, loss: 0.009578
 >> iter 86000, loss: 0.006325
 >> iter 87000, loss: 0.004990
 >> iter 88000, loss: 0.004469
 >> iter 89000, loss: 0.014596
 >> iter 90000, loss: 0.086789
   Number of active neurons: 10
 >> iter 91000, loss: 0.035040
 >> iter 92000, loss: 0.059947
 >> iter 93000, loss: 0.026083
 >> iter 94000, loss: 0.012375
 >> iter 95000, loss: 0.007300
 >> iter 96000, loss: 0.006056
 >> iter 97000, loss: 0.005381
 >> iter 98000, loss: 0.004401
 >> iter 99000, loss: 0.003896
 >> iter 100000, loss: 0.003567
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

