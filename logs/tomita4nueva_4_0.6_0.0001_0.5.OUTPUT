 > Problema: tomita4nueva
 > Args:
   - Hidden size: 4
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 20.524757
 >> iter 2000, loss: 18.054275
 >> iter 3000, loss: 17.068459
 >> iter 4000, loss: 16.779355
 >> iter 5000, loss: 16.602165
 >> iter 6000, loss: 16.598199
 >> iter 7000, loss: 16.539950
 >> iter 8000, loss: 15.284178
 >> iter 9000, loss: 9.787398
 >> iter 10000, loss: 5.049573
   Number of active neurons: 3
 >> iter 11000, loss: 2.280541
 >> iter 12000, loss: 1.267564
 >> iter 13000, loss: 0.786290
 >> iter 14000, loss: 0.507652
 >> iter 15000, loss: 0.341117
 >> iter 16000, loss: 0.464672
 >> iter 17000, loss: 0.313220
 >> iter 18000, loss: 0.276609
 >> iter 19000, loss: 0.359884
 >> iter 20000, loss: 0.235527
   Number of active neurons: 3
 >> iter 21000, loss: 0.355350
 >> iter 22000, loss: 0.374977
 >> iter 23000, loss: 0.207216
 >> iter 24000, loss: 0.170753
 >> iter 25000, loss: 0.192848
 >> iter 26000, loss: 0.298888
 >> iter 27000, loss: 0.227231
 >> iter 28000, loss: 0.398978
 >> iter 29000, loss: 0.319381
 >> iter 30000, loss: 0.336838
   Number of active neurons: 3
 >> iter 31000, loss: 0.329320
 >> iter 32000, loss: 0.365100
 >> iter 33000, loss: 0.346072
 >> iter 34000, loss: 0.157742
 >> iter 35000, loss: 0.187944
 >> iter 36000, loss: 0.229882
 >> iter 37000, loss: 0.251485
 >> iter 38000, loss: 0.324925
 >> iter 39000, loss: 0.231723
 >> iter 40000, loss: 0.153536
   Number of active neurons: 3
 >> iter 41000, loss: 0.270231
 >> iter 42000, loss: 0.262922
 >> iter 43000, loss: 0.307903
 >> iter 44000, loss: 0.209275
 >> iter 45000, loss: 0.329905
 >> iter 46000, loss: 0.275982
 >> iter 47000, loss: 0.157877
 >> iter 48000, loss: 0.088212
 >> iter 49000, loss: 0.201944
 >> iter 50000, loss: 0.333579
   Number of active neurons: 3
 >> iter 51000, loss: 0.304545
 >> iter 52000, loss: 0.300786
 >> iter 53000, loss: 0.311709
 >> iter 54000, loss: 0.352932
 >> iter 55000, loss: 0.268633
 >> iter 56000, loss: 0.260485
 >> iter 57000, loss: 0.211059
 >> iter 58000, loss: 0.206658
 >> iter 59000, loss: 0.130605
 >> iter 60000, loss: 0.173421
   Number of active neurons: 3
 >> iter 61000, loss: 0.389589
 >> iter 62000, loss: 0.212709
 >> iter 63000, loss: 0.223231
 >> iter 64000, loss: 0.344891
 >> iter 65000, loss: 0.228356
 >> iter 66000, loss: 0.226469
 >> iter 67000, loss: 0.184193
 >> iter 68000, loss: 0.352376
 >> iter 69000, loss: 0.180122
 >> iter 70000, loss: 0.287802
   Number of active neurons: 3
 >> iter 71000, loss: 0.349683
 >> iter 72000, loss: 0.372705
 >> iter 73000, loss: 0.209220
 >> iter 74000, loss: 0.145303
 >> iter 75000, loss: 0.322997
 >> iter 76000, loss: 0.297907
 >> iter 77000, loss: 0.222274
 >> iter 78000, loss: 0.315172
 >> iter 79000, loss: 0.213539
 >> iter 80000, loss: 0.160129
   Number of active neurons: 3
 >> iter 81000, loss: 0.318944
 >> iter 82000, loss: 0.239542
 >> iter 83000, loss: 0.260823
 >> iter 84000, loss: 0.186827
 >> iter 85000, loss: 0.198185
 >> iter 86000, loss: 0.189052
 >> iter 87000, loss: 0.249155
 >> iter 88000, loss: 0.342109
 >> iter 89000, loss: 0.297507
 >> iter 90000, loss: 0.151436
   Number of active neurons: 3
 >> iter 91000, loss: 0.200333
 >> iter 92000, loss: 0.273311
 >> iter 93000, loss: 0.275416
 >> iter 94000, loss: 0.211407
 >> iter 95000, loss: 0.371607
 >> iter 96000, loss: 0.215803
 >> iter 97000, loss: 0.288325
 >> iter 98000, loss: 0.288232
 >> iter 99000, loss: 0.270555
 >> iter 100000, loss: 0.371200
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.761961
 >> iter 2000, loss: 8.439134
 >> iter 3000, loss: 3.803074
 >> iter 4000, loss: 1.803326
 >> iter 5000, loss: 0.776854
 >> iter 6000, loss: 0.451992
 >> iter 7000, loss: 0.513959
 >> iter 8000, loss: 0.629319
 >> iter 9000, loss: 0.436095
 >> iter 10000, loss: 0.316528
   Number of active neurons: 4
 >> iter 11000, loss: 0.530868
 >> iter 12000, loss: 0.314701
 >> iter 13000, loss: 0.278456
 >> iter 14000, loss: 0.403930
 >> iter 15000, loss: 0.352267
 >> iter 16000, loss: 0.288630
 >> iter 17000, loss: 0.285796
 >> iter 18000, loss: 0.472047
 >> iter 19000, loss: 0.402682
 >> iter 20000, loss: 0.402039
   Number of active neurons: 4
 >> iter 21000, loss: 0.224411
 >> iter 22000, loss: 0.175445
 >> iter 23000, loss: 0.424570
 >> iter 24000, loss: 0.364584
 >> iter 25000, loss: 0.634576
 >> iter 26000, loss: 0.365872
 >> iter 27000, loss: 0.401055
 >> iter 28000, loss: 0.367471
 >> iter 29000, loss: 0.395301
 >> iter 30000, loss: 0.390794
   Number of active neurons: 4
 >> iter 31000, loss: 0.332418
 >> iter 32000, loss: 0.313154
 >> iter 33000, loss: 0.236918
 >> iter 34000, loss: 0.261836
 >> iter 35000, loss: 0.195750
 >> iter 36000, loss: 0.279432
 >> iter 37000, loss: 0.247483
 >> iter 38000, loss: 0.272033
 >> iter 39000, loss: 0.413842
 >> iter 40000, loss: 0.417341
   Number of active neurons: 3
 >> iter 41000, loss: 0.218640
 >> iter 42000, loss: 0.413643
 >> iter 43000, loss: 0.283067
 >> iter 44000, loss: 0.155507
 >> iter 45000, loss: 0.147549
 >> iter 46000, loss: 0.312856
 >> iter 47000, loss: 0.179051
 >> iter 48000, loss: 0.205259
 >> iter 49000, loss: 0.365456
 >> iter 50000, loss: 0.197023
   Number of active neurons: 3
 >> iter 51000, loss: 0.296011
 >> iter 52000, loss: 0.146403
 >> iter 53000, loss: 0.245668
 >> iter 54000, loss: 0.251847
 >> iter 55000, loss: 0.202274
 >> iter 56000, loss: 0.200941
 >> iter 57000, loss: 0.155050
 >> iter 58000, loss: 0.175506
 >> iter 59000, loss: 0.404242
 >> iter 60000, loss: 0.293011
   Number of active neurons: 3
 >> iter 61000, loss: 0.318691
 >> iter 62000, loss: 0.193664
 >> iter 63000, loss: 0.230016
 >> iter 64000, loss: 0.290547
 >> iter 65000, loss: 0.387116
 >> iter 66000, loss: 0.318985
 >> iter 67000, loss: 0.256871
 >> iter 68000, loss: 0.167628
 >> iter 69000, loss: 0.224595
 >> iter 70000, loss: 0.130580
   Number of active neurons: 3
 >> iter 71000, loss: 0.135758
 >> iter 72000, loss: 0.219643
 >> iter 73000, loss: 0.174271
 >> iter 74000, loss: 0.115804
 >> iter 75000, loss: 0.286949
 >> iter 76000, loss: 0.405110
 >> iter 77000, loss: 0.416895
 >> iter 78000, loss: 0.367911
 >> iter 79000, loss: 0.486725
 >> iter 80000, loss: 0.379938
   Number of active neurons: 3
 >> iter 81000, loss: 0.206328
 >> iter 82000, loss: 0.163488
 >> iter 83000, loss: 0.238949
 >> iter 84000, loss: 0.207132
 >> iter 85000, loss: 0.333040
 >> iter 86000, loss: 0.524411
 >> iter 87000, loss: 0.351576
 >> iter 88000, loss: 0.246801
 >> iter 89000, loss: 0.259807
 >> iter 90000, loss: 0.165260
   Number of active neurons: 3
 >> iter 91000, loss: 0.206111
 >> iter 92000, loss: 0.269423
 >> iter 93000, loss: 0.209708
 >> iter 94000, loss: 0.219372
 >> iter 95000, loss: 0.214014
 >> iter 96000, loss: 0.313715
 >> iter 97000, loss: 0.443430
 >> iter 98000, loss: 0.225280
 >> iter 99000, loss: 0.307957
 >> iter 100000, loss: 0.312567
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.935615
 >> iter 2000, loss: 13.909362
 >> iter 3000, loss: 8.780873
 >> iter 4000, loss: 4.478574
 >> iter 5000, loss: 2.423911
 >> iter 6000, loss: 1.692213
 >> iter 7000, loss: 1.048640
 >> iter 8000, loss: 0.932164
 >> iter 9000, loss: 0.739858
 >> iter 10000, loss: 0.758933
   Number of active neurons: 4
 >> iter 11000, loss: 0.668799
 >> iter 12000, loss: 0.411135
 >> iter 13000, loss: 0.458358
 >> iter 14000, loss: 0.447116
 >> iter 15000, loss: 0.442149
 >> iter 16000, loss: 0.452408
 >> iter 17000, loss: 0.552488
 >> iter 18000, loss: 0.437686
 >> iter 19000, loss: 0.417906
 >> iter 20000, loss: 0.417691
   Number of active neurons: 4
 >> iter 21000, loss: 0.394301
 >> iter 22000, loss: 0.472716
 >> iter 23000, loss: 0.389302
 >> iter 24000, loss: 0.433879
 >> iter 25000, loss: 0.459780
 >> iter 26000, loss: 0.499090
 >> iter 27000, loss: 0.476153
 >> iter 28000, loss: 0.361892
 >> iter 29000, loss: 0.485323
 >> iter 30000, loss: 0.608839
   Number of active neurons: 4
 >> iter 31000, loss: 0.441178
 >> iter 32000, loss: 0.302116
 >> iter 33000, loss: 0.304134
 >> iter 34000, loss: 0.607528
 >> iter 35000, loss: 0.730622
 >> iter 36000, loss: 0.452085
 >> iter 37000, loss: 0.497184
 >> iter 38000, loss: 0.413375
 >> iter 39000, loss: 0.423911
 >> iter 40000, loss: 0.574742
   Number of active neurons: 4
 >> iter 41000, loss: 0.459603
 >> iter 42000, loss: 0.476395
 >> iter 43000, loss: 0.448013
 >> iter 44000, loss: 0.413901
 >> iter 45000, loss: 0.350465
 >> iter 46000, loss: 0.498423
 >> iter 47000, loss: 0.462113
 >> iter 48000, loss: 0.337734
 >> iter 49000, loss: 0.488509
 >> iter 50000, loss: 0.493845
   Number of active neurons: 4
 >> iter 51000, loss: 0.597076
 >> iter 52000, loss: 0.544641
 >> iter 53000, loss: 0.595166
 >> iter 54000, loss: 0.558738
 >> iter 55000, loss: 0.410789
 >> iter 56000, loss: 0.443223
 >> iter 57000, loss: 0.591994
 >> iter 58000, loss: 0.480395
 >> iter 59000, loss: 0.602578
 >> iter 60000, loss: 0.315867
   Number of active neurons: 4
 >> iter 61000, loss: 0.328173
 >> iter 62000, loss: 0.282293
 >> iter 63000, loss: 0.503826
 >> iter 64000, loss: 0.508750
 >> iter 65000, loss: 0.374422
 >> iter 66000, loss: 0.385382
 >> iter 67000, loss: 0.293292
 >> iter 68000, loss: 0.283100
 >> iter 69000, loss: 0.486579
 >> iter 70000, loss: 0.576489
   Number of active neurons: 4
 >> iter 71000, loss: 0.596731
 >> iter 72000, loss: 0.590818
 >> iter 73000, loss: 0.362224
 >> iter 74000, loss: 0.502364
 >> iter 75000, loss: 0.495349
 >> iter 76000, loss: 0.376286
 >> iter 77000, loss: 0.356486
 >> iter 78000, loss: 0.338306
 >> iter 79000, loss: 0.410775
 >> iter 80000, loss: 0.332518
   Number of active neurons: 4
 >> iter 81000, loss: 0.431699
 >> iter 82000, loss: 0.417589
 >> iter 83000, loss: 0.342353
 >> iter 84000, loss: 0.479035
 >> iter 85000, loss: 0.395889
 >> iter 86000, loss: 0.309243
 >> iter 87000, loss: 0.547945
 >> iter 88000, loss: 0.571329
 >> iter 89000, loss: 0.393877
 >> iter 90000, loss: 0.407733
   Number of active neurons: 4
 >> iter 91000, loss: 0.372986
 >> iter 92000, loss: 0.316784
 >> iter 93000, loss: 0.318899
 >> iter 94000, loss: 0.426829
 >> iter 95000, loss: 0.307731
 >> iter 96000, loss: 0.449544
 >> iter 97000, loss: 0.354343
 >> iter 98000, loss: 0.392846
 >> iter 99000, loss: 0.307176
 >> iter 100000, loss: 0.283683
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.753536
 >> iter 2000, loss: 11.101063
 >> iter 3000, loss: 5.892765
 >> iter 4000, loss: 3.367925
 >> iter 5000, loss: 1.962187
 >> iter 6000, loss: 1.587769
 >> iter 7000, loss: 1.023180
 >> iter 8000, loss: 0.985823
 >> iter 9000, loss: 0.775528
 >> iter 10000, loss: 0.914518
   Number of active neurons: 4
 >> iter 11000, loss: 0.714449
 >> iter 12000, loss: 0.741621
 >> iter 13000, loss: 0.547439
 >> iter 14000, loss: 0.544415
 >> iter 15000, loss: 0.726920
 >> iter 16000, loss: 0.572759
 >> iter 17000, loss: 0.594643
 >> iter 18000, loss: 0.673972
 >> iter 19000, loss: 0.546754
 >> iter 20000, loss: 0.528502
   Number of active neurons: 4
 >> iter 21000, loss: 0.426985
 >> iter 22000, loss: 0.466327
 >> iter 23000, loss: 0.555864
 >> iter 24000, loss: 0.481901
 >> iter 25000, loss: 0.544369
 >> iter 26000, loss: 0.524707
 >> iter 27000, loss: 0.612790
 >> iter 28000, loss: 0.413377
 >> iter 29000, loss: 0.552113
 >> iter 30000, loss: 0.482721
   Number of active neurons: 4
 >> iter 31000, loss: 0.577685
 >> iter 32000, loss: 0.607061
 >> iter 33000, loss: 0.411418
 >> iter 34000, loss: 0.433343
 >> iter 35000, loss: 0.529201
 >> iter 36000, loss: 0.450980
 >> iter 37000, loss: 0.804476
 >> iter 38000, loss: 0.516159
 >> iter 39000, loss: 0.581649
 >> iter 40000, loss: 0.481803
   Number of active neurons: 4
 >> iter 41000, loss: 0.480204
 >> iter 42000, loss: 0.484314
 >> iter 43000, loss: 0.568436
 >> iter 44000, loss: 0.419761
 >> iter 45000, loss: 0.431486
 >> iter 46000, loss: 0.509709
 >> iter 47000, loss: 0.466255
 >> iter 48000, loss: 0.320917
 >> iter 49000, loss: 0.432301
 >> iter 50000, loss: 0.405247
   Number of active neurons: 4
 >> iter 51000, loss: 0.348792
 >> iter 52000, loss: 0.388223
 >> iter 53000, loss: 0.490713
 >> iter 54000, loss: 0.403514
 >> iter 55000, loss: 0.551276
 >> iter 56000, loss: 0.506874
 >> iter 57000, loss: 0.504943
 >> iter 58000, loss: 0.746838
 >> iter 59000, loss: 0.517774
 >> iter 60000, loss: 0.435029
   Number of active neurons: 4
 >> iter 61000, loss: 0.607574
 >> iter 62000, loss: 0.406274
 >> iter 63000, loss: 0.228005
 >> iter 64000, loss: 0.526471
 >> iter 65000, loss: 0.646146
 >> iter 66000, loss: 0.615629
 >> iter 67000, loss: 0.579889
 >> iter 68000, loss: 0.388576
 >> iter 69000, loss: 0.387481
 >> iter 70000, loss: 0.437972
   Number of active neurons: 4
 >> iter 71000, loss: 0.703534
 >> iter 72000, loss: 0.440801
 >> iter 73000, loss: 0.403786
 >> iter 74000, loss: 0.459516
 >> iter 75000, loss: 0.377226
 >> iter 76000, loss: 0.360274
 >> iter 77000, loss: 0.406396
 >> iter 78000, loss: 0.327325
 >> iter 79000, loss: 0.498239
 >> iter 80000, loss: 0.433915
   Number of active neurons: 4
 >> iter 81000, loss: 0.273682
 >> iter 82000, loss: 0.265970
 >> iter 83000, loss: 0.366029
 >> iter 84000, loss: 0.407660
 >> iter 85000, loss: 0.520093
 >> iter 86000, loss: 0.399283
 >> iter 87000, loss: 0.382301
 >> iter 88000, loss: 0.292947
 >> iter 89000, loss: 0.399415
 >> iter 90000, loss: 0.367442
   Number of active neurons: 4
 >> iter 91000, loss: 0.367091
 >> iter 92000, loss: 0.326959
 >> iter 93000, loss: 0.380238
 >> iter 94000, loss: 0.230252
 >> iter 95000, loss: 0.253107
 >> iter 96000, loss: 0.503922
 >> iter 97000, loss: 0.389891
 >> iter 98000, loss: 0.400103
 >> iter 99000, loss: 0.265501
 >> iter 100000, loss: 0.361764
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.272985
 >> iter 2000, loss: 11.766283
 >> iter 3000, loss: 6.264146
 >> iter 4000, loss: 2.915987
 >> iter 5000, loss: 1.743582
 >> iter 6000, loss: 1.271563
 >> iter 7000, loss: 0.791913
 >> iter 8000, loss: 0.577264
 >> iter 9000, loss: 0.580752
 >> iter 10000, loss: 0.530547
   Number of active neurons: 4
 >> iter 11000, loss: 0.415752
 >> iter 12000, loss: 0.550869
 >> iter 13000, loss: 0.543699
 >> iter 14000, loss: 0.386154
 >> iter 15000, loss: 0.328455
 >> iter 16000, loss: 0.402236
 >> iter 17000, loss: 0.550391
 >> iter 18000, loss: 0.697864
 >> iter 19000, loss: 0.707577
 >> iter 20000, loss: 0.503175
   Number of active neurons: 4
 >> iter 21000, loss: 0.371327
 >> iter 22000, loss: 0.355369
 >> iter 23000, loss: 0.415537
 >> iter 24000, loss: 0.396514
 >> iter 25000, loss: 0.379183
 >> iter 26000, loss: 0.426740
 >> iter 27000, loss: 0.547783
 >> iter 28000, loss: 0.417853
 >> iter 29000, loss: 0.635400
 >> iter 30000, loss: 0.529091
   Number of active neurons: 4
 >> iter 31000, loss: 0.592620
 >> iter 32000, loss: 0.506132
 >> iter 33000, loss: 0.522211
 >> iter 34000, loss: 0.711583
 >> iter 35000, loss: 0.463006
 >> iter 36000, loss: 0.507522
 >> iter 37000, loss: 0.435613
 >> iter 38000, loss: 0.512780
 >> iter 39000, loss: 0.366924
 >> iter 40000, loss: 0.407593
   Number of active neurons: 4
 >> iter 41000, loss: 0.338692
 >> iter 42000, loss: 0.471269
 >> iter 43000, loss: 0.583934
 >> iter 44000, loss: 0.670057
 >> iter 45000, loss: 0.522400
 >> iter 46000, loss: 0.382729
 >> iter 47000, loss: 0.391221
 >> iter 48000, loss: 0.532019
 >> iter 49000, loss: 0.343476
 >> iter 50000, loss: 0.355070
   Number of active neurons: 4
 >> iter 51000, loss: 0.408753
 >> iter 52000, loss: 0.441685
 >> iter 53000, loss: 0.472261
 >> iter 54000, loss: 0.526235
 >> iter 55000, loss: 0.464116
 >> iter 56000, loss: 0.441917
 >> iter 57000, loss: 0.620814
 >> iter 58000, loss: 0.526758
 >> iter 59000, loss: 0.459217
 >> iter 60000, loss: 0.312910
   Number of active neurons: 4
 >> iter 61000, loss: 0.503638
 >> iter 62000, loss: 0.409403
 >> iter 63000, loss: 0.621292
 >> iter 64000, loss: 0.487808
 >> iter 65000, loss: 0.233157
 >> iter 66000, loss: 0.229861
 >> iter 67000, loss: 0.318882
 >> iter 68000, loss: 0.496384
 >> iter 69000, loss: 0.489637
 >> iter 70000, loss: 0.409246
   Number of active neurons: 4
 >> iter 71000, loss: 0.215536
 >> iter 72000, loss: 0.652351
 >> iter 73000, loss: 0.404128
 >> iter 74000, loss: 0.321730
 >> iter 75000, loss: 0.535192
 >> iter 76000, loss: 0.478912
 >> iter 77000, loss: 0.500938
 >> iter 78000, loss: 0.527459
 >> iter 79000, loss: 0.523881
 >> iter 80000, loss: 0.487493
   Number of active neurons: 4
 >> iter 81000, loss: 0.381137
 >> iter 82000, loss: 0.544776
 >> iter 83000, loss: 0.417390
 >> iter 84000, loss: 0.390457
 >> iter 85000, loss: 0.387728
 >> iter 86000, loss: 0.636237
 >> iter 87000, loss: 0.542435
 >> iter 88000, loss: 0.462644
 >> iter 89000, loss: 0.331317
 >> iter 90000, loss: 0.255751
   Number of active neurons: 4
 >> iter 91000, loss: 0.329059
 >> iter 92000, loss: 0.292700
 >> iter 93000, loss: 0.213840
 >> iter 94000, loss: 0.415801
 >> iter 95000, loss: 0.421426
 >> iter 96000, loss: 0.462072
 >> iter 97000, loss: 0.500072
 >> iter 98000, loss: 0.423769
 >> iter 99000, loss: 0.319116
 >> iter 100000, loss: 0.330213
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524757
 >> iter 2000, loss: 18.054279
 >> iter 3000, loss: 17.068461
 >> iter 4000, loss: 16.779364
 >> iter 5000, loss: 16.602168
 >> iter 6000, loss: 16.033666
 >> iter 7000, loss: 11.571152
 >> iter 8000, loss: 6.252050
 >> iter 9000, loss: 2.968113
 >> iter 10000, loss: 1.602306
   Number of active neurons: 4
 >> iter 11000, loss: 0.901652
 >> iter 12000, loss: 0.563735
 >> iter 13000, loss: 0.457767
 >> iter 14000, loss: 0.308990
 >> iter 15000, loss: 0.467865
 >> iter 16000, loss: 0.331971
 >> iter 17000, loss: 0.478552
 >> iter 18000, loss: 0.375626
 >> iter 19000, loss: 0.346831
 >> iter 20000, loss: 0.337778
   Number of active neurons: 4
 >> iter 21000, loss: 0.508619
 >> iter 22000, loss: 0.426823
 >> iter 23000, loss: 0.335309
 >> iter 24000, loss: 0.252846
 >> iter 25000, loss: 0.371743
 >> iter 26000, loss: 0.417024
 >> iter 27000, loss: 0.616756
 >> iter 28000, loss: 0.401509
 >> iter 29000, loss: 0.341585
 >> iter 30000, loss: 0.208563
   Number of active neurons: 4
 >> iter 31000, loss: 0.278447
 >> iter 32000, loss: 0.163746
 >> iter 33000, loss: 0.123735
 >> iter 34000, loss: 0.211273
 >> iter 35000, loss: 0.271710
 >> iter 36000, loss: 0.336680
 >> iter 37000, loss: 0.402216
 >> iter 38000, loss: 0.464203
 >> iter 39000, loss: 0.367065
 >> iter 40000, loss: 0.268051
   Number of active neurons: 4
 >> iter 41000, loss: 0.196771
 >> iter 42000, loss: 0.314447
 >> iter 43000, loss: 0.377264
 >> iter 44000, loss: 0.404176
 >> iter 45000, loss: 0.319836
 >> iter 46000, loss: 0.441024
 >> iter 47000, loss: 0.268292
 >> iter 48000, loss: 0.324152
 >> iter 49000, loss: 0.277686
 >> iter 50000, loss: 0.194890
   Number of active neurons: 4
 >> iter 51000, loss: 0.113415
 >> iter 52000, loss: 0.134299
 >> iter 53000, loss: 0.264663
 >> iter 54000, loss: 0.352325
 >> iter 55000, loss: 0.298026
 >> iter 56000, loss: 0.278805
 >> iter 57000, loss: 0.216001
 >> iter 58000, loss: 0.308142
 >> iter 59000, loss: 0.277745
 >> iter 60000, loss: 0.644274
   Number of active neurons: 4
 >> iter 61000, loss: 0.341967
 >> iter 62000, loss: 0.223227
 >> iter 63000, loss: 0.193649
 >> iter 64000, loss: 0.236289
 >> iter 65000, loss: 0.324622
 >> iter 66000, loss: 0.234956
 >> iter 67000, loss: 0.250490
 >> iter 68000, loss: 0.381963
 >> iter 69000, loss: 0.242114
 >> iter 70000, loss: 0.595997
   Number of active neurons: 4
 >> iter 71000, loss: 0.342366
 >> iter 72000, loss: 0.192461
 >> iter 73000, loss: 0.155551
 >> iter 74000, loss: 0.223277
 >> iter 75000, loss: 0.273849
 >> iter 76000, loss: 0.404046
 >> iter 77000, loss: 0.227365
 >> iter 78000, loss: 0.244633
 >> iter 79000, loss: 0.403282
 >> iter 80000, loss: 0.353660
   Number of active neurons: 4
 >> iter 81000, loss: 0.427528
 >> iter 82000, loss: 0.281410
 >> iter 83000, loss: 0.370918
 >> iter 84000, loss: 0.335695
 >> iter 85000, loss: 0.156967
 >> iter 86000, loss: 0.324569
 >> iter 87000, loss: 0.232903
 >> iter 88000, loss: 0.367333
 >> iter 89000, loss: 0.172215
 >> iter 90000, loss: 0.259163
   Number of active neurons: 3
 >> iter 91000, loss: 0.155333
 >> iter 92000, loss: 0.180901
 >> iter 93000, loss: 0.165951
 >> iter 94000, loss: 0.320586
 >> iter 95000, loss: 0.299654
 >> iter 96000, loss: 0.186748
 >> iter 97000, loss: 0.198738
 >> iter 98000, loss: 0.249009
 >> iter 99000, loss: 0.342722
 >> iter 100000, loss: 0.225579
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.080448
 >> iter 2000, loss: 11.730789
 >> iter 3000, loss: 5.949989
 >> iter 4000, loss: 2.621143
 >> iter 5000, loss: 1.344533
 >> iter 6000, loss: 0.771859
 >> iter 7000, loss: 0.714195
 >> iter 8000, loss: 0.399633
 >> iter 9000, loss: 0.393092
 >> iter 10000, loss: 0.435505
   Number of active neurons: 4
 >> iter 11000, loss: 0.437995
 >> iter 12000, loss: 0.268581
 >> iter 13000, loss: 0.351968
 >> iter 14000, loss: 0.257873
 >> iter 15000, loss: 0.255811
 >> iter 16000, loss: 0.368227
 >> iter 17000, loss: 0.417480
 >> iter 18000, loss: 0.345167
 >> iter 19000, loss: 0.375905
 >> iter 20000, loss: 0.396003
   Number of active neurons: 4
 >> iter 21000, loss: 0.337138
 >> iter 22000, loss: 0.254164
 >> iter 23000, loss: 0.259391
 >> iter 24000, loss: 0.366195
 >> iter 25000, loss: 0.377255
 >> iter 26000, loss: 0.263802
 >> iter 27000, loss: 0.230061
 >> iter 28000, loss: 0.169347
 >> iter 29000, loss: 0.180557
 >> iter 30000, loss: 0.239572
   Number of active neurons: 4
 >> iter 31000, loss: 0.210691
 >> iter 32000, loss: 0.375678
 >> iter 33000, loss: 0.219885
 >> iter 34000, loss: 0.331177
 >> iter 35000, loss: 0.228772
 >> iter 36000, loss: 0.309846
 >> iter 37000, loss: 0.214082
 >> iter 38000, loss: 0.258612
 >> iter 39000, loss: 0.256263
 >> iter 40000, loss: 0.402608
   Number of active neurons: 4
 >> iter 41000, loss: 0.313497
 >> iter 42000, loss: 0.381511
 >> iter 43000, loss: 0.252437
 >> iter 44000, loss: 0.347923
 >> iter 45000, loss: 0.285195
 >> iter 46000, loss: 0.162009
 >> iter 47000, loss: 0.320207
 >> iter 48000, loss: 0.223040
 >> iter 49000, loss: 0.229310
 >> iter 50000, loss: 0.263969
   Number of active neurons: 4
 >> iter 51000, loss: 0.425755
 >> iter 52000, loss: 0.328686
 >> iter 53000, loss: 0.329335
 >> iter 54000, loss: 0.379937
 >> iter 55000, loss: 0.461112
 >> iter 56000, loss: 0.260812
 >> iter 57000, loss: 0.307090
 >> iter 58000, loss: 0.429739
 >> iter 59000, loss: 0.311601
 >> iter 60000, loss: 0.396552
   Number of active neurons: 4
 >> iter 61000, loss: 0.251136
 >> iter 62000, loss: 0.254420
 >> iter 63000, loss: 0.279472
 >> iter 64000, loss: 0.402694
 >> iter 65000, loss: 0.308789
 >> iter 66000, loss: 0.210585
 >> iter 67000, loss: 0.409144
 >> iter 68000, loss: 0.333996
 >> iter 69000, loss: 0.223460
 >> iter 70000, loss: 0.176576
   Number of active neurons: 4
 >> iter 71000, loss: 0.198164
 >> iter 72000, loss: 0.399340
 >> iter 73000, loss: 0.309156
 >> iter 74000, loss: 0.191178
 >> iter 75000, loss: 0.151064
 >> iter 76000, loss: 0.187962
 >> iter 77000, loss: 0.191092
 >> iter 78000, loss: 0.172931
 >> iter 79000, loss: 0.149468
 >> iter 80000, loss: 0.135579
   Number of active neurons: 4
 >> iter 81000, loss: 0.234829
 >> iter 82000, loss: 0.199207
 >> iter 83000, loss: 0.161303
 >> iter 84000, loss: 0.341242
 >> iter 85000, loss: 0.266146
 >> iter 86000, loss: 0.276204
 >> iter 87000, loss: 0.195399
 >> iter 88000, loss: 0.135714
 >> iter 89000, loss: 0.267305
 >> iter 90000, loss: 0.286943
   Number of active neurons: 4
 >> iter 91000, loss: 0.217084
 >> iter 92000, loss: 0.172571
 >> iter 93000, loss: 0.126693
 >> iter 94000, loss: 0.258776
 >> iter 95000, loss: 0.391522
 >> iter 96000, loss: 0.185600
 >> iter 97000, loss: 0.399790
 >> iter 98000, loss: 0.247627
 >> iter 99000, loss: 0.186880
 >> iter 100000, loss: 0.240954
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.521505
 >> iter 2000, loss: 10.351909
 >> iter 3000, loss: 5.132275
 >> iter 4000, loss: 2.683431
 >> iter 5000, loss: 1.405505
 >> iter 6000, loss: 0.783084
 >> iter 7000, loss: 0.830065
 >> iter 8000, loss: 0.517065
 >> iter 9000, loss: 0.429820
 >> iter 10000, loss: 0.502537
   Number of active neurons: 4
 >> iter 11000, loss: 0.486899
 >> iter 12000, loss: 0.533363
 >> iter 13000, loss: 0.378278
 >> iter 14000, loss: 0.340726
 >> iter 15000, loss: 0.346029
 >> iter 16000, loss: 0.464820
 >> iter 17000, loss: 0.343400
 >> iter 18000, loss: 0.400000
 >> iter 19000, loss: 0.443541
 >> iter 20000, loss: 0.483436
   Number of active neurons: 4
 >> iter 21000, loss: 0.492740
 >> iter 22000, loss: 0.547172
 >> iter 23000, loss: 0.356361
 >> iter 24000, loss: 0.612696
 >> iter 25000, loss: 0.481338
 >> iter 26000, loss: 0.470664
 >> iter 27000, loss: 0.632254
 >> iter 28000, loss: 0.471559
 >> iter 29000, loss: 0.506971
 >> iter 30000, loss: 0.428597
   Number of active neurons: 4
 >> iter 31000, loss: 0.583497
 >> iter 32000, loss: 0.756303
 >> iter 33000, loss: 0.502578
 >> iter 34000, loss: 0.497663
 >> iter 35000, loss: 0.429048
 >> iter 36000, loss: 0.191775
 >> iter 37000, loss: 0.435547
 >> iter 38000, loss: 0.629023
 >> iter 39000, loss: 0.520204
 >> iter 40000, loss: 0.322299
   Number of active neurons: 4
 >> iter 41000, loss: 0.383784
 >> iter 42000, loss: 0.300807
 >> iter 43000, loss: 0.631913
 >> iter 44000, loss: 0.567190
 >> iter 45000, loss: 0.593402
 >> iter 46000, loss: 0.555935
 >> iter 47000, loss: 0.360767
 >> iter 48000, loss: 0.598175
 >> iter 49000, loss: 0.491653
 >> iter 50000, loss: 0.584540
   Number of active neurons: 4
 >> iter 51000, loss: 0.563198
 >> iter 52000, loss: 0.319830
 >> iter 53000, loss: 0.402307
 >> iter 54000, loss: 0.717755
 >> iter 55000, loss: 0.522510
 >> iter 56000, loss: 0.628226
 >> iter 57000, loss: 0.677168
 >> iter 58000, loss: 0.594555
 >> iter 59000, loss: 0.610190
 >> iter 60000, loss: 0.413735
   Number of active neurons: 4
 >> iter 61000, loss: 0.455149
 >> iter 62000, loss: 0.362412
 >> iter 63000, loss: 0.344996
 >> iter 64000, loss: 0.423939
 >> iter 65000, loss: 0.348177
 >> iter 66000, loss: 0.566355
 >> iter 67000, loss: 0.501751
 >> iter 68000, loss: 0.553503
 >> iter 69000, loss: 0.318648
 >> iter 70000, loss: 0.460017
   Number of active neurons: 4
 >> iter 71000, loss: 0.364797
 >> iter 72000, loss: 0.459782
 >> iter 73000, loss: 0.360160
 >> iter 74000, loss: 0.381254
 >> iter 75000, loss: 0.429569
 >> iter 76000, loss: 0.343616
 >> iter 77000, loss: 0.400485
 >> iter 78000, loss: 0.296291
 >> iter 79000, loss: 0.231472
 >> iter 80000, loss: 0.224558
   Number of active neurons: 4
 >> iter 81000, loss: 0.249558
 >> iter 82000, loss: 0.304476
 >> iter 83000, loss: 0.248326
 >> iter 84000, loss: 0.544919
 >> iter 85000, loss: 0.454357
 >> iter 86000, loss: 0.253052
 >> iter 87000, loss: 0.304687
 >> iter 88000, loss: 0.237068
 >> iter 89000, loss: 0.193449
 >> iter 90000, loss: 0.384287
   Number of active neurons: 4
 >> iter 91000, loss: 0.320320
 >> iter 92000, loss: 0.446125
 >> iter 93000, loss: 0.577557
 >> iter 94000, loss: 0.515223
 >> iter 95000, loss: 0.389510
 >> iter 96000, loss: 0.354641
 >> iter 97000, loss: 0.452125
 >> iter 98000, loss: 0.499662
 >> iter 99000, loss: 0.326249
 >> iter 100000, loss: 0.355555
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.514835
 >> iter 2000, loss: 8.628945
 >> iter 3000, loss: 3.826409
 >> iter 4000, loss: 1.812843
 >> iter 5000, loss: 0.930755
 >> iter 6000, loss: 0.640742
 >> iter 7000, loss: 0.474689
 >> iter 8000, loss: 0.359152
 >> iter 9000, loss: 0.329376
 >> iter 10000, loss: 0.286351
   Number of active neurons: 4
 >> iter 11000, loss: 0.301399
 >> iter 12000, loss: 0.247109
 >> iter 13000, loss: 0.287525
 >> iter 14000, loss: 0.418217
 >> iter 15000, loss: 0.328237
 >> iter 16000, loss: 0.278889
 >> iter 17000, loss: 0.407013
 >> iter 18000, loss: 0.280374
 >> iter 19000, loss: 0.329522
 >> iter 20000, loss: 0.192940
   Number of active neurons: 4
 >> iter 21000, loss: 0.150084
 >> iter 22000, loss: 0.353601
 >> iter 23000, loss: 0.313798
 >> iter 24000, loss: 0.318625
 >> iter 25000, loss: 0.299840
 >> iter 26000, loss: 0.460230
 >> iter 27000, loss: 0.347978
 >> iter 28000, loss: 0.244730
 >> iter 29000, loss: 0.362519
 >> iter 30000, loss: 0.357378
   Number of active neurons: 3
 >> iter 31000, loss: 0.237062
 >> iter 32000, loss: 0.148142
 >> iter 33000, loss: 0.299124
 >> iter 34000, loss: 0.223857
 >> iter 35000, loss: 0.141885
 >> iter 36000, loss: 0.180280
 >> iter 37000, loss: 0.209067
 >> iter 38000, loss: 0.198821
 >> iter 39000, loss: 0.142801
 >> iter 40000, loss: 0.280445
   Number of active neurons: 3
 >> iter 41000, loss: 0.259869
 >> iter 42000, loss: 0.252158
 >> iter 43000, loss: 0.162128
 >> iter 44000, loss: 0.210241
 >> iter 45000, loss: 0.410465
 >> iter 46000, loss: 0.334072
 >> iter 47000, loss: 0.242639
 >> iter 48000, loss: 0.241291
 >> iter 49000, loss: 0.236303
 >> iter 50000, loss: 0.150121
   Number of active neurons: 3
 >> iter 51000, loss: 0.112947
 >> iter 52000, loss: 0.225748
 >> iter 53000, loss: 0.141868
 >> iter 54000, loss: 0.293787
 >> iter 55000, loss: 0.466086
 >> iter 56000, loss: 0.420721
 >> iter 57000, loss: 0.345771
 >> iter 58000, loss: 0.312906
 >> iter 59000, loss: 0.234062
 >> iter 60000, loss: 0.225738
   Number of active neurons: 3
 >> iter 61000, loss: 0.180541
 >> iter 62000, loss: 0.209522
 >> iter 63000, loss: 0.199280
 >> iter 64000, loss: 0.219362
 >> iter 65000, loss: 0.244779
 >> iter 66000, loss: 0.389525
 >> iter 67000, loss: 0.180465
 >> iter 68000, loss: 0.141208
 >> iter 69000, loss: 0.171631
 >> iter 70000, loss: 0.168616
   Number of active neurons: 3
 >> iter 71000, loss: 0.101903
 >> iter 72000, loss: 0.209917
 >> iter 73000, loss: 0.335563
 >> iter 74000, loss: 0.260837
 >> iter 75000, loss: 0.218455
 >> iter 76000, loss: 0.246044
 >> iter 77000, loss: 0.186146
 >> iter 78000, loss: 0.158763
 >> iter 79000, loss: 0.372513
 >> iter 80000, loss: 0.449288
   Number of active neurons: 3
 >> iter 81000, loss: 0.208908
 >> iter 82000, loss: 0.158321
 >> iter 83000, loss: 0.235562
 >> iter 84000, loss: 0.256266
 >> iter 85000, loss: 0.209454
 >> iter 86000, loss: 0.284402
 >> iter 87000, loss: 0.347321
 >> iter 88000, loss: 0.391314
 >> iter 89000, loss: 0.264543
 >> iter 90000, loss: 0.242489
   Number of active neurons: 3
 >> iter 91000, loss: 0.131137
 >> iter 92000, loss: 0.200093
 >> iter 93000, loss: 0.196761
 >> iter 94000, loss: 0.162198
 >> iter 95000, loss: 0.136792
 >> iter 96000, loss: 0.312249
 >> iter 97000, loss: 0.397561
 >> iter 98000, loss: 0.288247
 >> iter 99000, loss: 0.265291
 >> iter 100000, loss: 0.177088
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.143955
 >> iter 2000, loss: 10.782926
 >> iter 3000, loss: 5.452134
 >> iter 4000, loss: 2.657889
 >> iter 5000, loss: 1.881414
 >> iter 6000, loss: 1.324084
 >> iter 7000, loss: 0.810834
 >> iter 8000, loss: 0.871800
 >> iter 9000, loss: 0.737385
 >> iter 10000, loss: 0.830206
   Number of active neurons: 4
 >> iter 11000, loss: 0.716552
 >> iter 12000, loss: 0.453189
 >> iter 13000, loss: 0.417774
 >> iter 14000, loss: 0.599932
 >> iter 15000, loss: 0.417167
 >> iter 16000, loss: 0.584493
 >> iter 17000, loss: 0.820411
 >> iter 18000, loss: 0.833877
 >> iter 19000, loss: 0.693881
 >> iter 20000, loss: 0.562977
   Number of active neurons: 4
 >> iter 21000, loss: 0.679787
 >> iter 22000, loss: 0.644153
 >> iter 23000, loss: 0.455948
 >> iter 24000, loss: 0.543545
 >> iter 25000, loss: 0.578968
 >> iter 26000, loss: 0.537156
 >> iter 27000, loss: 0.545327
 >> iter 28000, loss: 0.561617
 >> iter 29000, loss: 0.683823
 >> iter 30000, loss: 0.475654
   Number of active neurons: 4
 >> iter 31000, loss: 0.651907
 >> iter 32000, loss: 0.630586
 >> iter 33000, loss: 0.715418
 >> iter 34000, loss: 0.455853
 >> iter 35000, loss: 0.517453
 >> iter 36000, loss: 0.671567
 >> iter 37000, loss: 0.367927
 >> iter 38000, loss: 0.569160
 >> iter 39000, loss: 0.400400
 >> iter 40000, loss: 0.576973
   Number of active neurons: 4
 >> iter 41000, loss: 0.650694
 >> iter 42000, loss: 0.563218
 >> iter 43000, loss: 0.443014
 >> iter 44000, loss: 0.379142
 >> iter 45000, loss: 0.455281
 >> iter 46000, loss: 0.346244
 >> iter 47000, loss: 0.266674
 >> iter 48000, loss: 0.796997
 >> iter 49000, loss: 0.646554
 >> iter 50000, loss: 0.334661
   Number of active neurons: 4
 >> iter 51000, loss: 0.247995
 >> iter 52000, loss: 0.374766
 >> iter 53000, loss: 0.379551
 >> iter 54000, loss: 0.397830
 >> iter 55000, loss: 0.513548
 >> iter 56000, loss: 0.418261
 >> iter 57000, loss: 0.476915
 >> iter 58000, loss: 0.294517
 >> iter 59000, loss: 0.285386
 >> iter 60000, loss: 0.279856
   Number of active neurons: 4
 >> iter 61000, loss: 0.229402
 >> iter 62000, loss: 0.641112
 >> iter 63000, loss: 0.446598
 >> iter 64000, loss: 0.365776
 >> iter 65000, loss: 0.366786
 >> iter 66000, loss: 0.406671
 >> iter 67000, loss: 0.384546
 >> iter 68000, loss: 0.309881
 >> iter 69000, loss: 0.384541
 >> iter 70000, loss: 0.444609
   Number of active neurons: 4
 >> iter 71000, loss: 0.445169
 >> iter 72000, loss: 0.395383
 >> iter 73000, loss: 0.252346
 >> iter 74000, loss: 0.209646
 >> iter 75000, loss: 0.371918
 >> iter 76000, loss: 0.368262
 >> iter 77000, loss: 0.291026
 >> iter 78000, loss: 0.644949
 >> iter 79000, loss: 0.378554
 >> iter 80000, loss: 0.346552
   Number of active neurons: 4
 >> iter 81000, loss: 0.302818
 >> iter 82000, loss: 0.391631
 >> iter 83000, loss: 0.251457
 >> iter 84000, loss: 0.257028
 >> iter 85000, loss: 0.380615
 >> iter 86000, loss: 0.330525
 >> iter 87000, loss: 0.352728
 >> iter 88000, loss: 0.286027
 >> iter 89000, loss: 0.254816
 >> iter 90000, loss: 0.430658
   Number of active neurons: 4
 >> iter 91000, loss: 0.289773
 >> iter 92000, loss: 0.262726
 >> iter 93000, loss: 0.550335
 >> iter 94000, loss: 0.401689
 >> iter 95000, loss: 0.348228
 >> iter 96000, loss: 0.334922
 >> iter 97000, loss: 0.496513
 >> iter 98000, loss: 0.363742
 >> iter 99000, loss: 0.334705
 >> iter 100000, loss: 0.497713
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.850834
 >> iter 2000, loss: 10.829592
 >> iter 3000, loss: 4.901157
 >> iter 4000, loss: 2.603199
 >> iter 5000, loss: 1.600789
 >> iter 6000, loss: 0.893332
 >> iter 7000, loss: 0.472603
 >> iter 8000, loss: 0.461988
 >> iter 9000, loss: 0.419337
 >> iter 10000, loss: 0.258786
   Number of active neurons: 4
 >> iter 11000, loss: 0.575736
 >> iter 12000, loss: 0.398170
 >> iter 13000, loss: 0.437598
 >> iter 14000, loss: 0.350741
 >> iter 15000, loss: 0.269019
 >> iter 16000, loss: 0.417353
 >> iter 17000, loss: 0.320158
 >> iter 18000, loss: 0.299052
 >> iter 19000, loss: 0.199927
 >> iter 20000, loss: 0.286949
   Number of active neurons: 4
 >> iter 21000, loss: 0.231041
 >> iter 22000, loss: 0.334488
 >> iter 23000, loss: 0.285871
 >> iter 24000, loss: 0.210702
 >> iter 25000, loss: 0.262721
 >> iter 26000, loss: 0.246409
 >> iter 27000, loss: 0.283984
 >> iter 28000, loss: 0.350665
 >> iter 29000, loss: 0.338853
 >> iter 30000, loss: 0.238438
   Number of active neurons: 4
 >> iter 31000, loss: 0.383663
 >> iter 32000, loss: 0.324399
 >> iter 33000, loss: 0.396304
 >> iter 34000, loss: 0.378295
 >> iter 35000, loss: 0.318561
 >> iter 36000, loss: 0.462241
 >> iter 37000, loss: 0.357419
 >> iter 38000, loss: 0.515295
 >> iter 39000, loss: 0.452613
 >> iter 40000, loss: 0.343642
   Number of active neurons: 4
 >> iter 41000, loss: 0.360497
 >> iter 42000, loss: 0.352530
 >> iter 43000, loss: 0.276430
 >> iter 44000, loss: 0.317869
 >> iter 45000, loss: 0.257203
 >> iter 46000, loss: 0.255780
 >> iter 47000, loss: 0.395547
 >> iter 48000, loss: 0.317575
 >> iter 49000, loss: 0.279555
 >> iter 50000, loss: 0.470504
   Number of active neurons: 4
 >> iter 51000, loss: 0.324915
 >> iter 52000, loss: 0.214136
 >> iter 53000, loss: 0.243575
 >> iter 54000, loss: 0.285398
 >> iter 55000, loss: 0.301780
 >> iter 56000, loss: 0.215863
 >> iter 57000, loss: 0.324946
 >> iter 58000, loss: 0.501993
 >> iter 59000, loss: 0.434113
 >> iter 60000, loss: 0.295540
   Number of active neurons: 4
 >> iter 61000, loss: 0.339152
 >> iter 62000, loss: 0.405296
 >> iter 63000, loss: 0.487415
 >> iter 64000, loss: 0.479817
 >> iter 65000, loss: 0.322717
 >> iter 66000, loss: 0.416131
 >> iter 67000, loss: 0.346321
 >> iter 68000, loss: 0.236247
 >> iter 69000, loss: 0.356980
 >> iter 70000, loss: 0.416620
   Number of active neurons: 4
 >> iter 71000, loss: 0.402917
 >> iter 72000, loss: 0.279075
 >> iter 73000, loss: 0.370192
 >> iter 74000, loss: 0.343910
 >> iter 75000, loss: 0.281552
 >> iter 76000, loss: 0.300669
 >> iter 77000, loss: 0.228968
 >> iter 78000, loss: 0.224326
 >> iter 79000, loss: 0.277406
 >> iter 80000, loss: 0.273844
   Number of active neurons: 4
 >> iter 81000, loss: 0.211674
 >> iter 82000, loss: 0.148183
 >> iter 83000, loss: 0.364068
 >> iter 84000, loss: 0.256756
 >> iter 85000, loss: 0.253408
 >> iter 86000, loss: 0.129127
 >> iter 87000, loss: 0.120045
 >> iter 88000, loss: 0.204924
 >> iter 89000, loss: 0.155865
 >> iter 90000, loss: 0.315852
   Number of active neurons: 4
 >> iter 91000, loss: 0.249590
 >> iter 92000, loss: 0.366895
 >> iter 93000, loss: 0.480467
 >> iter 94000, loss: 0.267435
 >> iter 95000, loss: 0.335145
 >> iter 96000, loss: 0.362839
 >> iter 97000, loss: 0.331038
 >> iter 98000, loss: 0.202542
 >> iter 99000, loss: 0.197034
 >> iter 100000, loss: 0.210637
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.561067
 >> iter 2000, loss: 10.923362
 >> iter 3000, loss: 5.311213
 >> iter 4000, loss: 2.746623
 >> iter 5000, loss: 1.419206
 >> iter 6000, loss: 0.943515
 >> iter 7000, loss: 0.779259
 >> iter 8000, loss: 0.541418
 >> iter 9000, loss: 0.595747
 >> iter 10000, loss: 0.357277
   Number of active neurons: 4
 >> iter 11000, loss: 0.304580
 >> iter 12000, loss: 0.367380
 >> iter 13000, loss: 0.227136
 >> iter 14000, loss: 0.252867
 >> iter 15000, loss: 0.243795
 >> iter 16000, loss: 0.471632
 >> iter 17000, loss: 0.298563
 >> iter 18000, loss: 0.274551
 >> iter 19000, loss: 0.390403
 >> iter 20000, loss: 0.330495
   Number of active neurons: 4
 >> iter 21000, loss: 0.309279
 >> iter 22000, loss: 0.326442
 >> iter 23000, loss: 0.261677
 >> iter 24000, loss: 0.276597
 >> iter 25000, loss: 0.297440
 >> iter 26000, loss: 0.332848
 >> iter 27000, loss: 0.302539
 >> iter 28000, loss: 0.274373
 >> iter 29000, loss: 0.285868
 >> iter 30000, loss: 0.447179
   Number of active neurons: 4
 >> iter 31000, loss: 0.500585
 >> iter 32000, loss: 0.397329
 >> iter 33000, loss: 0.497383
 >> iter 34000, loss: 0.260177
 >> iter 35000, loss: 0.399557
 >> iter 36000, loss: 0.293947
 >> iter 37000, loss: 0.370761
 >> iter 38000, loss: 0.269051
 >> iter 39000, loss: 0.308472
 >> iter 40000, loss: 0.274489
   Number of active neurons: 4
 >> iter 41000, loss: 0.250492
 >> iter 42000, loss: 0.227989
 >> iter 43000, loss: 0.235414
 >> iter 44000, loss: 0.185215
 >> iter 45000, loss: 0.164930
 >> iter 46000, loss: 0.356315
 >> iter 47000, loss: 0.311142
 >> iter 48000, loss: 0.392997
 >> iter 49000, loss: 0.318881
 >> iter 50000, loss: 0.295677
   Number of active neurons: 4
 >> iter 51000, loss: 0.315740
 >> iter 52000, loss: 0.248553
 >> iter 53000, loss: 0.270982
 >> iter 54000, loss: 0.418715
 >> iter 55000, loss: 0.321756
 >> iter 56000, loss: 0.233739
 >> iter 57000, loss: 0.213412
 >> iter 58000, loss: 0.216541
 >> iter 59000, loss: 0.266011
 >> iter 60000, loss: 0.343040
   Number of active neurons: 4
 >> iter 61000, loss: 0.248540
 >> iter 62000, loss: 0.227218
 >> iter 63000, loss: 0.242001
 >> iter 64000, loss: 0.322192
 >> iter 65000, loss: 0.270162
 >> iter 66000, loss: 0.325951
 >> iter 67000, loss: 0.259881
 >> iter 68000, loss: 0.201522
 >> iter 69000, loss: 0.300693
 >> iter 70000, loss: 0.234755
   Number of active neurons: 4
 >> iter 71000, loss: 0.366925
 >> iter 72000, loss: 0.316521
 >> iter 73000, loss: 0.356773
 >> iter 74000, loss: 0.385101
 >> iter 75000, loss: 0.461484
 >> iter 76000, loss: 0.339905
 >> iter 77000, loss: 0.159636
 >> iter 78000, loss: 0.261145
 >> iter 79000, loss: 0.217684
 >> iter 80000, loss: 0.257132
   Number of active neurons: 4
 >> iter 81000, loss: 0.231018
 >> iter 82000, loss: 0.306430
 >> iter 83000, loss: 0.213124
 >> iter 84000, loss: 0.244247
 >> iter 85000, loss: 0.235646
 >> iter 86000, loss: 0.265197
 >> iter 87000, loss: 0.196042
 >> iter 88000, loss: 0.245674
 >> iter 89000, loss: 0.402521
 >> iter 90000, loss: 0.242989
   Number of active neurons: 4
 >> iter 91000, loss: 0.300605
 >> iter 92000, loss: 0.278140
 >> iter 93000, loss: 0.235408
 >> iter 94000, loss: 0.390272
 >> iter 95000, loss: 0.281910
 >> iter 96000, loss: 0.248592
 >> iter 97000, loss: 0.188902
 >> iter 98000, loss: 0.333285
 >> iter 99000, loss: 0.242286
 >> iter 100000, loss: 0.274336
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.254631
 >> iter 2000, loss: 10.662659
 >> iter 3000, loss: 5.037087
 >> iter 4000, loss: 2.448715
 >> iter 5000, loss: 1.451917
 >> iter 6000, loss: 0.868234
 >> iter 7000, loss: 0.579658
 >> iter 8000, loss: 0.320823
 >> iter 9000, loss: 0.305950
 >> iter 10000, loss: 0.309278
   Number of active neurons: 4
 >> iter 11000, loss: 0.275631
 >> iter 12000, loss: 0.377861
 >> iter 13000, loss: 0.243688
 >> iter 14000, loss: 0.384735
 >> iter 15000, loss: 0.345754
 >> iter 16000, loss: 0.231828
 >> iter 17000, loss: 0.279355
 >> iter 18000, loss: 0.198044
 >> iter 19000, loss: 0.330755
 >> iter 20000, loss: 0.294710
   Number of active neurons: 4
 >> iter 21000, loss: 0.341457
 >> iter 22000, loss: 0.411686
 >> iter 23000, loss: 0.207057
 >> iter 24000, loss: 0.193378
 >> iter 25000, loss: 0.161338
 >> iter 26000, loss: 0.176219
 >> iter 27000, loss: 0.249259
 >> iter 28000, loss: 0.240551
 >> iter 29000, loss: 0.260793
 >> iter 30000, loss: 0.245552
   Number of active neurons: 4
 >> iter 31000, loss: 0.244539
 >> iter 32000, loss: 0.328479
 >> iter 33000, loss: 0.298670
 >> iter 34000, loss: 0.360045
 >> iter 35000, loss: 0.322278
 >> iter 36000, loss: 0.337824
 >> iter 37000, loss: 0.425032
 >> iter 38000, loss: 0.412036
 >> iter 39000, loss: 0.483091
 >> iter 40000, loss: 0.237918
   Number of active neurons: 4
 >> iter 41000, loss: 0.213273
 >> iter 42000, loss: 0.215021
 >> iter 43000, loss: 0.482702
 >> iter 44000, loss: 0.317355
 >> iter 45000, loss: 0.334559
 >> iter 46000, loss: 0.216247
 >> iter 47000, loss: 0.173008
 >> iter 48000, loss: 0.098793
 >> iter 49000, loss: 0.293801
 >> iter 50000, loss: 0.316353
   Number of active neurons: 4
 >> iter 51000, loss: 0.223653
 >> iter 52000, loss: 0.244722
 >> iter 53000, loss: 0.240301
 >> iter 54000, loss: 0.211595
 >> iter 55000, loss: 0.124682
 >> iter 56000, loss: 0.206093
 >> iter 57000, loss: 0.356474
 >> iter 58000, loss: 0.198678
 >> iter 59000, loss: 0.244785
 >> iter 60000, loss: 0.169944
   Number of active neurons: 3
 >> iter 61000, loss: 0.268521
 >> iter 62000, loss: 0.383577
 >> iter 63000, loss: 0.270603
 >> iter 64000, loss: 0.149725
 >> iter 65000, loss: 0.445776
 >> iter 66000, loss: 0.349775
 >> iter 67000, loss: 0.329780
 >> iter 68000, loss: 0.218563
 >> iter 69000, loss: 0.226815
 >> iter 70000, loss: 0.241384
   Number of active neurons: 3
 >> iter 71000, loss: 0.187641
 >> iter 72000, loss: 0.104795
 >> iter 73000, loss: 0.268100
 >> iter 74000, loss: 0.270741
 >> iter 75000, loss: 0.260583
 >> iter 76000, loss: 0.233250
 >> iter 77000, loss: 0.148603
 >> iter 78000, loss: 0.130990
 >> iter 79000, loss: 0.167700
 >> iter 80000, loss: 0.314561
   Number of active neurons: 3
 >> iter 81000, loss: 0.363073
 >> iter 82000, loss: 0.303754
 >> iter 83000, loss: 0.209170
 >> iter 84000, loss: 0.285473
 >> iter 85000, loss: 0.157981
 >> iter 86000, loss: 0.281853
 >> iter 87000, loss: 0.227130
 >> iter 88000, loss: 0.136250
 >> iter 89000, loss: 0.140373
 >> iter 90000, loss: 0.142311
   Number of active neurons: 3
 >> iter 91000, loss: 0.270706
 >> iter 92000, loss: 0.172498
 >> iter 93000, loss: 0.148418
 >> iter 94000, loss: 0.219385
 >> iter 95000, loss: 0.179910
 >> iter 96000, loss: 0.155875
 >> iter 97000, loss: 0.221043
 >> iter 98000, loss: 0.291953
 >> iter 99000, loss: 0.244671
 >> iter 100000, loss: 0.354916
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.180023
 >> iter 2000, loss: 10.653555
 >> iter 3000, loss: 4.950303
 >> iter 4000, loss: 2.412075
 >> iter 5000, loss: 1.099075
 >> iter 6000, loss: 0.640874
 >> iter 7000, loss: 0.336894
 >> iter 8000, loss: 0.258379
 >> iter 9000, loss: 0.214213
 >> iter 10000, loss: 0.389427
   Number of active neurons: 3
 >> iter 11000, loss: 0.276110
 >> iter 12000, loss: 0.473133
 >> iter 13000, loss: 0.292023
 >> iter 14000, loss: 0.194170
 >> iter 15000, loss: 0.164537
 >> iter 16000, loss: 0.233606
 >> iter 17000, loss: 0.292548
 >> iter 18000, loss: 0.222888
 >> iter 19000, loss: 0.201738
 >> iter 20000, loss: 0.200790
   Number of active neurons: 3
 >> iter 21000, loss: 0.299449
 >> iter 22000, loss: 0.253947
 >> iter 23000, loss: 0.274612
 >> iter 24000, loss: 0.243375
 >> iter 25000, loss: 0.388171
 >> iter 26000, loss: 0.336648
 >> iter 27000, loss: 0.275887
 >> iter 28000, loss: 0.343969
 >> iter 29000, loss: 0.169997
 >> iter 30000, loss: 0.149355
   Number of active neurons: 3
 >> iter 31000, loss: 0.386236
 >> iter 32000, loss: 0.192214
 >> iter 33000, loss: 0.314591
 >> iter 34000, loss: 0.338766
 >> iter 35000, loss: 0.243099
 >> iter 36000, loss: 0.354702
 >> iter 37000, loss: 0.418789
 >> iter 38000, loss: 0.359062
 >> iter 39000, loss: 0.384973
 >> iter 40000, loss: 0.347022
   Number of active neurons: 3
 >> iter 41000, loss: 0.343010
 >> iter 42000, loss: 0.210501
 >> iter 43000, loss: 0.235754
 >> iter 44000, loss: 0.492658
 >> iter 45000, loss: 0.316643
 >> iter 46000, loss: 0.267730
 >> iter 47000, loss: 0.155674
 >> iter 48000, loss: 0.146471
 >> iter 49000, loss: 0.147994
 >> iter 50000, loss: 0.197294
   Number of active neurons: 3
 >> iter 51000, loss: 0.285543
 >> iter 52000, loss: 0.254706
 >> iter 53000, loss: 0.252804
 >> iter 54000, loss: 0.147711
 >> iter 55000, loss: 0.120870
 >> iter 56000, loss: 0.114787
 >> iter 57000, loss: 0.277073
 >> iter 58000, loss: 0.199381
 >> iter 59000, loss: 0.241311
 >> iter 60000, loss: 0.185951
   Number of active neurons: 3
 >> iter 61000, loss: 0.194392
 >> iter 62000, loss: 0.254525
 >> iter 63000, loss: 0.433130
 >> iter 64000, loss: 0.324785
 >> iter 65000, loss: 0.293006
 >> iter 66000, loss: 0.414501
 >> iter 67000, loss: 0.408952
 >> iter 68000, loss: 0.264050
 >> iter 69000, loss: 0.140284
 >> iter 70000, loss: 0.204696
   Number of active neurons: 3
 >> iter 71000, loss: 0.238730
 >> iter 72000, loss: 0.252199
 >> iter 73000, loss: 0.211543
 >> iter 74000, loss: 0.217172
 >> iter 75000, loss: 0.262822
 >> iter 76000, loss: 0.319751
 >> iter 77000, loss: 0.159686
 >> iter 78000, loss: 0.204388
 >> iter 79000, loss: 0.270208
 >> iter 80000, loss: 0.187091
   Number of active neurons: 3
 >> iter 81000, loss: 0.236526
 >> iter 82000, loss: 0.250421
 >> iter 83000, loss: 0.207679
 >> iter 84000, loss: 0.199810
 >> iter 85000, loss: 0.236953
 >> iter 86000, loss: 0.340625
 >> iter 87000, loss: 0.214931
 >> iter 88000, loss: 0.240980
 >> iter 89000, loss: 0.168871
 >> iter 90000, loss: 0.238808
   Number of active neurons: 3
 >> iter 91000, loss: 0.176080
 >> iter 92000, loss: 0.302724
 >> iter 93000, loss: 0.281929
 >> iter 94000, loss: 0.261274
 >> iter 95000, loss: 0.411365
 >> iter 96000, loss: 0.365383
 >> iter 97000, loss: 0.203596
 >> iter 98000, loss: 0.114709
 >> iter 99000, loss: 0.375766
 >> iter 100000, loss: 0.349137
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524757
 >> iter 2000, loss: 18.054282
 >> iter 3000, loss: 17.068462
 >> iter 4000, loss: 16.779370
 >> iter 5000, loss: 16.602171
 >> iter 6000, loss: 16.598199
 >> iter 7000, loss: 16.539951
 >> iter 8000, loss: 16.020785
 >> iter 9000, loss: 10.636571
 >> iter 10000, loss: 6.039173
   Number of active neurons: 4
 >> iter 11000, loss: 2.981145
 >> iter 12000, loss: 1.924377
 >> iter 13000, loss: 1.324629
 >> iter 14000, loss: 0.776410
 >> iter 15000, loss: 0.605186
 >> iter 16000, loss: 0.580845
 >> iter 17000, loss: 0.652423
 >> iter 18000, loss: 0.845788
 >> iter 19000, loss: 0.576715
 >> iter 20000, loss: 0.596316
   Number of active neurons: 4
 >> iter 21000, loss: 0.597935
 >> iter 22000, loss: 0.774497
 >> iter 23000, loss: 0.731145
 >> iter 24000, loss: 0.501443
 >> iter 25000, loss: 0.403390
 >> iter 26000, loss: 0.423484
 >> iter 27000, loss: 0.584015
 >> iter 28000, loss: 0.449480
 >> iter 29000, loss: 0.400222
 >> iter 30000, loss: 0.497757
   Number of active neurons: 4
 >> iter 31000, loss: 0.553050
 >> iter 32000, loss: 0.544246
 >> iter 33000, loss: 0.502123
 >> iter 34000, loss: 0.515369
 >> iter 35000, loss: 0.426103
 >> iter 36000, loss: 0.418343
 >> iter 37000, loss: 0.511075
 >> iter 38000, loss: 0.378083
 >> iter 39000, loss: 0.471788
 >> iter 40000, loss: 0.488160
   Number of active neurons: 4
 >> iter 41000, loss: 0.447609
 >> iter 42000, loss: 0.304722
 >> iter 43000, loss: 0.801531
 >> iter 44000, loss: 0.815583
 >> iter 45000, loss: 0.513074
 >> iter 46000, loss: 0.384450
 >> iter 47000, loss: 0.778632
 >> iter 48000, loss: 0.577877
 >> iter 49000, loss: 0.585654
 >> iter 50000, loss: 0.573591
   Number of active neurons: 4
 >> iter 51000, loss: 0.386180
 >> iter 52000, loss: 0.378454
 >> iter 53000, loss: 0.294541
 >> iter 54000, loss: 0.561825
 >> iter 55000, loss: 0.374251
 >> iter 56000, loss: 0.416510
 >> iter 57000, loss: 0.380741
 >> iter 58000, loss: 0.483975
 >> iter 59000, loss: 0.414494
 >> iter 60000, loss: 0.478283
   Number of active neurons: 4
 >> iter 61000, loss: 0.495448
 >> iter 62000, loss: 0.468312
 >> iter 63000, loss: 0.354933
 >> iter 64000, loss: 0.467513
 >> iter 65000, loss: 0.448986
 >> iter 66000, loss: 0.406944
 >> iter 67000, loss: 0.204212
 >> iter 68000, loss: 0.345059
 >> iter 69000, loss: 0.522423
 >> iter 70000, loss: 0.329465
   Number of active neurons: 4
 >> iter 71000, loss: 0.325638
 >> iter 72000, loss: 0.373354
 >> iter 73000, loss: 0.292122
 >> iter 74000, loss: 0.380328
 >> iter 75000, loss: 0.317272
 >> iter 76000, loss: 0.282529
 >> iter 77000, loss: 0.290272
 >> iter 78000, loss: 0.307657
 >> iter 79000, loss: 0.270536
 >> iter 80000, loss: 0.415777
   Number of active neurons: 4
 >> iter 81000, loss: 0.285547
 >> iter 82000, loss: 0.461458
 >> iter 83000, loss: 0.473420
 >> iter 84000, loss: 0.389094
 >> iter 85000, loss: 0.337578
 >> iter 86000, loss: 0.431836
 >> iter 87000, loss: 0.478779
 >> iter 88000, loss: 0.476141
 >> iter 89000, loss: 0.365628
 >> iter 90000, loss: 0.473172
   Number of active neurons: 3
 >> iter 91000, loss: 0.289609
 >> iter 92000, loss: 0.256962
 >> iter 93000, loss: 0.396441
 >> iter 94000, loss: 0.334091
 >> iter 95000, loss: 0.194938
 >> iter 96000, loss: 0.310616
 >> iter 97000, loss: 0.318035
 >> iter 98000, loss: 0.341268
 >> iter 99000, loss: 0.400364
 >> iter 100000, loss: 0.513348
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.058236
 >> iter 2000, loss: 11.035930
 >> iter 3000, loss: 4.949241
 >> iter 4000, loss: 2.090040
 >> iter 5000, loss: 1.092089
 >> iter 6000, loss: 0.606648
 >> iter 7000, loss: 0.613170
 >> iter 8000, loss: 0.531884
 >> iter 9000, loss: 0.597729
 >> iter 10000, loss: 0.452828
   Number of active neurons: 4
 >> iter 11000, loss: 0.341567
 >> iter 12000, loss: 0.433369
 >> iter 13000, loss: 0.378847
 >> iter 14000, loss: 0.334485
 >> iter 15000, loss: 0.477871
 >> iter 16000, loss: 0.325863
 >> iter 17000, loss: 0.394645
 >> iter 18000, loss: 0.372077
 >> iter 19000, loss: 0.701380
 >> iter 20000, loss: 0.461305
   Number of active neurons: 4
 >> iter 21000, loss: 0.410197
 >> iter 22000, loss: 0.505205
 >> iter 23000, loss: 0.510909
 >> iter 24000, loss: 0.380320
 >> iter 25000, loss: 0.315952
 >> iter 26000, loss: 0.208210
 >> iter 27000, loss: 0.264369
 >> iter 28000, loss: 0.513192
 >> iter 29000, loss: 0.335162
 >> iter 30000, loss: 0.241729
   Number of active neurons: 4
 >> iter 31000, loss: 0.375442
 >> iter 32000, loss: 0.409007
 >> iter 33000, loss: 0.354143
 >> iter 34000, loss: 0.219324
 >> iter 35000, loss: 0.179991
 >> iter 36000, loss: 0.267283
 >> iter 37000, loss: 0.312127
 >> iter 38000, loss: 0.217078
 >> iter 39000, loss: 0.189092
 >> iter 40000, loss: 0.177941
   Number of active neurons: 4
 >> iter 41000, loss: 0.235372
 >> iter 42000, loss: 0.268534
 >> iter 43000, loss: 0.269806
 >> iter 44000, loss: 0.228521
 >> iter 45000, loss: 0.222684
 >> iter 46000, loss: 0.115584
 >> iter 47000, loss: 0.502092
 >> iter 48000, loss: 0.442286
 >> iter 49000, loss: 0.285578
 >> iter 50000, loss: 0.293399
   Number of active neurons: 4
 >> iter 51000, loss: 0.211818
 >> iter 52000, loss: 0.274300
 >> iter 53000, loss: 0.332116
 >> iter 54000, loss: 0.158005
 >> iter 55000, loss: 0.132497
 >> iter 56000, loss: 0.123577
 >> iter 57000, loss: 0.168625
 >> iter 58000, loss: 0.246346
 >> iter 59000, loss: 0.311964
 >> iter 60000, loss: 0.347247
   Number of active neurons: 4
 >> iter 61000, loss: 0.209243
 >> iter 62000, loss: 0.250342
 >> iter 63000, loss: 0.143413
 >> iter 64000, loss: 0.128443
 >> iter 65000, loss: 0.272752
 >> iter 66000, loss: 0.248503
 >> iter 67000, loss: 0.261349
 >> iter 68000, loss: 0.281609
 >> iter 69000, loss: 0.387177
 >> iter 70000, loss: 0.284541
   Number of active neurons: 3
 >> iter 71000, loss: 0.423608
 >> iter 72000, loss: 0.302970
 >> iter 73000, loss: 0.168912
 >> iter 74000, loss: 0.323253
 >> iter 75000, loss: 0.421348
 >> iter 76000, loss: 0.299300
 >> iter 77000, loss: 0.364533
 >> iter 78000, loss: 0.263781
 >> iter 79000, loss: 0.169299
 >> iter 80000, loss: 0.134852
   Number of active neurons: 3
 >> iter 81000, loss: 0.163495
 >> iter 82000, loss: 0.342199
 >> iter 83000, loss: 0.332959
 >> iter 84000, loss: 0.186866
 >> iter 85000, loss: 0.102401
 >> iter 86000, loss: 0.169864
 >> iter 87000, loss: 0.177996
 >> iter 88000, loss: 0.179749
 >> iter 89000, loss: 0.193067
 >> iter 90000, loss: 0.156583
   Number of active neurons: 3
 >> iter 91000, loss: 0.217245
 >> iter 92000, loss: 0.141886
 >> iter 93000, loss: 0.111053
 >> iter 94000, loss: 0.156935
 >> iter 95000, loss: 0.210044
 >> iter 96000, loss: 0.333386
 >> iter 97000, loss: 0.161850
 >> iter 98000, loss: 0.099732
 >> iter 99000, loss: 0.158940
 >> iter 100000, loss: 0.134218
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524761
 >> iter 2000, loss: 17.195086
 >> iter 3000, loss: 10.842012
 >> iter 4000, loss: 5.484618
 >> iter 5000, loss: 2.542107
 >> iter 6000, loss: 1.332942
 >> iter 7000, loss: 0.872184
 >> iter 8000, loss: 0.561537
 >> iter 9000, loss: 0.473682
 >> iter 10000, loss: 0.390099
   Number of active neurons: 3
 >> iter 11000, loss: 0.405404
 >> iter 12000, loss: 0.310305
 >> iter 13000, loss: 0.243846
 >> iter 14000, loss: 0.253889
 >> iter 15000, loss: 0.315834
 >> iter 16000, loss: 0.269583
 >> iter 17000, loss: 0.305539
 >> iter 18000, loss: 0.306469
 >> iter 19000, loss: 0.373358
 >> iter 20000, loss: 0.206525
   Number of active neurons: 3
 >> iter 21000, loss: 0.302155
 >> iter 22000, loss: 0.142425
 >> iter 23000, loss: 0.284318
 >> iter 24000, loss: 0.349018
 >> iter 25000, loss: 0.204439
 >> iter 26000, loss: 0.259013
 >> iter 27000, loss: 0.160904
 >> iter 28000, loss: 0.307663
 >> iter 29000, loss: 0.273693
 >> iter 30000, loss: 0.406398
   Number of active neurons: 3
 >> iter 31000, loss: 0.333158
 >> iter 32000, loss: 0.194238
 >> iter 33000, loss: 0.218036
 >> iter 34000, loss: 0.252852
 >> iter 35000, loss: 0.341402
 >> iter 36000, loss: 0.401903
 >> iter 37000, loss: 0.351818
 >> iter 38000, loss: 0.475787
 >> iter 39000, loss: 0.312751
 >> iter 40000, loss: 0.208570
   Number of active neurons: 3
 >> iter 41000, loss: 0.537902
 >> iter 42000, loss: 0.559617
 >> iter 43000, loss: 0.332316
 >> iter 44000, loss: 0.217101
 >> iter 45000, loss: 0.171021
 >> iter 46000, loss: 0.197190
 >> iter 47000, loss: 0.263251
 >> iter 48000, loss: 0.241146
 >> iter 49000, loss: 0.156333
 >> iter 50000, loss: 0.125632
   Number of active neurons: 3
 >> iter 51000, loss: 0.293599
 >> iter 52000, loss: 0.225852
 >> iter 53000, loss: 0.216751
 >> iter 54000, loss: 0.228596
 >> iter 55000, loss: 0.138255
 >> iter 56000, loss: 0.145606
 >> iter 57000, loss: 0.307623
 >> iter 58000, loss: 0.219353
 >> iter 59000, loss: 0.340856
 >> iter 60000, loss: 0.352872
   Number of active neurons: 3
 >> iter 61000, loss: 0.269148
 >> iter 62000, loss: 0.354643
 >> iter 63000, loss: 0.174239
 >> iter 64000, loss: 0.377746
 >> iter 65000, loss: 0.377636
 >> iter 66000, loss: 0.352977
 >> iter 67000, loss: 0.315496
 >> iter 68000, loss: 0.432021
 >> iter 69000, loss: 0.308690
 >> iter 70000, loss: 0.239906
   Number of active neurons: 3
 >> iter 71000, loss: 0.210436
 >> iter 72000, loss: 0.292065
 >> iter 73000, loss: 0.160795
 >> iter 74000, loss: 0.127719
 >> iter 75000, loss: 0.350819
 >> iter 76000, loss: 0.236612
 >> iter 77000, loss: 0.442679
 >> iter 78000, loss: 0.358832
 >> iter 79000, loss: 0.219664
 >> iter 80000, loss: 0.250405
   Number of active neurons: 3
 >> iter 81000, loss: 0.377608
 >> iter 82000, loss: 0.409129
 >> iter 83000, loss: 0.251174
 >> iter 84000, loss: 0.134499
 >> iter 85000, loss: 0.270280
 >> iter 86000, loss: 0.203338
 >> iter 87000, loss: 0.273193
 >> iter 88000, loss: 0.258122
 >> iter 89000, loss: 0.310080
 >> iter 90000, loss: 0.347279
   Number of active neurons: 3
 >> iter 91000, loss: 0.229755
 >> iter 92000, loss: 0.309137
 >> iter 93000, loss: 0.330048
 >> iter 94000, loss: 0.232336
 >> iter 95000, loss: 0.223383
 >> iter 96000, loss: 0.116880
 >> iter 97000, loss: 0.124547
 >> iter 98000, loss: 0.234370
 >> iter 99000, loss: 0.262915
 >> iter 100000, loss: 0.274161
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.444425
 >> iter 2000, loss: 11.708676
 >> iter 3000, loss: 5.955164
 >> iter 4000, loss: 2.907827
 >> iter 5000, loss: 1.537772
 >> iter 6000, loss: 1.065173
 >> iter 7000, loss: 0.984577
 >> iter 8000, loss: 0.800803
 >> iter 9000, loss: 0.633855
 >> iter 10000, loss: 0.780307
   Number of active neurons: 4
 >> iter 11000, loss: 0.527177
 >> iter 12000, loss: 0.533841
 >> iter 13000, loss: 0.364415
 >> iter 14000, loss: 0.419541
 >> iter 15000, loss: 0.592328
 >> iter 16000, loss: 0.590110
 >> iter 17000, loss: 0.487922
 >> iter 18000, loss: 0.500937
 >> iter 19000, loss: 0.412406
 >> iter 20000, loss: 0.292643
   Number of active neurons: 4
 >> iter 21000, loss: 0.589551
 >> iter 22000, loss: 0.467191
 >> iter 23000, loss: 0.410870
 >> iter 24000, loss: 0.347903
 >> iter 25000, loss: 0.451080
 >> iter 26000, loss: 0.584791
 >> iter 27000, loss: 0.583218
 >> iter 28000, loss: 0.480391
 >> iter 29000, loss: 0.530215
 >> iter 30000, loss: 0.438776
   Number of active neurons: 4
 >> iter 31000, loss: 0.517717
 >> iter 32000, loss: 0.668667
 >> iter 33000, loss: 0.528963
 >> iter 34000, loss: 0.611643
 >> iter 35000, loss: 0.576368
 >> iter 36000, loss: 0.466251
 >> iter 37000, loss: 0.390631
 >> iter 38000, loss: 0.619499
 >> iter 39000, loss: 0.338106
 >> iter 40000, loss: 0.425848
   Number of active neurons: 4
 >> iter 41000, loss: 0.675420
 >> iter 42000, loss: 0.500905
 >> iter 43000, loss: 0.465454
 >> iter 44000, loss: 0.780292
 >> iter 45000, loss: 0.552652
 >> iter 46000, loss: 0.742153
 >> iter 47000, loss: 0.556018
 >> iter 48000, loss: 0.635645
 >> iter 49000, loss: 0.513640
 >> iter 50000, loss: 0.646186
   Number of active neurons: 3
 >> iter 51000, loss: 0.501477
 >> iter 52000, loss: 0.590141
 >> iter 53000, loss: 0.589659
 >> iter 54000, loss: 0.521370
 >> iter 55000, loss: 0.549710
 >> iter 56000, loss: 0.356754
 >> iter 57000, loss: 0.460484
 >> iter 58000, loss: 0.380040
 >> iter 59000, loss: 0.424874
 >> iter 60000, loss: 0.472299
   Number of active neurons: 3
 >> iter 61000, loss: 0.562885
 >> iter 62000, loss: 0.675261
 >> iter 63000, loss: 0.520448
 >> iter 64000, loss: 0.317663
 >> iter 65000, loss: 0.663300
 >> iter 66000, loss: 0.504986
 >> iter 67000, loss: 0.478644
 >> iter 68000, loss: 0.513208
 >> iter 69000, loss: 0.434426
 >> iter 70000, loss: 0.556164
   Number of active neurons: 4
 >> iter 71000, loss: 0.422300
 >> iter 72000, loss: 0.540785
 >> iter 73000, loss: 0.656277
 >> iter 74000, loss: 0.642520
 >> iter 75000, loss: 0.587764
 >> iter 76000, loss: 0.780620
 >> iter 77000, loss: 0.564530
 >> iter 78000, loss: 0.439470
 >> iter 79000, loss: 0.511408
 >> iter 80000, loss: 0.565173
   Number of active neurons: 4
 >> iter 81000, loss: 0.384295
 >> iter 82000, loss: 0.384370
 >> iter 83000, loss: 0.246500
 >> iter 84000, loss: 0.486695
 >> iter 85000, loss: 0.538105
 >> iter 86000, loss: 0.325273
 >> iter 87000, loss: 0.695378
 >> iter 88000, loss: 0.653006
 >> iter 89000, loss: 0.607527
 >> iter 90000, loss: 0.759667
   Number of active neurons: 4
 >> iter 91000, loss: 0.594106
 >> iter 92000, loss: 0.484975
 >> iter 93000, loss: 0.741548
 >> iter 94000, loss: 0.566622
 >> iter 95000, loss: 0.420129
 >> iter 96000, loss: 0.469839
 >> iter 97000, loss: 0.512386
 >> iter 98000, loss: 0.481697
 >> iter 99000, loss: 0.525667
 >> iter 100000, loss: 0.581054
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.699308
 >> iter 2000, loss: 8.973121
 >> iter 3000, loss: 4.127049
 >> iter 4000, loss: 2.070457
 >> iter 5000, loss: 0.998792
 >> iter 6000, loss: 0.519002
 >> iter 7000, loss: 0.348174
 >> iter 8000, loss: 0.495196
 >> iter 9000, loss: 0.537932
 >> iter 10000, loss: 0.473341
   Number of active neurons: 4
 >> iter 11000, loss: 0.538266
 >> iter 12000, loss: 0.324721
 >> iter 13000, loss: 0.467198
 >> iter 14000, loss: 0.490363
 >> iter 15000, loss: 0.468416
 >> iter 16000, loss: 0.387005
 >> iter 17000, loss: 0.328492
 >> iter 18000, loss: 0.408724
 >> iter 19000, loss: 0.321704
 >> iter 20000, loss: 0.462848
   Number of active neurons: 4
 >> iter 21000, loss: 0.262053
 >> iter 22000, loss: 0.168888
 >> iter 23000, loss: 0.287898
 >> iter 24000, loss: 0.416398
 >> iter 25000, loss: 0.394753
 >> iter 26000, loss: 0.396127
 >> iter 27000, loss: 0.282432
 >> iter 28000, loss: 0.310711
 >> iter 29000, loss: 0.183869
 >> iter 30000, loss: 0.289426
   Number of active neurons: 4
 >> iter 31000, loss: 0.303760
 >> iter 32000, loss: 0.276115
 >> iter 33000, loss: 0.283050
 >> iter 34000, loss: 0.253623
 >> iter 35000, loss: 0.290657
 >> iter 36000, loss: 0.233396
 >> iter 37000, loss: 0.230725
 >> iter 38000, loss: 0.298970
 >> iter 39000, loss: 0.444690
 >> iter 40000, loss: 0.391644
   Number of active neurons: 4
 >> iter 41000, loss: 0.374188
 >> iter 42000, loss: 0.208507
 >> iter 43000, loss: 0.155650
 >> iter 44000, loss: 0.417030
 >> iter 45000, loss: 0.328473
 >> iter 46000, loss: 0.346313
 >> iter 47000, loss: 0.338356
 >> iter 48000, loss: 0.187900
 >> iter 49000, loss: 0.167196
 >> iter 50000, loss: 0.244629
   Number of active neurons: 4
 >> iter 51000, loss: 0.393177
 >> iter 52000, loss: 0.250639
 >> iter 53000, loss: 0.354791
 >> iter 54000, loss: 0.381314
 >> iter 55000, loss: 0.308311
 >> iter 56000, loss: 0.401056
 >> iter 57000, loss: 0.250541
 >> iter 58000, loss: 0.436719
 >> iter 59000, loss: 0.535659
 >> iter 60000, loss: 0.275468
   Number of active neurons: 3
 >> iter 61000, loss: 0.160153
 >> iter 62000, loss: 0.224230
 >> iter 63000, loss: 0.159713
 >> iter 64000, loss: 0.159145
 >> iter 65000, loss: 0.295708
 >> iter 66000, loss: 0.298737
 >> iter 67000, loss: 0.295382
 >> iter 68000, loss: 0.328367
 >> iter 69000, loss: 0.197215
 >> iter 70000, loss: 0.339214
   Number of active neurons: 3
 >> iter 71000, loss: 0.415929
 >> iter 72000, loss: 0.274144
 >> iter 73000, loss: 0.393433
 >> iter 74000, loss: 0.447447
 >> iter 75000, loss: 0.542987
 >> iter 76000, loss: 0.291316
 >> iter 77000, loss: 0.171759
 >> iter 78000, loss: 0.174885
 >> iter 79000, loss: 0.319677
 >> iter 80000, loss: 0.248763
   Number of active neurons: 3
 >> iter 81000, loss: 0.220062
 >> iter 82000, loss: 0.351316
 >> iter 83000, loss: 0.334194
 >> iter 84000, loss: 0.371815
 >> iter 85000, loss: 0.434538
 >> iter 86000, loss: 0.224092
 >> iter 87000, loss: 0.404612
 >> iter 88000, loss: 0.257348
 >> iter 89000, loss: 0.225515
 >> iter 90000, loss: 0.216043
   Number of active neurons: 3
 >> iter 91000, loss: 0.298544
 >> iter 92000, loss: 0.183195
 >> iter 93000, loss: 0.342718
 >> iter 94000, loss: 0.243552
 >> iter 95000, loss: 0.177915
 >> iter 96000, loss: 0.207405
 >> iter 97000, loss: 0.372531
 >> iter 98000, loss: 0.256662
 >> iter 99000, loss: 0.280579
 >> iter 100000, loss: 0.190441
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.418635
 >> iter 2000, loss: 8.594085
 >> iter 3000, loss: 4.016447
 >> iter 4000, loss: 1.971029
 >> iter 5000, loss: 1.059062
 >> iter 6000, loss: 0.693109
 >> iter 7000, loss: 0.498432
 >> iter 8000, loss: 0.424932
 >> iter 9000, loss: 0.308490
 >> iter 10000, loss: 0.483611
   Number of active neurons: 3
 >> iter 11000, loss: 0.357294
 >> iter 12000, loss: 0.268884
 >> iter 13000, loss: 0.192333
 >> iter 14000, loss: 0.180392
 >> iter 15000, loss: 0.154263
 >> iter 16000, loss: 0.399291
 >> iter 17000, loss: 0.394227
 >> iter 18000, loss: 0.370409
 >> iter 19000, loss: 0.459017
 >> iter 20000, loss: 0.378362
   Number of active neurons: 3
 >> iter 21000, loss: 0.266707
 >> iter 22000, loss: 0.259262
 >> iter 23000, loss: 0.219411
 >> iter 24000, loss: 0.418361
 >> iter 25000, loss: 0.519820
 >> iter 26000, loss: 0.273202
 >> iter 27000, loss: 0.343790
 >> iter 28000, loss: 0.315886
 >> iter 29000, loss: 0.259198
 >> iter 30000, loss: 0.386277
   Number of active neurons: 3
 >> iter 31000, loss: 0.186926
 >> iter 32000, loss: 0.121139
 >> iter 33000, loss: 0.304785
 >> iter 34000, loss: 0.322268
 >> iter 35000, loss: 0.287878
 >> iter 36000, loss: 0.267087
 >> iter 37000, loss: 0.327581
 >> iter 38000, loss: 0.292763
 >> iter 39000, loss: 0.320357
 >> iter 40000, loss: 0.305923
   Number of active neurons: 3
 >> iter 41000, loss: 0.315113
 >> iter 42000, loss: 0.347547
 >> iter 43000, loss: 0.207476
 >> iter 44000, loss: 0.186558
 >> iter 45000, loss: 0.211336
 >> iter 46000, loss: 0.261407
 >> iter 47000, loss: 0.325812
 >> iter 48000, loss: 0.222827
 >> iter 49000, loss: 0.212132
 >> iter 50000, loss: 0.247633
   Number of active neurons: 3
 >> iter 51000, loss: 0.129667
 >> iter 52000, loss: 0.154239
 >> iter 53000, loss: 0.198114
 >> iter 54000, loss: 0.277958
 >> iter 55000, loss: 0.151015
 >> iter 56000, loss: 0.408895
 >> iter 57000, loss: 0.284679
 >> iter 58000, loss: 0.428064
 >> iter 59000, loss: 0.378620
 >> iter 60000, loss: 0.316640
   Number of active neurons: 3
 >> iter 61000, loss: 0.277731
 >> iter 62000, loss: 0.253020
 >> iter 63000, loss: 0.321098
 >> iter 64000, loss: 0.374006
 >> iter 65000, loss: 0.204604
 >> iter 66000, loss: 0.201428
 >> iter 67000, loss: 0.227354
 >> iter 68000, loss: 0.130594
 >> iter 69000, loss: 0.108567
 >> iter 70000, loss: 0.193533
   Number of active neurons: 3
 >> iter 71000, loss: 0.363156
 >> iter 72000, loss: 0.469129
 >> iter 73000, loss: 0.282125
 >> iter 74000, loss: 0.248711
 >> iter 75000, loss: 0.136571
 >> iter 76000, loss: 0.358537
 >> iter 77000, loss: 0.227607
 >> iter 78000, loss: 0.288326
 >> iter 79000, loss: 0.215497
 >> iter 80000, loss: 0.282505
   Number of active neurons: 3
 >> iter 81000, loss: 0.232167
 >> iter 82000, loss: 0.443496
 >> iter 83000, loss: 0.264058
 >> iter 84000, loss: 0.214154
 >> iter 85000, loss: 0.110703
 >> iter 86000, loss: 0.118856
 >> iter 87000, loss: 0.126665
 >> iter 88000, loss: 0.218161
 >> iter 89000, loss: 0.209955
 >> iter 90000, loss: 0.292453
   Number of active neurons: 3
 >> iter 91000, loss: 0.354616
 >> iter 92000, loss: 0.306523
 >> iter 93000, loss: 0.242259
 >> iter 94000, loss: 0.185785
 >> iter 95000, loss: 0.254026
 >> iter 96000, loss: 0.196306
 >> iter 97000, loss: 0.183761
 >> iter 98000, loss: 0.193506
 >> iter 99000, loss: 0.258568
 >> iter 100000, loss: 0.215952
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

