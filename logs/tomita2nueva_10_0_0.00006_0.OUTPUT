 > Problema: tomita2nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 6e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.908878
 >> iter 2000, loss: 4.039923
 >> iter 3000, loss: 1.502030
 >> iter 4000, loss: 0.566390
 >> iter 5000, loss: 0.221375
 >> iter 6000, loss: 0.093624
 >> iter 7000, loss: 0.046565
 >> iter 8000, loss: 0.028774
 >> iter 9000, loss: 0.022371
 >> iter 10000, loss: 0.019474
   Number of active neurons: 8
 >> iter 11000, loss: 0.018533
 >> iter 12000, loss: 0.017633
 >> iter 13000, loss: 0.017474
 >> iter 14000, loss: 0.016822
 >> iter 15000, loss: 0.016938
 >> iter 16000, loss: 0.016329
 >> iter 17000, loss: 0.016522
 >> iter 18000, loss: 0.016083
 >> iter 19000, loss: 0.016352
 >> iter 20000, loss: 0.016008
   Number of active neurons: 8
 >> iter 21000, loss: 0.016285
 >> iter 22000, loss: 0.015969
 >> iter 23000, loss: 0.016240
 >> iter 24000, loss: 0.015934
 >> iter 25000, loss: 0.016217
 >> iter 26000, loss: 0.015908
 >> iter 27000, loss: 0.016186
 >> iter 28000, loss: 0.015870
 >> iter 29000, loss: 0.016136
 >> iter 30000, loss: 0.015831
   Number of active neurons: 7
 >> iter 31000, loss: 0.016084
 >> iter 32000, loss: 0.015765
 >> iter 33000, loss: 0.015997
 >> iter 34000, loss: 0.015698
 >> iter 35000, loss: 0.015854
 >> iter 36000, loss: 0.015504
 >> iter 37000, loss: 0.015623
 >> iter 38000, loss: 0.015305
 >> iter 39000, loss: 0.015437
 >> iter 40000, loss: 0.015180
   Number of active neurons: 7
 >> iter 41000, loss: 0.015294
 >> iter 42000, loss: 0.015032
 >> iter 43000, loss: 0.015143
 >> iter 44000, loss: 0.014916
 >> iter 45000, loss: 0.015045
 >> iter 46000, loss: 0.014837
 >> iter 47000, loss: 0.014982
 >> iter 48000, loss: 0.014756
 >> iter 49000, loss: 0.014863
 >> iter 50000, loss: 0.014649
   Number of active neurons: 6
 >> iter 51000, loss: 0.014758
 >> iter 52000, loss: 0.014580
 >> iter 53000, loss: 0.014655
 >> iter 54000, loss: 0.014466
 >> iter 55000, loss: 0.014491
 >> iter 56000, loss: 0.014287
 >> iter 57000, loss: 0.014299
 >> iter 58000, loss: 0.014101
 >> iter 59000, loss: 0.014124
 >> iter 60000, loss: 0.013954
   Number of active neurons: 6
 >> iter 61000, loss: 0.014001
 >> iter 62000, loss: 0.013818
 >> iter 63000, loss: 0.013851
 >> iter 64000, loss: 0.013677
 >> iter 65000, loss: 0.013701
 >> iter 66000, loss: 0.013559
 >> iter 67000, loss: 0.013610
 >> iter 68000, loss: 0.013504
 >> iter 69000, loss: 0.013557
 >> iter 70000, loss: 0.013462
   Number of active neurons: 6
 >> iter 71000, loss: 0.013501
 >> iter 72000, loss: 0.013413
 >> iter 73000, loss: 0.013478
 >> iter 74000, loss: 0.013389
 >> iter 75000, loss: 0.013451
 >> iter 76000, loss: 0.013371
 >> iter 77000, loss: 0.013430
 >> iter 78000, loss: 0.013344
 >> iter 79000, loss: 0.013400
 >> iter 80000, loss: 0.013303
   Number of active neurons: 5
 >> iter 81000, loss: 0.013330
 >> iter 82000, loss: 0.013178
 >> iter 83000, loss: 0.013176
 >> iter 84000, loss: 0.013036
 >> iter 85000, loss: 0.013035
 >> iter 86000, loss: 0.012887
 >> iter 87000, loss: 0.012856
 >> iter 88000, loss: 0.012724
 >> iter 89000, loss: 0.012696
 >> iter 90000, loss: 0.012569
   Number of active neurons: 5
 >> iter 91000, loss: 0.012537
 >> iter 92000, loss: 0.012416
 >> iter 93000, loss: 0.012372
 >> iter 94000, loss: 0.012240
 >> iter 95000, loss: 0.012214
 >> iter 96000, loss: 0.012106
 >> iter 97000, loss: 0.012113
 >> iter 98000, loss: 0.012029
 >> iter 99000, loss: 0.012058
 >> iter 100000, loss: 0.011995
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.847410
 >> iter 2000, loss: 4.013582
 >> iter 3000, loss: 1.491380
 >> iter 4000, loss: 0.560616
 >> iter 5000, loss: 0.217383
 >> iter 6000, loss: 0.090048
 >> iter 7000, loss: 0.042954
 >> iter 8000, loss: 0.024969
 >> iter 9000, loss: 0.018293
 >> iter 10000, loss: 0.015262
   Number of active neurons: 4
 >> iter 11000, loss: 0.014152
 >> iter 12000, loss: 0.013343
 >> iter 13000, loss: 0.013179
 >> iter 14000, loss: 0.012757
 >> iter 15000, loss: 0.012792
 >> iter 16000, loss: 0.012374
 >> iter 17000, loss: 0.012362
 >> iter 18000, loss: 0.011966
 >> iter 19000, loss: 0.012069
 >> iter 20000, loss: 0.011813
   Number of active neurons: 4
 >> iter 21000, loss: 0.011957
 >> iter 22000, loss: 0.011724
 >> iter 23000, loss: 0.011906
 >> iter 24000, loss: 0.011685
 >> iter 25000, loss: 0.011873
 >> iter 26000, loss: 0.011643
 >> iter 27000, loss: 0.011832
 >> iter 28000, loss: 0.011597
 >> iter 29000, loss: 0.011785
 >> iter 30000, loss: 0.011560
   Number of active neurons: 4
 >> iter 31000, loss: 0.011746
 >> iter 32000, loss: 0.011522
 >> iter 33000, loss: 0.011705
 >> iter 34000, loss: 0.011504
 >> iter 35000, loss: 0.011667
 >> iter 36000, loss: 0.011475
 >> iter 37000, loss: 0.011636
 >> iter 38000, loss: 0.011451
 >> iter 39000, loss: 0.011603
 >> iter 40000, loss: 0.011438
   Number of active neurons: 4
 >> iter 41000, loss: 0.011523
 >> iter 42000, loss: 0.011343
 >> iter 43000, loss: 0.011428
 >> iter 44000, loss: 0.011288
 >> iter 45000, loss: 0.011372
 >> iter 46000, loss: 0.011242
 >> iter 47000, loss: 0.011335
 >> iter 48000, loss: 0.011215
 >> iter 49000, loss: 0.011313
 >> iter 50000, loss: 0.011196
   Number of active neurons: 4
 >> iter 51000, loss: 0.011291
 >> iter 52000, loss: 0.011195
 >> iter 53000, loss: 0.011272
 >> iter 54000, loss: 0.011197
 >> iter 55000, loss: 0.011270
 >> iter 56000, loss: 0.011192
 >> iter 57000, loss: 0.011260
 >> iter 58000, loss: 0.011189
 >> iter 59000, loss: 0.011255
 >> iter 60000, loss: 0.011187
   Number of active neurons: 4
 >> iter 61000, loss: 0.011265
 >> iter 62000, loss: 0.011184
 >> iter 63000, loss: 0.011254
 >> iter 64000, loss: 0.011185
 >> iter 65000, loss: 0.011247
 >> iter 66000, loss: 0.011185
 >> iter 67000, loss: 0.011243
 >> iter 68000, loss: 0.011190
 >> iter 69000, loss: 0.011225
 >> iter 70000, loss: 0.011170
   Number of active neurons: 4
 >> iter 71000, loss: 0.011197
 >> iter 72000, loss: 0.011149
 >> iter 73000, loss: 0.011193
 >> iter 74000, loss: 0.011144
 >> iter 75000, loss: 0.011186
 >> iter 76000, loss: 0.011144
 >> iter 77000, loss: 0.011183
 >> iter 78000, loss: 0.011141
 >> iter 79000, loss: 0.011183
 >> iter 80000, loss: 0.011136
   Number of active neurons: 4
 >> iter 81000, loss: 0.011182
 >> iter 82000, loss: 0.011137
 >> iter 83000, loss: 0.011187
 >> iter 84000, loss: 0.011142
 >> iter 85000, loss: 0.011183
 >> iter 86000, loss: 0.011142
 >> iter 87000, loss: 0.011181
 >> iter 88000, loss: 0.011157
 >> iter 89000, loss: 0.011186
 >> iter 90000, loss: 0.011159
   Number of active neurons: 4
 >> iter 91000, loss: 0.011183
 >> iter 92000, loss: 0.011167
 >> iter 93000, loss: 0.011195
 >> iter 94000, loss: 0.011170
 >> iter 95000, loss: 0.011203
 >> iter 96000, loss: 0.011175
 >> iter 97000, loss: 0.011208
 >> iter 98000, loss: 0.011177
 >> iter 99000, loss: 0.011215
 >> iter 100000, loss: 0.011189
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.829203
 >> iter 2000, loss: 4.004947
 >> iter 3000, loss: 1.488024
 >> iter 4000, loss: 0.559984
 >> iter 5000, loss: 0.218061
 >> iter 6000, loss: 0.091317
 >> iter 7000, loss: 0.044623
 >> iter 8000, loss: 0.026733
 >> iter 9000, loss: 0.020229
 >> iter 10000, loss: 0.017418
   Number of active neurons: 6
 >> iter 11000, loss: 0.016645
 >> iter 12000, loss: 0.015943
 >> iter 13000, loss: 0.015917
 >> iter 14000, loss: 0.015498
 >> iter 15000, loss: 0.015634
 >> iter 16000, loss: 0.015176
 >> iter 17000, loss: 0.015301
 >> iter 18000, loss: 0.014931
 >> iter 19000, loss: 0.015133
 >> iter 20000, loss: 0.014836
   Number of active neurons: 6
 >> iter 21000, loss: 0.015063
 >> iter 22000, loss: 0.014823
 >> iter 23000, loss: 0.015067
 >> iter 24000, loss: 0.014826
 >> iter 25000, loss: 0.015080
 >> iter 26000, loss: 0.014835
 >> iter 27000, loss: 0.015089
 >> iter 28000, loss: 0.014833
 >> iter 29000, loss: 0.015078
 >> iter 30000, loss: 0.014830
   Number of active neurons: 5
 >> iter 31000, loss: 0.015065
 >> iter 32000, loss: 0.014807
 >> iter 33000, loss: 0.015026
 >> iter 34000, loss: 0.014785
 >> iter 35000, loss: 0.014964
 >> iter 36000, loss: 0.014721
 >> iter 37000, loss: 0.014877
 >> iter 38000, loss: 0.014605
 >> iter 39000, loss: 0.014677
 >> iter 40000, loss: 0.014366
   Number of active neurons: 4
 >> iter 41000, loss: 0.014341
 >> iter 42000, loss: 0.013950
 >> iter 43000, loss: 0.013885
 >> iter 44000, loss: 0.013545
 >> iter 45000, loss: 0.013479
 >> iter 46000, loss: 0.013163
 >> iter 47000, loss: 0.013118
 >> iter 48000, loss: 0.012812
 >> iter 49000, loss: 0.012769
 >> iter 50000, loss: 0.012470
   Number of active neurons: 4
 >> iter 51000, loss: 0.012441
 >> iter 52000, loss: 0.012194
 >> iter 53000, loss: 0.012192
 >> iter 54000, loss: 0.012016
 >> iter 55000, loss: 0.012050
 >> iter 56000, loss: 0.011907
 >> iter 57000, loss: 0.011957
 >> iter 58000, loss: 0.011840
 >> iter 59000, loss: 0.011904
 >> iter 60000, loss: 0.011800
   Number of active neurons: 4
 >> iter 61000, loss: 0.011878
 >> iter 62000, loss: 0.011753
 >> iter 63000, loss: 0.011820
 >> iter 64000, loss: 0.011717
 >> iter 65000, loss: 0.011784
 >> iter 66000, loss: 0.011697
 >> iter 67000, loss: 0.011768
 >> iter 68000, loss: 0.011697
 >> iter 69000, loss: 0.011757
 >> iter 70000, loss: 0.011695
   Number of active neurons: 4
 >> iter 71000, loss: 0.011753
 >> iter 72000, loss: 0.011696
 >> iter 73000, loss: 0.011770
 >> iter 74000, loss: 0.011707
 >> iter 75000, loss: 0.011776
 >> iter 76000, loss: 0.011720
 >> iter 77000, loss: 0.011786
 >> iter 78000, loss: 0.011728
 >> iter 79000, loss: 0.011797
 >> iter 80000, loss: 0.011735
   Number of active neurons: 4
 >> iter 81000, loss: 0.011809
 >> iter 82000, loss: 0.011748
 >> iter 83000, loss: 0.011823
 >> iter 84000, loss: 0.011766
 >> iter 85000, loss: 0.011832
 >> iter 86000, loss: 0.011778
 >> iter 87000, loss: 0.011844
 >> iter 88000, loss: 0.011804
 >> iter 89000, loss: 0.011863
 >> iter 90000, loss: 0.011818
   Number of active neurons: 4
 >> iter 91000, loss: 0.011873
 >> iter 92000, loss: 0.011838
 >> iter 93000, loss: 0.011893
 >> iter 94000, loss: 0.011852
 >> iter 95000, loss: 0.011912
 >> iter 96000, loss: 0.011864
 >> iter 97000, loss: 0.011924
 >> iter 98000, loss: 0.011872
 >> iter 99000, loss: 0.011931
 >> iter 100000, loss: 0.011882
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455179
   Number of active neurons: 0
 >> iter 1000, loss: 10.894191
 >> iter 2000, loss: 4.027440
 >> iter 3000, loss: 1.495622
 >> iter 4000, loss: 0.562113
 >> iter 5000, loss: 0.218278
 >> iter 6000, loss: 0.090982
 >> iter 7000, loss: 0.044238
 >> iter 8000, loss: 0.026594
 >> iter 9000, loss: 0.020368
 >> iter 10000, loss: 0.017754
   Number of active neurons: 6
 >> iter 11000, loss: 0.017107
 >> iter 12000, loss: 0.016483
 >> iter 13000, loss: 0.016498
 >> iter 14000, loss: 0.016148
 >> iter 15000, loss: 0.016364
 >> iter 16000, loss: 0.016030
 >> iter 17000, loss: 0.016279
 >> iter 18000, loss: 0.015967
 >> iter 19000, loss: 0.016218
 >> iter 20000, loss: 0.015912
   Number of active neurons: 5
 >> iter 21000, loss: 0.016133
 >> iter 22000, loss: 0.015814
 >> iter 23000, loss: 0.016010
 >> iter 24000, loss: 0.015669
 >> iter 25000, loss: 0.015826
 >> iter 26000, loss: 0.015400
 >> iter 27000, loss: 0.015494
 >> iter 28000, loss: 0.015071
 >> iter 29000, loss: 0.015163
 >> iter 30000, loss: 0.014730
   Number of active neurons: 3
 >> iter 31000, loss: 0.014751
 >> iter 32000, loss: 0.014238
 >> iter 33000, loss: 0.014180
 >> iter 34000, loss: 0.013701
 >> iter 35000, loss: 0.013653
 >> iter 36000, loss: 0.013247
 >> iter 37000, loss: 0.013238
 >> iter 38000, loss: 0.012866
 >> iter 39000, loss: 0.012845
 >> iter 40000, loss: 0.012499
   Number of active neurons: 3
 >> iter 41000, loss: 0.012441
 >> iter 42000, loss: 0.012099
 >> iter 43000, loss: 0.012068
 >> iter 44000, loss: 0.011824
 >> iter 45000, loss: 0.011840
 >> iter 46000, loss: 0.011645
 >> iter 47000, loss: 0.011695
 >> iter 48000, loss: 0.011531
 >> iter 49000, loss: 0.011601
 >> iter 50000, loss: 0.011452
   Number of active neurons: 3
 >> iter 51000, loss: 0.011526
 >> iter 52000, loss: 0.011405
 >> iter 53000, loss: 0.011467
 >> iter 54000, loss: 0.011372
 >> iter 55000, loss: 0.011433
 >> iter 56000, loss: 0.011340
 >> iter 57000, loss: 0.011397
 >> iter 58000, loss: 0.011314
 >> iter 59000, loss: 0.011372
 >> iter 60000, loss: 0.011293
   Number of active neurons: 3
 >> iter 61000, loss: 0.011365
 >> iter 62000, loss: 0.011275
 >> iter 63000, loss: 0.011339
 >> iter 64000, loss: 0.011263
 >> iter 65000, loss: 0.011320
 >> iter 66000, loss: 0.011249
 >> iter 67000, loss: 0.011292
 >> iter 68000, loss: 0.011227
 >> iter 69000, loss: 0.011257
 >> iter 70000, loss: 0.011203
   Number of active neurons: 3
 >> iter 71000, loss: 0.011232
 >> iter 72000, loss: 0.011186
 >> iter 73000, loss: 0.011230
 >> iter 74000, loss: 0.011181
 >> iter 75000, loss: 0.011221
 >> iter 76000, loss: 0.011178
 >> iter 77000, loss: 0.011215
 >> iter 78000, loss: 0.011171
 >> iter 79000, loss: 0.011211
 >> iter 80000, loss: 0.011162
   Number of active neurons: 3
 >> iter 81000, loss: 0.011206
 >> iter 82000, loss: 0.011158
 >> iter 83000, loss: 0.011206
 >> iter 84000, loss: 0.011159
 >> iter 85000, loss: 0.011197
 >> iter 86000, loss: 0.011155
 >> iter 87000, loss: 0.011192
 >> iter 88000, loss: 0.011167
 >> iter 89000, loss: 0.011192
 >> iter 90000, loss: 0.011164
   Number of active neurons: 3
 >> iter 91000, loss: 0.011186
 >> iter 92000, loss: 0.011169
 >> iter 93000, loss: 0.011195
 >> iter 94000, loss: 0.011169
 >> iter 95000, loss: 0.011199
 >> iter 96000, loss: 0.011171
 >> iter 97000, loss: 0.011200
 >> iter 98000, loss: 0.011170
 >> iter 99000, loss: 0.011204
 >> iter 100000, loss: 0.011178
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.862193
 >> iter 2000, loss: 4.017160
 >> iter 3000, loss: 1.492817
 >> iter 4000, loss: 0.562073
 >> iter 5000, loss: 0.219122
 >> iter 6000, loss: 0.092069
 >> iter 7000, loss: 0.045342
 >> iter 8000, loss: 0.027543
 >> iter 9000, loss: 0.021097
 >> iter 10000, loss: 0.018246
   Number of active neurons: 5
 >> iter 11000, loss: 0.017406
 >> iter 12000, loss: 0.016551
 >> iter 13000, loss: 0.016380
 >> iter 14000, loss: 0.015766
 >> iter 15000, loss: 0.015742
 >> iter 16000, loss: 0.015099
 >> iter 17000, loss: 0.015041
 >> iter 18000, loss: 0.014398
 >> iter 19000, loss: 0.014354
 >> iter 20000, loss: 0.013855
   Number of active neurons: 5
 >> iter 21000, loss: 0.013925
 >> iter 22000, loss: 0.013582
 >> iter 23000, loss: 0.013716
 >> iter 24000, loss: 0.013427
 >> iter 25000, loss: 0.013624
 >> iter 26000, loss: 0.013360
 >> iter 27000, loss: 0.013574
 >> iter 28000, loss: 0.013309
 >> iter 29000, loss: 0.013523
 >> iter 30000, loss: 0.013269
   Number of active neurons: 5
 >> iter 31000, loss: 0.013478
 >> iter 32000, loss: 0.013219
 >> iter 33000, loss: 0.013420
 >> iter 34000, loss: 0.013181
 >> iter 35000, loss: 0.013349
 >> iter 36000, loss: 0.013113
 >> iter 37000, loss: 0.013269
 >> iter 38000, loss: 0.013006
 >> iter 39000, loss: 0.013094
 >> iter 40000, loss: 0.012837
   Number of active neurons: 4
 >> iter 41000, loss: 0.012890
 >> iter 42000, loss: 0.012599
 >> iter 43000, loss: 0.012601
 >> iter 44000, loss: 0.012361
 >> iter 45000, loss: 0.012377
 >> iter 46000, loss: 0.012160
 >> iter 47000, loss: 0.012185
 >> iter 48000, loss: 0.011977
 >> iter 49000, loss: 0.011999
 >> iter 50000, loss: 0.011781
   Number of active neurons: 4
 >> iter 51000, loss: 0.011790
 >> iter 52000, loss: 0.011608
 >> iter 53000, loss: 0.011627
 >> iter 54000, loss: 0.011496
 >> iter 55000, loss: 0.011533
 >> iter 56000, loss: 0.011419
 >> iter 57000, loss: 0.011463
 >> iter 58000, loss: 0.011367
 >> iter 59000, loss: 0.011418
 >> iter 60000, loss: 0.011330
   Number of active neurons: 4
 >> iter 61000, loss: 0.011396
 >> iter 62000, loss: 0.011300
 >> iter 63000, loss: 0.011360
 >> iter 64000, loss: 0.011279
 >> iter 65000, loss: 0.011334
 >> iter 66000, loss: 0.011258
 >> iter 67000, loss: 0.011299
 >> iter 68000, loss: 0.011230
 >> iter 69000, loss: 0.011259
 >> iter 70000, loss: 0.011203
   Number of active neurons: 4
 >> iter 71000, loss: 0.011230
 >> iter 72000, loss: 0.011182
 >> iter 73000, loss: 0.011225
 >> iter 74000, loss: 0.011174
 >> iter 75000, loss: 0.011213
 >> iter 76000, loss: 0.011167
 >> iter 77000, loss: 0.011203
 >> iter 78000, loss: 0.011158
 >> iter 79000, loss: 0.011196
 >> iter 80000, loss: 0.011146
   Number of active neurons: 4
 >> iter 81000, loss: 0.011188
 >> iter 82000, loss: 0.011139
 >> iter 83000, loss: 0.011185
 >> iter 84000, loss: 0.011137
 >> iter 85000, loss: 0.011174
 >> iter 86000, loss: 0.011129
 >> iter 87000, loss: 0.011164
 >> iter 88000, loss: 0.011138
 >> iter 89000, loss: 0.011161
 >> iter 90000, loss: 0.011132
   Number of active neurons: 4
 >> iter 91000, loss: 0.011152
 >> iter 92000, loss: 0.011132
 >> iter 93000, loss: 0.011156
 >> iter 94000, loss: 0.011128
 >> iter 95000, loss: 0.011156
 >> iter 96000, loss: 0.011126
 >> iter 97000, loss: 0.011153
 >> iter 98000, loss: 0.011120
 >> iter 99000, loss: 0.011152
 >> iter 100000, loss: 0.011124
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.817207
 >> iter 2000, loss: 4.000999
 >> iter 3000, loss: 1.487031
 >> iter 4000, loss: 0.559882
 >> iter 5000, loss: 0.218344
 >> iter 6000, loss: 0.091812
 >> iter 7000, loss: 0.045362
 >> iter 8000, loss: 0.027646
 >> iter 9000, loss: 0.021269
 >> iter 10000, loss: 0.018511
   Number of active neurons: 7
 >> iter 11000, loss: 0.017797
 >> iter 12000, loss: 0.017197
 >> iter 13000, loss: 0.017299
 >> iter 14000, loss: 0.016984
 >> iter 15000, loss: 0.017269
 >> iter 16000, loss: 0.016854
 >> iter 17000, loss: 0.017122
 >> iter 18000, loss: 0.016703
 >> iter 19000, loss: 0.016938
 >> iter 20000, loss: 0.016485
   Number of active neurons: 5
 >> iter 21000, loss: 0.016640
 >> iter 22000, loss: 0.016124
 >> iter 23000, loss: 0.016169
 >> iter 24000, loss: 0.015649
 >> iter 25000, loss: 0.015696
 >> iter 26000, loss: 0.015235
 >> iter 27000, loss: 0.015324
 >> iter 28000, loss: 0.014881
 >> iter 29000, loss: 0.014920
 >> iter 30000, loss: 0.014496
   Number of active neurons: 5
 >> iter 31000, loss: 0.014567
 >> iter 32000, loss: 0.014194
 >> iter 33000, loss: 0.014309
 >> iter 34000, loss: 0.014008
 >> iter 35000, loss: 0.014114
 >> iter 36000, loss: 0.013827
 >> iter 37000, loss: 0.013925
 >> iter 38000, loss: 0.013660
 >> iter 39000, loss: 0.013774
 >> iter 40000, loss: 0.013567
   Number of active neurons: 4
 >> iter 41000, loss: 0.013652
 >> iter 42000, loss: 0.013422
 >> iter 43000, loss: 0.013497
 >> iter 44000, loss: 0.013301
 >> iter 45000, loss: 0.013366
 >> iter 46000, loss: 0.013157
 >> iter 47000, loss: 0.013191
 >> iter 48000, loss: 0.012955
 >> iter 49000, loss: 0.013003
 >> iter 50000, loss: 0.012782
   Number of active neurons: 4
 >> iter 51000, loss: 0.012814
 >> iter 52000, loss: 0.012600
 >> iter 53000, loss: 0.012618
 >> iter 54000, loss: 0.012440
 >> iter 55000, loss: 0.012457
 >> iter 56000, loss: 0.012281
 >> iter 57000, loss: 0.012285
 >> iter 58000, loss: 0.012107
 >> iter 59000, loss: 0.012103
 >> iter 60000, loss: 0.011940
   Number of active neurons: 4
 >> iter 61000, loss: 0.011975
 >> iter 62000, loss: 0.011826
 >> iter 63000, loss: 0.011866
 >> iter 64000, loss: 0.011739
 >> iter 65000, loss: 0.011785
 >> iter 66000, loss: 0.011683
 >> iter 67000, loss: 0.011740
 >> iter 68000, loss: 0.011659
 >> iter 69000, loss: 0.011709
 >> iter 70000, loss: 0.011642
   Number of active neurons: 4
 >> iter 71000, loss: 0.011691
 >> iter 72000, loss: 0.011631
 >> iter 73000, loss: 0.011699
 >> iter 74000, loss: 0.011634
 >> iter 75000, loss: 0.011697
 >> iter 76000, loss: 0.011639
 >> iter 77000, loss: 0.011700
 >> iter 78000, loss: 0.011641
 >> iter 79000, loss: 0.011705
 >> iter 80000, loss: 0.011642
   Number of active neurons: 4
 >> iter 81000, loss: 0.011711
 >> iter 82000, loss: 0.011650
 >> iter 83000, loss: 0.011721
 >> iter 84000, loss: 0.011664
 >> iter 85000, loss: 0.011726
 >> iter 86000, loss: 0.011673
 >> iter 87000, loss: 0.011735
 >> iter 88000, loss: 0.011697
 >> iter 89000, loss: 0.011752
 >> iter 90000, loss: 0.011709
   Number of active neurons: 4
 >> iter 91000, loss: 0.011762
 >> iter 92000, loss: 0.011730
 >> iter 93000, loss: 0.011783
 >> iter 94000, loss: 0.011747
 >> iter 95000, loss: 0.011806
 >> iter 96000, loss: 0.011764
 >> iter 97000, loss: 0.011824
 >> iter 98000, loss: 0.011780
 >> iter 99000, loss: 0.011842
 >> iter 100000, loss: 0.011803
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.845195
 >> iter 2000, loss: 4.010674
 >> iter 3000, loss: 1.489799
 >> iter 4000, loss: 0.559876
 >> iter 5000, loss: 0.217139
 >> iter 6000, loss: 0.090133
 >> iter 7000, loss: 0.043503
 >> iter 8000, loss: 0.025866
 >> iter 9000, loss: 0.019568
 >> iter 10000, loss: 0.016809
   Number of active neurons: 4
 >> iter 11000, loss: 0.015943
 >> iter 12000, loss: 0.015251
 >> iter 13000, loss: 0.015222
 >> iter 14000, loss: 0.014885
 >> iter 15000, loss: 0.015046
 >> iter 16000, loss: 0.014724
 >> iter 17000, loss: 0.014901
 >> iter 18000, loss: 0.014581
 >> iter 19000, loss: 0.014744
 >> iter 20000, loss: 0.014387
   Number of active neurons: 3
 >> iter 21000, loss: 0.014463
 >> iter 22000, loss: 0.014082
 >> iter 23000, loss: 0.014166
 >> iter 24000, loss: 0.013802
 >> iter 25000, loss: 0.013890
 >> iter 26000, loss: 0.013503
 >> iter 27000, loss: 0.013536
 >> iter 28000, loss: 0.013115
 >> iter 29000, loss: 0.013149
 >> iter 30000, loss: 0.012775
   Number of active neurons: 3
 >> iter 31000, loss: 0.012850
 >> iter 32000, loss: 0.012518
 >> iter 33000, loss: 0.012613
 >> iter 34000, loss: 0.012317
 >> iter 35000, loss: 0.012389
 >> iter 36000, loss: 0.012098
 >> iter 37000, loss: 0.012164
 >> iter 38000, loss: 0.011899
 >> iter 39000, loss: 0.011987
 >> iter 40000, loss: 0.011770
   Number of active neurons: 3
 >> iter 41000, loss: 0.011814
 >> iter 42000, loss: 0.011604
 >> iter 43000, loss: 0.011665
 >> iter 44000, loss: 0.011504
 >> iter 45000, loss: 0.011573
 >> iter 46000, loss: 0.011428
 >> iter 47000, loss: 0.011510
 >> iter 48000, loss: 0.011378
 >> iter 49000, loss: 0.011469
 >> iter 50000, loss: 0.011342
   Number of active neurons: 3
 >> iter 51000, loss: 0.011432
 >> iter 52000, loss: 0.011329
 >> iter 53000, loss: 0.011403
 >> iter 54000, loss: 0.011321
 >> iter 55000, loss: 0.011392
 >> iter 56000, loss: 0.011310
 >> iter 57000, loss: 0.011376
 >> iter 58000, loss: 0.011302
 >> iter 59000, loss: 0.011369
 >> iter 60000, loss: 0.011298
   Number of active neurons: 3
 >> iter 61000, loss: 0.011378
 >> iter 62000, loss: 0.011294
 >> iter 63000, loss: 0.011366
 >> iter 64000, loss: 0.011295
 >> iter 65000, loss: 0.011357
 >> iter 66000, loss: 0.011282
 >> iter 67000, loss: 0.011332
 >> iter 68000, loss: 0.011271
 >> iter 69000, loss: 0.011311
 >> iter 70000, loss: 0.011261
   Number of active neurons: 3
 >> iter 71000, loss: 0.011301
 >> iter 72000, loss: 0.011257
 >> iter 73000, loss: 0.011313
 >> iter 74000, loss: 0.011264
 >> iter 75000, loss: 0.011317
 >> iter 76000, loss: 0.011273
 >> iter 77000, loss: 0.011323
 >> iter 78000, loss: 0.011275
 >> iter 79000, loss: 0.011320
 >> iter 80000, loss: 0.011261
   Number of active neurons: 3
 >> iter 81000, loss: 0.011320
 >> iter 82000, loss: 0.011269
 >> iter 83000, loss: 0.011334
 >> iter 84000, loss: 0.011284
 >> iter 85000, loss: 0.011339
 >> iter 86000, loss: 0.011292
 >> iter 87000, loss: 0.011344
 >> iter 88000, loss: 0.011312
 >> iter 89000, loss: 0.011355
 >> iter 90000, loss: 0.011318
   Number of active neurons: 3
 >> iter 91000, loss: 0.011356
 >> iter 92000, loss: 0.011330
 >> iter 93000, loss: 0.011370
 >> iter 94000, loss: 0.011336
 >> iter 95000, loss: 0.011381
 >> iter 96000, loss: 0.011344
 >> iter 97000, loss: 0.011389
 >> iter 98000, loss: 0.011349
 >> iter 99000, loss: 0.011397
 >> iter 100000, loss: 0.011362
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.851362
 >> iter 2000, loss: 4.015986
 >> iter 3000, loss: 1.493141
 >> iter 4000, loss: 0.562763
 >> iter 5000, loss: 0.219896
 >> iter 6000, loss: 0.092732
 >> iter 7000, loss: 0.045847
 >> iter 8000, loss: 0.027972
 >> iter 9000, loss: 0.021620
 >> iter 10000, loss: 0.018877
   Number of active neurons: 8
 >> iter 11000, loss: 0.018220
 >> iter 12000, loss: 0.017580
 >> iter 13000, loss: 0.017697
 >> iter 14000, loss: 0.017362
 >> iter 15000, loss: 0.017628
 >> iter 16000, loss: 0.017255
 >> iter 17000, loss: 0.017446
 >> iter 18000, loss: 0.017064
 >> iter 19000, loss: 0.017245
 >> iter 20000, loss: 0.016864
   Number of active neurons: 7
 >> iter 21000, loss: 0.017028
 >> iter 22000, loss: 0.016668
 >> iter 23000, loss: 0.016804
 >> iter 24000, loss: 0.016437
 >> iter 25000, loss: 0.016556
 >> iter 26000, loss: 0.016166
 >> iter 27000, loss: 0.016273
 >> iter 28000, loss: 0.015889
 >> iter 29000, loss: 0.016019
 >> iter 30000, loss: 0.015628
   Number of active neurons: 5
 >> iter 31000, loss: 0.015689
 >> iter 32000, loss: 0.015276
 >> iter 33000, loss: 0.015310
 >> iter 34000, loss: 0.014883
 >> iter 35000, loss: 0.014850
 >> iter 36000, loss: 0.014457
 >> iter 37000, loss: 0.014450
 >> iter 38000, loss: 0.014083
 >> iter 39000, loss: 0.014013
 >> iter 40000, loss: 0.013630
   Number of active neurons: 5
 >> iter 41000, loss: 0.013558
 >> iter 42000, loss: 0.013233
 >> iter 43000, loss: 0.013209
 >> iter 44000, loss: 0.012934
 >> iter 45000, loss: 0.012917
 >> iter 46000, loss: 0.012664
 >> iter 47000, loss: 0.012690
 >> iter 48000, loss: 0.012479
 >> iter 49000, loss: 0.012550
 >> iter 50000, loss: 0.012362
   Number of active neurons: 5
 >> iter 51000, loss: 0.012449
 >> iter 52000, loss: 0.012294
 >> iter 53000, loss: 0.012373
 >> iter 54000, loss: 0.012243
 >> iter 55000, loss: 0.012313
 >> iter 56000, loss: 0.012147
 >> iter 57000, loss: 0.012142
 >> iter 58000, loss: 0.011953
 >> iter 59000, loss: 0.011957
 >> iter 60000, loss: 0.011793
   Number of active neurons: 4
 >> iter 61000, loss: 0.011821
 >> iter 62000, loss: 0.011655
 >> iter 63000, loss: 0.011676
 >> iter 64000, loss: 0.011510
 >> iter 65000, loss: 0.011485
 >> iter 66000, loss: 0.011304
 >> iter 67000, loss: 0.011274
 >> iter 68000, loss: 0.011107
 >> iter 69000, loss: 0.011061
 >> iter 70000, loss: 0.010896
   Number of active neurons: 4
 >> iter 71000, loss: 0.010830
 >> iter 72000, loss: 0.010651
 >> iter 73000, loss: 0.010577
 >> iter 74000, loss: 0.010399
 >> iter 75000, loss: 0.010343
 >> iter 76000, loss: 0.010200
 >> iter 77000, loss: 0.010169
 >> iter 78000, loss: 0.010050
 >> iter 79000, loss: 0.010039
 >> iter 80000, loss: 0.009933
   Number of active neurons: 4
 >> iter 81000, loss: 0.009939
 >> iter 82000, loss: 0.009845
 >> iter 83000, loss: 0.009859
 >> iter 84000, loss: 0.009776
 >> iter 85000, loss: 0.009789
 >> iter 86000, loss: 0.009715
 >> iter 87000, loss: 0.009730
 >> iter 88000, loss: 0.009671
 >> iter 89000, loss: 0.009684
 >> iter 90000, loss: 0.009625
   Number of active neurons: 4
 >> iter 91000, loss: 0.009638
 >> iter 92000, loss: 0.009589
 >> iter 93000, loss: 0.009604
 >> iter 94000, loss: 0.009554
 >> iter 95000, loss: 0.009575
 >> iter 96000, loss: 0.009522
 >> iter 97000, loss: 0.009545
 >> iter 98000, loss: 0.009492
 >> iter 99000, loss: 0.009517
 >> iter 100000, loss: 0.009470
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455162
   Number of active neurons: 0
 >> iter 1000, loss: 10.842932
 >> iter 2000, loss: 4.014810
 >> iter 3000, loss: 1.494431
 >> iter 4000, loss: 0.564422
 >> iter 5000, loss: 0.221355
 >> iter 6000, loss: 0.093987
 >> iter 7000, loss: 0.046986
 >> iter 8000, loss: 0.028819
 >> iter 9000, loss: 0.022068
 >> iter 10000, loss: 0.018806
   Number of active neurons: 5
 >> iter 11000, loss: 0.017664
 >> iter 12000, loss: 0.016644
 >> iter 13000, loss: 0.016365
 >> iter 14000, loss: 0.015653
 >> iter 15000, loss: 0.015480
 >> iter 16000, loss: 0.014829
 >> iter 17000, loss: 0.014660
 >> iter 18000, loss: 0.014042
 >> iter 19000, loss: 0.013902
 >> iter 20000, loss: 0.013353
   Number of active neurons: 6
 >> iter 21000, loss: 0.013255
 >> iter 22000, loss: 0.012796
 >> iter 23000, loss: 0.012778
 >> iter 24000, loss: 0.012420
 >> iter 25000, loss: 0.012501
 >> iter 26000, loss: 0.012200
 >> iter 27000, loss: 0.012323
 >> iter 28000, loss: 0.012067
 >> iter 29000, loss: 0.012233
 >> iter 30000, loss: 0.012012
   Number of active neurons: 6
 >> iter 31000, loss: 0.012188
 >> iter 32000, loss: 0.011972
 >> iter 33000, loss: 0.012149
 >> iter 34000, loss: 0.011958
 >> iter 35000, loss: 0.012116
 >> iter 36000, loss: 0.011936
 >> iter 37000, loss: 0.012082
 >> iter 38000, loss: 0.011877
 >> iter 39000, loss: 0.011985
 >> iter 40000, loss: 0.011820
   Number of active neurons: 6
 >> iter 41000, loss: 0.011921
 >> iter 42000, loss: 0.011767
 >> iter 43000, loss: 0.011880
 >> iter 44000, loss: 0.011751
 >> iter 45000, loss: 0.011862
 >> iter 46000, loss: 0.011735
 >> iter 47000, loss: 0.011855
 >> iter 48000, loss: 0.011729
 >> iter 49000, loss: 0.011858
 >> iter 50000, loss: 0.011730
   Number of active neurons: 6
 >> iter 51000, loss: 0.011857
 >> iter 52000, loss: 0.011749
 >> iter 53000, loss: 0.011858
 >> iter 54000, loss: 0.011769
 >> iter 55000, loss: 0.011873
 >> iter 56000, loss: 0.011784
 >> iter 57000, loss: 0.011882
 >> iter 58000, loss: 0.011799
 >> iter 59000, loss: 0.011897
 >> iter 60000, loss: 0.011818
   Number of active neurons: 6
 >> iter 61000, loss: 0.011922
 >> iter 62000, loss: 0.011815
 >> iter 63000, loss: 0.011906
 >> iter 64000, loss: 0.011816
 >> iter 65000, loss: 0.011904
 >> iter 66000, loss: 0.011825
 >> iter 67000, loss: 0.011913
 >> iter 68000, loss: 0.011845
 >> iter 69000, loss: 0.011919
 >> iter 70000, loss: 0.011858
   Number of active neurons: 6
 >> iter 71000, loss: 0.011927
 >> iter 72000, loss: 0.011868
 >> iter 73000, loss: 0.011950
 >> iter 74000, loss: 0.011882
 >> iter 75000, loss: 0.011956
 >> iter 76000, loss: 0.011890
 >> iter 77000, loss: 0.011951
 >> iter 78000, loss: 0.011832
 >> iter 79000, loss: 0.011837
 >> iter 80000, loss: 0.011708
   Number of active neurons: 5
 >> iter 81000, loss: 0.011725
 >> iter 82000, loss: 0.011608
 >> iter 83000, loss: 0.011631
 >> iter 84000, loss: 0.011524
 >> iter 85000, loss: 0.011535
 >> iter 86000, loss: 0.011428
 >> iter 87000, loss: 0.011400
 >> iter 88000, loss: 0.011264
 >> iter 89000, loss: 0.011218
 >> iter 90000, loss: 0.011084
   Number of active neurons: 5
 >> iter 91000, loss: 0.011033
 >> iter 92000, loss: 0.010907
 >> iter 93000, loss: 0.010845
 >> iter 94000, loss: 0.010703
 >> iter 95000, loss: 0.010626
 >> iter 96000, loss: 0.010461
 >> iter 97000, loss: 0.010378
 >> iter 98000, loss: 0.010233
 >> iter 99000, loss: 0.010181
 >> iter 100000, loss: 0.010069
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.804992
 >> iter 2000, loss: 3.999128
 >> iter 3000, loss: 1.487239
 >> iter 4000, loss: 0.559559
 >> iter 5000, loss: 0.217673
 >> iter 6000, loss: 0.090744
 >> iter 7000, loss: 0.044201
 >> iter 8000, loss: 0.026494
 >> iter 9000, loss: 0.020262
 >> iter 10000, loss: 0.017599
   Number of active neurons: 5
 >> iter 11000, loss: 0.016954
 >> iter 12000, loss: 0.016341
 >> iter 13000, loss: 0.016303
 >> iter 14000, loss: 0.015868
 >> iter 15000, loss: 0.015959
 >> iter 16000, loss: 0.015544
 >> iter 17000, loss: 0.015656
 >> iter 18000, loss: 0.015265
 >> iter 19000, loss: 0.015391
 >> iter 20000, loss: 0.015028
   Number of active neurons: 4
 >> iter 21000, loss: 0.015166
 >> iter 22000, loss: 0.014840
 >> iter 23000, loss: 0.014996
 >> iter 24000, loss: 0.014683
 >> iter 25000, loss: 0.014840
 >> iter 26000, loss: 0.014509
 >> iter 27000, loss: 0.014615
 >> iter 28000, loss: 0.014226
 >> iter 29000, loss: 0.014268
 >> iter 30000, loss: 0.013837
   Number of active neurons: 3
 >> iter 31000, loss: 0.013856
 >> iter 32000, loss: 0.013435
 >> iter 33000, loss: 0.013451
 >> iter 34000, loss: 0.013080
 >> iter 35000, loss: 0.013077
 >> iter 36000, loss: 0.012720
 >> iter 37000, loss: 0.012722
 >> iter 38000, loss: 0.012397
 >> iter 39000, loss: 0.012413
 >> iter 40000, loss: 0.012143
   Number of active neurons: 3
 >> iter 41000, loss: 0.012140
 >> iter 42000, loss: 0.011900
 >> iter 43000, loss: 0.011940
 >> iter 44000, loss: 0.011763
 >> iter 45000, loss: 0.011824
 >> iter 46000, loss: 0.011668
 >> iter 47000, loss: 0.011744
 >> iter 48000, loss: 0.011589
 >> iter 49000, loss: 0.011682
 >> iter 50000, loss: 0.011539
   Number of active neurons: 3
 >> iter 51000, loss: 0.011639
 >> iter 52000, loss: 0.011522
 >> iter 53000, loss: 0.011609
 >> iter 54000, loss: 0.011516
 >> iter 55000, loss: 0.011600
 >> iter 56000, loss: 0.011509
 >> iter 57000, loss: 0.011588
 >> iter 58000, loss: 0.011504
 >> iter 59000, loss: 0.011584
 >> iter 60000, loss: 0.011503
   Number of active neurons: 3
 >> iter 61000, loss: 0.011596
 >> iter 62000, loss: 0.011502
 >> iter 63000, loss: 0.011587
 >> iter 64000, loss: 0.011506
 >> iter 65000, loss: 0.011579
 >> iter 66000, loss: 0.011495
 >> iter 67000, loss: 0.011560
 >> iter 68000, loss: 0.011490
 >> iter 69000, loss: 0.011543
 >> iter 70000, loss: 0.011484
   Number of active neurons: 3
 >> iter 71000, loss: 0.011536
 >> iter 72000, loss: 0.011483
 >> iter 73000, loss: 0.011551
 >> iter 74000, loss: 0.011493
 >> iter 75000, loss: 0.011556
 >> iter 76000, loss: 0.011504
 >> iter 77000, loss: 0.011565
 >> iter 78000, loss: 0.011511
 >> iter 79000, loss: 0.011574
 >> iter 80000, loss: 0.011516
   Number of active neurons: 3
 >> iter 81000, loss: 0.011584
 >> iter 82000, loss: 0.011527
 >> iter 83000, loss: 0.011596
 >> iter 84000, loss: 0.011543
 >> iter 85000, loss: 0.011603
 >> iter 86000, loss: 0.011554
 >> iter 87000, loss: 0.011614
 >> iter 88000, loss: 0.011579
 >> iter 89000, loss: 0.011632
 >> iter 90000, loss: 0.011593
   Number of active neurons: 3
 >> iter 91000, loss: 0.011642
 >> iter 92000, loss: 0.011614
 >> iter 93000, loss: 0.011665
 >> iter 94000, loss: 0.011631
 >> iter 95000, loss: 0.011689
 >> iter 96000, loss: 0.011650
 >> iter 97000, loss: 0.011708
 >> iter 98000, loss: 0.011667
 >> iter 99000, loss: 0.011728
 >> iter 100000, loss: 0.011693
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.782212
 >> iter 2000, loss: 3.988677
 >> iter 3000, loss: 1.482890
 >> iter 4000, loss: 0.558399
 >> iter 5000, loss: 0.217471
 >> iter 6000, loss: 0.090751
 >> iter 7000, loss: 0.043961
 >> iter 8000, loss: 0.026038
 >> iter 9000, loss: 0.019538
 >> iter 10000, loss: 0.016643
   Number of active neurons: 6
 >> iter 11000, loss: 0.015792
 >> iter 12000, loss: 0.015101
 >> iter 13000, loss: 0.015115
 >> iter 14000, loss: 0.014822
 >> iter 15000, loss: 0.015050
 >> iter 16000, loss: 0.014803
 >> iter 17000, loss: 0.015053
 >> iter 18000, loss: 0.014807
 >> iter 19000, loss: 0.015044
 >> iter 20000, loss: 0.014785
   Number of active neurons: 4
 >> iter 21000, loss: 0.014982
 >> iter 22000, loss: 0.014700
 >> iter 23000, loss: 0.014867
 >> iter 24000, loss: 0.014559
 >> iter 25000, loss: 0.014691
 >> iter 26000, loss: 0.014303
 >> iter 27000, loss: 0.014322
 >> iter 28000, loss: 0.013871
 >> iter 29000, loss: 0.013870
 >> iter 30000, loss: 0.013458
   Number of active neurons: 4
 >> iter 31000, loss: 0.013484
 >> iter 32000, loss: 0.013101
 >> iter 33000, loss: 0.013124
 >> iter 34000, loss: 0.012758
 >> iter 35000, loss: 0.012750
 >> iter 36000, loss: 0.012415
 >> iter 37000, loss: 0.012448
 >> iter 38000, loss: 0.012169
 >> iter 39000, loss: 0.012200
 >> iter 40000, loss: 0.011963
   Number of active neurons: 4
 >> iter 41000, loss: 0.012009
 >> iter 42000, loss: 0.011812
 >> iter 43000, loss: 0.011890
 >> iter 44000, loss: 0.011737
 >> iter 45000, loss: 0.011823
 >> iter 46000, loss: 0.011679
 >> iter 47000, loss: 0.011778
 >> iter 48000, loss: 0.011642
 >> iter 49000, loss: 0.011753
 >> iter 50000, loss: 0.011618
   Number of active neurons: 4
 >> iter 51000, loss: 0.011728
 >> iter 52000, loss: 0.011614
 >> iter 53000, loss: 0.011709
 >> iter 54000, loss: 0.011616
 >> iter 55000, loss: 0.011706
 >> iter 56000, loss: 0.011614
 >> iter 57000, loss: 0.011699
 >> iter 58000, loss: 0.011614
 >> iter 59000, loss: 0.011700
 >> iter 60000, loss: 0.011620
   Number of active neurons: 4
 >> iter 61000, loss: 0.011718
 >> iter 62000, loss: 0.011624
 >> iter 63000, loss: 0.011711
 >> iter 64000, loss: 0.011619
 >> iter 65000, loss: 0.011692
 >> iter 66000, loss: 0.011611
 >> iter 67000, loss: 0.011686
 >> iter 68000, loss: 0.011620
 >> iter 69000, loss: 0.011683
 >> iter 70000, loss: 0.011626
   Number of active neurons: 4
 >> iter 71000, loss: 0.011687
 >> iter 72000, loss: 0.011635
 >> iter 73000, loss: 0.011712
 >> iter 74000, loss: 0.011653
 >> iter 75000, loss: 0.011725
 >> iter 76000, loss: 0.011673
 >> iter 77000, loss: 0.011741
 >> iter 78000, loss: 0.011687
 >> iter 79000, loss: 0.011757
 >> iter 80000, loss: 0.011699
   Number of active neurons: 4
 >> iter 81000, loss: 0.011774
 >> iter 82000, loss: 0.011716
 >> iter 83000, loss: 0.011792
 >> iter 84000, loss: 0.011738
 >> iter 85000, loss: 0.011805
 >> iter 86000, loss: 0.011754
 >> iter 87000, loss: 0.011820
 >> iter 88000, loss: 0.011782
 >> iter 89000, loss: 0.011842
 >> iter 90000, loss: 0.011798
   Number of active neurons: 4
 >> iter 91000, loss: 0.011855
 >> iter 92000, loss: 0.011821
 >> iter 93000, loss: 0.011877
 >> iter 94000, loss: 0.011837
 >> iter 95000, loss: 0.011897
 >> iter 96000, loss: 0.011850
 >> iter 97000, loss: 0.011910
 >> iter 98000, loss: 0.011857
 >> iter 99000, loss: 0.011917
 >> iter 100000, loss: 0.011867
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.811336
 >> iter 2000, loss: 3.999390
 >> iter 3000, loss: 1.487006
 >> iter 4000, loss: 0.560415
 >> iter 5000, loss: 0.218844
 >> iter 6000, loss: 0.092076
 >> iter 7000, loss: 0.045256
 >> iter 8000, loss: 0.027293
 >> iter 9000, loss: 0.020744
 >> iter 10000, loss: 0.017714
   Number of active neurons: 6
 >> iter 11000, loss: 0.016679
 >> iter 12000, loss: 0.015792
 >> iter 13000, loss: 0.015572
 >> iter 14000, loss: 0.014906
 >> iter 15000, loss: 0.014802
 >> iter 16000, loss: 0.014282
 >> iter 17000, loss: 0.014299
 >> iter 18000, loss: 0.013896
 >> iter 19000, loss: 0.013999
 >> iter 20000, loss: 0.013695
   Number of active neurons: 6
 >> iter 21000, loss: 0.013833
 >> iter 22000, loss: 0.013552
 >> iter 23000, loss: 0.013727
 >> iter 24000, loss: 0.013471
 >> iter 25000, loss: 0.013662
 >> iter 26000, loss: 0.013405
 >> iter 27000, loss: 0.013598
 >> iter 28000, loss: 0.013334
 >> iter 29000, loss: 0.013520
 >> iter 30000, loss: 0.013260
   Number of active neurons: 5
 >> iter 31000, loss: 0.013415
 >> iter 32000, loss: 0.013101
 >> iter 33000, loss: 0.013215
 >> iter 34000, loss: 0.012932
 >> iter 35000, loss: 0.013013
 >> iter 36000, loss: 0.012732
 >> iter 37000, loss: 0.012816
 >> iter 38000, loss: 0.012559
 >> iter 39000, loss: 0.012618
 >> iter 40000, loss: 0.012361
   Number of active neurons: 5
 >> iter 41000, loss: 0.012369
 >> iter 42000, loss: 0.012116
 >> iter 43000, loss: 0.012125
 >> iter 44000, loss: 0.011895
 >> iter 45000, loss: 0.011925
 >> iter 46000, loss: 0.011739
 >> iter 47000, loss: 0.011809
 >> iter 48000, loss: 0.011651
 >> iter 49000, loss: 0.011746
 >> iter 50000, loss: 0.011600
   Number of active neurons: 5
 >> iter 51000, loss: 0.011701
 >> iter 52000, loss: 0.011581
 >> iter 53000, loss: 0.011670
 >> iter 54000, loss: 0.011573
 >> iter 55000, loss: 0.011658
 >> iter 56000, loss: 0.011563
 >> iter 57000, loss: 0.011644
 >> iter 58000, loss: 0.011557
 >> iter 59000, loss: 0.011639
 >> iter 60000, loss: 0.011557
   Number of active neurons: 5
 >> iter 61000, loss: 0.011652
 >> iter 62000, loss: 0.011556
 >> iter 63000, loss: 0.011642
 >> iter 64000, loss: 0.011551
 >> iter 65000, loss: 0.011620
 >> iter 66000, loss: 0.011538
 >> iter 67000, loss: 0.011608
 >> iter 68000, loss: 0.011540
 >> iter 69000, loss: 0.011600
 >> iter 70000, loss: 0.011542
   Number of active neurons: 5
 >> iter 71000, loss: 0.011599
 >> iter 72000, loss: 0.011546
 >> iter 73000, loss: 0.011619
 >> iter 74000, loss: 0.011560
 >> iter 75000, loss: 0.011627
 >> iter 76000, loss: 0.011575
 >> iter 77000, loss: 0.011639
 >> iter 78000, loss: 0.011585
 >> iter 79000, loss: 0.011652
 >> iter 80000, loss: 0.011593
   Number of active neurons: 5
 >> iter 81000, loss: 0.011665
 >> iter 82000, loss: 0.011607
 >> iter 83000, loss: 0.011680
 >> iter 84000, loss: 0.011626
 >> iter 85000, loss: 0.011691
 >> iter 86000, loss: 0.011640
 >> iter 87000, loss: 0.011704
 >> iter 88000, loss: 0.011668
 >> iter 89000, loss: 0.011725
 >> iter 90000, loss: 0.011684
   Number of active neurons: 5
 >> iter 91000, loss: 0.011739
 >> iter 92000, loss: 0.011708
 >> iter 93000, loss: 0.011764
 >> iter 94000, loss: 0.011728
 >> iter 95000, loss: 0.011789
 >> iter 96000, loss: 0.011748
 >> iter 97000, loss: 0.011810
 >> iter 98000, loss: 0.011766
 >> iter 99000, loss: 0.011830
 >> iter 100000, loss: 0.011791
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.838188
 >> iter 2000, loss: 4.009855
 >> iter 3000, loss: 1.489860
 >> iter 4000, loss: 0.560128
 >> iter 5000, loss: 0.217708
 >> iter 6000, loss: 0.090753
 >> iter 7000, loss: 0.044246
 >> iter 8000, loss: 0.026577
 >> iter 9000, loss: 0.020369
 >> iter 10000, loss: 0.017706
   Number of active neurons: 5
 >> iter 11000, loss: 0.016983
 >> iter 12000, loss: 0.016304
 >> iter 13000, loss: 0.016257
 >> iter 14000, loss: 0.015820
 >> iter 15000, loss: 0.015900
 >> iter 16000, loss: 0.015465
 >> iter 17000, loss: 0.015566
 >> iter 18000, loss: 0.015158
 >> iter 19000, loss: 0.015273
 >> iter 20000, loss: 0.014897
   Number of active neurons: 4
 >> iter 21000, loss: 0.015027
 >> iter 22000, loss: 0.014685
 >> iter 23000, loss: 0.014825
 >> iter 24000, loss: 0.014461
 >> iter 25000, loss: 0.014550
 >> iter 26000, loss: 0.014158
 >> iter 27000, loss: 0.014256
 >> iter 28000, loss: 0.013885
 >> iter 29000, loss: 0.013987
 >> iter 30000, loss: 0.013607
   Number of active neurons: 3
 >> iter 31000, loss: 0.013648
 >> iter 32000, loss: 0.013238
 >> iter 33000, loss: 0.013273
 >> iter 34000, loss: 0.012909
 >> iter 35000, loss: 0.012949
 >> iter 36000, loss: 0.012643
 >> iter 37000, loss: 0.012709
 >> iter 38000, loss: 0.012430
 >> iter 39000, loss: 0.012491
 >> iter 40000, loss: 0.012235
   Number of active neurons: 3
 >> iter 41000, loss: 0.012224
 >> iter 42000, loss: 0.011946
 >> iter 43000, loss: 0.011957
 >> iter 44000, loss: 0.011753
 >> iter 45000, loss: 0.011795
 >> iter 46000, loss: 0.011625
 >> iter 47000, loss: 0.011695
 >> iter 48000, loss: 0.011547
 >> iter 49000, loss: 0.011635
 >> iter 50000, loss: 0.011495
   Number of active neurons: 3
 >> iter 51000, loss: 0.011587
 >> iter 52000, loss: 0.011473
 >> iter 53000, loss: 0.011552
 >> iter 54000, loss: 0.011462
 >> iter 55000, loss: 0.011539
 >> iter 56000, loss: 0.011450
 >> iter 57000, loss: 0.011525
 >> iter 58000, loss: 0.011440
 >> iter 59000, loss: 0.011506
 >> iter 60000, loss: 0.011417
   Number of active neurons: 3
 >> iter 61000, loss: 0.011504
 >> iter 62000, loss: 0.011409
 >> iter 63000, loss: 0.011492
 >> iter 64000, loss: 0.011408
 >> iter 65000, loss: 0.011477
 >> iter 66000, loss: 0.011398
 >> iter 67000, loss: 0.011466
 >> iter 68000, loss: 0.011401
 >> iter 69000, loss: 0.011456
 >> iter 70000, loss: 0.011400
   Number of active neurons: 3
 >> iter 71000, loss: 0.011451
 >> iter 72000, loss: 0.011400
 >> iter 73000, loss: 0.011467
 >> iter 74000, loss: 0.011409
 >> iter 75000, loss: 0.011470
 >> iter 76000, loss: 0.011419
 >> iter 77000, loss: 0.011476
 >> iter 78000, loss: 0.011423
 >> iter 79000, loss: 0.011482
 >> iter 80000, loss: 0.011424
   Number of active neurons: 3
 >> iter 81000, loss: 0.011489
 >> iter 82000, loss: 0.011432
 >> iter 83000, loss: 0.011498
 >> iter 84000, loss: 0.011444
 >> iter 85000, loss: 0.011501
 >> iter 86000, loss: 0.011450
 >> iter 87000, loss: 0.011506
 >> iter 88000, loss: 0.011471
 >> iter 89000, loss: 0.011520
 >> iter 90000, loss: 0.011481
   Number of active neurons: 3
 >> iter 91000, loss: 0.011526
 >> iter 92000, loss: 0.011498
 >> iter 93000, loss: 0.011545
 >> iter 94000, loss: 0.011511
 >> iter 95000, loss: 0.011563
 >> iter 96000, loss: 0.011525
 >> iter 97000, loss: 0.011578
 >> iter 98000, loss: 0.011538
 >> iter 99000, loss: 0.011595
 >> iter 100000, loss: 0.011560
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.895611
 >> iter 2000, loss: 4.036308
 >> iter 3000, loss: 1.501724
 >> iter 4000, loss: 0.567113
 >> iter 5000, loss: 0.222551
 >> iter 6000, loss: 0.094804
 >> iter 7000, loss: 0.047574
 >> iter 8000, loss: 0.029364
 >> iter 9000, loss: 0.022549
 >> iter 10000, loss: 0.019375
   Number of active neurons: 7
 >> iter 11000, loss: 0.018215
 >> iter 12000, loss: 0.017200
 >> iter 13000, loss: 0.017003
 >> iter 14000, loss: 0.016451
 >> iter 15000, loss: 0.016719
 >> iter 16000, loss: 0.015970
 >> iter 17000, loss: 0.016185
 >> iter 18000, loss: 0.015454
 >> iter 19000, loss: 0.015720
 >> iter 20000, loss: 0.015089
   Number of active neurons: 7
 >> iter 21000, loss: 0.015360
 >> iter 22000, loss: 0.014797
 >> iter 23000, loss: 0.015057
 >> iter 24000, loss: 0.014650
 >> iter 25000, loss: 0.014920
 >> iter 26000, loss: 0.014592
 >> iter 27000, loss: 0.014878
 >> iter 28000, loss: 0.014579
 >> iter 29000, loss: 0.014871
 >> iter 30000, loss: 0.014588
   Number of active neurons: 7
 >> iter 31000, loss: 0.014870
 >> iter 32000, loss: 0.014575
 >> iter 33000, loss: 0.014841
 >> iter 34000, loss: 0.014572
 >> iter 35000, loss: 0.014800
 >> iter 36000, loss: 0.014539
 >> iter 37000, loss: 0.014756
 >> iter 38000, loss: 0.014498
 >> iter 39000, loss: 0.014693
 >> iter 40000, loss: 0.014464
   Number of active neurons: 6
 >> iter 41000, loss: 0.014621
 >> iter 42000, loss: 0.014380
 >> iter 43000, loss: 0.014525
 >> iter 44000, loss: 0.014263
 >> iter 45000, loss: 0.014349
 >> iter 46000, loss: 0.014053
 >> iter 47000, loss: 0.014123
 >> iter 48000, loss: 0.013836
 >> iter 49000, loss: 0.013871
 >> iter 50000, loss: 0.013622
   Number of active neurons: 6
 >> iter 51000, loss: 0.013663
 >> iter 52000, loss: 0.013459
 >> iter 53000, loss: 0.013476
 >> iter 54000, loss: 0.013300
 >> iter 55000, loss: 0.013322
 >> iter 56000, loss: 0.013180
 >> iter 57000, loss: 0.013225
 >> iter 58000, loss: 0.013119
 >> iter 59000, loss: 0.013183
 >> iter 60000, loss: 0.013094
   Number of active neurons: 6
 >> iter 61000, loss: 0.013184
 >> iter 62000, loss: 0.013077
 >> iter 63000, loss: 0.013157
 >> iter 64000, loss: 0.013071
 >> iter 65000, loss: 0.013154
 >> iter 66000, loss: 0.013081
 >> iter 67000, loss: 0.013161
 >> iter 68000, loss: 0.013085
 >> iter 69000, loss: 0.013143
 >> iter 70000, loss: 0.013075
   Number of active neurons: 6
 >> iter 71000, loss: 0.013129
 >> iter 72000, loss: 0.013071
 >> iter 73000, loss: 0.013146
 >> iter 74000, loss: 0.013083
 >> iter 75000, loss: 0.013154
 >> iter 76000, loss: 0.013099
 >> iter 77000, loss: 0.013167
 >> iter 78000, loss: 0.013109
 >> iter 79000, loss: 0.013181
 >> iter 80000, loss: 0.013118
   Number of active neurons: 6
 >> iter 81000, loss: 0.013194
 >> iter 82000, loss: 0.013133
 >> iter 83000, loss: 0.013213
 >> iter 84000, loss: 0.013154
 >> iter 85000, loss: 0.013224
 >> iter 86000, loss: 0.013170
 >> iter 87000, loss: 0.013239
 >> iter 88000, loss: 0.013203
 >> iter 89000, loss: 0.013264
 >> iter 90000, loss: 0.013223
   Number of active neurons: 6
 >> iter 91000, loss: 0.013280
 >> iter 92000, loss: 0.013253
 >> iter 93000, loss: 0.013312
 >> iter 94000, loss: 0.013278
 >> iter 95000, loss: 0.013345
 >> iter 96000, loss: 0.013305
 >> iter 97000, loss: 0.013373
 >> iter 98000, loss: 0.013331
 >> iter 99000, loss: 0.013403
 >> iter 100000, loss: 0.013367
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.858304
 >> iter 2000, loss: 4.014764
 >> iter 3000, loss: 1.490770
 >> iter 4000, loss: 0.559858
 >> iter 5000, loss: 0.216981
 >> iter 6000, loss: 0.089957
 >> iter 7000, loss: 0.043291
 >> iter 8000, loss: 0.025627
 >> iter 9000, loss: 0.019292
 >> iter 10000, loss: 0.016597
   Number of active neurons: 5
 >> iter 11000, loss: 0.015823
 >> iter 12000, loss: 0.015225
 >> iter 13000, loss: 0.015267
 >> iter 14000, loss: 0.015003
 >> iter 15000, loss: 0.015227
 >> iter 16000, loss: 0.014977
 >> iter 17000, loss: 0.015220
 >> iter 18000, loss: 0.014988
 >> iter 19000, loss: 0.015247
 >> iter 20000, loss: 0.015017
   Number of active neurons: 5
 >> iter 21000, loss: 0.015265
 >> iter 22000, loss: 0.015039
 >> iter 23000, loss: 0.015290
 >> iter 24000, loss: 0.015064
 >> iter 25000, loss: 0.015320
 >> iter 26000, loss: 0.015087
 >> iter 27000, loss: 0.015348
 >> iter 28000, loss: 0.015107
 >> iter 29000, loss: 0.015365
 >> iter 30000, loss: 0.015136
   Number of active neurons: 4
 >> iter 31000, loss: 0.015389
 >> iter 32000, loss: 0.015149
 >> iter 33000, loss: 0.015389
 >> iter 34000, loss: 0.015167
 >> iter 35000, loss: 0.015370
 >> iter 36000, loss: 0.015143
 >> iter 37000, loss: 0.015290
 >> iter 38000, loss: 0.015021
 >> iter 39000, loss: 0.015143
 >> iter 40000, loss: 0.014896
   Number of active neurons: 4
 >> iter 41000, loss: 0.014941
 >> iter 42000, loss: 0.014664
 >> iter 43000, loss: 0.014723
 >> iter 44000, loss: 0.014491
 >> iter 45000, loss: 0.014550
 >> iter 46000, loss: 0.014314
 >> iter 47000, loss: 0.014370
 >> iter 48000, loss: 0.014141
 >> iter 49000, loss: 0.014234
 >> iter 50000, loss: 0.014027
   Number of active neurons: 3
 >> iter 51000, loss: 0.014136
 >> iter 52000, loss: 0.013950
 >> iter 53000, loss: 0.013994
 >> iter 54000, loss: 0.013793
 >> iter 55000, loss: 0.013830
 >> iter 56000, loss: 0.013642
 >> iter 57000, loss: 0.013672
 >> iter 58000, loss: 0.013435
 >> iter 59000, loss: 0.013348
 >> iter 60000, loss: 0.013061
   Number of active neurons: 2
 >> iter 61000, loss: 0.012987
 >> iter 62000, loss: 0.012710
 >> iter 63000, loss: 0.012631
 >> iter 64000, loss: 0.012357
 >> iter 65000, loss: 0.012217
 >> iter 66000, loss: 0.011916
 >> iter 67000, loss: 0.011781
 >> iter 68000, loss: 0.011526
 >> iter 69000, loss: 0.011403
 >> iter 70000, loss: 0.011175
   Number of active neurons: 2
 >> iter 71000, loss: 0.011052
 >> iter 72000, loss: 0.010829
 >> iter 73000, loss: 0.010730
 >> iter 74000, loss: 0.010541
 >> iter 75000, loss: 0.010476
 >> iter 76000, loss: 0.010329
 >> iter 77000, loss: 0.010291
 >> iter 78000, loss: 0.010169
 >> iter 79000, loss: 0.010152
 >> iter 80000, loss: 0.010043
   Number of active neurons: 2
 >> iter 81000, loss: 0.010043
 >> iter 82000, loss: 0.009946
 >> iter 83000, loss: 0.009955
 >> iter 84000, loss: 0.009869
 >> iter 85000, loss: 0.009877
 >> iter 86000, loss: 0.009800
 >> iter 87000, loss: 0.009812
 >> iter 88000, loss: 0.009749
 >> iter 89000, loss: 0.009759
 >> iter 90000, loss: 0.009697
   Number of active neurons: 2
 >> iter 91000, loss: 0.009706
 >> iter 92000, loss: 0.009655
 >> iter 93000, loss: 0.009667
 >> iter 94000, loss: 0.009614
 >> iter 95000, loss: 0.009632
 >> iter 96000, loss: 0.009578
 >> iter 97000, loss: 0.009597
 >> iter 98000, loss: 0.009543
 >> iter 99000, loss: 0.009565
 >> iter 100000, loss: 0.009517
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.877885
 >> iter 2000, loss: 4.025356
 >> iter 3000, loss: 1.496894
 >> iter 4000, loss: 0.564739
 >> iter 5000, loss: 0.221225
 >> iter 6000, loss: 0.093734
 >> iter 7000, loss: 0.046721
 >> iter 8000, loss: 0.028634
 >> iter 9000, loss: 0.021946
 >> iter 10000, loss: 0.018878
   Number of active neurons: 6
 >> iter 11000, loss: 0.017909
 >> iter 12000, loss: 0.017054
 >> iter 13000, loss: 0.016897
 >> iter 14000, loss: 0.016299
 >> iter 15000, loss: 0.016377
 >> iter 16000, loss: 0.015802
 >> iter 17000, loss: 0.015947
 >> iter 18000, loss: 0.015368
 >> iter 19000, loss: 0.015472
 >> iter 20000, loss: 0.014865
   Number of active neurons: 6
 >> iter 21000, loss: 0.014897
 >> iter 22000, loss: 0.014306
 >> iter 23000, loss: 0.014359
 >> iter 24000, loss: 0.013861
 >> iter 25000, loss: 0.013951
 >> iter 26000, loss: 0.013534
 >> iter 27000, loss: 0.013660
 >> iter 28000, loss: 0.013340
 >> iter 29000, loss: 0.013549
 >> iter 30000, loss: 0.013288
   Number of active neurons: 6
 >> iter 31000, loss: 0.013505
 >> iter 32000, loss: 0.013267
 >> iter 33000, loss: 0.013485
 >> iter 34000, loss: 0.013272
 >> iter 35000, loss: 0.013475
 >> iter 36000, loss: 0.013275
 >> iter 37000, loss: 0.013474
 >> iter 38000, loss: 0.013282
 >> iter 39000, loss: 0.013469
 >> iter 40000, loss: 0.013308
   Number of active neurons: 6
 >> iter 41000, loss: 0.013453
 >> iter 42000, loss: 0.013262
 >> iter 43000, loss: 0.013376
 >> iter 44000, loss: 0.013222
 >> iter 45000, loss: 0.013340
 >> iter 46000, loss: 0.013191
 >> iter 47000, loss: 0.013312
 >> iter 48000, loss: 0.013168
 >> iter 49000, loss: 0.013311
 >> iter 50000, loss: 0.013172
   Number of active neurons: 6
 >> iter 51000, loss: 0.013314
 >> iter 52000, loss: 0.013199
 >> iter 53000, loss: 0.013321
 >> iter 54000, loss: 0.013228
 >> iter 55000, loss: 0.013344
 >> iter 56000, loss: 0.013250
 >> iter 57000, loss: 0.013357
 >> iter 58000, loss: 0.013270
 >> iter 59000, loss: 0.013377
 >> iter 60000, loss: 0.013293
   Number of active neurons: 6
 >> iter 61000, loss: 0.013414
 >> iter 62000, loss: 0.013312
 >> iter 63000, loss: 0.013422
 >> iter 64000, loss: 0.013334
 >> iter 65000, loss: 0.013435
 >> iter 66000, loss: 0.013354
 >> iter 67000, loss: 0.013447
 >> iter 68000, loss: 0.013362
 >> iter 69000, loss: 0.013425
 >> iter 70000, loss: 0.013347
   Number of active neurons: 6
 >> iter 71000, loss: 0.013406
 >> iter 72000, loss: 0.013334
 >> iter 73000, loss: 0.013411
 >> iter 74000, loss: 0.013328
 >> iter 75000, loss: 0.013394
 >> iter 76000, loss: 0.013312
 >> iter 77000, loss: 0.013350
 >> iter 78000, loss: 0.013209
 >> iter 79000, loss: 0.013210
 >> iter 80000, loss: 0.013070
   Number of active neurons: 5
 >> iter 81000, loss: 0.013085
 >> iter 82000, loss: 0.012953
 >> iter 83000, loss: 0.012943
 >> iter 84000, loss: 0.012793
 >> iter 85000, loss: 0.012775
 >> iter 86000, loss: 0.012640
 >> iter 87000, loss: 0.012624
 >> iter 88000, loss: 0.012504
 >> iter 89000, loss: 0.012472
 >> iter 90000, loss: 0.012335
   Number of active neurons: 5
 >> iter 91000, loss: 0.012292
 >> iter 92000, loss: 0.012181
 >> iter 93000, loss: 0.012171
 >> iter 94000, loss: 0.012085
 >> iter 95000, loss: 0.012106
 >> iter 96000, loss: 0.012032
 >> iter 97000, loss: 0.012069
 >> iter 98000, loss: 0.012004
 >> iter 99000, loss: 0.012050
 >> iter 100000, loss: 0.011996
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.860572
 >> iter 2000, loss: 4.017466
 >> iter 3000, loss: 1.493090
 >> iter 4000, loss: 0.561712
 >> iter 5000, loss: 0.218382
 >> iter 6000, loss: 0.091063
 >> iter 7000, loss: 0.044247
 >> iter 8000, loss: 0.026359
 >> iter 9000, loss: 0.019866
 >> iter 10000, loss: 0.016983
   Number of active neurons: 4
 >> iter 11000, loss: 0.016077
 >> iter 12000, loss: 0.015335
 >> iter 13000, loss: 0.015236
 >> iter 14000, loss: 0.014778
 >> iter 15000, loss: 0.014774
 >> iter 16000, loss: 0.014296
 >> iter 17000, loss: 0.014296
 >> iter 18000, loss: 0.013844
 >> iter 19000, loss: 0.013818
 >> iter 20000, loss: 0.013368
   Number of active neurons: 4
 >> iter 21000, loss: 0.013349
 >> iter 22000, loss: 0.012926
 >> iter 23000, loss: 0.012936
 >> iter 24000, loss: 0.012561
 >> iter 25000, loss: 0.012606
 >> iter 26000, loss: 0.012253
 >> iter 27000, loss: 0.012334
 >> iter 28000, loss: 0.012031
 >> iter 29000, loss: 0.012157
 >> iter 30000, loss: 0.011903
   Number of active neurons: 4
 >> iter 31000, loss: 0.012053
 >> iter 32000, loss: 0.011817
 >> iter 33000, loss: 0.011978
 >> iter 34000, loss: 0.011775
 >> iter 35000, loss: 0.011921
 >> iter 36000, loss: 0.011734
 >> iter 37000, loss: 0.011883
 >> iter 38000, loss: 0.011682
 >> iter 39000, loss: 0.011777
 >> iter 40000, loss: 0.011607
   Number of active neurons: 4
 >> iter 41000, loss: 0.011693
 >> iter 42000, loss: 0.011538
 >> iter 43000, loss: 0.011630
 >> iter 44000, loss: 0.011494
 >> iter 45000, loss: 0.011592
 >> iter 46000, loss: 0.011466
 >> iter 47000, loss: 0.011576
 >> iter 48000, loss: 0.011456
 >> iter 49000, loss: 0.011575
 >> iter 50000, loss: 0.011454
   Number of active neurons: 4
 >> iter 51000, loss: 0.011570
 >> iter 52000, loss: 0.011468
 >> iter 53000, loss: 0.011567
 >> iter 54000, loss: 0.011483
 >> iter 55000, loss: 0.011576
 >> iter 56000, loss: 0.011491
 >> iter 57000, loss: 0.011578
 >> iter 58000, loss: 0.011499
 >> iter 59000, loss: 0.011586
 >> iter 60000, loss: 0.011510
   Number of active neurons: 4
 >> iter 61000, loss: 0.011609
 >> iter 62000, loss: 0.011519
 >> iter 63000, loss: 0.011610
 >> iter 64000, loss: 0.011528
 >> iter 65000, loss: 0.011602
 >> iter 66000, loss: 0.011521
 >> iter 67000, loss: 0.011593
 >> iter 68000, loss: 0.011526
 >> iter 69000, loss: 0.011587
 >> iter 70000, loss: 0.011531
   Number of active neurons: 4
 >> iter 71000, loss: 0.011589
 >> iter 72000, loss: 0.011538
 >> iter 73000, loss: 0.011612
 >> iter 74000, loss: 0.011555
 >> iter 75000, loss: 0.011624
 >> iter 76000, loss: 0.011573
 >> iter 77000, loss: 0.011639
 >> iter 78000, loss: 0.011586
 >> iter 79000, loss: 0.011655
 >> iter 80000, loss: 0.011598
   Number of active neurons: 4
 >> iter 81000, loss: 0.011670
 >> iter 82000, loss: 0.011615
 >> iter 83000, loss: 0.011689
 >> iter 84000, loss: 0.011636
 >> iter 85000, loss: 0.011702
 >> iter 86000, loss: 0.011652
 >> iter 87000, loss: 0.011717
 >> iter 88000, loss: 0.011682
 >> iter 89000, loss: 0.011740
 >> iter 90000, loss: 0.011700
   Number of active neurons: 4
 >> iter 91000, loss: 0.011755
 >> iter 92000, loss: 0.011725
 >> iter 93000, loss: 0.011781
 >> iter 94000, loss: 0.011746
 >> iter 95000, loss: 0.011807
 >> iter 96000, loss: 0.011766
 >> iter 97000, loss: 0.011828
 >> iter 98000, loss: 0.011784
 >> iter 99000, loss: 0.011848
 >> iter 100000, loss: 0.011808
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.764129
 >> iter 2000, loss: 3.981146
 >> iter 3000, loss: 1.479307
 >> iter 4000, loss: 0.556480
 >> iter 5000, loss: 0.216338
 >> iter 6000, loss: 0.090201
 >> iter 7000, loss: 0.043644
 >> iter 8000, loss: 0.025779
 >> iter 9000, loss: 0.019092
 >> iter 10000, loss: 0.015969
   Number of active neurons: 3
 >> iter 11000, loss: 0.014764
 >> iter 12000, loss: 0.013775
 >> iter 13000, loss: 0.013395
 >> iter 14000, loss: 0.012834
 >> iter 15000, loss: 0.012766
 >> iter 16000, loss: 0.012378
 >> iter 17000, loss: 0.012440
 >> iter 18000, loss: 0.012142
 >> iter 19000, loss: 0.012263
 >> iter 20000, loss: 0.012007
   Number of active neurons: 3
 >> iter 21000, loss: 0.012145
 >> iter 22000, loss: 0.011905
 >> iter 23000, loss: 0.012056
 >> iter 24000, loss: 0.011825
 >> iter 25000, loss: 0.011988
 >> iter 26000, loss: 0.011759
 >> iter 27000, loss: 0.011932
 >> iter 28000, loss: 0.011706
 >> iter 29000, loss: 0.011883
 >> iter 30000, loss: 0.011671
   Number of active neurons: 3
 >> iter 31000, loss: 0.011849
 >> iter 32000, loss: 0.011640
 >> iter 33000, loss: 0.011817
 >> iter 34000, loss: 0.011632
 >> iter 35000, loss: 0.011790
 >> iter 36000, loss: 0.011615
 >> iter 37000, loss: 0.011772
 >> iter 38000, loss: 0.011604
 >> iter 39000, loss: 0.011720
 >> iter 40000, loss: 0.011551
   Number of active neurons: 3
 >> iter 41000, loss: 0.011636
 >> iter 42000, loss: 0.011482
 >> iter 43000, loss: 0.011582
 >> iter 44000, loss: 0.011450
 >> iter 45000, loss: 0.011542
 >> iter 46000, loss: 0.011416
 >> iter 47000, loss: 0.011524
 >> iter 48000, loss: 0.011406
 >> iter 49000, loss: 0.011525
 >> iter 50000, loss: 0.011407
   Number of active neurons: 3
 >> iter 51000, loss: 0.011523
 >> iter 52000, loss: 0.011424
 >> iter 53000, loss: 0.011523
 >> iter 54000, loss: 0.011443
 >> iter 55000, loss: 0.011536
 >> iter 56000, loss: 0.011454
 >> iter 57000, loss: 0.011541
 >> iter 58000, loss: 0.011464
 >> iter 59000, loss: 0.011551
 >> iter 60000, loss: 0.011477
   Number of active neurons: 3
 >> iter 61000, loss: 0.011575
 >> iter 62000, loss: 0.011487
 >> iter 63000, loss: 0.011577
 >> iter 64000, loss: 0.011501
 >> iter 65000, loss: 0.011583
 >> iter 66000, loss: 0.011505
 >> iter 67000, loss: 0.011573
 >> iter 68000, loss: 0.011505
 >> iter 69000, loss: 0.011562
 >> iter 70000, loss: 0.011505
   Number of active neurons: 3
 >> iter 71000, loss: 0.011561
 >> iter 72000, loss: 0.011510
 >> iter 73000, loss: 0.011582
 >> iter 74000, loss: 0.011526
 >> iter 75000, loss: 0.011593
 >> iter 76000, loss: 0.011543
 >> iter 77000, loss: 0.011608
 >> iter 78000, loss: 0.011556
 >> iter 79000, loss: 0.011623
 >> iter 80000, loss: 0.011567
   Number of active neurons: 3
 >> iter 81000, loss: 0.011639
 >> iter 82000, loss: 0.011584
 >> iter 83000, loss: 0.011657
 >> iter 84000, loss: 0.011605
 >> iter 85000, loss: 0.011670
 >> iter 86000, loss: 0.011621
 >> iter 87000, loss: 0.011685
 >> iter 88000, loss: 0.011651
 >> iter 89000, loss: 0.011708
 >> iter 90000, loss: 0.011669
   Number of active neurons: 3
 >> iter 91000, loss: 0.011723
 >> iter 92000, loss: 0.011695
 >> iter 93000, loss: 0.011750
 >> iter 94000, loss: 0.011716
 >> iter 95000, loss: 0.011777
 >> iter 96000, loss: 0.011737
 >> iter 97000, loss: 0.011798
 >> iter 98000, loss: 0.011756
 >> iter 99000, loss: 0.011819
 >> iter 100000, loss: 0.011782
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 10.823980
 >> iter 2000, loss: 4.004501
 >> iter 3000, loss: 1.488572
 >> iter 4000, loss: 0.560154
 >> iter 5000, loss: 0.218357
 >> iter 6000, loss: 0.091613
 >> iter 7000, loss: 0.045249
 >> iter 8000, loss: 0.027636
 >> iter 9000, loss: 0.021405
 >> iter 10000, loss: 0.018705
   Number of active neurons: 5
 >> iter 11000, loss: 0.017938
 >> iter 12000, loss: 0.017159
 >> iter 13000, loss: 0.017018
 >> iter 14000, loss: 0.016554
 >> iter 15000, loss: 0.016646
 >> iter 16000, loss: 0.016159
 >> iter 17000, loss: 0.016230
 >> iter 18000, loss: 0.015739
 >> iter 19000, loss: 0.015803
 >> iter 20000, loss: 0.015348
   Number of active neurons: 5
 >> iter 21000, loss: 0.015464
 >> iter 22000, loss: 0.015074
 >> iter 23000, loss: 0.015229
 >> iter 24000, loss: 0.014891
 >> iter 25000, loss: 0.015097
 >> iter 26000, loss: 0.014792
 >> iter 27000, loss: 0.015026
 >> iter 28000, loss: 0.014731
 >> iter 29000, loss: 0.014971
 >> iter 30000, loss: 0.014694
   Number of active neurons: 4
 >> iter 31000, loss: 0.014931
 >> iter 32000, loss: 0.014647
 >> iter 33000, loss: 0.014872
 >> iter 34000, loss: 0.014609
 >> iter 35000, loss: 0.014795
 >> iter 36000, loss: 0.014533
 >> iter 37000, loss: 0.014695
 >> iter 38000, loss: 0.014390
 >> iter 39000, loss: 0.014489
 >> iter 40000, loss: 0.014195
   Number of active neurons: 4
 >> iter 41000, loss: 0.014258
 >> iter 42000, loss: 0.013982
 >> iter 43000, loss: 0.014059
 >> iter 44000, loss: 0.013787
 >> iter 45000, loss: 0.013793
 >> iter 46000, loss: 0.013520
 >> iter 47000, loss: 0.013523
 >> iter 48000, loss: 0.013268
 >> iter 49000, loss: 0.013297
 >> iter 50000, loss: 0.013070
   Number of active neurons: 3
 >> iter 51000, loss: 0.013074
 >> iter 52000, loss: 0.012842
 >> iter 53000, loss: 0.012829
 >> iter 54000, loss: 0.012630
 >> iter 55000, loss: 0.012605
 >> iter 56000, loss: 0.012417
 >> iter 57000, loss: 0.012403
 >> iter 58000, loss: 0.012237
 >> iter 59000, loss: 0.012227
 >> iter 60000, loss: 0.012063
   Number of active neurons: 3
 >> iter 61000, loss: 0.012056
 >> iter 62000, loss: 0.011870
 >> iter 63000, loss: 0.011851
 >> iter 64000, loss: 0.011691
 >> iter 65000, loss: 0.011677
 >> iter 66000, loss: 0.011548
 >> iter 67000, loss: 0.011558
 >> iter 68000, loss: 0.011466
 >> iter 69000, loss: 0.011481
 >> iter 70000, loss: 0.011412
   Number of active neurons: 3
 >> iter 71000, loss: 0.011433
 >> iter 72000, loss: 0.011376
 >> iter 73000, loss: 0.011417
 >> iter 74000, loss: 0.011358
 >> iter 75000, loss: 0.011398
 >> iter 76000, loss: 0.011347
 >> iter 77000, loss: 0.011385
 >> iter 78000, loss: 0.011334
 >> iter 79000, loss: 0.011377
 >> iter 80000, loss: 0.011321
   Number of active neurons: 3
 >> iter 81000, loss: 0.011370
 >> iter 82000, loss: 0.011316
 >> iter 83000, loss: 0.011368
 >> iter 84000, loss: 0.011317
 >> iter 85000, loss: 0.011361
 >> iter 86000, loss: 0.011314
 >> iter 87000, loss: 0.011358
 >> iter 88000, loss: 0.011327
 >> iter 89000, loss: 0.011356
 >> iter 90000, loss: 0.011310
   Number of active neurons: 3
 >> iter 91000, loss: 0.011343
 >> iter 92000, loss: 0.011317
 >> iter 93000, loss: 0.011357
 >> iter 94000, loss: 0.011325
 >> iter 95000, loss: 0.011370
 >> iter 96000, loss: 0.011333
 >> iter 97000, loss: 0.011378
 >> iter 98000, loss: 0.011338
 >> iter 99000, loss: 0.011384
 >> iter 100000, loss: 0.011349
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.895534
 >> iter 2000, loss: 4.029247
 >> iter 3000, loss: 1.496752
 >> iter 4000, loss: 0.562882
 >> iter 5000, loss: 0.218938
 >> iter 6000, loss: 0.091576
 >> iter 7000, loss: 0.044820
 >> iter 8000, loss: 0.027148
 >> iter 9000, loss: 0.020931
 >> iter 10000, loss: 0.018256
   Number of active neurons: 6
 >> iter 11000, loss: 0.017491
 >> iter 12000, loss: 0.016751
 >> iter 13000, loss: 0.016622
 >> iter 14000, loss: 0.016106
 >> iter 15000, loss: 0.016137
 >> iter 16000, loss: 0.015602
 >> iter 17000, loss: 0.015668
 >> iter 18000, loss: 0.015193
 >> iter 19000, loss: 0.015316
 >> iter 20000, loss: 0.014894
   Number of active neurons: 5
 >> iter 21000, loss: 0.015020
 >> iter 22000, loss: 0.014631
 >> iter 23000, loss: 0.014784
 >> iter 24000, loss: 0.014426
 >> iter 25000, loss: 0.014591
 >> iter 26000, loss: 0.014194
 >> iter 27000, loss: 0.014317
 >> iter 28000, loss: 0.013936
 >> iter 29000, loss: 0.014091
 >> iter 30000, loss: 0.013751
   Number of active neurons: 5
 >> iter 31000, loss: 0.013916
 >> iter 32000, loss: 0.013581
 >> iter 33000, loss: 0.013735
 >> iter 34000, loss: 0.013427
 >> iter 35000, loss: 0.013562
 >> iter 36000, loss: 0.013291
 >> iter 37000, loss: 0.013463
 >> iter 38000, loss: 0.013230
 >> iter 39000, loss: 0.013410
 >> iter 40000, loss: 0.013221
   Number of active neurons: 5
 >> iter 41000, loss: 0.013383
 >> iter 42000, loss: 0.013195
 >> iter 43000, loss: 0.013353
 >> iter 44000, loss: 0.013165
 >> iter 45000, loss: 0.013263
 >> iter 46000, loss: 0.013088
 >> iter 47000, loss: 0.013199
 >> iter 48000, loss: 0.013047
 >> iter 49000, loss: 0.013168
 >> iter 50000, loss: 0.013025
   Number of active neurons: 5
 >> iter 51000, loss: 0.013143
 >> iter 52000, loss: 0.013029
 >> iter 53000, loss: 0.013126
 >> iter 54000, loss: 0.013037
 >> iter 55000, loss: 0.013130
 >> iter 56000, loss: 0.013040
 >> iter 57000, loss: 0.013124
 >> iter 58000, loss: 0.013042
 >> iter 59000, loss: 0.013127
 >> iter 60000, loss: 0.013049
   Number of active neurons: 5
 >> iter 61000, loss: 0.013146
 >> iter 62000, loss: 0.013051
 >> iter 63000, loss: 0.013138
 >> iter 64000, loss: 0.013056
 >> iter 65000, loss: 0.013133
 >> iter 66000, loss: 0.013058
 >> iter 67000, loss: 0.013129
 >> iter 68000, loss: 0.013058
 >> iter 69000, loss: 0.013096
 >> iter 70000, loss: 0.013019
   Number of active neurons: 5
 >> iter 71000, loss: 0.013047
 >> iter 72000, loss: 0.012977
 >> iter 73000, loss: 0.013022
 >> iter 74000, loss: 0.012942
 >> iter 75000, loss: 0.012977
 >> iter 76000, loss: 0.012895
 >> iter 77000, loss: 0.012883
 >> iter 78000, loss: 0.012744
 >> iter 79000, loss: 0.012722
 >> iter 80000, loss: 0.012590
   Number of active neurons: 4
 >> iter 81000, loss: 0.012570
 >> iter 82000, loss: 0.012421
 >> iter 83000, loss: 0.012396
 >> iter 84000, loss: 0.012265
 >> iter 85000, loss: 0.012240
 >> iter 86000, loss: 0.012117
 >> iter 87000, loss: 0.012083
 >> iter 88000, loss: 0.011957
 >> iter 89000, loss: 0.011906
 >> iter 90000, loss: 0.011778
   Number of active neurons: 4
 >> iter 91000, loss: 0.011738
 >> iter 92000, loss: 0.011651
 >> iter 93000, loss: 0.011644
 >> iter 94000, loss: 0.011575
 >> iter 95000, loss: 0.011592
 >> iter 96000, loss: 0.011532
 >> iter 97000, loss: 0.011558
 >> iter 98000, loss: 0.011503
 >> iter 99000, loss: 0.011538
 >> iter 100000, loss: 0.011492
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

