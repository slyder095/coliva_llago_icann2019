 > Problema: tomita5nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.3
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 15.681100
 >> iter 2000, loss: 10.577814
 >> iter 3000, loss: 8.690381
 >> iter 4000, loss: 7.979287
 >> iter 5000, loss: 7.695406
 >> iter 6000, loss: 7.211434
 >> iter 7000, loss: 6.248582
 >> iter 8000, loss: 5.683426
 >> iter 9000, loss: 5.263521
 >> iter 10000, loss: 2.265324
   Number of active neurons: 10
 >> iter 11000, loss: 0.859367
 >> iter 12000, loss: 0.333083
 >> iter 13000, loss: 0.150567
 >> iter 14000, loss: 0.065809
 >> iter 15000, loss: 0.035843
 >> iter 16000, loss: 0.021139
 >> iter 17000, loss: 0.013698
 >> iter 18000, loss: 0.010418
 >> iter 19000, loss: 0.008794
 >> iter 20000, loss: 0.007582
   Number of active neurons: 10
 >> iter 21000, loss: 0.006818
 >> iter 22000, loss: 0.006204
 >> iter 23000, loss: 0.005882
 >> iter 24000, loss: 0.005429
 >> iter 25000, loss: 0.005191
 >> iter 26000, loss: 0.004649
 >> iter 27000, loss: 0.004235
 >> iter 28000, loss: 0.003915
 >> iter 29000, loss: 0.003784
 >> iter 30000, loss: 0.003532
   Number of active neurons: 10
 >> iter 31000, loss: 0.003305
 >> iter 32000, loss: 0.003156
 >> iter 33000, loss: 0.003045
 >> iter 34000, loss: 0.002940
 >> iter 35000, loss: 0.002896
 >> iter 36000, loss: 0.002690
 >> iter 37000, loss: 0.002533
 >> iter 38000, loss: 0.002486
 >> iter 39000, loss: 0.002383
 >> iter 40000, loss: 0.002358
   Number of active neurons: 10
 >> iter 41000, loss: 0.002323
 >> iter 42000, loss: 0.067521
 >> iter 43000, loss: 0.027025
 >> iter 44000, loss: 0.011813
 >> iter 45000, loss: 0.005999
 >> iter 46000, loss: 0.003799
 >> iter 47000, loss: 0.002827
 >> iter 48000, loss: 0.002447
 >> iter 49000, loss: 0.002224
 >> iter 50000, loss: 0.002136
   Number of active neurons: 10
 >> iter 51000, loss: 0.002039
 >> iter 52000, loss: 0.001944
 >> iter 53000, loss: 0.001881
 >> iter 54000, loss: 0.001845
 >> iter 55000, loss: 0.001785
 >> iter 56000, loss: 0.001828
 >> iter 57000, loss: 0.001696
 >> iter 58000, loss: 0.001675
 >> iter 59000, loss: 0.001616
 >> iter 60000, loss: 0.001585
   Number of active neurons: 10
 >> iter 61000, loss: 0.001554
 >> iter 62000, loss: 0.001494
 >> iter 63000, loss: 0.001424
 >> iter 64000, loss: 0.001400
 >> iter 65000, loss: 0.001356
 >> iter 66000, loss: 0.001361
 >> iter 67000, loss: 0.001316
 >> iter 68000, loss: 0.001361
 >> iter 69000, loss: 0.001274
 >> iter 70000, loss: 0.001241
   Number of active neurons: 10
 >> iter 71000, loss: 0.001218
 >> iter 72000, loss: 0.001180
 >> iter 73000, loss: 0.001143
 >> iter 74000, loss: 0.001137
 >> iter 75000, loss: 0.001110
 >> iter 76000, loss: 0.001098
 >> iter 77000, loss: 0.001129
 >> iter 78000, loss: 0.001145
 >> iter 79000, loss: 0.001076
 >> iter 80000, loss: 0.001051
   Number of active neurons: 10
 >> iter 81000, loss: 0.001055
 >> iter 82000, loss: 0.001226
 >> iter 83000, loss: 0.001069
 >> iter 84000, loss: 0.001012
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.600562
 >> iter 2000, loss: 10.556219
 >> iter 3000, loss: 8.694605
 >> iter 4000, loss: 8.008189
 >> iter 5000, loss: 7.751882
 >> iter 6000, loss: 7.670283
 >> iter 7000, loss: 7.569755
 >> iter 8000, loss: 7.116114
 >> iter 9000, loss: 3.724339
 >> iter 10000, loss: 1.418872
   Number of active neurons: 10
 >> iter 11000, loss: 0.543773
 >> iter 12000, loss: 0.213912
 >> iter 13000, loss: 0.089613
 >> iter 14000, loss: 0.041216
 >> iter 15000, loss: 0.022192
 >> iter 16000, loss: 0.013981
 >> iter 17000, loss: 0.010431
 >> iter 18000, loss: 0.008451
 >> iter 19000, loss: 0.007294
 >> iter 20000, loss: 0.006454
   Number of active neurons: 10
 >> iter 21000, loss: 0.005865
 >> iter 22000, loss: 0.005329
 >> iter 23000, loss: 0.005013
 >> iter 24000, loss: 0.004649
 >> iter 25000, loss: 0.004354
 >> iter 26000, loss: 0.004038
 >> iter 27000, loss: 0.003892
 >> iter 28000, loss: 0.003620
 >> iter 29000, loss: 0.003481
 >> iter 30000, loss: 0.003265
   Number of active neurons: 10
 >> iter 31000, loss: 0.003168
 >> iter 32000, loss: 0.003002
 >> iter 33000, loss: 0.002855
 >> iter 34000, loss: 0.002729
 >> iter 35000, loss: 0.002654
 >> iter 36000, loss: 0.002540
 >> iter 37000, loss: 0.002456
 >> iter 38000, loss: 0.002357
 >> iter 39000, loss: 0.002268
 >> iter 40000, loss: 0.002194
   Number of active neurons: 10
 >> iter 41000, loss: 0.002171
 >> iter 42000, loss: 0.002118
 >> iter 43000, loss: 0.002055
 >> iter 44000, loss: 0.001941
 >> iter 45000, loss: 0.025223
 >> iter 46000, loss: 0.010934
 >> iter 47000, loss: 0.005466
 >> iter 48000, loss: 0.003324
 >> iter 49000, loss: 0.002471
 >> iter 50000, loss: 0.002080
   Number of active neurons: 10
 >> iter 51000, loss: 0.001870
 >> iter 52000, loss: 0.001751
 >> iter 53000, loss: 0.001684
 >> iter 54000, loss: 0.001609
 >> iter 55000, loss: 0.001580
 >> iter 56000, loss: 0.001539
 >> iter 57000, loss: 0.001512
 >> iter 58000, loss: 0.001432
 >> iter 59000, loss: 0.001428
 >> iter 60000, loss: 0.001378
   Number of active neurons: 10
 >> iter 61000, loss: 0.001362
 >> iter 62000, loss: 0.001324
 >> iter 63000, loss: 0.001283
 >> iter 64000, loss: 0.001246
 >> iter 65000, loss: 0.001225
 >> iter 66000, loss: 0.001195
 >> iter 67000, loss: 0.001184
 >> iter 68000, loss: 0.001151
 >> iter 69000, loss: 0.001140
 >> iter 70000, loss: 0.001115
   Number of active neurons: 10
 >> iter 71000, loss: 0.001105
 >> iter 72000, loss: 0.001080
 >> iter 73000, loss: 0.001069
 >> iter 74000, loss: 0.001036
 >> iter 75000, loss: 0.001028
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.622070
 >> iter 2000, loss: 10.544768
 >> iter 3000, loss: 8.662554
 >> iter 4000, loss: 7.960979
 >> iter 5000, loss: 7.681263
 >> iter 6000, loss: 7.220186
 >> iter 7000, loss: 6.495866
 >> iter 8000, loss: 2.582533
 >> iter 9000, loss: 1.018826
 >> iter 10000, loss: 0.396067
   Number of active neurons: 10
 >> iter 11000, loss: 0.160364
 >> iter 12000, loss: 0.069972
 >> iter 13000, loss: 0.034978
 >> iter 14000, loss: 0.020503
 >> iter 15000, loss: 0.014298
 >> iter 16000, loss: 0.011242
 >> iter 17000, loss: 0.009374
 >> iter 18000, loss: 0.008179
 >> iter 19000, loss: 0.007351
 >> iter 20000, loss: 0.006728
   Number of active neurons: 10
 >> iter 21000, loss: 0.006199
 >> iter 22000, loss: 0.005679
 >> iter 23000, loss: 0.005372
 >> iter 24000, loss: 0.004942
 >> iter 25000, loss: 0.004811
 >> iter 26000, loss: 0.004449
 >> iter 27000, loss: 0.004151
 >> iter 28000, loss: 0.003995
 >> iter 29000, loss: 0.003792
 >> iter 30000, loss: 0.003775
   Number of active neurons: 10
 >> iter 31000, loss: 0.003491
 >> iter 32000, loss: 0.003309
 >> iter 33000, loss: 0.003150
 >> iter 34000, loss: 0.002986
 >> iter 35000, loss: 0.002897
 >> iter 36000, loss: 0.002792
 >> iter 37000, loss: 0.002666
 >> iter 38000, loss: 0.002654
 >> iter 39000, loss: 0.002623
 >> iter 40000, loss: 0.002491
   Number of active neurons: 10
 >> iter 41000, loss: 0.002380
 >> iter 42000, loss: 0.002249
 >> iter 43000, loss: 0.002197
 >> iter 44000, loss: 0.002131
 >> iter 45000, loss: 0.002082
 >> iter 46000, loss: 0.002033
 >> iter 47000, loss: 0.002073
 >> iter 48000, loss: 0.001976
 >> iter 49000, loss: 0.001897
 >> iter 50000, loss: 0.001838
   Number of active neurons: 10
 >> iter 51000, loss: 0.001793
 >> iter 52000, loss: 0.001779
 >> iter 53000, loss: 0.001724
 >> iter 54000, loss: 0.001661
 >> iter 55000, loss: 0.001631
 >> iter 56000, loss: 0.035362
 >> iter 57000, loss: 0.014418
 >> iter 58000, loss: 0.006495
 >> iter 59000, loss: 0.003526
 >> iter 60000, loss: 0.002400
   Number of active neurons: 10
 >> iter 61000, loss: 0.001921
 >> iter 62000, loss: 0.001716
 >> iter 63000, loss: 0.001620
 >> iter 64000, loss: 0.001533
 >> iter 65000, loss: 0.001487
 >> iter 66000, loss: 0.001430
 >> iter 67000, loss: 0.001424
 >> iter 68000, loss: 0.001366
 >> iter 69000, loss: 0.001341
 >> iter 70000, loss: 0.001309
   Number of active neurons: 10
 >> iter 71000, loss: 0.001296
 >> iter 72000, loss: 0.001267
 >> iter 73000, loss: 0.001237
 >> iter 74000, loss: 0.001207
 >> iter 75000, loss: 0.001196
 >> iter 76000, loss: 0.001209
 >> iter 77000, loss: 0.001362
 >> iter 78000, loss: 0.001220
 >> iter 79000, loss: 0.001148
 >> iter 80000, loss: 0.001430
   Number of active neurons: 10
 >> iter 81000, loss: 0.001226
 >> iter 82000, loss: 0.001133
 >> iter 83000, loss: 0.001097
 >> iter 84000, loss: 0.001069
 >> iter 85000, loss: 0.001063
 >> iter 86000, loss: 0.001047
 >> iter 87000, loss: 0.001025
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.610749
 >> iter 2000, loss: 10.520402
 >> iter 3000, loss: 8.646991
 >> iter 4000, loss: 7.938203
 >> iter 5000, loss: 7.681023
 >> iter 6000, loss: 7.567349
 >> iter 7000, loss: 7.539478
 >> iter 8000, loss: 7.387893
 >> iter 9000, loss: 6.752259
 >> iter 10000, loss: 5.973118
   Number of active neurons: 10
 >> iter 11000, loss: 5.366393
 >> iter 12000, loss: 2.514280
 >> iter 13000, loss: 0.952782
 >> iter 14000, loss: 0.367938
 >> iter 15000, loss: 0.164669
 >> iter 16000, loss: 0.070231
 >> iter 17000, loss: 0.033436
 >> iter 18000, loss: 0.018649
 >> iter 19000, loss: 0.012346
 >> iter 20000, loss: 0.009420
   Number of active neurons: 10
 >> iter 21000, loss: 0.007951
 >> iter 22000, loss: 0.007012
 >> iter 23000, loss: 0.006209
 >> iter 24000, loss: 0.006312
 >> iter 25000, loss: 0.005505
 >> iter 26000, loss: 0.005104
 >> iter 27000, loss: 0.004724
 >> iter 28000, loss: 0.004534
 >> iter 29000, loss: 0.004019
 >> iter 30000, loss: 0.013874
   Number of active neurons: 10
 >> iter 31000, loss: 0.007723
 >> iter 32000, loss: 0.005144
 >> iter 33000, loss: 0.003963
 >> iter 34000, loss: 0.003421
 >> iter 35000, loss: 0.003145
 >> iter 36000, loss: 0.002903
 >> iter 37000, loss: 0.002771
 >> iter 38000, loss: 0.002583
 >> iter 39000, loss: 0.002468
 >> iter 40000, loss: 0.002374
   Number of active neurons: 10
 >> iter 41000, loss: 0.002300
 >> iter 42000, loss: 0.002222
 >> iter 43000, loss: 0.002125
 >> iter 44000, loss: 0.002030
 >> iter 45000, loss: 0.002125
 >> iter 46000, loss: 0.002057
 >> iter 47000, loss: 0.001966
 >> iter 48000, loss: 0.001856
 >> iter 49000, loss: 0.001798
 >> iter 50000, loss: 0.001740
   Number of active neurons: 10
 >> iter 51000, loss: 0.001662
 >> iter 52000, loss: 0.001674
 >> iter 53000, loss: 0.001615
 >> iter 54000, loss: 0.001552
 >> iter 55000, loss: 0.129684
 >> iter 56000, loss: 0.049718
 >> iter 57000, loss: 0.019790
 >> iter 58000, loss: 0.008598
 >> iter 59000, loss: 0.004375
 >> iter 60000, loss: 0.002803
   Number of active neurons: 10
 >> iter 61000, loss: 0.002123
 >> iter 62000, loss: 0.001928
 >> iter 63000, loss: 0.001725
 >> iter 64000, loss: 0.001627
 >> iter 65000, loss: 0.001588
 >> iter 66000, loss: 0.001669
 >> iter 67000, loss: 0.001533
 >> iter 68000, loss: 0.001454
 >> iter 69000, loss: 0.001392
 >> iter 70000, loss: 0.001388
   Number of active neurons: 10
 >> iter 71000, loss: 0.001338
 >> iter 72000, loss: 0.001382
 >> iter 73000, loss: 0.001324
 >> iter 74000, loss: 0.001281
 >> iter 75000, loss: 0.001226
 >> iter 76000, loss: 0.001207
 >> iter 77000, loss: 0.001185
 >> iter 78000, loss: 0.001153
 >> iter 79000, loss: 0.001113
 >> iter 80000, loss: 0.001096
   Number of active neurons: 10
 >> iter 81000, loss: 0.001100
 >> iter 82000, loss: 0.001053
 >> iter 83000, loss: 0.001045
 >> iter 84000, loss: 0.001030
 >> iter 85000, loss: 0.001010
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.623360
 >> iter 2000, loss: 10.533614
 >> iter 3000, loss: 8.653786
 >> iter 4000, loss: 7.940302
 >> iter 5000, loss: 7.666398
 >> iter 6000, loss: 7.313712
 >> iter 7000, loss: 6.419121
 >> iter 8000, loss: 5.601552
 >> iter 9000, loss: 4.467107
 >> iter 10000, loss: 1.774502
   Number of active neurons: 10
 >> iter 11000, loss: 0.696069
 >> iter 12000, loss: 0.281385
 >> iter 13000, loss: 0.123893
 >> iter 14000, loss: 0.125085
 >> iter 15000, loss: 0.060995
 >> iter 16000, loss: 0.035508
 >> iter 17000, loss: 0.023437
 >> iter 18000, loss: 0.031066
 >> iter 19000, loss: 0.021363
 >> iter 20000, loss: 0.015743
   Number of active neurons: 10
 >> iter 21000, loss: 0.013034
 >> iter 22000, loss: 0.036494
 >> iter 23000, loss: 0.044423
 >> iter 24000, loss: 0.178909
 >> iter 25000, loss: 0.073424
 >> iter 26000, loss: 0.033249
 >> iter 27000, loss: 0.017886
 >> iter 28000, loss: 0.022630
 >> iter 29000, loss: 0.059319
 >> iter 30000, loss: 0.027049
   Number of active neurons: 10
 >> iter 31000, loss: 0.014346
 >> iter 32000, loss: 0.009258
 >> iter 33000, loss: 0.016767
 >> iter 34000, loss: 0.137123
 >> iter 35000, loss: 0.064838
 >> iter 36000, loss: 0.028142
 >> iter 37000, loss: 0.014313
 >> iter 38000, loss: 0.012463
 >> iter 39000, loss: 0.008195
 >> iter 40000, loss: 0.006381
   Number of active neurons: 10
 >> iter 41000, loss: 0.005498
 >> iter 42000, loss: 0.005068
 >> iter 43000, loss: 0.027570
 >> iter 44000, loss: 0.013090
 >> iter 45000, loss: 0.007482
 >> iter 46000, loss: 0.010331
 >> iter 47000, loss: 0.006365
 >> iter 48000, loss: 0.004721
 >> iter 49000, loss: 0.004069
 >> iter 50000, loss: 0.003705
   Number of active neurons: 10
 >> iter 51000, loss: 0.003502
 >> iter 52000, loss: 0.003226
 >> iter 53000, loss: 0.003056
 >> iter 54000, loss: 0.002932
 >> iter 55000, loss: 0.002856
 >> iter 56000, loss: 0.010210
 >> iter 57000, loss: 0.005726
 >> iter 58000, loss: 0.006542
 >> iter 59000, loss: 0.004603
 >> iter 60000, loss: 0.003589
   Number of active neurons: 10
 >> iter 61000, loss: 0.003089
 >> iter 62000, loss: 0.002791
 >> iter 63000, loss: 0.002688
 >> iter 64000, loss: 0.002593
 >> iter 65000, loss: 0.002399
 >> iter 66000, loss: 0.002450
 >> iter 67000, loss: 0.003278
 >> iter 68000, loss: 0.002921
 >> iter 69000, loss: 0.002560
 >> iter 70000, loss: 0.002317
   Number of active neurons: 10
 >> iter 71000, loss: 0.002561
 >> iter 72000, loss: 0.002303
 >> iter 73000, loss: 0.002180
 >> iter 74000, loss: 0.002088
 >> iter 75000, loss: 0.002033
 >> iter 76000, loss: 0.001972
 >> iter 77000, loss: 0.001956
 >> iter 78000, loss: 0.001902
 >> iter 79000, loss: 0.001776
 >> iter 80000, loss: 0.001744
   Number of active neurons: 10
 >> iter 81000, loss: 0.001686
 >> iter 82000, loss: 0.001641
 >> iter 83000, loss: 0.001590
 >> iter 84000, loss: 0.002079
 >> iter 85000, loss: 0.001815
 >> iter 86000, loss: 0.001703
 >> iter 87000, loss: 0.001758
 >> iter 88000, loss: 0.001621
 >> iter 89000, loss: 0.001533
 >> iter 90000, loss: 0.001526
   Number of active neurons: 10
 >> iter 91000, loss: 0.001476
 >> iter 92000, loss: 0.001439
 >> iter 93000, loss: 0.001634
 >> iter 94000, loss: 0.001560
 >> iter 95000, loss: 0.001491
 >> iter 96000, loss: 0.001486
 >> iter 97000, loss: 0.001413
 >> iter 98000, loss: 0.001359
 >> iter 99000, loss: 0.001420
 >> iter 100000, loss: 0.001332
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 15.771653
 >> iter 2000, loss: 10.612105
 >> iter 3000, loss: 8.705295
 >> iter 4000, loss: 7.983637
 >> iter 5000, loss: 7.721433
 >> iter 6000, loss: 7.609133
 >> iter 7000, loss: 7.319180
 >> iter 8000, loss: 6.608841
 >> iter 9000, loss: 6.020415
 >> iter 10000, loss: 5.485930
   Number of active neurons: 10
 >> iter 11000, loss: 5.020051
 >> iter 12000, loss: 4.784916
 >> iter 13000, loss: 3.184288
 >> iter 14000, loss: 1.390949
 >> iter 15000, loss: 0.583098
 >> iter 16000, loss: 0.254058
 >> iter 17000, loss: 0.111293
 >> iter 18000, loss: 0.054847
 >> iter 19000, loss: 0.032478
 >> iter 20000, loss: 0.054029
   Number of active neurons: 10
 >> iter 21000, loss: 0.029264
 >> iter 22000, loss: 0.143340
 >> iter 23000, loss: 0.102783
 >> iter 24000, loss: 0.046686
 >> iter 25000, loss: 0.023898
 >> iter 26000, loss: 0.014545
 >> iter 27000, loss: 0.010715
 >> iter 28000, loss: 0.008426
 >> iter 29000, loss: 0.007169
 >> iter 30000, loss: 0.006328
   Number of active neurons: 10
 >> iter 31000, loss: 0.006420
 >> iter 32000, loss: 0.005794
 >> iter 33000, loss: 0.005156
 >> iter 34000, loss: 0.009011
 >> iter 35000, loss: 0.006607
 >> iter 36000, loss: 0.005255
 >> iter 37000, loss: 0.004368
 >> iter 38000, loss: 0.004093
 >> iter 39000, loss: 0.003667
 >> iter 40000, loss: 0.003427
   Number of active neurons: 10
 >> iter 41000, loss: 0.003244
 >> iter 42000, loss: 0.003100
 >> iter 43000, loss: 0.003009
 >> iter 44000, loss: 0.002968
 >> iter 45000, loss: 0.002746
 >> iter 46000, loss: 0.002604
 >> iter 47000, loss: 0.002556
 >> iter 48000, loss: 0.002511
 >> iter 49000, loss: 0.002496
 >> iter 50000, loss: 0.002423
   Number of active neurons: 10
 >> iter 51000, loss: 0.002157
 >> iter 52000, loss: 0.002622
 >> iter 53000, loss: 0.002310
 >> iter 54000, loss: 0.005275
 >> iter 55000, loss: 0.003394
 >> iter 56000, loss: 0.002627
 >> iter 57000, loss: 0.002140
 >> iter 58000, loss: 0.002088
 >> iter 59000, loss: 0.001878
 >> iter 60000, loss: 0.001922
   Number of active neurons: 10
 >> iter 61000, loss: 0.001723
 >> iter 62000, loss: 0.001635
 >> iter 63000, loss: 0.001545
 >> iter 64000, loss: 0.001535
 >> iter 65000, loss: 0.001466
 >> iter 66000, loss: 0.001448
 >> iter 67000, loss: 0.001415
 >> iter 68000, loss: 0.001386
 >> iter 69000, loss: 0.001312
 >> iter 70000, loss: 0.001365
   Number of active neurons: 10
 >> iter 71000, loss: 0.001286
 >> iter 72000, loss: 0.001235
 >> iter 73000, loss: 0.001207
 >> iter 74000, loss: 0.001212
 >> iter 75000, loss: 0.001165
 >> iter 76000, loss: 0.001142
 >> iter 77000, loss: 0.001199
 >> iter 78000, loss: 0.001117
 >> iter 79000, loss: 0.001094
 >> iter 80000, loss: 0.001076
   Number of active neurons: 10
 >> iter 81000, loss: 0.001065
 >> iter 82000, loss: 0.001056
 >> iter 83000, loss: 0.001051
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.570862
 >> iter 2000, loss: 10.531756
 >> iter 3000, loss: 8.672231
 >> iter 4000, loss: 7.978175
 >> iter 5000, loss: 7.730704
 >> iter 6000, loss: 7.621564
 >> iter 7000, loss: 7.592478
 >> iter 8000, loss: 7.566038
 >> iter 9000, loss: 7.562648
 >> iter 10000, loss: 7.404082
   Number of active neurons: 10
 >> iter 11000, loss: 7.007272
 >> iter 12000, loss: 6.328898
 >> iter 13000, loss: 5.736464
 >> iter 14000, loss: 5.291138
 >> iter 15000, loss: 2.880793
 >> iter 16000, loss: 1.158494
 >> iter 17000, loss: 0.571096
 >> iter 18000, loss: 0.233870
 >> iter 19000, loss: 0.099402
 >> iter 20000, loss: 0.046797
   Number of active neurons: 10
 >> iter 21000, loss: 0.090833
 >> iter 22000, loss: 0.042297
 >> iter 23000, loss: 0.022732
 >> iter 24000, loss: 0.014426
 >> iter 25000, loss: 0.010528
 >> iter 26000, loss: 0.010160
 >> iter 27000, loss: 0.008109
 >> iter 28000, loss: 0.007396
 >> iter 29000, loss: 0.006318
 >> iter 30000, loss: 0.005640
   Number of active neurons: 10
 >> iter 31000, loss: 0.005171
 >> iter 32000, loss: 0.005127
 >> iter 33000, loss: 0.004616
 >> iter 34000, loss: 0.004231
 >> iter 35000, loss: 0.003933
 >> iter 36000, loss: 0.003671
 >> iter 37000, loss: 0.003504
 >> iter 38000, loss: 0.003351
 >> iter 39000, loss: 0.003199
 >> iter 40000, loss: 0.003333
   Number of active neurons: 10
 >> iter 41000, loss: 0.010329
 >> iter 42000, loss: 0.006079
 >> iter 43000, loss: 0.004173
 >> iter 44000, loss: 0.003259
 >> iter 45000, loss: 0.003501
 >> iter 46000, loss: 0.003014
 >> iter 47000, loss: 0.002699
 >> iter 48000, loss: 0.002535
 >> iter 49000, loss: 0.010856
 >> iter 50000, loss: 0.006097
   Number of active neurons: 10
 >> iter 51000, loss: 0.003928
 >> iter 52000, loss: 0.003010
 >> iter 53000, loss: 0.002558
 >> iter 54000, loss: 0.002515
 >> iter 55000, loss: 0.002269
 >> iter 56000, loss: 0.002094
 >> iter 57000, loss: 0.001995
 >> iter 58000, loss: 0.001917
 >> iter 59000, loss: 0.001867
 >> iter 60000, loss: 0.001790
   Number of active neurons: 10
 >> iter 61000, loss: 0.001733
 >> iter 62000, loss: 0.001669
 >> iter 63000, loss: 0.001639
 >> iter 64000, loss: 0.001603
 >> iter 65000, loss: 0.001559
 >> iter 66000, loss: 0.001521
 >> iter 67000, loss: 0.001504
 >> iter 68000, loss: 0.001506
 >> iter 69000, loss: 0.001455
 >> iter 70000, loss: 0.001405
   Number of active neurons: 10
 >> iter 71000, loss: 0.001372
 >> iter 72000, loss: 0.001338
 >> iter 73000, loss: 0.001333
 >> iter 74000, loss: 0.001294
 >> iter 75000, loss: 0.001262
 >> iter 76000, loss: 0.001227
 >> iter 77000, loss: 0.001212
 >> iter 78000, loss: 0.001191
 >> iter 79000, loss: 0.001167
 >> iter 80000, loss: 0.001146
   Number of active neurons: 10
 >> iter 81000, loss: 0.001668
 >> iter 82000, loss: 0.001406
 >> iter 83000, loss: 0.001311
 >> iter 84000, loss: 0.001249
 >> iter 85000, loss: 0.001549
 >> iter 86000, loss: 0.047941
 >> iter 87000, loss: 0.018743
 >> iter 88000, loss: 0.007816
 >> iter 89000, loss: 0.003759
 >> iter 90000, loss: 0.002209
   Number of active neurons: 10
 >> iter 91000, loss: 0.001612
 >> iter 92000, loss: 0.001345
 >> iter 93000, loss: 0.001249
 >> iter 94000, loss: 0.001274
 >> iter 95000, loss: 0.001183
 >> iter 96000, loss: 0.001132
 >> iter 97000, loss: 0.001092
 >> iter 98000, loss: 0.001066
 >> iter 99000, loss: 0.001042
 >> iter 100000, loss: 0.002106
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.600389
 >> iter 2000, loss: 10.542227
 >> iter 3000, loss: 8.673524
 >> iter 4000, loss: 7.966743
 >> iter 5000, loss: 7.597809
 >> iter 6000, loss: 6.764725
 >> iter 7000, loss: 5.923575
 >> iter 8000, loss: 5.429099
 >> iter 9000, loss: 2.554334
 >> iter 10000, loss: 1.092231
   Number of active neurons: 10
 >> iter 11000, loss: 0.472199
 >> iter 12000, loss: 0.204334
 >> iter 13000, loss: 0.111594
 >> iter 14000, loss: 0.063549
 >> iter 15000, loss: 0.039689
 >> iter 16000, loss: 0.035567
 >> iter 17000, loss: 0.051868
 >> iter 18000, loss: 0.051855
 >> iter 19000, loss: 0.029334
 >> iter 20000, loss: 0.019774
   Number of active neurons: 10
 >> iter 21000, loss: 0.015608
 >> iter 22000, loss: 0.013235
 >> iter 23000, loss: 0.011845
 >> iter 24000, loss: 0.011324
 >> iter 25000, loss: 0.047905
 >> iter 26000, loss: 0.023680
 >> iter 27000, loss: 0.014074
 >> iter 28000, loss: 0.010126
 >> iter 29000, loss: 0.008655
 >> iter 30000, loss: 0.007647
   Number of active neurons: 10
 >> iter 31000, loss: 0.006997
 >> iter 32000, loss: 0.006557
 >> iter 33000, loss: 0.006202
 >> iter 34000, loss: 0.005957
 >> iter 35000, loss: 0.005568
 >> iter 36000, loss: 0.005340
 >> iter 37000, loss: 0.005214
 >> iter 38000, loss: 0.005000
 >> iter 39000, loss: 0.004733
 >> iter 40000, loss: 0.004586
   Number of active neurons: 10
 >> iter 41000, loss: 0.004518
 >> iter 42000, loss: 0.004303
 >> iter 43000, loss: 0.004069
 >> iter 44000, loss: 0.033174
 >> iter 45000, loss: 0.014842
 >> iter 46000, loss: 0.007942
 >> iter 47000, loss: 0.005351
 >> iter 48000, loss: 0.004237
 >> iter 49000, loss: 0.268257
 >> iter 50000, loss: 0.102829
   Number of active neurons: 10
 >> iter 51000, loss: 0.041653
 >> iter 52000, loss: 0.020242
 >> iter 53000, loss: 0.010435
 >> iter 54000, loss: 0.006642
 >> iter 55000, loss: 0.005111
 >> iter 56000, loss: 0.004680
 >> iter 57000, loss: 0.045985
 >> iter 58000, loss: 0.019583
 >> iter 59000, loss: 0.009715
 >> iter 60000, loss: 0.006060
   Number of active neurons: 10
 >> iter 61000, loss: 0.004487
 >> iter 62000, loss: 0.003821
 >> iter 63000, loss: 0.003589
 >> iter 64000, loss: 0.003500
 >> iter 65000, loss: 0.004857
 >> iter 66000, loss: 0.003987
 >> iter 67000, loss: 0.003477
 >> iter 68000, loss: 0.033462
 >> iter 69000, loss: 0.014337
 >> iter 70000, loss: 0.007168
   Number of active neurons: 10
 >> iter 71000, loss: 0.004432
 >> iter 72000, loss: 0.003416
 >> iter 73000, loss: 0.002955
 >> iter 74000, loss: 0.009446
 >> iter 75000, loss: 0.005204
 >> iter 76000, loss: 0.003611
 >> iter 77000, loss: 0.003610
 >> iter 78000, loss: 0.002980
 >> iter 79000, loss: 0.002636
 >> iter 80000, loss: 0.002473
   Number of active neurons: 10
 >> iter 81000, loss: 0.041463
 >> iter 82000, loss: 0.016964
 >> iter 83000, loss: 0.007998
 >> iter 84000, loss: 0.004523
 >> iter 85000, loss: 0.003183
 >> iter 86000, loss: 0.002673
 >> iter 87000, loss: 0.002459
 >> iter 88000, loss: 0.002312
 >> iter 89000, loss: 0.002264
 >> iter 90000, loss: 0.002146
   Number of active neurons: 10
 >> iter 91000, loss: 0.002047
 >> iter 92000, loss: 0.002018
 >> iter 93000, loss: 0.001930
 >> iter 94000, loss: 0.001876
 >> iter 95000, loss: 0.001881
 >> iter 96000, loss: 0.001854
 >> iter 97000, loss: 0.034667
 >> iter 98000, loss: 0.014419
 >> iter 99000, loss: 0.006636
 >> iter 100000, loss: 0.003741
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.580700
 >> iter 2000, loss: 10.548425
 >> iter 3000, loss: 8.658863
 >> iter 4000, loss: 7.953764
 >> iter 5000, loss: 7.696476
 >> iter 6000, loss: 7.389180
 >> iter 7000, loss: 6.580363
 >> iter 8000, loss: 5.681598
 >> iter 9000, loss: 2.866141
 >> iter 10000, loss: 1.122510
   Number of active neurons: 10
 >> iter 11000, loss: 0.441214
 >> iter 12000, loss: 0.180738
 >> iter 13000, loss: 0.079664
 >> iter 14000, loss: 0.096415
 >> iter 15000, loss: 0.044944
 >> iter 16000, loss: 0.023934
 >> iter 17000, loss: 0.063195
 >> iter 18000, loss: 0.029678
 >> iter 19000, loss: 0.021365
 >> iter 20000, loss: 0.013041
   Number of active neurons: 10
 >> iter 21000, loss: 0.017326
 >> iter 22000, loss: 0.014614
 >> iter 23000, loss: 0.009095
 >> iter 24000, loss: 0.006587
 >> iter 25000, loss: 0.005437
 >> iter 26000, loss: 0.004697
 >> iter 27000, loss: 0.004225
 >> iter 28000, loss: 0.003884
 >> iter 29000, loss: 0.003784
 >> iter 30000, loss: 0.003517
   Number of active neurons: 10
 >> iter 31000, loss: 0.003294
 >> iter 32000, loss: 0.003060
 >> iter 33000, loss: 0.002826
 >> iter 34000, loss: 0.002713
 >> iter 35000, loss: 0.002653
 >> iter 36000, loss: 0.002519
 >> iter 37000, loss: 0.002355
 >> iter 38000, loss: 0.002310
 >> iter 39000, loss: 0.002186
 >> iter 40000, loss: 0.002124
   Number of active neurons: 10
 >> iter 41000, loss: 0.003775
 >> iter 42000, loss: 0.002848
 >> iter 43000, loss: 0.002336
 >> iter 44000, loss: 0.002100
 >> iter 45000, loss: 0.001979
 >> iter 46000, loss: 0.001846
 >> iter 47000, loss: 0.001787
 >> iter 48000, loss: 0.001735
 >> iter 49000, loss: 0.001654
 >> iter 50000, loss: 0.001573
   Number of active neurons: 10
 >> iter 51000, loss: 0.001546
 >> iter 52000, loss: 0.001465
 >> iter 53000, loss: 0.001450
 >> iter 54000, loss: 0.001398
 >> iter 55000, loss: 0.001360
 >> iter 56000, loss: 0.001362
 >> iter 57000, loss: 0.001323
 >> iter 58000, loss: 0.001280
 >> iter 59000, loss: 0.001266
 >> iter 60000, loss: 0.001200
   Number of active neurons: 10
 >> iter 61000, loss: 0.001185
 >> iter 62000, loss: 0.001136
 >> iter 63000, loss: 0.001137
 >> iter 64000, loss: 0.001103
 >> iter 65000, loss: 0.001113
 >> iter 66000, loss: 0.001059
 >> iter 67000, loss: 0.001071
 >> iter 68000, loss: 0.001027
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.650776
 >> iter 2000, loss: 10.567880
 >> iter 3000, loss: 8.691868
 >> iter 4000, loss: 7.978978
 >> iter 5000, loss: 7.690807
 >> iter 6000, loss: 7.135961
 >> iter 7000, loss: 6.309018
 >> iter 8000, loss: 5.595488
 >> iter 9000, loss: 3.245661
 >> iter 10000, loss: 1.268143
   Number of active neurons: 10
 >> iter 11000, loss: 0.491790
 >> iter 12000, loss: 0.198162
 >> iter 13000, loss: 0.085112
 >> iter 14000, loss: 0.042938
 >> iter 15000, loss: 0.024199
 >> iter 16000, loss: 0.015716
 >> iter 17000, loss: 0.011729
 >> iter 18000, loss: 0.009984
 >> iter 19000, loss: 0.008418
 >> iter 20000, loss: 0.007600
   Number of active neurons: 10
 >> iter 21000, loss: 0.006958
 >> iter 22000, loss: 0.006426
 >> iter 23000, loss: 0.005842
 >> iter 24000, loss: 0.005315
 >> iter 25000, loss: 0.004898
 >> iter 26000, loss: 0.004889
 >> iter 27000, loss: 0.004571
 >> iter 28000, loss: 0.004384
 >> iter 29000, loss: 0.004029
 >> iter 30000, loss: 0.068183
   Number of active neurons: 10
 >> iter 31000, loss: 0.027831
 >> iter 32000, loss: 0.012553
 >> iter 33000, loss: 0.006906
 >> iter 34000, loss: 0.004567
 >> iter 35000, loss: 0.003690
 >> iter 36000, loss: 0.003217
 >> iter 37000, loss: 0.003045
 >> iter 38000, loss: 0.002956
 >> iter 39000, loss: 0.002765
 >> iter 40000, loss: 0.002593
   Number of active neurons: 10
 >> iter 41000, loss: 0.002504
 >> iter 42000, loss: 0.002429
 >> iter 43000, loss: 0.002356
 >> iter 44000, loss: 0.003154
 >> iter 45000, loss: 0.002559
 >> iter 46000, loss: 0.002262
 >> iter 47000, loss: 0.002132
 >> iter 48000, loss: 0.002232
 >> iter 49000, loss: 0.002073
 >> iter 50000, loss: 0.001993
   Number of active neurons: 10
 >> iter 51000, loss: 0.001882
 >> iter 52000, loss: 0.001797
 >> iter 53000, loss: 0.001791
 >> iter 54000, loss: 0.001754
 >> iter 55000, loss: 0.001697
 >> iter 56000, loss: 0.001626
 >> iter 57000, loss: 0.001569
 >> iter 58000, loss: 0.001533
 >> iter 59000, loss: 0.001628
 >> iter 60000, loss: 0.001549
   Number of active neurons: 10
 >> iter 61000, loss: 0.001457
 >> iter 62000, loss: 0.001418
 >> iter 63000, loss: 0.001426
 >> iter 64000, loss: 0.001376
 >> iter 65000, loss: 0.001336
 >> iter 66000, loss: 0.001285
 >> iter 67000, loss: 0.001297
 >> iter 68000, loss: 0.001303
 >> iter 69000, loss: 0.001229
 >> iter 70000, loss: 0.001189
   Number of active neurons: 10
 >> iter 71000, loss: 0.001168
 >> iter 72000, loss: 0.001141
 >> iter 73000, loss: 0.001130
 >> iter 74000, loss: 0.001125
 >> iter 75000, loss: 0.001110
 >> iter 76000, loss: 0.001084
 >> iter 77000, loss: 0.001083
 >> iter 78000, loss: 0.001031
 >> iter 79000, loss: 0.001024
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.649695
 >> iter 2000, loss: 10.556971
 >> iter 3000, loss: 8.675705
 >> iter 4000, loss: 7.962537
 >> iter 5000, loss: 7.705538
 >> iter 6000, loss: 7.605057
 >> iter 7000, loss: 7.576346
 >> iter 8000, loss: 7.439471
 >> iter 9000, loss: 6.652286
 >> iter 10000, loss: 5.857770
   Number of active neurons: 10
 >> iter 11000, loss: 5.304176
 >> iter 12000, loss: 3.708618
 >> iter 13000, loss: 1.609577
 >> iter 14000, loss: 0.665412
 >> iter 15000, loss: 0.293859
 >> iter 16000, loss: 0.132631
 >> iter 17000, loss: 0.129207
 >> iter 18000, loss: 0.059452
 >> iter 19000, loss: 0.040801
 >> iter 20000, loss: 0.022501
   Number of active neurons: 10
 >> iter 21000, loss: 0.014412
 >> iter 22000, loss: 0.010353
 >> iter 23000, loss: 0.008157
 >> iter 24000, loss: 0.007005
 >> iter 25000, loss: 0.006028
 >> iter 26000, loss: 0.005384
 >> iter 27000, loss: 0.005042
 >> iter 28000, loss: 0.004519
 >> iter 29000, loss: 0.004409
 >> iter 30000, loss: 0.004350
   Number of active neurons: 10
 >> iter 31000, loss: 0.033347
 >> iter 32000, loss: 0.015007
 >> iter 33000, loss: 0.007982
 >> iter 34000, loss: 0.004965
 >> iter 35000, loss: 0.003707
 >> iter 36000, loss: 0.003251
 >> iter 37000, loss: 0.002925
 >> iter 38000, loss: 0.002646
 >> iter 39000, loss: 0.002474
 >> iter 40000, loss: 0.002360
   Number of active neurons: 10
 >> iter 41000, loss: 0.006741
 >> iter 42000, loss: 0.004229
 >> iter 43000, loss: 0.003008
 >> iter 44000, loss: 0.002478
 >> iter 45000, loss: 0.002150
 >> iter 46000, loss: 0.002005
 >> iter 47000, loss: 0.001906
 >> iter 48000, loss: 0.002010
 >> iter 49000, loss: 0.001839
 >> iter 50000, loss: 0.001797
   Number of active neurons: 10
 >> iter 51000, loss: 0.001618
 >> iter 52000, loss: 0.001576
 >> iter 53000, loss: 0.001540
 >> iter 54000, loss: 0.002783
 >> iter 55000, loss: 0.002114
 >> iter 56000, loss: 0.001777
 >> iter 57000, loss: 0.001563
 >> iter 58000, loss: 0.001429
 >> iter 59000, loss: 0.001381
 >> iter 60000, loss: 0.001332
   Number of active neurons: 10
 >> iter 61000, loss: 0.001269
 >> iter 62000, loss: 0.001224
 >> iter 63000, loss: 0.001162
 >> iter 64000, loss: 0.001126
 >> iter 65000, loss: 0.001125
 >> iter 66000, loss: 0.001084
 >> iter 67000, loss: 0.001065
 >> iter 68000, loss: 0.001071
 >> iter 69000, loss: 0.001007
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.584836
 >> iter 2000, loss: 10.551263
 >> iter 3000, loss: 8.679128
 >> iter 4000, loss: 7.977190
 >> iter 5000, loss: 7.717796
 >> iter 6000, loss: 7.609474
 >> iter 7000, loss: 7.581344
 >> iter 8000, loss: 7.555297
 >> iter 9000, loss: 7.451081
 >> iter 10000, loss: 6.950757
   Number of active neurons: 10
 >> iter 11000, loss: 3.982987
 >> iter 12000, loss: 1.509493
 >> iter 13000, loss: 0.577344
 >> iter 14000, loss: 0.227039
 >> iter 15000, loss: 0.094488
 >> iter 16000, loss: 0.043581
 >> iter 17000, loss: 0.023438
 >> iter 18000, loss: 0.014839
 >> iter 19000, loss: 0.010934
 >> iter 20000, loss: 0.009094
   Number of active neurons: 10
 >> iter 21000, loss: 0.007682
 >> iter 22000, loss: 0.006700
 >> iter 23000, loss: 0.006100
 >> iter 24000, loss: 0.005562
 >> iter 25000, loss: 0.005111
 >> iter 26000, loss: 0.004723
 >> iter 27000, loss: 0.004428
 >> iter 28000, loss: 0.004114
 >> iter 29000, loss: 0.003905
 >> iter 30000, loss: 0.003703
   Number of active neurons: 10
 >> iter 31000, loss: 0.003508
 >> iter 32000, loss: 0.003328
 >> iter 33000, loss: 0.003199
 >> iter 34000, loss: 0.003012
 >> iter 35000, loss: 0.002899
 >> iter 36000, loss: 0.002764
 >> iter 37000, loss: 0.002658
 >> iter 38000, loss: 0.002543
 >> iter 39000, loss: 0.002475
 >> iter 40000, loss: 0.002376
   Number of active neurons: 10
 >> iter 41000, loss: 0.002296
 >> iter 42000, loss: 0.002209
 >> iter 43000, loss: 0.002147
 >> iter 44000, loss: 0.002060
 >> iter 45000, loss: 0.002014
 >> iter 46000, loss: 0.001952
 >> iter 47000, loss: 0.001904
 >> iter 48000, loss: 0.001846
 >> iter 49000, loss: 0.001810
 >> iter 50000, loss: 0.001761
   Number of active neurons: 10
 >> iter 51000, loss: 0.001807
 >> iter 52000, loss: 0.001698
 >> iter 53000, loss: 0.001637
 >> iter 54000, loss: 0.001561
 >> iter 55000, loss: 0.001521
 >> iter 56000, loss: 0.001487
 >> iter 57000, loss: 0.001468
 >> iter 58000, loss: 0.001428
 >> iter 59000, loss: 0.001401
 >> iter 60000, loss: 0.001365
   Number of active neurons: 10
 >> iter 61000, loss: 0.001339
 >> iter 62000, loss: 0.001309
 >> iter 63000, loss: 0.001279
 >> iter 64000, loss: 0.001255
 >> iter 65000, loss: 0.001228
 >> iter 66000, loss: 0.001217
 >> iter 67000, loss: 0.001182
 >> iter 68000, loss: 0.001164
 >> iter 69000, loss: 0.001148
 >> iter 70000, loss: 0.001142
   Number of active neurons: 10
 >> iter 71000, loss: 0.001113
 >> iter 72000, loss: 0.001090
 >> iter 73000, loss: 0.001069
 >> iter 74000, loss: 0.001050
 >> iter 75000, loss: 0.001035
 >> iter 76000, loss: 0.001003
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.606372
 >> iter 2000, loss: 10.520539
 >> iter 3000, loss: 8.643683
 >> iter 4000, loss: 7.932636
 >> iter 5000, loss: 7.668787
 >> iter 6000, loss: 7.272320
 >> iter 7000, loss: 6.457947
 >> iter 8000, loss: 5.749029
 >> iter 9000, loss: 5.221102
 >> iter 10000, loss: 2.287125
   Number of active neurons: 10
 >> iter 11000, loss: 0.876565
 >> iter 12000, loss: 0.369296
 >> iter 13000, loss: 0.197133
 >> iter 14000, loss: 0.087868
 >> iter 15000, loss: 0.093945
 >> iter 16000, loss: 0.044056
 >> iter 17000, loss: 0.024054
 >> iter 18000, loss: 0.015721
 >> iter 19000, loss: 0.011595
 >> iter 20000, loss: 0.009782
   Number of active neurons: 10
 >> iter 21000, loss: 0.009944
 >> iter 22000, loss: 0.008429
 >> iter 23000, loss: 0.007296
 >> iter 24000, loss: 0.006569
 >> iter 25000, loss: 0.006522
 >> iter 26000, loss: 0.010180
 >> iter 27000, loss: 0.064008
 >> iter 28000, loss: 0.026685
 >> iter 29000, loss: 0.012861
 >> iter 30000, loss: 0.007976
   Number of active neurons: 10
 >> iter 31000, loss: 0.005515
 >> iter 32000, loss: 0.004307
 >> iter 33000, loss: 0.003751
 >> iter 34000, loss: 0.003365
 >> iter 35000, loss: 0.003245
 >> iter 36000, loss: 0.002962
 >> iter 37000, loss: 0.002786
 >> iter 38000, loss: 0.002728
 >> iter 39000, loss: 0.002604
 >> iter 40000, loss: 0.111478
   Number of active neurons: 10
 >> iter 41000, loss: 0.043268
 >> iter 42000, loss: 0.017808
 >> iter 43000, loss: 0.008304
 >> iter 44000, loss: 0.004663
 >> iter 45000, loss: 0.003258
 >> iter 46000, loss: 0.002672
 >> iter 47000, loss: 0.002407
 >> iter 48000, loss: 0.002219
 >> iter 49000, loss: 0.002143
 >> iter 50000, loss: 0.002063
   Number of active neurons: 10
 >> iter 51000, loss: 0.001988
 >> iter 52000, loss: 0.001918
 >> iter 53000, loss: 0.001827
 >> iter 54000, loss: 0.001754
 >> iter 55000, loss: 0.001673
 >> iter 56000, loss: 0.001599
 >> iter 57000, loss: 0.001618
 >> iter 58000, loss: 0.001555
 >> iter 59000, loss: 0.001546
 >> iter 60000, loss: 0.001457
   Number of active neurons: 10
 >> iter 61000, loss: 0.001496
 >> iter 62000, loss: 0.001404
 >> iter 63000, loss: 0.001384
 >> iter 64000, loss: 0.001316
 >> iter 65000, loss: 0.001277
 >> iter 66000, loss: 0.001275
 >> iter 67000, loss: 0.013401
 >> iter 68000, loss: 0.005865
 >> iter 69000, loss: 0.002986
 >> iter 70000, loss: 0.001900
   Number of active neurons: 10
 >> iter 71000, loss: 0.001495
 >> iter 72000, loss: 0.001278
 >> iter 73000, loss: 0.001218
 >> iter 74000, loss: 0.001181
 >> iter 75000, loss: 0.001116
 >> iter 76000, loss: 0.002834
 >> iter 77000, loss: 0.001828
 >> iter 78000, loss: 0.001395
 >> iter 79000, loss: 0.025596
 >> iter 80000, loss: 0.010663
   Number of active neurons: 10
 >> iter 81000, loss: 0.012188
 >> iter 82000, loss: 0.005656
 >> iter 83000, loss: 0.003165
 >> iter 84000, loss: 0.001996
 >> iter 85000, loss: 0.001502
 >> iter 86000, loss: 0.001262
 >> iter 87000, loss: 0.001087
 >> iter 88000, loss: 0.001010
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.641047
 >> iter 2000, loss: 10.549833
 >> iter 3000, loss: 8.664276
 >> iter 4000, loss: 7.952630
 >> iter 5000, loss: 7.693935
 >> iter 6000, loss: 7.468285
 >> iter 7000, loss: 6.862595
 >> iter 8000, loss: 6.080637
 >> iter 9000, loss: 5.601310
 >> iter 10000, loss: 4.954201
   Number of active neurons: 10
 >> iter 11000, loss: 2.631232
 >> iter 12000, loss: 1.044218
 >> iter 13000, loss: 0.420815
 >> iter 14000, loss: 0.170386
 >> iter 15000, loss: 0.074423
 >> iter 16000, loss: 0.036652
 >> iter 17000, loss: 0.021127
 >> iter 18000, loss: 0.013838
 >> iter 19000, loss: 0.010569
 >> iter 20000, loss: 0.008912
   Number of active neurons: 10
 >> iter 21000, loss: 0.016612
 >> iter 22000, loss: 0.011411
 >> iter 23000, loss: 0.008060
 >> iter 24000, loss: 0.006586
 >> iter 25000, loss: 0.005444
 >> iter 26000, loss: 0.004760
 >> iter 27000, loss: 0.004349
 >> iter 28000, loss: 0.004091
 >> iter 29000, loss: 0.003740
 >> iter 30000, loss: 0.003559
   Number of active neurons: 10
 >> iter 31000, loss: 0.003381
 >> iter 32000, loss: 0.003137
 >> iter 33000, loss: 0.003339
 >> iter 34000, loss: 0.003299
 >> iter 35000, loss: 0.002838
 >> iter 36000, loss: 0.002611
 >> iter 37000, loss: 0.002518
 >> iter 38000, loss: 0.016428
 >> iter 39000, loss: 0.007575
 >> iter 40000, loss: 0.004189
   Number of active neurons: 10
 >> iter 41000, loss: 0.002884
 >> iter 42000, loss: 0.002484
 >> iter 43000, loss: 0.002187
 >> iter 44000, loss: 0.002031
 >> iter 45000, loss: 0.001882
 >> iter 46000, loss: 0.002859
 >> iter 47000, loss: 0.002418
 >> iter 48000, loss: 0.002071
 >> iter 49000, loss: 0.001824
 >> iter 50000, loss: 0.001753
   Number of active neurons: 10
 >> iter 51000, loss: 0.004836
 >> iter 52000, loss: 0.003157
 >> iter 53000, loss: 0.002231
 >> iter 54000, loss: 0.001871
 >> iter 55000, loss: 0.001633
 >> iter 56000, loss: 0.002116
 >> iter 57000, loss: 0.001688
 >> iter 58000, loss: 0.001662
 >> iter 59000, loss: 0.001394
 >> iter 60000, loss: 0.001312
   Number of active neurons: 10
 >> iter 61000, loss: 0.001213
 >> iter 62000, loss: 0.001178
 >> iter 63000, loss: 0.001137
 >> iter 64000, loss: 0.001253
 >> iter 65000, loss: 0.001145
 >> iter 66000, loss: 0.001105
 >> iter 67000, loss: 0.001068
 >> iter 68000, loss: 0.001035
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.610078
 >> iter 2000, loss: 10.548008
 >> iter 3000, loss: 8.674419
 >> iter 4000, loss: 7.907555
 >> iter 5000, loss: 7.205574
 >> iter 6000, loss: 6.321369
 >> iter 7000, loss: 3.903925
 >> iter 8000, loss: 1.691390
 >> iter 9000, loss: 0.663020
 >> iter 10000, loss: 0.274077
   Number of active neurons: 10
 >> iter 11000, loss: 0.131206
 >> iter 12000, loss: 0.091940
 >> iter 13000, loss: 0.053467
 >> iter 14000, loss: 0.038936
 >> iter 15000, loss: 0.022084
 >> iter 16000, loss: 0.014075
 >> iter 17000, loss: 0.087885
 >> iter 18000, loss: 0.039156
 >> iter 19000, loss: 0.020128
 >> iter 20000, loss: 0.012266
   Number of active neurons: 10
 >> iter 21000, loss: 0.017693
 >> iter 22000, loss: 0.010138
 >> iter 23000, loss: 0.007138
 >> iter 24000, loss: 0.018066
 >> iter 25000, loss: 0.010033
 >> iter 26000, loss: 0.006932
 >> iter 27000, loss: 0.005411
 >> iter 28000, loss: 0.004382
 >> iter 29000, loss: 0.020990
 >> iter 30000, loss: 0.010141
   Number of active neurons: 10
 >> iter 31000, loss: 0.006955
 >> iter 32000, loss: 0.004792
 >> iter 33000, loss: 0.003746
 >> iter 34000, loss: 0.003274
 >> iter 35000, loss: 0.002969
 >> iter 36000, loss: 0.002791
 >> iter 37000, loss: 0.002574
 >> iter 38000, loss: 0.016074
 >> iter 39000, loss: 0.007979
 >> iter 40000, loss: 0.036548
   Number of active neurons: 10
 >> iter 41000, loss: 0.015601
 >> iter 42000, loss: 0.007612
 >> iter 43000, loss: 0.004759
 >> iter 44000, loss: 0.003433
 >> iter 45000, loss: 0.002838
 >> iter 46000, loss: 0.002574
 >> iter 47000, loss: 0.002300
 >> iter 48000, loss: 0.002099
 >> iter 49000, loss: 0.011110
 >> iter 50000, loss: 0.005446
   Number of active neurons: 10
 >> iter 51000, loss: 0.003377
 >> iter 52000, loss: 0.002419
 >> iter 53000, loss: 0.002059
 >> iter 54000, loss: 0.001831
 >> iter 55000, loss: 0.001731
 >> iter 56000, loss: 0.001656
 >> iter 57000, loss: 0.001569
 >> iter 58000, loss: 0.001565
 >> iter 59000, loss: 0.001708
 >> iter 60000, loss: 0.001628
   Number of active neurons: 10
 >> iter 61000, loss: 0.001525
 >> iter 62000, loss: 0.001419
 >> iter 63000, loss: 0.001373
 >> iter 64000, loss: 0.001328
 >> iter 65000, loss: 0.001440
 >> iter 66000, loss: 0.025162
 >> iter 67000, loss: 0.039017
 >> iter 68000, loss: 0.015586
 >> iter 69000, loss: 0.006833
 >> iter 70000, loss: 0.003581
   Number of active neurons: 10
 >> iter 71000, loss: 0.327613
 >> iter 72000, loss: 0.125469
 >> iter 73000, loss: 0.067937
 >> iter 74000, loss: 0.027731
 >> iter 75000, loss: 0.012358
 >> iter 76000, loss: 0.006502
 >> iter 77000, loss: 0.004163
 >> iter 78000, loss: 0.003219
 >> iter 79000, loss: 0.002702
 >> iter 80000, loss: 0.002418
   Number of active neurons: 10
 >> iter 81000, loss: 0.002270
 >> iter 82000, loss: 0.002145
 >> iter 83000, loss: 0.002085
 >> iter 84000, loss: 0.002051
 >> iter 85000, loss: 0.002035
 >> iter 86000, loss: 0.001917
 >> iter 87000, loss: 0.001806
 >> iter 88000, loss: 0.001715
 >> iter 89000, loss: 0.001636
 >> iter 90000, loss: 0.001585
   Number of active neurons: 10
 >> iter 91000, loss: 0.001579
 >> iter 92000, loss: 0.057446
 >> iter 93000, loss: 0.022442
 >> iter 94000, loss: 0.009466
 >> iter 95000, loss: 0.004602
 >> iter 96000, loss: 0.002753
 >> iter 97000, loss: 0.002000
 >> iter 98000, loss: 0.001703
 >> iter 99000, loss: 0.001523
 >> iter 100000, loss: 0.001410
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.601184
 >> iter 2000, loss: 10.563861
 >> iter 3000, loss: 8.678188
 >> iter 4000, loss: 7.969398
 >> iter 5000, loss: 7.689013
 >> iter 6000, loss: 7.268171
 >> iter 7000, loss: 4.673716
 >> iter 8000, loss: 1.763038
 >> iter 9000, loss: 0.668039
 >> iter 10000, loss: 0.258983
   Number of active neurons: 10
 >> iter 11000, loss: 0.104943
 >> iter 12000, loss: 0.046177
 >> iter 13000, loss: 0.023394
 >> iter 14000, loss: 0.014055
 >> iter 15000, loss: 0.009980
 >> iter 16000, loss: 0.007929
 >> iter 17000, loss: 0.006738
 >> iter 18000, loss: 0.005978
 >> iter 19000, loss: 0.005368
 >> iter 20000, loss: 0.004918
   Number of active neurons: 10
 >> iter 21000, loss: 0.004547
 >> iter 22000, loss: 0.004265
 >> iter 23000, loss: 0.003917
 >> iter 24000, loss: 0.003716
 >> iter 25000, loss: 0.003493
 >> iter 26000, loss: 0.003322
 >> iter 27000, loss: 0.003099
 >> iter 28000, loss: 0.002966
 >> iter 29000, loss: 0.002806
 >> iter 30000, loss: 0.002655
   Number of active neurons: 10
 >> iter 31000, loss: 0.002555
 >> iter 32000, loss: 0.002466
 >> iter 33000, loss: 0.002368
 >> iter 34000, loss: 0.002272
 >> iter 35000, loss: 0.002168
 >> iter 36000, loss: 0.002110
 >> iter 37000, loss: 0.002011
 >> iter 38000, loss: 0.001963
 >> iter 39000, loss: 0.001888
 >> iter 40000, loss: 0.001828
   Number of active neurons: 10
 >> iter 41000, loss: 0.001791
 >> iter 42000, loss: 0.001736
 >> iter 43000, loss: 0.001675
 >> iter 44000, loss: 0.001628
 >> iter 45000, loss: 0.001579
 >> iter 46000, loss: 0.001543
 >> iter 47000, loss: 0.001497
 >> iter 48000, loss: 0.001473
 >> iter 49000, loss: 0.001424
 >> iter 50000, loss: 0.001375
   Number of active neurons: 10
 >> iter 51000, loss: 0.001342
 >> iter 52000, loss: 0.001338
 >> iter 53000, loss: 0.001292
 >> iter 54000, loss: 0.001261
 >> iter 55000, loss: 0.001222
 >> iter 56000, loss: 0.001199
 >> iter 57000, loss: 0.002591
 >> iter 58000, loss: 0.001835
 >> iter 59000, loss: 0.001485
 >> iter 60000, loss: 0.001302
   Number of active neurons: 10
 >> iter 61000, loss: 0.001208
 >> iter 62000, loss: 0.001161
 >> iter 63000, loss: 0.001107
 >> iter 64000, loss: 0.001065
 >> iter 65000, loss: 0.001039
 >> iter 66000, loss: 0.001012
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.604361
 >> iter 2000, loss: 10.518395
 >> iter 3000, loss: 8.644137
 >> iter 4000, loss: 7.914333
 >> iter 5000, loss: 7.204441
 >> iter 6000, loss: 6.440060
 >> iter 7000, loss: 5.631827
 >> iter 8000, loss: 3.438418
 >> iter 9000, loss: 1.450072
 >> iter 10000, loss: 0.672826
   Number of active neurons: 10
 >> iter 11000, loss: 0.278176
 >> iter 12000, loss: 0.116341
 >> iter 13000, loss: 0.173254
 >> iter 14000, loss: 0.074061
 >> iter 15000, loss: 0.068446
 >> iter 16000, loss: 0.032534
 >> iter 17000, loss: 0.017975
 >> iter 18000, loss: 0.011777
 >> iter 19000, loss: 0.008918
 >> iter 20000, loss: 0.007239
   Number of active neurons: 10
 >> iter 21000, loss: 0.006296
 >> iter 22000, loss: 0.005565
 >> iter 23000, loss: 0.005201
 >> iter 24000, loss: 0.004704
 >> iter 25000, loss: 0.006662
 >> iter 26000, loss: 0.019864
 >> iter 27000, loss: 0.009909
 >> iter 28000, loss: 0.005933
 >> iter 29000, loss: 0.004316
 >> iter 30000, loss: 0.003560
   Number of active neurons: 10
 >> iter 31000, loss: 0.003206
 >> iter 32000, loss: 0.003015
 >> iter 33000, loss: 0.002816
 >> iter 34000, loss: 0.002640
 >> iter 35000, loss: 0.002509
 >> iter 36000, loss: 0.002418
 >> iter 37000, loss: 0.002299
 >> iter 38000, loss: 0.002218
 >> iter 39000, loss: 0.004546
 >> iter 40000, loss: 0.003075
   Number of active neurons: 10
 >> iter 41000, loss: 0.002461
 >> iter 42000, loss: 0.002161
 >> iter 43000, loss: 0.002000
 >> iter 44000, loss: 0.001889
 >> iter 45000, loss: 0.001814
 >> iter 46000, loss: 0.001731
 >> iter 47000, loss: 0.001687
 >> iter 48000, loss: 0.037401
 >> iter 49000, loss: 0.015126
 >> iter 50000, loss: 0.006696
   Number of active neurons: 10
 >> iter 51000, loss: 0.003567
 >> iter 52000, loss: 0.002348
 >> iter 53000, loss: 0.001869
 >> iter 54000, loss: 0.001643
 >> iter 55000, loss: 0.001542
 >> iter 56000, loss: 0.001464
 >> iter 57000, loss: 0.001424
 >> iter 58000, loss: 0.001376
 >> iter 59000, loss: 0.001336
 >> iter 60000, loss: 0.001325
   Number of active neurons: 10
 >> iter 61000, loss: 0.001287
 >> iter 62000, loss: 0.001255
 >> iter 63000, loss: 0.001234
 >> iter 64000, loss: 0.001198
 >> iter 65000, loss: 0.018200
 >> iter 66000, loss: 0.007620
 >> iter 67000, loss: 0.003660
 >> iter 68000, loss: 0.002180
 >> iter 69000, loss: 0.001610
 >> iter 70000, loss: 0.002105
   Number of active neurons: 10
 >> iter 71000, loss: 0.047370
 >> iter 72000, loss: 0.062560
 >> iter 73000, loss: 0.024146
 >> iter 74000, loss: 0.009882
 >> iter 75000, loss: 0.004581
 >> iter 76000, loss: 0.002570
 >> iter 77000, loss: 0.001828
 >> iter 78000, loss: 0.001562
 >> iter 79000, loss: 0.001380
 >> iter 80000, loss: 0.001279
   Number of active neurons: 10
 >> iter 81000, loss: 0.001221
 >> iter 82000, loss: 0.001180
 >> iter 83000, loss: 0.001163
 >> iter 84000, loss: 0.001123
 >> iter 85000, loss: 0.001097
 >> iter 86000, loss: 0.001073
 >> iter 87000, loss: 0.001051
 >> iter 88000, loss: 0.001029
 >> iter 89000, loss: 0.001006
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 15.615989
 >> iter 2000, loss: 10.529290
 >> iter 3000, loss: 8.646459
 >> iter 4000, loss: 7.929211
 >> iter 5000, loss: 7.670467
 >> iter 6000, loss: 7.534769
 >> iter 7000, loss: 7.102368
 >> iter 8000, loss: 6.374168
 >> iter 9000, loss: 3.527481
 >> iter 10000, loss: 1.344601
   Number of active neurons: 10
 >> iter 11000, loss: 0.534799
 >> iter 12000, loss: 0.213473
 >> iter 13000, loss: 0.090560
 >> iter 14000, loss: 0.042392
 >> iter 15000, loss: 0.023051
 >> iter 16000, loss: 0.014969
 >> iter 17000, loss: 0.011095
 >> iter 18000, loss: 0.009017
 >> iter 19000, loss: 0.007663
 >> iter 20000, loss: 0.006689
   Number of active neurons: 10
 >> iter 21000, loss: 0.006076
 >> iter 22000, loss: 0.005563
 >> iter 23000, loss: 0.005168
 >> iter 24000, loss: 0.004768
 >> iter 25000, loss: 0.004466
 >> iter 26000, loss: 0.004190
 >> iter 27000, loss: 0.003868
 >> iter 28000, loss: 0.003669
 >> iter 29000, loss: 0.003406
 >> iter 30000, loss: 0.003248
   Number of active neurons: 10
 >> iter 31000, loss: 0.003488
 >> iter 32000, loss: 0.003205
 >> iter 33000, loss: 0.002907
 >> iter 34000, loss: 0.002779
 >> iter 35000, loss: 0.002603
 >> iter 36000, loss: 0.002496
 >> iter 37000, loss: 0.002359
 >> iter 38000, loss: 0.002210
 >> iter 39000, loss: 0.002150
 >> iter 40000, loss: 0.002060
   Number of active neurons: 10
 >> iter 41000, loss: 0.001971
 >> iter 42000, loss: 0.001907
 >> iter 43000, loss: 0.001825
 >> iter 44000, loss: 0.001821
 >> iter 45000, loss: 0.001747
 >> iter 46000, loss: 0.004658
 >> iter 47000, loss: 0.003032
 >> iter 48000, loss: 0.002287
 >> iter 49000, loss: 0.001913
 >> iter 50000, loss: 0.001764
   Number of active neurons: 10
 >> iter 51000, loss: 0.001624
 >> iter 52000, loss: 0.001680
 >> iter 53000, loss: 0.001508
 >> iter 54000, loss: 0.001397
 >> iter 55000, loss: 0.001361
 >> iter 56000, loss: 0.001310
 >> iter 57000, loss: 0.001268
 >> iter 58000, loss: 0.001205
 >> iter 59000, loss: 0.001270
 >> iter 60000, loss: 0.001201
   Number of active neurons: 10
 >> iter 61000, loss: 0.001161
 >> iter 62000, loss: 0.001124
 >> iter 63000, loss: 0.001091
 >> iter 64000, loss: 0.001066
 >> iter 65000, loss: 0.001034
 >> iter 66000, loss: 0.001038
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.623964
 >> iter 2000, loss: 10.533199
 >> iter 3000, loss: 8.646577
 >> iter 4000, loss: 7.930977
 >> iter 5000, loss: 7.674904
 >> iter 6000, loss: 7.568067
 >> iter 7000, loss: 7.540862
 >> iter 8000, loss: 7.514352
 >> iter 9000, loss: 7.397464
 >> iter 10000, loss: 6.867381
   Number of active neurons: 10
 >> iter 11000, loss: 6.159512
 >> iter 12000, loss: 5.657917
 >> iter 13000, loss: 4.660648
 >> iter 14000, loss: 1.836705
 >> iter 15000, loss: 0.746028
 >> iter 16000, loss: 0.305937
 >> iter 17000, loss: 0.126719
 >> iter 18000, loss: 0.056823
 >> iter 19000, loss: 0.028908
 >> iter 20000, loss: 0.017814
   Number of active neurons: 10
 >> iter 21000, loss: 0.012328
 >> iter 22000, loss: 0.009622
 >> iter 23000, loss: 0.017033
 >> iter 24000, loss: 0.010816
 >> iter 25000, loss: 0.008389
 >> iter 26000, loss: 0.035436
 >> iter 27000, loss: 0.016906
 >> iter 28000, loss: 0.009454
 >> iter 29000, loss: 0.006490
 >> iter 30000, loss: 0.005205
   Number of active neurons: 10
 >> iter 31000, loss: 0.065660
 >> iter 32000, loss: 0.027398
 >> iter 33000, loss: 0.012933
 >> iter 34000, loss: 0.007327
 >> iter 35000, loss: 0.005043
 >> iter 36000, loss: 0.004147
 >> iter 37000, loss: 0.003604
 >> iter 38000, loss: 0.003399
 >> iter 39000, loss: 0.003083
 >> iter 40000, loss: 0.002902
   Number of active neurons: 10
 >> iter 41000, loss: 0.002718
 >> iter 42000, loss: 0.002581
 >> iter 43000, loss: 0.065293
 >> iter 44000, loss: 0.081071
 >> iter 45000, loss: 0.032195
 >> iter 46000, loss: 0.059596
 >> iter 47000, loss: 0.070823
 >> iter 48000, loss: 0.028531
 >> iter 49000, loss: 0.012522
 >> iter 50000, loss: 0.006407
   Number of active neurons: 10
 >> iter 51000, loss: 0.004027
 >> iter 52000, loss: 0.003045
 >> iter 53000, loss: 0.002579
 >> iter 54000, loss: 0.002378
 >> iter 55000, loss: 0.002260
 >> iter 56000, loss: 0.002159
 >> iter 57000, loss: 0.002044
 >> iter 58000, loss: 0.001953
 >> iter 59000, loss: 0.001888
 >> iter 60000, loss: 0.001782
   Number of active neurons: 10
 >> iter 61000, loss: 0.001718
 >> iter 62000, loss: 0.001694
 >> iter 63000, loss: 0.001668
 >> iter 64000, loss: 0.001599
 >> iter 65000, loss: 0.001515
 >> iter 66000, loss: 0.001501
 >> iter 67000, loss: 0.001468
 >> iter 68000, loss: 0.001434
 >> iter 69000, loss: 0.001399
 >> iter 70000, loss: 0.001333
   Number of active neurons: 10
 >> iter 71000, loss: 0.001295
 >> iter 72000, loss: 0.001277
 >> iter 73000, loss: 0.001286
 >> iter 74000, loss: 0.001223
 >> iter 75000, loss: 0.001237
 >> iter 76000, loss: 0.001229
 >> iter 77000, loss: 0.001182
 >> iter 78000, loss: 0.001128
 >> iter 79000, loss: 0.001093
 >> iter 80000, loss: 0.001071
   Number of active neurons: 10
 >> iter 81000, loss: 0.001081
 >> iter 82000, loss: 0.001035
 >> iter 83000, loss: 0.001042
 >> iter 84000, loss: 0.001009
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.553405
 >> iter 2000, loss: 10.510003
 >> iter 3000, loss: 8.645508
 >> iter 4000, loss: 7.925867
 >> iter 5000, loss: 7.669565
 >> iter 6000, loss: 7.551846
 >> iter 7000, loss: 7.504085
 >> iter 8000, loss: 7.157988
 >> iter 9000, loss: 6.423658
 >> iter 10000, loss: 5.728519
   Number of active neurons: 9
 >> iter 11000, loss: 5.341501
 >> iter 12000, loss: 4.917300
 >> iter 13000, loss: 4.345059
 >> iter 14000, loss: 1.686067
 >> iter 15000, loss: 0.650942
 >> iter 16000, loss: 0.263864
 >> iter 17000, loss: 0.113241
 >> iter 18000, loss: 0.054780
 >> iter 19000, loss: 0.030907
 >> iter 20000, loss: 0.020111
   Number of active neurons: 10
 >> iter 21000, loss: 0.015464
 >> iter 22000, loss: 0.105668
 >> iter 23000, loss: 0.047378
 >> iter 24000, loss: 0.023956
 >> iter 25000, loss: 0.014563
 >> iter 26000, loss: 0.010534
 >> iter 27000, loss: 0.008808
 >> iter 28000, loss: 0.008006
 >> iter 29000, loss: 0.009570
 >> iter 30000, loss: 0.007888
   Number of active neurons: 10
 >> iter 31000, loss: 0.008755
 >> iter 32000, loss: 0.007565
 >> iter 33000, loss: 0.006271
 >> iter 34000, loss: 0.005508
 >> iter 35000, loss: 0.004957
 >> iter 36000, loss: 0.004535
 >> iter 37000, loss: 0.004270
 >> iter 38000, loss: 0.004051
 >> iter 39000, loss: 0.003875
 >> iter 40000, loss: 0.003693
   Number of active neurons: 10
 >> iter 41000, loss: 0.003896
 >> iter 42000, loss: 0.003658
 >> iter 43000, loss: 0.003424
 >> iter 44000, loss: 0.003316
 >> iter 45000, loss: 0.003142
 >> iter 46000, loss: 0.002924
 >> iter 47000, loss: 0.002828
 >> iter 48000, loss: 0.002794
 >> iter 49000, loss: 0.002768
 >> iter 50000, loss: 0.002648
   Number of active neurons: 10
 >> iter 51000, loss: 0.002522
 >> iter 52000, loss: 0.002421
 >> iter 53000, loss: 0.002480
 >> iter 54000, loss: 0.002856
 >> iter 55000, loss: 0.003375
 >> iter 56000, loss: 0.003101
 >> iter 57000, loss: 0.002691
 >> iter 58000, loss: 0.002522
 >> iter 59000, loss: 0.002278
 >> iter 60000, loss: 0.002268
   Number of active neurons: 10
 >> iter 61000, loss: 0.002324
 >> iter 62000, loss: 0.002154
 >> iter 63000, loss: 0.002149
 >> iter 64000, loss: 0.001963
 >> iter 65000, loss: 0.001841
 >> iter 66000, loss: 0.033401
 >> iter 67000, loss: 0.013719
 >> iter 68000, loss: 0.006428
 >> iter 69000, loss: 0.003608
 >> iter 70000, loss: 0.002603
   Number of active neurons: 10
 >> iter 71000, loss: 0.002149
 >> iter 72000, loss: 0.002470
 >> iter 73000, loss: 0.002069
 >> iter 74000, loss: 0.001815
 >> iter 75000, loss: 0.001661
 >> iter 76000, loss: 0.001750
 >> iter 77000, loss: 0.001716
 >> iter 78000, loss: 0.001672
 >> iter 79000, loss: 0.001477
 >> iter 80000, loss: 0.001435
   Number of active neurons: 10
 >> iter 81000, loss: 0.001368
 >> iter 82000, loss: 0.001506
 >> iter 83000, loss: 0.001535
 >> iter 84000, loss: 0.001476
 >> iter 85000, loss: 0.001408
 >> iter 86000, loss: 0.001344
 >> iter 87000, loss: 0.001347
 >> iter 88000, loss: 0.001340
 >> iter 89000, loss: 0.001766
 >> iter 90000, loss: 0.001595
   Number of active neurons: 10
 >> iter 91000, loss: 0.001620
 >> iter 92000, loss: 0.001516
 >> iter 93000, loss: 0.001420
 >> iter 94000, loss: 0.002091
 >> iter 95000, loss: 0.001814
 >> iter 96000, loss: 0.001645
 >> iter 97000, loss: 0.001500
 >> iter 98000, loss: 0.001433
 >> iter 99000, loss: 0.001372
 >> iter 100000, loss: 0.001332
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

