 > Problema: tomita7nueva
 > Args:
   - Hidden size: 12
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.043045
 >> iter 2000, loss: 9.767801
 >> iter 3000, loss: 4.585102
 >> iter 4000, loss: 2.069020
 >> iter 5000, loss: 0.984278
 >> iter 6000, loss: 0.537924
 >> iter 7000, loss: 0.391941
 >> iter 8000, loss: 0.386250
 >> iter 9000, loss: 0.329388
 >> iter 10000, loss: 0.325196
   Number of active neurons: 10
 >> iter 11000, loss: 0.336873
 >> iter 12000, loss: 0.242479
 >> iter 13000, loss: 0.235182
 >> iter 14000, loss: 0.242518
 >> iter 15000, loss: 0.279407
 >> iter 16000, loss: 0.310056
 >> iter 17000, loss: 0.227699
 >> iter 18000, loss: 0.209920
 >> iter 19000, loss: 0.330231
 >> iter 20000, loss: 0.351982
   Number of active neurons: 10
 >> iter 21000, loss: 0.296385
 >> iter 22000, loss: 0.267118
 >> iter 23000, loss: 0.309621
 >> iter 24000, loss: 0.368462
 >> iter 25000, loss: 0.455054
 >> iter 26000, loss: 0.360720
 >> iter 27000, loss: 0.455550
 >> iter 28000, loss: 0.458836
 >> iter 29000, loss: 0.449177
 >> iter 30000, loss: 0.571045
   Number of active neurons: 10
 >> iter 31000, loss: 0.508431
 >> iter 32000, loss: 0.344370
 >> iter 33000, loss: 0.400704
 >> iter 34000, loss: 0.286595
 >> iter 35000, loss: 0.252956
 >> iter 36000, loss: 0.416239
 >> iter 37000, loss: 0.406173
 >> iter 38000, loss: 0.318565
 >> iter 39000, loss: 0.339415
 >> iter 40000, loss: 0.325029
   Number of active neurons: 9
 >> iter 41000, loss: 0.340604
 >> iter 42000, loss: 0.218184
 >> iter 43000, loss: 0.241937
 >> iter 44000, loss: 0.221194
 >> iter 45000, loss: 0.292284
 >> iter 46000, loss: 0.277478
 >> iter 47000, loss: 0.270152
 >> iter 48000, loss: 0.263694
 >> iter 49000, loss: 0.433999
 >> iter 50000, loss: 0.419806
   Number of active neurons: 7
 >> iter 51000, loss: 0.386046
 >> iter 52000, loss: 0.333997
 >> iter 53000, loss: 0.371827
 >> iter 54000, loss: 0.300839
 >> iter 55000, loss: 0.345303
 >> iter 56000, loss: 0.234685
 >> iter 57000, loss: 0.362760
 >> iter 58000, loss: 0.289992
 >> iter 59000, loss: 0.299836
 >> iter 60000, loss: 0.220949
   Number of active neurons: 7
 >> iter 61000, loss: 0.227875
 >> iter 62000, loss: 0.319034
 >> iter 63000, loss: 0.415620
 >> iter 64000, loss: 0.373736
 >> iter 65000, loss: 0.444422
 >> iter 66000, loss: 0.392023
 >> iter 67000, loss: 0.383766
 >> iter 68000, loss: 0.258680
 >> iter 69000, loss: 0.273712
 >> iter 70000, loss: 0.388867
   Number of active neurons: 7
 >> iter 71000, loss: 0.339116
 >> iter 72000, loss: 0.246868
 >> iter 73000, loss: 0.280553
 >> iter 74000, loss: 0.316036
 >> iter 75000, loss: 0.334015
 >> iter 76000, loss: 0.270962
 >> iter 77000, loss: 0.293186
 >> iter 78000, loss: 0.328780
 >> iter 79000, loss: 0.433152
 >> iter 80000, loss: 0.336909
   Number of active neurons: 7
 >> iter 81000, loss: 0.348337
 >> iter 82000, loss: 0.380367
 >> iter 83000, loss: 0.259880
 >> iter 84000, loss: 0.373830
 >> iter 85000, loss: 0.450609
 >> iter 86000, loss: 0.348228
 >> iter 87000, loss: 0.278548
 >> iter 88000, loss: 0.247676
 >> iter 89000, loss: 0.216775
 >> iter 90000, loss: 0.283653
   Number of active neurons: 7
 >> iter 91000, loss: 0.345809
 >> iter 92000, loss: 0.244314
 >> iter 93000, loss: 0.331310
 >> iter 94000, loss: 0.358402
 >> iter 95000, loss: 0.361093
 >> iter 96000, loss: 0.352645
 >> iter 97000, loss: 0.370464
 >> iter 98000, loss: 0.309173
 >> iter 99000, loss: 0.390101
 >> iter 100000, loss: 0.322138
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 17.191991
 >> iter 2000, loss: 10.137827
 >> iter 3000, loss: 6.441458
 >> iter 4000, loss: 2.843498
 >> iter 5000, loss: 1.484186
 >> iter 6000, loss: 0.833512
 >> iter 7000, loss: 0.503578
 >> iter 8000, loss: 0.607998
 >> iter 9000, loss: 0.481148
 >> iter 10000, loss: 0.392489
   Number of active neurons: 9
 >> iter 11000, loss: 0.479782
 >> iter 12000, loss: 0.415020
 >> iter 13000, loss: 0.419660
 >> iter 14000, loss: 0.368429
 >> iter 15000, loss: 0.368401
 >> iter 16000, loss: 0.312064
 >> iter 17000, loss: 0.285556
 >> iter 18000, loss: 0.265591
 >> iter 19000, loss: 0.260797
 >> iter 20000, loss: 0.226952
   Number of active neurons: 7
 >> iter 21000, loss: 0.238940
 >> iter 22000, loss: 0.315323
 >> iter 23000, loss: 0.356869
 >> iter 24000, loss: 0.347042
 >> iter 25000, loss: 0.296274
 >> iter 26000, loss: 0.398529
 >> iter 27000, loss: 0.370448
 >> iter 28000, loss: 0.323721
 >> iter 29000, loss: 0.393268
 >> iter 30000, loss: 0.287966
   Number of active neurons: 6
 >> iter 31000, loss: 0.373990
 >> iter 32000, loss: 0.325682
 >> iter 33000, loss: 0.358913
 >> iter 34000, loss: 0.349965
 >> iter 35000, loss: 0.243396
 >> iter 36000, loss: 0.235144
 >> iter 37000, loss: 0.322685
 >> iter 38000, loss: 0.236897
 >> iter 39000, loss: 0.301655
 >> iter 40000, loss: 0.440106
   Number of active neurons: 6
 >> iter 41000, loss: 0.302145
 >> iter 42000, loss: 0.310627
 >> iter 43000, loss: 0.302901
 >> iter 44000, loss: 0.286764
 >> iter 45000, loss: 0.333421
 >> iter 46000, loss: 0.315270
 >> iter 47000, loss: 0.256496
 >> iter 48000, loss: 0.268156
 >> iter 49000, loss: 0.282711
 >> iter 50000, loss: 0.438087
   Number of active neurons: 6
 >> iter 51000, loss: 0.359181
 >> iter 52000, loss: 0.367733
 >> iter 53000, loss: 0.412245
 >> iter 54000, loss: 0.309480
 >> iter 55000, loss: 0.262580
 >> iter 56000, loss: 0.333763
 >> iter 57000, loss: 0.386235
 >> iter 58000, loss: 0.311532
 >> iter 59000, loss: 0.295279
 >> iter 60000, loss: 0.304448
   Number of active neurons: 6
 >> iter 61000, loss: 0.295613
 >> iter 62000, loss: 0.272380
 >> iter 63000, loss: 0.349468
 >> iter 64000, loss: 0.323868
 >> iter 65000, loss: 0.374260
 >> iter 66000, loss: 0.253376
 >> iter 67000, loss: 0.370763
 >> iter 68000, loss: 0.257896
 >> iter 69000, loss: 0.283005
 >> iter 70000, loss: 0.267466
   Number of active neurons: 6
 >> iter 71000, loss: 0.251173
 >> iter 72000, loss: 0.329303
 >> iter 73000, loss: 0.308688
 >> iter 74000, loss: 0.407463
 >> iter 75000, loss: 0.389009
 >> iter 76000, loss: 0.390336
 >> iter 77000, loss: 0.351641
 >> iter 78000, loss: 0.312083
 >> iter 79000, loss: 0.292723
 >> iter 80000, loss: 0.386572
   Number of active neurons: 6
 >> iter 81000, loss: 0.427493
 >> iter 82000, loss: 0.402313
 >> iter 83000, loss: 0.388171
 >> iter 84000, loss: 0.381481
 >> iter 85000, loss: 0.310122
 >> iter 86000, loss: 0.222255
 >> iter 87000, loss: 0.368721
 >> iter 88000, loss: 0.380292
 >> iter 89000, loss: 0.340766
 >> iter 90000, loss: 0.336573
   Number of active neurons: 6
 >> iter 91000, loss: 0.407750
 >> iter 92000, loss: 0.345785
 >> iter 93000, loss: 0.378272
 >> iter 94000, loss: 0.360067
 >> iter 95000, loss: 0.320023
 >> iter 96000, loss: 0.501319
 >> iter 97000, loss: 0.347279
 >> iter 98000, loss: 0.347912
 >> iter 99000, loss: 0.239205
 >> iter 100000, loss: 0.316286
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 16.478761
 >> iter 2000, loss: 9.583201
 >> iter 3000, loss: 5.985117
 >> iter 4000, loss: 3.630232
 >> iter 5000, loss: 2.054283
 >> iter 6000, loss: 1.491796
 >> iter 7000, loss: 1.083404
 >> iter 8000, loss: 0.765999
 >> iter 9000, loss: 0.650523
 >> iter 10000, loss: 0.630472
   Number of active neurons: 9
 >> iter 11000, loss: 0.455156
 >> iter 12000, loss: 0.588256
 >> iter 13000, loss: 0.573611
 >> iter 14000, loss: 0.519004
 >> iter 15000, loss: 0.537168
 >> iter 16000, loss: 0.491753
 >> iter 17000, loss: 0.629110
 >> iter 18000, loss: 0.439470
 >> iter 19000, loss: 0.325242
 >> iter 20000, loss: 0.321282
   Number of active neurons: 9
 >> iter 21000, loss: 0.390358
 >> iter 22000, loss: 0.484746
 >> iter 23000, loss: 0.410345
 >> iter 24000, loss: 0.392360
 >> iter 25000, loss: 0.427131
 >> iter 26000, loss: 0.346894
 >> iter 27000, loss: 0.441204
 >> iter 28000, loss: 0.351480
 >> iter 29000, loss: 0.583224
 >> iter 30000, loss: 0.499674
   Number of active neurons: 8
 >> iter 31000, loss: 0.612084
 >> iter 32000, loss: 0.564512
 >> iter 33000, loss: 0.380953
 >> iter 34000, loss: 0.384979
 >> iter 35000, loss: 0.515202
 >> iter 36000, loss: 0.521469
 >> iter 37000, loss: 0.572709
 >> iter 38000, loss: 0.403696
 >> iter 39000, loss: 0.419214
 >> iter 40000, loss: 0.450465
   Number of active neurons: 7
 >> iter 41000, loss: 0.466626
 >> iter 42000, loss: 0.430885
 >> iter 43000, loss: 0.437067
 >> iter 44000, loss: 0.412895
 >> iter 45000, loss: 0.391092
 >> iter 46000, loss: 0.417191
 >> iter 47000, loss: 0.502145
 >> iter 48000, loss: 0.504823
 >> iter 49000, loss: 0.449021
 >> iter 50000, loss: 0.395419
   Number of active neurons: 7
 >> iter 51000, loss: 0.467482
 >> iter 52000, loss: 0.584435
 >> iter 53000, loss: 0.563587
 >> iter 54000, loss: 0.529495
 >> iter 55000, loss: 0.519896
 >> iter 56000, loss: 0.389106
 >> iter 57000, loss: 0.370874
 >> iter 58000, loss: 0.457152
 >> iter 59000, loss: 0.357443
 >> iter 60000, loss: 0.442800
   Number of active neurons: 7
 >> iter 61000, loss: 0.437699
 >> iter 62000, loss: 0.475127
 >> iter 63000, loss: 0.439071
 >> iter 64000, loss: 0.379619
 >> iter 65000, loss: 0.448413
 >> iter 66000, loss: 0.441222
 >> iter 67000, loss: 0.467119
 >> iter 68000, loss: 0.358913
 >> iter 69000, loss: 0.516199
 >> iter 70000, loss: 0.433168
   Number of active neurons: 7
 >> iter 71000, loss: 0.505648
 >> iter 72000, loss: 0.569115
 >> iter 73000, loss: 0.462124
 >> iter 74000, loss: 0.562505
 >> iter 75000, loss: 0.527557
 >> iter 76000, loss: 0.592764
 >> iter 77000, loss: 0.594747
 >> iter 78000, loss: 0.426496
 >> iter 79000, loss: 0.422017
 >> iter 80000, loss: 0.394610
   Number of active neurons: 7
 >> iter 81000, loss: 0.371949
 >> iter 82000, loss: 0.452665
 >> iter 83000, loss: 0.489100
 >> iter 84000, loss: 0.540043
 >> iter 85000, loss: 0.472405
 >> iter 86000, loss: 0.459286
 >> iter 87000, loss: 0.618025
 >> iter 88000, loss: 0.726167
 >> iter 89000, loss: 0.642993
 >> iter 90000, loss: 0.481360
   Number of active neurons: 7
 >> iter 91000, loss: 0.325903
 >> iter 92000, loss: 0.472058
 >> iter 93000, loss: 0.432592
 >> iter 94000, loss: 0.413800
 >> iter 95000, loss: 0.353518
 >> iter 96000, loss: 0.439290
 >> iter 97000, loss: 0.596107
 >> iter 98000, loss: 0.442306
 >> iter 99000, loss: 0.409010
 >> iter 100000, loss: 0.359803
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.903067
 >> iter 2000, loss: 10.285834
 >> iter 3000, loss: 6.956618
 >> iter 4000, loss: 3.800587
 >> iter 5000, loss: 2.080997
 >> iter 6000, loss: 1.259235
 >> iter 7000, loss: 0.789303
 >> iter 8000, loss: 0.575355
 >> iter 9000, loss: 0.704973
 >> iter 10000, loss: 0.630747
   Number of active neurons: 6
 >> iter 11000, loss: 0.467118
 >> iter 12000, loss: 0.449032
 >> iter 13000, loss: 0.457495
 >> iter 14000, loss: 0.523228
 >> iter 15000, loss: 0.492787
 >> iter 16000, loss: 0.456297
 >> iter 17000, loss: 0.396224
 >> iter 18000, loss: 0.364097
 >> iter 19000, loss: 0.320288
 >> iter 20000, loss: 0.371541
   Number of active neurons: 6
 >> iter 21000, loss: 0.393951
 >> iter 22000, loss: 0.384713
 >> iter 23000, loss: 0.381402
 >> iter 24000, loss: 0.622778
 >> iter 25000, loss: 0.606975
 >> iter 26000, loss: 0.435627
 >> iter 27000, loss: 0.623073
 >> iter 28000, loss: 0.444784
 >> iter 29000, loss: 0.383038
 >> iter 30000, loss: 0.417151
   Number of active neurons: 6
 >> iter 31000, loss: 0.490757
 >> iter 32000, loss: 0.524743
 >> iter 33000, loss: 0.488218
 >> iter 34000, loss: 0.527278
 >> iter 35000, loss: 0.446349
 >> iter 36000, loss: 0.521242
 >> iter 37000, loss: 0.410088
 >> iter 38000, loss: 0.552526
 >> iter 39000, loss: 0.520655
 >> iter 40000, loss: 0.335778
   Number of active neurons: 6
 >> iter 41000, loss: 0.494983
 >> iter 42000, loss: 0.476135
 >> iter 43000, loss: 0.554667
 >> iter 44000, loss: 0.526486
 >> iter 45000, loss: 0.567475
 >> iter 46000, loss: 0.494637
 >> iter 47000, loss: 0.416952
 >> iter 48000, loss: 0.457732
 >> iter 49000, loss: 0.491110
 >> iter 50000, loss: 0.534950
   Number of active neurons: 5
 >> iter 51000, loss: 0.409514
 >> iter 52000, loss: 0.604238
 >> iter 53000, loss: 0.567338
 >> iter 54000, loss: 0.607000
 >> iter 55000, loss: 0.672099
 >> iter 56000, loss: 0.598658
 >> iter 57000, loss: 0.545870
 >> iter 58000, loss: 0.543278
 >> iter 59000, loss: 0.457560
 >> iter 60000, loss: 0.605454
   Number of active neurons: 6
 >> iter 61000, loss: 0.559564
 >> iter 62000, loss: 0.495734
 >> iter 63000, loss: 0.652457
 >> iter 64000, loss: 0.577303
 >> iter 65000, loss: 0.517596
 >> iter 66000, loss: 0.624557
 >> iter 67000, loss: 0.587303
 >> iter 68000, loss: 0.749642
 >> iter 69000, loss: 0.812580
 >> iter 70000, loss: 0.631662
   Number of active neurons: 5
 >> iter 71000, loss: 0.691702
 >> iter 72000, loss: 0.652053
 >> iter 73000, loss: 0.541188
 >> iter 74000, loss: 0.474915
 >> iter 75000, loss: 0.509039
 >> iter 76000, loss: 0.417103
 >> iter 77000, loss: 0.555066
 >> iter 78000, loss: 0.573836
 >> iter 79000, loss: 0.469284
 >> iter 80000, loss: 0.536358
   Number of active neurons: 5
 >> iter 81000, loss: 0.568745
 >> iter 82000, loss: 0.459885
 >> iter 83000, loss: 0.480818
 >> iter 84000, loss: 0.536026
 >> iter 85000, loss: 0.572088
 >> iter 86000, loss: 0.661909
 >> iter 87000, loss: 0.523299
 >> iter 88000, loss: 0.504720
 >> iter 89000, loss: 0.515029
 >> iter 90000, loss: 0.720805
   Number of active neurons: 5
 >> iter 91000, loss: 0.618908
 >> iter 92000, loss: 0.496336
 >> iter 93000, loss: 0.508289
 >> iter 94000, loss: 0.580207
 >> iter 95000, loss: 0.629903
 >> iter 96000, loss: 0.630014
 >> iter 97000, loss: 0.642100
 >> iter 98000, loss: 0.447134
 >> iter 99000, loss: 0.600955
 >> iter 100000, loss: 0.470856
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 17.040223
 >> iter 2000, loss: 10.564419
 >> iter 3000, loss: 6.777650
 >> iter 4000, loss: 3.656425
 >> iter 5000, loss: 2.112002
 >> iter 6000, loss: 1.233302
 >> iter 7000, loss: 0.776482
 >> iter 8000, loss: 0.561774
 >> iter 9000, loss: 0.551834
 >> iter 10000, loss: 0.479835
   Number of active neurons: 5
 >> iter 11000, loss: 0.305186
 >> iter 12000, loss: 0.428253
 >> iter 13000, loss: 0.435374
 >> iter 14000, loss: 0.343189
 >> iter 15000, loss: 0.258914
 >> iter 16000, loss: 0.322932
 >> iter 17000, loss: 0.520716
 >> iter 18000, loss: 0.358652
 >> iter 19000, loss: 0.357520
 >> iter 20000, loss: 0.417455
   Number of active neurons: 5
 >> iter 21000, loss: 0.389890
 >> iter 22000, loss: 0.398419
 >> iter 23000, loss: 0.436347
 >> iter 24000, loss: 0.394728
 >> iter 25000, loss: 0.382203
 >> iter 26000, loss: 0.355400
 >> iter 27000, loss: 0.359875
 >> iter 28000, loss: 0.401464
 >> iter 29000, loss: 0.516320
 >> iter 30000, loss: 0.379490
   Number of active neurons: 5
 >> iter 31000, loss: 0.407227
 >> iter 32000, loss: 0.339312
 >> iter 33000, loss: 0.400080
 >> iter 34000, loss: 0.355244
 >> iter 35000, loss: 0.264672
 >> iter 36000, loss: 0.449798
 >> iter 37000, loss: 0.310087
 >> iter 38000, loss: 0.378503
 >> iter 39000, loss: 0.395416
 >> iter 40000, loss: 0.421744
   Number of active neurons: 5
 >> iter 41000, loss: 0.546098
 >> iter 42000, loss: 0.371758
 >> iter 43000, loss: 0.400423
 >> iter 44000, loss: 0.371631
 >> iter 45000, loss: 0.256612
 >> iter 46000, loss: 0.297829
 >> iter 47000, loss: 0.478785
 >> iter 48000, loss: 0.450972
 >> iter 49000, loss: 0.519535
 >> iter 50000, loss: 0.422992
   Number of active neurons: 5
 >> iter 51000, loss: 0.430582
 >> iter 52000, loss: 0.374431
 >> iter 53000, loss: 0.407136
 >> iter 54000, loss: 0.346569
 >> iter 55000, loss: 0.339309
 >> iter 56000, loss: 0.291874
 >> iter 57000, loss: 0.286580
 >> iter 58000, loss: 0.503550
 >> iter 59000, loss: 0.501757
 >> iter 60000, loss: 0.546376
   Number of active neurons: 7
 >> iter 61000, loss: 0.393941
 >> iter 62000, loss: 0.382719
 >> iter 63000, loss: 0.550419
 >> iter 64000, loss: 0.424966
 >> iter 65000, loss: 0.327656
 >> iter 66000, loss: 0.333118
 >> iter 67000, loss: 0.517195
 >> iter 68000, loss: 0.446946
 >> iter 69000, loss: 0.326748
 >> iter 70000, loss: 0.363983
   Number of active neurons: 5
 >> iter 71000, loss: 0.355153
 >> iter 72000, loss: 0.541958
 >> iter 73000, loss: 0.410242
 >> iter 74000, loss: 0.492391
 >> iter 75000, loss: 0.560258
 >> iter 76000, loss: 0.507846
 >> iter 77000, loss: 0.517658
 >> iter 78000, loss: 0.338183
 >> iter 79000, loss: 0.412449
 >> iter 80000, loss: 0.478695
   Number of active neurons: 4
 >> iter 81000, loss: 0.582883
 >> iter 82000, loss: 0.509943
 >> iter 83000, loss: 0.371331
 >> iter 84000, loss: 0.318027
 >> iter 85000, loss: 0.360289
 >> iter 86000, loss: 0.276012
 >> iter 87000, loss: 0.437649
 >> iter 88000, loss: 0.367038
 >> iter 89000, loss: 0.305701
 >> iter 90000, loss: 0.484851
   Number of active neurons: 4
 >> iter 91000, loss: 0.450146
 >> iter 92000, loss: 0.490648
 >> iter 93000, loss: 0.426988
 >> iter 94000, loss: 0.400356
 >> iter 95000, loss: 0.366883
 >> iter 96000, loss: 0.378756
 >> iter 97000, loss: 0.421046
 >> iter 98000, loss: 0.410152
 >> iter 99000, loss: 0.362449
 >> iter 100000, loss: 0.339634
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.854877
 >> iter 2000, loss: 9.717144
 >> iter 3000, loss: 6.061494
 >> iter 4000, loss: 3.547190
 >> iter 5000, loss: 2.220454
 >> iter 6000, loss: 1.496310
 >> iter 7000, loss: 1.251199
 >> iter 8000, loss: 0.842350
 >> iter 9000, loss: 0.740603
 >> iter 10000, loss: 0.597274
   Number of active neurons: 6
 >> iter 11000, loss: 0.744101
 >> iter 12000, loss: 0.571209
 >> iter 13000, loss: 0.523260
 >> iter 14000, loss: 0.463658
 >> iter 15000, loss: 0.495529
 >> iter 16000, loss: 0.523338
 >> iter 17000, loss: 0.547273
 >> iter 18000, loss: 0.399707
 >> iter 19000, loss: 0.406614
 >> iter 20000, loss: 0.474303
   Number of active neurons: 6
 >> iter 21000, loss: 0.636355
 >> iter 22000, loss: 0.570123
 >> iter 23000, loss: 0.555990
 >> iter 24000, loss: 0.515629
 >> iter 25000, loss: 0.555907
 >> iter 26000, loss: 0.525244
 >> iter 27000, loss: 0.505582
 >> iter 28000, loss: 0.664721
 >> iter 29000, loss: 0.513751
 >> iter 30000, loss: 0.506286
   Number of active neurons: 6
 >> iter 31000, loss: 0.506748
 >> iter 32000, loss: 0.586749
 >> iter 33000, loss: 0.658019
 >> iter 34000, loss: 0.616558
 >> iter 35000, loss: 0.387177
 >> iter 36000, loss: 0.439376
 >> iter 37000, loss: 0.433043
 >> iter 38000, loss: 0.475154
 >> iter 39000, loss: 0.487180
 >> iter 40000, loss: 0.717766
   Number of active neurons: 6
 >> iter 41000, loss: 0.616538
 >> iter 42000, loss: 0.415885
 >> iter 43000, loss: 0.498626
 >> iter 44000, loss: 0.495468
 >> iter 45000, loss: 0.406351
 >> iter 46000, loss: 0.419011
 >> iter 47000, loss: 0.576635
 >> iter 48000, loss: 0.700497
 >> iter 49000, loss: 0.616598
 >> iter 50000, loss: 0.624949
   Number of active neurons: 6
 >> iter 51000, loss: 0.541938
 >> iter 52000, loss: 0.471509
 >> iter 53000, loss: 0.372721
 >> iter 54000, loss: 0.370204
 >> iter 55000, loss: 0.343175
 >> iter 56000, loss: 0.351175
 >> iter 57000, loss: 0.443264
 >> iter 58000, loss: 0.569001
 >> iter 59000, loss: 0.491064
 >> iter 60000, loss: 0.378118
   Number of active neurons: 6
 >> iter 61000, loss: 0.433630
 >> iter 62000, loss: 0.492832
 >> iter 63000, loss: 0.550831
 >> iter 64000, loss: 0.499446
 >> iter 65000, loss: 0.507120
 >> iter 66000, loss: 0.500316
 >> iter 67000, loss: 0.387034
 >> iter 68000, loss: 0.447966
 >> iter 69000, loss: 0.461188
 >> iter 70000, loss: 0.398715
   Number of active neurons: 7
 >> iter 71000, loss: 0.355499
 >> iter 72000, loss: 0.419606
 >> iter 73000, loss: 0.365850
 >> iter 74000, loss: 0.380638
 >> iter 75000, loss: 0.360814
 >> iter 76000, loss: 0.334550
 >> iter 77000, loss: 0.487864
 >> iter 78000, loss: 0.396887
 >> iter 79000, loss: 0.484096
 >> iter 80000, loss: 0.726903
   Number of active neurons: 6
 >> iter 81000, loss: 0.512191
 >> iter 82000, loss: 0.352895
 >> iter 83000, loss: 0.417408
 >> iter 84000, loss: 0.327693
 >> iter 85000, loss: 0.352774
 >> iter 86000, loss: 0.460054
 >> iter 87000, loss: 0.325375
 >> iter 88000, loss: 0.364743
 >> iter 89000, loss: 0.335214
 >> iter 90000, loss: 0.358794
   Number of active neurons: 5
 >> iter 91000, loss: 0.435457
 >> iter 92000, loss: 0.488468
 >> iter 93000, loss: 0.421327
 >> iter 94000, loss: 0.405905
 >> iter 95000, loss: 0.292852
 >> iter 96000, loss: 0.268806
 >> iter 97000, loss: 0.226157
 >> iter 98000, loss: 0.309821
 >> iter 99000, loss: 0.348830
 >> iter 100000, loss: 0.473861
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.00599988000241
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 24.3917072195
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.695590
 >> iter 2000, loss: 9.546193
 >> iter 3000, loss: 4.868504
 >> iter 4000, loss: 2.392675
 >> iter 5000, loss: 1.358393
 >> iter 6000, loss: 0.903067
 >> iter 7000, loss: 0.738556
 >> iter 8000, loss: 0.607012
 >> iter 9000, loss: 0.672651
 >> iter 10000, loss: 0.595788
   Number of active neurons: 7
 >> iter 11000, loss: 0.426619
 >> iter 12000, loss: 0.466202
 >> iter 13000, loss: 0.467322
 >> iter 14000, loss: 0.314197
 >> iter 15000, loss: 0.459849
 >> iter 16000, loss: 0.407139
 >> iter 17000, loss: 0.432624
 >> iter 18000, loss: 0.397907
 >> iter 19000, loss: 0.554802
 >> iter 20000, loss: 0.479558
   Number of active neurons: 6
 >> iter 21000, loss: 0.355937
 >> iter 22000, loss: 0.356120
 >> iter 23000, loss: 0.496892
 >> iter 24000, loss: 0.372054
 >> iter 25000, loss: 0.278021
 >> iter 26000, loss: 0.263587
 >> iter 27000, loss: 0.606657
 >> iter 28000, loss: 0.514292
 >> iter 29000, loss: 0.559837
 >> iter 30000, loss: 0.643545
   Number of active neurons: 8
 >> iter 31000, loss: 0.462751
 >> iter 32000, loss: 0.402197
 >> iter 33000, loss: 0.475604
 >> iter 34000, loss: 0.392189
 >> iter 35000, loss: 0.509066
 >> iter 36000, loss: 0.508046
 >> iter 37000, loss: 0.446231
 >> iter 38000, loss: 0.407608
 >> iter 39000, loss: 0.484949
 >> iter 40000, loss: 0.491108
   Number of active neurons: 5
 >> iter 41000, loss: 0.543396
 >> iter 42000, loss: 0.552423
 >> iter 43000, loss: 0.583377
 >> iter 44000, loss: 0.452717
 >> iter 45000, loss: 0.456925
 >> iter 46000, loss: 0.616270
 >> iter 47000, loss: 0.487455
 >> iter 48000, loss: 0.448293
 >> iter 49000, loss: 0.360105
 >> iter 50000, loss: 0.395897
   Number of active neurons: 5
 >> iter 51000, loss: 0.381452
 >> iter 52000, loss: 0.314046
 >> iter 53000, loss: 0.376615
 >> iter 54000, loss: 0.415535
 >> iter 55000, loss: 0.431374
 >> iter 56000, loss: 0.477233
 >> iter 57000, loss: 0.491445
 >> iter 58000, loss: 0.461564
 >> iter 59000, loss: 0.442286
 >> iter 60000, loss: 0.431875
   Number of active neurons: 5
 >> iter 61000, loss: 0.406242
 >> iter 62000, loss: 0.481071
 >> iter 63000, loss: 0.484119
 >> iter 64000, loss: 0.585705
 >> iter 65000, loss: 0.445012
 >> iter 66000, loss: 0.387941
 >> iter 67000, loss: 0.449412
 >> iter 68000, loss: 0.394326
 >> iter 69000, loss: 0.411439
 >> iter 70000, loss: 0.591673
   Number of active neurons: 5
 >> iter 71000, loss: 0.480946
 >> iter 72000, loss: 0.504993
 >> iter 73000, loss: 0.619591
 >> iter 74000, loss: 0.574594
 >> iter 75000, loss: 0.505405
 >> iter 76000, loss: 0.611074
 >> iter 77000, loss: 0.520994
 >> iter 78000, loss: 0.658343
 >> iter 79000, loss: 0.558182
 >> iter 80000, loss: 0.511198
   Number of active neurons: 5
 >> iter 81000, loss: 0.621944
 >> iter 82000, loss: 0.702139
 >> iter 83000, loss: 0.701978
 >> iter 84000, loss: 0.658984
 >> iter 85000, loss: 0.709042
 >> iter 86000, loss: 0.627017
 >> iter 87000, loss: 0.556677
 >> iter 88000, loss: 0.586748
 >> iter 89000, loss: 0.567466
 >> iter 90000, loss: 0.542274
   Number of active neurons: 5
 >> iter 91000, loss: 0.659553
 >> iter 92000, loss: 0.684110
 >> iter 93000, loss: 0.720846
 >> iter 94000, loss: 0.594274
 >> iter 95000, loss: 0.683963
 >> iter 96000, loss: 0.582274
 >> iter 97000, loss: 0.754448
 >> iter 98000, loss: 0.733739
 >> iter 99000, loss: 0.766459
 >> iter 100000, loss: 0.668354
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.677276
 >> iter 2000, loss: 10.407377
 >> iter 3000, loss: 6.308207
 >> iter 4000, loss: 3.716424
 >> iter 5000, loss: 2.029817
 >> iter 6000, loss: 1.283075
 >> iter 7000, loss: 1.029848
 >> iter 8000, loss: 0.615372
 >> iter 9000, loss: 0.438334
 >> iter 10000, loss: 0.446054
   Number of active neurons: 8
 >> iter 11000, loss: 0.303830
 >> iter 12000, loss: 0.302195
 >> iter 13000, loss: 0.369053
 >> iter 14000, loss: 0.365843
 >> iter 15000, loss: 0.381160
 >> iter 16000, loss: 0.401983
 >> iter 17000, loss: 0.353166
 >> iter 18000, loss: 0.279442
 >> iter 19000, loss: 0.360412
 >> iter 20000, loss: 0.406735
   Number of active neurons: 8
 >> iter 21000, loss: 0.473384
 >> iter 22000, loss: 0.338802
 >> iter 23000, loss: 0.364627
 >> iter 24000, loss: 0.460819
 >> iter 25000, loss: 0.335869
 >> iter 26000, loss: 0.238195
 >> iter 27000, loss: 0.244768
 >> iter 28000, loss: 0.326347
 >> iter 29000, loss: 0.296312
 >> iter 30000, loss: 0.424648
   Number of active neurons: 7
 >> iter 31000, loss: 0.318004
 >> iter 32000, loss: 0.464023
 >> iter 33000, loss: 0.389861
 >> iter 34000, loss: 0.374052
 >> iter 35000, loss: 0.421585
 >> iter 36000, loss: 0.334626
 >> iter 37000, loss: 0.373164
 >> iter 38000, loss: 0.342319
 >> iter 39000, loss: 0.395682
 >> iter 40000, loss: 0.270189
   Number of active neurons: 7
 >> iter 41000, loss: 0.239136
 >> iter 42000, loss: 0.374490
 >> iter 43000, loss: 0.311112
 >> iter 44000, loss: 0.316516
 >> iter 45000, loss: 0.254946
 >> iter 46000, loss: 0.175853
 >> iter 47000, loss: 0.226378
 >> iter 48000, loss: 0.275041
 >> iter 49000, loss: 0.229331
 >> iter 50000, loss: 0.343150
   Number of active neurons: 7
 >> iter 51000, loss: 0.371923
 >> iter 52000, loss: 0.288098
 >> iter 53000, loss: 0.386935
 >> iter 54000, loss: 0.373916
 >> iter 55000, loss: 0.382670
 >> iter 56000, loss: 0.481938
 >> iter 57000, loss: 0.520695
 >> iter 58000, loss: 0.453420
 >> iter 59000, loss: 0.400813
 >> iter 60000, loss: 0.256283
   Number of active neurons: 6
 >> iter 61000, loss: 0.299675
 >> iter 62000, loss: 0.268314
 >> iter 63000, loss: 0.292941
 >> iter 64000, loss: 0.235066
 >> iter 65000, loss: 0.320854
 >> iter 66000, loss: 0.370591
 >> iter 67000, loss: 0.412991
 >> iter 68000, loss: 0.436952
 >> iter 69000, loss: 0.410078
 >> iter 70000, loss: 0.416405
   Number of active neurons: 5
 >> iter 71000, loss: 0.342089
 >> iter 72000, loss: 0.274573
 >> iter 73000, loss: 0.324563
 >> iter 74000, loss: 0.247458
 >> iter 75000, loss: 0.365988
 >> iter 76000, loss: 0.365351
 >> iter 77000, loss: 0.308218
 >> iter 78000, loss: 0.312369
 >> iter 79000, loss: 0.320836
 >> iter 80000, loss: 0.455930
   Number of active neurons: 5
 >> iter 81000, loss: 0.409250
 >> iter 82000, loss: 0.291916
 >> iter 83000, loss: 0.244793
 >> iter 84000, loss: 0.395351
 >> iter 85000, loss: 0.340437
 >> iter 86000, loss: 0.278192
 >> iter 87000, loss: 0.328892
 >> iter 88000, loss: 0.320488
 >> iter 89000, loss: 0.256817
 >> iter 90000, loss: 0.256882
   Number of active neurons: 5
 >> iter 91000, loss: 0.357530
 >> iter 92000, loss: 0.402890
 >> iter 93000, loss: 0.342821
 >> iter 94000, loss: 0.290437
 >> iter 95000, loss: 0.218719
 >> iter 96000, loss: 0.274204
 >> iter 97000, loss: 0.356185
 >> iter 98000, loss: 0.372402
 >> iter 99000, loss: 0.295370
 >> iter 100000, loss: 0.289542
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.900760
 >> iter 2000, loss: 9.970962
 >> iter 3000, loss: 5.877849
 >> iter 4000, loss: 3.286836
 >> iter 5000, loss: 2.105122
 >> iter 6000, loss: 1.503667
 >> iter 7000, loss: 1.104638
 >> iter 8000, loss: 0.869897
 >> iter 9000, loss: 0.765647
 >> iter 10000, loss: 0.639604
   Number of active neurons: 7
 >> iter 11000, loss: 0.696150
 >> iter 12000, loss: 0.610926
 >> iter 13000, loss: 0.508943
 >> iter 14000, loss: 0.452444
 >> iter 15000, loss: 0.422800
 >> iter 16000, loss: 0.477163
 >> iter 17000, loss: 0.428341
 >> iter 18000, loss: 0.471826
 >> iter 19000, loss: 0.446204
 >> iter 20000, loss: 0.487340
   Number of active neurons: 7
 >> iter 21000, loss: 0.497022
 >> iter 22000, loss: 0.571910
 >> iter 23000, loss: 0.469516
 >> iter 24000, loss: 0.420995
 >> iter 25000, loss: 0.528163
 >> iter 26000, loss: 0.493344
 >> iter 27000, loss: 0.546431
 >> iter 28000, loss: 0.613237
 >> iter 29000, loss: 0.605986
 >> iter 30000, loss: 0.423862
   Number of active neurons: 7
 >> iter 31000, loss: 0.565422
 >> iter 32000, loss: 0.503897
 >> iter 33000, loss: 0.553325
 >> iter 34000, loss: 0.421988
 >> iter 35000, loss: 0.470243
 >> iter 36000, loss: 0.479137
 >> iter 37000, loss: 0.396587
 >> iter 38000, loss: 0.400665
 >> iter 39000, loss: 0.453198
 >> iter 40000, loss: 0.359419
   Number of active neurons: 7
 >> iter 41000, loss: 0.456009
 >> iter 42000, loss: 0.436292
 >> iter 43000, loss: 0.456067
 >> iter 44000, loss: 0.481188
 >> iter 45000, loss: 0.426021
 >> iter 46000, loss: 0.488386
 >> iter 47000, loss: 0.440505
 >> iter 48000, loss: 0.343090
 >> iter 49000, loss: 0.466709
 >> iter 50000, loss: 0.441694
   Number of active neurons: 7
 >> iter 51000, loss: 0.517504
 >> iter 52000, loss: 0.341941
 >> iter 53000, loss: 0.449874
 >> iter 54000, loss: 0.443121
 >> iter 55000, loss: 0.704129
 >> iter 56000, loss: 0.513877
 >> iter 57000, loss: 0.387428
 >> iter 58000, loss: 0.464290
 >> iter 59000, loss: 0.451490
 >> iter 60000, loss: 0.398988
   Number of active neurons: 6
 >> iter 61000, loss: 0.419642
 >> iter 62000, loss: 0.339540
 >> iter 63000, loss: 0.358829
 >> iter 64000, loss: 0.333031
 >> iter 65000, loss: 0.340150
 >> iter 66000, loss: 0.399473
 >> iter 67000, loss: 0.413331
 >> iter 68000, loss: 0.560667
 >> iter 69000, loss: 0.516155
 >> iter 70000, loss: 0.436637
   Number of active neurons: 5
 >> iter 71000, loss: 0.315170
 >> iter 72000, loss: 0.372744
 >> iter 73000, loss: 0.300835
 >> iter 74000, loss: 0.265163
 >> iter 75000, loss: 0.317916
 >> iter 76000, loss: 0.342555
 >> iter 77000, loss: 0.309831
 >> iter 78000, loss: 0.320602
 >> iter 79000, loss: 0.335986
 >> iter 80000, loss: 0.401307
   Number of active neurons: 5
 >> iter 81000, loss: 0.405194
 >> iter 82000, loss: 0.296205
 >> iter 83000, loss: 0.332346
 >> iter 84000, loss: 0.298079
 >> iter 85000, loss: 0.342612
 >> iter 86000, loss: 0.300736
 >> iter 87000, loss: 0.340832
 >> iter 88000, loss: 0.379514
 >> iter 89000, loss: 0.264708
 >> iter 90000, loss: 0.278957
   Number of active neurons: 5
 >> iter 91000, loss: 0.351096
 >> iter 92000, loss: 0.398256
 >> iter 93000, loss: 0.422385
 >> iter 94000, loss: 0.536667
 >> iter 95000, loss: 0.512877
 >> iter 96000, loss: 0.365692
 >> iter 97000, loss: 0.438729
 >> iter 98000, loss: 0.415977
 >> iter 99000, loss: 0.409178
 >> iter 100000, loss: 0.386550
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.731429
 >> iter 2000, loss: 10.189751
 >> iter 3000, loss: 6.050026
 >> iter 4000, loss: 3.950890
 >> iter 5000, loss: 2.604889
 >> iter 6000, loss: 1.747256
 >> iter 7000, loss: 1.212897
 >> iter 8000, loss: 0.850063
 >> iter 9000, loss: 0.802206
 >> iter 10000, loss: 0.763918
   Number of active neurons: 6
 >> iter 11000, loss: 0.704571
 >> iter 12000, loss: 0.552724
 >> iter 13000, loss: 0.741485
 >> iter 14000, loss: 0.628326
 >> iter 15000, loss: 0.619022
 >> iter 16000, loss: 0.736438
 >> iter 17000, loss: 0.543680
 >> iter 18000, loss: 0.387309
 >> iter 19000, loss: 0.483863
 >> iter 20000, loss: 0.486105
   Number of active neurons: 6
 >> iter 21000, loss: 0.451588
 >> iter 22000, loss: 0.431365
 >> iter 23000, loss: 0.482814
 >> iter 24000, loss: 0.667537
 >> iter 25000, loss: 0.700350
 >> iter 26000, loss: 0.680493
 >> iter 27000, loss: 0.504069
 >> iter 28000, loss: 0.368785
 >> iter 29000, loss: 0.411534
 >> iter 30000, loss: 0.385839
   Number of active neurons: 6
 >> iter 31000, loss: 0.397454
 >> iter 32000, loss: 0.490503
 >> iter 33000, loss: 0.518328
 >> iter 34000, loss: 0.432448
 >> iter 35000, loss: 0.459279
 >> iter 36000, loss: 0.373083
 >> iter 37000, loss: 0.403148
 >> iter 38000, loss: 0.453358
 >> iter 39000, loss: 0.482350
 >> iter 40000, loss: 0.364601
   Number of active neurons: 6
 >> iter 41000, loss: 0.317882
 >> iter 42000, loss: 0.380955
 >> iter 43000, loss: 0.359854
 >> iter 44000, loss: 0.494633
 >> iter 45000, loss: 0.514322
 >> iter 46000, loss: 0.442797
 >> iter 47000, loss: 0.473204
 >> iter 48000, loss: 0.393178
 >> iter 49000, loss: 0.340925
 >> iter 50000, loss: 0.438272
   Number of active neurons: 6
 >> iter 51000, loss: 0.494433
 >> iter 52000, loss: 0.433560
 >> iter 53000, loss: 0.366910
 >> iter 54000, loss: 0.371517
 >> iter 55000, loss: 0.319826
 >> iter 56000, loss: 0.349112
 >> iter 57000, loss: 0.300600
 >> iter 58000, loss: 0.360544
 >> iter 59000, loss: 0.358857
 >> iter 60000, loss: 0.395048
   Number of active neurons: 6
 >> iter 61000, loss: 0.468549
 >> iter 62000, loss: 0.427427
 >> iter 63000, loss: 0.379814
 >> iter 64000, loss: 0.367883
 >> iter 65000, loss: 0.319066
 >> iter 66000, loss: 0.374065
 >> iter 67000, loss: 0.316012
 >> iter 68000, loss: 0.333696
 >> iter 69000, loss: 0.347849
 >> iter 70000, loss: 0.362298
   Number of active neurons: 6
 >> iter 71000, loss: 0.371269
 >> iter 72000, loss: 0.517582
 >> iter 73000, loss: 0.579261
 >> iter 74000, loss: 0.435546
 >> iter 75000, loss: 0.357475
 >> iter 76000, loss: 0.284189
 >> iter 77000, loss: 0.361161
 >> iter 78000, loss: 0.309404
 >> iter 79000, loss: 0.375721
 >> iter 80000, loss: 0.340865
   Number of active neurons: 6
 >> iter 81000, loss: 0.341434
 >> iter 82000, loss: 0.411800
 >> iter 83000, loss: 0.479149
 >> iter 84000, loss: 0.409590
 >> iter 85000, loss: 0.671800
 >> iter 86000, loss: 0.475746
 >> iter 87000, loss: 0.526750
 >> iter 88000, loss: 0.420572
 >> iter 89000, loss: 0.432656
 >> iter 90000, loss: 0.408900
   Number of active neurons: 6
 >> iter 91000, loss: 0.390263
 >> iter 92000, loss: 0.393416
 >> iter 93000, loss: 0.438202
 >> iter 94000, loss: 0.417202
 >> iter 95000, loss: 0.472564
 >> iter 96000, loss: 0.409306
 >> iter 97000, loss: 0.436730
 >> iter 98000, loss: 0.393370
 >> iter 99000, loss: 0.481703
 >> iter 100000, loss: 0.493964
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.599149
 >> iter 2000, loss: 9.903257
 >> iter 3000, loss: 5.815077
 >> iter 4000, loss: 2.872275
 >> iter 5000, loss: 1.458877
 >> iter 6000, loss: 0.756873
 >> iter 7000, loss: 0.531927
 >> iter 8000, loss: 0.421439
 >> iter 9000, loss: 0.391491
 >> iter 10000, loss: 0.316164
   Number of active neurons: 6
 >> iter 11000, loss: 0.392104
 >> iter 12000, loss: 0.278624
 >> iter 13000, loss: 0.396894
 >> iter 14000, loss: 0.375385
 >> iter 15000, loss: 0.345217
 >> iter 16000, loss: 0.374262
 >> iter 17000, loss: 0.291416
 >> iter 18000, loss: 0.249651
 >> iter 19000, loss: 0.252466
 >> iter 20000, loss: 0.187653
   Number of active neurons: 6
 >> iter 21000, loss: 0.366065
 >> iter 22000, loss: 0.395949
 >> iter 23000, loss: 0.392427
 >> iter 24000, loss: 0.360086
 >> iter 25000, loss: 0.335445
 >> iter 26000, loss: 0.413473
 >> iter 27000, loss: 0.428863
 >> iter 28000, loss: 0.438848
 >> iter 29000, loss: 0.318204
 >> iter 30000, loss: 0.308052
   Number of active neurons: 6
 >> iter 31000, loss: 0.403750
 >> iter 32000, loss: 0.368095
 >> iter 33000, loss: 0.326945
 >> iter 34000, loss: 0.359566
 >> iter 35000, loss: 0.317669
 >> iter 36000, loss: 0.302815
 >> iter 37000, loss: 0.292280
 >> iter 38000, loss: 0.351194
 >> iter 39000, loss: 0.440009
 >> iter 40000, loss: 0.382247
   Number of active neurons: 6
 >> iter 41000, loss: 0.340887
 >> iter 42000, loss: 0.374074
 >> iter 43000, loss: 0.341935
 >> iter 44000, loss: 0.298547
 >> iter 45000, loss: 0.266283
 >> iter 46000, loss: 0.269734
 >> iter 47000, loss: 0.287596
 >> iter 48000, loss: 0.329842
 >> iter 49000, loss: 0.323115
 >> iter 50000, loss: 0.381687
   Number of active neurons: 6
 >> iter 51000, loss: 0.289639
 >> iter 52000, loss: 0.213132
 >> iter 53000, loss: 0.309435
 >> iter 54000, loss: 0.307418
 >> iter 55000, loss: 0.405724
 >> iter 56000, loss: 0.311906
 >> iter 57000, loss: 0.432318
 >> iter 58000, loss: 0.423109
 >> iter 59000, loss: 0.391573
 >> iter 60000, loss: 0.276558
   Number of active neurons: 6
 >> iter 61000, loss: 0.295448
 >> iter 62000, loss: 0.383214
 >> iter 63000, loss: 0.513485
 >> iter 64000, loss: 0.433577
 >> iter 65000, loss: 0.408165
 >> iter 66000, loss: 0.344222
 >> iter 67000, loss: 0.291120
 >> iter 68000, loss: 0.357794
 >> iter 69000, loss: 0.406796
 >> iter 70000, loss: 0.380261
   Number of active neurons: 6
 >> iter 71000, loss: 0.435510
 >> iter 72000, loss: 0.502231
 >> iter 73000, loss: 0.331968
 >> iter 74000, loss: 0.365561
 >> iter 75000, loss: 0.450946
 >> iter 76000, loss: 0.413843
 >> iter 77000, loss: 0.319508
 >> iter 78000, loss: 0.357334
 >> iter 79000, loss: 0.353052
 >> iter 80000, loss: 0.320051
   Number of active neurons: 5
 >> iter 81000, loss: 0.281992
 >> iter 82000, loss: 0.281708
 >> iter 83000, loss: 0.307495
 >> iter 84000, loss: 0.267424
 >> iter 85000, loss: 0.352959
 >> iter 86000, loss: 0.359924
 >> iter 87000, loss: 0.306035
 >> iter 88000, loss: 0.261710
 >> iter 89000, loss: 0.233220
 >> iter 90000, loss: 0.230643
   Number of active neurons: 5
 >> iter 91000, loss: 0.384076
 >> iter 92000, loss: 0.358693
 >> iter 93000, loss: 0.416541
 >> iter 94000, loss: 0.354893
 >> iter 95000, loss: 0.381652
 >> iter 96000, loss: 0.323845
 >> iter 97000, loss: 0.262800
 >> iter 98000, loss: 0.280504
 >> iter 99000, loss: 0.180488
 >> iter 100000, loss: 0.204999
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.700088
 >> iter 2000, loss: 11.095937
 >> iter 3000, loss: 7.239315
 >> iter 4000, loss: 4.404518
 >> iter 5000, loss: 2.777385
 >> iter 6000, loss: 1.910366
 >> iter 7000, loss: 1.484168
 >> iter 8000, loss: 1.222188
 >> iter 9000, loss: 1.033483
 >> iter 10000, loss: 0.695561
   Number of active neurons: 7
 >> iter 11000, loss: 0.658978
 >> iter 12000, loss: 0.639341
 >> iter 13000, loss: 0.623397
 >> iter 14000, loss: 0.553217
 >> iter 15000, loss: 0.658756
 >> iter 16000, loss: 0.610304
 >> iter 17000, loss: 0.575884
 >> iter 18000, loss: 0.527221
 >> iter 19000, loss: 0.525116
 >> iter 20000, loss: 0.619218
   Number of active neurons: 5
 >> iter 21000, loss: 0.745543
 >> iter 22000, loss: 0.546483
 >> iter 23000, loss: 0.508553
 >> iter 24000, loss: 0.482105
 >> iter 25000, loss: 0.423268
 >> iter 26000, loss: 0.532922
 >> iter 27000, loss: 0.613740
 >> iter 28000, loss: 0.471575
 >> iter 29000, loss: 0.498232
 >> iter 30000, loss: 0.489621
   Number of active neurons: 4
 >> iter 31000, loss: 0.447879
 >> iter 32000, loss: 0.604987
 >> iter 33000, loss: 0.568765
 >> iter 34000, loss: 0.454661
 >> iter 35000, loss: 0.520398
 >> iter 36000, loss: 0.499766
 >> iter 37000, loss: 0.518797
 >> iter 38000, loss: 0.473904
 >> iter 39000, loss: 0.355989
 >> iter 40000, loss: 0.415425
   Number of active neurons: 4
 >> iter 41000, loss: 0.521262
 >> iter 42000, loss: 0.568541
 >> iter 43000, loss: 0.463050
 >> iter 44000, loss: 0.514389
 >> iter 45000, loss: 0.467374
 >> iter 46000, loss: 0.544844
 >> iter 47000, loss: 0.484280
 >> iter 48000, loss: 0.440279
 >> iter 49000, loss: 0.482109
 >> iter 50000, loss: 0.408648
   Number of active neurons: 4
 >> iter 51000, loss: 0.427393
 >> iter 52000, loss: 0.451079
 >> iter 53000, loss: 0.332538
 >> iter 54000, loss: 0.372453
 >> iter 55000, loss: 0.317517
 >> iter 56000, loss: 0.348008
 >> iter 57000, loss: 0.522155
 >> iter 58000, loss: 0.466280
 >> iter 59000, loss: 0.469103
 >> iter 60000, loss: 0.450981
   Number of active neurons: 4
 >> iter 61000, loss: 0.573573
 >> iter 62000, loss: 0.378876
 >> iter 63000, loss: 0.398848
 >> iter 64000, loss: 0.543117
 >> iter 65000, loss: 0.545030
 >> iter 66000, loss: 0.693221
 >> iter 67000, loss: 0.916998
 >> iter 68000, loss: 0.677461
 >> iter 69000, loss: 0.630007
 >> iter 70000, loss: 0.600712
   Number of active neurons: 4
 >> iter 71000, loss: 0.565056
 >> iter 72000, loss: 0.499624
 >> iter 73000, loss: 0.420871
 >> iter 74000, loss: 0.571101
 >> iter 75000, loss: 0.505809
 >> iter 76000, loss: 0.470873
 >> iter 77000, loss: 0.496879
 >> iter 78000, loss: 0.383651
 >> iter 79000, loss: 0.325535
 >> iter 80000, loss: 0.422674
   Number of active neurons: 4
 >> iter 81000, loss: 0.328261
 >> iter 82000, loss: 0.369250
 >> iter 83000, loss: 0.508883
 >> iter 84000, loss: 0.466203
 >> iter 85000, loss: 0.580813
 >> iter 86000, loss: 0.523811
 >> iter 87000, loss: 0.490714
 >> iter 88000, loss: 0.425528
 >> iter 89000, loss: 0.440378
 >> iter 90000, loss: 0.491479
   Number of active neurons: 4
 >> iter 91000, loss: 0.557134
 >> iter 92000, loss: 0.518639
 >> iter 93000, loss: 0.596898
 >> iter 94000, loss: 0.474779
 >> iter 95000, loss: 0.419136
 >> iter 96000, loss: 0.576429
 >> iter 97000, loss: 0.472048
 >> iter 98000, loss: 0.492517
 >> iter 99000, loss: 0.573522
 >> iter 100000, loss: 0.479741
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455178
   Number of active neurons: 0
 >> iter 1000, loss: 16.554010
 >> iter 2000, loss: 9.487462
 >> iter 3000, loss: 5.570634
 >> iter 4000, loss: 3.339920
 >> iter 5000, loss: 2.036869
 >> iter 6000, loss: 1.595013
 >> iter 7000, loss: 1.297563
 >> iter 8000, loss: 1.180187
 >> iter 9000, loss: 0.804589
 >> iter 10000, loss: 0.651207
   Number of active neurons: 7
 >> iter 11000, loss: 0.675786
 >> iter 12000, loss: 0.741889
 >> iter 13000, loss: 0.758394
 >> iter 14000, loss: 0.603353
 >> iter 15000, loss: 0.574953
 >> iter 16000, loss: 0.547872
 >> iter 17000, loss: 0.667655
 >> iter 18000, loss: 0.664895
 >> iter 19000, loss: 0.543824
 >> iter 20000, loss: 0.477648
   Number of active neurons: 6
 >> iter 21000, loss: 0.740765
 >> iter 22000, loss: 0.674471
 >> iter 23000, loss: 0.592533
 >> iter 24000, loss: 0.684262
 >> iter 25000, loss: 0.729084
 >> iter 26000, loss: 0.774883
 >> iter 27000, loss: 0.856971
 >> iter 28000, loss: 0.720311
 >> iter 29000, loss: 0.659972
 >> iter 30000, loss: 0.522153
   Number of active neurons: 6
 >> iter 31000, loss: 0.570986
 >> iter 32000, loss: 0.449196
 >> iter 33000, loss: 0.480440
 >> iter 34000, loss: 0.470007
 >> iter 35000, loss: 0.497835
 >> iter 36000, loss: 0.489713
 >> iter 37000, loss: 0.534154
 >> iter 38000, loss: 0.480890
 >> iter 39000, loss: 0.584694
 >> iter 40000, loss: 0.489945
   Number of active neurons: 6
 >> iter 41000, loss: 0.615108
 >> iter 42000, loss: 0.480715
 >> iter 43000, loss: 0.487456
 >> iter 44000, loss: 0.518499
 >> iter 45000, loss: 0.548195
 >> iter 46000, loss: 0.615704
 >> iter 47000, loss: 0.508221
 >> iter 48000, loss: 0.548576
 >> iter 49000, loss: 0.629226
 >> iter 50000, loss: 0.528882
   Number of active neurons: 6
 >> iter 51000, loss: 0.632005
 >> iter 52000, loss: 0.500680
 >> iter 53000, loss: 0.621694
 >> iter 54000, loss: 0.508347
 >> iter 55000, loss: 0.594818
 >> iter 56000, loss: 0.669045
 >> iter 57000, loss: 0.693411
 >> iter 58000, loss: 0.644630
 >> iter 59000, loss: 0.568429
 >> iter 60000, loss: 0.542462
   Number of active neurons: 6
 >> iter 61000, loss: 0.588961
 >> iter 62000, loss: 0.579654
 >> iter 63000, loss: 0.477448
 >> iter 64000, loss: 0.421873
 >> iter 65000, loss: 0.545870
 >> iter 66000, loss: 0.672394
 >> iter 67000, loss: 0.519067
 >> iter 68000, loss: 0.578192
 >> iter 69000, loss: 0.651162
 >> iter 70000, loss: 0.526109
   Number of active neurons: 6
 >> iter 71000, loss: 0.667178
 >> iter 72000, loss: 0.759060
 >> iter 73000, loss: 0.590605
 >> iter 74000, loss: 0.571107
 >> iter 75000, loss: 0.570089
 >> iter 76000, loss: 0.586874
 >> iter 77000, loss: 0.560954
 >> iter 78000, loss: 0.552320
 >> iter 79000, loss: 0.457083
 >> iter 80000, loss: 0.493406
   Number of active neurons: 6
 >> iter 81000, loss: 0.588532
 >> iter 82000, loss: 0.403811
 >> iter 83000, loss: 0.451734
 >> iter 84000, loss: 0.519733
 >> iter 85000, loss: 0.471213
 >> iter 86000, loss: 0.433963
 >> iter 87000, loss: 0.472111
 >> iter 88000, loss: 0.342453
 >> iter 89000, loss: 0.428820
 >> iter 90000, loss: 0.525946
   Number of active neurons: 6
 >> iter 91000, loss: 0.535954
 >> iter 92000, loss: 0.642687
 >> iter 93000, loss: 0.608949
 >> iter 94000, loss: 0.678940
 >> iter 95000, loss: 0.558006
 >> iter 96000, loss: 0.494441
 >> iter 97000, loss: 0.559193
 >> iter 98000, loss: 0.573448
 >> iter 99000, loss: 0.697877
 >> iter 100000, loss: 0.643777
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0039999200016
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.459969335378
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.905405
 >> iter 2000, loss: 9.687005
 >> iter 3000, loss: 4.845055
 >> iter 4000, loss: 2.139995
 >> iter 5000, loss: 0.994337
 >> iter 6000, loss: 0.568041
 >> iter 7000, loss: 0.465899
 >> iter 8000, loss: 0.351920
 >> iter 9000, loss: 0.403585
 >> iter 10000, loss: 0.397560
   Number of active neurons: 6
 >> iter 11000, loss: 0.429593
 >> iter 12000, loss: 0.397337
 >> iter 13000, loss: 0.376104
 >> iter 14000, loss: 0.315872
 >> iter 15000, loss: 0.327854
 >> iter 16000, loss: 0.416892
 >> iter 17000, loss: 0.388218
 >> iter 18000, loss: 0.491856
 >> iter 19000, loss: 0.328080
 >> iter 20000, loss: 0.243658
   Number of active neurons: 5
 >> iter 21000, loss: 0.330259
 >> iter 22000, loss: 0.346580
 >> iter 23000, loss: 0.418076
 >> iter 24000, loss: 0.309263
 >> iter 25000, loss: 0.436672
 >> iter 26000, loss: 0.367759
 >> iter 27000, loss: 0.426880
 >> iter 28000, loss: 0.373696
 >> iter 29000, loss: 0.409427
 >> iter 30000, loss: 0.408947
   Number of active neurons: 5
 >> iter 31000, loss: 0.396703
 >> iter 32000, loss: 0.422461
 >> iter 33000, loss: 0.459063
 >> iter 34000, loss: 0.275597
 >> iter 35000, loss: 0.351344
 >> iter 36000, loss: 0.275077
 >> iter 37000, loss: 0.330316
 >> iter 38000, loss: 0.419698
 >> iter 39000, loss: 0.352931
 >> iter 40000, loss: 0.370693
   Number of active neurons: 5
 >> iter 41000, loss: 0.532684
 >> iter 42000, loss: 0.430327
 >> iter 43000, loss: 0.428651
 >> iter 44000, loss: 0.369735
 >> iter 45000, loss: 0.366510
 >> iter 46000, loss: 0.297613
 >> iter 47000, loss: 0.325474
 >> iter 48000, loss: 0.292497
 >> iter 49000, loss: 0.321553
 >> iter 50000, loss: 0.288179
   Number of active neurons: 5
 >> iter 51000, loss: 0.269981
 >> iter 52000, loss: 0.297438
 >> iter 53000, loss: 0.331695
 >> iter 54000, loss: 0.354062
 >> iter 55000, loss: 0.411375
 >> iter 56000, loss: 0.387831
 >> iter 57000, loss: 0.443469
 >> iter 58000, loss: 0.365785
 >> iter 59000, loss: 0.337832
 >> iter 60000, loss: 0.225807
   Number of active neurons: 4
 >> iter 61000, loss: 0.229197
 >> iter 62000, loss: 0.281653
 >> iter 63000, loss: 0.390797
 >> iter 64000, loss: 0.336568
 >> iter 65000, loss: 0.304007
 >> iter 66000, loss: 0.315694
 >> iter 67000, loss: 0.417537
 >> iter 68000, loss: 0.343227
 >> iter 69000, loss: 0.417644
 >> iter 70000, loss: 0.472230
   Number of active neurons: 4
 >> iter 71000, loss: 0.367922
 >> iter 72000, loss: 0.291793
 >> iter 73000, loss: 0.288183
 >> iter 74000, loss: 0.326051
 >> iter 75000, loss: 0.334472
 >> iter 76000, loss: 0.243013
 >> iter 77000, loss: 0.253159
 >> iter 78000, loss: 0.427204
 >> iter 79000, loss: 0.388201
 >> iter 80000, loss: 0.332799
   Number of active neurons: 4
 >> iter 81000, loss: 0.327262
 >> iter 82000, loss: 0.388580
 >> iter 83000, loss: 0.315974
 >> iter 84000, loss: 0.294059
 >> iter 85000, loss: 0.391182
 >> iter 86000, loss: 0.411338
 >> iter 87000, loss: 0.406423
 >> iter 88000, loss: 0.468182
 >> iter 89000, loss: 0.411531
 >> iter 90000, loss: 0.451476
   Number of active neurons: 4
 >> iter 91000, loss: 0.376309
 >> iter 92000, loss: 0.400864
 >> iter 93000, loss: 0.426959
 >> iter 94000, loss: 0.316380
 >> iter 95000, loss: 0.345878
 >> iter 96000, loss: 0.368649
 >> iter 97000, loss: 0.310259
 >> iter 98000, loss: 0.407423
 >> iter 99000, loss: 0.477738
 >> iter 100000, loss: 0.538360
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.895970
 >> iter 2000, loss: 9.702409
 >> iter 3000, loss: 6.099607
 >> iter 4000, loss: 3.844118
 >> iter 5000, loss: 2.537821
 >> iter 6000, loss: 1.779944
 >> iter 7000, loss: 1.380605
 >> iter 8000, loss: 1.060658
 >> iter 9000, loss: 0.755412
 >> iter 10000, loss: 0.649846
   Number of active neurons: 9
 >> iter 11000, loss: 0.695644
 >> iter 12000, loss: 0.530516
 >> iter 13000, loss: 0.513333
 >> iter 14000, loss: 0.475289
 >> iter 15000, loss: 0.333968
 >> iter 16000, loss: 0.472583
 >> iter 17000, loss: 0.411385
 >> iter 18000, loss: 0.441272
 >> iter 19000, loss: 0.383030
 >> iter 20000, loss: 0.349476
   Number of active neurons: 8
 >> iter 21000, loss: 0.595633
 >> iter 22000, loss: 0.538039
 >> iter 23000, loss: 0.424472
 >> iter 24000, loss: 0.410218
 >> iter 25000, loss: 0.562365
 >> iter 26000, loss: 0.619951
 >> iter 27000, loss: 0.514626
 >> iter 28000, loss: 0.364562
 >> iter 29000, loss: 0.403097
 >> iter 30000, loss: 0.546262
   Number of active neurons: 8
 >> iter 31000, loss: 0.391471
 >> iter 32000, loss: 0.431825
 >> iter 33000, loss: 0.545835
 >> iter 34000, loss: 0.533248
 >> iter 35000, loss: 0.718040
 >> iter 36000, loss: 0.626666
 >> iter 37000, loss: 0.616682
 >> iter 38000, loss: 0.558128
 >> iter 39000, loss: 0.491286
 >> iter 40000, loss: 0.474696
   Number of active neurons: 7
 >> iter 41000, loss: 0.423071
 >> iter 42000, loss: 0.335164
 >> iter 43000, loss: 0.431810
 >> iter 44000, loss: 0.476554
 >> iter 45000, loss: 0.494280
 >> iter 46000, loss: 0.509475
 >> iter 47000, loss: 0.582231
 >> iter 48000, loss: 0.515730
 >> iter 49000, loss: 0.377096
 >> iter 50000, loss: 0.336939
   Number of active neurons: 6
 >> iter 51000, loss: 0.437641
 >> iter 52000, loss: 0.588465
 >> iter 53000, loss: 0.437836
 >> iter 54000, loss: 0.345328
 >> iter 55000, loss: 0.432187
 >> iter 56000, loss: 0.342519
 >> iter 57000, loss: 0.478738
 >> iter 58000, loss: 0.464064
 >> iter 59000, loss: 0.407879
 >> iter 60000, loss: 0.286197
   Number of active neurons: 5
 >> iter 61000, loss: 0.469095
 >> iter 62000, loss: 0.490340
 >> iter 63000, loss: 0.533946
 >> iter 64000, loss: 0.399674
 >> iter 65000, loss: 0.393056
 >> iter 66000, loss: 0.393179
 >> iter 67000, loss: 0.379065
 >> iter 68000, loss: 0.525533
 >> iter 69000, loss: 0.486818
 >> iter 70000, loss: 0.473687
   Number of active neurons: 5
 >> iter 71000, loss: 0.395084
 >> iter 72000, loss: 0.406503
 >> iter 73000, loss: 0.498206
 >> iter 74000, loss: 0.563828
 >> iter 75000, loss: 0.442981
 >> iter 76000, loss: 0.406963
 >> iter 77000, loss: 0.462452
 >> iter 78000, loss: 0.512075
 >> iter 79000, loss: 0.538062
 >> iter 80000, loss: 0.445607
   Number of active neurons: 5
 >> iter 81000, loss: 0.412443
 >> iter 82000, loss: 0.296100
 >> iter 83000, loss: 0.417139
 >> iter 84000, loss: 0.476797
 >> iter 85000, loss: 0.415424
 >> iter 86000, loss: 0.430358
 >> iter 87000, loss: 0.506223
 >> iter 88000, loss: 0.368024
 >> iter 89000, loss: 0.540399
 >> iter 90000, loss: 0.591220
   Number of active neurons: 5
 >> iter 91000, loss: 0.655929
 >> iter 92000, loss: 0.491015
 >> iter 93000, loss: 0.524505
 >> iter 94000, loss: 0.448007
 >> iter 95000, loss: 0.516362
 >> iter 96000, loss: 0.494280
 >> iter 97000, loss: 0.538045
 >> iter 98000, loss: 0.578700
 >> iter 99000, loss: 0.616173
 >> iter 100000, loss: 0.604627
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 15.1589894007
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.150843
 >> iter 2000, loss: 9.758272
 >> iter 3000, loss: 5.658158
 >> iter 4000, loss: 3.406443
 >> iter 5000, loss: 2.259522
 >> iter 6000, loss: 1.475700
 >> iter 7000, loss: 0.987842
 >> iter 8000, loss: 0.927493
 >> iter 9000, loss: 0.860381
 >> iter 10000, loss: 0.790452
   Number of active neurons: 5
 >> iter 11000, loss: 0.935678
 >> iter 12000, loss: 0.611054
 >> iter 13000, loss: 0.537965
 >> iter 14000, loss: 0.520885
 >> iter 15000, loss: 0.635758
 >> iter 16000, loss: 0.668025
 >> iter 17000, loss: 0.495659
 >> iter 18000, loss: 0.500030
 >> iter 19000, loss: 0.513470
 >> iter 20000, loss: 0.411720
   Number of active neurons: 5
 >> iter 21000, loss: 0.419517
 >> iter 22000, loss: 0.537554
 >> iter 23000, loss: 0.508145
 >> iter 24000, loss: 0.595712
 >> iter 25000, loss: 0.538410
 >> iter 26000, loss: 0.557644
 >> iter 27000, loss: 0.525192
 >> iter 28000, loss: 0.503394
 >> iter 29000, loss: 0.602324
 >> iter 30000, loss: 0.483825
   Number of active neurons: 5
 >> iter 31000, loss: 0.639611
 >> iter 32000, loss: 0.708118
 >> iter 33000, loss: 0.696146
 >> iter 34000, loss: 0.736667
 >> iter 35000, loss: 0.510281
 >> iter 36000, loss: 0.732486
 >> iter 37000, loss: 0.682254
 >> iter 38000, loss: 0.698254
 >> iter 39000, loss: 0.779386
 >> iter 40000, loss: 0.645675
   Number of active neurons: 5
 >> iter 41000, loss: 0.694048
 >> iter 42000, loss: 0.719245
 >> iter 43000, loss: 0.591296
 >> iter 44000, loss: 0.572741
 >> iter 45000, loss: 0.526113
 >> iter 46000, loss: 0.435335
 >> iter 47000, loss: 0.642810
 >> iter 48000, loss: 0.651680
 >> iter 49000, loss: 0.507583
 >> iter 50000, loss: 0.615750
   Number of active neurons: 5
 >> iter 51000, loss: 0.539809
 >> iter 52000, loss: 0.579958
 >> iter 53000, loss: 0.521016
 >> iter 54000, loss: 0.416341
 >> iter 55000, loss: 0.503417
 >> iter 56000, loss: 0.685127
 >> iter 57000, loss: 0.591063
 >> iter 58000, loss: 0.528581
 >> iter 59000, loss: 0.470570
 >> iter 60000, loss: 0.497601
   Number of active neurons: 5
 >> iter 61000, loss: 0.648216
 >> iter 62000, loss: 0.484372
 >> iter 63000, loss: 0.515681
 >> iter 64000, loss: 0.525705
 >> iter 65000, loss: 0.526886
 >> iter 66000, loss: 0.441923
 >> iter 67000, loss: 0.521962
 >> iter 68000, loss: 0.436552
 >> iter 69000, loss: 0.508716
 >> iter 70000, loss: 0.532080
   Number of active neurons: 5
 >> iter 71000, loss: 0.521844
 >> iter 72000, loss: 0.559714
 >> iter 73000, loss: 0.602715
 >> iter 74000, loss: 0.588676
 >> iter 75000, loss: 0.551714
 >> iter 76000, loss: 0.475988
 >> iter 77000, loss: 0.379670
 >> iter 78000, loss: 0.457189
 >> iter 79000, loss: 0.493760
 >> iter 80000, loss: 0.472519
   Number of active neurons: 5
 >> iter 81000, loss: 0.688828
 >> iter 82000, loss: 0.521274
 >> iter 83000, loss: 0.453829
 >> iter 84000, loss: 0.411536
 >> iter 85000, loss: 0.398339
 >> iter 86000, loss: 0.590910
 >> iter 87000, loss: 0.602458
 >> iter 88000, loss: 0.703475
 >> iter 89000, loss: 0.656065
 >> iter 90000, loss: 0.531963
   Number of active neurons: 5
 >> iter 91000, loss: 0.599786
 >> iter 92000, loss: 0.454674
 >> iter 93000, loss: 0.464364
 >> iter 94000, loss: 0.365777
 >> iter 95000, loss: 0.533001
 >> iter 96000, loss: 0.668900
 >> iter 97000, loss: 0.723774
 >> iter 98000, loss: 0.660003
 >> iter 99000, loss: 0.527204
 >> iter 100000, loss: 0.457105
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 17.858107
 >> iter 2000, loss: 10.924153
 >> iter 3000, loss: 7.175309
 >> iter 4000, loss: 3.986987
 >> iter 5000, loss: 1.823229
 >> iter 6000, loss: 0.888709
 >> iter 7000, loss: 0.534202
 >> iter 8000, loss: 0.300395
 >> iter 9000, loss: 0.461138
 >> iter 10000, loss: 0.438588
   Number of active neurons: 12
 >> iter 11000, loss: 0.331580
 >> iter 12000, loss: 0.293358
 >> iter 13000, loss: 0.335885
 >> iter 14000, loss: 0.259847
 >> iter 15000, loss: 0.311850
 >> iter 16000, loss: 0.280414
 >> iter 17000, loss: 0.267324
 >> iter 18000, loss: 0.305329
 >> iter 19000, loss: 0.264303
 >> iter 20000, loss: 0.240500
   Number of active neurons: 12
 >> iter 21000, loss: 0.357395
 >> iter 22000, loss: 0.354477
 >> iter 23000, loss: 0.275795
 >> iter 24000, loss: 0.364623
 >> iter 25000, loss: 0.241885
 >> iter 26000, loss: 0.250270
 >> iter 27000, loss: 0.299855
 >> iter 28000, loss: 0.200690
 >> iter 29000, loss: 0.276210
 >> iter 30000, loss: 0.256511
   Number of active neurons: 11
 >> iter 31000, loss: 0.238528
 >> iter 32000, loss: 0.291238
 >> iter 33000, loss: 0.378537
 >> iter 34000, loss: 0.251728
 >> iter 35000, loss: 0.303215
 >> iter 36000, loss: 0.289163
 >> iter 37000, loss: 0.296509
 >> iter 38000, loss: 0.295842
 >> iter 39000, loss: 0.226044
 >> iter 40000, loss: 0.283132
   Number of active neurons: 10
 >> iter 41000, loss: 0.234249
 >> iter 42000, loss: 0.274253
 >> iter 43000, loss: 0.262592
 >> iter 44000, loss: 0.294488
 >> iter 45000, loss: 0.231711
 >> iter 46000, loss: 0.214120
 >> iter 47000, loss: 0.327739
 >> iter 48000, loss: 0.302819
 >> iter 49000, loss: 0.234776
 >> iter 50000, loss: 0.284641
   Number of active neurons: 10
 >> iter 51000, loss: 0.286477
 >> iter 52000, loss: 0.434359
 >> iter 53000, loss: 0.377243
 >> iter 54000, loss: 0.327678
 >> iter 55000, loss: 0.364546
 >> iter 56000, loss: 0.242399
 >> iter 57000, loss: 0.164805
 >> iter 58000, loss: 0.227144
 >> iter 59000, loss: 0.307590
 >> iter 60000, loss: 0.341364
   Number of active neurons: 10
 >> iter 61000, loss: 0.275327
 >> iter 62000, loss: 0.279562
 >> iter 63000, loss: 0.331522
 >> iter 64000, loss: 0.388313
 >> iter 65000, loss: 0.345989
 >> iter 66000, loss: 0.260028
 >> iter 67000, loss: 0.273871
 >> iter 68000, loss: 0.353583
 >> iter 69000, loss: 0.313062
 >> iter 70000, loss: 0.238965
   Number of active neurons: 10
 >> iter 71000, loss: 0.365579
 >> iter 72000, loss: 0.259752
 >> iter 73000, loss: 0.277369
 >> iter 74000, loss: 0.191784
 >> iter 75000, loss: 0.324850
 >> iter 76000, loss: 0.270748
 >> iter 77000, loss: 0.286552
 >> iter 78000, loss: 0.263640
 >> iter 79000, loss: 0.256776
 >> iter 80000, loss: 0.307408
   Number of active neurons: 9
 >> iter 81000, loss: 0.342433
 >> iter 82000, loss: 0.254100
 >> iter 83000, loss: 0.226290
 >> iter 84000, loss: 0.276920
 >> iter 85000, loss: 0.271121
 >> iter 86000, loss: 0.312487
 >> iter 87000, loss: 0.344221
 >> iter 88000, loss: 0.305522
 >> iter 89000, loss: 0.293641
 >> iter 90000, loss: 0.320334
   Number of active neurons: 9
 >> iter 91000, loss: 0.269563
 >> iter 92000, loss: 0.221352
 >> iter 93000, loss: 0.268753
 >> iter 94000, loss: 0.250904
 >> iter 95000, loss: 0.296034
 >> iter 96000, loss: 0.364767
 >> iter 97000, loss: 0.285146
 >> iter 98000, loss: 0.236681
 >> iter 99000, loss: 0.261368
 >> iter 100000, loss: 0.274481
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.420620
 >> iter 2000, loss: 10.211323
 >> iter 3000, loss: 4.727062
 >> iter 4000, loss: 2.088638
 >> iter 5000, loss: 1.065438
 >> iter 6000, loss: 0.586308
 >> iter 7000, loss: 0.410337
 >> iter 8000, loss: 0.492561
 >> iter 9000, loss: 0.423306
 >> iter 10000, loss: 0.343502
   Number of active neurons: 10
 >> iter 11000, loss: 0.441954
 >> iter 12000, loss: 0.290310
 >> iter 13000, loss: 0.233624
 >> iter 14000, loss: 0.315898
 >> iter 15000, loss: 0.225812
 >> iter 16000, loss: 0.270865
 >> iter 17000, loss: 0.284454
 >> iter 18000, loss: 0.308247
 >> iter 19000, loss: 0.428807
 >> iter 20000, loss: 0.335179
   Number of active neurons: 9
 >> iter 21000, loss: 0.253891
 >> iter 22000, loss: 0.347951
 >> iter 23000, loss: 0.271114
 >> iter 24000, loss: 0.307779
 >> iter 25000, loss: 0.395607
 >> iter 26000, loss: 0.292751
 >> iter 27000, loss: 0.301648
 >> iter 28000, loss: 0.295700
 >> iter 29000, loss: 0.341892
 >> iter 30000, loss: 0.271597
   Number of active neurons: 9
 >> iter 31000, loss: 0.275628
 >> iter 32000, loss: 0.278326
 >> iter 33000, loss: 0.309197
 >> iter 34000, loss: 0.263252
 >> iter 35000, loss: 0.321222
 >> iter 36000, loss: 0.331489
 >> iter 37000, loss: 0.318970
 >> iter 38000, loss: 0.331994
 >> iter 39000, loss: 0.242112
 >> iter 40000, loss: 0.241301
   Number of active neurons: 9
 >> iter 41000, loss: 0.277300
 >> iter 42000, loss: 0.375415
 >> iter 43000, loss: 0.294210
 >> iter 44000, loss: 0.224437
 >> iter 45000, loss: 0.284811
 >> iter 46000, loss: 0.267733
 >> iter 47000, loss: 0.368287
 >> iter 48000, loss: 0.456104
 >> iter 49000, loss: 0.375083
 >> iter 50000, loss: 0.271840
   Number of active neurons: 9
 >> iter 51000, loss: 0.256703
 >> iter 52000, loss: 0.222351
 >> iter 53000, loss: 0.312519
 >> iter 54000, loss: 0.303855
 >> iter 55000, loss: 0.324436
 >> iter 56000, loss: 0.286354
 >> iter 57000, loss: 0.330842
 >> iter 58000, loss: 0.255725
 >> iter 59000, loss: 0.290971
 >> iter 60000, loss: 0.262165
   Number of active neurons: 9
 >> iter 61000, loss: 0.314090
 >> iter 62000, loss: 0.299167
 >> iter 63000, loss: 0.371843
 >> iter 64000, loss: 0.389917
 >> iter 65000, loss: 0.273589
 >> iter 66000, loss: 0.357881
 >> iter 67000, loss: 0.248319
 >> iter 68000, loss: 0.382535
 >> iter 69000, loss: 0.321754
 >> iter 70000, loss: 0.323661
   Number of active neurons: 8
 >> iter 71000, loss: 0.248759
 >> iter 72000, loss: 0.260843
 >> iter 73000, loss: 0.365212
 >> iter 74000, loss: 0.328326
 >> iter 75000, loss: 0.315931
 >> iter 76000, loss: 0.257223
 >> iter 77000, loss: 0.274572
 >> iter 78000, loss: 0.276120
 >> iter 79000, loss: 0.235160
 >> iter 80000, loss: 0.294382
   Number of active neurons: 8
 >> iter 81000, loss: 0.337008
 >> iter 82000, loss: 0.336841
 >> iter 83000, loss: 0.309055
 >> iter 84000, loss: 0.299672
 >> iter 85000, loss: 0.273280
 >> iter 86000, loss: 0.280166
 >> iter 87000, loss: 0.271249
 >> iter 88000, loss: 0.311272
 >> iter 89000, loss: 0.308898
 >> iter 90000, loss: 0.301092
   Number of active neurons: 8
 >> iter 91000, loss: 0.221694
 >> iter 92000, loss: 0.215242
 >> iter 93000, loss: 0.313720
 >> iter 94000, loss: 0.306721
 >> iter 95000, loss: 0.283990
 >> iter 96000, loss: 0.301858
 >> iter 97000, loss: 0.394350
 >> iter 98000, loss: 0.368212
 >> iter 99000, loss: 0.330382
 >> iter 100000, loss: 0.229159
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.510682
 >> iter 2000, loss: 9.825535
 >> iter 3000, loss: 5.453358
 >> iter 4000, loss: 2.442534
 >> iter 5000, loss: 1.163578
 >> iter 6000, loss: 0.716667
 >> iter 7000, loss: 0.500221
 >> iter 8000, loss: 0.372423
 >> iter 9000, loss: 0.297520
 >> iter 10000, loss: 0.288707
   Number of active neurons: 10
 >> iter 11000, loss: 0.283955
 >> iter 12000, loss: 0.268132
 >> iter 13000, loss: 0.273843
 >> iter 14000, loss: 0.312243
 >> iter 15000, loss: 0.371943
 >> iter 16000, loss: 0.376007
 >> iter 17000, loss: 0.343852
 >> iter 18000, loss: 0.333455
 >> iter 19000, loss: 0.312524
 >> iter 20000, loss: 0.277849
   Number of active neurons: 10
 >> iter 21000, loss: 0.269733
 >> iter 22000, loss: 0.329613
 >> iter 23000, loss: 0.319860
 >> iter 24000, loss: 0.278902
 >> iter 25000, loss: 0.307882
 >> iter 26000, loss: 0.326298
 >> iter 27000, loss: 0.354099
 >> iter 28000, loss: 0.239380
 >> iter 29000, loss: 0.245156
 >> iter 30000, loss: 0.250318
   Number of active neurons: 8
 >> iter 31000, loss: 0.199378
 >> iter 32000, loss: 0.265067
 >> iter 33000, loss: 0.365850
 >> iter 34000, loss: 0.327666
 >> iter 35000, loss: 0.381013
 >> iter 36000, loss: 0.283853
 >> iter 37000, loss: 0.398276
 >> iter 38000, loss: 0.349830
 >> iter 39000, loss: 0.365239
 >> iter 40000, loss: 0.278523
   Number of active neurons: 8
 >> iter 41000, loss: 0.326915
 >> iter 42000, loss: 0.263808
 >> iter 43000, loss: 0.293766
 >> iter 44000, loss: 0.295564
 >> iter 45000, loss: 0.393748
 >> iter 46000, loss: 0.419043
 >> iter 47000, loss: 0.444082
 >> iter 48000, loss: 0.357319
 >> iter 49000, loss: 0.283045
 >> iter 50000, loss: 0.319089
   Number of active neurons: 8
 >> iter 51000, loss: 0.297087
 >> iter 52000, loss: 0.220731
 >> iter 53000, loss: 0.228529
 >> iter 54000, loss: 0.266032
 >> iter 55000, loss: 0.198891
 >> iter 56000, loss: 0.196371
 >> iter 57000, loss: 0.257950
 >> iter 58000, loss: 0.277568
 >> iter 59000, loss: 0.441976
 >> iter 60000, loss: 0.320150
   Number of active neurons: 8
 >> iter 61000, loss: 0.250428
 >> iter 62000, loss: 0.303396
 >> iter 63000, loss: 0.432455
 >> iter 64000, loss: 0.343651
 >> iter 65000, loss: 0.394009
 >> iter 66000, loss: 0.387842
 >> iter 67000, loss: 0.416289
 >> iter 68000, loss: 0.352918
 >> iter 69000, loss: 0.432653
 >> iter 70000, loss: 0.302396
   Number of active neurons: 8
 >> iter 71000, loss: 0.247847
 >> iter 72000, loss: 0.373912
 >> iter 73000, loss: 0.225323
 >> iter 74000, loss: 0.293723
 >> iter 75000, loss: 0.375504
 >> iter 76000, loss: 0.351217
 >> iter 77000, loss: 0.348061
 >> iter 78000, loss: 0.255003
 >> iter 79000, loss: 0.248034
 >> iter 80000, loss: 0.327536
   Number of active neurons: 8
 >> iter 81000, loss: 0.346576
 >> iter 82000, loss: 0.287518
 >> iter 83000, loss: 0.338479
 >> iter 84000, loss: 0.333967
 >> iter 85000, loss: 0.272295
 >> iter 86000, loss: 0.215263
 >> iter 87000, loss: 0.311553
 >> iter 88000, loss: 0.308041
 >> iter 89000, loss: 0.320827
 >> iter 90000, loss: 0.255608
   Number of active neurons: 8
 >> iter 91000, loss: 0.416077
 >> iter 92000, loss: 0.278870
 >> iter 93000, loss: 0.259738
 >> iter 94000, loss: 0.318497
 >> iter 95000, loss: 0.373780
 >> iter 96000, loss: 0.233706
 >> iter 97000, loss: 0.230457
 >> iter 98000, loss: 0.254867
 >> iter 99000, loss: 0.269785
 >> iter 100000, loss: 0.217138
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.861096
 >> iter 2000, loss: 9.896727
 >> iter 3000, loss: 5.802571
 >> iter 4000, loss: 3.402891
 >> iter 5000, loss: 2.081504
 >> iter 6000, loss: 1.229194
 >> iter 7000, loss: 0.755699
 >> iter 8000, loss: 0.537439
 >> iter 9000, loss: 0.451658
 >> iter 10000, loss: 0.311001
   Number of active neurons: 9
 >> iter 11000, loss: 0.289205
 >> iter 12000, loss: 0.307581
 >> iter 13000, loss: 0.283878
 >> iter 14000, loss: 0.253705
 >> iter 15000, loss: 0.216288
 >> iter 16000, loss: 0.190051
 >> iter 17000, loss: 0.274255
 >> iter 18000, loss: 0.345395
 >> iter 19000, loss: 0.361459
 >> iter 20000, loss: 0.324444
   Number of active neurons: 9
 >> iter 21000, loss: 0.316521
 >> iter 22000, loss: 0.301381
 >> iter 23000, loss: 0.242660
 >> iter 24000, loss: 0.292779
 >> iter 25000, loss: 0.289479
 >> iter 26000, loss: 0.366084
 >> iter 27000, loss: 0.332042
 >> iter 28000, loss: 0.221333
 >> iter 29000, loss: 0.289730
 >> iter 30000, loss: 0.343587
   Number of active neurons: 8
 >> iter 31000, loss: 0.345653
 >> iter 32000, loss: 0.322336
 >> iter 33000, loss: 0.342972
 >> iter 34000, loss: 0.305125
 >> iter 35000, loss: 0.355281
 >> iter 36000, loss: 0.252972
 >> iter 37000, loss: 0.250324
 >> iter 38000, loss: 0.283555
 >> iter 39000, loss: 0.342896
 >> iter 40000, loss: 0.339158
   Number of active neurons: 8
 >> iter 41000, loss: 0.333456
 >> iter 42000, loss: 0.380336
 >> iter 43000, loss: 0.253079
 >> iter 44000, loss: 0.355008
 >> iter 45000, loss: 0.347847
 >> iter 46000, loss: 0.302057
 >> iter 47000, loss: 0.286387
 >> iter 48000, loss: 0.358635
 >> iter 49000, loss: 0.469073
 >> iter 50000, loss: 0.456055
   Number of active neurons: 8
 >> iter 51000, loss: 0.296194
 >> iter 52000, loss: 0.259763
 >> iter 53000, loss: 0.297497
 >> iter 54000, loss: 0.281648
 >> iter 55000, loss: 0.259260
 >> iter 56000, loss: 0.344025
 >> iter 57000, loss: 0.205229
 >> iter 58000, loss: 0.447338
 >> iter 59000, loss: 0.350361
 >> iter 60000, loss: 0.475969
   Number of active neurons: 8
 >> iter 61000, loss: 0.403781
 >> iter 62000, loss: 0.246035
 >> iter 63000, loss: 0.224705
 >> iter 64000, loss: 0.374241
 >> iter 65000, loss: 0.332024
 >> iter 66000, loss: 0.311353
 >> iter 67000, loss: 0.176754
 >> iter 68000, loss: 0.437897
 >> iter 69000, loss: 0.317762
 >> iter 70000, loss: 0.272013
   Number of active neurons: 8
 >> iter 71000, loss: 0.304493
 >> iter 72000, loss: 0.288350
 >> iter 73000, loss: 0.325025
 >> iter 74000, loss: 0.383495
 >> iter 75000, loss: 0.289606
 >> iter 76000, loss: 0.358516
 >> iter 77000, loss: 0.246843
 >> iter 78000, loss: 0.314386
 >> iter 79000, loss: 0.326769
 >> iter 80000, loss: 0.291347
   Number of active neurons: 8
 >> iter 81000, loss: 0.399458
 >> iter 82000, loss: 0.292670
 >> iter 83000, loss: 0.291464
 >> iter 84000, loss: 0.276215
 >> iter 85000, loss: 0.310454
 >> iter 86000, loss: 0.334232
 >> iter 87000, loss: 0.313552
 >> iter 88000, loss: 0.331062
 >> iter 89000, loss: 0.311026
 >> iter 90000, loss: 0.320739
   Number of active neurons: 8
 >> iter 91000, loss: 0.301298
 >> iter 92000, loss: 0.341542
 >> iter 93000, loss: 0.338300
 >> iter 94000, loss: 0.321886
 >> iter 95000, loss: 0.319757
 >> iter 96000, loss: 0.239425
 >> iter 97000, loss: 0.275513
 >> iter 98000, loss: 0.301638
 >> iter 99000, loss: 0.403998
 >> iter 100000, loss: 0.360722
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

