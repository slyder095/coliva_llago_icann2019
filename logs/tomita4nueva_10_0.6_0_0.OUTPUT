 > Problema: tomita4nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.6
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.691268
 >> iter 2000, loss: 8.997757
 >> iter 3000, loss: 4.182334
 >> iter 4000, loss: 1.680026
 >> iter 5000, loss: 0.771379
 >> iter 6000, loss: 0.463901
 >> iter 7000, loss: 0.228512
 >> iter 8000, loss: 0.110118
 >> iter 9000, loss: 0.053001
 >> iter 10000, loss: 0.061503
   Number of active neurons: 10
 >> iter 11000, loss: 0.091973
 >> iter 12000, loss: 0.052716
 >> iter 13000, loss: 0.053618
 >> iter 14000, loss: 0.023291
 >> iter 15000, loss: 0.014693
 >> iter 16000, loss: 0.013967
 >> iter 17000, loss: 0.125171
 >> iter 18000, loss: 0.116793
 >> iter 19000, loss: 0.075244
 >> iter 20000, loss: 0.127811
   Number of active neurons: 10
 >> iter 21000, loss: 0.052447
 >> iter 22000, loss: 0.026404
 >> iter 23000, loss: 0.098922
 >> iter 24000, loss: 0.087287
 >> iter 25000, loss: 0.119817
 >> iter 26000, loss: 0.060097
 >> iter 27000, loss: 0.045327
 >> iter 28000, loss: 0.074353
 >> iter 29000, loss: 0.091801
 >> iter 30000, loss: 0.037038
   Number of active neurons: 10
 >> iter 31000, loss: 0.027482
 >> iter 32000, loss: 0.012496
 >> iter 33000, loss: 0.110327
 >> iter 34000, loss: 0.071314
 >> iter 35000, loss: 0.029115
 >> iter 36000, loss: 0.079203
 >> iter 37000, loss: 0.032177
 >> iter 38000, loss: 0.014203
 >> iter 39000, loss: 0.029048
 >> iter 40000, loss: 0.056780
   Number of active neurons: 10
 >> iter 41000, loss: 0.031557
 >> iter 42000, loss: 0.028551
 >> iter 43000, loss: 0.038522
 >> iter 44000, loss: 0.016371
 >> iter 45000, loss: 0.008118
 >> iter 46000, loss: 0.007871
 >> iter 47000, loss: 0.136452
 >> iter 48000, loss: 0.052547
 >> iter 49000, loss: 0.021879
 >> iter 50000, loss: 0.009943
   Number of active neurons: 10
 >> iter 51000, loss: 0.005068
 >> iter 52000, loss: 0.003185
 >> iter 53000, loss: 0.002297
 >> iter 54000, loss: 0.025596
 >> iter 55000, loss: 0.011118
 >> iter 56000, loss: 0.006822
 >> iter 57000, loss: 0.192564
 >> iter 58000, loss: 0.072585
 >> iter 59000, loss: 0.028275
 >> iter 60000, loss: 0.011835
   Number of active neurons: 10
 >> iter 61000, loss: 0.005568
 >> iter 62000, loss: 0.003174
 >> iter 63000, loss: 0.002191
 >> iter 64000, loss: 0.001738
 >> iter 65000, loss: 0.022770
 >> iter 66000, loss: 0.009355
 >> iter 67000, loss: 0.006007
 >> iter 68000, loss: 0.003045
 >> iter 69000, loss: 0.001937
 >> iter 70000, loss: 0.010079
   Number of active neurons: 10
 >> iter 71000, loss: 0.007969
 >> iter 72000, loss: 0.011791
 >> iter 73000, loss: 0.054055
 >> iter 74000, loss: 0.020954
 >> iter 75000, loss: 0.023502
 >> iter 76000, loss: 0.041255
 >> iter 77000, loss: 0.031071
 >> iter 78000, loss: 0.013419
 >> iter 79000, loss: 0.006096
 >> iter 80000, loss: 0.003159
   Number of active neurons: 10
 >> iter 81000, loss: 0.002151
 >> iter 82000, loss: 0.146914
 >> iter 83000, loss: 0.056871
 >> iter 84000, loss: 0.022173
 >> iter 85000, loss: 0.009323
 >> iter 86000, loss: 0.004443
 >> iter 87000, loss: 0.004660
 >> iter 88000, loss: 0.002653
 >> iter 89000, loss: 0.001834
 >> iter 90000, loss: 0.001462
   Number of active neurons: 10
 >> iter 91000, loss: 0.001231
 >> iter 92000, loss: 0.001142
 >> iter 93000, loss: 0.001027
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.475525
 >> iter 2000, loss: 8.580769
 >> iter 3000, loss: 3.653840
 >> iter 4000, loss: 1.727941
 >> iter 5000, loss: 0.994400
 >> iter 6000, loss: 0.451091
 >> iter 7000, loss: 0.183373
 >> iter 8000, loss: 0.187053
 >> iter 9000, loss: 0.223028
 >> iter 10000, loss: 0.206517
   Number of active neurons: 10
 >> iter 11000, loss: 0.349483
 >> iter 12000, loss: 0.138732
 >> iter 13000, loss: 0.067861
 >> iter 14000, loss: 0.029863
 >> iter 15000, loss: 0.020345
 >> iter 16000, loss: 0.043281
 >> iter 17000, loss: 0.069077
 >> iter 18000, loss: 0.053784
 >> iter 19000, loss: 0.181944
 >> iter 20000, loss: 0.072834
   Number of active neurons: 10
 >> iter 21000, loss: 0.038579
 >> iter 22000, loss: 0.053920
 >> iter 23000, loss: 0.023027
 >> iter 24000, loss: 0.011070
 >> iter 25000, loss: 0.030095
 >> iter 26000, loss: 0.013489
 >> iter 27000, loss: 0.015613
 >> iter 28000, loss: 0.045310
 >> iter 29000, loss: 0.019587
 >> iter 30000, loss: 0.009604
   Number of active neurons: 10
 >> iter 31000, loss: 0.042337
 >> iter 32000, loss: 0.131698
 >> iter 33000, loss: 0.051619
 >> iter 34000, loss: 0.021546
 >> iter 35000, loss: 0.136123
 >> iter 36000, loss: 0.053057
 >> iter 37000, loss: 0.022313
 >> iter 38000, loss: 0.010441
 >> iter 39000, loss: 0.005696
 >> iter 40000, loss: 0.008832
   Number of active neurons: 10
 >> iter 41000, loss: 0.008315
 >> iter 42000, loss: 0.004623
 >> iter 43000, loss: 0.003027
 >> iter 44000, loss: 0.002290
 >> iter 45000, loss: 0.002154
 >> iter 46000, loss: 0.001800
 >> iter 47000, loss: 0.001667
 >> iter 48000, loss: 0.079241
 >> iter 49000, loss: 0.030763
 >> iter 50000, loss: 0.012786
   Number of active neurons: 10
 >> iter 51000, loss: 0.005922
 >> iter 52000, loss: 0.003415
 >> iter 53000, loss: 0.002309
 >> iter 54000, loss: 0.008565
 >> iter 55000, loss: 0.004143
 >> iter 56000, loss: 0.002413
 >> iter 57000, loss: 0.088151
 >> iter 58000, loss: 0.082286
 >> iter 59000, loss: 0.064285
 >> iter 60000, loss: 0.025959
   Number of active neurons: 10
 >> iter 61000, loss: 0.010860
 >> iter 62000, loss: 0.005188
 >> iter 63000, loss: 0.002969
 >> iter 64000, loss: 0.002080
 >> iter 65000, loss: 0.001696
 >> iter 66000, loss: 0.001477
 >> iter 67000, loss: 0.001369
 >> iter 68000, loss: 0.001327
 >> iter 69000, loss: 0.001225
 >> iter 70000, loss: 0.001148
   Number of active neurons: 10
 >> iter 71000, loss: 0.001128
 >> iter 72000, loss: 0.074346
 >> iter 73000, loss: 0.070445
 >> iter 74000, loss: 0.027545
 >> iter 75000, loss: 0.031747
 >> iter 76000, loss: 0.012775
 >> iter 77000, loss: 0.005733
 >> iter 78000, loss: 0.003024
 >> iter 79000, loss: 0.001974
 >> iter 80000, loss: 0.001989
   Number of active neurons: 10
 >> iter 81000, loss: 0.001499
 >> iter 82000, loss: 0.001283
 >> iter 83000, loss: 0.001156
 >> iter 84000, loss: 0.027635
 >> iter 85000, loss: 0.019751
 >> iter 86000, loss: 0.008627
 >> iter 87000, loss: 0.004010
 >> iter 88000, loss: 0.008183
 >> iter 89000, loss: 0.003861
 >> iter 90000, loss: 0.002153
   Number of active neurons: 10
 >> iter 91000, loss: 0.040690
 >> iter 92000, loss: 0.016325
 >> iter 93000, loss: 0.007167
 >> iter 94000, loss: 0.003651
 >> iter 95000, loss: 0.002280
 >> iter 96000, loss: 0.001669
 >> iter 97000, loss: 0.001399
 >> iter 98000, loss: 0.001630
 >> iter 99000, loss: 0.001330
 >> iter 100000, loss: 0.001672
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.268169
 >> iter 2000, loss: 8.724751
 >> iter 3000, loss: 4.039151
 >> iter 4000, loss: 1.567923
 >> iter 5000, loss: 0.697947
 >> iter 6000, loss: 0.359621
 >> iter 7000, loss: 0.188458
 >> iter 8000, loss: 0.350360
 >> iter 9000, loss: 0.176660
 >> iter 10000, loss: 0.087993
   Number of active neurons: 10
 >> iter 11000, loss: 0.148254
 >> iter 12000, loss: 0.061685
 >> iter 13000, loss: 0.038281
 >> iter 14000, loss: 0.021766
 >> iter 15000, loss: 0.095198
 >> iter 16000, loss: 0.038441
 >> iter 17000, loss: 0.053003
 >> iter 18000, loss: 0.022963
 >> iter 19000, loss: 0.011408
 >> iter 20000, loss: 0.006248
   Number of active neurons: 10
 >> iter 21000, loss: 0.006729
 >> iter 22000, loss: 0.004518
 >> iter 23000, loss: 0.003472
 >> iter 24000, loss: 0.002478
 >> iter 25000, loss: 0.004437
 >> iter 26000, loss: 0.002770
 >> iter 27000, loss: 0.002190
 >> iter 28000, loss: 0.001934
 >> iter 29000, loss: 0.001701
 >> iter 30000, loss: 0.003043
   Number of active neurons: 10
 >> iter 31000, loss: 0.001938
 >> iter 32000, loss: 0.001525
 >> iter 33000, loss: 0.001461
 >> iter 34000, loss: 0.141042
 >> iter 35000, loss: 0.054415
 >> iter 36000, loss: 0.021868
 >> iter 37000, loss: 0.009989
 >> iter 38000, loss: 0.004884
 >> iter 39000, loss: 0.005573
 >> iter 40000, loss: 0.003219
   Number of active neurons: 10
 >> iter 41000, loss: 0.002278
 >> iter 42000, loss: 0.002091
 >> iter 43000, loss: 0.001949
 >> iter 44000, loss: 0.095268
 >> iter 45000, loss: 0.036300
 >> iter 46000, loss: 0.014276
 >> iter 47000, loss: 0.006156
 >> iter 48000, loss: 0.185510
 >> iter 49000, loss: 0.071305
 >> iter 50000, loss: 0.028255
   Number of active neurons: 10
 >> iter 51000, loss: 0.012308
 >> iter 52000, loss: 0.005983
 >> iter 53000, loss: 0.003523
 >> iter 54000, loss: 0.003571
 >> iter 55000, loss: 0.002319
 >> iter 56000, loss: 0.001829
 >> iter 57000, loss: 0.078413
 >> iter 58000, loss: 0.031295
 >> iter 59000, loss: 0.012766
 >> iter 60000, loss: 0.005731
   Number of active neurons: 10
 >> iter 61000, loss: 0.010120
 >> iter 62000, loss: 0.015881
 >> iter 63000, loss: 0.006879
 >> iter 64000, loss: 0.081706
 >> iter 65000, loss: 0.042822
 >> iter 66000, loss: 0.016994
 >> iter 67000, loss: 0.007347
 >> iter 68000, loss: 0.003930
 >> iter 69000, loss: 0.002719
 >> iter 70000, loss: 0.003146
   Number of active neurons: 10
 >> iter 71000, loss: 0.002068
 >> iter 72000, loss: 0.001767
 >> iter 73000, loss: 0.001377
 >> iter 74000, loss: 0.001207
 >> iter 75000, loss: 0.001128
 >> iter 76000, loss: 0.001177
 >> iter 77000, loss: 0.001097
 >> iter 78000, loss: 0.001026
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.262465
 >> iter 2000, loss: 8.042538
 >> iter 3000, loss: 3.669247
 >> iter 4000, loss: 1.588286
 >> iter 5000, loss: 0.660656
 >> iter 6000, loss: 0.276893
 >> iter 7000, loss: 0.408089
 >> iter 8000, loss: 0.281833
 >> iter 9000, loss: 0.168923
 >> iter 10000, loss: 0.071900
   Number of active neurons: 10
 >> iter 11000, loss: 0.061422
 >> iter 12000, loss: 0.027585
 >> iter 13000, loss: 0.062104
 >> iter 14000, loss: 0.099841
 >> iter 15000, loss: 0.076323
 >> iter 16000, loss: 0.044084
 >> iter 17000, loss: 0.044911
 >> iter 18000, loss: 0.102732
 >> iter 19000, loss: 0.041588
 >> iter 20000, loss: 0.051340
   Number of active neurons: 10
 >> iter 21000, loss: 0.023143
 >> iter 22000, loss: 0.055342
 >> iter 23000, loss: 0.022923
 >> iter 24000, loss: 0.010543
 >> iter 25000, loss: 0.005658
 >> iter 26000, loss: 0.014981
 >> iter 27000, loss: 0.062997
 >> iter 28000, loss: 0.025606
 >> iter 29000, loss: 0.011968
 >> iter 30000, loss: 0.018821
   Number of active neurons: 10
 >> iter 31000, loss: 0.038301
 >> iter 32000, loss: 0.015927
 >> iter 33000, loss: 0.007391
 >> iter 34000, loss: 0.019691
 >> iter 35000, loss: 0.015283
 >> iter 36000, loss: 0.096693
 >> iter 37000, loss: 0.038034
 >> iter 38000, loss: 0.015853
 >> iter 39000, loss: 0.008119
 >> iter 40000, loss: 0.004514
   Number of active neurons: 10
 >> iter 41000, loss: 0.002972
 >> iter 42000, loss: 0.004761
 >> iter 43000, loss: 0.003049
 >> iter 44000, loss: 0.002282
 >> iter 45000, loss: 0.001823
 >> iter 46000, loss: 0.001612
 >> iter 47000, loss: 0.001454
 >> iter 48000, loss: 0.001283
 >> iter 49000, loss: 0.001186
 >> iter 50000, loss: 0.001111
   Number of active neurons: 10
 >> iter 51000, loss: 0.001076
 >> iter 52000, loss: 0.001067
 >> iter 53000, loss: 0.065477
 >> iter 54000, loss: 0.025119
 >> iter 55000, loss: 0.010191
 >> iter 56000, loss: 0.004543
 >> iter 57000, loss: 0.002622
 >> iter 58000, loss: 0.001660
 >> iter 59000, loss: 0.001255
 >> iter 60000, loss: 0.001106
   Number of active neurons: 10
 >> iter 61000, loss: 0.016946
 >> iter 62000, loss: 0.006890
 >> iter 63000, loss: 0.003301
 >> iter 64000, loss: 0.001802
 >> iter 65000, loss: 0.001457
 >> iter 66000, loss: 0.001112
 >> iter 67000, loss: 0.001105
 >> iter 68000, loss: 0.003033
 >> iter 69000, loss: 0.100665
 >> iter 70000, loss: 0.039210
   Number of active neurons: 10
 >> iter 71000, loss: 0.015158
 >> iter 72000, loss: 0.006249
 >> iter 73000, loss: 0.002943
 >> iter 74000, loss: 0.003686
 >> iter 75000, loss: 0.002188
 >> iter 76000, loss: 0.001664
 >> iter 77000, loss: 0.001140
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.556395
 >> iter 2000, loss: 9.030482
 >> iter 3000, loss: 3.856648
 >> iter 4000, loss: 1.637445
 >> iter 5000, loss: 0.851467
 >> iter 6000, loss: 0.477149
 >> iter 7000, loss: 0.200718
 >> iter 8000, loss: 0.142814
 >> iter 9000, loss: 0.130256
 >> iter 10000, loss: 0.150073
   Number of active neurons: 10
 >> iter 11000, loss: 0.117023
 >> iter 12000, loss: 0.098589
 >> iter 13000, loss: 0.045753
 >> iter 14000, loss: 0.020744
 >> iter 15000, loss: 0.010731
 >> iter 16000, loss: 0.050269
 >> iter 17000, loss: 0.030438
 >> iter 18000, loss: 0.128334
 >> iter 19000, loss: 0.050026
 >> iter 20000, loss: 0.020855
   Number of active neurons: 10
 >> iter 21000, loss: 0.138855
 >> iter 22000, loss: 0.055672
 >> iter 23000, loss: 0.023334
 >> iter 24000, loss: 0.010908
 >> iter 25000, loss: 0.006069
 >> iter 26000, loss: 0.004918
 >> iter 27000, loss: 0.078976
 >> iter 28000, loss: 0.031701
 >> iter 29000, loss: 0.052926
 >> iter 30000, loss: 0.021795
   Number of active neurons: 10
 >> iter 31000, loss: 0.013336
 >> iter 32000, loss: 0.006371
 >> iter 33000, loss: 0.003644
 >> iter 34000, loss: 0.002520
 >> iter 35000, loss: 0.002329
 >> iter 36000, loss: 0.001790
 >> iter 37000, loss: 0.001561
 >> iter 38000, loss: 0.009807
 >> iter 39000, loss: 0.004795
 >> iter 40000, loss: 0.097264
   Number of active neurons: 10
 >> iter 41000, loss: 0.085922
 >> iter 42000, loss: 0.166552
 >> iter 43000, loss: 0.064531
 >> iter 44000, loss: 0.092047
 >> iter 45000, loss: 0.037383
 >> iter 46000, loss: 0.020101
 >> iter 47000, loss: 0.013577
 >> iter 48000, loss: 0.006772
 >> iter 49000, loss: 0.003932
 >> iter 50000, loss: 0.042659
   Number of active neurons: 10
 >> iter 51000, loss: 0.017198
 >> iter 52000, loss: 0.007680
 >> iter 53000, loss: 0.004049
 >> iter 54000, loss: 0.073703
 >> iter 55000, loss: 0.113648
 >> iter 56000, loss: 0.044596
 >> iter 57000, loss: 0.020759
 >> iter 58000, loss: 0.010292
 >> iter 59000, loss: 0.010326
 >> iter 60000, loss: 0.005360
   Number of active neurons: 10
 >> iter 61000, loss: 0.003428
 >> iter 62000, loss: 0.002420
 >> iter 63000, loss: 0.001936
 >> iter 64000, loss: 0.001626
 >> iter 65000, loss: 0.001838
 >> iter 66000, loss: 0.001477
 >> iter 67000, loss: 0.001329
 >> iter 68000, loss: 0.001185
 >> iter 69000, loss: 0.001078
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.086207
 >> iter 2000, loss: 8.712321
 >> iter 3000, loss: 3.860948
 >> iter 4000, loss: 1.756336
 >> iter 5000, loss: 0.766214
 >> iter 6000, loss: 0.330823
 >> iter 7000, loss: 0.306552
 >> iter 8000, loss: 0.232378
 >> iter 9000, loss: 0.134558
 >> iter 10000, loss: 0.149462
   Number of active neurons: 10
 >> iter 11000, loss: 0.136970
 >> iter 12000, loss: 0.057903
 >> iter 13000, loss: 0.044973
 >> iter 14000, loss: 0.035044
 >> iter 15000, loss: 0.017608
 >> iter 16000, loss: 0.013829
 >> iter 17000, loss: 0.085430
 >> iter 18000, loss: 0.090391
 >> iter 19000, loss: 0.039096
 >> iter 20000, loss: 0.016887
   Number of active neurons: 10
 >> iter 21000, loss: 0.011583
 >> iter 22000, loss: 0.006306
 >> iter 23000, loss: 0.054979
 >> iter 24000, loss: 0.028415
 >> iter 25000, loss: 0.012378
 >> iter 26000, loss: 0.057802
 >> iter 27000, loss: 0.023948
 >> iter 28000, loss: 0.013768
 >> iter 29000, loss: 0.007081
 >> iter 30000, loss: 0.004176
   Number of active neurons: 10
 >> iter 31000, loss: 0.002958
 >> iter 32000, loss: 0.050091
 >> iter 33000, loss: 0.106868
 >> iter 34000, loss: 0.041554
 >> iter 35000, loss: 0.020445
 >> iter 36000, loss: 0.009407
 >> iter 37000, loss: 0.011903
 >> iter 38000, loss: 0.005685
 >> iter 39000, loss: 0.003255
 >> iter 40000, loss: 0.009368
   Number of active neurons: 10
 >> iter 41000, loss: 0.070360
 >> iter 42000, loss: 0.027168
 >> iter 43000, loss: 0.012490
 >> iter 44000, loss: 0.006480
 >> iter 45000, loss: 0.003430
 >> iter 46000, loss: 0.002212
 >> iter 47000, loss: 0.082694
 >> iter 48000, loss: 0.078249
 >> iter 49000, loss: 0.045995
 >> iter 50000, loss: 0.028703
   Number of active neurons: 10
 >> iter 51000, loss: 0.012482
 >> iter 52000, loss: 0.006012
 >> iter 53000, loss: 0.042933
 >> iter 54000, loss: 0.017581
 >> iter 55000, loss: 0.008055
 >> iter 56000, loss: 0.004432
 >> iter 57000, loss: 0.002666
 >> iter 58000, loss: 0.001863
 >> iter 59000, loss: 0.006833
 >> iter 60000, loss: 0.003478
   Number of active neurons: 10
 >> iter 61000, loss: 0.002114
 >> iter 62000, loss: 0.002196
 >> iter 63000, loss: 0.001556
 >> iter 64000, loss: 0.010265
 >> iter 65000, loss: 0.004504
 >> iter 66000, loss: 0.002345
 >> iter 67000, loss: 0.001522
 >> iter 68000, loss: 0.128469
 >> iter 69000, loss: 0.096108
 >> iter 70000, loss: 0.036634
   Number of active neurons: 10
 >> iter 71000, loss: 0.014583
 >> iter 72000, loss: 0.006439
 >> iter 73000, loss: 0.003255
 >> iter 74000, loss: 0.002009
 >> iter 75000, loss: 0.001499
 >> iter 76000, loss: 0.001272
 >> iter 77000, loss: 0.001175
 >> iter 78000, loss: 0.001121
 >> iter 79000, loss: 0.001091
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.924568
 >> iter 2000, loss: 7.894476
 >> iter 3000, loss: 3.434338
 >> iter 4000, loss: 1.344119
 >> iter 5000, loss: 0.761059
 >> iter 6000, loss: 0.436621
 >> iter 7000, loss: 0.213958
 >> iter 8000, loss: 0.215781
 >> iter 9000, loss: 0.230008
 >> iter 10000, loss: 0.276438
   Number of active neurons: 10
 >> iter 11000, loss: 0.390231
 >> iter 12000, loss: 0.173912
 >> iter 13000, loss: 0.078055
 >> iter 14000, loss: 0.063063
 >> iter 15000, loss: 0.037912
 >> iter 16000, loss: 0.071297
 >> iter 17000, loss: 0.031859
 >> iter 18000, loss: 0.015614
 >> iter 19000, loss: 0.041317
 >> iter 20000, loss: 0.018675
   Number of active neurons: 10
 >> iter 21000, loss: 0.012325
 >> iter 22000, loss: 0.058201
 >> iter 23000, loss: 0.048722
 >> iter 24000, loss: 0.064078
 >> iter 25000, loss: 0.026353
 >> iter 26000, loss: 0.012323
 >> iter 27000, loss: 0.006883
 >> iter 28000, loss: 0.004451
 >> iter 29000, loss: 0.003450
 >> iter 30000, loss: 0.002756
   Number of active neurons: 10
 >> iter 31000, loss: 0.004569
 >> iter 32000, loss: 0.003670
 >> iter 33000, loss: 0.002578
 >> iter 34000, loss: 0.003636
 >> iter 35000, loss: 0.002507
 >> iter 36000, loss: 0.004559
 >> iter 37000, loss: 0.016543
 >> iter 38000, loss: 0.008831
 >> iter 39000, loss: 0.004243
 >> iter 40000, loss: 0.002504
   Number of active neurons: 10
 >> iter 41000, loss: 0.003831
 >> iter 42000, loss: 0.147332
 >> iter 43000, loss: 0.056063
 >> iter 44000, loss: 0.022275
 >> iter 45000, loss: 0.034305
 >> iter 46000, loss: 0.042957
 >> iter 47000, loss: 0.018095
 >> iter 48000, loss: 0.008429
 >> iter 49000, loss: 0.004884
 >> iter 50000, loss: 0.003535
   Number of active neurons: 10
 >> iter 51000, loss: 0.003395
 >> iter 52000, loss: 0.011621
 >> iter 53000, loss: 0.023757
 >> iter 54000, loss: 0.010114
 >> iter 55000, loss: 0.004948
 >> iter 56000, loss: 0.002794
 >> iter 57000, loss: 0.001921
 >> iter 58000, loss: 0.001596
 >> iter 59000, loss: 0.017671
 >> iter 60000, loss: 0.007466
   Number of active neurons: 10
 >> iter 61000, loss: 0.003862
 >> iter 62000, loss: 0.002248
 >> iter 63000, loss: 0.001851
 >> iter 64000, loss: 0.005789
 >> iter 65000, loss: 0.003174
 >> iter 66000, loss: 0.002061
 >> iter 67000, loss: 0.001546
 >> iter 68000, loss: 0.004314
 >> iter 69000, loss: 0.002367
 >> iter 70000, loss: 0.004544
   Number of active neurons: 10
 >> iter 71000, loss: 0.002285
 >> iter 72000, loss: 0.001439
 >> iter 73000, loss: 0.001116
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.158865
 >> iter 2000, loss: 8.023560
 >> iter 3000, loss: 3.511043
 >> iter 4000, loss: 1.555839
 >> iter 5000, loss: 0.662386
 >> iter 6000, loss: 0.443158
 >> iter 7000, loss: 0.298976
 >> iter 8000, loss: 0.250962
 >> iter 9000, loss: 0.142095
 >> iter 10000, loss: 0.161357
   Number of active neurons: 10
 >> iter 11000, loss: 0.090368
 >> iter 12000, loss: 0.047507
 >> iter 13000, loss: 0.200279
 >> iter 14000, loss: 0.213875
 >> iter 15000, loss: 0.143603
 >> iter 16000, loss: 0.082770
 >> iter 17000, loss: 0.039826
 >> iter 18000, loss: 0.066272
 >> iter 19000, loss: 0.078633
 >> iter 20000, loss: 0.040466
   Number of active neurons: 10
 >> iter 21000, loss: 0.110220
 >> iter 22000, loss: 0.046241
 >> iter 23000, loss: 0.020990
 >> iter 24000, loss: 0.010401
 >> iter 25000, loss: 0.005982
 >> iter 26000, loss: 0.005341
 >> iter 27000, loss: 0.044953
 >> iter 28000, loss: 0.018625
 >> iter 29000, loss: 0.008548
 >> iter 30000, loss: 0.056773
   Number of active neurons: 10
 >> iter 31000, loss: 0.022934
 >> iter 32000, loss: 0.164935
 >> iter 33000, loss: 0.063789
 >> iter 34000, loss: 0.025495
 >> iter 35000, loss: 0.011980
 >> iter 36000, loss: 0.005991
 >> iter 37000, loss: 0.003740
 >> iter 38000, loss: 0.048429
 >> iter 39000, loss: 0.077217
 >> iter 40000, loss: 0.030533
   Number of active neurons: 10
 >> iter 41000, loss: 0.013167
 >> iter 42000, loss: 0.006287
 >> iter 43000, loss: 0.034114
 >> iter 44000, loss: 0.013913
 >> iter 45000, loss: 0.006407
 >> iter 46000, loss: 0.003483
 >> iter 47000, loss: 0.002279
 >> iter 48000, loss: 0.001721
 >> iter 49000, loss: 0.001464
 >> iter 50000, loss: 0.001434
   Number of active neurons: 10
 >> iter 51000, loss: 0.001313
 >> iter 52000, loss: 0.025525
 >> iter 53000, loss: 0.072335
 >> iter 54000, loss: 0.028188
 >> iter 55000, loss: 0.011677
 >> iter 56000, loss: 0.005345
 >> iter 57000, loss: 0.003005
 >> iter 58000, loss: 0.001992
 >> iter 59000, loss: 0.003143
 >> iter 60000, loss: 0.002005
   Number of active neurons: 10
 >> iter 61000, loss: 0.001581
 >> iter 62000, loss: 0.001394
 >> iter 63000, loss: 0.001235
 >> iter 64000, loss: 0.001071
 >> iter 65000, loss: 0.001108
 >> iter 66000, loss: 0.051602
 >> iter 67000, loss: 0.019872
 >> iter 68000, loss: 0.008140
 >> iter 69000, loss: 0.144126
 >> iter 70000, loss: 0.055745
   Number of active neurons: 10
 >> iter 71000, loss: 0.022110
 >> iter 72000, loss: 0.009509
 >> iter 73000, loss: 0.004634
 >> iter 74000, loss: 0.002957
 >> iter 75000, loss: 0.002200
 >> iter 76000, loss: 0.029040
 >> iter 77000, loss: 0.011731
 >> iter 78000, loss: 0.005211
 >> iter 79000, loss: 0.003016
 >> iter 80000, loss: 0.001851
   Number of active neurons: 10
 >> iter 81000, loss: 0.001419
 >> iter 82000, loss: 0.001228
 >> iter 83000, loss: 0.001099
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.315340
 >> iter 2000, loss: 8.795461
 >> iter 3000, loss: 4.014479
 >> iter 4000, loss: 1.765839
 >> iter 5000, loss: 0.891591
 >> iter 6000, loss: 0.401837
 >> iter 7000, loss: 0.215552
 >> iter 8000, loss: 0.086780
 >> iter 9000, loss: 0.274054
 >> iter 10000, loss: 0.307875
   Number of active neurons: 10
 >> iter 11000, loss: 0.207884
 >> iter 12000, loss: 0.183225
 >> iter 13000, loss: 0.149777
 >> iter 14000, loss: 0.146813
 >> iter 15000, loss: 0.062403
 >> iter 16000, loss: 0.026462
 >> iter 17000, loss: 0.021124
 >> iter 18000, loss: 0.010392
 >> iter 19000, loss: 0.211353
 >> iter 20000, loss: 0.082673
   Number of active neurons: 9
 >> iter 21000, loss: 0.033910
 >> iter 22000, loss: 0.068741
 >> iter 23000, loss: 0.027774
 >> iter 24000, loss: 0.014606
 >> iter 25000, loss: 0.007911
 >> iter 26000, loss: 0.069665
 >> iter 27000, loss: 0.027885
 >> iter 28000, loss: 0.012180
 >> iter 29000, loss: 0.006186
 >> iter 30000, loss: 0.035682
   Number of active neurons: 10
 >> iter 31000, loss: 0.014912
 >> iter 32000, loss: 0.006819
 >> iter 33000, loss: 0.055775
 >> iter 34000, loss: 0.034747
 >> iter 35000, loss: 0.063485
 >> iter 36000, loss: 0.025049
 >> iter 37000, loss: 0.011429
 >> iter 38000, loss: 0.005485
 >> iter 39000, loss: 0.030228
 >> iter 40000, loss: 0.078145
   Number of active neurons: 10
 >> iter 41000, loss: 0.030182
 >> iter 42000, loss: 0.085934
 >> iter 43000, loss: 0.033617
 >> iter 44000, loss: 0.040084
 >> iter 45000, loss: 0.017673
 >> iter 46000, loss: 0.008149
 >> iter 47000, loss: 0.004367
 >> iter 48000, loss: 0.002800
 >> iter 49000, loss: 0.002317
 >> iter 50000, loss: 0.001842
   Number of active neurons: 10
 >> iter 51000, loss: 0.001553
 >> iter 52000, loss: 0.001345
 >> iter 53000, loss: 0.001419
 >> iter 54000, loss: 0.001363
 >> iter 55000, loss: 0.055322
 >> iter 56000, loss: 0.029458
 >> iter 57000, loss: 0.012225
 >> iter 58000, loss: 0.029374
 >> iter 59000, loss: 0.013337
 >> iter 60000, loss: 0.021603
   Number of active neurons: 10
 >> iter 61000, loss: 0.009319
 >> iter 62000, loss: 0.099102
 >> iter 63000, loss: 0.038323
 >> iter 64000, loss: 0.015551
 >> iter 65000, loss: 0.006868
 >> iter 66000, loss: 0.003529
 >> iter 67000, loss: 0.005236
 >> iter 68000, loss: 0.002841
 >> iter 69000, loss: 0.006417
 >> iter 70000, loss: 0.135224
   Number of active neurons: 10
 >> iter 71000, loss: 0.207792
 >> iter 72000, loss: 0.079017
 >> iter 73000, loss: 0.031004
 >> iter 74000, loss: 0.013079
 >> iter 75000, loss: 0.006188
 >> iter 76000, loss: 0.003467
 >> iter 77000, loss: 0.002377
 >> iter 78000, loss: 0.001888
 >> iter 79000, loss: 0.019326
 >> iter 80000, loss: 0.010318
   Number of active neurons: 10
 >> iter 81000, loss: 0.004783
 >> iter 82000, loss: 0.002616
 >> iter 83000, loss: 0.083595
 >> iter 84000, loss: 0.032366
 >> iter 85000, loss: 0.013065
 >> iter 86000, loss: 0.005761
 >> iter 87000, loss: 0.003012
 >> iter 88000, loss: 0.009597
 >> iter 89000, loss: 0.004307
 >> iter 90000, loss: 0.002284
   Number of active neurons: 10
 >> iter 91000, loss: 0.001545
 >> iter 92000, loss: 0.001176
 >> iter 93000, loss: 0.076882
 >> iter 94000, loss: 0.086930
 >> iter 95000, loss: 0.058092
 >> iter 96000, loss: 0.023362
 >> iter 97000, loss: 0.009654
 >> iter 98000, loss: 0.004529
 >> iter 99000, loss: 0.002496
 >> iter 100000, loss: 0.001740
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.620739
 >> iter 2000, loss: 8.463293
 >> iter 3000, loss: 3.756464
 >> iter 4000, loss: 1.476375
 >> iter 5000, loss: 0.757473
 >> iter 6000, loss: 0.346236
 >> iter 7000, loss: 0.225460
 >> iter 8000, loss: 0.142261
 >> iter 9000, loss: 0.147631
 >> iter 10000, loss: 0.140675
   Number of active neurons: 10
 >> iter 11000, loss: 0.219313
 >> iter 12000, loss: 0.113607
 >> iter 13000, loss: 0.131294
 >> iter 14000, loss: 0.172685
 >> iter 15000, loss: 0.295130
 >> iter 16000, loss: 0.117621
 >> iter 17000, loss: 0.050296
 >> iter 18000, loss: 0.128659
 >> iter 19000, loss: 0.053726
 >> iter 20000, loss: 0.048387
   Number of active neurons: 10
 >> iter 21000, loss: 0.043241
 >> iter 22000, loss: 0.021181
 >> iter 23000, loss: 0.012053
 >> iter 24000, loss: 0.006844
 >> iter 25000, loss: 0.004800
 >> iter 26000, loss: 0.003420
 >> iter 27000, loss: 0.015038
 >> iter 28000, loss: 0.007596
 >> iter 29000, loss: 0.045272
 >> iter 30000, loss: 0.019043
   Number of active neurons: 10
 >> iter 31000, loss: 0.017923
 >> iter 32000, loss: 0.008221
 >> iter 33000, loss: 0.123203
 >> iter 34000, loss: 0.057352
 >> iter 35000, loss: 0.064663
 >> iter 36000, loss: 0.026376
 >> iter 37000, loss: 0.011535
 >> iter 38000, loss: 0.005754
 >> iter 39000, loss: 0.003605
 >> iter 40000, loss: 0.002564
   Number of active neurons: 10
 >> iter 41000, loss: 0.053265
 >> iter 42000, loss: 0.021350
 >> iter 43000, loss: 0.009256
 >> iter 44000, loss: 0.004581
 >> iter 45000, loss: 0.002766
 >> iter 46000, loss: 0.002034
 >> iter 47000, loss: 0.001635
 >> iter 48000, loss: 0.001403
 >> iter 49000, loss: 0.048227
 >> iter 50000, loss: 0.019020
   Number of active neurons: 10
 >> iter 51000, loss: 0.008065
 >> iter 52000, loss: 0.004171
 >> iter 53000, loss: 0.003204
 >> iter 54000, loss: 0.001940
 >> iter 55000, loss: 0.005594
 >> iter 56000, loss: 0.002900
 >> iter 57000, loss: 0.001939
 >> iter 58000, loss: 0.002442
 >> iter 59000, loss: 0.075858
 >> iter 60000, loss: 0.028843
   Number of active neurons: 10
 >> iter 61000, loss: 0.020915
 >> iter 62000, loss: 0.008588
 >> iter 63000, loss: 0.003910
 >> iter 64000, loss: 0.002173
 >> iter 65000, loss: 0.001420
 >> iter 66000, loss: 0.001115
 >> iter 67000, loss: 0.001022
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.314154
 >> iter 2000, loss: 8.794797
 >> iter 3000, loss: 3.662712
 >> iter 4000, loss: 1.728397
 >> iter 5000, loss: 0.832945
 >> iter 6000, loss: 0.541671
 >> iter 7000, loss: 0.434351
 >> iter 8000, loss: 0.240339
 >> iter 9000, loss: 0.123913
 >> iter 10000, loss: 0.081766
   Number of active neurons: 10
 >> iter 11000, loss: 0.100359
 >> iter 12000, loss: 0.120215
 >> iter 13000, loss: 0.054115
 >> iter 14000, loss: 0.025345
 >> iter 15000, loss: 0.017014
 >> iter 16000, loss: 0.009280
 >> iter 17000, loss: 0.010615
 >> iter 18000, loss: 0.168930
 >> iter 19000, loss: 0.066254
 >> iter 20000, loss: 0.039400
   Number of active neurons: 10
 >> iter 21000, loss: 0.022286
 >> iter 22000, loss: 0.010339
 >> iter 23000, loss: 0.005742
 >> iter 24000, loss: 0.004654
 >> iter 25000, loss: 0.003717
 >> iter 26000, loss: 0.002862
 >> iter 27000, loss: 0.117859
 >> iter 28000, loss: 0.061263
 >> iter 29000, loss: 0.024672
 >> iter 30000, loss: 0.083270
   Number of active neurons: 10
 >> iter 31000, loss: 0.032609
 >> iter 32000, loss: 0.100454
 >> iter 33000, loss: 0.052116
 >> iter 34000, loss: 0.021205
 >> iter 35000, loss: 0.009614
 >> iter 36000, loss: 0.004938
 >> iter 37000, loss: 0.003094
 >> iter 38000, loss: 0.002303
 >> iter 39000, loss: 0.017980
 >> iter 40000, loss: 0.008101
   Number of active neurons: 10
 >> iter 41000, loss: 0.004151
 >> iter 42000, loss: 0.002549
 >> iter 43000, loss: 0.001888
 >> iter 44000, loss: 0.001694
 >> iter 45000, loss: 0.019300
 >> iter 46000, loss: 0.073746
 >> iter 47000, loss: 0.144533
 >> iter 48000, loss: 0.055567
 >> iter 49000, loss: 0.023485
 >> iter 50000, loss: 0.010573
   Number of active neurons: 10
 >> iter 51000, loss: 0.005220
 >> iter 52000, loss: 0.003020
 >> iter 53000, loss: 0.002251
 >> iter 54000, loss: 0.001814
 >> iter 55000, loss: 0.001572
 >> iter 56000, loss: 0.001370
 >> iter 57000, loss: 0.001253
 >> iter 58000, loss: 0.001272
 >> iter 59000, loss: 0.001170
 >> iter 60000, loss: 0.026255
   Number of active neurons: 10
 >> iter 61000, loss: 0.074802
 >> iter 62000, loss: 0.028539
 >> iter 63000, loss: 0.011450
 >> iter 64000, loss: 0.005015
 >> iter 65000, loss: 0.002626
 >> iter 66000, loss: 0.002020
 >> iter 67000, loss: 0.001536
 >> iter 68000, loss: 0.001298
 >> iter 69000, loss: 0.024684
 >> iter 70000, loss: 0.010278
   Number of active neurons: 10
 >> iter 71000, loss: 0.004666
 >> iter 72000, loss: 0.002433
 >> iter 73000, loss: 0.001670
 >> iter 74000, loss: 0.025967
 >> iter 75000, loss: 0.010421
 >> iter 76000, loss: 0.004635
 >> iter 77000, loss: 0.002443
 >> iter 78000, loss: 0.001619
 >> iter 79000, loss: 0.004479
 >> iter 80000, loss: 0.003908
   Number of active neurons: 10
 >> iter 81000, loss: 0.002169
 >> iter 82000, loss: 0.001664
 >> iter 83000, loss: 0.001354
 >> iter 84000, loss: 0.001189
 >> iter 85000, loss: 0.001075
 >> iter 86000, loss: 0.001058
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.108317
 >> iter 2000, loss: 8.232488
 >> iter 3000, loss: 3.522481
 >> iter 4000, loss: 1.661958
 >> iter 5000, loss: 0.758308
 >> iter 6000, loss: 0.371541
 >> iter 7000, loss: 0.225826
 >> iter 8000, loss: 0.198206
 >> iter 9000, loss: 0.175741
 >> iter 10000, loss: 0.076968
   Number of active neurons: 10
 >> iter 11000, loss: 0.038187
 >> iter 12000, loss: 0.100289
 >> iter 13000, loss: 0.112103
 >> iter 14000, loss: 0.116440
 >> iter 15000, loss: 0.048152
 >> iter 16000, loss: 0.052654
 >> iter 17000, loss: 0.023353
 >> iter 18000, loss: 0.050200
 >> iter 19000, loss: 0.111085
 >> iter 20000, loss: 0.066347
   Number of active neurons: 10
 >> iter 21000, loss: 0.027614
 >> iter 22000, loss: 0.012876
 >> iter 23000, loss: 0.007004
 >> iter 24000, loss: 0.004762
 >> iter 25000, loss: 0.030489
 >> iter 26000, loss: 0.033484
 >> iter 27000, loss: 0.014320
 >> iter 28000, loss: 0.011161
 >> iter 29000, loss: 0.005714
 >> iter 30000, loss: 0.003850
   Number of active neurons: 10
 >> iter 31000, loss: 0.010496
 >> iter 32000, loss: 0.072844
 >> iter 33000, loss: 0.028858
 >> iter 34000, loss: 0.074130
 >> iter 35000, loss: 0.029866
 >> iter 36000, loss: 0.013002
 >> iter 37000, loss: 0.006397
 >> iter 38000, loss: 0.003740
 >> iter 39000, loss: 0.026710
 >> iter 40000, loss: 0.284037
   Number of active neurons: 10
 >> iter 41000, loss: 0.108167
 >> iter 42000, loss: 0.042367
 >> iter 43000, loss: 0.017560
 >> iter 44000, loss: 0.008122
 >> iter 45000, loss: 0.004907
 >> iter 46000, loss: 0.003323
 >> iter 47000, loss: 0.003251
 >> iter 48000, loss: 0.002255
 >> iter 49000, loss: 0.001845
 >> iter 50000, loss: 0.001609
   Number of active neurons: 10
 >> iter 51000, loss: 0.001459
 >> iter 52000, loss: 0.001428
 >> iter 53000, loss: 0.001334
 >> iter 54000, loss: 0.002726
 >> iter 55000, loss: 0.061732
 >> iter 56000, loss: 0.023957
 >> iter 57000, loss: 0.010073
 >> iter 58000, loss: 0.081363
 >> iter 59000, loss: 0.031790
 >> iter 60000, loss: 0.012798
   Number of active neurons: 10
 >> iter 61000, loss: 0.005726
 >> iter 62000, loss: 0.003386
 >> iter 63000, loss: 0.002173
 >> iter 64000, loss: 0.001634
 >> iter 65000, loss: 0.001400
 >> iter 66000, loss: 0.001370
 >> iter 67000, loss: 0.001210
 >> iter 68000, loss: 0.001128
 >> iter 69000, loss: 0.026341
 >> iter 70000, loss: 0.022104
   Number of active neurons: 10
 >> iter 71000, loss: 0.009001
 >> iter 72000, loss: 0.004071
 >> iter 73000, loss: 0.028776
 >> iter 74000, loss: 0.011420
 >> iter 75000, loss: 0.005682
 >> iter 76000, loss: 0.004143
 >> iter 77000, loss: 0.002379
 >> iter 78000, loss: 0.001542
 >> iter 79000, loss: 0.001468
 >> iter 80000, loss: 0.007318
   Number of active neurons: 10
 >> iter 81000, loss: 0.104023
 >> iter 82000, loss: 0.039246
 >> iter 83000, loss: 0.015324
 >> iter 84000, loss: 0.006487
 >> iter 85000, loss: 0.003172
 >> iter 86000, loss: 0.001885
 >> iter 87000, loss: 0.001370
 >> iter 88000, loss: 0.001173
 >> iter 89000, loss: 0.001074
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.061953
 >> iter 2000, loss: 7.958080
 >> iter 3000, loss: 3.425441
 >> iter 4000, loss: 1.463971
 >> iter 5000, loss: 0.836422
 >> iter 6000, loss: 0.562070
 >> iter 7000, loss: 0.275632
 >> iter 8000, loss: 0.159996
 >> iter 9000, loss: 0.109394
 >> iter 10000, loss: 0.137436
   Number of active neurons: 9
 >> iter 11000, loss: 0.077699
 >> iter 12000, loss: 0.172298
 >> iter 13000, loss: 0.150913
 >> iter 14000, loss: 0.062762
 >> iter 15000, loss: 0.089801
 >> iter 16000, loss: 0.038616
 >> iter 17000, loss: 0.018916
 >> iter 18000, loss: 0.012668
 >> iter 19000, loss: 0.115529
 >> iter 20000, loss: 0.046725
   Number of active neurons: 10
 >> iter 21000, loss: 0.059853
 >> iter 22000, loss: 0.044687
 >> iter 23000, loss: 0.020234
 >> iter 24000, loss: 0.186226
 >> iter 25000, loss: 0.088035
 >> iter 26000, loss: 0.035878
 >> iter 27000, loss: 0.031765
 >> iter 28000, loss: 0.014265
 >> iter 29000, loss: 0.053310
 >> iter 30000, loss: 0.022153
   Number of active neurons: 10
 >> iter 31000, loss: 0.011396
 >> iter 32000, loss: 0.006313
 >> iter 33000, loss: 0.008518
 >> iter 34000, loss: 0.005988
 >> iter 35000, loss: 0.018091
 >> iter 36000, loss: 0.008637
 >> iter 37000, loss: 0.004965
 >> iter 38000, loss: 0.003402
 >> iter 39000, loss: 0.078159
 >> iter 40000, loss: 0.030949
   Number of active neurons: 10
 >> iter 41000, loss: 0.015174
 >> iter 42000, loss: 0.007015
 >> iter 43000, loss: 0.003909
 >> iter 44000, loss: 0.002772
 >> iter 45000, loss: 0.002140
 >> iter 46000, loss: 0.003671
 >> iter 47000, loss: 0.061222
 >> iter 48000, loss: 0.023924
 >> iter 49000, loss: 0.009916
 >> iter 50000, loss: 0.004673
   Number of active neurons: 10
 >> iter 51000, loss: 0.002682
 >> iter 52000, loss: 0.001954
 >> iter 53000, loss: 0.001637
 >> iter 54000, loss: 0.001424
 >> iter 55000, loss: 0.001321
 >> iter 56000, loss: 0.001542
 >> iter 57000, loss: 0.001295
 >> iter 58000, loss: 0.077026
 >> iter 59000, loss: 0.118042
 >> iter 60000, loss: 0.046045
   Number of active neurons: 10
 >> iter 61000, loss: 0.018145
 >> iter 62000, loss: 0.007726
 >> iter 63000, loss: 0.007345
 >> iter 64000, loss: 0.003442
 >> iter 65000, loss: 0.002156
 >> iter 66000, loss: 0.048549
 >> iter 67000, loss: 0.018905
 >> iter 68000, loss: 0.013517
 >> iter 69000, loss: 0.005839
 >> iter 70000, loss: 0.002944
   Number of active neurons: 10
 >> iter 71000, loss: 0.001824
 >> iter 72000, loss: 0.001393
 >> iter 73000, loss: 0.001179
 >> iter 74000, loss: 0.001059
 >> iter 75000, loss: 0.001016
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.781877
 >> iter 2000, loss: 7.881387
 >> iter 3000, loss: 3.175275
 >> iter 4000, loss: 1.357207
 >> iter 5000, loss: 0.577260
 >> iter 6000, loss: 0.294314
 >> iter 7000, loss: 0.200639
 >> iter 8000, loss: 0.437339
 >> iter 9000, loss: 0.286935
 >> iter 10000, loss: 0.257864
   Number of active neurons: 10
 >> iter 11000, loss: 0.243870
 >> iter 12000, loss: 0.104250
 >> iter 13000, loss: 0.042973
 >> iter 14000, loss: 0.225306
 >> iter 15000, loss: 0.088690
 >> iter 16000, loss: 0.036425
 >> iter 17000, loss: 0.072374
 >> iter 18000, loss: 0.127366
 >> iter 19000, loss: 0.104346
 >> iter 20000, loss: 0.046740
   Number of active neurons: 10
 >> iter 21000, loss: 0.020339
 >> iter 22000, loss: 0.023822
 >> iter 23000, loss: 0.154427
 >> iter 24000, loss: 0.060649
 >> iter 25000, loss: 0.024864
 >> iter 26000, loss: 0.011348
 >> iter 27000, loss: 0.005982
 >> iter 28000, loss: 0.003887
 >> iter 29000, loss: 0.069279
 >> iter 30000, loss: 0.066350
   Number of active neurons: 10
 >> iter 31000, loss: 0.026998
 >> iter 32000, loss: 0.011916
 >> iter 33000, loss: 0.006116
 >> iter 34000, loss: 0.003764
 >> iter 35000, loss: 0.002851
 >> iter 36000, loss: 0.002263
 >> iter 37000, loss: 0.001966
 >> iter 38000, loss: 0.001770
 >> iter 39000, loss: 0.001646
 >> iter 40000, loss: 0.022273
   Number of active neurons: 10
 >> iter 41000, loss: 0.009264
 >> iter 42000, loss: 0.014946
 >> iter 43000, loss: 0.009509
 >> iter 44000, loss: 0.004466
 >> iter 45000, loss: 0.002517
 >> iter 46000, loss: 0.061056
 >> iter 47000, loss: 0.032389
 >> iter 48000, loss: 0.013136
 >> iter 49000, loss: 0.005813
 >> iter 50000, loss: 0.003076
   Number of active neurons: 10
 >> iter 51000, loss: 0.175510
 >> iter 52000, loss: 0.066833
 >> iter 53000, loss: 0.026216
 >> iter 54000, loss: 0.091306
 >> iter 55000, loss: 0.035888
 >> iter 56000, loss: 0.016079
 >> iter 57000, loss: 0.007624
 >> iter 58000, loss: 0.004208
 >> iter 59000, loss: 0.008191
 >> iter 60000, loss: 0.042318
   Number of active neurons: 10
 >> iter 61000, loss: 0.041109
 >> iter 62000, loss: 0.016827
 >> iter 63000, loss: 0.007649
 >> iter 64000, loss: 0.003983
 >> iter 65000, loss: 0.002516
 >> iter 66000, loss: 0.005063
 >> iter 67000, loss: 0.003218
 >> iter 68000, loss: 0.002174
 >> iter 69000, loss: 0.001618
 >> iter 70000, loss: 0.001569
   Number of active neurons: 10
 >> iter 71000, loss: 0.001388
 >> iter 72000, loss: 0.001241
 >> iter 73000, loss: 0.001117
 >> iter 74000, loss: 0.001013
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 17.421390
 >> iter 2000, loss: 8.891919
 >> iter 3000, loss: 3.886857
 >> iter 4000, loss: 1.776253
 >> iter 5000, loss: 1.008923
 >> iter 6000, loss: 0.491420
 >> iter 7000, loss: 0.385167
 >> iter 8000, loss: 0.198408
 >> iter 9000, loss: 0.206710
 >> iter 10000, loss: 0.084330
   Number of active neurons: 10
 >> iter 11000, loss: 0.036563
 >> iter 12000, loss: 0.073534
 >> iter 13000, loss: 0.048278
 >> iter 14000, loss: 0.082937
 >> iter 15000, loss: 0.059450
 >> iter 16000, loss: 0.051211
 >> iter 17000, loss: 0.022267
 >> iter 18000, loss: 0.010738
 >> iter 19000, loss: 0.023132
 >> iter 20000, loss: 0.150054
   Number of active neurons: 10
 >> iter 21000, loss: 0.065168
 >> iter 22000, loss: 0.039441
 >> iter 23000, loss: 0.016973
 >> iter 24000, loss: 0.008543
 >> iter 25000, loss: 0.044431
 >> iter 26000, loss: 0.018277
 >> iter 27000, loss: 0.008484
 >> iter 28000, loss: 0.004704
 >> iter 29000, loss: 0.003196
 >> iter 30000, loss: 0.002460
   Number of active neurons: 10
 >> iter 31000, loss: 0.002043
 >> iter 32000, loss: 0.001794
 >> iter 33000, loss: 0.002918
 >> iter 34000, loss: 0.007087
 >> iter 35000, loss: 0.003711
 >> iter 36000, loss: 0.002340
 >> iter 37000, loss: 0.109036
 >> iter 38000, loss: 0.044463
 >> iter 39000, loss: 0.017707
 >> iter 40000, loss: 0.007685
   Number of active neurons: 10
 >> iter 41000, loss: 0.013025
 >> iter 42000, loss: 0.005898
 >> iter 43000, loss: 0.003501
 >> iter 44000, loss: 0.002238
 >> iter 45000, loss: 0.001782
 >> iter 46000, loss: 0.001552
 >> iter 47000, loss: 0.001295
 >> iter 48000, loss: 0.001127
 >> iter 49000, loss: 0.001092
 >> iter 50000, loss: 0.001049
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.278984
 >> iter 2000, loss: 8.542256
 >> iter 3000, loss: 3.381557
 >> iter 4000, loss: 1.615747
 >> iter 5000, loss: 0.642244
 >> iter 6000, loss: 0.459424
 >> iter 7000, loss: 0.287645
 >> iter 8000, loss: 0.286434
 >> iter 9000, loss: 0.210133
 >> iter 10000, loss: 0.137107
   Number of active neurons: 10
 >> iter 11000, loss: 0.140795
 >> iter 12000, loss: 0.059367
 >> iter 13000, loss: 0.067819
 >> iter 14000, loss: 0.037575
 >> iter 15000, loss: 0.131724
 >> iter 16000, loss: 0.134794
 >> iter 17000, loss: 0.247265
 >> iter 18000, loss: 0.209261
 >> iter 19000, loss: 0.133809
 >> iter 20000, loss: 0.216001
   Number of active neurons: 10
 >> iter 21000, loss: 0.085892
 >> iter 22000, loss: 0.045888
 >> iter 23000, loss: 0.332233
 >> iter 24000, loss: 0.129126
 >> iter 25000, loss: 0.057610
 >> iter 26000, loss: 0.025091
 >> iter 27000, loss: 0.014719
 >> iter 28000, loss: 0.008184
 >> iter 29000, loss: 0.020478
 >> iter 30000, loss: 0.029919
   Number of active neurons: 10
 >> iter 31000, loss: 0.013206
 >> iter 32000, loss: 0.006589
 >> iter 33000, loss: 0.030662
 >> iter 34000, loss: 0.132194
 >> iter 35000, loss: 0.099203
 >> iter 36000, loss: 0.212762
 >> iter 37000, loss: 0.085450
 >> iter 38000, loss: 0.033956
 >> iter 39000, loss: 0.014759
 >> iter 40000, loss: 0.028267
   Number of active neurons: 10
 >> iter 41000, loss: 0.012687
 >> iter 42000, loss: 0.006413
 >> iter 43000, loss: 0.004023
 >> iter 44000, loss: 0.002844
 >> iter 45000, loss: 0.002283
 >> iter 46000, loss: 0.003038
 >> iter 47000, loss: 0.005220
 >> iter 48000, loss: 0.003119
 >> iter 49000, loss: 0.002567
 >> iter 50000, loss: 0.002605
   Number of active neurons: 10
 >> iter 51000, loss: 0.042914
 >> iter 52000, loss: 0.017136
 >> iter 53000, loss: 0.008173
 >> iter 54000, loss: 0.005419
 >> iter 55000, loss: 0.002950
 >> iter 56000, loss: 0.002041
 >> iter 57000, loss: 0.001570
 >> iter 58000, loss: 0.032683
 >> iter 59000, loss: 0.013427
 >> iter 60000, loss: 0.005944
   Number of active neurons: 10
 >> iter 61000, loss: 0.003305
 >> iter 62000, loss: 0.002014
 >> iter 63000, loss: 0.002136
 >> iter 64000, loss: 0.001545
 >> iter 65000, loss: 0.001227
 >> iter 66000, loss: 0.001094
 >> iter 67000, loss: 0.085830
 >> iter 68000, loss: 0.032557
 >> iter 69000, loss: 0.012860
 >> iter 70000, loss: 0.005525
   Number of active neurons: 10
 >> iter 71000, loss: 0.002824
 >> iter 72000, loss: 0.001788
 >> iter 73000, loss: 0.001422
 >> iter 74000, loss: 0.001180
 >> iter 75000, loss: 0.004872
 >> iter 76000, loss: 0.002448
 >> iter 77000, loss: 0.001553
 >> iter 78000, loss: 0.001201
 >> iter 79000, loss: 0.001059
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.148339
 >> iter 2000, loss: 8.131931
 >> iter 3000, loss: 3.314244
 >> iter 4000, loss: 1.510328
 >> iter 5000, loss: 0.829237
 >> iter 6000, loss: 0.384100
 >> iter 7000, loss: 0.193252
 >> iter 8000, loss: 0.117160
 >> iter 9000, loss: 0.077149
 >> iter 10000, loss: 0.106355
   Number of active neurons: 10
 >> iter 11000, loss: 0.112867
 >> iter 12000, loss: 0.145465
 >> iter 13000, loss: 0.194899
 >> iter 14000, loss: 0.135341
 >> iter 15000, loss: 0.057413
 >> iter 16000, loss: 0.157443
 >> iter 17000, loss: 0.063571
 >> iter 18000, loss: 0.069346
 >> iter 19000, loss: 0.086951
 >> iter 20000, loss: 0.035814
   Number of active neurons: 10
 >> iter 21000, loss: 0.163287
 >> iter 22000, loss: 0.162495
 >> iter 23000, loss: 0.135237
 >> iter 24000, loss: 0.129131
 >> iter 25000, loss: 0.079933
 >> iter 26000, loss: 0.033492
 >> iter 27000, loss: 0.045503
 >> iter 28000, loss: 0.056450
 >> iter 29000, loss: 0.087805
 >> iter 30000, loss: 0.085110
   Number of active neurons: 10
 >> iter 31000, loss: 0.034282
 >> iter 32000, loss: 0.015001
 >> iter 33000, loss: 0.007584
 >> iter 34000, loss: 0.014005
 >> iter 35000, loss: 0.049879
 >> iter 36000, loss: 0.028960
 >> iter 37000, loss: 0.012697
 >> iter 38000, loss: 0.006417
 >> iter 39000, loss: 0.003699
 >> iter 40000, loss: 0.002626
   Number of active neurons: 10
 >> iter 41000, loss: 0.002153
 >> iter 42000, loss: 0.001914
 >> iter 43000, loss: 0.001813
 >> iter 44000, loss: 0.002276
 >> iter 45000, loss: 0.001753
 >> iter 46000, loss: 0.001525
 >> iter 47000, loss: 0.001329
 >> iter 48000, loss: 0.003799
 >> iter 49000, loss: 0.002373
 >> iter 50000, loss: 0.012033
   Number of active neurons: 10
 >> iter 51000, loss: 0.008713
 >> iter 52000, loss: 0.004301
 >> iter 53000, loss: 0.004587
 >> iter 54000, loss: 0.003700
 >> iter 55000, loss: 0.025285
 >> iter 56000, loss: 0.010423
 >> iter 57000, loss: 0.067266
 >> iter 58000, loss: 0.025997
 >> iter 59000, loss: 0.010972
 >> iter 60000, loss: 0.005079
   Number of active neurons: 10
 >> iter 61000, loss: 0.002823
 >> iter 62000, loss: 0.001840
 >> iter 63000, loss: 0.001426
 >> iter 64000, loss: 0.001255
 >> iter 65000, loss: 0.001115
 >> iter 66000, loss: 0.001082
 >> iter 67000, loss: 0.001008
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.210606
 >> iter 2000, loss: 8.478202
 >> iter 3000, loss: 3.663921
 >> iter 4000, loss: 1.741688
 >> iter 5000, loss: 0.702483
 >> iter 6000, loss: 0.269230
 >> iter 7000, loss: 0.106686
 >> iter 8000, loss: 0.152111
 >> iter 9000, loss: 0.244056
 >> iter 10000, loss: 0.099956
   Number of active neurons: 10
 >> iter 11000, loss: 0.189182
 >> iter 12000, loss: 0.075664
 >> iter 13000, loss: 0.184373
 >> iter 14000, loss: 0.214466
 >> iter 15000, loss: 0.085404
 >> iter 16000, loss: 0.130721
 >> iter 17000, loss: 0.158394
 >> iter 18000, loss: 0.188122
 >> iter 19000, loss: 0.150692
 >> iter 20000, loss: 0.059543
   Number of active neurons: 10
 >> iter 21000, loss: 0.037347
 >> iter 22000, loss: 0.016746
 >> iter 23000, loss: 0.103350
 >> iter 24000, loss: 0.045136
 >> iter 25000, loss: 0.039980
 >> iter 26000, loss: 0.093952
 >> iter 27000, loss: 0.062444
 >> iter 28000, loss: 0.098470
 >> iter 29000, loss: 0.064703
 >> iter 30000, loss: 0.026793
   Number of active neurons: 10
 >> iter 31000, loss: 0.011994
 >> iter 32000, loss: 0.011537
 >> iter 33000, loss: 0.006179
 >> iter 34000, loss: 0.003748
 >> iter 35000, loss: 0.002692
 >> iter 36000, loss: 0.005368
 >> iter 37000, loss: 0.003041
 >> iter 38000, loss: 0.002024
 >> iter 39000, loss: 0.022559
 >> iter 40000, loss: 0.009451
   Number of active neurons: 10
 >> iter 41000, loss: 0.004446
 >> iter 42000, loss: 0.002420
 >> iter 43000, loss: 0.001641
 >> iter 44000, loss: 0.001281
 >> iter 45000, loss: 0.001205
 >> iter 46000, loss: 0.001521
 >> iter 47000, loss: 0.001101
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.388694
 >> iter 2000, loss: 8.436666
 >> iter 3000, loss: 3.706799
 >> iter 4000, loss: 1.768162
 >> iter 5000, loss: 0.838507
 >> iter 6000, loss: 0.516762
 >> iter 7000, loss: 0.439408
 >> iter 8000, loss: 0.282801
 >> iter 9000, loss: 0.160696
 >> iter 10000, loss: 0.129355
   Number of active neurons: 10
 >> iter 11000, loss: 0.221458
 >> iter 12000, loss: 0.092044
 >> iter 13000, loss: 0.131668
 >> iter 14000, loss: 0.061882
 >> iter 15000, loss: 0.027648
 >> iter 16000, loss: 0.013812
 >> iter 17000, loss: 0.100071
 >> iter 18000, loss: 0.105614
 >> iter 19000, loss: 0.049043
 >> iter 20000, loss: 0.261206
   Number of active neurons: 10
 >> iter 21000, loss: 0.166703
 >> iter 22000, loss: 0.250929
 >> iter 23000, loss: 0.150361
 >> iter 24000, loss: 0.297482
 >> iter 25000, loss: 0.116283
 >> iter 26000, loss: 0.050163
 >> iter 27000, loss: 0.056248
 >> iter 28000, loss: 0.117175
 >> iter 29000, loss: 0.048401
 >> iter 30000, loss: 0.021214
   Number of active neurons: 10
 >> iter 31000, loss: 0.010630
 >> iter 32000, loss: 0.006285
 >> iter 33000, loss: 0.004515
 >> iter 34000, loss: 0.003494
 >> iter 35000, loss: 0.003067
 >> iter 36000, loss: 0.002697
 >> iter 37000, loss: 0.002420
 >> iter 38000, loss: 0.143755
 >> iter 39000, loss: 0.055517
 >> iter 40000, loss: 0.022563
   Number of active neurons: 10
 >> iter 41000, loss: 0.014676
 >> iter 42000, loss: 0.007250
 >> iter 43000, loss: 0.067040
 >> iter 44000, loss: 0.027219
 >> iter 45000, loss: 0.053626
 >> iter 46000, loss: 0.203983
 >> iter 47000, loss: 0.079473
 >> iter 48000, loss: 0.032031
 >> iter 49000, loss: 0.014011
 >> iter 50000, loss: 0.031504
   Number of active neurons: 10
 >> iter 51000, loss: 0.013507
 >> iter 52000, loss: 0.006731
 >> iter 53000, loss: 0.004000
 >> iter 54000, loss: 0.003049
 >> iter 55000, loss: 0.002436
 >> iter 56000, loss: 0.002025
 >> iter 57000, loss: 0.016685
 >> iter 58000, loss: 0.013075
 >> iter 59000, loss: 0.006210
 >> iter 60000, loss: 0.039533
   Number of active neurons: 10
 >> iter 61000, loss: 0.016283
 >> iter 62000, loss: 0.007200
 >> iter 63000, loss: 0.003783
 >> iter 64000, loss: 0.003094
 >> iter 65000, loss: 0.002288
 >> iter 66000, loss: 0.001836
 >> iter 67000, loss: 0.001494
 >> iter 68000, loss: 0.016585
 >> iter 69000, loss: 0.006922
 >> iter 70000, loss: 0.003927
   Number of active neurons: 10
 >> iter 71000, loss: 0.002358
 >> iter 72000, loss: 0.001527
 >> iter 73000, loss: 0.001278
 >> iter 74000, loss: 0.001103
 >> iter 75000, loss: 0.001037
 >> iter 76000, loss: 0.025059
 >> iter 77000, loss: 0.010001
 >> iter 78000, loss: 0.004805
 >> iter 79000, loss: 0.002521
 >> iter 80000, loss: 0.006315
   Number of active neurons: 10
 >> iter 81000, loss: 0.003599
 >> iter 82000, loss: 0.001847
 >> iter 83000, loss: 0.001190
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.821203
 >> iter 2000, loss: 7.734269
 >> iter 3000, loss: 3.485234
 >> iter 4000, loss: 1.548800
 >> iter 5000, loss: 0.781478
 >> iter 6000, loss: 0.437819
 >> iter 7000, loss: 0.235425
 >> iter 8000, loss: 0.139068
 >> iter 9000, loss: 0.148500
 >> iter 10000, loss: 0.100805
   Number of active neurons: 9
 >> iter 11000, loss: 0.169328
 >> iter 12000, loss: 0.130628
 >> iter 13000, loss: 0.280219
 >> iter 14000, loss: 0.293795
 >> iter 15000, loss: 0.328572
 >> iter 16000, loss: 0.152316
 >> iter 17000, loss: 0.112234
 >> iter 18000, loss: 0.047634
 >> iter 19000, loss: 0.022393
 >> iter 20000, loss: 0.101185
   Number of active neurons: 10
 >> iter 21000, loss: 0.045524
 >> iter 22000, loss: 0.032599
 >> iter 23000, loss: 0.033318
 >> iter 24000, loss: 0.017856
 >> iter 25000, loss: 0.042113
 >> iter 26000, loss: 0.119504
 >> iter 27000, loss: 0.078380
 >> iter 28000, loss: 0.032227
 >> iter 29000, loss: 0.014647
 >> iter 30000, loss: 0.008092
   Number of active neurons: 10
 >> iter 31000, loss: 0.038431
 >> iter 32000, loss: 0.016867
 >> iter 33000, loss: 0.008441
 >> iter 34000, loss: 0.005141
 >> iter 35000, loss: 0.003593
 >> iter 36000, loss: 0.080298
 >> iter 37000, loss: 0.031491
 >> iter 38000, loss: 0.013384
 >> iter 39000, loss: 0.010493
 >> iter 40000, loss: 0.040215
   Number of active neurons: 10
 >> iter 41000, loss: 0.016554
 >> iter 42000, loss: 0.007571
 >> iter 43000, loss: 0.007708
 >> iter 44000, loss: 0.004115
 >> iter 45000, loss: 0.002957
 >> iter 46000, loss: 0.002207
 >> iter 47000, loss: 0.001855
 >> iter 48000, loss: 0.075163
 >> iter 49000, loss: 0.029525
 >> iter 50000, loss: 0.012411
   Number of active neurons: 10
 >> iter 51000, loss: 0.005998
 >> iter 52000, loss: 0.014139
 >> iter 53000, loss: 0.006891
 >> iter 54000, loss: 0.145106
 >> iter 55000, loss: 0.056158
 >> iter 56000, loss: 0.035429
 >> iter 57000, loss: 0.014634
 >> iter 58000, loss: 0.013555
 >> iter 59000, loss: 0.006442
 >> iter 60000, loss: 0.003603
   Number of active neurons: 10
 >> iter 61000, loss: 0.002386
 >> iter 62000, loss: 0.024244
 >> iter 63000, loss: 0.010075
 >> iter 64000, loss: 0.041981
 >> iter 65000, loss: 0.016592
 >> iter 66000, loss: 0.049890
 >> iter 67000, loss: 0.020124
 >> iter 68000, loss: 0.008612
 >> iter 69000, loss: 0.011023
 >> iter 70000, loss: 0.005436
   Number of active neurons: 10
 >> iter 71000, loss: 0.003061
 >> iter 72000, loss: 0.002028
 >> iter 73000, loss: 0.001669
 >> iter 74000, loss: 0.001434
 >> iter 75000, loss: 0.001303
 >> iter 76000, loss: 0.001250
 >> iter 77000, loss: 0.001165
 >> iter 78000, loss: 0.001230
 >> iter 79000, loss: 0.001065
 >> iter 80000, loss: 0.218402
   Number of active neurons: 10
 >> iter 81000, loss: 0.081952
 >> iter 82000, loss: 0.031415
 >> iter 83000, loss: 0.012635
 >> iter 84000, loss: 0.005605
 >> iter 85000, loss: 0.013657
 >> iter 86000, loss: 0.136322
 >> iter 87000, loss: 0.051669
 >> iter 88000, loss: 0.075207
 >> iter 89000, loss: 0.050763
 >> iter 90000, loss: 0.021217
   Number of active neurons: 10
 >> iter 91000, loss: 0.008989
 >> iter 92000, loss: 0.004374
 >> iter 93000, loss: 0.002776
 >> iter 94000, loss: 0.008552
 >> iter 95000, loss: 0.004095
 >> iter 96000, loss: 0.002361
 >> iter 97000, loss: 0.001675
 >> iter 98000, loss: 0.006766
 >> iter 99000, loss: 0.003729
 >> iter 100000, loss: 0.035884
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

