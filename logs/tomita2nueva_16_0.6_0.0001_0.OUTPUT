 > Problema: tomita2nueva
 > Args:
   - Hidden size: 16
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.289689
 >> iter 2000, loss: 4.408890
 >> iter 3000, loss: 1.748425
 >> iter 4000, loss: 0.741352
 >> iter 5000, loss: 0.320984
 >> iter 6000, loss: 0.159366
 >> iter 7000, loss: 0.105589
 >> iter 8000, loss: 0.088340
 >> iter 9000, loss: 0.078267
 >> iter 10000, loss: 0.059270
   Number of active neurons: 9
 >> iter 11000, loss: 0.073624
 >> iter 12000, loss: 0.065378
 >> iter 13000, loss: 0.064579
 >> iter 14000, loss: 0.083499
 >> iter 15000, loss: 0.068821
 >> iter 16000, loss: 0.060461
 >> iter 17000, loss: 0.079131
 >> iter 18000, loss: 0.065320
 >> iter 19000, loss: 0.048126
 >> iter 20000, loss: 0.071813
   Number of active neurons: 8
 >> iter 21000, loss: 0.067456
 >> iter 22000, loss: 0.065625
 >> iter 23000, loss: 0.052325
 >> iter 24000, loss: 0.067938
 >> iter 25000, loss: 0.055218
 >> iter 26000, loss: 0.050256
 >> iter 27000, loss: 0.068962
 >> iter 28000, loss: 0.068967
 >> iter 29000, loss: 0.074060
 >> iter 30000, loss: 0.050450
   Number of active neurons: 7
 >> iter 31000, loss: 0.052318
 >> iter 32000, loss: 0.050809
 >> iter 33000, loss: 0.047896
 >> iter 34000, loss: 0.061417
 >> iter 35000, loss: 0.050830
 >> iter 36000, loss: 0.060267
 >> iter 37000, loss: 0.061093
 >> iter 38000, loss: 0.045639
 >> iter 39000, loss: 0.056391
 >> iter 40000, loss: 0.052297
   Number of active neurons: 5
 >> iter 41000, loss: 0.043680
 >> iter 42000, loss: 0.060289
 >> iter 43000, loss: 0.060131
 >> iter 44000, loss: 0.050685
 >> iter 45000, loss: 0.071619
 >> iter 46000, loss: 0.049588
 >> iter 47000, loss: 0.061911
 >> iter 48000, loss: 0.061071
 >> iter 49000, loss: 0.049876
 >> iter 50000, loss: 0.050735
   Number of active neurons: 5
 >> iter 51000, loss: 0.060497
 >> iter 52000, loss: 0.053254
 >> iter 53000, loss: 0.053214
 >> iter 54000, loss: 0.065708
 >> iter 55000, loss: 0.057480
 >> iter 56000, loss: 0.068075
 >> iter 57000, loss: 0.069040
 >> iter 58000, loss: 0.048470
 >> iter 59000, loss: 0.044167
 >> iter 60000, loss: 0.056228
   Number of active neurons: 3
 >> iter 61000, loss: 0.060725
 >> iter 62000, loss: 0.048065
 >> iter 63000, loss: 0.054186
 >> iter 64000, loss: 0.068492
 >> iter 65000, loss: 0.058041
 >> iter 66000, loss: 0.065187
 >> iter 67000, loss: 0.066951
 >> iter 68000, loss: 0.071084
 >> iter 69000, loss: 0.047720
 >> iter 70000, loss: 0.038971
   Number of active neurons: 2
 >> iter 71000, loss: 0.044340
 >> iter 72000, loss: 0.036790
 >> iter 73000, loss: 0.049974
 >> iter 74000, loss: 0.049934
 >> iter 75000, loss: 0.047202
 >> iter 76000, loss: 0.049250
 >> iter 77000, loss: 0.059602
 >> iter 78000, loss: 0.049400
 >> iter 79000, loss: 0.042183
 >> iter 80000, loss: 0.031524
   Number of active neurons: 2
 >> iter 81000, loss: 0.038831
 >> iter 82000, loss: 0.035742
 >> iter 83000, loss: 0.029326
 >> iter 84000, loss: 0.029470
 >> iter 85000, loss: 0.031948
 >> iter 86000, loss: 0.033408
 >> iter 87000, loss: 0.045410
 >> iter 88000, loss: 0.032584
 >> iter 89000, loss: 0.059036
 >> iter 90000, loss: 0.059634
   Number of active neurons: 2
 >> iter 91000, loss: 0.041175
 >> iter 92000, loss: 0.047784
 >> iter 93000, loss: 0.043226
 >> iter 94000, loss: 0.054331
 >> iter 95000, loss: 0.038114
 >> iter 96000, loss: 0.038930
 >> iter 97000, loss: 0.041397
 >> iter 98000, loss: 0.054557
 >> iter 99000, loss: 0.039997
 >> iter 100000, loss: 0.056232
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 11.328652
 >> iter 2000, loss: 4.451069
 >> iter 3000, loss: 1.787494
 >> iter 4000, loss: 0.751932
 >> iter 5000, loss: 0.356802
 >> iter 6000, loss: 0.212299
 >> iter 7000, loss: 0.126484
 >> iter 8000, loss: 0.103971
 >> iter 9000, loss: 0.080080
 >> iter 10000, loss: 0.069028
   Number of active neurons: 10
 >> iter 11000, loss: 0.078447
 >> iter 12000, loss: 0.090402
 >> iter 13000, loss: 0.077089
 >> iter 14000, loss: 0.061645
 >> iter 15000, loss: 0.091332
 >> iter 16000, loss: 0.090340
 >> iter 17000, loss: 0.074855
 >> iter 18000, loss: 0.075874
 >> iter 19000, loss: 0.068251
 >> iter 20000, loss: 0.062184
   Number of active neurons: 8
 >> iter 21000, loss: 0.083219
 >> iter 22000, loss: 0.070476
 >> iter 23000, loss: 0.053323
 >> iter 24000, loss: 0.054303
 >> iter 25000, loss: 0.049598
 >> iter 26000, loss: 0.060826
 >> iter 27000, loss: 0.074946
 >> iter 28000, loss: 0.071475
 >> iter 29000, loss: 0.056552
 >> iter 30000, loss: 0.058337
   Number of active neurons: 5
 >> iter 31000, loss: 0.046958
 >> iter 32000, loss: 0.045580
 >> iter 33000, loss: 0.048273
 >> iter 34000, loss: 0.062752
 >> iter 35000, loss: 0.081770
 >> iter 36000, loss: 0.056159
 >> iter 37000, loss: 0.048969
 >> iter 38000, loss: 0.054359
 >> iter 39000, loss: 0.039381
 >> iter 40000, loss: 0.058981
   Number of active neurons: 4
 >> iter 41000, loss: 0.056157
 >> iter 42000, loss: 0.046397
 >> iter 43000, loss: 0.039921
 >> iter 44000, loss: 0.038472
 >> iter 45000, loss: 0.058282
 >> iter 46000, loss: 0.046963
 >> iter 47000, loss: 0.045719
 >> iter 48000, loss: 0.041792
 >> iter 49000, loss: 0.053419
 >> iter 50000, loss: 0.038054
   Number of active neurons: 4
 >> iter 51000, loss: 0.034570
 >> iter 52000, loss: 0.035496
 >> iter 53000, loss: 0.059171
 >> iter 54000, loss: 0.035658
 >> iter 55000, loss: 0.052357
 >> iter 56000, loss: 0.045993
 >> iter 57000, loss: 0.066527
 >> iter 58000, loss: 0.044106
 >> iter 59000, loss: 0.041185
 >> iter 60000, loss: 0.057011
   Number of active neurons: 3
 >> iter 61000, loss: 0.057099
 >> iter 62000, loss: 0.049033
 >> iter 63000, loss: 0.048329
 >> iter 64000, loss: 0.048378
 >> iter 65000, loss: 0.037472
 >> iter 66000, loss: 0.066043
 >> iter 67000, loss: 0.048483
 >> iter 68000, loss: 0.039354
 >> iter 69000, loss: 0.054288
 >> iter 70000, loss: 0.040990
   Number of active neurons: 3
 >> iter 71000, loss: 0.035559
 >> iter 72000, loss: 0.041938
 >> iter 73000, loss: 0.042785
 >> iter 74000, loss: 0.054121
 >> iter 75000, loss: 0.053597
 >> iter 76000, loss: 0.048099
 >> iter 77000, loss: 0.047838
 >> iter 78000, loss: 0.042667
 >> iter 79000, loss: 0.040087
 >> iter 80000, loss: 0.046434
   Number of active neurons: 3
 >> iter 81000, loss: 0.049869
 >> iter 82000, loss: 0.050953
 >> iter 83000, loss: 0.046863
 >> iter 84000, loss: 0.043532
 >> iter 85000, loss: 0.042048
 >> iter 86000, loss: 0.036021
 >> iter 87000, loss: 0.038657
 >> iter 88000, loss: 0.037623
 >> iter 89000, loss: 0.029076
 >> iter 90000, loss: 0.029000
   Number of active neurons: 3
 >> iter 91000, loss: 0.039189
 >> iter 92000, loss: 0.028924
 >> iter 93000, loss: 0.034505
 >> iter 94000, loss: 0.044382
 >> iter 95000, loss: 0.036317
 >> iter 96000, loss: 0.062005
 >> iter 97000, loss: 0.056717
 >> iter 98000, loss: 0.051041
 >> iter 99000, loss: 0.047455
 >> iter 100000, loss: 0.051124
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.314408
 >> iter 2000, loss: 4.458620
 >> iter 3000, loss: 1.785462
 >> iter 4000, loss: 0.774767
 >> iter 5000, loss: 0.337949
 >> iter 6000, loss: 0.197115
 >> iter 7000, loss: 0.115871
 >> iter 8000, loss: 0.097103
 >> iter 9000, loss: 0.080372
 >> iter 10000, loss: 0.077494
   Number of active neurons: 8
 >> iter 11000, loss: 0.063589
 >> iter 12000, loss: 0.056902
 >> iter 13000, loss: 0.092418
 >> iter 14000, loss: 0.094897
 >> iter 15000, loss: 0.093394
 >> iter 16000, loss: 0.080972
 >> iter 17000, loss: 0.080692
 >> iter 18000, loss: 0.070461
 >> iter 19000, loss: 0.061095
 >> iter 20000, loss: 0.058399
   Number of active neurons: 5
 >> iter 21000, loss: 0.073798
 >> iter 22000, loss: 0.072815
 >> iter 23000, loss: 0.055231
 >> iter 24000, loss: 0.048410
 >> iter 25000, loss: 0.047674
 >> iter 26000, loss: 0.047708
 >> iter 27000, loss: 0.059945
 >> iter 28000, loss: 0.045577
 >> iter 29000, loss: 0.063838
 >> iter 30000, loss: 0.054188
   Number of active neurons: 4
 >> iter 31000, loss: 0.050506
 >> iter 32000, loss: 0.042523
 >> iter 33000, loss: 0.035645
 >> iter 34000, loss: 0.041221
 >> iter 35000, loss: 0.047612
 >> iter 36000, loss: 0.048416
 >> iter 37000, loss: 0.060533
 >> iter 38000, loss: 0.078805
 >> iter 39000, loss: 0.063886
 >> iter 40000, loss: 0.049440
   Number of active neurons: 4
 >> iter 41000, loss: 0.059960
 >> iter 42000, loss: 0.050449
 >> iter 43000, loss: 0.054103
 >> iter 44000, loss: 0.053943
 >> iter 45000, loss: 0.068451
 >> iter 46000, loss: 0.049926
 >> iter 47000, loss: 0.036481
 >> iter 48000, loss: 0.061153
 >> iter 49000, loss: 0.051904
 >> iter 50000, loss: 0.060436
   Number of active neurons: 4
 >> iter 51000, loss: 0.054452
 >> iter 52000, loss: 0.055823
 >> iter 53000, loss: 0.042526
 >> iter 54000, loss: 0.043012
 >> iter 55000, loss: 0.053715
 >> iter 56000, loss: 0.073475
 >> iter 57000, loss: 0.072336
 >> iter 58000, loss: 0.062123
 >> iter 59000, loss: 0.046193
 >> iter 60000, loss: 0.045130
   Number of active neurons: 4
 >> iter 61000, loss: 0.042150
 >> iter 62000, loss: 0.055290
 >> iter 63000, loss: 0.042608
 >> iter 64000, loss: 0.042723
 >> iter 65000, loss: 0.049589
 >> iter 66000, loss: 0.052369
 >> iter 67000, loss: 0.043799
 >> iter 68000, loss: 0.051536
 >> iter 69000, loss: 0.043138
 >> iter 70000, loss: 0.059089
   Number of active neurons: 4
 >> iter 71000, loss: 0.044539
 >> iter 72000, loss: 0.058042
 >> iter 73000, loss: 0.042758
 >> iter 74000, loss: 0.035329
 >> iter 75000, loss: 0.037462
 >> iter 76000, loss: 0.034736
 >> iter 77000, loss: 0.033075
 >> iter 78000, loss: 0.047388
 >> iter 79000, loss: 0.046583
 >> iter 80000, loss: 0.034627
   Number of active neurons: 4
 >> iter 81000, loss: 0.044304
 >> iter 82000, loss: 0.045809
 >> iter 83000, loss: 0.055948
 >> iter 84000, loss: 0.055143
 >> iter 85000, loss: 0.060693
 >> iter 86000, loss: 0.051944
 >> iter 87000, loss: 0.035670
 >> iter 88000, loss: 0.041797
 >> iter 89000, loss: 0.053459
 >> iter 90000, loss: 0.065571
   Number of active neurons: 3
 >> iter 91000, loss: 0.047710
 >> iter 92000, loss: 0.083398
 >> iter 93000, loss: 0.051870
 >> iter 94000, loss: 0.045686
 >> iter 95000, loss: 0.038521
 >> iter 96000, loss: 0.039682
 >> iter 97000, loss: 0.051029
 >> iter 98000, loss: 0.054612
 >> iter 99000, loss: 0.037183
 >> iter 100000, loss: 0.043044
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.396964
 >> iter 2000, loss: 4.480569
 >> iter 3000, loss: 1.790994
 >> iter 4000, loss: 0.768906
 >> iter 5000, loss: 0.395423
 >> iter 6000, loss: 0.207720
 >> iter 7000, loss: 0.151572
 >> iter 8000, loss: 0.125833
 >> iter 9000, loss: 0.089815
 >> iter 10000, loss: 0.090763
   Number of active neurons: 10
 >> iter 11000, loss: 0.083519
 >> iter 12000, loss: 0.088969
 >> iter 13000, loss: 0.106715
 >> iter 14000, loss: 0.094139
 >> iter 15000, loss: 0.083989
 >> iter 16000, loss: 0.077876
 >> iter 17000, loss: 0.068935
 >> iter 18000, loss: 0.066557
 >> iter 19000, loss: 0.075498
 >> iter 20000, loss: 0.060475
   Number of active neurons: 10
 >> iter 21000, loss: 0.101091
 >> iter 22000, loss: 0.071545
 >> iter 23000, loss: 0.050526
 >> iter 24000, loss: 0.057637
 >> iter 25000, loss: 0.069929
 >> iter 26000, loss: 0.055922
 >> iter 27000, loss: 0.067843
 >> iter 28000, loss: 0.054642
 >> iter 29000, loss: 0.046988
 >> iter 30000, loss: 0.046745
   Number of active neurons: 7
 >> iter 31000, loss: 0.044293
 >> iter 32000, loss: 0.041584
 >> iter 33000, loss: 0.038361
 >> iter 34000, loss: 0.045570
 >> iter 35000, loss: 0.051629
 >> iter 36000, loss: 0.041289
 >> iter 37000, loss: 0.045472
 >> iter 38000, loss: 0.048672
 >> iter 39000, loss: 0.046089
 >> iter 40000, loss: 0.063653
   Number of active neurons: 4
 >> iter 41000, loss: 0.103459
 >> iter 42000, loss: 0.055200
 >> iter 43000, loss: 0.058849
 >> iter 44000, loss: 0.052818
 >> iter 45000, loss: 0.045444
 >> iter 46000, loss: 0.036044
 >> iter 47000, loss: 0.032277
 >> iter 48000, loss: 0.035734
 >> iter 49000, loss: 0.047553
 >> iter 50000, loss: 0.039620
   Number of active neurons: 3
 >> iter 51000, loss: 0.058906
 >> iter 52000, loss: 0.037671
 >> iter 53000, loss: 0.038571
 >> iter 54000, loss: 0.031104
 >> iter 55000, loss: 0.053551
 >> iter 56000, loss: 0.045660
 >> iter 57000, loss: 0.069234
 >> iter 58000, loss: 0.047403
 >> iter 59000, loss: 0.044299
 >> iter 60000, loss: 0.050977
   Number of active neurons: 3
 >> iter 61000, loss: 0.039887
 >> iter 62000, loss: 0.034590
 >> iter 63000, loss: 0.044439
 >> iter 64000, loss: 0.034675
 >> iter 65000, loss: 0.035728
 >> iter 66000, loss: 0.038794
 >> iter 67000, loss: 0.035751
 >> iter 68000, loss: 0.044294
 >> iter 69000, loss: 0.060977
 >> iter 70000, loss: 0.051797
   Number of active neurons: 3
 >> iter 71000, loss: 0.058862
 >> iter 72000, loss: 0.044825
 >> iter 73000, loss: 0.047819
 >> iter 74000, loss: 0.053776
 >> iter 75000, loss: 0.046799
 >> iter 76000, loss: 0.056479
 >> iter 77000, loss: 0.055945
 >> iter 78000, loss: 0.055637
 >> iter 79000, loss: 0.053829
 >> iter 80000, loss: 0.036740
   Number of active neurons: 3
 >> iter 81000, loss: 0.048239
 >> iter 82000, loss: 0.038936
 >> iter 83000, loss: 0.039182
 >> iter 84000, loss: 0.032943
 >> iter 85000, loss: 0.035065
 >> iter 86000, loss: 0.041516
 >> iter 87000, loss: 0.043833
 >> iter 88000, loss: 0.055330
 >> iter 89000, loss: 0.064030
 >> iter 90000, loss: 0.062224
   Number of active neurons: 3
 >> iter 91000, loss: 0.067801
 >> iter 92000, loss: 0.067219
 >> iter 93000, loss: 0.056960
 >> iter 94000, loss: 0.055563
 >> iter 95000, loss: 0.049635
 >> iter 96000, loss: 0.066974
 >> iter 97000, loss: 0.050185
 >> iter 98000, loss: 0.047396
 >> iter 99000, loss: 0.041984
 >> iter 100000, loss: 0.038813
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.332330
 >> iter 2000, loss: 4.425374
 >> iter 3000, loss: 1.727055
 >> iter 4000, loss: 0.722026
 >> iter 5000, loss: 0.342345
 >> iter 6000, loss: 0.195914
 >> iter 7000, loss: 0.117090
 >> iter 8000, loss: 0.102024
 >> iter 9000, loss: 0.084489
 >> iter 10000, loss: 0.069320
   Number of active neurons: 8
 >> iter 11000, loss: 0.085234
 >> iter 12000, loss: 0.086905
 >> iter 13000, loss: 0.070425
 >> iter 14000, loss: 0.048661
 >> iter 15000, loss: 0.056213
 >> iter 16000, loss: 0.047166
 >> iter 17000, loss: 0.067290
 >> iter 18000, loss: 0.061376
 >> iter 19000, loss: 0.055055
 >> iter 20000, loss: 0.041421
   Number of active neurons: 6
 >> iter 21000, loss: 0.049556
 >> iter 22000, loss: 0.047273
 >> iter 23000, loss: 0.061292
 >> iter 24000, loss: 0.064066
 >> iter 25000, loss: 0.064393
 >> iter 26000, loss: 0.079051
 >> iter 27000, loss: 0.062411
 >> iter 28000, loss: 0.058458
 >> iter 29000, loss: 0.057037
 >> iter 30000, loss: 0.059275
   Number of active neurons: 5
 >> iter 31000, loss: 0.062341
 >> iter 32000, loss: 0.059254
 >> iter 33000, loss: 0.051112
 >> iter 34000, loss: 0.053114
 >> iter 35000, loss: 0.038846
 >> iter 36000, loss: 0.030830
 >> iter 37000, loss: 0.042381
 >> iter 38000, loss: 0.038852
 >> iter 39000, loss: 0.055841
 >> iter 40000, loss: 0.045948
   Number of active neurons: 5
 >> iter 41000, loss: 0.040157
 >> iter 42000, loss: 0.060512
 >> iter 43000, loss: 0.072404
 >> iter 44000, loss: 0.064876
 >> iter 45000, loss: 0.049804
 >> iter 46000, loss: 0.041648
 >> iter 47000, loss: 0.041203
 >> iter 48000, loss: 0.068132
 >> iter 49000, loss: 0.046870
 >> iter 50000, loss: 0.043705
   Number of active neurons: 5
 >> iter 51000, loss: 0.041343
 >> iter 52000, loss: 0.059073
 >> iter 53000, loss: 0.048850
 >> iter 54000, loss: 0.040149
 >> iter 55000, loss: 0.050161
 >> iter 56000, loss: 0.066333
 >> iter 57000, loss: 0.052364
 >> iter 58000, loss: 0.068870
 >> iter 59000, loss: 0.061184
 >> iter 60000, loss: 0.060543
   Number of active neurons: 4
 >> iter 61000, loss: 0.044391
 >> iter 62000, loss: 0.036149
 >> iter 63000, loss: 0.046805
 >> iter 64000, loss: 0.048410
 >> iter 65000, loss: 0.044333
 >> iter 66000, loss: 0.046222
 >> iter 67000, loss: 0.061147
 >> iter 68000, loss: 0.067518
 >> iter 69000, loss: 0.063298
 >> iter 70000, loss: 0.040313
   Number of active neurons: 4
 >> iter 71000, loss: 0.048651
 >> iter 72000, loss: 0.032764
 >> iter 73000, loss: 0.041931
 >> iter 74000, loss: 0.037957
 >> iter 75000, loss: 0.065634
 >> iter 76000, loss: 0.060404
 >> iter 77000, loss: 0.057392
 >> iter 78000, loss: 0.071545
 >> iter 79000, loss: 0.055530
 >> iter 80000, loss: 0.039851
   Number of active neurons: 4
 >> iter 81000, loss: 0.036406
 >> iter 82000, loss: 0.047511
 >> iter 83000, loss: 0.060998
 >> iter 84000, loss: 0.062325
 >> iter 85000, loss: 0.048448
 >> iter 86000, loss: 0.065079
 >> iter 87000, loss: 0.067496
 >> iter 88000, loss: 0.055987
 >> iter 89000, loss: 0.050395
 >> iter 90000, loss: 0.045764
   Number of active neurons: 4
 >> iter 91000, loss: 0.037442
 >> iter 92000, loss: 0.048889
 >> iter 93000, loss: 0.044797
 >> iter 94000, loss: 0.035386
 >> iter 95000, loss: 0.038206
 >> iter 96000, loss: 0.049064
 >> iter 97000, loss: 0.059053
 >> iter 98000, loss: 0.052912
 >> iter 99000, loss: 0.040526
 >> iter 100000, loss: 0.047898
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.370459
 >> iter 2000, loss: 4.468759
 >> iter 3000, loss: 1.797837
 >> iter 4000, loss: 0.776089
 >> iter 5000, loss: 0.355123
 >> iter 6000, loss: 0.191348
 >> iter 7000, loss: 0.147724
 >> iter 8000, loss: 0.097914
 >> iter 9000, loss: 0.074142
 >> iter 10000, loss: 0.082850
   Number of active neurons: 9
 >> iter 11000, loss: 0.071780
 >> iter 12000, loss: 0.049584
 >> iter 13000, loss: 0.090292
 >> iter 14000, loss: 0.091494
 >> iter 15000, loss: 0.077226
 >> iter 16000, loss: 0.072853
 >> iter 17000, loss: 0.085386
 >> iter 18000, loss: 0.085412
 >> iter 19000, loss: 0.072765
 >> iter 20000, loss: 0.068372
   Number of active neurons: 6
 >> iter 21000, loss: 0.053541
 >> iter 22000, loss: 0.056188
 >> iter 23000, loss: 0.042998
 >> iter 24000, loss: 0.043716
 >> iter 25000, loss: 0.047607
 >> iter 26000, loss: 0.051318
 >> iter 27000, loss: 0.063304
 >> iter 28000, loss: 0.070229
 >> iter 29000, loss: 0.048766
 >> iter 30000, loss: 0.051560
   Number of active neurons: 4
 >> iter 31000, loss: 0.042631
 >> iter 32000, loss: 0.062942
 >> iter 33000, loss: 0.052480
 >> iter 34000, loss: 0.053574
 >> iter 35000, loss: 0.053225
 >> iter 36000, loss: 0.079089
 >> iter 37000, loss: 0.084434
 >> iter 38000, loss: 0.068631
 >> iter 39000, loss: 0.054346
 >> iter 40000, loss: 0.049625
   Number of active neurons: 4
 >> iter 41000, loss: 0.045266
 >> iter 42000, loss: 0.047848
 >> iter 43000, loss: 0.042687
 >> iter 44000, loss: 0.057736
 >> iter 45000, loss: 0.065016
 >> iter 46000, loss: 0.048440
 >> iter 47000, loss: 0.065134
 >> iter 48000, loss: 0.059183
 >> iter 49000, loss: 0.050587
 >> iter 50000, loss: 0.050987
   Number of active neurons: 4
 >> iter 51000, loss: 0.053396
 >> iter 52000, loss: 0.049504
 >> iter 53000, loss: 0.047790
 >> iter 54000, loss: 0.048749
 >> iter 55000, loss: 0.047463
 >> iter 56000, loss: 0.056347
 >> iter 57000, loss: 0.056560
 >> iter 58000, loss: 0.048336
 >> iter 59000, loss: 0.047081
 >> iter 60000, loss: 0.047122
   Number of active neurons: 4
 >> iter 61000, loss: 0.041073
 >> iter 62000, loss: 0.045411
 >> iter 63000, loss: 0.044415
 >> iter 64000, loss: 0.044683
 >> iter 65000, loss: 0.041172
 >> iter 66000, loss: 0.049899
 >> iter 67000, loss: 0.048036
 >> iter 68000, loss: 0.039926
 >> iter 69000, loss: 0.041457
 >> iter 70000, loss: 0.042867
   Number of active neurons: 3
 >> iter 71000, loss: 0.036577
 >> iter 72000, loss: 0.040233
 >> iter 73000, loss: 0.050438
 >> iter 74000, loss: 0.043868
 >> iter 75000, loss: 0.055484
 >> iter 76000, loss: 0.057351
 >> iter 77000, loss: 0.042830
 >> iter 78000, loss: 0.048718
 >> iter 79000, loss: 0.043385
 >> iter 80000, loss: 0.040735
   Number of active neurons: 3
 >> iter 81000, loss: 0.058834
 >> iter 82000, loss: 0.047025
 >> iter 83000, loss: 0.036897
 >> iter 84000, loss: 0.039452
 >> iter 85000, loss: 0.038860
 >> iter 86000, loss: 0.041865
 >> iter 87000, loss: 0.034548
 >> iter 88000, loss: 0.054958
 >> iter 89000, loss: 0.051693
 >> iter 90000, loss: 0.065023
   Number of active neurons: 3
 >> iter 91000, loss: 0.049918
 >> iter 92000, loss: 0.046094
 >> iter 93000, loss: 0.040829
 >> iter 94000, loss: 0.038636
 >> iter 95000, loss: 0.039522
 >> iter 96000, loss: 0.050374
 >> iter 97000, loss: 0.039816
 >> iter 98000, loss: 0.031673
 >> iter 99000, loss: 0.042334
 >> iter 100000, loss: 0.050378
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.356677
 >> iter 2000, loss: 4.449002
 >> iter 3000, loss: 1.766985
 >> iter 4000, loss: 0.735535
 >> iter 5000, loss: 0.351648
 >> iter 6000, loss: 0.191597
 >> iter 7000, loss: 0.140449
 >> iter 8000, loss: 0.099648
 >> iter 9000, loss: 0.106311
 >> iter 10000, loss: 0.079646
   Number of active neurons: 8
 >> iter 11000, loss: 0.078799
 >> iter 12000, loss: 0.078463
 >> iter 13000, loss: 0.085242
 >> iter 14000, loss: 0.063256
 >> iter 15000, loss: 0.060947
 >> iter 16000, loss: 0.064310
 >> iter 17000, loss: 0.079574
 >> iter 18000, loss: 0.059940
 >> iter 19000, loss: 0.051836
 >> iter 20000, loss: 0.060297
   Number of active neurons: 8
 >> iter 21000, loss: 0.061315
 >> iter 22000, loss: 0.070525
 >> iter 23000, loss: 0.066937
 >> iter 24000, loss: 0.071197
 >> iter 25000, loss: 0.074631
 >> iter 26000, loss: 0.046384
 >> iter 27000, loss: 0.054541
 >> iter 28000, loss: 0.043861
 >> iter 29000, loss: 0.050795
 >> iter 30000, loss: 0.045201
   Number of active neurons: 6
 >> iter 31000, loss: 0.057621
 >> iter 32000, loss: 0.043024
 >> iter 33000, loss: 0.043226
 >> iter 34000, loss: 0.067347
 >> iter 35000, loss: 0.060286
 >> iter 36000, loss: 0.050047
 >> iter 37000, loss: 0.039260
 >> iter 38000, loss: 0.047320
 >> iter 39000, loss: 0.043406
 >> iter 40000, loss: 0.065221
   Number of active neurons: 5
 >> iter 41000, loss: 0.081759
 >> iter 42000, loss: 0.061794
 >> iter 43000, loss: 0.052357
 >> iter 44000, loss: 0.053917
 >> iter 45000, loss: 0.049562
 >> iter 46000, loss: 0.037169
 >> iter 47000, loss: 0.034938
 >> iter 48000, loss: 0.046446
 >> iter 49000, loss: 0.042024
 >> iter 50000, loss: 0.037052
   Number of active neurons: 5
 >> iter 51000, loss: 0.042153
 >> iter 52000, loss: 0.041552
 >> iter 53000, loss: 0.043942
 >> iter 54000, loss: 0.046480
 >> iter 55000, loss: 0.044044
 >> iter 56000, loss: 0.035292
 >> iter 57000, loss: 0.043071
 >> iter 58000, loss: 0.043275
 >> iter 59000, loss: 0.043427
 >> iter 60000, loss: 0.055601
   Number of active neurons: 4
 >> iter 61000, loss: 0.040999
 >> iter 62000, loss: 0.036644
 >> iter 63000, loss: 0.043743
 >> iter 64000, loss: 0.043012
 >> iter 65000, loss: 0.063369
 >> iter 66000, loss: 0.055051
 >> iter 67000, loss: 0.052860
 >> iter 68000, loss: 0.059602
 >> iter 69000, loss: 0.054311
 >> iter 70000, loss: 0.055335
   Number of active neurons: 4
 >> iter 71000, loss: 0.044573
 >> iter 72000, loss: 0.031812
 >> iter 73000, loss: 0.032692
 >> iter 74000, loss: 0.046103
 >> iter 75000, loss: 0.038501
 >> iter 76000, loss: 0.044649
 >> iter 77000, loss: 0.041851
 >> iter 78000, loss: 0.057738
 >> iter 79000, loss: 0.046684
 >> iter 80000, loss: 0.040925
   Number of active neurons: 4
 >> iter 81000, loss: 0.039218
 >> iter 82000, loss: 0.044140
 >> iter 83000, loss: 0.050785
 >> iter 84000, loss: 0.038500
 >> iter 85000, loss: 0.044663
 >> iter 86000, loss: 0.045918
 >> iter 87000, loss: 0.047135
 >> iter 88000, loss: 0.041541
 >> iter 89000, loss: 0.030499
 >> iter 90000, loss: 0.048611
   Number of active neurons: 3
 >> iter 91000, loss: 0.031412
 >> iter 92000, loss: 0.054212
 >> iter 93000, loss: 0.043962
 >> iter 94000, loss: 0.049395
 >> iter 95000, loss: 0.046913
 >> iter 96000, loss: 0.049501
 >> iter 97000, loss: 0.035705
 >> iter 98000, loss: 0.043915
 >> iter 99000, loss: 0.034077
 >> iter 100000, loss: 0.044898
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455186
   Number of active neurons: 0
 >> iter 1000, loss: 11.345331
 >> iter 2000, loss: 4.460513
 >> iter 3000, loss: 1.799822
 >> iter 4000, loss: 0.771731
 >> iter 5000, loss: 0.356426
 >> iter 6000, loss: 0.206584
 >> iter 7000, loss: 0.132932
 >> iter 8000, loss: 0.089011
 >> iter 9000, loss: 0.106081
 >> iter 10000, loss: 0.098712
   Number of active neurons: 9
 >> iter 11000, loss: 0.084740
 >> iter 12000, loss: 0.091747
 >> iter 13000, loss: 0.086285
 >> iter 14000, loss: 0.066284
 >> iter 15000, loss: 0.071503
 >> iter 16000, loss: 0.079267
 >> iter 17000, loss: 0.072403
 >> iter 18000, loss: 0.070599
 >> iter 19000, loss: 0.074119
 >> iter 20000, loss: 0.057396
   Number of active neurons: 7
 >> iter 21000, loss: 0.051958
 >> iter 22000, loss: 0.047240
 >> iter 23000, loss: 0.066651
 >> iter 24000, loss: 0.057272
 >> iter 25000, loss: 0.065075
 >> iter 26000, loss: 0.049373
 >> iter 27000, loss: 0.038219
 >> iter 28000, loss: 0.054850
 >> iter 29000, loss: 0.079874
 >> iter 30000, loss: 0.054627
   Number of active neurons: 6
 >> iter 31000, loss: 0.043301
 >> iter 32000, loss: 0.053335
 >> iter 33000, loss: 0.075797
 >> iter 34000, loss: 0.052703
 >> iter 35000, loss: 0.051095
 >> iter 36000, loss: 0.040453
 >> iter 37000, loss: 0.055866
 >> iter 38000, loss: 0.042646
 >> iter 39000, loss: 0.038146
 >> iter 40000, loss: 0.056460
   Number of active neurons: 6
 >> iter 41000, loss: 0.056782
 >> iter 42000, loss: 0.057810
 >> iter 43000, loss: 0.070728
 >> iter 44000, loss: 0.071879
 >> iter 45000, loss: 0.048491
 >> iter 46000, loss: 0.057377
 >> iter 47000, loss: 0.060671
 >> iter 48000, loss: 0.054642
 >> iter 49000, loss: 0.048743
 >> iter 50000, loss: 0.052526
   Number of active neurons: 6
 >> iter 51000, loss: 0.041448
 >> iter 52000, loss: 0.041590
 >> iter 53000, loss: 0.038714
 >> iter 54000, loss: 0.054367
 >> iter 55000, loss: 0.052465
 >> iter 56000, loss: 0.048528
 >> iter 57000, loss: 0.054975
 >> iter 58000, loss: 0.057655
 >> iter 59000, loss: 0.043799
 >> iter 60000, loss: 0.033198
   Number of active neurons: 4
 >> iter 61000, loss: 0.057329
 >> iter 62000, loss: 0.053800
 >> iter 63000, loss: 0.043258
 >> iter 64000, loss: 0.048853
 >> iter 65000, loss: 0.057050
 >> iter 66000, loss: 0.042642
 >> iter 67000, loss: 0.043764
 >> iter 68000, loss: 0.036551
 >> iter 69000, loss: 0.032687
 >> iter 70000, loss: 0.067327
   Number of active neurons: 4
 >> iter 71000, loss: 0.058076
 >> iter 72000, loss: 0.043133
 >> iter 73000, loss: 0.042832
 >> iter 74000, loss: 0.061848
 >> iter 75000, loss: 0.067286
 >> iter 76000, loss: 0.056969
 >> iter 77000, loss: 0.057429
 >> iter 78000, loss: 0.052017
 >> iter 79000, loss: 0.049388
 >> iter 80000, loss: 0.051627
   Number of active neurons: 4
 >> iter 81000, loss: 0.038258
 >> iter 82000, loss: 0.042290
 >> iter 83000, loss: 0.055655
 >> iter 84000, loss: 0.072248
 >> iter 85000, loss: 0.063920
 >> iter 86000, loss: 0.070329
 >> iter 87000, loss: 0.070007
 >> iter 88000, loss: 0.046540
 >> iter 89000, loss: 0.050162
 >> iter 90000, loss: 0.044222
   Number of active neurons: 4
 >> iter 91000, loss: 0.041431
 >> iter 92000, loss: 0.034016
 >> iter 93000, loss: 0.044839
 >> iter 94000, loss: 0.061463
 >> iter 95000, loss: 0.061435
 >> iter 96000, loss: 0.053728
 >> iter 97000, loss: 0.041772
 >> iter 98000, loss: 0.032851
 >> iter 99000, loss: 0.042266
 >> iter 100000, loss: 0.041762
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.344682
 >> iter 2000, loss: 4.450185
 >> iter 3000, loss: 1.771259
 >> iter 4000, loss: 0.754424
 >> iter 5000, loss: 0.362324
 >> iter 6000, loss: 0.210086
 >> iter 7000, loss: 0.142632
 >> iter 8000, loss: 0.095565
 >> iter 9000, loss: 0.102657
 >> iter 10000, loss: 0.093153
   Number of active neurons: 10
 >> iter 11000, loss: 0.092059
 >> iter 12000, loss: 0.071619
 >> iter 13000, loss: 0.083613
 >> iter 14000, loss: 0.085125
 >> iter 15000, loss: 0.076177
 >> iter 16000, loss: 0.082271
 >> iter 17000, loss: 0.063170
 >> iter 18000, loss: 0.074006
 >> iter 19000, loss: 0.085535
 >> iter 20000, loss: 0.072428
   Number of active neurons: 7
 >> iter 21000, loss: 0.064749
 >> iter 22000, loss: 0.058373
 >> iter 23000, loss: 0.056382
 >> iter 24000, loss: 0.054855
 >> iter 25000, loss: 0.048923
 >> iter 26000, loss: 0.062285
 >> iter 27000, loss: 0.066541
 >> iter 28000, loss: 0.068704
 >> iter 29000, loss: 0.064256
 >> iter 30000, loss: 0.052725
   Number of active neurons: 7
 >> iter 31000, loss: 0.066323
 >> iter 32000, loss: 0.052707
 >> iter 33000, loss: 0.057904
 >> iter 34000, loss: 0.052777
 >> iter 35000, loss: 0.050483
 >> iter 36000, loss: 0.047543
 >> iter 37000, loss: 0.055648
 >> iter 38000, loss: 0.053379
 >> iter 39000, loss: 0.104999
 >> iter 40000, loss: 0.071523
   Number of active neurons: 4
 >> iter 41000, loss: 0.063080
 >> iter 42000, loss: 0.061545
 >> iter 43000, loss: 0.062928
 >> iter 44000, loss: 0.053747
 >> iter 45000, loss: 0.066085
 >> iter 46000, loss: 0.055102
 >> iter 47000, loss: 0.056156
 >> iter 48000, loss: 0.044349
 >> iter 49000, loss: 0.050054
 >> iter 50000, loss: 0.049093
   Number of active neurons: 4
 >> iter 51000, loss: 0.043924
 >> iter 52000, loss: 0.053586
 >> iter 53000, loss: 0.048675
 >> iter 54000, loss: 0.035883
 >> iter 55000, loss: 0.053024
 >> iter 56000, loss: 0.051284
 >> iter 57000, loss: 0.054972
 >> iter 58000, loss: 0.059867
 >> iter 59000, loss: 0.041946
 >> iter 60000, loss: 0.046950
   Number of active neurons: 3
 >> iter 61000, loss: 0.044425
 >> iter 62000, loss: 0.039008
 >> iter 63000, loss: 0.045869
 >> iter 64000, loss: 0.048930
 >> iter 65000, loss: 0.040805
 >> iter 66000, loss: 0.055588
 >> iter 67000, loss: 0.069827
 >> iter 68000, loss: 0.050386
 >> iter 69000, loss: 0.042341
 >> iter 70000, loss: 0.051601
   Number of active neurons: 2
 >> iter 71000, loss: 0.038520
 >> iter 72000, loss: 0.034043
 >> iter 73000, loss: 0.038831
 >> iter 74000, loss: 0.038141
 >> iter 75000, loss: 0.065051
 >> iter 76000, loss: 0.048540
 >> iter 77000, loss: 0.042602
 >> iter 78000, loss: 0.041519
 >> iter 79000, loss: 0.045049
 >> iter 80000, loss: 0.045447
   Number of active neurons: 2
 >> iter 81000, loss: 0.046315
 >> iter 82000, loss: 0.054001
 >> iter 83000, loss: 0.057311
 >> iter 84000, loss: 0.061912
 >> iter 85000, loss: 0.051434
 >> iter 86000, loss: 0.049483
 >> iter 87000, loss: 0.046263
 >> iter 88000, loss: 0.041978
 >> iter 89000, loss: 0.054582
 >> iter 90000, loss: 0.068287
   Number of active neurons: 2
 >> iter 91000, loss: 0.047536
 >> iter 92000, loss: 0.035060
 >> iter 93000, loss: 0.031107
 >> iter 94000, loss: 0.030589
 >> iter 95000, loss: 0.028232
 >> iter 96000, loss: 0.035581
 >> iter 97000, loss: 0.038127
 >> iter 98000, loss: 0.061046
 >> iter 99000, loss: 0.055581
 >> iter 100000, loss: 0.061506
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.338461
 >> iter 2000, loss: 4.484051
 >> iter 3000, loss: 1.792301
 >> iter 4000, loss: 0.757438
 >> iter 5000, loss: 0.385846
 >> iter 6000, loss: 0.199252
 >> iter 7000, loss: 0.139371
 >> iter 8000, loss: 0.106937
 >> iter 9000, loss: 0.113625
 >> iter 10000, loss: 0.085925
   Number of active neurons: 9
 >> iter 11000, loss: 0.081831
 >> iter 12000, loss: 0.075181
 >> iter 13000, loss: 0.084428
 >> iter 14000, loss: 0.083878
 >> iter 15000, loss: 0.072651
 >> iter 16000, loss: 0.064846
 >> iter 17000, loss: 0.097923
 >> iter 18000, loss: 0.071619
 >> iter 19000, loss: 0.069369
 >> iter 20000, loss: 0.072768
   Number of active neurons: 8
 >> iter 21000, loss: 0.053284
 >> iter 22000, loss: 0.048613
 >> iter 23000, loss: 0.066108
 >> iter 24000, loss: 0.067052
 >> iter 25000, loss: 0.058093
 >> iter 26000, loss: 0.053639
 >> iter 27000, loss: 0.051533
 >> iter 28000, loss: 0.048696
 >> iter 29000, loss: 0.045391
 >> iter 30000, loss: 0.043573
   Number of active neurons: 7
 >> iter 31000, loss: 0.057863
 >> iter 32000, loss: 0.048148
 >> iter 33000, loss: 0.048378
 >> iter 34000, loss: 0.044651
 >> iter 35000, loss: 0.059670
 >> iter 36000, loss: 0.049925
 >> iter 37000, loss: 0.062876
 >> iter 38000, loss: 0.049212
 >> iter 39000, loss: 0.047044
 >> iter 40000, loss: 0.059656
   Number of active neurons: 6
 >> iter 41000, loss: 0.050752
 >> iter 42000, loss: 0.049804
 >> iter 43000, loss: 0.046835
 >> iter 44000, loss: 0.080216
 >> iter 45000, loss: 0.064527
 >> iter 46000, loss: 0.043900
 >> iter 47000, loss: 0.047890
 >> iter 48000, loss: 0.042747
 >> iter 49000, loss: 0.057584
 >> iter 50000, loss: 0.086592
   Number of active neurons: 6
 >> iter 51000, loss: 0.088321
 >> iter 52000, loss: 0.054802
 >> iter 53000, loss: 0.043062
 >> iter 54000, loss: 0.044966
 >> iter 55000, loss: 0.051428
 >> iter 56000, loss: 0.045606
 >> iter 57000, loss: 0.049649
 >> iter 58000, loss: 0.047572
 >> iter 59000, loss: 0.041516
 >> iter 60000, loss: 0.042234
   Number of active neurons: 4
 >> iter 61000, loss: 0.052218
 >> iter 62000, loss: 0.068279
 >> iter 63000, loss: 0.080405
 >> iter 64000, loss: 0.045040
 >> iter 65000, loss: 0.034581
 >> iter 66000, loss: 0.049694
 >> iter 67000, loss: 0.059735
 >> iter 68000, loss: 0.075815
 >> iter 69000, loss: 0.061133
 >> iter 70000, loss: 0.048358
   Number of active neurons: 4
 >> iter 71000, loss: 0.054931
 >> iter 72000, loss: 0.045418
 >> iter 73000, loss: 0.049545
 >> iter 74000, loss: 0.052418
 >> iter 75000, loss: 0.043796
 >> iter 76000, loss: 0.046815
 >> iter 77000, loss: 0.053215
 >> iter 78000, loss: 0.037724
 >> iter 79000, loss: 0.032989
 >> iter 80000, loss: 0.041331
   Number of active neurons: 4
 >> iter 81000, loss: 0.043850
 >> iter 82000, loss: 0.050114
 >> iter 83000, loss: 0.058831
 >> iter 84000, loss: 0.055267
 >> iter 85000, loss: 0.042567
 >> iter 86000, loss: 0.052610
 >> iter 87000, loss: 0.044342
 >> iter 88000, loss: 0.053637
 >> iter 89000, loss: 0.045566
 >> iter 90000, loss: 0.056672
   Number of active neurons: 4
 >> iter 91000, loss: 0.049202
 >> iter 92000, loss: 0.048317
 >> iter 93000, loss: 0.046886
 >> iter 94000, loss: 0.045999
 >> iter 95000, loss: 0.044815
 >> iter 96000, loss: 0.055811
 >> iter 97000, loss: 0.038535
 >> iter 98000, loss: 0.031367
 >> iter 99000, loss: 0.028066
 >> iter 100000, loss: 0.043792
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.315984
 >> iter 2000, loss: 4.435533
 >> iter 3000, loss: 1.755438
 >> iter 4000, loss: 0.723270
 >> iter 5000, loss: 0.332970
 >> iter 6000, loss: 0.183080
 >> iter 7000, loss: 0.137085
 >> iter 8000, loss: 0.095725
 >> iter 9000, loss: 0.103676
 >> iter 10000, loss: 0.095397
   Number of active neurons: 8
 >> iter 11000, loss: 0.073266
 >> iter 12000, loss: 0.058385
 >> iter 13000, loss: 0.064527
 >> iter 14000, loss: 0.062748
 >> iter 15000, loss: 0.064413
 >> iter 16000, loss: 0.046908
 >> iter 17000, loss: 0.073227
 >> iter 18000, loss: 0.061722
 >> iter 19000, loss: 0.070827
 >> iter 20000, loss: 0.065650
   Number of active neurons: 8
 >> iter 21000, loss: 0.075014
 >> iter 22000, loss: 0.084889
 >> iter 23000, loss: 0.076656
 >> iter 24000, loss: 0.074017
 >> iter 25000, loss: 0.056989
 >> iter 26000, loss: 0.051963
 >> iter 27000, loss: 0.049986
 >> iter 28000, loss: 0.062044
 >> iter 29000, loss: 0.047368
 >> iter 30000, loss: 0.050331
   Number of active neurons: 6
 >> iter 31000, loss: 0.058439
 >> iter 32000, loss: 0.065126
 >> iter 33000, loss: 0.065659
 >> iter 34000, loss: 0.044746
 >> iter 35000, loss: 0.048975
 >> iter 36000, loss: 0.049641
 >> iter 37000, loss: 0.047930
 >> iter 38000, loss: 0.066919
 >> iter 39000, loss: 0.060116
 >> iter 40000, loss: 0.056470
   Number of active neurons: 5
 >> iter 41000, loss: 0.044566
 >> iter 42000, loss: 0.057576
 >> iter 43000, loss: 0.044723
 >> iter 44000, loss: 0.040463
 >> iter 45000, loss: 0.045773
 >> iter 46000, loss: 0.055438
 >> iter 47000, loss: 0.045592
 >> iter 48000, loss: 0.038904
 >> iter 49000, loss: 0.049255
 >> iter 50000, loss: 0.041845
   Number of active neurons: 3
 >> iter 51000, loss: 0.038915
 >> iter 52000, loss: 0.068366
 >> iter 53000, loss: 0.054123
 >> iter 54000, loss: 0.065222
 >> iter 55000, loss: 0.073185
 >> iter 56000, loss: 0.055754
 >> iter 57000, loss: 0.054875
 >> iter 58000, loss: 0.036316
 >> iter 59000, loss: 0.044726
 >> iter 60000, loss: 0.042037
   Number of active neurons: 3
 >> iter 61000, loss: 0.046745
 >> iter 62000, loss: 0.036873
 >> iter 63000, loss: 0.042151
 >> iter 64000, loss: 0.052095
 >> iter 65000, loss: 0.054680
 >> iter 66000, loss: 0.064903
 >> iter 67000, loss: 0.043036
 >> iter 68000, loss: 0.034467
 >> iter 69000, loss: 0.033075
 >> iter 70000, loss: 0.040218
   Number of active neurons: 3
 >> iter 71000, loss: 0.057112
 >> iter 72000, loss: 0.072571
 >> iter 73000, loss: 0.039048
 >> iter 74000, loss: 0.035722
 >> iter 75000, loss: 0.029902
 >> iter 76000, loss: 0.038732
 >> iter 77000, loss: 0.043444
 >> iter 78000, loss: 0.057658
 >> iter 79000, loss: 0.052461
 >> iter 80000, loss: 0.044056
   Number of active neurons: 3
 >> iter 81000, loss: 0.033846
 >> iter 82000, loss: 0.046300
 >> iter 83000, loss: 0.052640
 >> iter 84000, loss: 0.045438
 >> iter 85000, loss: 0.040579
 >> iter 86000, loss: 0.041569
 >> iter 87000, loss: 0.053853
 >> iter 88000, loss: 0.055967
 >> iter 89000, loss: 0.035551
 >> iter 90000, loss: 0.048816
   Number of active neurons: 3
 >> iter 91000, loss: 0.045620
 >> iter 92000, loss: 0.030818
 >> iter 93000, loss: 0.052397
 >> iter 94000, loss: 0.036564
 >> iter 95000, loss: 0.035305
 >> iter 96000, loss: 0.027769
 >> iter 97000, loss: 0.036143
 >> iter 98000, loss: 0.053863
 >> iter 99000, loss: 0.039160
 >> iter 100000, loss: 0.039740
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.320271
 >> iter 2000, loss: 4.419799
 >> iter 3000, loss: 1.766185
 >> iter 4000, loss: 0.749983
 >> iter 5000, loss: 0.331877
 >> iter 6000, loss: 0.181706
 >> iter 7000, loss: 0.132238
 >> iter 8000, loss: 0.120338
 >> iter 9000, loss: 0.084146
 >> iter 10000, loss: 0.076016
   Number of active neurons: 8
 >> iter 11000, loss: 0.069435
 >> iter 12000, loss: 0.070948
 >> iter 13000, loss: 0.084291
 >> iter 14000, loss: 0.094969
 >> iter 15000, loss: 0.091188
 >> iter 16000, loss: 0.068455
 >> iter 17000, loss: 0.055505
 >> iter 18000, loss: 0.070485
 >> iter 19000, loss: 0.062656
 >> iter 20000, loss: 0.055962
   Number of active neurons: 8
 >> iter 21000, loss: 0.070691
 >> iter 22000, loss: 0.067214
 >> iter 23000, loss: 0.063015
 >> iter 24000, loss: 0.073167
 >> iter 25000, loss: 0.069591
 >> iter 26000, loss: 0.061951
 >> iter 27000, loss: 0.062095
 >> iter 28000, loss: 0.054987
 >> iter 29000, loss: 0.041791
 >> iter 30000, loss: 0.065370
   Number of active neurons: 7
 >> iter 31000, loss: 0.066903
 >> iter 32000, loss: 0.067547
 >> iter 33000, loss: 0.069018
 >> iter 34000, loss: 0.072147
 >> iter 35000, loss: 0.060959
 >> iter 36000, loss: 0.048281
 >> iter 37000, loss: 0.054167
 >> iter 38000, loss: 0.052501
 >> iter 39000, loss: 0.048832
 >> iter 40000, loss: 0.048481
   Number of active neurons: 5
 >> iter 41000, loss: 0.042378
 >> iter 42000, loss: 0.040301
 >> iter 43000, loss: 0.040009
 >> iter 44000, loss: 0.036587
 >> iter 45000, loss: 0.040966
 >> iter 46000, loss: 0.061622
 >> iter 47000, loss: 0.082622
 >> iter 48000, loss: 0.063132
 >> iter 49000, loss: 0.051609
 >> iter 50000, loss: 0.047095
   Number of active neurons: 4
 >> iter 51000, loss: 0.068795
 >> iter 52000, loss: 0.057537
 >> iter 53000, loss: 0.048583
 >> iter 54000, loss: 0.062255
 >> iter 55000, loss: 0.064884
 >> iter 56000, loss: 0.049738
 >> iter 57000, loss: 0.050416
 >> iter 58000, loss: 0.043378
 >> iter 59000, loss: 0.043375
 >> iter 60000, loss: 0.043579
   Number of active neurons: 4
 >> iter 61000, loss: 0.042812
 >> iter 62000, loss: 0.040732
 >> iter 63000, loss: 0.038491
 >> iter 64000, loss: 0.041268
 >> iter 65000, loss: 0.050736
 >> iter 66000, loss: 0.051150
 >> iter 67000, loss: 0.059683
 >> iter 68000, loss: 0.044827
 >> iter 69000, loss: 0.039362
 >> iter 70000, loss: 0.034643
   Number of active neurons: 4
 >> iter 71000, loss: 0.042553
 >> iter 72000, loss: 0.048025
 >> iter 73000, loss: 0.058107
 >> iter 74000, loss: 0.049260
 >> iter 75000, loss: 0.044636
 >> iter 76000, loss: 0.048360
 >> iter 77000, loss: 0.059593
 >> iter 78000, loss: 0.044835
 >> iter 79000, loss: 0.056219
 >> iter 80000, loss: 0.066034
   Number of active neurons: 4
 >> iter 81000, loss: 0.048750
 >> iter 82000, loss: 0.052578
 >> iter 83000, loss: 0.040700
 >> iter 84000, loss: 0.085065
 >> iter 85000, loss: 0.061904
 >> iter 86000, loss: 0.056870
 >> iter 87000, loss: 0.065837
 >> iter 88000, loss: 0.069799
 >> iter 89000, loss: 0.051406
 >> iter 90000, loss: 0.041131
   Number of active neurons: 4
 >> iter 91000, loss: 0.071348
 >> iter 92000, loss: 0.051722
 >> iter 93000, loss: 0.055284
 >> iter 94000, loss: 0.049062
 >> iter 95000, loss: 0.054033
 >> iter 96000, loss: 0.053202
 >> iter 97000, loss: 0.042032
 >> iter 98000, loss: 0.049441
 >> iter 99000, loss: 0.043443
 >> iter 100000, loss: 0.043439
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.334868
 >> iter 2000, loss: 4.457842
 >> iter 3000, loss: 1.749995
 >> iter 4000, loss: 0.713969
 >> iter 5000, loss: 0.325301
 >> iter 6000, loss: 0.176500
 >> iter 7000, loss: 0.123158
 >> iter 8000, loss: 0.107850
 >> iter 9000, loss: 0.072918
 >> iter 10000, loss: 0.079276
   Number of active neurons: 9
 >> iter 11000, loss: 0.063560
 >> iter 12000, loss: 0.062635
 >> iter 13000, loss: 0.072773
 >> iter 14000, loss: 0.086302
 >> iter 15000, loss: 0.062303
 >> iter 16000, loss: 0.057075
 >> iter 17000, loss: 0.063082
 >> iter 18000, loss: 0.062665
 >> iter 19000, loss: 0.071321
 >> iter 20000, loss: 0.065704
   Number of active neurons: 7
 >> iter 21000, loss: 0.077405
 >> iter 22000, loss: 0.070425
 >> iter 23000, loss: 0.053907
 >> iter 24000, loss: 0.056327
 >> iter 25000, loss: 0.064220
 >> iter 26000, loss: 0.061144
 >> iter 27000, loss: 0.054585
 >> iter 28000, loss: 0.050767
 >> iter 29000, loss: 0.048977
 >> iter 30000, loss: 0.054004
   Number of active neurons: 6
 >> iter 31000, loss: 0.065277
 >> iter 32000, loss: 0.083189
 >> iter 33000, loss: 0.084070
 >> iter 34000, loss: 0.066940
 >> iter 35000, loss: 0.066807
 >> iter 36000, loss: 0.063687
 >> iter 37000, loss: 0.055117
 >> iter 38000, loss: 0.063797
 >> iter 39000, loss: 0.046650
 >> iter 40000, loss: 0.060889
   Number of active neurons: 6
 >> iter 41000, loss: 0.048360
 >> iter 42000, loss: 0.053455
 >> iter 43000, loss: 0.067327
 >> iter 44000, loss: 0.058331
 >> iter 45000, loss: 0.066039
 >> iter 46000, loss: 0.053415
 >> iter 47000, loss: 0.066570
 >> iter 48000, loss: 0.054012
 >> iter 49000, loss: 0.043639
 >> iter 50000, loss: 0.056889
   Number of active neurons: 4
 >> iter 51000, loss: 0.052059
 >> iter 52000, loss: 0.052009
 >> iter 53000, loss: 0.050188
 >> iter 54000, loss: 0.044550
 >> iter 55000, loss: 0.045730
 >> iter 56000, loss: 0.053261
 >> iter 57000, loss: 0.048987
 >> iter 58000, loss: 0.038087
 >> iter 59000, loss: 0.039487
 >> iter 60000, loss: 0.038085
   Number of active neurons: 4
 >> iter 61000, loss: 0.042628
 >> iter 62000, loss: 0.059132
 >> iter 63000, loss: 0.049025
 >> iter 64000, loss: 0.047514
 >> iter 65000, loss: 0.073589
 >> iter 66000, loss: 0.048257
 >> iter 67000, loss: 0.037101
 >> iter 68000, loss: 0.043847
 >> iter 69000, loss: 0.052951
 >> iter 70000, loss: 0.050333
   Number of active neurons: 4
 >> iter 71000, loss: 0.041967
 >> iter 72000, loss: 0.031284
 >> iter 73000, loss: 0.045958
 >> iter 74000, loss: 0.077368
 >> iter 75000, loss: 0.051708
 >> iter 76000, loss: 0.050315
 >> iter 77000, loss: 0.042855
 >> iter 78000, loss: 0.044428
 >> iter 79000, loss: 0.044512
 >> iter 80000, loss: 0.047248
   Number of active neurons: 4
 >> iter 81000, loss: 0.035833
 >> iter 82000, loss: 0.044366
 >> iter 83000, loss: 0.053299
 >> iter 84000, loss: 0.041457
 >> iter 85000, loss: 0.063811
 >> iter 86000, loss: 0.045763
 >> iter 87000, loss: 0.041956
 >> iter 88000, loss: 0.040099
 >> iter 89000, loss: 0.043352
 >> iter 90000, loss: 0.044370
   Number of active neurons: 4
 >> iter 91000, loss: 0.052958
 >> iter 92000, loss: 0.056714
 >> iter 93000, loss: 0.041579
 >> iter 94000, loss: 0.055849
 >> iter 95000, loss: 0.061036
 >> iter 96000, loss: 0.047632
 >> iter 97000, loss: 0.052577
 >> iter 98000, loss: 0.072706
 >> iter 99000, loss: 0.060695
 >> iter 100000, loss: 0.048344
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.336987
 >> iter 2000, loss: 4.429187
 >> iter 3000, loss: 1.772412
 >> iter 4000, loss: 0.701452
 >> iter 5000, loss: 0.318126
 >> iter 6000, loss: 0.170753
 >> iter 7000, loss: 0.125767
 >> iter 8000, loss: 0.110476
 >> iter 9000, loss: 0.086644
 >> iter 10000, loss: 0.084569
   Number of active neurons: 7
 >> iter 11000, loss: 0.067792
 >> iter 12000, loss: 0.067904
 >> iter 13000, loss: 0.081368
 >> iter 14000, loss: 0.070096
 >> iter 15000, loss: 0.059252
 >> iter 16000, loss: 0.050016
 >> iter 17000, loss: 0.057614
 >> iter 18000, loss: 0.081085
 >> iter 19000, loss: 0.071670
 >> iter 20000, loss: 0.054169
   Number of active neurons: 6
 >> iter 21000, loss: 0.048147
 >> iter 22000, loss: 0.050166
 >> iter 23000, loss: 0.043393
 >> iter 24000, loss: 0.036050
 >> iter 25000, loss: 0.042426
 >> iter 26000, loss: 0.057610
 >> iter 27000, loss: 0.060833
 >> iter 28000, loss: 0.042319
 >> iter 29000, loss: 0.040175
 >> iter 30000, loss: 0.057395
   Number of active neurons: 5
 >> iter 31000, loss: 0.047093
 >> iter 32000, loss: 0.050869
 >> iter 33000, loss: 0.047477
 >> iter 34000, loss: 0.037593
 >> iter 35000, loss: 0.045531
 >> iter 36000, loss: 0.053532
 >> iter 37000, loss: 0.050638
 >> iter 38000, loss: 0.047467
 >> iter 39000, loss: 0.052160
 >> iter 40000, loss: 0.038132
   Number of active neurons: 5
 >> iter 41000, loss: 0.034298
 >> iter 42000, loss: 0.041240
 >> iter 43000, loss: 0.056153
 >> iter 44000, loss: 0.047635
 >> iter 45000, loss: 0.047222
 >> iter 46000, loss: 0.046280
 >> iter 47000, loss: 0.060711
 >> iter 48000, loss: 0.053786
 >> iter 49000, loss: 0.049184
 >> iter 50000, loss: 0.039778
   Number of active neurons: 5
 >> iter 51000, loss: 0.049688
 >> iter 52000, loss: 0.053793
 >> iter 53000, loss: 0.052794
 >> iter 54000, loss: 0.061171
 >> iter 55000, loss: 0.054930
 >> iter 56000, loss: 0.048698
 >> iter 57000, loss: 0.064059
 >> iter 58000, loss: 0.045827
 >> iter 59000, loss: 0.043492
 >> iter 60000, loss: 0.043488
   Number of active neurons: 4
 >> iter 61000, loss: 0.043733
 >> iter 62000, loss: 0.042701
 >> iter 63000, loss: 0.048386
 >> iter 64000, loss: 0.035588
 >> iter 65000, loss: 0.041039
 >> iter 66000, loss: 0.035123
 >> iter 67000, loss: 0.041611
 >> iter 68000, loss: 0.054430
 >> iter 69000, loss: 0.039158
 >> iter 70000, loss: 0.041754
   Number of active neurons: 4
 >> iter 71000, loss: 0.049420
 >> iter 72000, loss: 0.059329
 >> iter 73000, loss: 0.056238
 >> iter 74000, loss: 0.049293
 >> iter 75000, loss: 0.053445
 >> iter 76000, loss: 0.046879
 >> iter 77000, loss: 0.054313
 >> iter 78000, loss: 0.060876
 >> iter 79000, loss: 0.055339
 >> iter 80000, loss: 0.048297
   Number of active neurons: 3
 >> iter 81000, loss: 0.037200
 >> iter 82000, loss: 0.038801
 >> iter 83000, loss: 0.060063
 >> iter 84000, loss: 0.052855
 >> iter 85000, loss: 0.071985
 >> iter 86000, loss: 0.060989
 >> iter 87000, loss: 0.053997
 >> iter 88000, loss: 0.043182
 >> iter 89000, loss: 0.041825
 >> iter 90000, loss: 0.044330
   Number of active neurons: 3
 >> iter 91000, loss: 0.061741
 >> iter 92000, loss: 0.043691
 >> iter 93000, loss: 0.041437
 >> iter 94000, loss: 0.053109
 >> iter 95000, loss: 0.050470
 >> iter 96000, loss: 0.049372
 >> iter 97000, loss: 0.063387
 >> iter 98000, loss: 0.055789
 >> iter 99000, loss: 0.054976
 >> iter 100000, loss: 0.056867
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.359723
 >> iter 2000, loss: 4.500323
 >> iter 3000, loss: 1.821153
 >> iter 4000, loss: 0.772927
 >> iter 5000, loss: 0.359258
 >> iter 6000, loss: 0.215005
 >> iter 7000, loss: 0.145858
 >> iter 8000, loss: 0.108035
 >> iter 9000, loss: 0.111780
 >> iter 10000, loss: 0.081470
   Number of active neurons: 9
 >> iter 11000, loss: 0.078108
 >> iter 12000, loss: 0.066818
 >> iter 13000, loss: 0.062617
 >> iter 14000, loss: 0.072162
 >> iter 15000, loss: 0.065253
 >> iter 16000, loss: 0.066104
 >> iter 17000, loss: 0.065583
 >> iter 18000, loss: 0.073516
 >> iter 19000, loss: 0.054166
 >> iter 20000, loss: 0.054896
   Number of active neurons: 7
 >> iter 21000, loss: 0.050923
 >> iter 22000, loss: 0.047439
 >> iter 23000, loss: 0.077781
 >> iter 24000, loss: 0.048034
 >> iter 25000, loss: 0.038326
 >> iter 26000, loss: 0.079633
 >> iter 27000, loss: 0.058145
 >> iter 28000, loss: 0.061411
 >> iter 29000, loss: 0.054299
 >> iter 30000, loss: 0.058751
   Number of active neurons: 6
 >> iter 31000, loss: 0.074943
 >> iter 32000, loss: 0.058488
 >> iter 33000, loss: 0.060115
 >> iter 34000, loss: 0.046337
 >> iter 35000, loss: 0.065227
 >> iter 36000, loss: 0.056585
 >> iter 37000, loss: 0.053603
 >> iter 38000, loss: 0.040659
 >> iter 39000, loss: 0.034187
 >> iter 40000, loss: 0.035272
   Number of active neurons: 5
 >> iter 41000, loss: 0.041857
 >> iter 42000, loss: 0.057372
 >> iter 43000, loss: 0.052521
 >> iter 44000, loss: 0.044475
 >> iter 45000, loss: 0.035763
 >> iter 46000, loss: 0.031987
 >> iter 47000, loss: 0.044427
 >> iter 48000, loss: 0.055784
 >> iter 49000, loss: 0.054564
 >> iter 50000, loss: 0.039004
   Number of active neurons: 4
 >> iter 51000, loss: 0.036977
 >> iter 52000, loss: 0.042609
 >> iter 53000, loss: 0.056255
 >> iter 54000, loss: 0.041865
 >> iter 55000, loss: 0.038364
 >> iter 56000, loss: 0.038078
 >> iter 57000, loss: 0.057681
 >> iter 58000, loss: 0.050394
 >> iter 59000, loss: 0.044091
 >> iter 60000, loss: 0.048975
   Number of active neurons: 4
 >> iter 61000, loss: 0.049714
 >> iter 62000, loss: 0.042313
 >> iter 63000, loss: 0.036243
 >> iter 64000, loss: 0.045612
 >> iter 65000, loss: 0.059007
 >> iter 66000, loss: 0.053535
 >> iter 67000, loss: 0.065611
 >> iter 68000, loss: 0.071918
 >> iter 69000, loss: 0.050678
 >> iter 70000, loss: 0.057767
   Number of active neurons: 4
 >> iter 71000, loss: 0.055558
 >> iter 72000, loss: 0.061611
 >> iter 73000, loss: 0.048426
 >> iter 74000, loss: 0.059602
 >> iter 75000, loss: 0.043792
 >> iter 76000, loss: 0.045881
 >> iter 77000, loss: 0.041582
 >> iter 78000, loss: 0.039296
 >> iter 79000, loss: 0.048104
 >> iter 80000, loss: 0.047258
   Number of active neurons: 3
 >> iter 81000, loss: 0.056068
 >> iter 82000, loss: 0.047863
 >> iter 83000, loss: 0.042349
 >> iter 84000, loss: 0.038772
 >> iter 85000, loss: 0.043154
 >> iter 86000, loss: 0.054116
 >> iter 87000, loss: 0.069186
 >> iter 88000, loss: 0.073901
 >> iter 89000, loss: 0.070009
 >> iter 90000, loss: 0.043842
   Number of active neurons: 3
 >> iter 91000, loss: 0.076676
 >> iter 92000, loss: 0.053944
 >> iter 93000, loss: 0.048161
 >> iter 94000, loss: 0.036498
 >> iter 95000, loss: 0.047868
 >> iter 96000, loss: 0.032101
 >> iter 97000, loss: 0.036809
 >> iter 98000, loss: 0.038567
 >> iter 99000, loss: 0.051726
 >> iter 100000, loss: 0.060493
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.278853
 >> iter 2000, loss: 4.373828
 >> iter 3000, loss: 1.720677
 >> iter 4000, loss: 0.714633
 >> iter 5000, loss: 0.348502
 >> iter 6000, loss: 0.209007
 >> iter 7000, loss: 0.152270
 >> iter 8000, loss: 0.111978
 >> iter 9000, loss: 0.091271
 >> iter 10000, loss: 0.092522
   Number of active neurons: 8
 >> iter 11000, loss: 0.094128
 >> iter 12000, loss: 0.085562
 >> iter 13000, loss: 0.068695
 >> iter 14000, loss: 0.064518
 >> iter 15000, loss: 0.069992
 >> iter 16000, loss: 0.081941
 >> iter 17000, loss: 0.092461
 >> iter 18000, loss: 0.063591
 >> iter 19000, loss: 0.052196
 >> iter 20000, loss: 0.059520
   Number of active neurons: 8
 >> iter 21000, loss: 0.054934
 >> iter 22000, loss: 0.059187
 >> iter 23000, loss: 0.055162
 >> iter 24000, loss: 0.073211
 >> iter 25000, loss: 0.063180
 >> iter 26000, loss: 0.057014
 >> iter 27000, loss: 0.061310
 >> iter 28000, loss: 0.063307
 >> iter 29000, loss: 0.056516
 >> iter 30000, loss: 0.068090
   Number of active neurons: 6
 >> iter 31000, loss: 0.052380
 >> iter 32000, loss: 0.051770
 >> iter 33000, loss: 0.054253
 >> iter 34000, loss: 0.046220
 >> iter 35000, loss: 0.047647
 >> iter 36000, loss: 0.066507
 >> iter 37000, loss: 0.053201
 >> iter 38000, loss: 0.043757
 >> iter 39000, loss: 0.046662
 >> iter 40000, loss: 0.041333
   Number of active neurons: 6
 >> iter 41000, loss: 0.046962
 >> iter 42000, loss: 0.045345
 >> iter 43000, loss: 0.065471
 >> iter 44000, loss: 0.057719
 >> iter 45000, loss: 0.057357
 >> iter 46000, loss: 0.045313
 >> iter 47000, loss: 0.080709
 >> iter 48000, loss: 0.068650
 >> iter 49000, loss: 0.058462
 >> iter 50000, loss: 0.069836
   Number of active neurons: 6
 >> iter 51000, loss: 0.063622
 >> iter 52000, loss: 0.055284
 >> iter 53000, loss: 0.045313
 >> iter 54000, loss: 0.069308
 >> iter 55000, loss: 0.050336
 >> iter 56000, loss: 0.046025
 >> iter 57000, loss: 0.064505
 >> iter 58000, loss: 0.076100
 >> iter 59000, loss: 0.057786
 >> iter 60000, loss: 0.065985
   Number of active neurons: 6
 >> iter 61000, loss: 0.053421
 >> iter 62000, loss: 0.050634
 >> iter 63000, loss: 0.078670
 >> iter 64000, loss: 0.066341
 >> iter 65000, loss: 0.065544
 >> iter 66000, loss: 0.054398
 >> iter 67000, loss: 0.055728
 >> iter 68000, loss: 0.057307
 >> iter 69000, loss: 0.062004
 >> iter 70000, loss: 0.044209
   Number of active neurons: 5
 >> iter 71000, loss: 0.048697
 >> iter 72000, loss: 0.050349
 >> iter 73000, loss: 0.056690
 >> iter 74000, loss: 0.042567
 >> iter 75000, loss: 0.055880
 >> iter 76000, loss: 0.046790
 >> iter 77000, loss: 0.066778
 >> iter 78000, loss: 0.051053
 >> iter 79000, loss: 0.051876
 >> iter 80000, loss: 0.056749
   Number of active neurons: 5
 >> iter 81000, loss: 0.052968
 >> iter 82000, loss: 0.039806
 >> iter 83000, loss: 0.056718
 >> iter 84000, loss: 0.060861
 >> iter 85000, loss: 0.059471
 >> iter 86000, loss: 0.045932
 >> iter 87000, loss: 0.036616
 >> iter 88000, loss: 0.050655
 >> iter 89000, loss: 0.041130
 >> iter 90000, loss: 0.040014
   Number of active neurons: 4
 >> iter 91000, loss: 0.055467
 >> iter 92000, loss: 0.040812
 >> iter 93000, loss: 0.037223
 >> iter 94000, loss: 0.034350
 >> iter 95000, loss: 0.049577
 >> iter 96000, loss: 0.052405
 >> iter 97000, loss: 0.047966
 >> iter 98000, loss: 0.050698
 >> iter 99000, loss: 0.047065
 >> iter 100000, loss: 0.037617
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.354651
 >> iter 2000, loss: 4.482980
 >> iter 3000, loss: 1.820966
 >> iter 4000, loss: 0.781880
 >> iter 5000, loss: 0.375554
 >> iter 6000, loss: 0.204662
 >> iter 7000, loss: 0.170985
 >> iter 8000, loss: 0.118776
 >> iter 9000, loss: 0.102164
 >> iter 10000, loss: 0.077533
   Number of active neurons: 10
 >> iter 11000, loss: 0.059947
 >> iter 12000, loss: 0.096610
 >> iter 13000, loss: 0.072413
 >> iter 14000, loss: 0.079778
 >> iter 15000, loss: 0.092601
 >> iter 16000, loss: 0.057354
 >> iter 17000, loss: 0.060449
 >> iter 18000, loss: 0.073558
 >> iter 19000, loss: 0.078584
 >> iter 20000, loss: 0.068073
   Number of active neurons: 6
 >> iter 21000, loss: 0.079050
 >> iter 22000, loss: 0.066356
 >> iter 23000, loss: 0.065530
 >> iter 24000, loss: 0.057259
 >> iter 25000, loss: 0.082061
 >> iter 26000, loss: 0.070735
 >> iter 27000, loss: 0.062310
 >> iter 28000, loss: 0.049327
 >> iter 29000, loss: 0.061187
 >> iter 30000, loss: 0.055217
   Number of active neurons: 6
 >> iter 31000, loss: 0.072366
 >> iter 32000, loss: 0.056472
 >> iter 33000, loss: 0.056224
 >> iter 34000, loss: 0.044588
 >> iter 35000, loss: 0.047152
 >> iter 36000, loss: 0.046775
 >> iter 37000, loss: 0.043510
 >> iter 38000, loss: 0.040351
 >> iter 39000, loss: 0.054460
 >> iter 40000, loss: 0.044438
   Number of active neurons: 4
 >> iter 41000, loss: 0.043442
 >> iter 42000, loss: 0.044862
 >> iter 43000, loss: 0.046099
 >> iter 44000, loss: 0.049380
 >> iter 45000, loss: 0.074188
 >> iter 46000, loss: 0.054944
 >> iter 47000, loss: 0.067162
 >> iter 48000, loss: 0.053225
 >> iter 49000, loss: 0.044099
 >> iter 50000, loss: 0.047239
   Number of active neurons: 3
 >> iter 51000, loss: 0.044203
 >> iter 52000, loss: 0.032275
 >> iter 53000, loss: 0.044540
 >> iter 54000, loss: 0.035579
 >> iter 55000, loss: 0.037233
 >> iter 56000, loss: 0.047221
 >> iter 57000, loss: 0.044115
 >> iter 58000, loss: 0.050819
 >> iter 59000, loss: 0.049372
 >> iter 60000, loss: 0.064822
   Number of active neurons: 3
 >> iter 61000, loss: 0.071802
 >> iter 62000, loss: 0.054569
 >> iter 63000, loss: 0.046273
 >> iter 64000, loss: 0.034228
 >> iter 65000, loss: 0.055100
 >> iter 66000, loss: 0.071578
 >> iter 67000, loss: 0.052878
 >> iter 68000, loss: 0.045795
 >> iter 69000, loss: 0.059275
 >> iter 70000, loss: 0.041364
   Number of active neurons: 3
 >> iter 71000, loss: 0.060762
 >> iter 72000, loss: 0.067949
 >> iter 73000, loss: 0.061073
 >> iter 74000, loss: 0.045685
 >> iter 75000, loss: 0.035906
 >> iter 76000, loss: 0.061295
 >> iter 77000, loss: 0.047363
 >> iter 78000, loss: 0.049040
 >> iter 79000, loss: 0.046122
 >> iter 80000, loss: 0.045370
   Number of active neurons: 3
 >> iter 81000, loss: 0.047648
 >> iter 82000, loss: 0.035827
 >> iter 83000, loss: 0.035571
 >> iter 84000, loss: 0.045561
 >> iter 85000, loss: 0.053234
 >> iter 86000, loss: 0.061143
 >> iter 87000, loss: 0.051463
 >> iter 88000, loss: 0.035334
 >> iter 89000, loss: 0.052599
 >> iter 90000, loss: 0.037797
   Number of active neurons: 3
 >> iter 91000, loss: 0.040791
 >> iter 92000, loss: 0.047256
 >> iter 93000, loss: 0.045960
 >> iter 94000, loss: 0.044092
 >> iter 95000, loss: 0.071159
 >> iter 96000, loss: 0.069174
 >> iter 97000, loss: 0.064290
 >> iter 98000, loss: 0.049726
 >> iter 99000, loss: 0.041895
 >> iter 100000, loss: 0.047916
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.328730
 >> iter 2000, loss: 4.495420
 >> iter 3000, loss: 1.750749
 >> iter 4000, loss: 0.786155
 >> iter 5000, loss: 0.357353
 >> iter 6000, loss: 0.180517
 >> iter 7000, loss: 0.126130
 >> iter 8000, loss: 0.092837
 >> iter 9000, loss: 0.088607
 >> iter 10000, loss: 0.088992
   Number of active neurons: 9
 >> iter 11000, loss: 0.090418
 >> iter 12000, loss: 0.087397
 >> iter 13000, loss: 0.070133
 >> iter 14000, loss: 0.068393
 >> iter 15000, loss: 0.072131
 >> iter 16000, loss: 0.051850
 >> iter 17000, loss: 0.078248
 >> iter 18000, loss: 0.048507
 >> iter 19000, loss: 0.053563
 >> iter 20000, loss: 0.046178
   Number of active neurons: 6
 >> iter 21000, loss: 0.042051
 >> iter 22000, loss: 0.065977
 >> iter 23000, loss: 0.058830
 >> iter 24000, loss: 0.053281
 >> iter 25000, loss: 0.051871
 >> iter 26000, loss: 0.056607
 >> iter 27000, loss: 0.043992
 >> iter 28000, loss: 0.047770
 >> iter 29000, loss: 0.056235
 >> iter 30000, loss: 0.053573
   Number of active neurons: 6
 >> iter 31000, loss: 0.057649
 >> iter 32000, loss: 0.065861
 >> iter 33000, loss: 0.059915
 >> iter 34000, loss: 0.047930
 >> iter 35000, loss: 0.053981
 >> iter 36000, loss: 0.066219
 >> iter 37000, loss: 0.044808
 >> iter 38000, loss: 0.044027
 >> iter 39000, loss: 0.037000
 >> iter 40000, loss: 0.045911
   Number of active neurons: 5
 >> iter 41000, loss: 0.055258
 >> iter 42000, loss: 0.056050
 >> iter 43000, loss: 0.046048
 >> iter 44000, loss: 0.047806
 >> iter 45000, loss: 0.052794
 >> iter 46000, loss: 0.061006
 >> iter 47000, loss: 0.056342
 >> iter 48000, loss: 0.050215
 >> iter 49000, loss: 0.058254
 >> iter 50000, loss: 0.047531
   Number of active neurons: 5
 >> iter 51000, loss: 0.059601
 >> iter 52000, loss: 0.069288
 >> iter 53000, loss: 0.064063
 >> iter 54000, loss: 0.073280
 >> iter 55000, loss: 0.052631
 >> iter 56000, loss: 0.039894
 >> iter 57000, loss: 0.034431
 >> iter 58000, loss: 0.032420
 >> iter 59000, loss: 0.040162
 >> iter 60000, loss: 0.052631
   Number of active neurons: 4
 >> iter 61000, loss: 0.057493
 >> iter 62000, loss: 0.046628
 >> iter 63000, loss: 0.046029
 >> iter 64000, loss: 0.036540
 >> iter 65000, loss: 0.039118
 >> iter 66000, loss: 0.057747
 >> iter 67000, loss: 0.046156
 >> iter 68000, loss: 0.045888
 >> iter 69000, loss: 0.035379
 >> iter 70000, loss: 0.041577
   Number of active neurons: 4
 >> iter 71000, loss: 0.055627
 >> iter 72000, loss: 0.051178
 >> iter 73000, loss: 0.052979
 >> iter 74000, loss: 0.053048
 >> iter 75000, loss: 0.061391
 >> iter 76000, loss: 0.045621
 >> iter 77000, loss: 0.040715
 >> iter 78000, loss: 0.059438
 >> iter 79000, loss: 0.041065
 >> iter 80000, loss: 0.037125
   Number of active neurons: 3
 >> iter 81000, loss: 0.040043
 >> iter 82000, loss: 0.054838
 >> iter 83000, loss: 0.051599
 >> iter 84000, loss: 0.050877
 >> iter 85000, loss: 0.039991
 >> iter 86000, loss: 0.046997
 >> iter 87000, loss: 0.046374
 >> iter 88000, loss: 0.050996
 >> iter 89000, loss: 0.053322
 >> iter 90000, loss: 0.043337
   Number of active neurons: 3
 >> iter 91000, loss: 0.050053
 >> iter 92000, loss: 0.049099
 >> iter 93000, loss: 0.037014
 >> iter 94000, loss: 0.033329
 >> iter 95000, loss: 0.035066
 >> iter 96000, loss: 0.031875
 >> iter 97000, loss: 0.033550
 >> iter 98000, loss: 0.041756
 >> iter 99000, loss: 0.042544
 >> iter 100000, loss: 0.042866
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455158
   Number of active neurons: 0
 >> iter 1000, loss: 11.320807
 >> iter 2000, loss: 4.403339
 >> iter 3000, loss: 1.752616
 >> iter 4000, loss: 0.741248
 >> iter 5000, loss: 0.343927
 >> iter 6000, loss: 0.193147
 >> iter 7000, loss: 0.122201
 >> iter 8000, loss: 0.095168
 >> iter 9000, loss: 0.105082
 >> iter 10000, loss: 0.082098
   Number of active neurons: 10
 >> iter 11000, loss: 0.090127
 >> iter 12000, loss: 0.074714
 >> iter 13000, loss: 0.076062
 >> iter 14000, loss: 0.064236
 >> iter 15000, loss: 0.077939
 >> iter 16000, loss: 0.075139
 >> iter 17000, loss: 0.060581
 >> iter 18000, loss: 0.058228
 >> iter 19000, loss: 0.050050
 >> iter 20000, loss: 0.068351
   Number of active neurons: 6
 >> iter 21000, loss: 0.056321
 >> iter 22000, loss: 0.049050
 >> iter 23000, loss: 0.048314
 >> iter 24000, loss: 0.049883
 >> iter 25000, loss: 0.062639
 >> iter 26000, loss: 0.059375
 >> iter 27000, loss: 0.057457
 >> iter 28000, loss: 0.070298
 >> iter 29000, loss: 0.053681
 >> iter 30000, loss: 0.047708
   Number of active neurons: 6
 >> iter 31000, loss: 0.055086
 >> iter 32000, loss: 0.045532
 >> iter 33000, loss: 0.052432
 >> iter 34000, loss: 0.066525
 >> iter 35000, loss: 0.059281
 >> iter 36000, loss: 0.051611
 >> iter 37000, loss: 0.046334
 >> iter 38000, loss: 0.052612
 >> iter 39000, loss: 0.054270
 >> iter 40000, loss: 0.050991
   Number of active neurons: 4
 >> iter 41000, loss: 0.054010
 >> iter 42000, loss: 0.055393
 >> iter 43000, loss: 0.047782
 >> iter 44000, loss: 0.037205
 >> iter 45000, loss: 0.038019
 >> iter 46000, loss: 0.046564
 >> iter 47000, loss: 0.045134
 >> iter 48000, loss: 0.042612
 >> iter 49000, loss: 0.046240
 >> iter 50000, loss: 0.039361
   Number of active neurons: 4
 >> iter 51000, loss: 0.035537
 >> iter 52000, loss: 0.036023
 >> iter 53000, loss: 0.053780
 >> iter 54000, loss: 0.060462
 >> iter 55000, loss: 0.059573
 >> iter 56000, loss: 0.048193
 >> iter 57000, loss: 0.053490
 >> iter 58000, loss: 0.064352
 >> iter 59000, loss: 0.051035
 >> iter 60000, loss: 0.035189
   Number of active neurons: 3
 >> iter 61000, loss: 0.049465
 >> iter 62000, loss: 0.037408
 >> iter 63000, loss: 0.056060
 >> iter 64000, loss: 0.064319
 >> iter 65000, loss: 0.053609
 >> iter 66000, loss: 0.046771
 >> iter 67000, loss: 0.050781
 >> iter 68000, loss: 0.047905
 >> iter 69000, loss: 0.050217
 >> iter 70000, loss: 0.041153
   Number of active neurons: 3
 >> iter 71000, loss: 0.067633
 >> iter 72000, loss: 0.052161
 >> iter 73000, loss: 0.045014
 >> iter 74000, loss: 0.052023
 >> iter 75000, loss: 0.046689
 >> iter 76000, loss: 0.044371
 >> iter 77000, loss: 0.048806
 >> iter 78000, loss: 0.062224
 >> iter 79000, loss: 0.043572
 >> iter 80000, loss: 0.037006
   Number of active neurons: 3
 >> iter 81000, loss: 0.052672
 >> iter 82000, loss: 0.064765
 >> iter 83000, loss: 0.061739
 >> iter 84000, loss: 0.049857
 >> iter 85000, loss: 0.037895
 >> iter 86000, loss: 0.048167
 >> iter 87000, loss: 0.035298
 >> iter 88000, loss: 0.038968
 >> iter 89000, loss: 0.048809
 >> iter 90000, loss: 0.059829
   Number of active neurons: 3
 >> iter 91000, loss: 0.044800
 >> iter 92000, loss: 0.055491
 >> iter 93000, loss: 0.068079
 >> iter 94000, loss: 0.052362
 >> iter 95000, loss: 0.037693
 >> iter 96000, loss: 0.059945
 >> iter 97000, loss: 0.040997
 >> iter 98000, loss: 0.043187
 >> iter 99000, loss: 0.057810
 >> iter 100000, loss: 0.048827
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.352050
 >> iter 2000, loss: 4.481713
 >> iter 3000, loss: 1.798976
 >> iter 4000, loss: 0.748534
 >> iter 5000, loss: 0.349324
 >> iter 6000, loss: 0.194349
 >> iter 7000, loss: 0.111356
 >> iter 8000, loss: 0.100799
 >> iter 9000, loss: 0.083640
 >> iter 10000, loss: 0.112063
   Number of active neurons: 9
 >> iter 11000, loss: 0.089773
 >> iter 12000, loss: 0.074737
 >> iter 13000, loss: 0.064445
 >> iter 14000, loss: 0.068306
 >> iter 15000, loss: 0.064194
 >> iter 16000, loss: 0.069566
 >> iter 17000, loss: 0.078790
 >> iter 18000, loss: 0.090183
 >> iter 19000, loss: 0.077836
 >> iter 20000, loss: 0.064617
   Number of active neurons: 5
 >> iter 21000, loss: 0.072718
 >> iter 22000, loss: 0.047751
 >> iter 23000, loss: 0.046957
 >> iter 24000, loss: 0.048553
 >> iter 25000, loss: 0.046352
 >> iter 26000, loss: 0.052015
 >> iter 27000, loss: 0.048147
 >> iter 28000, loss: 0.061292
 >> iter 29000, loss: 0.053924
 >> iter 30000, loss: 0.051835
   Number of active neurons: 5
 >> iter 31000, loss: 0.072500
 >> iter 32000, loss: 0.065650
 >> iter 33000, loss: 0.054791
 >> iter 34000, loss: 0.039322
 >> iter 35000, loss: 0.056700
 >> iter 36000, loss: 0.047156
 >> iter 37000, loss: 0.046925
 >> iter 38000, loss: 0.042256
 >> iter 39000, loss: 0.041279
 >> iter 40000, loss: 0.057921
   Number of active neurons: 5
 >> iter 41000, loss: 0.054428
 >> iter 42000, loss: 0.048012
 >> iter 43000, loss: 0.048395
 >> iter 44000, loss: 0.059497
 >> iter 45000, loss: 0.045744
 >> iter 46000, loss: 0.038910
 >> iter 47000, loss: 0.041000
 >> iter 48000, loss: 0.052983
 >> iter 49000, loss: 0.075840
 >> iter 50000, loss: 0.054711
   Number of active neurons: 5
 >> iter 51000, loss: 0.058957
 >> iter 52000, loss: 0.073136
 >> iter 53000, loss: 0.059835
 >> iter 54000, loss: 0.041789
 >> iter 55000, loss: 0.041620
 >> iter 56000, loss: 0.044339
 >> iter 57000, loss: 0.040158
 >> iter 58000, loss: 0.044700
 >> iter 59000, loss: 0.042781
 >> iter 60000, loss: 0.046141
   Number of active neurons: 5
 >> iter 61000, loss: 0.048292
 >> iter 62000, loss: 0.040926
 >> iter 63000, loss: 0.040291
 >> iter 64000, loss: 0.046707
 >> iter 65000, loss: 0.051193
 >> iter 66000, loss: 0.049386
 >> iter 67000, loss: 0.059962
 >> iter 68000, loss: 0.055475
 >> iter 69000, loss: 0.060460
 >> iter 70000, loss: 0.038579
   Number of active neurons: 4
 >> iter 71000, loss: 0.043215
 >> iter 72000, loss: 0.046071
 >> iter 73000, loss: 0.048619
 >> iter 74000, loss: 0.059782
 >> iter 75000, loss: 0.062191
 >> iter 76000, loss: 0.043227
 >> iter 77000, loss: 0.034844
 >> iter 78000, loss: 0.039752
 >> iter 79000, loss: 0.041999
 >> iter 80000, loss: 0.035763
   Number of active neurons: 3
 >> iter 81000, loss: 0.037301
 >> iter 82000, loss: 0.034853
 >> iter 83000, loss: 0.046206
 >> iter 84000, loss: 0.043184
 >> iter 85000, loss: 0.046709
 >> iter 86000, loss: 0.048363
 >> iter 87000, loss: 0.060930
 >> iter 88000, loss: 0.047838
 >> iter 89000, loss: 0.041077
 >> iter 90000, loss: 0.056586
   Number of active neurons: 3
 >> iter 91000, loss: 0.053675
 >> iter 92000, loss: 0.060793
 >> iter 93000, loss: 0.052798
 >> iter 94000, loss: 0.039083
 >> iter 95000, loss: 0.035850
 >> iter 96000, loss: 0.032042
 >> iter 97000, loss: 0.032267
 >> iter 98000, loss: 0.030503
 >> iter 99000, loss: 0.028563
 >> iter 100000, loss: 0.026855
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

