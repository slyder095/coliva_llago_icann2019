 > Problema: tomita5nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 2e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.542787
 >> iter 2000, loss: 10.494419
 >> iter 3000, loss: 8.633133
 >> iter 4000, loss: 7.915902
 >> iter 5000, loss: 7.709455
 >> iter 6000, loss: 7.393773
 >> iter 7000, loss: 5.936378
 >> iter 8000, loss: 2.239182
 >> iter 9000, loss: 0.846509
 >> iter 10000, loss: 0.327014
   Number of active neurons: 8
 >> iter 11000, loss: 0.132971
 >> iter 12000, loss: 0.059771
 >> iter 13000, loss: 0.031870
 >> iter 14000, loss: 0.020799
 >> iter 15000, loss: 0.016298
 >> iter 16000, loss: 0.014194
 >> iter 17000, loss: 0.013217
 >> iter 18000, loss: 0.012571
 >> iter 19000, loss: 0.012238
 >> iter 20000, loss: 0.011912
   Number of active neurons: 8
 >> iter 21000, loss: 0.011743
 >> iter 22000, loss: 0.011521
 >> iter 23000, loss: 0.011419
 >> iter 24000, loss: 0.011245
 >> iter 25000, loss: 0.011173
 >> iter 26000, loss: 0.011034
 >> iter 27000, loss: 0.010988
 >> iter 28000, loss: 0.010868
 >> iter 29000, loss: 0.010830
 >> iter 30000, loss: 0.010721
   Number of active neurons: 8
 >> iter 31000, loss: 0.010693
 >> iter 32000, loss: 0.010596
 >> iter 33000, loss: 0.010577
 >> iter 34000, loss: 0.010483
 >> iter 35000, loss: 0.010469
 >> iter 36000, loss: 0.010393
 >> iter 37000, loss: 0.010390
 >> iter 38000, loss: 0.010326
 >> iter 39000, loss: 0.010328
 >> iter 40000, loss: 0.010269
   Number of active neurons: 8
 >> iter 41000, loss: 0.010277
 >> iter 42000, loss: 0.010223
 >> iter 43000, loss: 0.010234
 >> iter 44000, loss: 0.010177
 >> iter 45000, loss: 0.010187
 >> iter 46000, loss: 0.010134
 >> iter 47000, loss: 0.010145
 >> iter 48000, loss: 0.010096
 >> iter 49000, loss: 0.010114
 >> iter 50000, loss: 0.010065
   Number of active neurons: 8
 >> iter 51000, loss: 0.010076
 >> iter 52000, loss: 0.010026
 >> iter 53000, loss: 0.010033
 >> iter 54000, loss: 0.009985
 >> iter 55000, loss: 0.009984
 >> iter 56000, loss: 0.009944
 >> iter 57000, loss: 0.009942
 >> iter 58000, loss: 0.009908
 >> iter 59000, loss: 0.009903
 >> iter 60000, loss: 0.009866
   Number of active neurons: 8
 >> iter 61000, loss: 0.009856
 >> iter 62000, loss: 0.009823
 >> iter 63000, loss: 0.009813
 >> iter 64000, loss: 0.009786
 >> iter 65000, loss: 0.009777
 >> iter 66000, loss: 0.009756
 >> iter 67000, loss: 0.009750
 >> iter 68000, loss: 0.009735
 >> iter 69000, loss: 0.009729
 >> iter 70000, loss: 0.009713
   Number of active neurons: 8
 >> iter 71000, loss: 0.009704
 >> iter 72000, loss: 0.009689
 >> iter 73000, loss: 0.009681
 >> iter 74000, loss: 0.009670
 >> iter 75000, loss: 0.009662
 >> iter 76000, loss: 0.009655
 >> iter 77000, loss: 0.009644
 >> iter 78000, loss: 0.009635
 >> iter 79000, loss: 0.009621
 >> iter 80000, loss: 0.009612
   Number of active neurons: 8
 >> iter 81000, loss: 0.009598
 >> iter 82000, loss: 0.009594
 >> iter 83000, loss: 0.009578
 >> iter 84000, loss: 0.009579
 >> iter 85000, loss: 0.009563
 >> iter 86000, loss: 0.009567
 >> iter 87000, loss: 0.009547
 >> iter 88000, loss: 0.009552
 >> iter 89000, loss: 0.009531
 >> iter 90000, loss: 0.009535
   Number of active neurons: 8
 >> iter 91000, loss: 0.009510
 >> iter 92000, loss: 0.009518
 >> iter 93000, loss: 0.009492
 >> iter 94000, loss: 0.009502
 >> iter 95000, loss: 0.009478
 >> iter 96000, loss: 0.009485
 >> iter 97000, loss: 0.009462
 >> iter 98000, loss: 0.009469
 >> iter 99000, loss: 0.009444
 >> iter 100000, loss: 0.009450
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.539745
 >> iter 2000, loss: 10.480921
 >> iter 3000, loss: 8.617373
 >> iter 4000, loss: 7.903358
 >> iter 5000, loss: 7.653634
 >> iter 6000, loss: 7.580387
 >> iter 7000, loss: 6.918059
 >> iter 8000, loss: 6.206459
 >> iter 9000, loss: 5.633471
 >> iter 10000, loss: 5.294226
   Number of active neurons: 7
 >> iter 11000, loss: 5.085036
 >> iter 12000, loss: 4.616981
 >> iter 13000, loss: 3.867542
 >> iter 14000, loss: 4.275469
 >> iter 15000, loss: 3.787755
 >> iter 16000, loss: 3.200613
 >> iter 17000, loss: 1.398681
 >> iter 18000, loss: 0.558192
 >> iter 19000, loss: 0.234298
 >> iter 20000, loss: 0.108883
   Number of active neurons: 8
 >> iter 21000, loss: 0.058803
 >> iter 22000, loss: 0.038007
 >> iter 23000, loss: 0.028487
 >> iter 24000, loss: 0.023708
 >> iter 25000, loss: 0.020900
 >> iter 26000, loss: 0.019130
 >> iter 27000, loss: 0.017811
 >> iter 28000, loss: 0.016826
 >> iter 29000, loss: 0.016482
 >> iter 30000, loss: 0.015138
   Number of active neurons: 8
 >> iter 31000, loss: 0.014751
 >> iter 32000, loss: 0.013080
 >> iter 33000, loss: 0.011780
 >> iter 34000, loss: 0.010894
 >> iter 35000, loss: 0.010067
 >> iter 36000, loss: 0.009621
 >> iter 37000, loss: 0.009171
 >> iter 38000, loss: 0.008983
 >> iter 39000, loss: 0.008783
 >> iter 40000, loss: 0.008702
   Number of active neurons: 8
 >> iter 41000, loss: 0.008631
 >> iter 42000, loss: 0.008613
 >> iter 43000, loss: 0.008607
 >> iter 44000, loss: 0.008607
 >> iter 45000, loss: 0.008644
 >> iter 46000, loss: 0.008663
 >> iter 47000, loss: 0.008733
 >> iter 48000, loss: 0.008754
 >> iter 49000, loss: 0.008851
 >> iter 50000, loss: 0.008869
   Number of active neurons: 8
 >> iter 51000, loss: 0.008981
 >> iter 52000, loss: 0.008993
 >> iter 53000, loss: 0.009109
 >> iter 54000, loss: 0.009107
 >> iter 55000, loss: 0.009228
 >> iter 56000, loss: 0.009212
 >> iter 57000, loss: 0.009331
 >> iter 58000, loss: 0.009311
 >> iter 59000, loss: 0.009431
 >> iter 60000, loss: 0.009411
   Number of active neurons: 8
 >> iter 61000, loss: 0.009527
 >> iter 62000, loss: 0.009491
 >> iter 63000, loss: 0.009586
 >> iter 64000, loss: 0.009534
 >> iter 65000, loss: 0.009622
 >> iter 66000, loss: 0.009565
 >> iter 67000, loss: 0.009653
 >> iter 68000, loss: 0.009595
 >> iter 69000, loss: 0.009685
 >> iter 70000, loss: 0.009628
   Number of active neurons: 8
 >> iter 71000, loss: 0.009721
 >> iter 72000, loss: 0.009656
 >> iter 73000, loss: 0.009747
 >> iter 74000, loss: 0.009679
 >> iter 75000, loss: 0.009773
 >> iter 76000, loss: 0.009705
 >> iter 77000, loss: 0.009802
 >> iter 78000, loss: 0.009736
 >> iter 79000, loss: 0.009830
 >> iter 80000, loss: 0.009766
   Number of active neurons: 8
 >> iter 81000, loss: 0.009855
 >> iter 82000, loss: 0.009787
 >> iter 83000, loss: 0.009874
 >> iter 84000, loss: 0.009806
 >> iter 85000, loss: 0.009894
 >> iter 86000, loss: 0.009826
 >> iter 87000, loss: 0.009910
 >> iter 88000, loss: 0.009842
 >> iter 89000, loss: 0.009924
 >> iter 90000, loss: 0.009858
   Number of active neurons: 7
 >> iter 91000, loss: 0.009938
 >> iter 92000, loss: 0.009872
 >> iter 93000, loss: 0.009951
 >> iter 94000, loss: 0.009888
 >> iter 95000, loss: 0.009961
 >> iter 96000, loss: 0.009898
 >> iter 97000, loss: 0.009972
 >> iter 98000, loss: 0.009906
 >> iter 99000, loss: 0.009982
 >> iter 100000, loss: 0.009907
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.607217
 >> iter 2000, loss: 10.508909
 >> iter 3000, loss: 8.621818
 >> iter 4000, loss: 7.903306
 >> iter 5000, loss: 7.648436
 >> iter 6000, loss: 7.538264
 >> iter 7000, loss: 7.510280
 >> iter 8000, loss: 7.495278
 >> iter 9000, loss: 7.832138
 >> iter 10000, loss: 7.902307
   Number of active neurons: 10
 >> iter 11000, loss: 8.025164
 >> iter 12000, loss: 6.960209
 >> iter 13000, loss: 2.748173
 >> iter 14000, loss: 1.064543
 >> iter 15000, loss: 0.426800
 >> iter 16000, loss: 0.183282
 >> iter 17000, loss: 0.094159
 >> iter 18000, loss: 0.053686
 >> iter 19000, loss: 0.037140
 >> iter 20000, loss: 0.029343
   Number of active neurons: 10
 >> iter 21000, loss: 0.025744
 >> iter 22000, loss: 0.023329
 >> iter 23000, loss: 0.022120
 >> iter 24000, loss: 0.020885
 >> iter 25000, loss: 0.020303
 >> iter 26000, loss: 0.019486
 >> iter 27000, loss: 0.019157
 >> iter 28000, loss: 0.018533
 >> iter 29000, loss: 0.018335
 >> iter 30000, loss: 0.017812
   Number of active neurons: 9
 >> iter 31000, loss: 0.017687
 >> iter 32000, loss: 0.017221
 >> iter 33000, loss: 0.017132
 >> iter 34000, loss: 0.016743
 >> iter 35000, loss: 0.016690
 >> iter 36000, loss: 0.016354
 >> iter 37000, loss: 0.016316
 >> iter 38000, loss: 0.016022
 >> iter 39000, loss: 0.015994
 >> iter 40000, loss: 0.015739
   Number of active neurons: 9
 >> iter 41000, loss: 0.015722
 >> iter 42000, loss: 0.015477
 >> iter 43000, loss: 0.015455
 >> iter 44000, loss: 0.015214
 >> iter 45000, loss: 0.015191
 >> iter 46000, loss: 0.014969
 >> iter 47000, loss: 0.014958
 >> iter 48000, loss: 0.014744
 >> iter 49000, loss: 0.014752
 >> iter 50000, loss: 0.014554
   Number of active neurons: 9
 >> iter 51000, loss: 0.014567
 >> iter 52000, loss: 0.014379
 >> iter 53000, loss: 0.014399
 >> iter 54000, loss: 0.014211
 >> iter 55000, loss: 0.014241
 >> iter 56000, loss: 0.014050
 >> iter 57000, loss: 0.014088
 >> iter 58000, loss: 0.013895
 >> iter 59000, loss: 0.013946
 >> iter 60000, loss: 0.013758
   Number of active neurons: 9
 >> iter 61000, loss: 0.013826
 >> iter 62000, loss: 0.013633
 >> iter 63000, loss: 0.013714
 >> iter 64000, loss: 0.013523
 >> iter 65000, loss: 0.013606
 >> iter 66000, loss: 0.013409
 >> iter 67000, loss: 0.013495
 >> iter 68000, loss: 0.013304
 >> iter 69000, loss: 0.013397
 >> iter 70000, loss: 0.013217
   Number of active neurons: 9
 >> iter 71000, loss: 0.013316
 >> iter 72000, loss: 0.013140
 >> iter 73000, loss: 0.013248
 >> iter 74000, loss: 0.013063
 >> iter 75000, loss: 0.013172
 >> iter 76000, loss: 0.012987
 >> iter 77000, loss: 0.013113
 >> iter 78000, loss: 0.012919
 >> iter 79000, loss: 0.013042
 >> iter 80000, loss: 0.012857
   Number of active neurons: 9
 >> iter 81000, loss: 0.012973
 >> iter 82000, loss: 0.012791
 >> iter 83000, loss: 0.012908
 >> iter 84000, loss: 0.012724
 >> iter 85000, loss: 0.012840
 >> iter 86000, loss: 0.012653
 >> iter 87000, loss: 0.012772
 >> iter 88000, loss: 0.012586
 >> iter 89000, loss: 0.012703
 >> iter 90000, loss: 0.012522
   Number of active neurons: 9
 >> iter 91000, loss: 0.012639
 >> iter 92000, loss: 0.012465
 >> iter 93000, loss: 0.012577
 >> iter 94000, loss: 0.012403
 >> iter 95000, loss: 0.012514
 >> iter 96000, loss: 0.012339
 >> iter 97000, loss: 0.012447
 >> iter 98000, loss: 0.012280
 >> iter 99000, loss: 0.012378
 >> iter 100000, loss: 0.012221
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.525886
 >> iter 2000, loss: 10.470616
 >> iter 3000, loss: 8.612155
 >> iter 4000, loss: 7.908899
 >> iter 5000, loss: 7.690033
 >> iter 6000, loss: 7.592937
 >> iter 7000, loss: 6.026278
 >> iter 8000, loss: 2.291907
 >> iter 9000, loss: 0.872884
 >> iter 10000, loss: 0.341046
   Number of active neurons: 7
 >> iter 11000, loss: 0.141366
 >> iter 12000, loss: 0.065362
 >> iter 13000, loss: 0.035979
 >> iter 14000, loss: 0.024003
 >> iter 15000, loss: 0.018917
 >> iter 16000, loss: 0.016383
 >> iter 17000, loss: 0.015080
 >> iter 18000, loss: 0.014166
 >> iter 19000, loss: 0.013616
 >> iter 20000, loss: 0.013108
   Number of active neurons: 7
 >> iter 21000, loss: 0.012792
 >> iter 22000, loss: 0.012444
 >> iter 23000, loss: 0.012234
 >> iter 24000, loss: 0.011972
 >> iter 25000, loss: 0.011825
 >> iter 26000, loss: 0.011619
 >> iter 27000, loss: 0.011515
 >> iter 28000, loss: 0.011346
 >> iter 29000, loss: 0.011263
 >> iter 30000, loss: 0.011125
   Number of active neurons: 7
 >> iter 31000, loss: 0.011070
 >> iter 32000, loss: 0.010955
 >> iter 33000, loss: 0.010913
 >> iter 34000, loss: 0.010815
 >> iter 35000, loss: 0.010785
 >> iter 36000, loss: 0.010706
 >> iter 37000, loss: 0.010678
 >> iter 38000, loss: 0.010613
 >> iter 39000, loss: 0.010591
 >> iter 40000, loss: 0.010535
   Number of active neurons: 7
 >> iter 41000, loss: 0.010522
 >> iter 42000, loss: 0.010472
 >> iter 43000, loss: 0.010462
 >> iter 44000, loss: 0.010419
 >> iter 45000, loss: 0.010409
 >> iter 46000, loss: 0.010370
 >> iter 47000, loss: 0.010362
 >> iter 48000, loss: 0.010327
 >> iter 49000, loss: 0.010324
 >> iter 50000, loss: 0.010292
   Number of active neurons: 7
 >> iter 51000, loss: 0.010291
 >> iter 52000, loss: 0.010259
 >> iter 53000, loss: 0.010255
 >> iter 54000, loss: 0.010226
 >> iter 55000, loss: 0.010213
 >> iter 56000, loss: 0.010187
 >> iter 57000, loss: 0.010168
 >> iter 58000, loss: 0.010148
 >> iter 59000, loss: 0.010122
 >> iter 60000, loss: 0.010102
   Number of active neurons: 7
 >> iter 61000, loss: 0.010067
 >> iter 62000, loss: 0.010043
 >> iter 63000, loss: 0.010002
 >> iter 64000, loss: 0.009983
 >> iter 65000, loss: 0.009948
 >> iter 66000, loss: 0.009940
 >> iter 67000, loss: 0.009904
 >> iter 68000, loss: 0.009904
 >> iter 69000, loss: 0.009865
 >> iter 70000, loss: 0.009866
   Number of active neurons: 6
 >> iter 71000, loss: 0.009825
 >> iter 72000, loss: 0.009830
 >> iter 73000, loss: 0.009786
 >> iter 74000, loss: 0.009788
 >> iter 75000, loss: 0.009735
 >> iter 76000, loss: 0.009734
 >> iter 77000, loss: 0.009676
 >> iter 78000, loss: 0.009679
 >> iter 79000, loss: 0.009629
 >> iter 80000, loss: 0.009628
   Number of active neurons: 6
 >> iter 81000, loss: 0.009575
 >> iter 82000, loss: 0.009570
 >> iter 83000, loss: 0.009508
 >> iter 84000, loss: 0.009503
 >> iter 85000, loss: 0.009446
 >> iter 86000, loss: 0.009443
 >> iter 87000, loss: 0.009388
 >> iter 88000, loss: 0.009386
 >> iter 89000, loss: 0.009335
 >> iter 90000, loss: 0.009332
   Number of active neurons: 6
 >> iter 91000, loss: 0.009281
 >> iter 92000, loss: 0.009283
 >> iter 93000, loss: 0.009233
 >> iter 94000, loss: 0.009236
 >> iter 95000, loss: 0.009197
 >> iter 96000, loss: 0.009198
 >> iter 97000, loss: 0.009160
 >> iter 98000, loss: 0.009162
 >> iter 99000, loss: 0.009127
 >> iter 100000, loss: 0.009130
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.555067
 >> iter 2000, loss: 10.506601
 >> iter 3000, loss: 8.641666
 >> iter 4000, loss: 7.927641
 >> iter 5000, loss: 7.606123
 >> iter 6000, loss: 6.896759
 >> iter 7000, loss: 2.651645
 >> iter 8000, loss: 1.006576
 >> iter 9000, loss: 0.390843
 >> iter 10000, loss: 0.159666
   Number of active neurons: 9
 >> iter 11000, loss: 0.072150
 >> iter 12000, loss: 0.038285
 >> iter 13000, loss: 0.024779
 >> iter 14000, loss: 0.018973
 >> iter 15000, loss: 0.016290
 >> iter 16000, loss: 0.014808
 >> iter 17000, loss: 0.014007
 >> iter 18000, loss: 0.013411
 >> iter 19000, loss: 0.013026
 >> iter 20000, loss: 0.012655
   Number of active neurons: 9
 >> iter 21000, loss: 0.012405
 >> iter 22000, loss: 0.012130
 >> iter 23000, loss: 0.011944
 >> iter 24000, loss: 0.011735
 >> iter 25000, loss: 0.011594
 >> iter 26000, loss: 0.011423
 >> iter 27000, loss: 0.011306
 >> iter 28000, loss: 0.011163
 >> iter 29000, loss: 0.011067
 >> iter 30000, loss: 0.010949
   Number of active neurons: 8
 >> iter 31000, loss: 0.010870
 >> iter 32000, loss: 0.010763
 >> iter 33000, loss: 0.010701
 >> iter 34000, loss: 0.010607
 >> iter 35000, loss: 0.010545
 >> iter 36000, loss: 0.010443
 >> iter 37000, loss: 0.010383
 >> iter 38000, loss: 0.010296
 >> iter 39000, loss: 0.010240
 >> iter 40000, loss: 0.010160
   Number of active neurons: 8
 >> iter 41000, loss: 0.010109
 >> iter 42000, loss: 0.010036
 >> iter 43000, loss: 0.009991
 >> iter 44000, loss: 0.009924
 >> iter 45000, loss: 0.009887
 >> iter 46000, loss: 0.009829
 >> iter 47000, loss: 0.009799
 >> iter 48000, loss: 0.009744
 >> iter 49000, loss: 0.009722
 >> iter 50000, loss: 0.009675
   Number of active neurons: 8
 >> iter 51000, loss: 0.009659
 >> iter 52000, loss: 0.009618
 >> iter 53000, loss: 0.009603
 >> iter 54000, loss: 0.009571
 >> iter 55000, loss: 0.009553
 >> iter 56000, loss: 0.009527
 >> iter 57000, loss: 0.009509
 >> iter 58000, loss: 0.009488
 >> iter 59000, loss: 0.009468
 >> iter 60000, loss: 0.009451
   Number of active neurons: 8
 >> iter 61000, loss: 0.009431
 >> iter 62000, loss: 0.009411
 >> iter 63000, loss: 0.009387
 >> iter 64000, loss: 0.009368
 >> iter 65000, loss: 0.009345
 >> iter 66000, loss: 0.009327
 >> iter 67000, loss: 0.009304
 >> iter 68000, loss: 0.009290
 >> iter 69000, loss: 0.009268
 >> iter 70000, loss: 0.009254
   Number of active neurons: 8
 >> iter 71000, loss: 0.009233
 >> iter 72000, loss: 0.009223
 >> iter 73000, loss: 0.009202
 >> iter 74000, loss: 0.009194
 >> iter 75000, loss: 0.009172
 >> iter 76000, loss: 0.009166
 >> iter 77000, loss: 0.009143
 >> iter 78000, loss: 0.009138
 >> iter 79000, loss: 0.009118
 >> iter 80000, loss: 0.009114
   Number of active neurons: 8
 >> iter 81000, loss: 0.009092
 >> iter 82000, loss: 0.009090
 >> iter 83000, loss: 0.009066
 >> iter 84000, loss: 0.009067
 >> iter 85000, loss: 0.009042
 >> iter 86000, loss: 0.009048
 >> iter 87000, loss: 0.009021
 >> iter 88000, loss: 0.009026
 >> iter 89000, loss: 0.008998
 >> iter 90000, loss: 0.008998
   Number of active neurons: 8
 >> iter 91000, loss: 0.008956
 >> iter 92000, loss: 0.008954
 >> iter 93000, loss: 0.008910
 >> iter 94000, loss: 0.008910
 >> iter 95000, loss: 0.008874
 >> iter 96000, loss: 0.008877
 >> iter 97000, loss: 0.008844
 >> iter 98000, loss: 0.008848
 >> iter 99000, loss: 0.008817
 >> iter 100000, loss: 0.008824
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.586703
 >> iter 2000, loss: 10.525757
 >> iter 3000, loss: 8.656008
 >> iter 4000, loss: 7.949283
 >> iter 5000, loss: 7.695613
 >> iter 6000, loss: 7.580365
 >> iter 7000, loss: 7.585132
 >> iter 8000, loss: 7.272773
 >> iter 9000, loss: 6.245551
 >> iter 10000, loss: 3.690046
   Number of active neurons: 8
 >> iter 11000, loss: 1.408128
 >> iter 12000, loss: 0.545897
 >> iter 13000, loss: 0.220873
 >> iter 14000, loss: 0.097668
 >> iter 15000, loss: 0.049855
 >> iter 16000, loss: 0.030857
 >> iter 17000, loss: 0.022725
 >> iter 18000, loss: 0.019075
 >> iter 19000, loss: 0.017104
 >> iter 20000, loss: 0.016020
   Number of active neurons: 7
 >> iter 21000, loss: 0.015233
 >> iter 22000, loss: 0.014722
 >> iter 23000, loss: 0.014251
 >> iter 24000, loss: 0.013920
 >> iter 25000, loss: 0.013567
 >> iter 26000, loss: 0.013344
 >> iter 27000, loss: 0.013096
 >> iter 28000, loss: 0.012967
 >> iter 29000, loss: 0.012790
 >> iter 30000, loss: 0.012723
   Number of active neurons: 7
 >> iter 31000, loss: 0.012593
 >> iter 32000, loss: 0.012561
 >> iter 33000, loss: 0.012456
 >> iter 34000, loss: 0.012448
 >> iter 35000, loss: 0.012366
 >> iter 36000, loss: 0.012378
 >> iter 37000, loss: 0.012296
 >> iter 38000, loss: 0.012326
 >> iter 39000, loss: 0.012247
 >> iter 40000, loss: 0.012294
   Number of active neurons: 7
 >> iter 41000, loss: 0.012205
 >> iter 42000, loss: 0.012261
 >> iter 43000, loss: 0.012172
 >> iter 44000, loss: 0.012242
 >> iter 45000, loss: 0.012158
 >> iter 46000, loss: 0.012242
 >> iter 47000, loss: 0.012158
 >> iter 48000, loss: 0.012236
 >> iter 49000, loss: 0.012145
 >> iter 50000, loss: 0.012211
   Number of active neurons: 7
 >> iter 51000, loss: 0.012111
 >> iter 52000, loss: 0.012158
 >> iter 53000, loss: 0.012034
 >> iter 54000, loss: 0.012046
 >> iter 55000, loss: 0.011899
 >> iter 56000, loss: 0.011888
 >> iter 57000, loss: 0.011722
 >> iter 58000, loss: 0.011686
 >> iter 59000, loss: 0.011504
 >> iter 60000, loss: 0.011450
   Number of active neurons: 7
 >> iter 61000, loss: 0.011264
 >> iter 62000, loss: 0.011204
 >> iter 63000, loss: 0.011035
 >> iter 64000, loss: 0.010990
 >> iter 65000, loss: 0.010856
 >> iter 66000, loss: 0.010832
 >> iter 67000, loss: 0.010730
 >> iter 68000, loss: 0.010733
 >> iter 69000, loss: 0.010660
 >> iter 70000, loss: 0.010681
   Number of active neurons: 7
 >> iter 71000, loss: 0.010630
 >> iter 72000, loss: 0.010662
 >> iter 73000, loss: 0.010624
 >> iter 74000, loss: 0.010663
 >> iter 75000, loss: 0.010634
 >> iter 76000, loss: 0.010677
 >> iter 77000, loss: 0.010648
 >> iter 78000, loss: 0.010685
 >> iter 79000, loss: 0.010661
 >> iter 80000, loss: 0.010693
   Number of active neurons: 7
 >> iter 81000, loss: 0.010667
 >> iter 82000, loss: 0.010691
 >> iter 83000, loss: 0.010671
 >> iter 84000, loss: 0.010692
 >> iter 85000, loss: 0.010680
 >> iter 86000, loss: 0.010698
 >> iter 87000, loss: 0.010688
 >> iter 88000, loss: 0.010705
 >> iter 89000, loss: 0.010696
 >> iter 90000, loss: 0.010714
   Number of active neurons: 7
 >> iter 91000, loss: 0.010707
 >> iter 92000, loss: 0.010725
 >> iter 93000, loss: 0.010719
 >> iter 94000, loss: 0.010734
 >> iter 95000, loss: 0.010730
 >> iter 96000, loss: 0.010742
 >> iter 97000, loss: 0.010742
 >> iter 98000, loss: 0.010747
 >> iter 99000, loss: 0.010747
 >> iter 100000, loss: 0.010746
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.593700
 >> iter 2000, loss: 10.528708
 >> iter 3000, loss: 8.653640
 >> iter 4000, loss: 7.940684
 >> iter 5000, loss: 7.683789
 >> iter 6000, loss: 7.572481
 >> iter 7000, loss: 7.566768
 >> iter 8000, loss: 7.304676
 >> iter 9000, loss: 6.885773
 >> iter 10000, loss: 2.973166
   Number of active neurons: 10
 >> iter 11000, loss: 1.119402
 >> iter 12000, loss: 0.428987
 >> iter 13000, loss: 0.171618
 >> iter 14000, loss: 0.074922
 >> iter 15000, loss: 0.038220
 >> iter 16000, loss: 0.023822
 >> iter 17000, loss: 0.018008
 >> iter 18000, loss: 0.015360
 >> iter 19000, loss: 0.014121
 >> iter 20000, loss: 0.013330
   Number of active neurons: 10
 >> iter 21000, loss: 0.012884
 >> iter 22000, loss: 0.012469
 >> iter 23000, loss: 0.012213
 >> iter 24000, loss: 0.011920
 >> iter 25000, loss: 0.011751
 >> iter 26000, loss: 0.011522
 >> iter 27000, loss: 0.011403
 >> iter 28000, loss: 0.011214
 >> iter 29000, loss: 0.011123
 >> iter 30000, loss: 0.010965
   Number of active neurons: 10
 >> iter 31000, loss: 0.010903
 >> iter 32000, loss: 0.010774
 >> iter 33000, loss: 0.010733
 >> iter 34000, loss: 0.010619
 >> iter 35000, loss: 0.010589
 >> iter 36000, loss: 0.010487
 >> iter 37000, loss: 0.010451
 >> iter 38000, loss: 0.010358
 >> iter 39000, loss: 0.010318
 >> iter 40000, loss: 0.010226
   Number of active neurons: 10
 >> iter 41000, loss: 0.010184
 >> iter 42000, loss: 0.010105
 >> iter 43000, loss: 0.010069
 >> iter 44000, loss: 0.009999
 >> iter 45000, loss: 0.009954
 >> iter 46000, loss: 0.009885
 >> iter 47000, loss: 0.009840
 >> iter 48000, loss: 0.009774
 >> iter 49000, loss: 0.009726
 >> iter 50000, loss: 0.009661
   Number of active neurons: 8
 >> iter 51000, loss: 0.009608
 >> iter 52000, loss: 0.009547
 >> iter 53000, loss: 0.009502
 >> iter 54000, loss: 0.009456
 >> iter 55000, loss: 0.009418
 >> iter 56000, loss: 0.009380
 >> iter 57000, loss: 0.009340
 >> iter 58000, loss: 0.009306
 >> iter 59000, loss: 0.009261
 >> iter 60000, loss: 0.009226
   Number of active neurons: 7
 >> iter 61000, loss: 0.009180
 >> iter 62000, loss: 0.009145
 >> iter 63000, loss: 0.009096
 >> iter 64000, loss: 0.009063
 >> iter 65000, loss: 0.009008
 >> iter 66000, loss: 0.008977
 >> iter 67000, loss: 0.008923
 >> iter 68000, loss: 0.008896
 >> iter 69000, loss: 0.008843
 >> iter 70000, loss: 0.008815
   Number of active neurons: 7
 >> iter 71000, loss: 0.008754
 >> iter 72000, loss: 0.008722
 >> iter 73000, loss: 0.008657
 >> iter 74000, loss: 0.008631
 >> iter 75000, loss: 0.008572
 >> iter 76000, loss: 0.008559
 >> iter 77000, loss: 0.008510
 >> iter 78000, loss: 0.008508
 >> iter 79000, loss: 0.008467
 >> iter 80000, loss: 0.008471
   Number of active neurons: 7
 >> iter 81000, loss: 0.008431
 >> iter 82000, loss: 0.008437
 >> iter 83000, loss: 0.008396
 >> iter 84000, loss: 0.008406
 >> iter 85000, loss: 0.008367
 >> iter 86000, loss: 0.008382
 >> iter 87000, loss: 0.008343
 >> iter 88000, loss: 0.008360
 >> iter 89000, loss: 0.008321
 >> iter 90000, loss: 0.008341
   Number of active neurons: 7
 >> iter 91000, loss: 0.008302
 >> iter 92000, loss: 0.008326
 >> iter 93000, loss: 0.008284
 >> iter 94000, loss: 0.008310
 >> iter 95000, loss: 0.008272
 >> iter 96000, loss: 0.008298
 >> iter 97000, loss: 0.008260
 >> iter 98000, loss: 0.008286
 >> iter 99000, loss: 0.008247
 >> iter 100000, loss: 0.008274
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.547149
 >> iter 2000, loss: 10.494724
 >> iter 3000, loss: 8.634405
 >> iter 4000, loss: 7.931747
 >> iter 5000, loss: 7.671596
 >> iter 6000, loss: 7.576096
 >> iter 7000, loss: 7.300188
 >> iter 8000, loss: 3.871912
 >> iter 9000, loss: 1.466161
 >> iter 10000, loss: 0.562388
   Number of active neurons: 7
 >> iter 11000, loss: 0.223632
 >> iter 12000, loss: 0.095771
 >> iter 13000, loss: 0.046875
 >> iter 14000, loss: 0.027609
 >> iter 15000, loss: 0.019689
 >> iter 16000, loss: 0.016120
 >> iter 17000, loss: 0.014367
 >> iter 18000, loss: 0.013336
 >> iter 19000, loss: 0.012701
 >> iter 20000, loss: 0.012227
   Number of active neurons: 7
 >> iter 21000, loss: 0.011893
 >> iter 22000, loss: 0.011612
 >> iter 23000, loss: 0.011403
 >> iter 24000, loss: 0.011222
 >> iter 25000, loss: 0.011088
 >> iter 26000, loss: 0.010970
 >> iter 27000, loss: 0.010880
 >> iter 28000, loss: 0.010797
 >> iter 29000, loss: 0.010736
 >> iter 30000, loss: 0.010684
   Number of active neurons: 7
 >> iter 31000, loss: 0.010643
 >> iter 32000, loss: 0.010595
 >> iter 33000, loss: 0.010550
 >> iter 34000, loss: 0.010493
 >> iter 35000, loss: 0.010452
 >> iter 36000, loss: 0.010404
 >> iter 37000, loss: 0.010373
 >> iter 38000, loss: 0.010340
 >> iter 39000, loss: 0.010316
 >> iter 40000, loss: 0.010288
   Number of active neurons: 7
 >> iter 41000, loss: 0.010269
 >> iter 42000, loss: 0.010238
 >> iter 43000, loss: 0.010217
 >> iter 44000, loss: 0.010187
 >> iter 45000, loss: 0.010170
 >> iter 46000, loss: 0.010141
 >> iter 47000, loss: 0.010118
 >> iter 48000, loss: 0.010085
 >> iter 49000, loss: 0.010068
 >> iter 50000, loss: 0.010041
   Number of active neurons: 7
 >> iter 51000, loss: 0.010024
 >> iter 52000, loss: 0.010001
 >> iter 53000, loss: 0.009983
 >> iter 54000, loss: 0.009968
 >> iter 55000, loss: 0.009946
 >> iter 56000, loss: 0.009937
 >> iter 57000, loss: 0.009913
 >> iter 58000, loss: 0.009907
 >> iter 59000, loss: 0.009882
 >> iter 60000, loss: 0.009878
   Number of active neurons: 7
 >> iter 61000, loss: 0.009852
 >> iter 62000, loss: 0.009849
 >> iter 63000, loss: 0.009820
 >> iter 64000, loss: 0.009816
 >> iter 65000, loss: 0.009785
 >> iter 66000, loss: 0.009781
 >> iter 67000, loss: 0.009750
 >> iter 68000, loss: 0.009746
 >> iter 69000, loss: 0.009713
 >> iter 70000, loss: 0.009707
   Number of active neurons: 7
 >> iter 71000, loss: 0.009667
 >> iter 72000, loss: 0.009655
 >> iter 73000, loss: 0.009616
 >> iter 74000, loss: 0.009606
 >> iter 75000, loss: 0.009566
 >> iter 76000, loss: 0.009555
 >> iter 77000, loss: 0.009513
 >> iter 78000, loss: 0.009504
 >> iter 79000, loss: 0.009466
 >> iter 80000, loss: 0.009458
   Number of active neurons: 7
 >> iter 81000, loss: 0.009421
 >> iter 82000, loss: 0.009418
 >> iter 83000, loss: 0.009379
 >> iter 84000, loss: 0.009380
 >> iter 85000, loss: 0.009343
 >> iter 86000, loss: 0.009347
 >> iter 87000, loss: 0.009309
 >> iter 88000, loss: 0.009314
 >> iter 89000, loss: 0.009274
 >> iter 90000, loss: 0.009279
   Number of active neurons: 7
 >> iter 91000, loss: 0.009234
 >> iter 92000, loss: 0.009237
 >> iter 93000, loss: 0.009189
 >> iter 94000, loss: 0.009193
 >> iter 95000, loss: 0.009151
 >> iter 96000, loss: 0.009155
 >> iter 97000, loss: 0.009113
 >> iter 98000, loss: 0.009118
 >> iter 99000, loss: 0.009078
 >> iter 100000, loss: 0.009082
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.600260
 >> iter 2000, loss: 10.530998
 >> iter 3000, loss: 8.657836
 >> iter 4000, loss: 7.944048
 >> iter 5000, loss: 7.702881
 >> iter 6000, loss: 7.570043
 >> iter 7000, loss: 7.315745
 >> iter 8000, loss: 5.560766
 >> iter 9000, loss: 2.098510
 >> iter 10000, loss: 0.796022
   Number of active neurons: 9
 >> iter 11000, loss: 0.309907
 >> iter 12000, loss: 0.127871
 >> iter 13000, loss: 0.059095
 >> iter 14000, loss: 0.032616
 >> iter 15000, loss: 0.022092
 >> iter 16000, loss: 0.017620
 >> iter 17000, loss: 0.015576
 >> iter 18000, loss: 0.014475
 >> iter 19000, loss: 0.013854
 >> iter 20000, loss: 0.013415
   Number of active neurons: 9
 >> iter 21000, loss: 0.013130
 >> iter 22000, loss: 0.012886
 >> iter 23000, loss: 0.012711
 >> iter 24000, loss: 0.012547
 >> iter 25000, loss: 0.012424
 >> iter 26000, loss: 0.012312
 >> iter 27000, loss: 0.012229
 >> iter 28000, loss: 0.012140
 >> iter 29000, loss: 0.012064
 >> iter 30000, loss: 0.011988
   Number of active neurons: 9
 >> iter 31000, loss: 0.011925
 >> iter 32000, loss: 0.011862
 >> iter 33000, loss: 0.011819
 >> iter 34000, loss: 0.011767
 >> iter 35000, loss: 0.011733
 >> iter 36000, loss: 0.011686
 >> iter 37000, loss: 0.011659
 >> iter 38000, loss: 0.011622
 >> iter 39000, loss: 0.011598
 >> iter 40000, loss: 0.011562
   Number of active neurons: 9
 >> iter 41000, loss: 0.011534
 >> iter 42000, loss: 0.011496
 >> iter 43000, loss: 0.011474
 >> iter 44000, loss: 0.011438
 >> iter 45000, loss: 0.011417
 >> iter 46000, loss: 0.011379
 >> iter 47000, loss: 0.011353
 >> iter 48000, loss: 0.011306
 >> iter 49000, loss: 0.011281
 >> iter 50000, loss: 0.011240
   Number of active neurons: 9
 >> iter 51000, loss: 0.011217
 >> iter 52000, loss: 0.011179
 >> iter 53000, loss: 0.011152
 >> iter 54000, loss: 0.011124
 >> iter 55000, loss: 0.011098
 >> iter 56000, loss: 0.011082
 >> iter 57000, loss: 0.011061
 >> iter 58000, loss: 0.011055
 >> iter 59000, loss: 0.011036
 >> iter 60000, loss: 0.011036
   Number of active neurons: 9
 >> iter 61000, loss: 0.011019
 >> iter 62000, loss: 0.011021
 >> iter 63000, loss: 0.011004
 >> iter 64000, loss: 0.011009
 >> iter 65000, loss: 0.010990
 >> iter 66000, loss: 0.010991
 >> iter 67000, loss: 0.010971
 >> iter 68000, loss: 0.010975
 >> iter 69000, loss: 0.010955
 >> iter 70000, loss: 0.010959
   Number of active neurons: 9
 >> iter 71000, loss: 0.010940
 >> iter 72000, loss: 0.010946
 >> iter 73000, loss: 0.010924
 >> iter 74000, loss: 0.010927
 >> iter 75000, loss: 0.010902
 >> iter 76000, loss: 0.010907
 >> iter 77000, loss: 0.010880
 >> iter 78000, loss: 0.010883
 >> iter 79000, loss: 0.010853
 >> iter 80000, loss: 0.010853
   Number of active neurons: 9
 >> iter 81000, loss: 0.010823
 >> iter 82000, loss: 0.010829
 >> iter 83000, loss: 0.010797
 >> iter 84000, loss: 0.010806
 >> iter 85000, loss: 0.010775
 >> iter 86000, loss: 0.010790
 >> iter 87000, loss: 0.010755
 >> iter 88000, loss: 0.010761
 >> iter 89000, loss: 0.010711
 >> iter 90000, loss: 0.010705
   Number of active neurons: 9
 >> iter 91000, loss: 0.010648
 >> iter 92000, loss: 0.010648
 >> iter 93000, loss: 0.010596
 >> iter 94000, loss: 0.010603
 >> iter 95000, loss: 0.010562
 >> iter 96000, loss: 0.010571
 >> iter 97000, loss: 0.010536
 >> iter 98000, loss: 0.010542
 >> iter 99000, loss: 0.010506
 >> iter 100000, loss: 0.010514
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.607890
 >> iter 2000, loss: 10.544851
 >> iter 3000, loss: 8.674296
 >> iter 4000, loss: 7.968587
 >> iter 5000, loss: 7.710543
 >> iter 6000, loss: 7.581465
 >> iter 7000, loss: 7.475208
 >> iter 8000, loss: 6.932416
 >> iter 9000, loss: 5.997588
 >> iter 10000, loss: 3.213902
   Number of active neurons: 8
 >> iter 11000, loss: 1.230824
 >> iter 12000, loss: 0.480469
 >> iter 13000, loss: 0.197712
 >> iter 14000, loss: 0.090138
 >> iter 15000, loss: 0.048452
 >> iter 16000, loss: 0.031698
 >> iter 17000, loss: 0.024588
 >> iter 18000, loss: 0.021282
 >> iter 19000, loss: 0.019556
 >> iter 20000, loss: 0.018534
   Number of active neurons: 8
 >> iter 21000, loss: 0.017837
 >> iter 22000, loss: 0.017332
 >> iter 23000, loss: 0.016908
 >> iter 24000, loss: 0.016567
 >> iter 25000, loss: 0.016275
 >> iter 26000, loss: 0.016027
 >> iter 27000, loss: 0.015815
 >> iter 28000, loss: 0.015634
 >> iter 29000, loss: 0.015475
 >> iter 30000, loss: 0.015334
   Number of active neurons: 8
 >> iter 31000, loss: 0.015210
 >> iter 32000, loss: 0.015100
 >> iter 33000, loss: 0.014989
 >> iter 34000, loss: 0.014887
 >> iter 35000, loss: 0.014790
 >> iter 36000, loss: 0.014684
 >> iter 37000, loss: 0.014577
 >> iter 38000, loss: 0.014470
 >> iter 39000, loss: 0.014349
 >> iter 40000, loss: 0.014230
   Number of active neurons: 8
 >> iter 41000, loss: 0.014103
 >> iter 42000, loss: 0.013989
 >> iter 43000, loss: 0.013856
 >> iter 44000, loss: 0.013748
 >> iter 45000, loss: 0.013653
 >> iter 46000, loss: 0.013585
 >> iter 47000, loss: 0.013490
 >> iter 48000, loss: 0.013409
 >> iter 49000, loss: 0.013319
 >> iter 50000, loss: 0.013249
   Number of active neurons: 8
 >> iter 51000, loss: 0.013172
 >> iter 52000, loss: 0.013109
 >> iter 53000, loss: 0.013046
 >> iter 54000, loss: 0.012986
 >> iter 55000, loss: 0.012914
 >> iter 56000, loss: 0.012851
 >> iter 57000, loss: 0.012778
 >> iter 58000, loss: 0.012725
 >> iter 59000, loss: 0.012651
 >> iter 60000, loss: 0.012608
   Number of active neurons: 8
 >> iter 61000, loss: 0.012537
 >> iter 62000, loss: 0.012496
 >> iter 63000, loss: 0.012423
 >> iter 64000, loss: 0.012385
 >> iter 65000, loss: 0.012317
 >> iter 66000, loss: 0.012282
 >> iter 67000, loss: 0.012216
 >> iter 68000, loss: 0.012188
 >> iter 69000, loss: 0.012123
 >> iter 70000, loss: 0.012098
   Number of active neurons: 8
 >> iter 71000, loss: 0.012034
 >> iter 72000, loss: 0.012012
 >> iter 73000, loss: 0.011950
 >> iter 74000, loss: 0.011932
 >> iter 75000, loss: 0.011872
 >> iter 76000, loss: 0.011861
 >> iter 77000, loss: 0.011802
 >> iter 78000, loss: 0.011790
 >> iter 79000, loss: 0.011735
 >> iter 80000, loss: 0.011714
   Number of active neurons: 8
 >> iter 81000, loss: 0.011655
 >> iter 82000, loss: 0.011640
 >> iter 83000, loss: 0.011586
 >> iter 84000, loss: 0.011565
 >> iter 85000, loss: 0.011513
 >> iter 86000, loss: 0.011498
 >> iter 87000, loss: 0.011447
 >> iter 88000, loss: 0.011436
 >> iter 89000, loss: 0.011381
 >> iter 90000, loss: 0.011377
   Number of active neurons: 8
 >> iter 91000, loss: 0.011322
 >> iter 92000, loss: 0.011314
 >> iter 93000, loss: 0.011261
 >> iter 94000, loss: 0.011246
 >> iter 95000, loss: 0.011198
 >> iter 96000, loss: 0.011182
 >> iter 97000, loss: 0.011137
 >> iter 98000, loss: 0.011119
 >> iter 99000, loss: 0.011074
 >> iter 100000, loss: 0.011059
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.646205
 >> iter 2000, loss: 10.545646
 >> iter 3000, loss: 8.663009
 >> iter 4000, loss: 7.957467
 >> iter 5000, loss: 7.706309
 >> iter 6000, loss: 7.597544
 >> iter 7000, loss: 7.566309
 >> iter 8000, loss: 7.474012
 >> iter 9000, loss: 7.084209
 >> iter 10000, loss: 5.037750
   Number of active neurons: 8
 >> iter 11000, loss: 1.915195
 >> iter 12000, loss: 0.730702
 >> iter 13000, loss: 0.286327
 >> iter 14000, loss: 0.119197
 >> iter 15000, loss: 0.055754
 >> iter 16000, loss: 0.031121
 >> iter 17000, loss: 0.021212
 >> iter 18000, loss: 0.016909
 >> iter 19000, loss: 0.014884
 >> iter 20000, loss: 0.013761
   Number of active neurons: 8
 >> iter 21000, loss: 0.013080
 >> iter 22000, loss: 0.012582
 >> iter 23000, loss: 0.012220
 >> iter 24000, loss: 0.011918
 >> iter 25000, loss: 0.011682
 >> iter 26000, loss: 0.011485
 >> iter 27000, loss: 0.011324
 >> iter 28000, loss: 0.011192
 >> iter 29000, loss: 0.011077
 >> iter 30000, loss: 0.010990
   Number of active neurons: 8
 >> iter 31000, loss: 0.010910
 >> iter 32000, loss: 0.010850
 >> iter 33000, loss: 0.010793
 >> iter 34000, loss: 0.010753
 >> iter 35000, loss: 0.010704
 >> iter 36000, loss: 0.010667
 >> iter 37000, loss: 0.010625
 >> iter 38000, loss: 0.010598
 >> iter 39000, loss: 0.010552
 >> iter 40000, loss: 0.010525
   Number of active neurons: 7
 >> iter 41000, loss: 0.010480
 >> iter 42000, loss: 0.010460
 >> iter 43000, loss: 0.010421
 >> iter 44000, loss: 0.010402
 >> iter 45000, loss: 0.010368
 >> iter 46000, loss: 0.010344
 >> iter 47000, loss: 0.010298
 >> iter 48000, loss: 0.010262
 >> iter 49000, loss: 0.010221
 >> iter 50000, loss: 0.010191
   Number of active neurons: 7
 >> iter 51000, loss: 0.010154
 >> iter 52000, loss: 0.010127
 >> iter 53000, loss: 0.010077
 >> iter 54000, loss: 0.010045
 >> iter 55000, loss: 0.009985
 >> iter 56000, loss: 0.009957
 >> iter 57000, loss: 0.009897
 >> iter 58000, loss: 0.009875
 >> iter 59000, loss: 0.009816
 >> iter 60000, loss: 0.009797
   Number of active neurons: 7
 >> iter 61000, loss: 0.009742
 >> iter 62000, loss: 0.009730
 >> iter 63000, loss: 0.009680
 >> iter 64000, loss: 0.009675
 >> iter 65000, loss: 0.009632
 >> iter 66000, loss: 0.009629
 >> iter 67000, loss: 0.009587
 >> iter 68000, loss: 0.009583
 >> iter 69000, loss: 0.009531
 >> iter 70000, loss: 0.009519
   Number of active neurons: 6
 >> iter 71000, loss: 0.009462
 >> iter 72000, loss: 0.009444
 >> iter 73000, loss: 0.009383
 >> iter 74000, loss: 0.009364
 >> iter 75000, loss: 0.009300
 >> iter 76000, loss: 0.009280
 >> iter 77000, loss: 0.009213
 >> iter 78000, loss: 0.009193
 >> iter 79000, loss: 0.009127
 >> iter 80000, loss: 0.009109
   Number of active neurons: 7
 >> iter 81000, loss: 0.009040
 >> iter 82000, loss: 0.009025
 >> iter 83000, loss: 0.008956
 >> iter 84000, loss: 0.008944
 >> iter 85000, loss: 0.008876
 >> iter 86000, loss: 0.008866
 >> iter 87000, loss: 0.008797
 >> iter 88000, loss: 0.008783
 >> iter 89000, loss: 0.008708
 >> iter 90000, loss: 0.008694
   Number of active neurons: 7
 >> iter 91000, loss: 0.008621
 >> iter 92000, loss: 0.008613
 >> iter 93000, loss: 0.008542
 >> iter 94000, loss: 0.008533
 >> iter 95000, loss: 0.008463
 >> iter 96000, loss: 0.008460
 >> iter 97000, loss: 0.008393
 >> iter 98000, loss: 0.008392
 >> iter 99000, loss: 0.008327
 >> iter 100000, loss: 0.008328
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.544339
 >> iter 2000, loss: 10.503373
 >> iter 3000, loss: 8.646570
 >> iter 4000, loss: 7.939863
 >> iter 5000, loss: 7.704336
 >> iter 6000, loss: 7.435013
 >> iter 7000, loss: 6.859651
 >> iter 8000, loss: 3.463834
 >> iter 9000, loss: 1.448007
 >> iter 10000, loss: 0.572242
   Number of active neurons: 8
 >> iter 11000, loss: 0.238425
 >> iter 12000, loss: 0.108131
 >> iter 13000, loss: 0.057109
 >> iter 14000, loss: 0.036014
 >> iter 15000, loss: 0.027197
 >> iter 16000, loss: 0.022684
 >> iter 17000, loss: 0.020503
 >> iter 18000, loss: 0.018937
 >> iter 19000, loss: 0.018069
 >> iter 20000, loss: 0.017218
   Number of active neurons: 8
 >> iter 21000, loss: 0.016735
 >> iter 22000, loss: 0.016146
 >> iter 23000, loss: 0.015853
 >> iter 24000, loss: 0.015429
 >> iter 25000, loss: 0.015250
 >> iter 26000, loss: 0.014912
 >> iter 27000, loss: 0.014793
 >> iter 28000, loss: 0.014511
 >> iter 29000, loss: 0.014443
 >> iter 30000, loss: 0.014204
   Number of active neurons: 8
 >> iter 31000, loss: 0.014166
 >> iter 32000, loss: 0.013953
 >> iter 33000, loss: 0.013933
 >> iter 34000, loss: 0.013746
 >> iter 35000, loss: 0.013750
 >> iter 36000, loss: 0.013591
 >> iter 37000, loss: 0.013605
 >> iter 38000, loss: 0.013464
 >> iter 39000, loss: 0.013497
 >> iter 40000, loss: 0.013372
   Number of active neurons: 8
 >> iter 41000, loss: 0.013409
 >> iter 42000, loss: 0.013287
 >> iter 43000, loss: 0.013320
 >> iter 44000, loss: 0.013194
 >> iter 45000, loss: 0.013229
 >> iter 46000, loss: 0.013112
 >> iter 47000, loss: 0.013140
 >> iter 48000, loss: 0.013016
 >> iter 49000, loss: 0.013040
 >> iter 50000, loss: 0.012921
   Number of active neurons: 8
 >> iter 51000, loss: 0.012948
 >> iter 52000, loss: 0.012837
 >> iter 53000, loss: 0.012871
 >> iter 54000, loss: 0.012763
 >> iter 55000, loss: 0.012802
 >> iter 56000, loss: 0.012685
 >> iter 57000, loss: 0.012713
 >> iter 58000, loss: 0.012597
 >> iter 59000, loss: 0.012621
 >> iter 60000, loss: 0.012510
   Number of active neurons: 8
 >> iter 61000, loss: 0.012535
 >> iter 62000, loss: 0.012436
 >> iter 63000, loss: 0.012464
 >> iter 64000, loss: 0.012379
 >> iter 65000, loss: 0.012402
 >> iter 66000, loss: 0.012323
 >> iter 67000, loss: 0.012351
 >> iter 68000, loss: 0.012279
 >> iter 69000, loss: 0.012309
 >> iter 70000, loss: 0.012241
   Number of active neurons: 8
 >> iter 71000, loss: 0.012268
 >> iter 72000, loss: 0.012206
 >> iter 73000, loss: 0.012234
 >> iter 74000, loss: 0.012176
 >> iter 75000, loss: 0.012202
 >> iter 76000, loss: 0.012146
 >> iter 77000, loss: 0.012173
 >> iter 78000, loss: 0.012123
 >> iter 79000, loss: 0.012141
 >> iter 80000, loss: 0.012103
   Number of active neurons: 8
 >> iter 81000, loss: 0.012114
 >> iter 82000, loss: 0.012084
 >> iter 83000, loss: 0.012087
 >> iter 84000, loss: 0.012065
 >> iter 85000, loss: 0.012067
 >> iter 86000, loss: 0.012048
 >> iter 87000, loss: 0.012039
 >> iter 88000, loss: 0.012041
 >> iter 89000, loss: 0.012012
 >> iter 90000, loss: 0.012036
   Number of active neurons: 8
 >> iter 91000, loss: 0.011985
 >> iter 92000, loss: 0.012027
 >> iter 93000, loss: 0.011954
 >> iter 94000, loss: 0.012010
 >> iter 95000, loss: 0.011926
 >> iter 96000, loss: 0.011999
 >> iter 97000, loss: 0.011910
 >> iter 98000, loss: 0.012008
 >> iter 99000, loss: 0.011904
 >> iter 100000, loss: 0.012002
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 3.08646090261
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.577218
 >> iter 2000, loss: 10.508683
 >> iter 3000, loss: 8.639688
 >> iter 4000, loss: 7.933105
 >> iter 5000, loss: 7.680506
 >> iter 6000, loss: 7.550955
 >> iter 7000, loss: 7.477229
 >> iter 8000, loss: 6.144228
 >> iter 9000, loss: 2.336342
 >> iter 10000, loss: 0.887819
   Number of active neurons: 7
 >> iter 11000, loss: 0.345291
 >> iter 12000, loss: 0.141449
 >> iter 13000, loss: 0.064141
 >> iter 14000, loss: 0.034198
 >> iter 15000, loss: 0.022202
 >> iter 16000, loss: 0.017055
 >> iter 17000, loss: 0.014654
 >> iter 18000, loss: 0.013344
 >> iter 19000, loss: 0.012573
 >> iter 20000, loss: 0.012019
   Number of active neurons: 7
 >> iter 21000, loss: 0.011630
 >> iter 22000, loss: 0.011304
 >> iter 23000, loss: 0.011063
 >> iter 24000, loss: 0.010849
 >> iter 25000, loss: 0.010689
 >> iter 26000, loss: 0.010540
 >> iter 27000, loss: 0.010428
 >> iter 28000, loss: 0.010315
 >> iter 29000, loss: 0.010233
 >> iter 30000, loss: 0.010148
   Number of active neurons: 7
 >> iter 31000, loss: 0.010089
 >> iter 32000, loss: 0.010019
 >> iter 33000, loss: 0.009973
 >> iter 34000, loss: 0.009913
 >> iter 35000, loss: 0.009874
 >> iter 36000, loss: 0.009812
 >> iter 37000, loss: 0.009773
 >> iter 38000, loss: 0.009724
 >> iter 39000, loss: 0.009695
 >> iter 40000, loss: 0.009654
   Number of active neurons: 7
 >> iter 41000, loss: 0.009630
 >> iter 42000, loss: 0.009589
 >> iter 43000, loss: 0.009566
 >> iter 44000, loss: 0.009523
 >> iter 45000, loss: 0.009503
 >> iter 46000, loss: 0.009464
 >> iter 47000, loss: 0.009447
 >> iter 48000, loss: 0.009408
 >> iter 49000, loss: 0.009393
 >> iter 50000, loss: 0.009357
   Number of active neurons: 7
 >> iter 51000, loss: 0.009346
 >> iter 52000, loss: 0.009316
 >> iter 53000, loss: 0.009303
 >> iter 54000, loss: 0.009280
 >> iter 55000, loss: 0.009260
 >> iter 56000, loss: 0.009243
 >> iter 57000, loss: 0.009224
 >> iter 58000, loss: 0.009211
 >> iter 59000, loss: 0.009190
 >> iter 60000, loss: 0.009178
   Number of active neurons: 7
 >> iter 61000, loss: 0.009153
 >> iter 62000, loss: 0.009139
 >> iter 63000, loss: 0.009115
 >> iter 64000, loss: 0.009104
 >> iter 65000, loss: 0.009080
 >> iter 66000, loss: 0.009071
 >> iter 67000, loss: 0.009048
 >> iter 68000, loss: 0.009042
 >> iter 69000, loss: 0.009019
 >> iter 70000, loss: 0.009012
   Number of active neurons: 7
 >> iter 71000, loss: 0.008986
 >> iter 72000, loss: 0.008977
 >> iter 73000, loss: 0.008950
 >> iter 74000, loss: 0.008944
 >> iter 75000, loss: 0.008918
 >> iter 76000, loss: 0.008915
 >> iter 77000, loss: 0.008888
 >> iter 78000, loss: 0.008887
 >> iter 79000, loss: 0.008863
 >> iter 80000, loss: 0.008863
   Number of active neurons: 7
 >> iter 81000, loss: 0.008838
 >> iter 82000, loss: 0.008841
 >> iter 83000, loss: 0.008814
 >> iter 84000, loss: 0.008819
 >> iter 85000, loss: 0.008792
 >> iter 86000, loss: 0.008801
 >> iter 87000, loss: 0.008772
 >> iter 88000, loss: 0.008779
 >> iter 89000, loss: 0.008748
 >> iter 90000, loss: 0.008757
   Number of active neurons: 7
 >> iter 91000, loss: 0.008725
 >> iter 92000, loss: 0.008738
 >> iter 93000, loss: 0.008704
 >> iter 94000, loss: 0.008717
 >> iter 95000, loss: 0.008688
 >> iter 96000, loss: 0.008701
 >> iter 97000, loss: 0.008672
 >> iter 98000, loss: 0.008685
 >> iter 99000, loss: 0.008658
 >> iter 100000, loss: 0.008668
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.561538
 >> iter 2000, loss: 10.503024
 >> iter 3000, loss: 8.637903
 >> iter 4000, loss: 7.929526
 >> iter 5000, loss: 7.693924
 >> iter 6000, loss: 7.481019
 >> iter 7000, loss: 6.764613
 >> iter 8000, loss: 2.687818
 >> iter 9000, loss: 1.019372
 >> iter 10000, loss: 0.393975
   Number of active neurons: 8
 >> iter 11000, loss: 0.159630
 >> iter 12000, loss: 0.070942
 >> iter 13000, loss: 0.036980
 >> iter 14000, loss: 0.023432
 >> iter 15000, loss: 0.017861
 >> iter 16000, loss: 0.015241
 >> iter 17000, loss: 0.013986
 >> iter 18000, loss: 0.013164
 >> iter 19000, loss: 0.012705
 >> iter 20000, loss: 0.012284
   Number of active neurons: 8
 >> iter 21000, loss: 0.012044
 >> iter 22000, loss: 0.011773
 >> iter 23000, loss: 0.011631
 >> iter 24000, loss: 0.011437
 >> iter 25000, loss: 0.011355
 >> iter 26000, loss: 0.011215
 >> iter 27000, loss: 0.011173
 >> iter 28000, loss: 0.011067
 >> iter 29000, loss: 0.011049
 >> iter 30000, loss: 0.010963
   Number of active neurons: 8
 >> iter 31000, loss: 0.010954
 >> iter 32000, loss: 0.010872
 >> iter 33000, loss: 0.010870
 >> iter 34000, loss: 0.010798
 >> iter 35000, loss: 0.010808
 >> iter 36000, loss: 0.010747
 >> iter 37000, loss: 0.010755
 >> iter 38000, loss: 0.010703
 >> iter 39000, loss: 0.010718
 >> iter 40000, loss: 0.010672
   Number of active neurons: 8
 >> iter 41000, loss: 0.010693
 >> iter 42000, loss: 0.010651
 >> iter 43000, loss: 0.010663
 >> iter 44000, loss: 0.010623
 >> iter 45000, loss: 0.010631
 >> iter 46000, loss: 0.010591
 >> iter 47000, loss: 0.010591
 >> iter 48000, loss: 0.010545
 >> iter 49000, loss: 0.010546
 >> iter 50000, loss: 0.010507
   Number of active neurons: 8
 >> iter 51000, loss: 0.010510
 >> iter 52000, loss: 0.010476
 >> iter 53000, loss: 0.010473
 >> iter 54000, loss: 0.010442
 >> iter 55000, loss: 0.010431
 >> iter 56000, loss: 0.010405
 >> iter 57000, loss: 0.010392
 >> iter 58000, loss: 0.010371
 >> iter 59000, loss: 0.010356
 >> iter 60000, loss: 0.010342
   Number of active neurons: 8
 >> iter 61000, loss: 0.010326
 >> iter 62000, loss: 0.010314
 >> iter 63000, loss: 0.010298
 >> iter 64000, loss: 0.010290
 >> iter 65000, loss: 0.010270
 >> iter 66000, loss: 0.010263
 >> iter 67000, loss: 0.010245
 >> iter 68000, loss: 0.010243
 >> iter 69000, loss: 0.010224
 >> iter 70000, loss: 0.010222
   Number of active neurons: 8
 >> iter 71000, loss: 0.010202
 >> iter 72000, loss: 0.010202
 >> iter 73000, loss: 0.010182
 >> iter 74000, loss: 0.010183
 >> iter 75000, loss: 0.010160
 >> iter 76000, loss: 0.010163
 >> iter 77000, loss: 0.010138
 >> iter 78000, loss: 0.010141
 >> iter 79000, loss: 0.010113
 >> iter 80000, loss: 0.010116
   Number of active neurons: 7
 >> iter 81000, loss: 0.010087
 >> iter 82000, loss: 0.010094
 >> iter 83000, loss: 0.010062
 >> iter 84000, loss: 0.010070
 >> iter 85000, loss: 0.010036
 >> iter 86000, loss: 0.010047
 >> iter 87000, loss: 0.010012
 >> iter 88000, loss: 0.010024
 >> iter 89000, loss: 0.009990
 >> iter 90000, loss: 0.010002
   Number of active neurons: 7
 >> iter 91000, loss: 0.009960
 >> iter 92000, loss: 0.009966
 >> iter 93000, loss: 0.009913
 >> iter 94000, loss: 0.009922
 >> iter 95000, loss: 0.009878
 >> iter 96000, loss: 0.009889
 >> iter 97000, loss: 0.009850
 >> iter 98000, loss: 0.009866
 >> iter 99000, loss: 0.009829
 >> iter 100000, loss: 0.009845
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.541929
 >> iter 2000, loss: 10.493092
 >> iter 3000, loss: 8.630928
 >> iter 4000, loss: 7.913952
 >> iter 5000, loss: 7.620379
 >> iter 6000, loss: 7.254814
 >> iter 7000, loss: 6.295374
 >> iter 8000, loss: 2.388499
 >> iter 9000, loss: 0.905648
 >> iter 10000, loss: 0.351357
   Number of active neurons: 8
 >> iter 11000, loss: 0.143718
 >> iter 12000, loss: 0.065124
 >> iter 13000, loss: 0.034900
 >> iter 14000, loss: 0.022802
 >> iter 15000, loss: 0.017726
 >> iter 16000, loss: 0.015323
 >> iter 17000, loss: 0.014110
 >> iter 18000, loss: 0.013330
 >> iter 19000, loss: 0.012859
 >> iter 20000, loss: 0.012466
   Number of active neurons: 8
 >> iter 21000, loss: 0.012215
 >> iter 22000, loss: 0.011965
 >> iter 23000, loss: 0.011811
 >> iter 24000, loss: 0.011647
 >> iter 25000, loss: 0.011555
 >> iter 26000, loss: 0.011448
 >> iter 27000, loss: 0.011399
 >> iter 28000, loss: 0.011332
 >> iter 29000, loss: 0.011310
 >> iter 30000, loss: 0.011268
   Number of active neurons: 8
 >> iter 31000, loss: 0.011258
 >> iter 32000, loss: 0.011224
 >> iter 33000, loss: 0.011227
 >> iter 34000, loss: 0.011204
 >> iter 35000, loss: 0.011215
 >> iter 36000, loss: 0.011192
 >> iter 37000, loss: 0.011206
 >> iter 38000, loss: 0.011190
 >> iter 39000, loss: 0.011204
 >> iter 40000, loss: 0.011192
   Number of active neurons: 8
 >> iter 41000, loss: 0.011206
 >> iter 42000, loss: 0.011193
 >> iter 43000, loss: 0.011204
 >> iter 44000, loss: 0.011186
 >> iter 45000, loss: 0.011200
 >> iter 46000, loss: 0.011180
 >> iter 47000, loss: 0.011186
 >> iter 48000, loss: 0.011156
 >> iter 49000, loss: 0.011161
 >> iter 50000, loss: 0.011133
   Number of active neurons: 8
 >> iter 51000, loss: 0.011140
 >> iter 52000, loss: 0.011117
 >> iter 53000, loss: 0.011118
 >> iter 54000, loss: 0.011096
 >> iter 55000, loss: 0.011086
 >> iter 56000, loss: 0.011059
 >> iter 57000, loss: 0.011041
 >> iter 58000, loss: 0.011015
 >> iter 59000, loss: 0.010996
 >> iter 60000, loss: 0.010971
   Number of active neurons: 8
 >> iter 61000, loss: 0.010952
 >> iter 62000, loss: 0.010921
 >> iter 63000, loss: 0.010902
 >> iter 64000, loss: 0.010877
 >> iter 65000, loss: 0.010861
 >> iter 66000, loss: 0.010836
 >> iter 67000, loss: 0.010820
 >> iter 68000, loss: 0.010795
 >> iter 69000, loss: 0.010774
 >> iter 70000, loss: 0.010748
   Number of active neurons: 8
 >> iter 71000, loss: 0.010730
 >> iter 72000, loss: 0.010705
 >> iter 73000, loss: 0.010683
 >> iter 74000, loss: 0.010659
 >> iter 75000, loss: 0.010636
 >> iter 76000, loss: 0.010615
 >> iter 77000, loss: 0.010587
 >> iter 78000, loss: 0.010565
 >> iter 79000, loss: 0.010540
 >> iter 80000, loss: 0.010520
   Number of active neurons: 8
 >> iter 81000, loss: 0.010496
 >> iter 82000, loss: 0.010479
 >> iter 83000, loss: 0.010453
 >> iter 84000, loss: 0.010439
 >> iter 85000, loss: 0.010413
 >> iter 86000, loss: 0.010404
 >> iter 87000, loss: 0.010376
 >> iter 88000, loss: 0.010367
 >> iter 89000, loss: 0.010341
 >> iter 90000, loss: 0.010329
   Number of active neurons: 8
 >> iter 91000, loss: 0.010291
 >> iter 92000, loss: 0.010276
 >> iter 93000, loss: 0.010234
 >> iter 94000, loss: 0.010223
 >> iter 95000, loss: 0.010191
 >> iter 96000, loss: 0.010181
 >> iter 97000, loss: 0.010157
 >> iter 98000, loss: 0.010149
 >> iter 99000, loss: 0.010126
 >> iter 100000, loss: 0.010115
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.568885
 >> iter 2000, loss: 10.504440
 >> iter 3000, loss: 8.636025
 >> iter 4000, loss: 7.915858
 >> iter 5000, loss: 7.631550
 >> iter 6000, loss: 7.175783
 >> iter 7000, loss: 4.827713
 >> iter 8000, loss: 1.848006
 >> iter 9000, loss: 0.715063
 >> iter 10000, loss: 0.287168
   Number of active neurons: 8
 >> iter 11000, loss: 0.124663
 >> iter 12000, loss: 0.061786
 >> iter 13000, loss: 0.036738
 >> iter 14000, loss: 0.026133
 >> iter 15000, loss: 0.021258
 >> iter 16000, loss: 0.018678
 >> iter 17000, loss: 0.017150
 >> iter 18000, loss: 0.016086
 >> iter 19000, loss: 0.015335
 >> iter 20000, loss: 0.014706
   Number of active neurons: 8
 >> iter 21000, loss: 0.014251
 >> iter 22000, loss: 0.013843
 >> iter 23000, loss: 0.013543
 >> iter 24000, loss: 0.013250
 >> iter 25000, loss: 0.013035
 >> iter 26000, loss: 0.012804
 >> iter 27000, loss: 0.012637
 >> iter 28000, loss: 0.012458
 >> iter 29000, loss: 0.012339
 >> iter 30000, loss: 0.012189
   Number of active neurons: 8
 >> iter 31000, loss: 0.012087
 >> iter 32000, loss: 0.011951
 >> iter 33000, loss: 0.011868
 >> iter 34000, loss: 0.011755
 >> iter 35000, loss: 0.011695
 >> iter 36000, loss: 0.011609
 >> iter 37000, loss: 0.011561
 >> iter 38000, loss: 0.011490
 >> iter 39000, loss: 0.011452
 >> iter 40000, loss: 0.011379
   Number of active neurons: 8
 >> iter 41000, loss: 0.011334
 >> iter 42000, loss: 0.011257
 >> iter 43000, loss: 0.011206
 >> iter 44000, loss: 0.011131
 >> iter 45000, loss: 0.011082
 >> iter 46000, loss: 0.011014
 >> iter 47000, loss: 0.010963
 >> iter 48000, loss: 0.010888
 >> iter 49000, loss: 0.010838
 >> iter 50000, loss: 0.010770
   Number of active neurons: 8
 >> iter 51000, loss: 0.010715
 >> iter 52000, loss: 0.010645
 >> iter 53000, loss: 0.010594
 >> iter 54000, loss: 0.010524
 >> iter 55000, loss: 0.010475
 >> iter 56000, loss: 0.010414
 >> iter 57000, loss: 0.010373
 >> iter 58000, loss: 0.010321
 >> iter 59000, loss: 0.010290
 >> iter 60000, loss: 0.010245
   Number of active neurons: 8
 >> iter 61000, loss: 0.010214
 >> iter 62000, loss: 0.010178
 >> iter 63000, loss: 0.010157
 >> iter 64000, loss: 0.010133
 >> iter 65000, loss: 0.010120
 >> iter 66000, loss: 0.010099
 >> iter 67000, loss: 0.010092
 >> iter 68000, loss: 0.010080
 >> iter 69000, loss: 0.010082
 >> iter 70000, loss: 0.010073
   Number of active neurons: 8
 >> iter 71000, loss: 0.010078
 >> iter 72000, loss: 0.010073
 >> iter 73000, loss: 0.010075
 >> iter 74000, loss: 0.010059
 >> iter 75000, loss: 0.010059
 >> iter 76000, loss: 0.010044
 >> iter 77000, loss: 0.010046
 >> iter 78000, loss: 0.010032
 >> iter 79000, loss: 0.010035
 >> iter 80000, loss: 0.010021
   Number of active neurons: 7
 >> iter 81000, loss: 0.010022
 >> iter 82000, loss: 0.010011
 >> iter 83000, loss: 0.010011
 >> iter 84000, loss: 0.010000
 >> iter 85000, loss: 0.009998
 >> iter 86000, loss: 0.009987
 >> iter 87000, loss: 0.009984
 >> iter 88000, loss: 0.009973
 >> iter 89000, loss: 0.009962
 >> iter 90000, loss: 0.009948
   Number of active neurons: 7
 >> iter 91000, loss: 0.009931
 >> iter 92000, loss: 0.009914
 >> iter 93000, loss: 0.009896
 >> iter 94000, loss: 0.009879
 >> iter 95000, loss: 0.009861
 >> iter 96000, loss: 0.009842
 >> iter 97000, loss: 0.009824
 >> iter 98000, loss: 0.009808
 >> iter 99000, loss: 0.009791
 >> iter 100000, loss: 0.009771
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.564839
 >> iter 2000, loss: 10.511123
 >> iter 3000, loss: 8.638838
 >> iter 4000, loss: 7.928206
 >> iter 5000, loss: 7.675690
 >> iter 6000, loss: 7.567143
 >> iter 7000, loss: 7.533870
 >> iter 8000, loss: 7.523808
 >> iter 9000, loss: 7.673452
 >> iter 10000, loss: 7.338085
   Number of active neurons: 8
 >> iter 11000, loss: 4.436885
 >> iter 12000, loss: 1.667109
 >> iter 13000, loss: 0.632508
 >> iter 14000, loss: 0.246921
 >> iter 15000, loss: 0.102711
 >> iter 16000, loss: 0.048207
 >> iter 17000, loss: 0.027292
 >> iter 18000, loss: 0.018944
 >> iter 19000, loss: 0.015466
 >> iter 20000, loss: 0.013829
   Number of active neurons: 8
 >> iter 21000, loss: 0.013015
 >> iter 22000, loss: 0.012509
 >> iter 23000, loss: 0.012208
 >> iter 24000, loss: 0.011968
 >> iter 25000, loss: 0.011821
 >> iter 26000, loss: 0.011670
 >> iter 27000, loss: 0.011575
 >> iter 28000, loss: 0.011453
 >> iter 29000, loss: 0.011395
 >> iter 30000, loss: 0.011298
   Number of active neurons: 8
 >> iter 31000, loss: 0.011260
 >> iter 32000, loss: 0.011179
 >> iter 33000, loss: 0.011153
 >> iter 34000, loss: 0.011081
 >> iter 35000, loss: 0.011055
 >> iter 36000, loss: 0.010983
 >> iter 37000, loss: 0.010960
 >> iter 38000, loss: 0.010892
 >> iter 39000, loss: 0.010868
 >> iter 40000, loss: 0.010805
   Number of active neurons: 8
 >> iter 41000, loss: 0.010787
 >> iter 42000, loss: 0.010730
 >> iter 43000, loss: 0.010714
 >> iter 44000, loss: 0.010653
 >> iter 45000, loss: 0.010640
 >> iter 46000, loss: 0.010582
 >> iter 47000, loss: 0.010574
 >> iter 48000, loss: 0.010517
 >> iter 49000, loss: 0.010516
 >> iter 50000, loss: 0.010467
   Number of active neurons: 8
 >> iter 51000, loss: 0.010471
 >> iter 52000, loss: 0.010427
 >> iter 53000, loss: 0.010432
 >> iter 54000, loss: 0.010396
 >> iter 55000, loss: 0.010397
 >> iter 56000, loss: 0.010363
 >> iter 57000, loss: 0.010358
 >> iter 58000, loss: 0.010329
 >> iter 59000, loss: 0.010322
 >> iter 60000, loss: 0.010297
   Number of active neurons: 8
 >> iter 61000, loss: 0.010290
 >> iter 62000, loss: 0.010267
 >> iter 63000, loss: 0.010261
 >> iter 64000, loss: 0.010245
 >> iter 65000, loss: 0.010236
 >> iter 66000, loss: 0.010221
 >> iter 67000, loss: 0.010213
 >> iter 68000, loss: 0.010202
 >> iter 69000, loss: 0.010193
 >> iter 70000, loss: 0.010183
   Number of active neurons: 7
 >> iter 71000, loss: 0.010176
 >> iter 72000, loss: 0.010171
 >> iter 73000, loss: 0.010162
 >> iter 74000, loss: 0.010152
 >> iter 75000, loss: 0.010139
 >> iter 76000, loss: 0.010132
 >> iter 77000, loss: 0.010121
 >> iter 78000, loss: 0.010117
 >> iter 79000, loss: 0.010100
 >> iter 80000, loss: 0.010091
   Number of active neurons: 7
 >> iter 81000, loss: 0.010073
 >> iter 82000, loss: 0.010068
 >> iter 83000, loss: 0.010050
 >> iter 84000, loss: 0.010045
 >> iter 85000, loss: 0.010018
 >> iter 86000, loss: 0.010011
 >> iter 87000, loss: 0.009985
 >> iter 88000, loss: 0.009984
 >> iter 89000, loss: 0.009962
 >> iter 90000, loss: 0.009966
   Number of active neurons: 7
 >> iter 91000, loss: 0.009943
 >> iter 92000, loss: 0.009953
 >> iter 93000, loss: 0.009928
 >> iter 94000, loss: 0.009940
 >> iter 95000, loss: 0.009920
 >> iter 96000, loss: 0.009932
 >> iter 97000, loss: 0.009913
 >> iter 98000, loss: 0.009926
 >> iter 99000, loss: 0.009905
 >> iter 100000, loss: 0.009916
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.563274
 >> iter 2000, loss: 10.497705
 >> iter 3000, loss: 8.628712
 >> iter 4000, loss: 7.920997
 >> iter 5000, loss: 7.671645
 >> iter 6000, loss: 7.578818
 >> iter 7000, loss: 7.211888
 >> iter 8000, loss: 3.933709
 >> iter 9000, loss: 1.488351
 >> iter 10000, loss: 0.570018
   Number of active neurons: 8
 >> iter 11000, loss: 0.226061
 >> iter 12000, loss: 0.096449
 >> iter 13000, loss: 0.047031
 >> iter 14000, loss: 0.027665
 >> iter 15000, loss: 0.019772
 >> iter 16000, loss: 0.016268
 >> iter 17000, loss: 0.014570
 >> iter 18000, loss: 0.013589
 >> iter 19000, loss: 0.013003
 >> iter 20000, loss: 0.012566
   Number of active neurons: 8
 >> iter 21000, loss: 0.012260
 >> iter 22000, loss: 0.011985
 >> iter 23000, loss: 0.011786
 >> iter 24000, loss: 0.011605
 >> iter 25000, loss: 0.011480
 >> iter 26000, loss: 0.011352
 >> iter 27000, loss: 0.011268
 >> iter 28000, loss: 0.011175
 >> iter 29000, loss: 0.011119
 >> iter 30000, loss: 0.011053
   Number of active neurons: 7
 >> iter 31000, loss: 0.011018
 >> iter 32000, loss: 0.010964
 >> iter 33000, loss: 0.010941
 >> iter 34000, loss: 0.010893
 >> iter 35000, loss: 0.010877
 >> iter 36000, loss: 0.010825
 >> iter 37000, loss: 0.010802
 >> iter 38000, loss: 0.010753
 >> iter 39000, loss: 0.010733
 >> iter 40000, loss: 0.010692
   Number of active neurons: 7
 >> iter 41000, loss: 0.010680
 >> iter 42000, loss: 0.010644
 >> iter 43000, loss: 0.010639
 >> iter 44000, loss: 0.010605
 >> iter 45000, loss: 0.010605
 >> iter 46000, loss: 0.010574
 >> iter 47000, loss: 0.010576
 >> iter 48000, loss: 0.010542
 >> iter 49000, loss: 0.010549
 >> iter 50000, loss: 0.010519
   Number of active neurons: 7
 >> iter 51000, loss: 0.010526
 >> iter 52000, loss: 0.010498
 >> iter 53000, loss: 0.010500
 >> iter 54000, loss: 0.010476
 >> iter 55000, loss: 0.010468
 >> iter 56000, loss: 0.010443
 >> iter 57000, loss: 0.010431
 >> iter 58000, loss: 0.010405
 >> iter 59000, loss: 0.010389
 >> iter 60000, loss: 0.010365
   Number of active neurons: 7
 >> iter 61000, loss: 0.010347
 >> iter 62000, loss: 0.010321
 >> iter 63000, loss: 0.010307
 >> iter 64000, loss: 0.010289
 >> iter 65000, loss: 0.010278
 >> iter 66000, loss: 0.010261
 >> iter 67000, loss: 0.010250
 >> iter 68000, loss: 0.010232
 >> iter 69000, loss: 0.010217
 >> iter 70000, loss: 0.010199
   Number of active neurons: 7
 >> iter 71000, loss: 0.010186
 >> iter 72000, loss: 0.010172
 >> iter 73000, loss: 0.010161
 >> iter 74000, loss: 0.010148
 >> iter 75000, loss: 0.010133
 >> iter 76000, loss: 0.010119
 >> iter 77000, loss: 0.010103
 >> iter 78000, loss: 0.010093
 >> iter 79000, loss: 0.010079
 >> iter 80000, loss: 0.010070
   Number of active neurons: 6
 >> iter 81000, loss: 0.010055
 >> iter 82000, loss: 0.010048
 >> iter 83000, loss: 0.010026
 >> iter 84000, loss: 0.010016
 >> iter 85000, loss: 0.009991
 >> iter 86000, loss: 0.009984
 >> iter 87000, loss: 0.009950
 >> iter 88000, loss: 0.009935
 >> iter 89000, loss: 0.009899
 >> iter 90000, loss: 0.009887
   Number of active neurons: 6
 >> iter 91000, loss: 0.009851
 >> iter 92000, loss: 0.009844
 >> iter 93000, loss: 0.009801
 >> iter 94000, loss: 0.009784
 >> iter 95000, loss: 0.009734
 >> iter 96000, loss: 0.009703
 >> iter 97000, loss: 0.009654
 >> iter 98000, loss: 0.009628
 >> iter 99000, loss: 0.009585
 >> iter 100000, loss: 0.009564
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 15.508958
 >> iter 2000, loss: 10.472383
 >> iter 3000, loss: 8.617607
 >> iter 4000, loss: 7.905515
 >> iter 5000, loss: 7.652661
 >> iter 6000, loss: 7.172184
 >> iter 7000, loss: 6.245337
 >> iter 8000, loss: 2.445043
 >> iter 9000, loss: 0.947052
 >> iter 10000, loss: 0.376389
   Number of active neurons: 7
 >> iter 11000, loss: 0.160081
 >> iter 12000, loss: 0.076498
 >> iter 13000, loss: 0.043626
 >> iter 14000, loss: 0.029738
 >> iter 15000, loss: 0.023647
 >> iter 16000, loss: 0.020388
 >> iter 17000, loss: 0.018682
 >> iter 18000, loss: 0.017405
 >> iter 19000, loss: 0.016650
 >> iter 20000, loss: 0.015905
   Number of active neurons: 7
 >> iter 21000, loss: 0.015476
 >> iter 22000, loss: 0.014966
 >> iter 23000, loss: 0.014704
 >> iter 24000, loss: 0.014321
 >> iter 25000, loss: 0.014159
 >> iter 26000, loss: 0.013867
 >> iter 27000, loss: 0.013780
 >> iter 28000, loss: 0.013555
 >> iter 29000, loss: 0.013518
 >> iter 30000, loss: 0.013320
   Number of active neurons: 7
 >> iter 31000, loss: 0.013300
 >> iter 32000, loss: 0.013117
 >> iter 33000, loss: 0.013103
 >> iter 34000, loss: 0.012953
 >> iter 35000, loss: 0.012977
 >> iter 36000, loss: 0.012849
 >> iter 37000, loss: 0.012869
 >> iter 38000, loss: 0.012751
 >> iter 39000, loss: 0.012777
 >> iter 40000, loss: 0.012663
   Number of active neurons: 7
 >> iter 41000, loss: 0.012693
 >> iter 42000, loss: 0.012587
 >> iter 43000, loss: 0.012615
 >> iter 44000, loss: 0.012520
 >> iter 45000, loss: 0.012540
 >> iter 46000, loss: 0.012454
 >> iter 47000, loss: 0.012465
 >> iter 48000, loss: 0.012377
 >> iter 49000, loss: 0.012399
 >> iter 50000, loss: 0.012324
   Number of active neurons: 7
 >> iter 51000, loss: 0.012349
 >> iter 52000, loss: 0.012277
 >> iter 53000, loss: 0.012311
 >> iter 54000, loss: 0.012233
 >> iter 55000, loss: 0.012261
 >> iter 56000, loss: 0.012169
 >> iter 57000, loss: 0.012187
 >> iter 58000, loss: 0.012101
 >> iter 59000, loss: 0.012118
 >> iter 60000, loss: 0.012044
   Number of active neurons: 7
 >> iter 61000, loss: 0.012059
 >> iter 62000, loss: 0.011993
 >> iter 63000, loss: 0.012010
 >> iter 64000, loss: 0.011957
 >> iter 65000, loss: 0.011971
 >> iter 66000, loss: 0.011919
 >> iter 67000, loss: 0.011932
 >> iter 68000, loss: 0.011886
 >> iter 69000, loss: 0.011900
 >> iter 70000, loss: 0.011856
   Number of active neurons: 7
 >> iter 71000, loss: 0.011867
 >> iter 72000, loss: 0.011823
 >> iter 73000, loss: 0.011830
 >> iter 74000, loss: 0.011782
 >> iter 75000, loss: 0.011784
 >> iter 76000, loss: 0.011729
 >> iter 77000, loss: 0.011717
 >> iter 78000, loss: 0.011654
 >> iter 79000, loss: 0.011642
 >> iter 80000, loss: 0.011595
   Number of active neurons: 7
 >> iter 81000, loss: 0.011597
 >> iter 82000, loss: 0.011565
 >> iter 83000, loss: 0.011581
 >> iter 84000, loss: 0.011552
 >> iter 85000, loss: 0.011578
 >> iter 86000, loss: 0.011551
 >> iter 87000, loss: 0.011580
 >> iter 88000, loss: 0.011553
 >> iter 89000, loss: 0.011577
 >> iter 90000, loss: 0.011552
   Number of active neurons: 7
 >> iter 91000, loss: 0.011574
 >> iter 92000, loss: 0.011546
 >> iter 93000, loss: 0.011567
 >> iter 94000, loss: 0.011535
 >> iter 95000, loss: 0.011555
 >> iter 96000, loss: 0.011526
 >> iter 97000, loss: 0.011541
 >> iter 98000, loss: 0.011513
 >> iter 99000, loss: 0.011523
 >> iter 100000, loss: 0.011501
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.561346
 >> iter 2000, loss: 10.488045
 >> iter 3000, loss: 8.621145
 >> iter 4000, loss: 7.914707
 >> iter 5000, loss: 7.659855
 >> iter 6000, loss: 7.548669
 >> iter 7000, loss: 7.542081
 >> iter 8000, loss: 7.521413
 >> iter 9000, loss: 6.188905
 >> iter 10000, loss: 2.367100
   Number of active neurons: 6
 >> iter 11000, loss: 0.905303
 >> iter 12000, loss: 0.355286
 >> iter 13000, loss: 0.147794
 >> iter 14000, loss: 0.068531
 >> iter 15000, loss: 0.037637
 >> iter 16000, loss: 0.025022
 >> iter 17000, loss: 0.019568
 >> iter 18000, loss: 0.016886
 >> iter 19000, loss: 0.015461
 >> iter 20000, loss: 0.014521
   Number of active neurons: 6
 >> iter 21000, loss: 0.013898
 >> iter 22000, loss: 0.013384
 >> iter 23000, loss: 0.013003
 >> iter 24000, loss: 0.012644
 >> iter 25000, loss: 0.012366
 >> iter 26000, loss: 0.012093
 >> iter 27000, loss: 0.011885
 >> iter 28000, loss: 0.011671
 >> iter 29000, loss: 0.011511
 >> iter 30000, loss: 0.011348
   Number of active neurons: 6
 >> iter 31000, loss: 0.011225
 >> iter 32000, loss: 0.011096
 >> iter 33000, loss: 0.011006
 >> iter 34000, loss: 0.010901
 >> iter 35000, loss: 0.010827
 >> iter 36000, loss: 0.010739
 >> iter 37000, loss: 0.010678
 >> iter 38000, loss: 0.010609
 >> iter 39000, loss: 0.010554
 >> iter 40000, loss: 0.010488
   Number of active neurons: 6
 >> iter 41000, loss: 0.010439
 >> iter 42000, loss: 0.010381
 >> iter 43000, loss: 0.010344
 >> iter 44000, loss: 0.010293
 >> iter 45000, loss: 0.010262
 >> iter 46000, loss: 0.010216
 >> iter 47000, loss: 0.010185
 >> iter 48000, loss: 0.010136
 >> iter 49000, loss: 0.010110
 >> iter 50000, loss: 0.010069
   Number of active neurons: 6
 >> iter 51000, loss: 0.010048
 >> iter 52000, loss: 0.010012
 >> iter 53000, loss: 0.009993
 >> iter 54000, loss: 0.009966
 >> iter 55000, loss: 0.009938
 >> iter 56000, loss: 0.009914
 >> iter 57000, loss: 0.009888
 >> iter 58000, loss: 0.009871
 >> iter 59000, loss: 0.009846
 >> iter 60000, loss: 0.009833
   Number of active neurons: 6
 >> iter 61000, loss: 0.009811
 >> iter 62000, loss: 0.009802
 >> iter 63000, loss: 0.009782
 >> iter 64000, loss: 0.009779
 >> iter 65000, loss: 0.009760
 >> iter 66000, loss: 0.009759
 >> iter 67000, loss: 0.009738
 >> iter 68000, loss: 0.009734
 >> iter 69000, loss: 0.009708
 >> iter 70000, loss: 0.009706
   Number of active neurons: 6
 >> iter 71000, loss: 0.009681
 >> iter 72000, loss: 0.009681
 >> iter 73000, loss: 0.009657
 >> iter 74000, loss: 0.009660
 >> iter 75000, loss: 0.009635
 >> iter 76000, loss: 0.009641
 >> iter 77000, loss: 0.009615
 >> iter 78000, loss: 0.009623
 >> iter 79000, loss: 0.009600
 >> iter 80000, loss: 0.009606
   Number of active neurons: 6
 >> iter 81000, loss: 0.009582
 >> iter 82000, loss: 0.009586
 >> iter 83000, loss: 0.009554
 >> iter 84000, loss: 0.009560
 >> iter 85000, loss: 0.009527
 >> iter 86000, loss: 0.009537
 >> iter 87000, loss: 0.009502
 >> iter 88000, loss: 0.009513
 >> iter 89000, loss: 0.009479
 >> iter 90000, loss: 0.009493
   Number of active neurons: 6
 >> iter 91000, loss: 0.009457
 >> iter 92000, loss: 0.009474
 >> iter 93000, loss: 0.009437
 >> iter 94000, loss: 0.009454
 >> iter 95000, loss: 0.009420
 >> iter 96000, loss: 0.009436
 >> iter 97000, loss: 0.009403
 >> iter 98000, loss: 0.009418
 >> iter 99000, loss: 0.009386
 >> iter 100000, loss: 0.009399
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

