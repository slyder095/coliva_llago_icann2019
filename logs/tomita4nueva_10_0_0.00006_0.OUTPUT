 > Problema: tomita4nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 6e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.266279
 >> iter 2000, loss: 6.735869
 >> iter 3000, loss: 2.508346
 >> iter 4000, loss: 0.941029
 >> iter 5000, loss: 0.516979
 >> iter 6000, loss: 0.293128
 >> iter 7000, loss: 0.356327
 >> iter 8000, loss: 0.334201
 >> iter 9000, loss: 0.138804
 >> iter 10000, loss: 0.132673
   Number of active neurons: 4
 >> iter 11000, loss: 0.060350
 >> iter 12000, loss: 0.232429
 >> iter 13000, loss: 0.175357
 >> iter 14000, loss: 0.164045
 >> iter 15000, loss: 0.235170
 >> iter 16000, loss: 0.210806
 >> iter 17000, loss: 0.159253
 >> iter 18000, loss: 0.073885
 >> iter 19000, loss: 0.040339
 >> iter 20000, loss: 0.041373
   Number of active neurons: 4
 >> iter 21000, loss: 0.055795
 >> iter 22000, loss: 0.039542
 >> iter 23000, loss: 0.157981
 >> iter 24000, loss: 0.087573
 >> iter 25000, loss: 0.276738
 >> iter 26000, loss: 0.228556
 >> iter 27000, loss: 0.098060
 >> iter 28000, loss: 0.057223
 >> iter 29000, loss: 0.298315
 >> iter 30000, loss: 0.234187
   Number of active neurons: 4
 >> iter 31000, loss: 0.148003
 >> iter 32000, loss: 0.138686
 >> iter 33000, loss: 0.062926
 >> iter 34000, loss: 0.302795
 >> iter 35000, loss: 0.126536
 >> iter 36000, loss: 0.060896
 >> iter 37000, loss: 0.156980
 >> iter 38000, loss: 0.111875
 >> iter 39000, loss: 0.076594
 >> iter 40000, loss: 0.044042
   Number of active neurons: 4
 >> iter 41000, loss: 0.117918
 >> iter 42000, loss: 0.167391
 >> iter 43000, loss: 0.148027
 >> iter 44000, loss: 0.072049
 >> iter 45000, loss: 0.186884
 >> iter 46000, loss: 0.150563
 >> iter 47000, loss: 0.067892
 >> iter 48000, loss: 0.046556
 >> iter 49000, loss: 0.039704
 >> iter 50000, loss: 0.415148
   Number of active neurons: 4
 >> iter 51000, loss: 0.167655
 >> iter 52000, loss: 0.315318
 >> iter 53000, loss: 0.306150
 >> iter 54000, loss: 0.237989
 >> iter 55000, loss: 0.101672
 >> iter 56000, loss: 0.351865
 >> iter 57000, loss: 0.146046
 >> iter 58000, loss: 0.202593
 >> iter 59000, loss: 0.087212
 >> iter 60000, loss: 0.052461
   Number of active neurons: 4
 >> iter 61000, loss: 0.074486
 >> iter 62000, loss: 0.274531
 >> iter 63000, loss: 0.114041
 >> iter 64000, loss: 0.172694
 >> iter 65000, loss: 0.074861
 >> iter 66000, loss: 0.297618
 >> iter 67000, loss: 0.167024
 >> iter 68000, loss: 0.080796
 >> iter 69000, loss: 0.132313
 >> iter 70000, loss: 0.196710
   Number of active neurons: 4
 >> iter 71000, loss: 0.294696
 >> iter 72000, loss: 0.224547
 >> iter 73000, loss: 0.220951
 >> iter 74000, loss: 0.101747
 >> iter 75000, loss: 0.095632
 >> iter 76000, loss: 0.158295
 >> iter 77000, loss: 0.162894
 >> iter 78000, loss: 0.183446
 >> iter 79000, loss: 0.147310
 >> iter 80000, loss: 0.222627
   Number of active neurons: 4
 >> iter 81000, loss: 0.139998
 >> iter 82000, loss: 0.100269
 >> iter 83000, loss: 0.047665
 >> iter 84000, loss: 0.081790
 >> iter 85000, loss: 0.194601
 >> iter 86000, loss: 0.191824
 >> iter 87000, loss: 0.145492
 >> iter 88000, loss: 0.113833
 >> iter 89000, loss: 0.079309
 >> iter 90000, loss: 0.361085
   Number of active neurons: 4
 >> iter 91000, loss: 0.155149
 >> iter 92000, loss: 0.122266
 >> iter 93000, loss: 0.057308
 >> iter 94000, loss: 0.112370
 >> iter 95000, loss: 0.096908
 >> iter 96000, loss: 0.143515
 >> iter 97000, loss: 0.141110
 >> iter 98000, loss: 0.070959
 >> iter 99000, loss: 0.195008
 >> iter 100000, loss: 0.191442
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.209647
 >> iter 2000, loss: 5.651891
 >> iter 3000, loss: 2.175696
 >> iter 4000, loss: 0.819998
 >> iter 5000, loss: 0.360162
 >> iter 6000, loss: 0.335786
 >> iter 7000, loss: 0.160062
 >> iter 8000, loss: 0.206338
 >> iter 9000, loss: 0.288332
 >> iter 10000, loss: 0.125062
   Number of active neurons: 3
 >> iter 11000, loss: 0.110622
 >> iter 12000, loss: 0.436876
 >> iter 13000, loss: 0.224364
 >> iter 14000, loss: 0.187433
 >> iter 15000, loss: 0.127088
 >> iter 16000, loss: 0.061647
 >> iter 17000, loss: 0.115360
 >> iter 18000, loss: 0.057575
 >> iter 19000, loss: 0.147840
 >> iter 20000, loss: 0.219418
   Number of active neurons: 3
 >> iter 21000, loss: 0.165463
 >> iter 22000, loss: 0.075035
 >> iter 23000, loss: 0.115951
 >> iter 24000, loss: 0.055314
 >> iter 25000, loss: 0.089834
 >> iter 26000, loss: 0.044467
 >> iter 27000, loss: 0.152100
 >> iter 28000, loss: 0.068700
 >> iter 29000, loss: 0.107337
 >> iter 30000, loss: 0.096550
   Number of active neurons: 3
 >> iter 31000, loss: 0.323996
 >> iter 32000, loss: 0.135376
 >> iter 33000, loss: 0.122213
 >> iter 34000, loss: 0.058465
 >> iter 35000, loss: 0.181279
 >> iter 36000, loss: 0.130801
 >> iter 37000, loss: 0.084905
 >> iter 38000, loss: 0.042926
 >> iter 39000, loss: 0.095184
 >> iter 40000, loss: 0.340734
   Number of active neurons: 3
 >> iter 41000, loss: 0.171372
 >> iter 42000, loss: 0.210937
 >> iter 43000, loss: 0.116963
 >> iter 44000, loss: 0.127102
 >> iter 45000, loss: 0.074688
 >> iter 46000, loss: 0.303516
 >> iter 47000, loss: 0.125264
 >> iter 48000, loss: 0.194153
 >> iter 49000, loss: 0.087062
 >> iter 50000, loss: 0.321057
   Number of active neurons: 3
 >> iter 51000, loss: 0.213754
 >> iter 52000, loss: 0.280933
 >> iter 53000, loss: 0.118845
 >> iter 54000, loss: 0.189720
 >> iter 55000, loss: 0.141613
 >> iter 56000, loss: 0.194845
 >> iter 57000, loss: 0.175126
 >> iter 58000, loss: 0.077700
 >> iter 59000, loss: 0.104351
 >> iter 60000, loss: 0.050205
   Number of active neurons: 3
 >> iter 61000, loss: 0.072784
 >> iter 62000, loss: 0.037823
 >> iter 63000, loss: 0.118674
 >> iter 64000, loss: 0.054965
 >> iter 65000, loss: 0.189463
 >> iter 66000, loss: 0.082121
 >> iter 67000, loss: 0.083245
 >> iter 68000, loss: 0.364204
 >> iter 69000, loss: 0.148976
 >> iter 70000, loss: 0.205954
   Number of active neurons: 3
 >> iter 71000, loss: 0.135582
 >> iter 72000, loss: 0.066061
 >> iter 73000, loss: 0.035626
 >> iter 74000, loss: 0.332469
 >> iter 75000, loss: 0.211360
 >> iter 76000, loss: 0.191477
 >> iter 77000, loss: 0.110104
 >> iter 78000, loss: 0.238291
 >> iter 79000, loss: 0.176549
 >> iter 80000, loss: 0.186407
   Number of active neurons: 3
 >> iter 81000, loss: 0.103648
 >> iter 82000, loss: 0.243966
 >> iter 83000, loss: 0.168155
 >> iter 84000, loss: 0.274027
 >> iter 85000, loss: 0.117189
 >> iter 86000, loss: 0.173810
 >> iter 87000, loss: 0.260925
 >> iter 88000, loss: 0.148603
 >> iter 89000, loss: 0.069142
 >> iter 90000, loss: 0.155641
   Number of active neurons: 3
 >> iter 91000, loss: 0.139483
 >> iter 92000, loss: 0.238290
 >> iter 93000, loss: 0.170833
 >> iter 94000, loss: 0.273202
 >> iter 95000, loss: 0.135247
 >> iter 96000, loss: 0.242397
 >> iter 97000, loss: 0.164260
 >> iter 98000, loss: 0.190872
 >> iter 99000, loss: 0.093941
 >> iter 100000, loss: 0.211849
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.00799984000319
   - Test - Long: 0.01999900005
   - Test - Big: 0.0089999100009
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.321098
 >> iter 2000, loss: 5.723111
 >> iter 3000, loss: 2.168062
 >> iter 4000, loss: 0.814726
 >> iter 5000, loss: 0.325797
 >> iter 6000, loss: 0.133061
 >> iter 7000, loss: 0.097839
 >> iter 8000, loss: 0.172052
 >> iter 9000, loss: 0.077675
 >> iter 10000, loss: 0.042187
   Number of active neurons: 5
 >> iter 11000, loss: 0.104623
 >> iter 12000, loss: 0.051738
 >> iter 13000, loss: 0.145687
 >> iter 14000, loss: 0.101757
 >> iter 15000, loss: 0.050135
 >> iter 16000, loss: 0.402130
 >> iter 17000, loss: 0.170036
 >> iter 18000, loss: 0.440624
 >> iter 19000, loss: 0.180664
 >> iter 20000, loss: 0.146596
   Number of active neurons: 4
 >> iter 21000, loss: 0.067107
 >> iter 22000, loss: 0.273929
 >> iter 23000, loss: 0.260750
 >> iter 24000, loss: 0.345634
 >> iter 25000, loss: 0.143983
 >> iter 26000, loss: 0.133276
 >> iter 27000, loss: 0.132380
 >> iter 28000, loss: 0.152722
 >> iter 29000, loss: 0.068927
 >> iter 30000, loss: 0.455693
   Number of active neurons: 4
 >> iter 31000, loss: 0.226526
 >> iter 32000, loss: 0.097828
 >> iter 33000, loss: 0.063811
 >> iter 34000, loss: 0.035012
 >> iter 35000, loss: 0.093869
 >> iter 36000, loss: 0.118097
 >> iter 37000, loss: 0.054696
 >> iter 38000, loss: 0.130601
 >> iter 39000, loss: 0.127256
 >> iter 40000, loss: 0.058856
   Number of active neurons: 3
 >> iter 41000, loss: 0.167680
 >> iter 42000, loss: 0.075864
 >> iter 43000, loss: 0.201266
 >> iter 44000, loss: 0.177860
 >> iter 45000, loss: 0.113840
 >> iter 46000, loss: 0.194709
 >> iter 47000, loss: 0.128867
 >> iter 48000, loss: 0.062173
 >> iter 49000, loss: 0.054434
 >> iter 50000, loss: 0.173711
   Number of active neurons: 4
 >> iter 51000, loss: 0.077101
 >> iter 52000, loss: 0.207101
 >> iter 53000, loss: 0.090732
 >> iter 54000, loss: 0.324253
 >> iter 55000, loss: 0.135943
 >> iter 56000, loss: 0.201863
 >> iter 57000, loss: 0.177231
 >> iter 58000, loss: 0.098824
 >> iter 59000, loss: 0.065569
 >> iter 60000, loss: 0.293099
   Number of active neurons: 3
 >> iter 61000, loss: 0.122910
 >> iter 62000, loss: 0.390547
 >> iter 63000, loss: 0.161346
 >> iter 64000, loss: 0.268925
 >> iter 65000, loss: 0.115140
 >> iter 66000, loss: 0.164599
 >> iter 67000, loss: 0.075130
 >> iter 68000, loss: 0.128455
 >> iter 69000, loss: 0.100822
 >> iter 70000, loss: 0.343618
   Number of active neurons: 4
 >> iter 71000, loss: 0.144623
 >> iter 72000, loss: 0.292053
 >> iter 73000, loss: 0.124845
 >> iter 74000, loss: 0.242664
 >> iter 75000, loss: 0.105504
 >> iter 76000, loss: 0.156224
 >> iter 77000, loss: 0.127154
 >> iter 78000, loss: 0.063457
 >> iter 79000, loss: 0.077496
 >> iter 80000, loss: 0.168823
   Number of active neurons: 4
 >> iter 81000, loss: 0.076092
 >> iter 82000, loss: 0.197983
 >> iter 83000, loss: 0.129301
 >> iter 84000, loss: 0.134219
 >> iter 85000, loss: 0.062933
 >> iter 86000, loss: 0.243163
 >> iter 87000, loss: 0.105309
 >> iter 88000, loss: 0.239658
 >> iter 89000, loss: 0.105416
 >> iter 90000, loss: 0.052510
   Number of active neurons: 4
 >> iter 91000, loss: 0.121365
 >> iter 92000, loss: 0.199169
 >> iter 93000, loss: 0.213602
 >> iter 94000, loss: 0.161787
 >> iter 95000, loss: 0.115167
 >> iter 96000, loss: 0.062168
 >> iter 97000, loss: 0.045752
 >> iter 98000, loss: 0.153746
 >> iter 99000, loss: 0.196278
 >> iter 100000, loss: 0.086666
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.460310
 >> iter 2000, loss: 6.557014
 >> iter 3000, loss: 2.438493
 >> iter 4000, loss: 0.914772
 >> iter 5000, loss: 0.351389
 >> iter 6000, loss: 0.175544
 >> iter 7000, loss: 0.077428
 >> iter 8000, loss: 0.077105
 >> iter 9000, loss: 0.076191
 >> iter 10000, loss: 0.605052
   Number of active neurons: 4
 >> iter 11000, loss: 0.254996
 >> iter 12000, loss: 0.211201
 >> iter 13000, loss: 0.095755
 >> iter 14000, loss: 0.290511
 >> iter 15000, loss: 0.125213
 >> iter 16000, loss: 0.400468
 >> iter 17000, loss: 0.167567
 >> iter 18000, loss: 0.279439
 >> iter 19000, loss: 0.130237
 >> iter 20000, loss: 0.337944
   Number of active neurons: 4
 >> iter 21000, loss: 0.141412
 >> iter 22000, loss: 0.389485
 >> iter 23000, loss: 0.174485
 >> iter 24000, loss: 0.559755
 >> iter 25000, loss: 0.248198
 >> iter 26000, loss: 0.107666
 >> iter 27000, loss: 0.053074
 >> iter 28000, loss: 0.584279
 >> iter 29000, loss: 0.259535
 >> iter 30000, loss: 0.405822
   Number of active neurons: 4
 >> iter 31000, loss: 0.166722
 >> iter 32000, loss: 0.075248
 >> iter 33000, loss: 0.063456
 >> iter 34000, loss: 0.036474
 >> iter 35000, loss: 0.059428
 >> iter 36000, loss: 0.270748
 >> iter 37000, loss: 0.153996
 >> iter 38000, loss: 0.337961
 >> iter 39000, loss: 0.141936
 >> iter 40000, loss: 0.095060
   Number of active neurons: 4
 >> iter 41000, loss: 0.047328
 >> iter 42000, loss: 0.192030
 >> iter 43000, loss: 0.084531
 >> iter 44000, loss: 0.216140
 >> iter 45000, loss: 0.202855
 >> iter 46000, loss: 0.208889
 >> iter 47000, loss: 0.109212
 >> iter 48000, loss: 0.210159
 >> iter 49000, loss: 0.092068
 >> iter 50000, loss: 0.343784
   Number of active neurons: 4
 >> iter 51000, loss: 0.144652
 >> iter 52000, loss: 0.253197
 >> iter 53000, loss: 0.138517
 >> iter 54000, loss: 0.191169
 >> iter 55000, loss: 0.103101
 >> iter 56000, loss: 0.278316
 >> iter 57000, loss: 0.240772
 >> iter 58000, loss: 0.231080
 >> iter 59000, loss: 0.153593
 >> iter 60000, loss: 0.074839
   Number of active neurons: 4
 >> iter 61000, loss: 0.040841
 >> iter 62000, loss: 0.169730
 >> iter 63000, loss: 0.098902
 >> iter 64000, loss: 0.609938
 >> iter 65000, loss: 0.412360
 >> iter 66000, loss: 0.203459
 >> iter 67000, loss: 0.112448
 >> iter 68000, loss: 0.115914
 >> iter 69000, loss: 0.141508
 >> iter 70000, loss: 0.068565
   Number of active neurons: 4
 >> iter 71000, loss: 0.036954
 >> iter 72000, loss: 0.224536
 >> iter 73000, loss: 0.110418
 >> iter 74000, loss: 0.266999
 >> iter 75000, loss: 0.130232
 >> iter 76000, loss: 0.066539
 >> iter 77000, loss: 0.060488
 >> iter 78000, loss: 0.095758
 >> iter 79000, loss: 0.195751
 >> iter 80000, loss: 0.087859
   Number of active neurons: 4
 >> iter 81000, loss: 0.158800
 >> iter 82000, loss: 0.071381
 >> iter 83000, loss: 0.160744
 >> iter 84000, loss: 0.082583
 >> iter 85000, loss: 0.237031
 >> iter 86000, loss: 0.101060
 >> iter 87000, loss: 0.147147
 >> iter 88000, loss: 0.067805
 >> iter 89000, loss: 0.278573
 >> iter 90000, loss: 0.119468
   Number of active neurons: 3
 >> iter 91000, loss: 0.214281
 >> iter 92000, loss: 0.157031
 >> iter 93000, loss: 0.137170
 >> iter 94000, loss: 0.063710
 >> iter 95000, loss: 0.099732
 >> iter 96000, loss: 0.115221
 >> iter 97000, loss: 0.133649
 >> iter 98000, loss: 0.066387
 >> iter 99000, loss: 0.134798
 >> iter 100000, loss: 0.062158
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.693669
 >> iter 2000, loss: 6.324278
 >> iter 3000, loss: 2.349712
 >> iter 4000, loss: 0.881199
 >> iter 5000, loss: 0.382151
 >> iter 6000, loss: 0.154510
 >> iter 7000, loss: 0.111232
 >> iter 8000, loss: 0.329385
 >> iter 9000, loss: 0.206790
 >> iter 10000, loss: 0.091299
   Number of active neurons: 4
 >> iter 11000, loss: 0.074713
 >> iter 12000, loss: 0.260351
 >> iter 13000, loss: 0.110387
 >> iter 14000, loss: 0.127442
 >> iter 15000, loss: 0.232379
 >> iter 16000, loss: 0.289417
 >> iter 17000, loss: 0.123703
 >> iter 18000, loss: 0.157555
 >> iter 19000, loss: 0.071982
 >> iter 20000, loss: 0.276136
   Number of active neurons: 4
 >> iter 21000, loss: 0.118471
 >> iter 22000, loss: 0.115454
 >> iter 23000, loss: 0.074951
 >> iter 24000, loss: 0.264048
 >> iter 25000, loss: 0.130179
 >> iter 26000, loss: 0.144847
 >> iter 27000, loss: 0.066405
 >> iter 28000, loss: 0.148505
 >> iter 29000, loss: 0.244310
 >> iter 30000, loss: 0.105035
   Number of active neurons: 4
 >> iter 31000, loss: 0.067322
 >> iter 32000, loss: 0.272992
 >> iter 33000, loss: 0.123207
 >> iter 34000, loss: 0.097387
 >> iter 35000, loss: 0.073623
 >> iter 36000, loss: 0.161218
 >> iter 37000, loss: 0.075094
 >> iter 38000, loss: 0.293522
 >> iter 39000, loss: 0.140173
 >> iter 40000, loss: 0.176859
   Number of active neurons: 4
 >> iter 41000, loss: 0.125520
 >> iter 42000, loss: 0.191765
 >> iter 43000, loss: 0.085087
 >> iter 44000, loss: 0.360918
 >> iter 45000, loss: 0.150726
 >> iter 46000, loss: 0.237960
 >> iter 47000, loss: 0.119713
 >> iter 48000, loss: 0.791973
 >> iter 49000, loss: 0.374095
 >> iter 50000, loss: 0.266970
   Number of active neurons: 4
 >> iter 51000, loss: 0.191373
 >> iter 52000, loss: 0.260412
 >> iter 53000, loss: 0.133042
 >> iter 54000, loss: 0.121733
 >> iter 55000, loss: 0.058748
 >> iter 56000, loss: 0.276080
 >> iter 57000, loss: 0.138532
 >> iter 58000, loss: 0.174961
 >> iter 59000, loss: 0.120030
 >> iter 60000, loss: 0.057255
   Number of active neurons: 4
 >> iter 61000, loss: 0.049766
 >> iter 62000, loss: 0.196498
 >> iter 63000, loss: 0.130293
 >> iter 64000, loss: 0.204082
 >> iter 65000, loss: 0.089518
 >> iter 66000, loss: 0.138440
 >> iter 67000, loss: 0.066060
 >> iter 68000, loss: 0.037113
 >> iter 69000, loss: 0.024173
 >> iter 70000, loss: 0.022612
   Number of active neurons: 3
 >> iter 71000, loss: 0.038257
 >> iter 72000, loss: 0.154736
 >> iter 73000, loss: 0.105650
 >> iter 74000, loss: 0.053775
 >> iter 75000, loss: 0.282093
 >> iter 76000, loss: 0.123223
 >> iter 77000, loss: 0.143977
 >> iter 78000, loss: 0.065761
 >> iter 79000, loss: 0.084700
 >> iter 80000, loss: 0.055231
   Number of active neurons: 3
 >> iter 81000, loss: 0.050033
 >> iter 82000, loss: 0.031503
 >> iter 83000, loss: 0.047648
 >> iter 84000, loss: 0.032107
 >> iter 85000, loss: 0.039138
 >> iter 86000, loss: 0.185644
 >> iter 87000, loss: 0.079627
 >> iter 88000, loss: 0.053137
 >> iter 89000, loss: 0.056906
 >> iter 90000, loss: 0.038891
   Number of active neurons: 3
 >> iter 91000, loss: 0.079868
 >> iter 92000, loss: 0.046852
 >> iter 93000, loss: 0.149081
 >> iter 94000, loss: 0.070710
 >> iter 95000, loss: 0.071632
 >> iter 96000, loss: 0.036656
 >> iter 97000, loss: 0.083159
 >> iter 98000, loss: 0.047983
 >> iter 99000, loss: 0.045881
 >> iter 100000, loss: 0.102015
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.592123
 >> iter 2000, loss: 6.429107
 >> iter 3000, loss: 2.487718
 >> iter 4000, loss: 0.935026
 >> iter 5000, loss: 0.535866
 >> iter 6000, loss: 0.217208
 >> iter 7000, loss: 0.166515
 >> iter 8000, loss: 0.133662
 >> iter 9000, loss: 0.134629
 >> iter 10000, loss: 0.108429
   Number of active neurons: 5
 >> iter 11000, loss: 0.242001
 >> iter 12000, loss: 0.107272
 >> iter 13000, loss: 0.168327
 >> iter 14000, loss: 0.078635
 >> iter 15000, loss: 0.077573
 >> iter 16000, loss: 0.292610
 >> iter 17000, loss: 0.125425
 >> iter 18000, loss: 0.190452
 >> iter 19000, loss: 0.270051
 >> iter 20000, loss: 0.229513
   Number of active neurons: 4
 >> iter 21000, loss: 0.160010
 >> iter 22000, loss: 0.188894
 >> iter 23000, loss: 0.516146
 >> iter 24000, loss: 0.317915
 >> iter 25000, loss: 0.134683
 >> iter 26000, loss: 0.214340
 >> iter 27000, loss: 0.093470
 >> iter 28000, loss: 0.104687
 >> iter 29000, loss: 0.250719
 >> iter 30000, loss: 0.108578
   Number of active neurons: 4
 >> iter 31000, loss: 0.258142
 >> iter 32000, loss: 0.111919
 >> iter 33000, loss: 0.319456
 >> iter 34000, loss: 0.135802
 >> iter 35000, loss: 0.128596
 >> iter 36000, loss: 0.061206
 >> iter 37000, loss: 0.144479
 >> iter 38000, loss: 0.070671
 >> iter 39000, loss: 0.131213
 >> iter 40000, loss: 0.075679
   Number of active neurons: 4
 >> iter 41000, loss: 0.168277
 >> iter 42000, loss: 0.296789
 >> iter 43000, loss: 0.155341
 >> iter 44000, loss: 0.164796
 >> iter 45000, loss: 0.082635
 >> iter 46000, loss: 0.252729
 >> iter 47000, loss: 0.127665
 >> iter 48000, loss: 0.093142
 >> iter 49000, loss: 0.045751
 >> iter 50000, loss: 0.582344
   Number of active neurons: 3
 >> iter 51000, loss: 0.517516
 >> iter 52000, loss: 0.395803
 >> iter 53000, loss: 0.199982
 >> iter 54000, loss: 0.245002
 >> iter 55000, loss: 0.116216
 >> iter 56000, loss: 0.059514
 >> iter 57000, loss: 0.051940
 >> iter 58000, loss: 0.237567
 >> iter 59000, loss: 0.101261
 >> iter 60000, loss: 0.229560
   Number of active neurons: 3
 >> iter 61000, loss: 0.098469
 >> iter 62000, loss: 0.097546
 >> iter 63000, loss: 0.084891
 >> iter 64000, loss: 0.166378
 >> iter 65000, loss: 0.077435
 >> iter 66000, loss: 0.309352
 >> iter 67000, loss: 0.129636
 >> iter 68000, loss: 0.396177
 >> iter 69000, loss: 0.349104
 >> iter 70000, loss: 0.254152
   Number of active neurons: 3
 >> iter 71000, loss: 0.287890
 >> iter 72000, loss: 0.270700
 >> iter 73000, loss: 0.186484
 >> iter 74000, loss: 0.214590
 >> iter 75000, loss: 0.124806
 >> iter 76000, loss: 0.271148
 >> iter 77000, loss: 0.138556
 >> iter 78000, loss: 0.073096
 >> iter 79000, loss: 0.038776
 >> iter 80000, loss: 0.501268
   Number of active neurons: 3
 >> iter 81000, loss: 0.243251
 >> iter 82000, loss: 0.160582
 >> iter 83000, loss: 0.073270
 >> iter 84000, loss: 0.069584
 >> iter 85000, loss: 0.037371
 >> iter 86000, loss: 0.163931
 >> iter 87000, loss: 0.073465
 >> iter 88000, loss: 0.216082
 >> iter 89000, loss: 0.142126
 >> iter 90000, loss: 0.259158
   Number of active neurons: 3
 >> iter 91000, loss: 0.112881
 >> iter 92000, loss: 0.225777
 >> iter 93000, loss: 0.099800
 >> iter 94000, loss: 0.051687
 >> iter 95000, loss: 0.031725
 >> iter 96000, loss: 0.278654
 >> iter 97000, loss: 0.186125
 >> iter 98000, loss: 0.185500
 >> iter 99000, loss: 0.177968
 >> iter 100000, loss: 0.319964
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.985900
 >> iter 2000, loss: 6.224034
 >> iter 3000, loss: 2.314470
 >> iter 4000, loss: 1.060013
 >> iter 5000, loss: 0.605563
 >> iter 6000, loss: 0.244186
 >> iter 7000, loss: 0.184971
 >> iter 8000, loss: 0.216783
 >> iter 9000, loss: 0.288605
 >> iter 10000, loss: 0.123551
   Number of active neurons: 5
 >> iter 11000, loss: 0.222436
 >> iter 12000, loss: 0.281100
 >> iter 13000, loss: 0.146323
 >> iter 14000, loss: 0.122774
 >> iter 15000, loss: 0.229426
 >> iter 16000, loss: 0.338091
 >> iter 17000, loss: 0.141903
 >> iter 18000, loss: 0.311848
 >> iter 19000, loss: 0.130865
 >> iter 20000, loss: 0.063850
   Number of active neurons: 4
 >> iter 21000, loss: 0.035017
 >> iter 22000, loss: 0.208722
 >> iter 23000, loss: 0.149178
 >> iter 24000, loss: 0.107432
 >> iter 25000, loss: 0.122097
 >> iter 26000, loss: 0.060805
 >> iter 27000, loss: 0.034586
 >> iter 28000, loss: 0.105201
 >> iter 29000, loss: 0.050200
 >> iter 30000, loss: 0.152043
   Number of active neurons: 4
 >> iter 31000, loss: 0.112928
 >> iter 32000, loss: 0.060803
 >> iter 33000, loss: 0.103278
 >> iter 34000, loss: 0.165914
 >> iter 35000, loss: 0.074285
 >> iter 36000, loss: 0.156141
 >> iter 37000, loss: 0.088552
 >> iter 38000, loss: 0.160777
 >> iter 39000, loss: 0.171836
 >> iter 40000, loss: 0.403478
   Number of active neurons: 4
 >> iter 41000, loss: 0.166483
 >> iter 42000, loss: 0.113215
 >> iter 43000, loss: 0.054420
 >> iter 44000, loss: 0.367406
 >> iter 45000, loss: 0.159295
 >> iter 46000, loss: 0.179092
 >> iter 47000, loss: 0.077944
 >> iter 48000, loss: 0.147252
 >> iter 49000, loss: 0.065157
 >> iter 50000, loss: 0.090920
   Number of active neurons: 4
 >> iter 51000, loss: 0.045716
 >> iter 52000, loss: 0.377955
 >> iter 53000, loss: 0.152070
 >> iter 54000, loss: 0.282540
 >> iter 55000, loss: 0.116293
 >> iter 56000, loss: 0.164093
 >> iter 57000, loss: 0.283965
 >> iter 58000, loss: 0.143646
 >> iter 59000, loss: 0.094969
 >> iter 60000, loss: 0.150583
   Number of active neurons: 4
 >> iter 61000, loss: 0.136429
 >> iter 62000, loss: 0.062342
 >> iter 63000, loss: 0.099516
 >> iter 64000, loss: 0.158625
 >> iter 65000, loss: 0.070158
 >> iter 66000, loss: 0.038336
 >> iter 67000, loss: 0.047735
 >> iter 68000, loss: 0.035700
 >> iter 69000, loss: 0.139750
 >> iter 70000, loss: 0.309680
   Number of active neurons: 3
 >> iter 71000, loss: 0.196325
 >> iter 72000, loss: 0.266054
 >> iter 73000, loss: 0.111592
 >> iter 74000, loss: 0.157512
 >> iter 75000, loss: 0.069550
 >> iter 76000, loss: 0.045321
 >> iter 77000, loss: 0.026709
 >> iter 78000, loss: 0.030971
 >> iter 79000, loss: 0.020507
 >> iter 80000, loss: 0.132551
   Number of active neurons: 3
 >> iter 81000, loss: 0.127256
 >> iter 82000, loss: 0.188967
 >> iter 83000, loss: 0.086704
 >> iter 84000, loss: 0.291694
 >> iter 85000, loss: 0.208736
 >> iter 86000, loss: 0.111429
 >> iter 87000, loss: 0.052613
 >> iter 88000, loss: 0.066001
 >> iter 89000, loss: 0.035029
 >> iter 90000, loss: 0.719378
   Number of active neurons: 3
 >> iter 91000, loss: 0.286916
 >> iter 92000, loss: 0.187659
 >> iter 93000, loss: 0.082613
 >> iter 94000, loss: 0.043261
 >> iter 95000, loss: 0.026652
 >> iter 96000, loss: 0.022702
 >> iter 97000, loss: 0.078986
 >> iter 98000, loss: 0.144191
 >> iter 99000, loss: 0.110482
 >> iter 100000, loss: 0.155329
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.428981
 >> iter 2000, loss: 5.813942
 >> iter 3000, loss: 2.163077
 >> iter 4000, loss: 0.952673
 >> iter 5000, loss: 0.374315
 >> iter 6000, loss: 0.266463
 >> iter 7000, loss: 0.315915
 >> iter 8000, loss: 0.134401
 >> iter 9000, loss: 0.064467
 >> iter 10000, loss: 0.111550
   Number of active neurons: 3
 >> iter 11000, loss: 0.170730
 >> iter 12000, loss: 0.221774
 >> iter 13000, loss: 0.099517
 >> iter 14000, loss: 0.138317
 >> iter 15000, loss: 0.159892
 >> iter 16000, loss: 0.071821
 >> iter 17000, loss: 0.115092
 >> iter 18000, loss: 0.057414
 >> iter 19000, loss: 0.152802
 >> iter 20000, loss: 0.122687
   Number of active neurons: 4
 >> iter 21000, loss: 0.088191
 >> iter 22000, loss: 0.092990
 >> iter 23000, loss: 0.046108
 >> iter 24000, loss: 0.255974
 >> iter 25000, loss: 0.138352
 >> iter 26000, loss: 0.199199
 >> iter 27000, loss: 0.088589
 >> iter 28000, loss: 0.236006
 >> iter 29000, loss: 0.101944
 >> iter 30000, loss: 0.146066
   Number of active neurons: 3
 >> iter 31000, loss: 0.067243
 >> iter 32000, loss: 0.184703
 >> iter 33000, loss: 0.108386
 >> iter 34000, loss: 0.165071
 >> iter 35000, loss: 0.093363
 >> iter 36000, loss: 0.144416
 >> iter 37000, loss: 0.081342
 >> iter 38000, loss: 0.047732
 >> iter 39000, loss: 0.054745
 >> iter 40000, loss: 0.264774
   Number of active neurons: 4
 >> iter 41000, loss: 0.147922
 >> iter 42000, loss: 0.207551
 >> iter 43000, loss: 0.111874
 >> iter 44000, loss: 0.618932
 >> iter 45000, loss: 0.271797
 >> iter 46000, loss: 0.124273
 >> iter 47000, loss: 0.058746
 >> iter 48000, loss: 0.230837
 >> iter 49000, loss: 0.203852
 >> iter 50000, loss: 0.092477
   Number of active neurons: 3
 >> iter 51000, loss: 0.045829
 >> iter 52000, loss: 0.377103
 >> iter 53000, loss: 0.156141
 >> iter 54000, loss: 0.214412
 >> iter 55000, loss: 0.093580
 >> iter 56000, loss: 0.057484
 >> iter 57000, loss: 0.054570
 >> iter 58000, loss: 0.144646
 >> iter 59000, loss: 0.189017
 >> iter 60000, loss: 0.203679
   Number of active neurons: 3
 >> iter 61000, loss: 0.290716
 >> iter 62000, loss: 0.133810
 >> iter 63000, loss: 0.085487
 >> iter 64000, loss: 0.855647
 >> iter 65000, loss: 0.345781
 >> iter 66000, loss: 0.152942
 >> iter 67000, loss: 0.070557
 >> iter 68000, loss: 0.298189
 >> iter 69000, loss: 0.138906
 >> iter 70000, loss: 0.205430
   Number of active neurons: 3
 >> iter 71000, loss: 0.101227
 >> iter 72000, loss: 0.142400
 >> iter 73000, loss: 0.081373
 >> iter 74000, loss: 0.182536
 >> iter 75000, loss: 0.081436
 >> iter 76000, loss: 0.263799
 >> iter 77000, loss: 0.131387
 >> iter 78000, loss: 0.064882
 >> iter 79000, loss: 0.035782
 >> iter 80000, loss: 0.487369
   Number of active neurons: 4
 >> iter 81000, loss: 0.200219
 >> iter 82000, loss: 0.216203
 >> iter 83000, loss: 0.145895
 >> iter 84000, loss: 0.250598
 >> iter 85000, loss: 0.162951
 >> iter 86000, loss: 0.307512
 >> iter 87000, loss: 0.261843
 >> iter 88000, loss: 0.241896
 >> iter 89000, loss: 0.225853
 >> iter 90000, loss: 0.198422
   Number of active neurons: 4
 >> iter 91000, loss: 0.128858
 >> iter 92000, loss: 0.062001
 >> iter 93000, loss: 0.136516
 >> iter 94000, loss: 0.294966
 >> iter 95000, loss: 0.236300
 >> iter 96000, loss: 0.103928
 >> iter 97000, loss: 0.134632
 >> iter 98000, loss: 0.076570
 >> iter 99000, loss: 0.040200
 >> iter 100000, loss: 0.472644
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.653465
 >> iter 2000, loss: 5.943965
 >> iter 3000, loss: 2.254102
 >> iter 4000, loss: 0.958585
 >> iter 5000, loss: 0.467361
 >> iter 6000, loss: 0.289324
 >> iter 7000, loss: 0.216644
 >> iter 8000, loss: 0.208601
 >> iter 9000, loss: 0.246308
 >> iter 10000, loss: 0.218353
   Number of active neurons: 4
 >> iter 11000, loss: 0.168138
 >> iter 12000, loss: 0.192226
 >> iter 13000, loss: 0.158230
 >> iter 14000, loss: 0.074437
 >> iter 15000, loss: 0.109807
 >> iter 16000, loss: 0.168040
 >> iter 17000, loss: 0.136402
 >> iter 18000, loss: 0.298800
 >> iter 19000, loss: 0.126270
 >> iter 20000, loss: 0.173661
   Number of active neurons: 4
 >> iter 21000, loss: 0.090509
 >> iter 22000, loss: 0.166246
 >> iter 23000, loss: 0.073769
 >> iter 24000, loss: 0.076534
 >> iter 25000, loss: 0.167972
 >> iter 26000, loss: 0.148510
 >> iter 27000, loss: 0.068562
 >> iter 28000, loss: 0.157466
 >> iter 29000, loss: 0.093845
 >> iter 30000, loss: 0.049694
   Number of active neurons: 4
 >> iter 31000, loss: 0.055535
 >> iter 32000, loss: 0.153348
 >> iter 33000, loss: 0.092937
 >> iter 34000, loss: 0.162950
 >> iter 35000, loss: 0.072058
 >> iter 36000, loss: 0.154214
 >> iter 37000, loss: 0.068139
 >> iter 38000, loss: 0.153614
 >> iter 39000, loss: 0.148582
 >> iter 40000, loss: 0.172938
   Number of active neurons: 4
 >> iter 41000, loss: 0.157828
 >> iter 42000, loss: 0.071060
 >> iter 43000, loss: 0.054612
 >> iter 44000, loss: 0.197563
 >> iter 45000, loss: 0.130132
 >> iter 46000, loss: 0.167594
 >> iter 47000, loss: 0.073181
 >> iter 48000, loss: 0.338287
 >> iter 49000, loss: 0.190695
 >> iter 50000, loss: 0.097552
   Number of active neurons: 4
 >> iter 51000, loss: 0.090695
 >> iter 52000, loss: 0.402505
 >> iter 53000, loss: 0.162987
 >> iter 54000, loss: 0.182269
 >> iter 55000, loss: 0.217744
 >> iter 56000, loss: 0.200432
 >> iter 57000, loss: 0.171889
 >> iter 58000, loss: 0.184119
 >> iter 59000, loss: 0.188535
 >> iter 60000, loss: 0.187914
   Number of active neurons: 4
 >> iter 61000, loss: 0.151138
 >> iter 62000, loss: 0.069268
 >> iter 63000, loss: 0.057576
 >> iter 64000, loss: 0.146271
 >> iter 65000, loss: 0.177343
 >> iter 66000, loss: 0.184638
 >> iter 67000, loss: 0.143713
 >> iter 68000, loss: 0.065597
 >> iter 69000, loss: 0.117789
 >> iter 70000, loss: 0.094549
   Number of active neurons: 3
 >> iter 71000, loss: 0.085984
 >> iter 72000, loss: 0.121639
 >> iter 73000, loss: 0.055562
 >> iter 74000, loss: 0.104601
 >> iter 75000, loss: 0.049035
 >> iter 76000, loss: 0.135010
 >> iter 77000, loss: 0.059469
 >> iter 78000, loss: 0.536238
 >> iter 79000, loss: 0.213168
 >> iter 80000, loss: 0.091274
   Number of active neurons: 3
 >> iter 81000, loss: 0.045153
 >> iter 82000, loss: 0.141911
 >> iter 83000, loss: 0.063758
 >> iter 84000, loss: 0.386395
 >> iter 85000, loss: 0.156391
 >> iter 86000, loss: 0.118169
 >> iter 87000, loss: 0.152076
 >> iter 88000, loss: 0.166671
 >> iter 89000, loss: 0.073374
 >> iter 90000, loss: 0.144910
   Number of active neurons: 3
 >> iter 91000, loss: 0.117233
 >> iter 92000, loss: 0.123544
 >> iter 93000, loss: 0.055688
 >> iter 94000, loss: 0.140667
 >> iter 95000, loss: 0.130756
 >> iter 96000, loss: 0.148456
 >> iter 97000, loss: 0.066187
 >> iter 98000, loss: 0.100165
 >> iter 99000, loss: 0.047351
 >> iter 100000, loss: 0.327541
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.280917
 >> iter 2000, loss: 5.758795
 >> iter 3000, loss: 2.142011
 >> iter 4000, loss: 0.862665
 >> iter 5000, loss: 0.334909
 >> iter 6000, loss: 0.139899
 >> iter 7000, loss: 0.244856
 >> iter 8000, loss: 0.109312
 >> iter 9000, loss: 0.078583
 >> iter 10000, loss: 0.139963
   Number of active neurons: 6
 >> iter 11000, loss: 0.067416
 >> iter 12000, loss: 0.268946
 >> iter 13000, loss: 0.116768
 >> iter 14000, loss: 0.270747
 >> iter 15000, loss: 0.117163
 >> iter 16000, loss: 0.137092
 >> iter 17000, loss: 0.077387
 >> iter 18000, loss: 0.160994
 >> iter 19000, loss: 0.077252
 >> iter 20000, loss: 0.113308
   Number of active neurons: 4
 >> iter 21000, loss: 0.071280
 >> iter 22000, loss: 0.364083
 >> iter 23000, loss: 0.151053
 >> iter 24000, loss: 0.327517
 >> iter 25000, loss: 0.149324
 >> iter 26000, loss: 0.136488
 >> iter 27000, loss: 0.064502
 >> iter 28000, loss: 0.340767
 >> iter 29000, loss: 0.141758
 >> iter 30000, loss: 0.139039
   Number of active neurons: 3
 >> iter 31000, loss: 0.064292
 >> iter 32000, loss: 0.138630
 >> iter 33000, loss: 0.064281
 >> iter 34000, loss: 0.098682
 >> iter 35000, loss: 0.452401
 >> iter 36000, loss: 0.184899
 >> iter 37000, loss: 0.098508
 >> iter 38000, loss: 0.257528
 >> iter 39000, loss: 0.142356
 >> iter 40000, loss: 0.067927
   Number of active neurons: 4
 >> iter 41000, loss: 0.056307
 >> iter 42000, loss: 0.268911
 >> iter 43000, loss: 0.128964
 >> iter 44000, loss: 0.065654
 >> iter 45000, loss: 0.059162
 >> iter 46000, loss: 0.297723
 >> iter 47000, loss: 0.137304
 >> iter 48000, loss: 0.102854
 >> iter 49000, loss: 0.395822
 >> iter 50000, loss: 0.161961
   Number of active neurons: 4
 >> iter 51000, loss: 0.094308
 >> iter 52000, loss: 0.534897
 >> iter 53000, loss: 0.216594
 >> iter 54000, loss: 0.190840
 >> iter 55000, loss: 0.084107
 >> iter 56000, loss: 0.485764
 >> iter 57000, loss: 0.197529
 >> iter 58000, loss: 0.315856
 >> iter 59000, loss: 0.133678
 >> iter 60000, loss: 0.154603
   Number of active neurons: 4
 >> iter 61000, loss: 0.071345
 >> iter 62000, loss: 0.278822
 >> iter 63000, loss: 0.117437
 >> iter 64000, loss: 0.117642
 >> iter 65000, loss: 0.071207
 >> iter 66000, loss: 0.053878
 >> iter 67000, loss: 0.079307
 >> iter 68000, loss: 0.377712
 >> iter 69000, loss: 0.157281
 >> iter 70000, loss: 0.335144
   Number of active neurons: 4
 >> iter 71000, loss: 0.141652
 >> iter 72000, loss: 0.188872
 >> iter 73000, loss: 0.084715
 >> iter 74000, loss: 0.164262
 >> iter 75000, loss: 0.121198
 >> iter 76000, loss: 0.059954
 >> iter 77000, loss: 0.113222
 >> iter 78000, loss: 0.071390
 >> iter 79000, loss: 0.107350
 >> iter 80000, loss: 0.131077
   Number of active neurons: 4
 >> iter 81000, loss: 0.138767
 >> iter 82000, loss: 0.161272
 >> iter 83000, loss: 0.120865
 >> iter 84000, loss: 0.058831
 >> iter 85000, loss: 0.075623
 >> iter 86000, loss: 0.039491
 >> iter 87000, loss: 0.073806
 >> iter 88000, loss: 0.038547
 >> iter 89000, loss: 0.127713
 >> iter 90000, loss: 0.121856
   Number of active neurons: 3
 >> iter 91000, loss: 0.056585
 >> iter 92000, loss: 0.033010
 >> iter 93000, loss: 0.088474
 >> iter 94000, loss: 0.093654
 >> iter 95000, loss: 0.045425
 >> iter 96000, loss: 0.028449
 >> iter 97000, loss: 0.035609
 >> iter 98000, loss: 0.053178
 >> iter 99000, loss: 0.101949
 >> iter 100000, loss: 0.048469
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.382187
 >> iter 2000, loss: 6.179868
 >> iter 3000, loss: 2.295574
 >> iter 4000, loss: 0.860843
 >> iter 5000, loss: 0.361041
 >> iter 6000, loss: 0.145852
 >> iter 7000, loss: 0.072384
 >> iter 8000, loss: 0.071284
 >> iter 9000, loss: 0.050184
 >> iter 10000, loss: 0.076903
   Number of active neurons: 4
 >> iter 11000, loss: 0.068626
 >> iter 12000, loss: 0.524680
 >> iter 13000, loss: 0.214606
 >> iter 14000, loss: 0.269680
 >> iter 15000, loss: 0.116530
 >> iter 16000, loss: 0.154647
 >> iter 17000, loss: 0.090342
 >> iter 18000, loss: 0.361332
 >> iter 19000, loss: 0.169845
 >> iter 20000, loss: 0.088976
   Number of active neurons: 3
 >> iter 21000, loss: 0.063945
 >> iter 22000, loss: 0.371362
 >> iter 23000, loss: 0.155397
 >> iter 24000, loss: 0.498945
 >> iter 25000, loss: 0.206402
 >> iter 26000, loss: 0.419487
 >> iter 27000, loss: 0.232964
 >> iter 28000, loss: 0.492705
 >> iter 29000, loss: 0.338891
 >> iter 30000, loss: 0.156048
   Number of active neurons: 4
 >> iter 31000, loss: 0.092158
 >> iter 32000, loss: 0.384161
 >> iter 33000, loss: 0.315655
 >> iter 34000, loss: 0.326984
 >> iter 35000, loss: 0.147908
 >> iter 36000, loss: 0.191649
 >> iter 37000, loss: 0.175475
 >> iter 38000, loss: 0.348906
 >> iter 39000, loss: 0.218756
 >> iter 40000, loss: 0.130569
   Number of active neurons: 4
 >> iter 41000, loss: 0.120278
 >> iter 42000, loss: 0.209750
 >> iter 43000, loss: 0.091543
 >> iter 44000, loss: 0.109047
 >> iter 45000, loss: 0.120096
 >> iter 46000, loss: 0.447054
 >> iter 47000, loss: 0.226687
 >> iter 48000, loss: 0.132687
 >> iter 49000, loss: 0.063086
 >> iter 50000, loss: 0.136320
   Number of active neurons: 7
 >> iter 51000, loss: 0.109203
 >> iter 52000, loss: 0.243021
 >> iter 53000, loss: 0.111274
 >> iter 54000, loss: 0.166816
 >> iter 55000, loss: 0.113532
 >> iter 56000, loss: 0.179288
 >> iter 57000, loss: 0.079190
 >> iter 58000, loss: 0.042010
 >> iter 59000, loss: 0.026605
 >> iter 60000, loss: 0.132995
   Number of active neurons: 3
 >> iter 61000, loss: 0.076369
 >> iter 62000, loss: 0.155004
 >> iter 63000, loss: 0.084434
 >> iter 64000, loss: 0.222072
 >> iter 65000, loss: 0.117899
 >> iter 66000, loss: 0.218976
 >> iter 67000, loss: 0.107289
 >> iter 68000, loss: 0.147728
 >> iter 69000, loss: 0.069238
 >> iter 70000, loss: 0.094011
   Number of active neurons: 3
 >> iter 71000, loss: 0.047795
 >> iter 72000, loss: 0.031281
 >> iter 73000, loss: 0.060595
 >> iter 74000, loss: 0.048944
 >> iter 75000, loss: 0.031295
 >> iter 76000, loss: 0.026022
 >> iter 77000, loss: 0.040561
 >> iter 78000, loss: 0.088100
 >> iter 79000, loss: 0.063204
 >> iter 80000, loss: 0.098452
   Number of active neurons: 3
 >> iter 81000, loss: 0.091813
 >> iter 82000, loss: 0.081536
 >> iter 83000, loss: 0.042304
 >> iter 84000, loss: 0.061887
 >> iter 85000, loss: 0.068434
 >> iter 86000, loss: 0.035688
 >> iter 87000, loss: 0.030806
 >> iter 88000, loss: 0.025878
 >> iter 89000, loss: 0.070694
 >> iter 90000, loss: 0.049941
   Number of active neurons: 3
 >> iter 91000, loss: 0.037691
 >> iter 92000, loss: 0.024412
 >> iter 93000, loss: 0.052811
 >> iter 94000, loss: 0.029996
 >> iter 95000, loss: 0.050651
 >> iter 96000, loss: 0.028687
 >> iter 97000, loss: 0.056914
 >> iter 98000, loss: 0.031025
 >> iter 99000, loss: 0.103143
 >> iter 100000, loss: 0.049672
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.022872
 >> iter 2000, loss: 6.014062
 >> iter 3000, loss: 2.357025
 >> iter 4000, loss: 0.887555
 >> iter 5000, loss: 0.524669
 >> iter 6000, loss: 0.212382
 >> iter 7000, loss: 0.114461
 >> iter 8000, loss: 0.056497
 >> iter 9000, loss: 0.267081
 >> iter 10000, loss: 0.116475
   Number of active neurons: 5
 >> iter 11000, loss: 0.146079
 >> iter 12000, loss: 0.068617
 >> iter 13000, loss: 0.094460
 >> iter 14000, loss: 0.048555
 >> iter 15000, loss: 0.052646
 >> iter 16000, loss: 0.036935
 >> iter 17000, loss: 0.113640
 >> iter 18000, loss: 0.260821
 >> iter 19000, loss: 0.111884
 >> iter 20000, loss: 0.155382
   Number of active neurons: 4
 >> iter 21000, loss: 0.082436
 >> iter 22000, loss: 0.557897
 >> iter 23000, loss: 0.268671
 >> iter 24000, loss: 0.226135
 >> iter 25000, loss: 0.142248
 >> iter 26000, loss: 0.270498
 >> iter 27000, loss: 0.278583
 >> iter 28000, loss: 0.119325
 >> iter 29000, loss: 0.076556
 >> iter 30000, loss: 0.184639
   Number of active neurons: 3
 >> iter 31000, loss: 0.130022
 >> iter 32000, loss: 0.298501
 >> iter 33000, loss: 0.142125
 >> iter 34000, loss: 0.065801
 >> iter 35000, loss: 0.110631
 >> iter 36000, loss: 0.163110
 >> iter 37000, loss: 0.106455
 >> iter 38000, loss: 0.100755
 >> iter 39000, loss: 0.443889
 >> iter 40000, loss: 0.182418
   Number of active neurons: 3
 >> iter 41000, loss: 0.100705
 >> iter 42000, loss: 0.150003
 >> iter 43000, loss: 0.114780
 >> iter 44000, loss: 0.057820
 >> iter 45000, loss: 0.074733
 >> iter 46000, loss: 0.078365
 >> iter 47000, loss: 0.239883
 >> iter 48000, loss: 0.199461
 >> iter 49000, loss: 0.137566
 >> iter 50000, loss: 0.062822
   Number of active neurons: 3
 >> iter 51000, loss: 0.218030
 >> iter 52000, loss: 0.094752
 >> iter 53000, loss: 0.195011
 >> iter 54000, loss: 0.108310
 >> iter 55000, loss: 0.112475
 >> iter 56000, loss: 0.054247
 >> iter 57000, loss: 0.191658
 >> iter 58000, loss: 0.084012
 >> iter 59000, loss: 0.155025
 >> iter 60000, loss: 0.160898
   Number of active neurons: 3
 >> iter 61000, loss: 0.177211
 >> iter 62000, loss: 0.078942
 >> iter 63000, loss: 0.134718
 >> iter 64000, loss: 0.062840
 >> iter 65000, loss: 0.243995
 >> iter 66000, loss: 0.108560
 >> iter 67000, loss: 0.070663
 >> iter 68000, loss: 0.063889
 >> iter 69000, loss: 0.045941
 >> iter 70000, loss: 0.415727
   Number of active neurons: 3
 >> iter 71000, loss: 0.173670
 >> iter 72000, loss: 0.185148
 >> iter 73000, loss: 0.193041
 >> iter 74000, loss: 0.202725
 >> iter 75000, loss: 0.151253
 >> iter 76000, loss: 0.244107
 >> iter 77000, loss: 0.183623
 >> iter 78000, loss: 0.083111
 >> iter 79000, loss: 0.060000
 >> iter 80000, loss: 0.070345
   Number of active neurons: 3
 >> iter 81000, loss: 0.101210
 >> iter 82000, loss: 0.254233
 >> iter 83000, loss: 0.123260
 >> iter 84000, loss: 0.360534
 >> iter 85000, loss: 0.203615
 >> iter 86000, loss: 0.352612
 >> iter 87000, loss: 0.176941
 >> iter 88000, loss: 0.080207
 >> iter 89000, loss: 0.042722
 >> iter 90000, loss: 0.271221
   Number of active neurons: 3
 >> iter 91000, loss: 0.117389
 >> iter 92000, loss: 0.093718
 >> iter 93000, loss: 0.086526
 >> iter 94000, loss: 0.043182
 >> iter 95000, loss: 0.049699
 >> iter 96000, loss: 0.601385
 >> iter 97000, loss: 0.414878
 >> iter 98000, loss: 0.173764
 >> iter 99000, loss: 0.087518
 >> iter 100000, loss: 0.104773
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.514008
 >> iter 2000, loss: 6.338173
 >> iter 3000, loss: 2.409262
 >> iter 4000, loss: 1.021551
 >> iter 5000, loss: 0.416966
 >> iter 6000, loss: 0.387012
 >> iter 7000, loss: 0.157472
 >> iter 8000, loss: 0.217005
 >> iter 9000, loss: 0.175758
 >> iter 10000, loss: 0.193656
   Number of active neurons: 5
 >> iter 11000, loss: 0.110178
 >> iter 12000, loss: 0.193708
 >> iter 13000, loss: 0.110459
 >> iter 14000, loss: 0.072762
 >> iter 15000, loss: 0.076149
 >> iter 16000, loss: 0.063688
 >> iter 17000, loss: 0.122855
 >> iter 18000, loss: 0.070856
 >> iter 19000, loss: 0.041422
 >> iter 20000, loss: 0.235184
   Number of active neurons: 5
 >> iter 21000, loss: 0.252860
 >> iter 22000, loss: 0.157576
 >> iter 23000, loss: 0.206385
 >> iter 24000, loss: 0.091183
 >> iter 25000, loss: 0.240455
 >> iter 26000, loss: 0.114555
 >> iter 27000, loss: 0.204786
 >> iter 28000, loss: 0.270829
 >> iter 29000, loss: 0.203428
 >> iter 30000, loss: 0.228776
   Number of active neurons: 5
 >> iter 31000, loss: 0.100017
 >> iter 32000, loss: 0.236428
 >> iter 33000, loss: 0.223838
 >> iter 34000, loss: 0.180832
 >> iter 35000, loss: 0.080412
 >> iter 36000, loss: 0.234468
 >> iter 37000, loss: 0.219482
 >> iter 38000, loss: 0.155232
 >> iter 39000, loss: 0.337194
 >> iter 40000, loss: 0.339916
   Number of active neurons: 5
 >> iter 41000, loss: 0.140914
 >> iter 42000, loss: 0.310598
 >> iter 43000, loss: 0.129000
 >> iter 44000, loss: 0.184176
 >> iter 45000, loss: 0.079783
 >> iter 46000, loss: 0.181900
 >> iter 47000, loss: 0.188700
 >> iter 48000, loss: 0.204897
 >> iter 49000, loss: 0.116383
 >> iter 50000, loss: 0.441724
   Number of active neurons: 4
 >> iter 51000, loss: 0.180836
 >> iter 52000, loss: 0.353849
 >> iter 53000, loss: 0.147209
 >> iter 54000, loss: 0.126231
 >> iter 55000, loss: 0.058918
 >> iter 56000, loss: 0.202456
 >> iter 57000, loss: 0.086976
 >> iter 58000, loss: 0.180275
 >> iter 59000, loss: 0.080145
 >> iter 60000, loss: 0.129451
   Number of active neurons: 4
 >> iter 61000, loss: 0.059059
 >> iter 62000, loss: 0.034676
 >> iter 63000, loss: 0.387762
 >> iter 64000, loss: 0.263320
 >> iter 65000, loss: 0.112880
 >> iter 66000, loss: 0.056120
 >> iter 67000, loss: 0.088881
 >> iter 68000, loss: 0.171040
 >> iter 69000, loss: 0.144798
 >> iter 70000, loss: 0.221011
   Number of active neurons: 4
 >> iter 71000, loss: 0.103247
 >> iter 72000, loss: 0.174642
 >> iter 73000, loss: 0.171815
 >> iter 74000, loss: 0.229308
 >> iter 75000, loss: 0.121203
 >> iter 76000, loss: 0.112416
 >> iter 77000, loss: 0.161690
 >> iter 78000, loss: 0.215030
 >> iter 79000, loss: 0.136954
 >> iter 80000, loss: 0.175728
   Number of active neurons: 4
 >> iter 81000, loss: 0.179514
 >> iter 82000, loss: 0.297918
 >> iter 83000, loss: 0.178230
 >> iter 84000, loss: 0.161816
 >> iter 85000, loss: 0.099015
 >> iter 86000, loss: 0.161745
 >> iter 87000, loss: 0.144408
 >> iter 88000, loss: 0.105720
 >> iter 89000, loss: 0.141748
 >> iter 90000, loss: 0.175878
   Number of active neurons: 4
 >> iter 91000, loss: 0.141452
 >> iter 92000, loss: 0.174178
 >> iter 93000, loss: 0.187836
 >> iter 94000, loss: 0.191226
 >> iter 95000, loss: 0.140675
 >> iter 96000, loss: 0.174836
 >> iter 97000, loss: 0.148797
 >> iter 98000, loss: 0.070875
 >> iter 99000, loss: 0.109258
 >> iter 100000, loss: 0.234184
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.147997040059
   - Test - Long: 0.964951752412
   - Test - Big: 0.10499895001
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.274814
 >> iter 2000, loss: 6.386540
 >> iter 3000, loss: 2.443568
 >> iter 4000, loss: 0.925172
 >> iter 5000, loss: 0.360350
 >> iter 6000, loss: 0.149340
 >> iter 7000, loss: 0.069695
 >> iter 8000, loss: 0.040411
 >> iter 9000, loss: 0.027496
 >> iter 10000, loss: 0.026320
   Number of active neurons: 2
 >> iter 11000, loss: 0.021133
 >> iter 12000, loss: 0.021245
 >> iter 13000, loss: 0.019760
 >> iter 14000, loss: 0.156404
 >> iter 15000, loss: 0.068672
 >> iter 16000, loss: 0.039041
 >> iter 17000, loss: 0.126519
 >> iter 18000, loss: 0.159117
 >> iter 19000, loss: 0.362404
 >> iter 20000, loss: 0.630556
   Number of active neurons: 2
 >> iter 21000, loss: 0.332010
 >> iter 22000, loss: 0.347276
 >> iter 23000, loss: 0.214705
 >> iter 24000, loss: 0.162118
 >> iter 25000, loss: 0.076936
 >> iter 26000, loss: 0.045352
 >> iter 27000, loss: 0.303915
 >> iter 28000, loss: 0.130002
 >> iter 29000, loss: 0.343529
 >> iter 30000, loss: 0.363119
   Number of active neurons: 2
 >> iter 31000, loss: 0.534089
 >> iter 32000, loss: 0.684733
 >> iter 33000, loss: 0.381972
 >> iter 34000, loss: 0.172722
 >> iter 35000, loss: 0.080820
 >> iter 36000, loss: 0.045998
 >> iter 37000, loss: 0.029617
 >> iter 38000, loss: 0.027488
 >> iter 39000, loss: 0.021216
 >> iter 40000, loss: 0.036356
   Number of active neurons: 2
 >> iter 41000, loss: 0.042664
 >> iter 42000, loss: 0.032152
 >> iter 43000, loss: 0.044574
 >> iter 44000, loss: 0.178143
 >> iter 45000, loss: 0.104478
 >> iter 46000, loss: 0.952490
 >> iter 47000, loss: 0.500395
 >> iter 48000, loss: 0.588360
 >> iter 49000, loss: 0.273142
 >> iter 50000, loss: 0.277456
   Number of active neurons: 3
 >> iter 51000, loss: 0.120551
 >> iter 52000, loss: 0.062623
 >> iter 53000, loss: 0.036307
 >> iter 54000, loss: 0.069396
 >> iter 55000, loss: 0.489619
 >> iter 56000, loss: 0.310703
 >> iter 57000, loss: 0.131194
 >> iter 58000, loss: 0.062168
 >> iter 59000, loss: 0.034984
 >> iter 60000, loss: 0.024878
   Number of active neurons: 3
 >> iter 61000, loss: 0.019346
 >> iter 62000, loss: 0.151529
 >> iter 63000, loss: 0.166029
 >> iter 64000, loss: 0.072979
 >> iter 65000, loss: 0.144314
 >> iter 66000, loss: 0.070604
 >> iter 67000, loss: 0.064043
 >> iter 68000, loss: 0.138432
 >> iter 69000, loss: 0.061627
 >> iter 70000, loss: 0.039755
   Number of active neurons: 3
 >> iter 71000, loss: 0.124148
 >> iter 72000, loss: 0.204993
 >> iter 73000, loss: 0.103423
 >> iter 74000, loss: 0.056518
 >> iter 75000, loss: 0.030373
 >> iter 76000, loss: 0.103002
 >> iter 77000, loss: 0.047481
 >> iter 78000, loss: 0.051916
 >> iter 79000, loss: 0.142626
 >> iter 80000, loss: 0.154968
   Number of active neurons: 3
 >> iter 81000, loss: 0.067713
 >> iter 82000, loss: 0.215757
 >> iter 83000, loss: 0.164486
 >> iter 84000, loss: 0.077511
 >> iter 85000, loss: 0.039737
 >> iter 86000, loss: 0.036780
 >> iter 87000, loss: 0.023368
 >> iter 88000, loss: 0.133858
 >> iter 89000, loss: 0.059997
 >> iter 90000, loss: 0.135919
   Number of active neurons: 3
 >> iter 91000, loss: 0.189886
 >> iter 92000, loss: 0.150315
 >> iter 93000, loss: 0.066649
 >> iter 94000, loss: 0.055472
 >> iter 95000, loss: 0.111860
 >> iter 96000, loss: 0.283713
 >> iter 97000, loss: 0.116753
 >> iter 98000, loss: 0.081228
 >> iter 99000, loss: 0.040379
 >> iter 100000, loss: 0.085736
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.242216
 >> iter 2000, loss: 6.504002
 >> iter 3000, loss: 2.420012
 >> iter 4000, loss: 0.908928
 >> iter 5000, loss: 0.472046
 >> iter 6000, loss: 0.191410
 >> iter 7000, loss: 0.221727
 >> iter 8000, loss: 0.144858
 >> iter 9000, loss: 0.081692
 >> iter 10000, loss: 0.362881
   Number of active neurons: 6
 >> iter 11000, loss: 0.257822
 >> iter 12000, loss: 0.331406
 >> iter 13000, loss: 0.555423
 >> iter 14000, loss: 0.226547
 >> iter 15000, loss: 0.099585
 >> iter 16000, loss: 0.122536
 >> iter 17000, loss: 0.107070
 >> iter 18000, loss: 0.205923
 >> iter 19000, loss: 0.253272
 >> iter 20000, loss: 0.345297
   Number of active neurons: 4
 >> iter 21000, loss: 0.160795
 >> iter 22000, loss: 0.172559
 >> iter 23000, loss: 0.091521
 >> iter 24000, loss: 0.498904
 >> iter 25000, loss: 0.467945
 >> iter 26000, loss: 0.273169
 >> iter 27000, loss: 0.116649
 >> iter 28000, loss: 0.237145
 >> iter 29000, loss: 0.135964
 >> iter 30000, loss: 0.538357
   Number of active neurons: 4
 >> iter 31000, loss: 0.229637
 >> iter 32000, loss: 0.100519
 >> iter 33000, loss: 0.217516
 >> iter 34000, loss: 0.237528
 >> iter 35000, loss: 0.107083
 >> iter 36000, loss: 0.053891
 >> iter 37000, loss: 0.120396
 >> iter 38000, loss: 0.273855
 >> iter 39000, loss: 0.117692
 >> iter 40000, loss: 0.250414
   Number of active neurons: 4
 >> iter 41000, loss: 0.107685
 >> iter 42000, loss: 0.054055
 >> iter 43000, loss: 0.157939
 >> iter 44000, loss: 0.072960
 >> iter 45000, loss: 0.149731
 >> iter 46000, loss: 0.167548
 >> iter 47000, loss: 0.104572
 >> iter 48000, loss: 0.052708
 >> iter 49000, loss: 0.124428
 >> iter 50000, loss: 0.221646
   Number of active neurons: 4
 >> iter 51000, loss: 0.143059
 >> iter 52000, loss: 0.066597
 >> iter 53000, loss: 0.080866
 >> iter 54000, loss: 0.046385
 >> iter 55000, loss: 0.199011
 >> iter 56000, loss: 0.091657
 >> iter 57000, loss: 0.061787
 >> iter 58000, loss: 0.121337
 >> iter 59000, loss: 0.165796
 >> iter 60000, loss: 0.083974
   Number of active neurons: 4
 >> iter 61000, loss: 0.122889
 >> iter 62000, loss: 0.164521
 >> iter 63000, loss: 0.210499
 >> iter 64000, loss: 0.179412
 >> iter 65000, loss: 0.080627
 >> iter 66000, loss: 0.115096
 >> iter 67000, loss: 0.055799
 >> iter 68000, loss: 0.127176
 >> iter 69000, loss: 0.059604
 >> iter 70000, loss: 0.216479
   Number of active neurons: 3
 >> iter 71000, loss: 0.158463
 >> iter 72000, loss: 0.203589
 >> iter 73000, loss: 0.106777
 >> iter 74000, loss: 0.051931
 >> iter 75000, loss: 0.056982
 >> iter 76000, loss: 0.147758
 >> iter 77000, loss: 0.159608
 >> iter 78000, loss: 0.115801
 >> iter 79000, loss: 0.110247
 >> iter 80000, loss: 0.056228
   Number of active neurons: 3
 >> iter 81000, loss: 0.083818
 >> iter 82000, loss: 0.131255
 >> iter 83000, loss: 0.217923
 >> iter 84000, loss: 0.242831
 >> iter 85000, loss: 0.104039
 >> iter 86000, loss: 0.123374
 >> iter 87000, loss: 0.057894
 >> iter 88000, loss: 0.148650
 >> iter 89000, loss: 0.065980
 >> iter 90000, loss: 0.167776
   Number of active neurons: 3
 >> iter 91000, loss: 0.073819
 >> iter 92000, loss: 0.096591
 >> iter 93000, loss: 0.046897
 >> iter 94000, loss: 0.396828
 >> iter 95000, loss: 0.163964
 >> iter 96000, loss: 0.231440
 >> iter 97000, loss: 0.099515
 >> iter 98000, loss: 0.106411
 >> iter 99000, loss: 0.131488
 >> iter 100000, loss: 0.099991
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.002446
 >> iter 2000, loss: 6.785234
 >> iter 3000, loss: 2.522938
 >> iter 4000, loss: 0.945741
 >> iter 5000, loss: 0.415956
 >> iter 6000, loss: 0.597497
 >> iter 7000, loss: 0.258782
 >> iter 8000, loss: 0.110649
 >> iter 9000, loss: 0.135801
 >> iter 10000, loss: 0.854046
   Number of active neurons: 8
 >> iter 11000, loss: 0.353125
 >> iter 12000, loss: 0.145666
 >> iter 13000, loss: 0.117094
 >> iter 14000, loss: 0.280170
 >> iter 15000, loss: 0.183883
 >> iter 16000, loss: 0.082879
 >> iter 17000, loss: 0.150212
 >> iter 18000, loss: 0.070546
 >> iter 19000, loss: 0.431645
 >> iter 20000, loss: 0.243438
   Number of active neurons: 5
 >> iter 21000, loss: 0.156335
 >> iter 22000, loss: 0.071940
 >> iter 23000, loss: 0.157535
 >> iter 24000, loss: 0.381622
 >> iter 25000, loss: 0.228950
 >> iter 26000, loss: 0.696503
 >> iter 27000, loss: 0.305153
 >> iter 28000, loss: 0.127495
 >> iter 29000, loss: 0.270478
 >> iter 30000, loss: 0.143501
   Number of active neurons: 5
 >> iter 31000, loss: 0.104500
 >> iter 32000, loss: 0.053001
 >> iter 33000, loss: 0.078010
 >> iter 34000, loss: 0.365317
 >> iter 35000, loss: 0.215228
 >> iter 36000, loss: 0.095295
 >> iter 37000, loss: 0.067092
 >> iter 38000, loss: 0.037243
 >> iter 39000, loss: 0.096809
 >> iter 40000, loss: 0.048763
   Number of active neurons: 4
 >> iter 41000, loss: 0.209067
 >> iter 42000, loss: 0.092749
 >> iter 43000, loss: 0.098145
 >> iter 44000, loss: 0.050193
 >> iter 45000, loss: 0.105223
 >> iter 46000, loss: 0.105291
 >> iter 47000, loss: 0.220772
 >> iter 48000, loss: 0.148381
 >> iter 49000, loss: 0.107347
 >> iter 50000, loss: 0.352628
   Number of active neurons: 4
 >> iter 51000, loss: 0.232738
 >> iter 52000, loss: 0.127138
 >> iter 53000, loss: 0.060941
 >> iter 54000, loss: 0.222542
 >> iter 55000, loss: 0.139976
 >> iter 56000, loss: 0.089107
 >> iter 57000, loss: 0.067250
 >> iter 58000, loss: 0.097055
 >> iter 59000, loss: 0.073278
 >> iter 60000, loss: 0.059801
   Number of active neurons: 4
 >> iter 61000, loss: 0.082991
 >> iter 62000, loss: 0.111541
 >> iter 63000, loss: 0.227722
 >> iter 64000, loss: 0.100773
 >> iter 65000, loss: 0.105251
 >> iter 66000, loss: 0.123999
 >> iter 67000, loss: 0.097489
 >> iter 68000, loss: 0.105520
 >> iter 69000, loss: 0.095985
 >> iter 70000, loss: 0.049937
   Number of active neurons: 4
 >> iter 71000, loss: 0.093894
 >> iter 72000, loss: 0.047147
 >> iter 73000, loss: 0.118980
 >> iter 74000, loss: 0.057560
 >> iter 75000, loss: 0.083291
 >> iter 76000, loss: 0.044704
 >> iter 77000, loss: 0.139368
 >> iter 78000, loss: 0.068349
 >> iter 79000, loss: 0.191686
 >> iter 80000, loss: 0.089517
   Number of active neurons: 4
 >> iter 81000, loss: 0.049578
 >> iter 82000, loss: 0.030535
 >> iter 83000, loss: 0.061665
 >> iter 84000, loss: 0.034968
 >> iter 85000, loss: 0.047841
 >> iter 86000, loss: 0.216295
 >> iter 87000, loss: 0.136594
 >> iter 88000, loss: 0.066212
 >> iter 89000, loss: 0.060675
 >> iter 90000, loss: 0.108798
   Number of active neurons: 4
 >> iter 91000, loss: 0.080737
 >> iter 92000, loss: 0.043440
 >> iter 93000, loss: 0.067566
 >> iter 94000, loss: 0.062552
 >> iter 95000, loss: 0.073117
 >> iter 96000, loss: 0.075442
 >> iter 97000, loss: 0.049807
 >> iter 98000, loss: 0.030953
 >> iter 99000, loss: 0.046019
 >> iter 100000, loss: 0.029802
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.647737
 >> iter 2000, loss: 6.822498
 >> iter 3000, loss: 2.606533
 >> iter 4000, loss: 0.978428
 >> iter 5000, loss: 0.589800
 >> iter 6000, loss: 0.236694
 >> iter 7000, loss: 0.384260
 >> iter 8000, loss: 0.255246
 >> iter 9000, loss: 0.201651
 >> iter 10000, loss: 0.133286
   Number of active neurons: 5
 >> iter 11000, loss: 0.144803
 >> iter 12000, loss: 0.068745
 >> iter 13000, loss: 0.380325
 >> iter 14000, loss: 0.161087
 >> iter 15000, loss: 0.108312
 >> iter 16000, loss: 0.185845
 >> iter 17000, loss: 0.178215
 >> iter 18000, loss: 0.486506
 >> iter 19000, loss: 0.270776
 >> iter 20000, loss: 0.753666
   Number of active neurons: 4
 >> iter 21000, loss: 0.306682
 >> iter 22000, loss: 0.550316
 >> iter 23000, loss: 0.225129
 >> iter 24000, loss: 0.284997
 >> iter 25000, loss: 0.177572
 >> iter 26000, loss: 0.196537
 >> iter 27000, loss: 0.107636
 >> iter 28000, loss: 0.393578
 >> iter 29000, loss: 0.225067
 >> iter 30000, loss: 0.225999
   Number of active neurons: 4
 >> iter 31000, loss: 0.393360
 >> iter 32000, loss: 0.490949
 >> iter 33000, loss: 0.201912
 >> iter 34000, loss: 0.205859
 >> iter 35000, loss: 0.165812
 >> iter 36000, loss: 0.278019
 >> iter 37000, loss: 0.539616
 >> iter 38000, loss: 0.327439
 >> iter 39000, loss: 0.136266
 >> iter 40000, loss: 0.544214
   Number of active neurons: 4
 >> iter 41000, loss: 0.220758
 >> iter 42000, loss: 0.318421
 >> iter 43000, loss: 0.133759
 >> iter 44000, loss: 0.252006
 >> iter 45000, loss: 0.367154
 >> iter 46000, loss: 0.273710
 >> iter 47000, loss: 0.270801
 >> iter 48000, loss: 0.227273
 >> iter 49000, loss: 0.199997
 >> iter 50000, loss: 0.275857
   Number of active neurons: 4
 >> iter 51000, loss: 0.223681
 >> iter 52000, loss: 0.196169
 >> iter 53000, loss: 0.169118
 >> iter 54000, loss: 0.108533
 >> iter 55000, loss: 0.116149
 >> iter 56000, loss: 0.165480
 >> iter 57000, loss: 0.138161
 >> iter 58000, loss: 0.104847
 >> iter 59000, loss: 0.060283
 >> iter 60000, loss: 0.033531
   Number of active neurons: 4
 >> iter 61000, loss: 0.112537
 >> iter 62000, loss: 0.053628
 >> iter 63000, loss: 0.127959
 >> iter 64000, loss: 0.059455
 >> iter 65000, loss: 0.080766
 >> iter 66000, loss: 0.042653
 >> iter 67000, loss: 0.131116
 >> iter 68000, loss: 0.228740
 >> iter 69000, loss: 0.099320
 >> iter 70000, loss: 0.049282
   Number of active neurons: 3
 >> iter 71000, loss: 0.083102
 >> iter 72000, loss: 0.042556
 >> iter 73000, loss: 0.127795
 >> iter 74000, loss: 0.152682
 >> iter 75000, loss: 0.138015
 >> iter 76000, loss: 0.290016
 >> iter 77000, loss: 0.143143
 >> iter 78000, loss: 0.210755
 >> iter 79000, loss: 0.109969
 >> iter 80000, loss: 0.535360
   Number of active neurons: 4
 >> iter 81000, loss: 0.215429
 >> iter 82000, loss: 0.167264
 >> iter 83000, loss: 0.192183
 >> iter 84000, loss: 0.116357
 >> iter 85000, loss: 0.095892
 >> iter 86000, loss: 0.188503
 >> iter 87000, loss: 0.082493
 >> iter 88000, loss: 0.112860
 >> iter 89000, loss: 0.052445
 >> iter 90000, loss: 0.236745
   Number of active neurons: 4
 >> iter 91000, loss: 0.191562
 >> iter 92000, loss: 0.260049
 >> iter 93000, loss: 0.110352
 >> iter 94000, loss: 0.210268
 >> iter 95000, loss: 0.153350
 >> iter 96000, loss: 0.225706
 >> iter 97000, loss: 0.194431
 >> iter 98000, loss: 0.086416
 >> iter 99000, loss: 0.081514
 >> iter 100000, loss: 0.063453
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.636695
 >> iter 2000, loss: 6.825290
 >> iter 3000, loss: 2.544486
 >> iter 4000, loss: 0.955290
 >> iter 5000, loss: 0.366922
 >> iter 6000, loss: 0.549108
 >> iter 7000, loss: 0.297477
 >> iter 8000, loss: 0.126471
 >> iter 9000, loss: 0.105411
 >> iter 10000, loss: 0.134989
   Number of active neurons: 3
 >> iter 11000, loss: 0.063722
 >> iter 12000, loss: 0.057497
 >> iter 13000, loss: 0.101428
 >> iter 14000, loss: 0.364015
 >> iter 15000, loss: 0.184779
 >> iter 16000, loss: 0.090131
 >> iter 17000, loss: 0.165651
 >> iter 18000, loss: 0.078291
 >> iter 19000, loss: 0.102698
 >> iter 20000, loss: 0.184164
   Number of active neurons: 3
 >> iter 21000, loss: 0.082083
 >> iter 22000, loss: 0.052871
 >> iter 23000, loss: 0.073965
 >> iter 24000, loss: 0.695764
 >> iter 25000, loss: 0.309460
 >> iter 26000, loss: 0.133612
 >> iter 27000, loss: 0.063256
 >> iter 28000, loss: 0.039087
 >> iter 29000, loss: 0.100676
 >> iter 30000, loss: 0.717669
   Number of active neurons: 3
 >> iter 31000, loss: 0.306062
 >> iter 32000, loss: 0.130903
 >> iter 33000, loss: 0.080268
 >> iter 34000, loss: 0.043096
 >> iter 35000, loss: 0.197022
 >> iter 36000, loss: 0.557779
 >> iter 37000, loss: 0.228407
 >> iter 38000, loss: 0.142426
 >> iter 39000, loss: 0.121123
 >> iter 40000, loss: 0.298141
   Number of active neurons: 3
 >> iter 41000, loss: 0.166512
 >> iter 42000, loss: 0.076566
 >> iter 43000, loss: 0.261538
 >> iter 44000, loss: 0.505841
 >> iter 45000, loss: 0.246487
 >> iter 46000, loss: 0.750840
 >> iter 47000, loss: 0.325701
 >> iter 48000, loss: 0.185993
 >> iter 49000, loss: 0.241703
 >> iter 50000, loss: 0.110745
   Number of active neurons: 3
 >> iter 51000, loss: 0.251587
 >> iter 52000, loss: 0.110531
 >> iter 53000, loss: 0.471134
 >> iter 54000, loss: 0.195805
 >> iter 55000, loss: 0.119640
 >> iter 56000, loss: 0.057520
 >> iter 57000, loss: 0.208763
 >> iter 58000, loss: 0.529049
 >> iter 59000, loss: 0.219947
 >> iter 60000, loss: 0.097052
   Number of active neurons: 3
 >> iter 61000, loss: 0.119345
 >> iter 62000, loss: 0.058082
 >> iter 63000, loss: 0.206751
 >> iter 64000, loss: 0.092278
 >> iter 65000, loss: 0.222036
 >> iter 66000, loss: 0.097917
 >> iter 67000, loss: 0.260907
 >> iter 68000, loss: 0.175252
 >> iter 69000, loss: 0.135546
 >> iter 70000, loss: 0.096318
   Number of active neurons: 3
 >> iter 71000, loss: 0.161347
 >> iter 72000, loss: 0.110694
 >> iter 73000, loss: 0.070818
 >> iter 74000, loss: 0.039606
 >> iter 75000, loss: 0.089611
 >> iter 76000, loss: 0.204131
 >> iter 77000, loss: 0.095251
 >> iter 78000, loss: 0.045998
 >> iter 79000, loss: 0.107906
 >> iter 80000, loss: 0.051126
   Number of active neurons: 3
 >> iter 81000, loss: 0.090946
 >> iter 82000, loss: 0.236034
 >> iter 83000, loss: 0.203333
 >> iter 84000, loss: 0.200437
 >> iter 85000, loss: 0.204357
 >> iter 86000, loss: 0.172926
 >> iter 87000, loss: 0.170427
 >> iter 88000, loss: 0.109036
 >> iter 89000, loss: 0.051996
 >> iter 90000, loss: 0.029977
   Number of active neurons: 3
 >> iter 91000, loss: 0.085868
 >> iter 92000, loss: 0.092399
 >> iter 93000, loss: 0.056645
 >> iter 94000, loss: 0.156230
 >> iter 95000, loss: 0.141321
 >> iter 96000, loss: 0.063840
 >> iter 97000, loss: 0.218982
 >> iter 98000, loss: 0.093943
 >> iter 99000, loss: 0.178885
 >> iter 100000, loss: 0.201171
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0639987200256
   - Test - Long: 0.1599920004
   - Test - Big: 0.0189998100019
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.664916
 >> iter 2000, loss: 5.959312
 >> iter 3000, loss: 2.215519
 >> iter 4000, loss: 0.831930
 >> iter 5000, loss: 0.320829
 >> iter 6000, loss: 0.131481
 >> iter 7000, loss: 0.095709
 >> iter 8000, loss: 0.048065
 >> iter 9000, loss: 0.067271
 >> iter 10000, loss: 0.037920
   Number of active neurons: 4
 >> iter 11000, loss: 0.063559
 >> iter 12000, loss: 0.040729
 >> iter 13000, loss: 0.061884
 >> iter 14000, loss: 0.071549
 >> iter 15000, loss: 0.223193
 >> iter 16000, loss: 0.165979
 >> iter 17000, loss: 0.075714
 >> iter 18000, loss: 0.132897
 >> iter 19000, loss: 0.068519
 >> iter 20000, loss: 0.041033
   Number of active neurons: 4
 >> iter 21000, loss: 0.320438
 >> iter 22000, loss: 0.135630
 >> iter 23000, loss: 0.083226
 >> iter 24000, loss: 0.373865
 >> iter 25000, loss: 0.235923
 >> iter 26000, loss: 0.225895
 >> iter 27000, loss: 0.142784
 >> iter 28000, loss: 0.066602
 >> iter 29000, loss: 0.069210
 >> iter 30000, loss: 0.228188
   Number of active neurons: 4
 >> iter 31000, loss: 0.106628
 >> iter 32000, loss: 0.183170
 >> iter 33000, loss: 0.081308
 >> iter 34000, loss: 0.228708
 >> iter 35000, loss: 0.122842
 >> iter 36000, loss: 0.299556
 >> iter 37000, loss: 0.126420
 >> iter 38000, loss: 0.709906
 >> iter 39000, loss: 0.307176
 >> iter 40000, loss: 0.138018
   Number of active neurons: 4
 >> iter 41000, loss: 0.063914
 >> iter 42000, loss: 0.278465
 >> iter 43000, loss: 0.118693
 >> iter 44000, loss: 0.462235
 >> iter 45000, loss: 0.191295
 >> iter 46000, loss: 0.084848
 >> iter 47000, loss: 0.059068
 >> iter 48000, loss: 0.119033
 >> iter 49000, loss: 0.061841
 >> iter 50000, loss: 0.478484
   Number of active neurons: 4
 >> iter 51000, loss: 0.266480
 >> iter 52000, loss: 0.301816
 >> iter 53000, loss: 0.227657
 >> iter 54000, loss: 0.326095
 >> iter 55000, loss: 0.192381
 >> iter 56000, loss: 0.213337
 >> iter 57000, loss: 0.134207
 >> iter 58000, loss: 0.098457
 >> iter 59000, loss: 0.101066
 >> iter 60000, loss: 0.297020
   Number of active neurons: 4
 >> iter 61000, loss: 0.139817
 >> iter 62000, loss: 0.077973
 >> iter 63000, loss: 0.041436
 >> iter 64000, loss: 0.044732
 >> iter 65000, loss: 0.028235
 >> iter 66000, loss: 0.032908
 >> iter 67000, loss: 0.025060
 >> iter 68000, loss: 0.281698
 >> iter 69000, loss: 0.144235
 >> iter 70000, loss: 0.066232
   Number of active neurons: 3
 >> iter 71000, loss: 0.049901
 >> iter 72000, loss: 0.260565
 >> iter 73000, loss: 0.131244
 >> iter 74000, loss: 0.177327
 >> iter 75000, loss: 0.087023
 >> iter 76000, loss: 0.043891
 >> iter 77000, loss: 0.055169
 >> iter 78000, loss: 0.280663
 >> iter 79000, loss: 0.138370
 >> iter 80000, loss: 0.119843
   Number of active neurons: 3
 >> iter 81000, loss: 0.090644
 >> iter 82000, loss: 0.044180
 >> iter 83000, loss: 0.052850
 >> iter 84000, loss: 0.029369
 >> iter 85000, loss: 0.095075
 >> iter 86000, loss: 0.045273
 >> iter 87000, loss: 0.034580
 >> iter 88000, loss: 0.045287
 >> iter 89000, loss: 0.067790
 >> iter 90000, loss: 0.041190
   Number of active neurons: 3
 >> iter 91000, loss: 0.148386
 >> iter 92000, loss: 0.178305
 >> iter 93000, loss: 0.161958
 >> iter 94000, loss: 0.296660
 >> iter 95000, loss: 0.218627
 >> iter 96000, loss: 0.095772
 >> iter 97000, loss: 0.048365
 >> iter 98000, loss: 0.101212
 >> iter 99000, loss: 0.191208
 >> iter 100000, loss: 0.174967
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0039999200016
   - Test - Long: 0.0
   - Test - Big: 0.029999700003
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.740098
 >> iter 2000, loss: 6.188274
 >> iter 3000, loss: 2.304794
 >> iter 4000, loss: 0.873211
 >> iter 5000, loss: 0.336077
 >> iter 6000, loss: 0.224321
 >> iter 7000, loss: 0.120853
 >> iter 8000, loss: 0.057393
 >> iter 9000, loss: 0.264539
 >> iter 10000, loss: 0.113849
   Number of active neurons: 3
 >> iter 11000, loss: 0.055885
 >> iter 12000, loss: 0.473706
 >> iter 13000, loss: 0.371624
 >> iter 14000, loss: 0.159920
 >> iter 15000, loss: 0.122523
 >> iter 16000, loss: 0.597484
 >> iter 17000, loss: 0.314174
 >> iter 18000, loss: 0.135156
 >> iter 19000, loss: 0.064742
 >> iter 20000, loss: 0.330837
   Number of active neurons: 3
 >> iter 21000, loss: 0.140024
 >> iter 22000, loss: 0.066941
 >> iter 23000, loss: 0.037011
 >> iter 24000, loss: 0.029312
 >> iter 25000, loss: 0.553534
 >> iter 26000, loss: 0.226061
 >> iter 27000, loss: 0.135109
 >> iter 28000, loss: 0.064411
 >> iter 29000, loss: 0.282105
 >> iter 30000, loss: 0.122499
   Number of active neurons: 3
 >> iter 31000, loss: 0.128480
 >> iter 32000, loss: 0.063155
 >> iter 33000, loss: 0.642355
 >> iter 34000, loss: 0.267407
 >> iter 35000, loss: 0.143203
 >> iter 36000, loss: 0.067692
 >> iter 37000, loss: 0.130392
 >> iter 38000, loss: 0.062348
 >> iter 39000, loss: 0.059714
 >> iter 40000, loss: 0.064669
   Number of active neurons: 3
 >> iter 41000, loss: 0.250001
 >> iter 42000, loss: 0.110670
 >> iter 43000, loss: 0.072883
 >> iter 44000, loss: 0.038061
 >> iter 45000, loss: 0.045871
 >> iter 46000, loss: 0.064350
 >> iter 47000, loss: 0.099116
 >> iter 48000, loss: 0.120591
 >> iter 49000, loss: 0.084925
 >> iter 50000, loss: 0.078173
   Number of active neurons: 3
 >> iter 51000, loss: 0.079050
 >> iter 52000, loss: 0.146233
 >> iter 53000, loss: 0.065905
 >> iter 54000, loss: 0.035424
 >> iter 55000, loss: 0.102728
 >> iter 56000, loss: 0.097288
 >> iter 57000, loss: 0.238194
 >> iter 58000, loss: 0.113802
 >> iter 59000, loss: 0.061683
 >> iter 60000, loss: 0.092686
   Number of active neurons: 3
 >> iter 61000, loss: 0.088537
 >> iter 62000, loss: 0.043924
 >> iter 63000, loss: 0.200637
 >> iter 64000, loss: 0.087014
 >> iter 65000, loss: 0.122985
 >> iter 66000, loss: 0.112891
 >> iter 67000, loss: 0.053084
 >> iter 68000, loss: 0.032601
 >> iter 69000, loss: 0.041035
 >> iter 70000, loss: 0.239870
   Number of active neurons: 3
 >> iter 71000, loss: 0.114005
 >> iter 72000, loss: 0.323033
 >> iter 73000, loss: 0.134358
 >> iter 74000, loss: 0.301883
 >> iter 75000, loss: 0.126777
 >> iter 76000, loss: 0.168501
 >> iter 77000, loss: 0.252348
 >> iter 78000, loss: 0.237757
 >> iter 79000, loss: 0.198579
 >> iter 80000, loss: 0.087179
   Number of active neurons: 3
 >> iter 81000, loss: 0.060858
 >> iter 82000, loss: 0.161955
 >> iter 83000, loss: 0.116935
 >> iter 84000, loss: 0.055833
 >> iter 85000, loss: 0.068064
 >> iter 86000, loss: 0.245452
 >> iter 87000, loss: 0.148637
 >> iter 88000, loss: 0.067428
 >> iter 89000, loss: 0.054566
 >> iter 90000, loss: 0.165857
   Number of active neurons: 3
 >> iter 91000, loss: 0.093016
 >> iter 92000, loss: 0.178357
 >> iter 93000, loss: 0.079306
 >> iter 94000, loss: 0.082005
 >> iter 95000, loss: 0.080720
 >> iter 96000, loss: 0.198246
 >> iter 97000, loss: 0.106272
 >> iter 98000, loss: 0.502927
 >> iter 99000, loss: 0.207602
 >> iter 100000, loss: 0.255808
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

