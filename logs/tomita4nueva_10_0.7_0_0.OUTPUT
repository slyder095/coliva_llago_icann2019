 > Problema: tomita4nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.7
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.346034
 >> iter 2000, loss: 9.042955
 >> iter 3000, loss: 4.163217
 >> iter 4000, loss: 1.910521
 >> iter 5000, loss: 1.075619
 >> iter 6000, loss: 0.681684
 >> iter 7000, loss: 0.502927
 >> iter 8000, loss: 0.343109
 >> iter 9000, loss: 0.251098
 >> iter 10000, loss: 0.259167
   Number of active neurons: 10
 >> iter 11000, loss: 0.344515
 >> iter 12000, loss: 0.270943
 >> iter 13000, loss: 0.231064
 >> iter 14000, loss: 0.106520
 >> iter 15000, loss: 0.054025
 >> iter 16000, loss: 0.046364
 >> iter 17000, loss: 0.171586
 >> iter 18000, loss: 0.215770
 >> iter 19000, loss: 0.098166
 >> iter 20000, loss: 0.115400
   Number of active neurons: 10
 >> iter 21000, loss: 0.047635
 >> iter 22000, loss: 0.036040
 >> iter 23000, loss: 0.061134
 >> iter 24000, loss: 0.046045
 >> iter 25000, loss: 0.021003
 >> iter 26000, loss: 0.017157
 >> iter 27000, loss: 0.009317
 >> iter 28000, loss: 0.021551
 >> iter 29000, loss: 0.010418
 >> iter 30000, loss: 0.006266
   Number of active neurons: 10
 >> iter 31000, loss: 0.044210
 >> iter 32000, loss: 0.019072
 >> iter 33000, loss: 0.063509
 >> iter 34000, loss: 0.025487
 >> iter 35000, loss: 0.031735
 >> iter 36000, loss: 0.134506
 >> iter 37000, loss: 0.058199
 >> iter 38000, loss: 0.091968
 >> iter 39000, loss: 0.037425
 >> iter 40000, loss: 0.016632
   Number of active neurons: 10
 >> iter 41000, loss: 0.081911
 >> iter 42000, loss: 0.033282
 >> iter 43000, loss: 0.014612
 >> iter 44000, loss: 0.038895
 >> iter 45000, loss: 0.016911
 >> iter 46000, loss: 0.008279
 >> iter 47000, loss: 0.016603
 >> iter 48000, loss: 0.023765
 >> iter 49000, loss: 0.010865
 >> iter 50000, loss: 0.005719
   Number of active neurons: 10
 >> iter 51000, loss: 0.003628
 >> iter 52000, loss: 0.002701
 >> iter 53000, loss: 0.002265
 >> iter 54000, loss: 0.002377
 >> iter 55000, loss: 0.230564
 >> iter 56000, loss: 0.166698
 >> iter 57000, loss: 0.064949
 >> iter 58000, loss: 0.213945
 >> iter 59000, loss: 0.082508
 >> iter 60000, loss: 0.033256
   Number of active neurons: 10
 >> iter 61000, loss: 0.020816
 >> iter 62000, loss: 0.009875
 >> iter 63000, loss: 0.006558
 >> iter 64000, loss: 0.004035
 >> iter 65000, loss: 0.030688
 >> iter 66000, loss: 0.013004
 >> iter 67000, loss: 0.006324
 >> iter 68000, loss: 0.003698
 >> iter 69000, loss: 0.003856
 >> iter 70000, loss: 0.167327
   Number of active neurons: 10
 >> iter 71000, loss: 0.064979
 >> iter 72000, loss: 0.025685
 >> iter 73000, loss: 0.012573
 >> iter 74000, loss: 0.006157
 >> iter 75000, loss: 0.004616
 >> iter 76000, loss: 0.002912
 >> iter 77000, loss: 0.002250
 >> iter 78000, loss: 0.046944
 >> iter 79000, loss: 0.102223
 >> iter 80000, loss: 0.039324
   Number of active neurons: 10
 >> iter 81000, loss: 0.016704
 >> iter 82000, loss: 0.007376
 >> iter 83000, loss: 0.014393
 >> iter 84000, loss: 0.007039
 >> iter 85000, loss: 0.003887
 >> iter 86000, loss: 0.258594
 >> iter 87000, loss: 0.099103
 >> iter 88000, loss: 0.065540
 >> iter 89000, loss: 0.026330
 >> iter 90000, loss: 0.025241
   Number of active neurons: 10
 >> iter 91000, loss: 0.011384
 >> iter 92000, loss: 0.005500
 >> iter 93000, loss: 0.009557
 >> iter 94000, loss: 0.005300
 >> iter 95000, loss: 0.003151
 >> iter 96000, loss: 0.003033
 >> iter 97000, loss: 0.003868
 >> iter 98000, loss: 0.042249
 >> iter 99000, loss: 0.016786
 >> iter 100000, loss: 0.007231
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.715276
 >> iter 2000, loss: 9.194497
 >> iter 3000, loss: 4.595462
 >> iter 4000, loss: 2.260945
 >> iter 5000, loss: 1.137861
 >> iter 6000, loss: 0.645925
 >> iter 7000, loss: 0.265557
 >> iter 8000, loss: 0.287449
 >> iter 9000, loss: 0.129626
 >> iter 10000, loss: 0.159145
   Number of active neurons: 10
 >> iter 11000, loss: 0.144773
 >> iter 12000, loss: 0.202553
 >> iter 13000, loss: 0.170396
 >> iter 14000, loss: 0.115765
 >> iter 15000, loss: 0.065000
 >> iter 16000, loss: 0.115523
 >> iter 17000, loss: 0.062968
 >> iter 18000, loss: 0.063729
 >> iter 19000, loss: 0.168358
 >> iter 20000, loss: 0.069167
   Number of active neurons: 10
 >> iter 21000, loss: 0.093327
 >> iter 22000, loss: 0.057093
 >> iter 23000, loss: 0.095128
 >> iter 24000, loss: 0.038854
 >> iter 25000, loss: 0.017574
 >> iter 26000, loss: 0.019594
 >> iter 27000, loss: 0.009604
 >> iter 28000, loss: 0.005490
 >> iter 29000, loss: 0.005920
 >> iter 30000, loss: 0.017933
   Number of active neurons: 10
 >> iter 31000, loss: 0.008434
 >> iter 32000, loss: 0.059467
 >> iter 33000, loss: 0.071199
 >> iter 34000, loss: 0.053753
 >> iter 35000, loss: 0.021980
 >> iter 36000, loss: 0.009899
 >> iter 37000, loss: 0.117289
 >> iter 38000, loss: 0.045718
 >> iter 39000, loss: 0.029992
 >> iter 40000, loss: 0.013144
   Number of active neurons: 10
 >> iter 41000, loss: 0.006466
 >> iter 42000, loss: 0.003900
 >> iter 43000, loss: 0.031244
 >> iter 44000, loss: 0.013383
 >> iter 45000, loss: 0.006521
 >> iter 46000, loss: 0.003808
 >> iter 47000, loss: 0.004802
 >> iter 48000, loss: 0.036521
 >> iter 49000, loss: 0.014802
 >> iter 50000, loss: 0.006595
   Number of active neurons: 10
 >> iter 51000, loss: 0.129106
 >> iter 52000, loss: 0.050271
 >> iter 53000, loss: 0.020949
 >> iter 54000, loss: 0.008788
 >> iter 55000, loss: 0.004346
 >> iter 56000, loss: 0.002526
 >> iter 57000, loss: 0.001785
 >> iter 58000, loss: 0.001561
 >> iter 59000, loss: 0.001289
 >> iter 60000, loss: 0.003364
   Number of active neurons: 10
 >> iter 61000, loss: 0.002441
 >> iter 62000, loss: 0.026080
 >> iter 63000, loss: 0.010883
 >> iter 64000, loss: 0.086713
 >> iter 65000, loss: 0.032785
 >> iter 66000, loss: 0.012942
 >> iter 67000, loss: 0.005513
 >> iter 68000, loss: 0.002724
 >> iter 69000, loss: 0.048199
 >> iter 70000, loss: 0.027716
   Number of active neurons: 10
 >> iter 71000, loss: 0.042074
 >> iter 72000, loss: 0.016532
 >> iter 73000, loss: 0.039983
 >> iter 74000, loss: 0.016060
 >> iter 75000, loss: 0.007713
 >> iter 76000, loss: 0.003735
 >> iter 77000, loss: 0.044718
 >> iter 78000, loss: 0.017652
 >> iter 79000, loss: 0.007558
 >> iter 80000, loss: 0.003757
   Number of active neurons: 10
 >> iter 81000, loss: 0.005915
 >> iter 82000, loss: 0.003110
 >> iter 83000, loss: 0.001938
 >> iter 84000, loss: 0.001455
 >> iter 85000, loss: 0.002456
 >> iter 86000, loss: 0.001666
 >> iter 87000, loss: 0.001329
 >> iter 88000, loss: 0.033355
 >> iter 89000, loss: 0.110048
 >> iter 90000, loss: 0.041518
   Number of active neurons: 10
 >> iter 91000, loss: 0.016228
 >> iter 92000, loss: 0.016091
 >> iter 93000, loss: 0.008725
 >> iter 94000, loss: 0.010864
 >> iter 95000, loss: 0.004911
 >> iter 96000, loss: 0.002575
 >> iter 97000, loss: 0.001671
 >> iter 98000, loss: 0.001303
 >> iter 99000, loss: 0.001135
 >> iter 100000, loss: 0.001032
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.634837
 >> iter 2000, loss: 8.596941
 >> iter 3000, loss: 3.915467
 >> iter 4000, loss: 1.855352
 >> iter 5000, loss: 0.989129
 >> iter 6000, loss: 0.554442
 >> iter 7000, loss: 0.273429
 >> iter 8000, loss: 0.219161
 >> iter 9000, loss: 0.094508
 >> iter 10000, loss: 0.043699
   Number of active neurons: 10
 >> iter 11000, loss: 0.046333
 >> iter 12000, loss: 0.085832
 >> iter 13000, loss: 0.056633
 >> iter 14000, loss: 0.025905
 >> iter 15000, loss: 0.017373
 >> iter 16000, loss: 0.155346
 >> iter 17000, loss: 0.191806
 >> iter 18000, loss: 0.099957
 >> iter 19000, loss: 0.040292
 >> iter 20000, loss: 0.023158
   Number of active neurons: 10
 >> iter 21000, loss: 0.017200
 >> iter 22000, loss: 0.008929
 >> iter 23000, loss: 0.083084
 >> iter 24000, loss: 0.067696
 >> iter 25000, loss: 0.027760
 >> iter 26000, loss: 0.039516
 >> iter 27000, loss: 0.018973
 >> iter 28000, loss: 0.067124
 >> iter 29000, loss: 0.091470
 >> iter 30000, loss: 0.041611
   Number of active neurons: 10
 >> iter 31000, loss: 0.017888
 >> iter 32000, loss: 0.008957
 >> iter 33000, loss: 0.005458
 >> iter 34000, loss: 0.004057
 >> iter 35000, loss: 0.002987
 >> iter 36000, loss: 0.002829
 >> iter 37000, loss: 0.028306
 >> iter 38000, loss: 0.011941
 >> iter 39000, loss: 0.005759
 >> iter 40000, loss: 0.005571
   Number of active neurons: 10
 >> iter 41000, loss: 0.003244
 >> iter 42000, loss: 0.002355
 >> iter 43000, loss: 0.002017
 >> iter 44000, loss: 0.002132
 >> iter 45000, loss: 0.001816
 >> iter 46000, loss: 0.002777
 >> iter 47000, loss: 0.002006
 >> iter 48000, loss: 0.012865
 >> iter 49000, loss: 0.005536
 >> iter 50000, loss: 0.002816
   Number of active neurons: 10
 >> iter 51000, loss: 0.001822
 >> iter 52000, loss: 0.001382
 >> iter 53000, loss: 0.001186
 >> iter 54000, loss: 0.001141
 >> iter 55000, loss: 0.003869
 >> iter 56000, loss: 0.076248
 >> iter 57000, loss: 0.028773
 >> iter 58000, loss: 0.088816
 >> iter 59000, loss: 0.033952
 >> iter 60000, loss: 0.124003
   Number of active neurons: 10
 >> iter 61000, loss: 0.047450
 >> iter 62000, loss: 0.018830
 >> iter 63000, loss: 0.008388
 >> iter 64000, loss: 0.028214
 >> iter 65000, loss: 0.011715
 >> iter 66000, loss: 0.005362
 >> iter 67000, loss: 0.002909
 >> iter 68000, loss: 0.002104
 >> iter 69000, loss: 0.001637
 >> iter 70000, loss: 0.003223
   Number of active neurons: 10
 >> iter 71000, loss: 0.006678
 >> iter 72000, loss: 0.003307
 >> iter 73000, loss: 0.001944
 >> iter 74000, loss: 0.048923
 >> iter 75000, loss: 0.018950
 >> iter 76000, loss: 0.007876
 >> iter 77000, loss: 0.003658
 >> iter 78000, loss: 0.002079
 >> iter 79000, loss: 0.050243
 >> iter 80000, loss: 0.021003
   Number of active neurons: 10
 >> iter 81000, loss: 0.008622
 >> iter 82000, loss: 0.003997
 >> iter 83000, loss: 0.002194
 >> iter 84000, loss: 0.001769
 >> iter 85000, loss: 0.001313
 >> iter 86000, loss: 0.001206
 >> iter 87000, loss: 0.001081
 >> iter 88000, loss: 0.001097
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.163862
 >> iter 2000, loss: 8.780573
 >> iter 3000, loss: 4.128614
 >> iter 4000, loss: 1.927658
 >> iter 5000, loss: 0.984238
 >> iter 6000, loss: 0.560636
 >> iter 7000, loss: 0.331220
 >> iter 8000, loss: 0.227197
 >> iter 9000, loss: 0.257206
 >> iter 10000, loss: 0.138775
   Number of active neurons: 10
 >> iter 11000, loss: 0.131583
 >> iter 12000, loss: 0.079361
 >> iter 13000, loss: 0.101614
 >> iter 14000, loss: 0.044332
 >> iter 15000, loss: 0.022621
 >> iter 16000, loss: 0.188914
 >> iter 17000, loss: 0.075631
 >> iter 18000, loss: 0.037620
 >> iter 19000, loss: 0.089250
 >> iter 20000, loss: 0.137303
   Number of active neurons: 10
 >> iter 21000, loss: 0.339717
 >> iter 22000, loss: 0.193154
 >> iter 23000, loss: 0.079067
 >> iter 24000, loss: 0.143632
 >> iter 25000, loss: 0.078300
 >> iter 26000, loss: 0.033496
 >> iter 27000, loss: 0.029585
 >> iter 28000, loss: 0.013510
 >> iter 29000, loss: 0.007260
 >> iter 30000, loss: 0.050438
   Number of active neurons: 10
 >> iter 31000, loss: 0.045485
 >> iter 32000, loss: 0.043545
 >> iter 33000, loss: 0.018827
 >> iter 34000, loss: 0.019980
 >> iter 35000, loss: 0.048248
 >> iter 36000, loss: 0.042695
 >> iter 37000, loss: 0.018559
 >> iter 38000, loss: 0.016850
 >> iter 39000, loss: 0.095356
 >> iter 40000, loss: 0.053932
   Number of active neurons: 10
 >> iter 41000, loss: 0.116378
 >> iter 42000, loss: 0.046251
 >> iter 43000, loss: 0.067244
 >> iter 44000, loss: 0.027802
 >> iter 45000, loss: 0.012566
 >> iter 46000, loss: 0.031155
 >> iter 47000, loss: 0.060840
 >> iter 48000, loss: 0.025002
 >> iter 49000, loss: 0.117401
 >> iter 50000, loss: 0.046577
   Number of active neurons: 10
 >> iter 51000, loss: 0.020096
 >> iter 52000, loss: 0.054741
 >> iter 53000, loss: 0.022530
 >> iter 54000, loss: 0.066801
 >> iter 55000, loss: 0.027711
 >> iter 56000, loss: 0.044026
 >> iter 57000, loss: 0.018371
 >> iter 58000, loss: 0.008873
 >> iter 59000, loss: 0.005000
 >> iter 60000, loss: 0.003477
   Number of active neurons: 10
 >> iter 61000, loss: 0.128764
 >> iter 62000, loss: 0.127218
 >> iter 63000, loss: 0.086552
 >> iter 64000, loss: 0.075069
 >> iter 65000, loss: 0.073394
 >> iter 66000, loss: 0.048073
 >> iter 67000, loss: 0.020943
 >> iter 68000, loss: 0.017550
 >> iter 69000, loss: 0.018194
 >> iter 70000, loss: 0.008585
   Number of active neurons: 10
 >> iter 71000, loss: 0.004924
 >> iter 72000, loss: 0.003297
 >> iter 73000, loss: 0.002501
 >> iter 74000, loss: 0.002263
 >> iter 75000, loss: 0.002009
 >> iter 76000, loss: 0.034193
 >> iter 77000, loss: 0.122948
 >> iter 78000, loss: 0.047203
 >> iter 79000, loss: 0.018971
 >> iter 80000, loss: 0.008393
   Number of active neurons: 10
 >> iter 81000, loss: 0.004389
 >> iter 82000, loss: 0.002836
 >> iter 83000, loss: 0.002665
 >> iter 84000, loss: 0.002195
 >> iter 85000, loss: 0.001916
 >> iter 86000, loss: 0.042507
 >> iter 87000, loss: 0.016720
 >> iter 88000, loss: 0.052169
 >> iter 89000, loss: 0.020569
 >> iter 90000, loss: 0.008791
   Number of active neurons: 10
 >> iter 91000, loss: 0.004712
 >> iter 92000, loss: 0.002709
 >> iter 93000, loss: 0.082287
 >> iter 94000, loss: 0.171898
 >> iter 95000, loss: 0.066112
 >> iter 96000, loss: 0.036811
 >> iter 97000, loss: 0.027437
 >> iter 98000, loss: 0.011819
 >> iter 99000, loss: 0.005686
 >> iter 100000, loss: 0.003287
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.820648
 >> iter 2000, loss: 9.228533
 >> iter 3000, loss: 3.838015
 >> iter 4000, loss: 1.525624
 >> iter 5000, loss: 0.682598
 >> iter 6000, loss: 0.328435
 >> iter 7000, loss: 0.153579
 >> iter 8000, loss: 0.170877
 >> iter 9000, loss: 0.076128
 >> iter 10000, loss: 0.035547
   Number of active neurons: 10
 >> iter 11000, loss: 0.022241
 >> iter 12000, loss: 0.013239
 >> iter 13000, loss: 0.025575
 >> iter 14000, loss: 0.014654
 >> iter 15000, loss: 0.023181
 >> iter 16000, loss: 0.017233
 >> iter 17000, loss: 0.010218
 >> iter 18000, loss: 0.023379
 >> iter 19000, loss: 0.142272
 >> iter 20000, loss: 0.127081
   Number of active neurons: 10
 >> iter 21000, loss: 0.067158
 >> iter 22000, loss: 0.029711
 >> iter 23000, loss: 0.014521
 >> iter 24000, loss: 0.007480
 >> iter 25000, loss: 0.004784
 >> iter 26000, loss: 0.003521
 >> iter 27000, loss: 0.014927
 >> iter 28000, loss: 0.007398
 >> iter 29000, loss: 0.004227
 >> iter 30000, loss: 0.004399
   Number of active neurons: 10
 >> iter 31000, loss: 0.002965
 >> iter 32000, loss: 0.006646
 >> iter 33000, loss: 0.003984
 >> iter 34000, loss: 0.021271
 >> iter 35000, loss: 0.059003
 >> iter 36000, loss: 0.085630
 >> iter 37000, loss: 0.033602
 >> iter 38000, loss: 0.019199
 >> iter 39000, loss: 0.074681
 >> iter 40000, loss: 0.031213
   Number of active neurons: 10
 >> iter 41000, loss: 0.013369
 >> iter 42000, loss: 0.009981
 >> iter 43000, loss: 0.010523
 >> iter 44000, loss: 0.005388
 >> iter 45000, loss: 0.003262
 >> iter 46000, loss: 0.002384
 >> iter 47000, loss: 0.001893
 >> iter 48000, loss: 0.001815
 >> iter 49000, loss: 0.002894
 >> iter 50000, loss: 0.002221
   Number of active neurons: 10
 >> iter 51000, loss: 0.001725
 >> iter 52000, loss: 0.001448
 >> iter 53000, loss: 0.001467
 >> iter 54000, loss: 0.001776
 >> iter 55000, loss: 0.001599
 >> iter 56000, loss: 0.001337
 >> iter 57000, loss: 0.001476
 >> iter 58000, loss: 0.001762
 >> iter 59000, loss: 0.002475
 >> iter 60000, loss: 0.001636
   Number of active neurons: 10
 >> iter 61000, loss: 0.008683
 >> iter 62000, loss: 0.004243
 >> iter 63000, loss: 0.024214
 >> iter 64000, loss: 0.010159
 >> iter 65000, loss: 0.004817
 >> iter 66000, loss: 0.002264
 >> iter 67000, loss: 0.001994
 >> iter 68000, loss: 0.079638
 >> iter 69000, loss: 0.030252
 >> iter 70000, loss: 0.011783
   Number of active neurons: 10
 >> iter 71000, loss: 0.005033
 >> iter 72000, loss: 0.002423
 >> iter 73000, loss: 0.001515
 >> iter 74000, loss: 0.001056
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.689965
 >> iter 2000, loss: 9.179552
 >> iter 3000, loss: 4.046231
 >> iter 4000, loss: 1.730232
 >> iter 5000, loss: 0.671426
 >> iter 6000, loss: 0.322974
 >> iter 7000, loss: 0.258304
 >> iter 8000, loss: 0.208739
 >> iter 9000, loss: 0.175799
 >> iter 10000, loss: 0.137601
   Number of active neurons: 10
 >> iter 11000, loss: 0.062145
 >> iter 12000, loss: 0.030625
 >> iter 13000, loss: 0.137066
 >> iter 14000, loss: 0.057849
 >> iter 15000, loss: 0.025570
 >> iter 16000, loss: 0.164733
 >> iter 17000, loss: 0.137015
 >> iter 18000, loss: 0.055947
 >> iter 19000, loss: 0.032319
 >> iter 20000, loss: 0.015130
   Number of active neurons: 10
 >> iter 21000, loss: 0.008964
 >> iter 22000, loss: 0.020725
 >> iter 23000, loss: 0.039031
 >> iter 24000, loss: 0.081014
 >> iter 25000, loss: 0.032745
 >> iter 26000, loss: 0.071743
 >> iter 27000, loss: 0.029782
 >> iter 28000, loss: 0.155171
 >> iter 29000, loss: 0.060039
 >> iter 30000, loss: 0.024589
   Number of active neurons: 10
 >> iter 31000, loss: 0.015102
 >> iter 32000, loss: 0.007691
 >> iter 33000, loss: 0.006306
 >> iter 34000, loss: 0.198749
 >> iter 35000, loss: 0.076328
 >> iter 36000, loss: 0.035905
 >> iter 37000, loss: 0.016493
 >> iter 38000, loss: 0.008176
 >> iter 39000, loss: 0.004720
 >> iter 40000, loss: 0.004311
   Number of active neurons: 10
 >> iter 41000, loss: 0.003311
 >> iter 42000, loss: 0.002507
 >> iter 43000, loss: 0.142352
 >> iter 44000, loss: 0.054174
 >> iter 45000, loss: 0.022426
 >> iter 46000, loss: 0.009982
 >> iter 47000, loss: 0.005237
 >> iter 48000, loss: 0.003527
 >> iter 49000, loss: 0.002678
 >> iter 50000, loss: 0.002240
   Number of active neurons: 10
 >> iter 51000, loss: 0.002026
 >> iter 52000, loss: 0.001844
 >> iter 53000, loss: 0.001701
 >> iter 54000, loss: 0.001598
 >> iter 55000, loss: 0.001562
 >> iter 56000, loss: 0.001418
 >> iter 57000, loss: 0.001594
 >> iter 58000, loss: 0.001984
 >> iter 59000, loss: 0.001517
 >> iter 60000, loss: 0.007631
   Number of active neurons: 10
 >> iter 61000, loss: 0.003661
 >> iter 62000, loss: 0.002103
 >> iter 63000, loss: 0.147081
 >> iter 64000, loss: 0.064859
 >> iter 65000, loss: 0.025275
 >> iter 66000, loss: 0.011224
 >> iter 67000, loss: 0.005255
 >> iter 68000, loss: 0.002979
 >> iter 69000, loss: 0.003259
 >> iter 70000, loss: 0.002295
   Number of active neurons: 10
 >> iter 71000, loss: 0.001815
 >> iter 72000, loss: 0.001639
 >> iter 73000, loss: 0.001525
 >> iter 74000, loss: 0.001283
 >> iter 75000, loss: 0.001252
 >> iter 76000, loss: 0.001361
 >> iter 77000, loss: 0.001275
 >> iter 78000, loss: 0.001107
 >> iter 79000, loss: 0.001467
 >> iter 80000, loss: 0.001482
   Number of active neurons: 10
 >> iter 81000, loss: 0.002503
 >> iter 82000, loss: 0.001556
 >> iter 83000, loss: 0.001209
 >> iter 84000, loss: 0.001118
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.453658
 >> iter 2000, loss: 8.873416
 >> iter 3000, loss: 4.068887
 >> iter 4000, loss: 2.027790
 >> iter 5000, loss: 1.003603
 >> iter 6000, loss: 0.475626
 >> iter 7000, loss: 0.266328
 >> iter 8000, loss: 0.277439
 >> iter 9000, loss: 0.326592
 >> iter 10000, loss: 0.164445
   Number of active neurons: 10
 >> iter 11000, loss: 0.078164
 >> iter 12000, loss: 0.066494
 >> iter 13000, loss: 0.042343
 >> iter 14000, loss: 0.102355
 >> iter 15000, loss: 0.075982
 >> iter 16000, loss: 0.032068
 >> iter 17000, loss: 0.016733
 >> iter 18000, loss: 0.026235
 >> iter 19000, loss: 0.054178
 >> iter 20000, loss: 0.067014
   Number of active neurons: 10
 >> iter 21000, loss: 0.033834
 >> iter 22000, loss: 0.015682
 >> iter 23000, loss: 0.098194
 >> iter 24000, loss: 0.069454
 >> iter 25000, loss: 0.076654
 >> iter 26000, loss: 0.031623
 >> iter 27000, loss: 0.136729
 >> iter 28000, loss: 0.060932
 >> iter 29000, loss: 0.052065
 >> iter 30000, loss: 0.030893
   Number of active neurons: 10
 >> iter 31000, loss: 0.032100
 >> iter 32000, loss: 0.025629
 >> iter 33000, loss: 0.037861
 >> iter 34000, loss: 0.016189
 >> iter 35000, loss: 0.052739
 >> iter 36000, loss: 0.048377
 >> iter 37000, loss: 0.055944
 >> iter 38000, loss: 0.023725
 >> iter 39000, loss: 0.010913
 >> iter 40000, loss: 0.006576
   Number of active neurons: 10
 >> iter 41000, loss: 0.039490
 >> iter 42000, loss: 0.063406
 >> iter 43000, loss: 0.025623
 >> iter 44000, loss: 0.012586
 >> iter 45000, loss: 0.006245
 >> iter 46000, loss: 0.004451
 >> iter 47000, loss: 0.028899
 >> iter 48000, loss: 0.012045
 >> iter 49000, loss: 0.006433
 >> iter 50000, loss: 0.003744
   Number of active neurons: 10
 >> iter 51000, loss: 0.003091
 >> iter 52000, loss: 0.003091
 >> iter 53000, loss: 0.004154
 >> iter 54000, loss: 0.002621
 >> iter 55000, loss: 0.001912
 >> iter 56000, loss: 0.001573
 >> iter 57000, loss: 0.083067
 >> iter 58000, loss: 0.031907
 >> iter 59000, loss: 0.012967
 >> iter 60000, loss: 0.005803
   Number of active neurons: 10
 >> iter 61000, loss: 0.004681
 >> iter 62000, loss: 0.011378
 >> iter 63000, loss: 0.005106
 >> iter 64000, loss: 0.072368
 >> iter 65000, loss: 0.054974
 >> iter 66000, loss: 0.022393
 >> iter 67000, loss: 0.021411
 >> iter 68000, loss: 0.010906
 >> iter 69000, loss: 0.005674
 >> iter 70000, loss: 0.003200
   Number of active neurons: 10
 >> iter 71000, loss: 0.046480
 >> iter 72000, loss: 0.018717
 >> iter 73000, loss: 0.008532
 >> iter 74000, loss: 0.069534
 >> iter 75000, loss: 0.029337
 >> iter 76000, loss: 0.011958
 >> iter 77000, loss: 0.005432
 >> iter 78000, loss: 0.011614
 >> iter 79000, loss: 0.005238
 >> iter 80000, loss: 0.002761
   Number of active neurons: 10
 >> iter 81000, loss: 0.001876
 >> iter 82000, loss: 0.001384
 >> iter 83000, loss: 0.001196
 >> iter 84000, loss: 0.001065
 >> iter 85000, loss: 0.001030
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.451828
 >> iter 2000, loss: 9.510729
 >> iter 3000, loss: 4.830118
 >> iter 4000, loss: 2.256042
 >> iter 5000, loss: 1.236260
 >> iter 6000, loss: 0.934204
 >> iter 7000, loss: 0.389803
 >> iter 8000, loss: 0.420795
 >> iter 9000, loss: 0.313358
 >> iter 10000, loss: 0.195782
   Number of active neurons: 10
 >> iter 11000, loss: 0.155302
 >> iter 12000, loss: 0.166565
 >> iter 13000, loss: 0.178800
 >> iter 14000, loss: 0.186421
 >> iter 15000, loss: 0.144081
 >> iter 16000, loss: 0.059755
 >> iter 17000, loss: 0.173017
 >> iter 18000, loss: 0.078167
 >> iter 19000, loss: 0.047494
 >> iter 20000, loss: 0.170515
   Number of active neurons: 10
 >> iter 21000, loss: 0.067261
 >> iter 22000, loss: 0.030005
 >> iter 23000, loss: 0.043037
 >> iter 24000, loss: 0.018554
 >> iter 25000, loss: 0.010718
 >> iter 26000, loss: 0.057405
 >> iter 27000, loss: 0.036605
 >> iter 28000, loss: 0.105728
 >> iter 29000, loss: 0.042375
 >> iter 30000, loss: 0.018491
   Number of active neurons: 10
 >> iter 31000, loss: 0.009310
 >> iter 32000, loss: 0.023162
 >> iter 33000, loss: 0.012148
 >> iter 34000, loss: 0.011431
 >> iter 35000, loss: 0.006270
 >> iter 36000, loss: 0.003983
 >> iter 37000, loss: 0.004140
 >> iter 38000, loss: 0.005212
 >> iter 39000, loss: 0.003688
 >> iter 40000, loss: 0.004795
   Number of active neurons: 10
 >> iter 41000, loss: 0.003047
 >> iter 42000, loss: 0.008498
 >> iter 43000, loss: 0.028760
 >> iter 44000, loss: 0.012479
 >> iter 45000, loss: 0.005633
 >> iter 46000, loss: 0.003797
 >> iter 47000, loss: 0.002646
 >> iter 48000, loss: 0.006569
 >> iter 49000, loss: 0.011823
 >> iter 50000, loss: 0.005334
   Number of active neurons: 10
 >> iter 51000, loss: 0.002749
 >> iter 52000, loss: 0.003175
 >> iter 53000, loss: 0.002802
 >> iter 54000, loss: 0.003149
 >> iter 55000, loss: 0.020602
 >> iter 56000, loss: 0.012392
 >> iter 57000, loss: 0.020364
 >> iter 58000, loss: 0.008417
 >> iter 59000, loss: 0.005137
 >> iter 60000, loss: 0.007513
   Number of active neurons: 10
 >> iter 61000, loss: 0.004642
 >> iter 62000, loss: 0.002561
 >> iter 63000, loss: 0.001706
 >> iter 64000, loss: 0.018448
 >> iter 65000, loss: 0.007490
 >> iter 66000, loss: 0.003377
 >> iter 67000, loss: 0.004652
 >> iter 68000, loss: 0.002284
 >> iter 69000, loss: 0.001457
 >> iter 70000, loss: 0.001287
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.579927
 >> iter 2000, loss: 8.109816
 >> iter 3000, loss: 3.675928
 >> iter 4000, loss: 1.563207
 >> iter 5000, loss: 0.686114
 >> iter 6000, loss: 0.282497
 >> iter 7000, loss: 0.116703
 >> iter 8000, loss: 0.050296
 >> iter 9000, loss: 0.032377
 >> iter 10000, loss: 0.120565
   Number of active neurons: 10
 >> iter 11000, loss: 0.102221
 >> iter 12000, loss: 0.043575
 >> iter 13000, loss: 0.035674
 >> iter 14000, loss: 0.079638
 >> iter 15000, loss: 0.187041
 >> iter 16000, loss: 0.075745
 >> iter 17000, loss: 0.040960
 >> iter 18000, loss: 0.020690
 >> iter 19000, loss: 0.012254
 >> iter 20000, loss: 0.119329
   Number of active neurons: 10
 >> iter 21000, loss: 0.048938
 >> iter 22000, loss: 0.024498
 >> iter 23000, loss: 0.048496
 >> iter 24000, loss: 0.023689
 >> iter 25000, loss: 0.012850
 >> iter 26000, loss: 0.065530
 >> iter 27000, loss: 0.027159
 >> iter 28000, loss: 0.020489
 >> iter 29000, loss: 0.010651
 >> iter 30000, loss: 0.007260
   Number of active neurons: 10
 >> iter 31000, loss: 0.004832
 >> iter 32000, loss: 0.003567
 >> iter 33000, loss: 0.003092
 >> iter 34000, loss: 0.002680
 >> iter 35000, loss: 0.003047
 >> iter 36000, loss: 0.100506
 >> iter 37000, loss: 0.039090
 >> iter 38000, loss: 0.023019
 >> iter 39000, loss: 0.010610
 >> iter 40000, loss: 0.005377
   Number of active neurons: 10
 >> iter 41000, loss: 0.004907
 >> iter 42000, loss: 0.007103
 >> iter 43000, loss: 0.003857
 >> iter 44000, loss: 0.004147
 >> iter 45000, loss: 0.002613
 >> iter 46000, loss: 0.002781
 >> iter 47000, loss: 0.026821
 >> iter 48000, loss: 0.015811
 >> iter 49000, loss: 0.006997
 >> iter 50000, loss: 0.004977
   Number of active neurons: 10
 >> iter 51000, loss: 0.030903
 >> iter 52000, loss: 0.012276
 >> iter 53000, loss: 0.005650
 >> iter 54000, loss: 0.030905
 >> iter 55000, loss: 0.012515
 >> iter 56000, loss: 0.083716
 >> iter 57000, loss: 0.035652
 >> iter 58000, loss: 0.204343
 >> iter 59000, loss: 0.147139
 >> iter 60000, loss: 0.102687
   Number of active neurons: 10
 >> iter 61000, loss: 0.040474
 >> iter 62000, loss: 0.032018
 >> iter 63000, loss: 0.013943
 >> iter 64000, loss: 0.007009
 >> iter 65000, loss: 0.004193
 >> iter 66000, loss: 0.005793
 >> iter 67000, loss: 0.003466
 >> iter 68000, loss: 0.002489
 >> iter 69000, loss: 0.002146
 >> iter 70000, loss: 0.002356
   Number of active neurons: 10
 >> iter 71000, loss: 0.001831
 >> iter 72000, loss: 0.001619
 >> iter 73000, loss: 0.001479
 >> iter 74000, loss: 0.001323
 >> iter 75000, loss: 0.001342
 >> iter 76000, loss: 0.001421
 >> iter 77000, loss: 0.001275
 >> iter 78000, loss: 0.001158
 >> iter 79000, loss: 0.001160
 >> iter 80000, loss: 0.001057
   Number of active neurons: 10
 >> iter 81000, loss: 0.001053
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.338548
 >> iter 2000, loss: 8.546086
 >> iter 3000, loss: 3.970308
 >> iter 4000, loss: 1.702822
 >> iter 5000, loss: 0.848492
 >> iter 6000, loss: 0.488206
 >> iter 7000, loss: 0.365732
 >> iter 8000, loss: 0.297499
 >> iter 9000, loss: 0.264333
 >> iter 10000, loss: 0.263104
   Number of active neurons: 10
 >> iter 11000, loss: 0.157987
 >> iter 12000, loss: 0.090903
 >> iter 13000, loss: 0.086893
 >> iter 14000, loss: 0.144670
 >> iter 15000, loss: 0.134729
 >> iter 16000, loss: 0.059084
 >> iter 17000, loss: 0.069130
 >> iter 18000, loss: 0.029148
 >> iter 19000, loss: 0.104667
 >> iter 20000, loss: 0.119671
   Number of active neurons: 10
 >> iter 21000, loss: 0.048853
 >> iter 22000, loss: 0.020981
 >> iter 23000, loss: 0.094410
 >> iter 24000, loss: 0.097880
 >> iter 25000, loss: 0.042546
 >> iter 26000, loss: 0.020480
 >> iter 27000, loss: 0.125476
 >> iter 28000, loss: 0.049834
 >> iter 29000, loss: 0.020878
 >> iter 30000, loss: 0.010008
   Number of active neurons: 10
 >> iter 31000, loss: 0.112611
 >> iter 32000, loss: 0.044420
 >> iter 33000, loss: 0.050807
 >> iter 34000, loss: 0.021041
 >> iter 35000, loss: 0.010176
 >> iter 36000, loss: 0.020259
 >> iter 37000, loss: 0.022160
 >> iter 38000, loss: 0.054509
 >> iter 39000, loss: 0.082021
 >> iter 40000, loss: 0.032849
   Number of active neurons: 10
 >> iter 41000, loss: 0.173602
 >> iter 42000, loss: 0.066617
 >> iter 43000, loss: 0.026561
 >> iter 44000, loss: 0.025476
 >> iter 45000, loss: 0.058982
 >> iter 46000, loss: 0.023956
 >> iter 47000, loss: 0.010734
 >> iter 48000, loss: 0.042528
 >> iter 49000, loss: 0.034818
 >> iter 50000, loss: 0.072124
   Number of active neurons: 10
 >> iter 51000, loss: 0.028464
 >> iter 52000, loss: 0.012048
 >> iter 53000, loss: 0.028812
 >> iter 54000, loss: 0.257993
 >> iter 55000, loss: 0.147121
 >> iter 56000, loss: 0.057518
 >> iter 57000, loss: 0.023538
 >> iter 58000, loss: 0.010474
 >> iter 59000, loss: 0.012879
 >> iter 60000, loss: 0.006734
   Number of active neurons: 10
 >> iter 61000, loss: 0.003964
 >> iter 62000, loss: 0.007125
 >> iter 63000, loss: 0.021510
 >> iter 64000, loss: 0.009302
 >> iter 65000, loss: 0.004668
 >> iter 66000, loss: 0.004362
 >> iter 67000, loss: 0.004651
 >> iter 68000, loss: 0.002831
 >> iter 69000, loss: 0.002341
 >> iter 70000, loss: 0.002101
   Number of active neurons: 10
 >> iter 71000, loss: 0.001660
 >> iter 72000, loss: 0.001320
 >> iter 73000, loss: 0.001164
 >> iter 74000, loss: 0.001083
 >> iter 75000, loss: 0.014755
 >> iter 76000, loss: 0.006646
 >> iter 77000, loss: 0.003132
 >> iter 78000, loss: 0.001809
 >> iter 79000, loss: 0.001252
 >> iter 80000, loss: 0.001127
   Number of active neurons: 10
 >> iter 81000, loss: 0.001024
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.760350
 >> iter 2000, loss: 9.076486
 >> iter 3000, loss: 4.139745
 >> iter 4000, loss: 1.891040
 >> iter 5000, loss: 0.877617
 >> iter 6000, loss: 0.503435
 >> iter 7000, loss: 0.228308
 >> iter 8000, loss: 0.103062
 >> iter 9000, loss: 0.387500
 >> iter 10000, loss: 0.153954
   Number of active neurons: 10
 >> iter 11000, loss: 0.075961
 >> iter 12000, loss: 0.034116
 >> iter 13000, loss: 0.054856
 >> iter 14000, loss: 0.130348
 >> iter 15000, loss: 0.053566
 >> iter 16000, loss: 0.023927
 >> iter 17000, loss: 0.013478
 >> iter 18000, loss: 0.008244
 >> iter 19000, loss: 0.009331
 >> iter 20000, loss: 0.006181
   Number of active neurons: 10
 >> iter 21000, loss: 0.113861
 >> iter 22000, loss: 0.050379
 >> iter 23000, loss: 0.020828
 >> iter 24000, loss: 0.019384
 >> iter 25000, loss: 0.010152
 >> iter 26000, loss: 0.047115
 >> iter 27000, loss: 0.025098
 >> iter 28000, loss: 0.020348
 >> iter 29000, loss: 0.009804
 >> iter 30000, loss: 0.025504
   Number of active neurons: 10
 >> iter 31000, loss: 0.027462
 >> iter 32000, loss: 0.025532
 >> iter 33000, loss: 0.012028
 >> iter 34000, loss: 0.017147
 >> iter 35000, loss: 0.008202
 >> iter 36000, loss: 0.042075
 >> iter 37000, loss: 0.017335
 >> iter 38000, loss: 0.010089
 >> iter 39000, loss: 0.005296
 >> iter 40000, loss: 0.003380
   Number of active neurons: 10
 >> iter 41000, loss: 0.006520
 >> iter 42000, loss: 0.141253
 >> iter 43000, loss: 0.054292
 >> iter 44000, loss: 0.169899
 >> iter 45000, loss: 0.065108
 >> iter 46000, loss: 0.026157
 >> iter 47000, loss: 0.040131
 >> iter 48000, loss: 0.016756
 >> iter 49000, loss: 0.007916
 >> iter 50000, loss: 0.005579
   Number of active neurons: 10
 >> iter 51000, loss: 0.003540
 >> iter 52000, loss: 0.002684
 >> iter 53000, loss: 0.002347
 >> iter 54000, loss: 0.002094
 >> iter 55000, loss: 0.001774
 >> iter 56000, loss: 0.001708
 >> iter 57000, loss: 0.001565
 >> iter 58000, loss: 0.001482
 >> iter 59000, loss: 0.001539
 >> iter 60000, loss: 0.001468
   Number of active neurons: 10
 >> iter 61000, loss: 0.001375
 >> iter 62000, loss: 0.001868
 >> iter 63000, loss: 0.001455
 >> iter 64000, loss: 0.001344
 >> iter 65000, loss: 0.001206
 >> iter 66000, loss: 0.001102
 >> iter 67000, loss: 0.001029
 >> iter 68000, loss: 0.001025
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.088715
 >> iter 2000, loss: 8.233300
 >> iter 3000, loss: 3.849016
 >> iter 4000, loss: 1.653569
 >> iter 5000, loss: 0.889780
 >> iter 6000, loss: 0.465662
 >> iter 7000, loss: 0.272069
 >> iter 8000, loss: 0.253337
 >> iter 9000, loss: 0.244106
 >> iter 10000, loss: 0.136926
   Number of active neurons: 10
 >> iter 11000, loss: 0.122469
 >> iter 12000, loss: 0.055080
 >> iter 13000, loss: 0.085460
 >> iter 14000, loss: 0.159647
 >> iter 15000, loss: 0.067086
 >> iter 16000, loss: 0.031324
 >> iter 17000, loss: 0.096894
 >> iter 18000, loss: 0.117543
 >> iter 19000, loss: 0.078436
 >> iter 20000, loss: 0.034102
   Number of active neurons: 10
 >> iter 21000, loss: 0.102104
 >> iter 22000, loss: 0.084990
 >> iter 23000, loss: 0.035936
 >> iter 24000, loss: 0.067993
 >> iter 25000, loss: 0.139087
 >> iter 26000, loss: 0.055366
 >> iter 27000, loss: 0.023617
 >> iter 28000, loss: 0.120055
 >> iter 29000, loss: 0.139369
 >> iter 30000, loss: 0.055173
   Number of active neurons: 10
 >> iter 31000, loss: 0.132442
 >> iter 32000, loss: 0.118015
 >> iter 33000, loss: 0.136339
 >> iter 34000, loss: 0.054624
 >> iter 35000, loss: 0.023390
 >> iter 36000, loss: 0.040438
 >> iter 37000, loss: 0.070077
 >> iter 38000, loss: 0.050363
 >> iter 39000, loss: 0.146227
 >> iter 40000, loss: 0.058792
   Number of active neurons: 10
 >> iter 41000, loss: 0.025582
 >> iter 42000, loss: 0.012050
 >> iter 43000, loss: 0.053427
 >> iter 44000, loss: 0.022344
 >> iter 45000, loss: 0.010561
 >> iter 46000, loss: 0.006269
 >> iter 47000, loss: 0.009912
 >> iter 48000, loss: 0.005311
 >> iter 49000, loss: 0.003514
 >> iter 50000, loss: 0.004588
   Number of active neurons: 10
 >> iter 51000, loss: 0.016752
 >> iter 52000, loss: 0.007682
 >> iter 53000, loss: 0.004145
 >> iter 54000, loss: 0.019221
 >> iter 55000, loss: 0.026577
 >> iter 56000, loss: 0.026547
 >> iter 57000, loss: 0.011710
 >> iter 58000, loss: 0.005790
 >> iter 59000, loss: 0.005836
 >> iter 60000, loss: 0.003292
   Number of active neurons: 10
 >> iter 61000, loss: 0.002211
 >> iter 62000, loss: 0.031091
 >> iter 63000, loss: 0.012672
 >> iter 64000, loss: 0.006012
 >> iter 65000, loss: 0.003235
 >> iter 66000, loss: 0.016465
 >> iter 67000, loss: 0.007966
 >> iter 68000, loss: 0.003991
 >> iter 69000, loss: 0.003297
 >> iter 70000, loss: 0.078620
   Number of active neurons: 10
 >> iter 71000, loss: 0.083198
 >> iter 72000, loss: 0.077293
 >> iter 73000, loss: 0.030896
 >> iter 74000, loss: 0.028538
 >> iter 75000, loss: 0.011988
 >> iter 76000, loss: 0.005604
 >> iter 77000, loss: 0.003184
 >> iter 78000, loss: 0.002145
 >> iter 79000, loss: 0.017232
 >> iter 80000, loss: 0.091872
   Number of active neurons: 10
 >> iter 81000, loss: 0.035404
 >> iter 82000, loss: 0.014293
 >> iter 83000, loss: 0.006452
 >> iter 84000, loss: 0.003766
 >> iter 85000, loss: 0.006014
 >> iter 86000, loss: 0.003201
 >> iter 87000, loss: 0.002197
 >> iter 88000, loss: 0.001770
 >> iter 89000, loss: 0.001412
 >> iter 90000, loss: 0.137483
   Number of active neurons: 10
 >> iter 91000, loss: 0.058822
 >> iter 92000, loss: 0.022722
 >> iter 93000, loss: 0.009375
 >> iter 94000, loss: 0.045377
 >> iter 95000, loss: 0.017968
 >> iter 96000, loss: 0.007711
 >> iter 97000, loss: 0.003838
 >> iter 98000, loss: 0.002337
 >> iter 99000, loss: 0.001708
 >> iter 100000, loss: 0.001471
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.286896
 >> iter 2000, loss: 9.381810
 >> iter 3000, loss: 4.288709
 >> iter 4000, loss: 2.135721
 >> iter 5000, loss: 1.051235
 >> iter 6000, loss: 0.716861
 >> iter 7000, loss: 0.373646
 >> iter 8000, loss: 0.304636
 >> iter 9000, loss: 0.174576
 >> iter 10000, loss: 0.113359
   Number of active neurons: 10
 >> iter 11000, loss: 0.152806
 >> iter 12000, loss: 0.104952
 >> iter 13000, loss: 0.057558
 >> iter 14000, loss: 0.067006
 >> iter 15000, loss: 0.030309
 >> iter 16000, loss: 0.169838
 >> iter 17000, loss: 0.155637
 >> iter 18000, loss: 0.128139
 >> iter 19000, loss: 0.159609
 >> iter 20000, loss: 0.107337
   Number of active neurons: 10
 >> iter 21000, loss: 0.081369
 >> iter 22000, loss: 0.036281
 >> iter 23000, loss: 0.019764
 >> iter 24000, loss: 0.067408
 >> iter 25000, loss: 0.027799
 >> iter 26000, loss: 0.111557
 >> iter 27000, loss: 0.080872
 >> iter 28000, loss: 0.136818
 >> iter 29000, loss: 0.117976
 >> iter 30000, loss: 0.131154
   Number of active neurons: 10
 >> iter 31000, loss: 0.052688
 >> iter 32000, loss: 0.168887
 >> iter 33000, loss: 0.067587
 >> iter 34000, loss: 0.036149
 >> iter 35000, loss: 0.034912
 >> iter 36000, loss: 0.113555
 >> iter 37000, loss: 0.115032
 >> iter 38000, loss: 0.069782
 >> iter 39000, loss: 0.029735
 >> iter 40000, loss: 0.034974
   Number of active neurons: 10
 >> iter 41000, loss: 0.015292
 >> iter 42000, loss: 0.007693
 >> iter 43000, loss: 0.004728
 >> iter 44000, loss: 0.003292
 >> iter 45000, loss: 0.002728
 >> iter 46000, loss: 0.002441
 >> iter 47000, loss: 0.002094
 >> iter 48000, loss: 0.027199
 >> iter 49000, loss: 0.047867
 >> iter 50000, loss: 0.019465
   Number of active neurons: 10
 >> iter 51000, loss: 0.159752
 >> iter 52000, loss: 0.061699
 >> iter 53000, loss: 0.024637
 >> iter 54000, loss: 0.018886
 >> iter 55000, loss: 0.008339
 >> iter 56000, loss: 0.004181
 >> iter 57000, loss: 0.019561
 >> iter 58000, loss: 0.008690
 >> iter 59000, loss: 0.063373
 >> iter 60000, loss: 0.024694
   Number of active neurons: 10
 >> iter 61000, loss: 0.010417
 >> iter 62000, loss: 0.098284
 >> iter 63000, loss: 0.038056
 >> iter 64000, loss: 0.015522
 >> iter 65000, loss: 0.006896
 >> iter 66000, loss: 0.003630
 >> iter 67000, loss: 0.002311
 >> iter 68000, loss: 0.091623
 >> iter 69000, loss: 0.035114
 >> iter 70000, loss: 0.024703
   Number of active neurons: 10
 >> iter 71000, loss: 0.010456
 >> iter 72000, loss: 0.005016
 >> iter 73000, loss: 0.003049
 >> iter 74000, loss: 0.002037
 >> iter 75000, loss: 0.001688
 >> iter 76000, loss: 0.001482
 >> iter 77000, loss: 0.001331
 >> iter 78000, loss: 0.001232
 >> iter 79000, loss: 0.001264
 >> iter 80000, loss: 0.001110
   Number of active neurons: 10
 >> iter 81000, loss: 0.001374
 >> iter 82000, loss: 0.007325
 >> iter 83000, loss: 0.003304
 >> iter 84000, loss: 0.001792
 >> iter 85000, loss: 0.021247
 >> iter 86000, loss: 0.033395
 >> iter 87000, loss: 0.066256
 >> iter 88000, loss: 0.056676
 >> iter 89000, loss: 0.023440
 >> iter 90000, loss: 0.009835
   Number of active neurons: 10
 >> iter 91000, loss: 0.004709
 >> iter 92000, loss: 0.005940
 >> iter 93000, loss: 0.003134
 >> iter 94000, loss: 0.002136
 >> iter 95000, loss: 0.001567
 >> iter 96000, loss: 0.001391
 >> iter 97000, loss: 0.001185
 >> iter 98000, loss: 0.001058
 >> iter 99000, loss: 0.001018
 >> iter 100000, loss: 0.040322
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.418730
 >> iter 2000, loss: 8.890052
 >> iter 3000, loss: 3.888758
 >> iter 4000, loss: 1.783427
 >> iter 5000, loss: 0.886856
 >> iter 6000, loss: 0.392861
 >> iter 7000, loss: 0.290686
 >> iter 8000, loss: 0.399039
 >> iter 9000, loss: 0.334135
 >> iter 10000, loss: 0.250157
   Number of active neurons: 10
 >> iter 11000, loss: 0.142568
 >> iter 12000, loss: 0.123797
 >> iter 13000, loss: 0.141659
 >> iter 14000, loss: 0.190008
 >> iter 15000, loss: 0.081290
 >> iter 16000, loss: 0.185293
 >> iter 17000, loss: 0.074999
 >> iter 18000, loss: 0.031847
 >> iter 19000, loss: 0.290283
 >> iter 20000, loss: 0.197794
   Number of active neurons: 10
 >> iter 21000, loss: 0.077296
 >> iter 22000, loss: 0.095197
 >> iter 23000, loss: 0.101569
 >> iter 24000, loss: 0.042398
 >> iter 25000, loss: 0.020061
 >> iter 26000, loss: 0.010658
 >> iter 27000, loss: 0.006452
 >> iter 28000, loss: 0.180119
 >> iter 29000, loss: 0.069145
 >> iter 30000, loss: 0.027665
   Number of active neurons: 10
 >> iter 31000, loss: 0.012108
 >> iter 32000, loss: 0.007929
 >> iter 33000, loss: 0.012653
 >> iter 34000, loss: 0.008771
 >> iter 35000, loss: 0.039588
 >> iter 36000, loss: 0.045541
 >> iter 37000, loss: 0.020747
 >> iter 38000, loss: 0.015782
 >> iter 39000, loss: 0.158059
 >> iter 40000, loss: 0.064508
   Number of active neurons: 10
 >> iter 41000, loss: 0.026158
 >> iter 42000, loss: 0.030538
 >> iter 43000, loss: 0.041179
 >> iter 44000, loss: 0.017481
 >> iter 45000, loss: 0.008487
 >> iter 46000, loss: 0.010046
 >> iter 47000, loss: 0.005735
 >> iter 48000, loss: 0.026641
 >> iter 49000, loss: 0.011213
 >> iter 50000, loss: 0.006467
   Number of active neurons: 10
 >> iter 51000, loss: 0.100294
 >> iter 52000, loss: 0.039218
 >> iter 53000, loss: 0.016235
 >> iter 54000, loss: 0.008203
 >> iter 55000, loss: 0.004381
 >> iter 56000, loss: 0.004530
 >> iter 57000, loss: 0.002772
 >> iter 58000, loss: 0.071602
 >> iter 59000, loss: 0.047457
 >> iter 60000, loss: 0.084901
   Number of active neurons: 10
 >> iter 61000, loss: 0.033174
 >> iter 62000, loss: 0.013999
 >> iter 63000, loss: 0.040470
 >> iter 64000, loss: 0.017069
 >> iter 65000, loss: 0.008185
 >> iter 66000, loss: 0.004544
 >> iter 67000, loss: 0.002682
 >> iter 68000, loss: 0.002143
 >> iter 69000, loss: 0.002236
 >> iter 70000, loss: 0.021378
   Number of active neurons: 10
 >> iter 71000, loss: 0.009017
 >> iter 72000, loss: 0.038348
 >> iter 73000, loss: 0.047983
 >> iter 74000, loss: 0.019455
 >> iter 75000, loss: 0.032324
 >> iter 76000, loss: 0.013176
 >> iter 77000, loss: 0.006048
 >> iter 78000, loss: 0.050016
 >> iter 79000, loss: 0.019932
 >> iter 80000, loss: 0.009494
   Number of active neurons: 10
 >> iter 81000, loss: 0.011367
 >> iter 82000, loss: 0.067434
 >> iter 83000, loss: 0.073645
 >> iter 84000, loss: 0.028821
 >> iter 85000, loss: 0.012199
 >> iter 86000, loss: 0.005668
 >> iter 87000, loss: 0.003122
 >> iter 88000, loss: 0.062359
 >> iter 89000, loss: 0.064322
 >> iter 90000, loss: 0.026453
   Number of active neurons: 10
 >> iter 91000, loss: 0.011472
 >> iter 92000, loss: 0.005484
 >> iter 93000, loss: 0.007247
 >> iter 94000, loss: 0.043835
 >> iter 95000, loss: 0.017231
 >> iter 96000, loss: 0.007488
 >> iter 97000, loss: 0.030324
 >> iter 98000, loss: 0.012608
 >> iter 99000, loss: 0.005818
 >> iter 100000, loss: 0.003101
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.709289
 >> iter 2000, loss: 8.420987
 >> iter 3000, loss: 3.762308
 >> iter 4000, loss: 1.584888
 >> iter 5000, loss: 0.802527
 >> iter 6000, loss: 0.323197
 >> iter 7000, loss: 0.167588
 >> iter 8000, loss: 0.071668
 >> iter 9000, loss: 0.082922
 >> iter 10000, loss: 0.076481
   Number of active neurons: 10
 >> iter 11000, loss: 0.093795
 >> iter 12000, loss: 0.040583
 >> iter 13000, loss: 0.020090
 >> iter 14000, loss: 0.016435
 >> iter 15000, loss: 0.060847
 >> iter 16000, loss: 0.026001
 >> iter 17000, loss: 0.013159
 >> iter 18000, loss: 0.008297
 >> iter 19000, loss: 0.005546
 >> iter 20000, loss: 0.006391
   Number of active neurons: 10
 >> iter 21000, loss: 0.005341
 >> iter 22000, loss: 0.098097
 >> iter 23000, loss: 0.039236
 >> iter 24000, loss: 0.017042
 >> iter 25000, loss: 0.009204
 >> iter 26000, loss: 0.006273
 >> iter 27000, loss: 0.005077
 >> iter 28000, loss: 0.004261
 >> iter 29000, loss: 0.003338
 >> iter 30000, loss: 0.002656
   Number of active neurons: 10
 >> iter 31000, loss: 0.003142
 >> iter 32000, loss: 0.002480
 >> iter 33000, loss: 0.002161
 >> iter 34000, loss: 0.001930
 >> iter 35000, loss: 0.002859
 >> iter 36000, loss: 0.002565
 >> iter 37000, loss: 0.002288
 >> iter 38000, loss: 0.002037
 >> iter 39000, loss: 0.002208
 >> iter 40000, loss: 0.036098
   Number of active neurons: 10
 >> iter 41000, loss: 0.027378
 >> iter 42000, loss: 0.011561
 >> iter 43000, loss: 0.005980
 >> iter 44000, loss: 0.003411
 >> iter 45000, loss: 0.002758
 >> iter 46000, loss: 0.002159
 >> iter 47000, loss: 0.092055
 >> iter 48000, loss: 0.036843
 >> iter 49000, loss: 0.015324
 >> iter 50000, loss: 0.006668
   Number of active neurons: 10
 >> iter 51000, loss: 0.003439
 >> iter 52000, loss: 0.006074
 >> iter 53000, loss: 0.003604
 >> iter 54000, loss: 0.002814
 >> iter 55000, loss: 0.002030
 >> iter 56000, loss: 0.001533
 >> iter 57000, loss: 0.001362
 >> iter 58000, loss: 0.001385
 >> iter 59000, loss: 0.001245
 >> iter 60000, loss: 0.171741
   Number of active neurons: 10
 >> iter 61000, loss: 0.064835
 >> iter 62000, loss: 0.030259
 >> iter 63000, loss: 0.012160
 >> iter 64000, loss: 0.008395
 >> iter 65000, loss: 0.004080
 >> iter 66000, loss: 0.002267
 >> iter 67000, loss: 0.001531
 >> iter 68000, loss: 0.001272
 >> iter 69000, loss: 0.001095
 >> iter 70000, loss: 0.001104
   Number of active neurons: 10
 >> iter 71000, loss: 0.001082
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.704248
 >> iter 2000, loss: 9.293687
 >> iter 3000, loss: 4.144976
 >> iter 4000, loss: 1.913528
 >> iter 5000, loss: 0.898351
 >> iter 6000, loss: 0.568587
 >> iter 7000, loss: 0.282224
 >> iter 8000, loss: 0.241692
 >> iter 9000, loss: 0.265630
 >> iter 10000, loss: 0.223645
   Number of active neurons: 10
 >> iter 11000, loss: 0.123761
 >> iter 12000, loss: 0.212031
 >> iter 13000, loss: 0.275732
 >> iter 14000, loss: 0.112601
 >> iter 15000, loss: 0.046780
 >> iter 16000, loss: 0.059658
 >> iter 17000, loss: 0.068374
 >> iter 18000, loss: 0.118029
 >> iter 19000, loss: 0.093382
 >> iter 20000, loss: 0.051392
   Number of active neurons: 10
 >> iter 21000, loss: 0.109489
 >> iter 22000, loss: 0.050749
 >> iter 23000, loss: 0.062923
 >> iter 24000, loss: 0.027413
 >> iter 25000, loss: 0.048886
 >> iter 26000, loss: 0.021346
 >> iter 27000, loss: 0.010199
 >> iter 28000, loss: 0.043765
 >> iter 29000, loss: 0.018987
 >> iter 30000, loss: 0.060252
   Number of active neurons: 10
 >> iter 31000, loss: 0.035596
 >> iter 32000, loss: 0.064383
 >> iter 33000, loss: 0.085669
 >> iter 34000, loss: 0.035204
 >> iter 35000, loss: 0.015779
 >> iter 36000, loss: 0.081147
 >> iter 37000, loss: 0.033110
 >> iter 38000, loss: 0.015349
 >> iter 39000, loss: 0.007692
 >> iter 40000, loss: 0.004438
   Number of active neurons: 10
 >> iter 41000, loss: 0.003135
 >> iter 42000, loss: 0.009085
 >> iter 43000, loss: 0.004666
 >> iter 44000, loss: 0.002750
 >> iter 45000, loss: 0.002023
 >> iter 46000, loss: 0.001664
 >> iter 47000, loss: 0.001419
 >> iter 48000, loss: 0.001373
 >> iter 49000, loss: 0.001271
 >> iter 50000, loss: 0.004213
   Number of active neurons: 10
 >> iter 51000, loss: 0.002481
 >> iter 52000, loss: 0.001710
 >> iter 53000, loss: 0.001257
 >> iter 54000, loss: 0.001610
 >> iter 55000, loss: 0.059535
 >> iter 56000, loss: 0.080410
 >> iter 57000, loss: 0.031811
 >> iter 58000, loss: 0.012711
 >> iter 59000, loss: 0.005668
 >> iter 60000, loss: 0.002941
   Number of active neurons: 10
 >> iter 61000, loss: 0.001887
 >> iter 62000, loss: 0.001520
 >> iter 63000, loss: 0.001405
 >> iter 64000, loss: 0.001242
 >> iter 65000, loss: 0.001090
 >> iter 66000, loss: 0.001025
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.672461
 >> iter 2000, loss: 8.994424
 >> iter 3000, loss: 4.030237
 >> iter 4000, loss: 1.840506
 >> iter 5000, loss: 0.828935
 >> iter 6000, loss: 0.466133
 >> iter 7000, loss: 0.294353
 >> iter 8000, loss: 0.124977
 >> iter 9000, loss: 0.094900
 >> iter 10000, loss: 0.041615
   Number of active neurons: 10
 >> iter 11000, loss: 0.034220
 >> iter 12000, loss: 0.018555
 >> iter 13000, loss: 0.053197
 >> iter 14000, loss: 0.024063
 >> iter 15000, loss: 0.039694
 >> iter 16000, loss: 0.038499
 >> iter 17000, loss: 0.066950
 >> iter 18000, loss: 0.051780
 >> iter 19000, loss: 0.024515
 >> iter 20000, loss: 0.012843
   Number of active neurons: 10
 >> iter 21000, loss: 0.007404
 >> iter 22000, loss: 0.005260
 >> iter 23000, loss: 0.004041
 >> iter 24000, loss: 0.051593
 >> iter 25000, loss: 0.092958
 >> iter 26000, loss: 0.062204
 >> iter 27000, loss: 0.033415
 >> iter 28000, loss: 0.227560
 >> iter 29000, loss: 0.095213
 >> iter 30000, loss: 0.066771
   Number of active neurons: 10
 >> iter 31000, loss: 0.131535
 >> iter 32000, loss: 0.053709
 >> iter 33000, loss: 0.023306
 >> iter 34000, loss: 0.012275
 >> iter 35000, loss: 0.007214
 >> iter 36000, loss: 0.005107
 >> iter 37000, loss: 0.004009
 >> iter 38000, loss: 0.003285
 >> iter 39000, loss: 0.002815
 >> iter 40000, loss: 0.002779
   Number of active neurons: 10
 >> iter 41000, loss: 0.002533
 >> iter 42000, loss: 0.002258
 >> iter 43000, loss: 0.002139
 >> iter 44000, loss: 0.001896
 >> iter 45000, loss: 0.001917
 >> iter 46000, loss: 0.001731
 >> iter 47000, loss: 0.001636
 >> iter 48000, loss: 0.002563
 >> iter 49000, loss: 0.025674
 >> iter 50000, loss: 0.012438
   Number of active neurons: 10
 >> iter 51000, loss: 0.006264
 >> iter 52000, loss: 0.003730
 >> iter 53000, loss: 0.002638
 >> iter 54000, loss: 0.002131
 >> iter 55000, loss: 0.002120
 >> iter 56000, loss: 0.001578
 >> iter 57000, loss: 0.001365
 >> iter 58000, loss: 0.001230
 >> iter 59000, loss: 0.001215
 >> iter 60000, loss: 0.001190
   Number of active neurons: 10
 >> iter 61000, loss: 0.001175
 >> iter 62000, loss: 0.003327
 >> iter 63000, loss: 0.015028
 >> iter 64000, loss: 0.053750
 >> iter 65000, loss: 0.020759
 >> iter 66000, loss: 0.008807
 >> iter 67000, loss: 0.004082
 >> iter 68000, loss: 0.002288
 >> iter 69000, loss: 0.001524
 >> iter 70000, loss: 0.001710
   Number of active neurons: 10
 >> iter 71000, loss: 0.001431
 >> iter 72000, loss: 0.003401
 >> iter 73000, loss: 0.081203
 >> iter 74000, loss: 0.050624
 >> iter 75000, loss: 0.019817
 >> iter 76000, loss: 0.065743
 >> iter 77000, loss: 0.025387
 >> iter 78000, loss: 0.010627
 >> iter 79000, loss: 0.005052
 >> iter 80000, loss: 0.003570
   Number of active neurons: 10
 >> iter 81000, loss: 0.005112
 >> iter 82000, loss: 0.003056
 >> iter 83000, loss: 0.008426
 >> iter 84000, loss: 0.004129
 >> iter 85000, loss: 0.002368
 >> iter 86000, loss: 0.001692
 >> iter 87000, loss: 0.001311
 >> iter 88000, loss: 0.001136
 >> iter 89000, loss: 0.001007
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.404474
 >> iter 2000, loss: 8.533474
 >> iter 3000, loss: 3.888436
 >> iter 4000, loss: 1.779351
 >> iter 5000, loss: 0.891821
 >> iter 6000, loss: 0.411854
 >> iter 7000, loss: 0.340840
 >> iter 8000, loss: 0.154704
 >> iter 9000, loss: 0.075684
 >> iter 10000, loss: 0.168861
   Number of active neurons: 10
 >> iter 11000, loss: 0.077355
 >> iter 12000, loss: 0.044052
 >> iter 13000, loss: 0.102612
 >> iter 14000, loss: 0.246526
 >> iter 15000, loss: 0.102518
 >> iter 16000, loss: 0.044000
 >> iter 17000, loss: 0.031762
 >> iter 18000, loss: 0.358413
 >> iter 19000, loss: 0.140736
 >> iter 20000, loss: 0.112347
   Number of active neurons: 10
 >> iter 21000, loss: 0.046523
 >> iter 22000, loss: 0.020559
 >> iter 23000, loss: 0.010579
 >> iter 24000, loss: 0.037212
 >> iter 25000, loss: 0.017003
 >> iter 26000, loss: 0.008292
 >> iter 27000, loss: 0.054277
 >> iter 28000, loss: 0.047710
 >> iter 29000, loss: 0.019792
 >> iter 30000, loss: 0.027472
   Number of active neurons: 10
 >> iter 31000, loss: 0.063235
 >> iter 32000, loss: 0.025771
 >> iter 33000, loss: 0.136754
 >> iter 34000, loss: 0.053353
 >> iter 35000, loss: 0.021929
 >> iter 36000, loss: 0.010076
 >> iter 37000, loss: 0.005298
 >> iter 38000, loss: 0.024341
 >> iter 39000, loss: 0.010690
 >> iter 40000, loss: 0.037451
   Number of active neurons: 10
 >> iter 41000, loss: 0.015511
 >> iter 42000, loss: 0.007242
 >> iter 43000, loss: 0.004248
 >> iter 44000, loss: 0.005208
 >> iter 45000, loss: 0.037000
 >> iter 46000, loss: 0.015382
 >> iter 47000, loss: 0.007035
 >> iter 48000, loss: 0.003865
 >> iter 49000, loss: 0.003314
 >> iter 50000, loss: 0.002457
   Number of active neurons: 10
 >> iter 51000, loss: 0.006096
 >> iter 52000, loss: 0.059581
 >> iter 53000, loss: 0.024106
 >> iter 54000, loss: 0.013269
 >> iter 55000, loss: 0.006356
 >> iter 56000, loss: 0.003568
 >> iter 57000, loss: 0.004249
 >> iter 58000, loss: 0.002836
 >> iter 59000, loss: 0.003900
 >> iter 60000, loss: 0.002804
   Number of active neurons: 10
 >> iter 61000, loss: 0.002060
 >> iter 62000, loss: 0.001693
 >> iter 63000, loss: 0.001441
 >> iter 64000, loss: 0.001283
 >> iter 65000, loss: 0.001439
 >> iter 66000, loss: 0.003620
 >> iter 67000, loss: 0.002082
 >> iter 68000, loss: 0.001529
 >> iter 69000, loss: 0.001152
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.023568
 >> iter 2000, loss: 9.538648
 >> iter 3000, loss: 4.043328
 >> iter 4000, loss: 1.805060
 >> iter 5000, loss: 0.802392
 >> iter 6000, loss: 0.439297
 >> iter 7000, loss: 0.197743
 >> iter 8000, loss: 0.081148
 >> iter 9000, loss: 0.036800
 >> iter 10000, loss: 0.071830
   Number of active neurons: 10
 >> iter 11000, loss: 0.031377
 >> iter 12000, loss: 0.265267
 >> iter 13000, loss: 0.106559
 >> iter 14000, loss: 0.086682
 >> iter 15000, loss: 0.036648
 >> iter 16000, loss: 0.053200
 >> iter 17000, loss: 0.025074
 >> iter 18000, loss: 0.012558
 >> iter 19000, loss: 0.078458
 >> iter 20000, loss: 0.077062
   Number of active neurons: 10
 >> iter 21000, loss: 0.031831
 >> iter 22000, loss: 0.015236
 >> iter 23000, loss: 0.052684
 >> iter 24000, loss: 0.022739
 >> iter 25000, loss: 0.011263
 >> iter 26000, loss: 0.005854
 >> iter 27000, loss: 0.004616
 >> iter 28000, loss: 0.004267
 >> iter 29000, loss: 0.005465
 >> iter 30000, loss: 0.055470
   Number of active neurons: 10
 >> iter 31000, loss: 0.022211
 >> iter 32000, loss: 0.009614
 >> iter 33000, loss: 0.005660
 >> iter 34000, loss: 0.003724
 >> iter 35000, loss: 0.020951
 >> iter 36000, loss: 0.009299
 >> iter 37000, loss: 0.004863
 >> iter 38000, loss: 0.002851
 >> iter 39000, loss: 0.002204
 >> iter 40000, loss: 0.001965
   Number of active neurons: 10
 >> iter 41000, loss: 0.002034
 >> iter 42000, loss: 0.010850
 >> iter 43000, loss: 0.023211
 >> iter 44000, loss: 0.011188
 >> iter 45000, loss: 0.128234
 >> iter 46000, loss: 0.049297
 >> iter 47000, loss: 0.021236
 >> iter 48000, loss: 0.009108
 >> iter 49000, loss: 0.004723
 >> iter 50000, loss: 0.002977
   Number of active neurons: 10
 >> iter 51000, loss: 0.002368
 >> iter 52000, loss: 0.001785
 >> iter 53000, loss: 0.001565
 >> iter 54000, loss: 0.001617
 >> iter 55000, loss: 0.001429
 >> iter 56000, loss: 0.001267
 >> iter 57000, loss: 0.001230
 >> iter 58000, loss: 0.001172
 >> iter 59000, loss: 0.001153
 >> iter 60000, loss: 0.001037
   Number of active neurons: 10
 >> iter 61000, loss: 0.001062
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.724886
 >> iter 2000, loss: 9.025024
 >> iter 3000, loss: 4.207794
 >> iter 4000, loss: 1.806939
 >> iter 5000, loss: 0.775700
 >> iter 6000, loss: 0.675527
 >> iter 7000, loss: 0.362284
 >> iter 8000, loss: 0.166826
 >> iter 9000, loss: 0.144379
 >> iter 10000, loss: 0.080883
   Number of active neurons: 10
 >> iter 11000, loss: 0.175557
 >> iter 12000, loss: 0.085406
 >> iter 13000, loss: 0.123100
 >> iter 14000, loss: 0.149955
 >> iter 15000, loss: 0.095734
 >> iter 16000, loss: 0.040716
 >> iter 17000, loss: 0.062943
 >> iter 18000, loss: 0.078010
 >> iter 19000, loss: 0.091023
 >> iter 20000, loss: 0.037925
   Number of active neurons: 10
 >> iter 21000, loss: 0.072556
 >> iter 22000, loss: 0.307027
 >> iter 23000, loss: 0.143873
 >> iter 24000, loss: 0.192059
 >> iter 25000, loss: 0.077947
 >> iter 26000, loss: 0.042128
 >> iter 27000, loss: 0.018978
 >> iter 28000, loss: 0.010544
 >> iter 29000, loss: 0.006323
 >> iter 30000, loss: 0.004418
   Number of active neurons: 10
 >> iter 31000, loss: 0.056315
 >> iter 32000, loss: 0.023366
 >> iter 33000, loss: 0.011274
 >> iter 34000, loss: 0.005901
 >> iter 35000, loss: 0.003864
 >> iter 36000, loss: 0.111898
 >> iter 37000, loss: 0.045291
 >> iter 38000, loss: 0.019415
 >> iter 39000, loss: 0.008770
 >> iter 40000, loss: 0.004585
   Number of active neurons: 10
 >> iter 41000, loss: 0.003000
 >> iter 42000, loss: 0.002265
 >> iter 43000, loss: 0.001934
 >> iter 44000, loss: 0.002063
 >> iter 45000, loss: 0.001774
 >> iter 46000, loss: 0.001550
 >> iter 47000, loss: 0.001648
 >> iter 48000, loss: 0.001490
 >> iter 49000, loss: 0.001322
 >> iter 50000, loss: 0.001612
   Number of active neurons: 10
 >> iter 51000, loss: 0.001278
 >> iter 52000, loss: 0.001173
 >> iter 53000, loss: 0.001114
 >> iter 54000, loss: 0.001210
 >> iter 55000, loss: 0.001005
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

