 > Problema: tomita7nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.6
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.641815
 >> iter 2000, loss: 9.748168
 >> iter 3000, loss: 5.770304
 >> iter 4000, loss: 2.770234
 >> iter 5000, loss: 1.351294
 >> iter 6000, loss: 0.630434
 >> iter 7000, loss: 0.647246
 >> iter 8000, loss: 0.410332
 >> iter 9000, loss: 0.267435
 >> iter 10000, loss: 0.169449
   Number of active neurons: 10
 >> iter 11000, loss: 0.143453
 >> iter 12000, loss: 0.101941
 >> iter 13000, loss: 0.171767
 >> iter 14000, loss: 0.147720
 >> iter 15000, loss: 0.069319
 >> iter 16000, loss: 0.179944
 >> iter 17000, loss: 0.094830
 >> iter 18000, loss: 0.077449
 >> iter 19000, loss: 0.038161
 >> iter 20000, loss: 0.038269
   Number of active neurons: 10
 >> iter 21000, loss: 0.028299
 >> iter 22000, loss: 0.021454
 >> iter 23000, loss: 0.026671
 >> iter 24000, loss: 0.093165
 >> iter 25000, loss: 0.048232
 >> iter 26000, loss: 0.068286
 >> iter 27000, loss: 0.051980
 >> iter 28000, loss: 0.022903
 >> iter 29000, loss: 0.036328
 >> iter 30000, loss: 0.016819
   Number of active neurons: 10
 >> iter 31000, loss: 0.037817
 >> iter 32000, loss: 0.049441
 >> iter 33000, loss: 0.022407
 >> iter 34000, loss: 0.051185
 >> iter 35000, loss: 0.021874
 >> iter 36000, loss: 0.010398
 >> iter 37000, loss: 0.046415
 >> iter 38000, loss: 0.142419
 >> iter 39000, loss: 0.068446
 >> iter 40000, loss: 0.040368
   Number of active neurons: 10
 >> iter 41000, loss: 0.017257
 >> iter 42000, loss: 0.081101
 >> iter 43000, loss: 0.033056
 >> iter 44000, loss: 0.014630
 >> iter 45000, loss: 0.039717
 >> iter 46000, loss: 0.059878
 >> iter 47000, loss: 0.025459
 >> iter 48000, loss: 0.035816
 >> iter 49000, loss: 0.016168
 >> iter 50000, loss: 0.033647
   Number of active neurons: 10
 >> iter 51000, loss: 0.015130
 >> iter 52000, loss: 0.029444
 >> iter 53000, loss: 0.015431
 >> iter 54000, loss: 0.023068
 >> iter 55000, loss: 0.020602
 >> iter 56000, loss: 0.009510
 >> iter 57000, loss: 0.005427
 >> iter 58000, loss: 0.003560
 >> iter 59000, loss: 0.002803
 >> iter 60000, loss: 0.016802
   Number of active neurons: 10
 >> iter 61000, loss: 0.008083
 >> iter 62000, loss: 0.004420
 >> iter 63000, loss: 0.002935
 >> iter 64000, loss: 0.002284
 >> iter 65000, loss: 0.028936
 >> iter 66000, loss: 0.013206
 >> iter 67000, loss: 0.013857
 >> iter 68000, loss: 0.006552
 >> iter 69000, loss: 0.011093
 >> iter 70000, loss: 0.005358
   Number of active neurons: 10
 >> iter 71000, loss: 0.003331
 >> iter 72000, loss: 0.002354
 >> iter 73000, loss: 0.002008
 >> iter 74000, loss: 0.001824
 >> iter 75000, loss: 0.001629
 >> iter 76000, loss: 0.001907
 >> iter 77000, loss: 0.010964
 >> iter 78000, loss: 0.037897
 >> iter 79000, loss: 0.015116
 >> iter 80000, loss: 0.016636
   Number of active neurons: 10
 >> iter 81000, loss: 0.030675
 >> iter 82000, loss: 0.012406
 >> iter 83000, loss: 0.005653
 >> iter 84000, loss: 0.017102
 >> iter 85000, loss: 0.031529
 >> iter 86000, loss: 0.012893
 >> iter 87000, loss: 0.005899
 >> iter 88000, loss: 0.039897
 >> iter 89000, loss: 0.016403
 >> iter 90000, loss: 0.007159
   Number of active neurons: 10
 >> iter 91000, loss: 0.003656
 >> iter 92000, loss: 0.002226
 >> iter 93000, loss: 0.001702
 >> iter 94000, loss: 0.001426
 >> iter 95000, loss: 0.020379
 >> iter 96000, loss: 0.030040
 >> iter 97000, loss: 0.031498
 >> iter 98000, loss: 0.014036
 >> iter 99000, loss: 0.024536
 >> iter 100000, loss: 0.010353
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.231478
 >> iter 2000, loss: 9.642941
 >> iter 3000, loss: 5.993914
 >> iter 4000, loss: 2.947245
 >> iter 5000, loss: 1.459008
 >> iter 6000, loss: 0.899372
 >> iter 7000, loss: 0.454717
 >> iter 8000, loss: 0.245331
 >> iter 9000, loss: 0.314918
 >> iter 10000, loss: 0.375554
   Number of active neurons: 10
 >> iter 11000, loss: 0.154198
 >> iter 12000, loss: 0.119364
 >> iter 13000, loss: 0.093818
 >> iter 14000, loss: 0.068981
 >> iter 15000, loss: 0.076495
 >> iter 16000, loss: 0.079194
 >> iter 17000, loss: 0.043206
 >> iter 18000, loss: 0.020251
 >> iter 19000, loss: 0.016224
 >> iter 20000, loss: 0.057045
   Number of active neurons: 10
 >> iter 21000, loss: 0.025280
 >> iter 22000, loss: 0.019590
 >> iter 23000, loss: 0.039850
 >> iter 24000, loss: 0.029922
 >> iter 25000, loss: 0.062351
 >> iter 26000, loss: 0.064597
 >> iter 27000, loss: 0.056327
 >> iter 28000, loss: 0.068191
 >> iter 29000, loss: 0.040707
 >> iter 30000, loss: 0.030859
   Number of active neurons: 10
 >> iter 31000, loss: 0.070443
 >> iter 32000, loss: 0.050982
 >> iter 33000, loss: 0.022679
 >> iter 34000, loss: 0.011329
 >> iter 35000, loss: 0.006866
 >> iter 36000, loss: 0.004858
 >> iter 37000, loss: 0.017164
 >> iter 38000, loss: 0.074725
 >> iter 39000, loss: 0.087924
 >> iter 40000, loss: 0.041344
   Number of active neurons: 10
 >> iter 41000, loss: 0.060625
 >> iter 42000, loss: 0.054429
 >> iter 43000, loss: 0.024062
 >> iter 44000, loss: 0.011596
 >> iter 45000, loss: 0.023277
 >> iter 46000, loss: 0.010941
 >> iter 47000, loss: 0.038912
 >> iter 48000, loss: 0.027824
 >> iter 49000, loss: 0.046808
 >> iter 50000, loss: 0.040835
   Number of active neurons: 10
 >> iter 51000, loss: 0.017226
 >> iter 52000, loss: 0.165759
 >> iter 53000, loss: 0.091437
 >> iter 54000, loss: 0.040600
 >> iter 55000, loss: 0.018307
 >> iter 56000, loss: 0.009046
 >> iter 57000, loss: 0.057059
 >> iter 58000, loss: 0.023450
 >> iter 59000, loss: 0.010540
 >> iter 60000, loss: 0.005822
   Number of active neurons: 10
 >> iter 61000, loss: 0.023885
 >> iter 62000, loss: 0.010732
 >> iter 63000, loss: 0.022077
 >> iter 64000, loss: 0.029862
 >> iter 65000, loss: 0.012644
 >> iter 66000, loss: 0.006107
 >> iter 67000, loss: 0.004241
 >> iter 68000, loss: 0.002933
 >> iter 69000, loss: 0.049742
 >> iter 70000, loss: 0.081321
   Number of active neurons: 10
 >> iter 71000, loss: 0.032464
 >> iter 72000, loss: 0.014165
 >> iter 73000, loss: 0.044471
 >> iter 74000, loss: 0.027533
 >> iter 75000, loss: 0.012206
 >> iter 76000, loss: 0.026379
 >> iter 77000, loss: 0.011399
 >> iter 78000, loss: 0.005698
 >> iter 79000, loss: 0.003501
 >> iter 80000, loss: 0.002487
   Number of active neurons: 10
 >> iter 81000, loss: 0.002033
 >> iter 82000, loss: 0.024468
 >> iter 83000, loss: 0.013075
 >> iter 84000, loss: 0.010316
 >> iter 85000, loss: 0.010118
 >> iter 86000, loss: 0.004780
 >> iter 87000, loss: 0.027188
 >> iter 88000, loss: 0.011237
 >> iter 89000, loss: 0.006174
 >> iter 90000, loss: 0.003491
   Number of active neurons: 10
 >> iter 91000, loss: 0.002312
 >> iter 92000, loss: 0.002259
 >> iter 93000, loss: 0.001775
 >> iter 94000, loss: 0.001405
 >> iter 95000, loss: 0.001793
 >> iter 96000, loss: 0.020657
 >> iter 97000, loss: 0.025015
 >> iter 98000, loss: 0.034163
 >> iter 99000, loss: 0.013894
 >> iter 100000, loss: 0.005965
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 16.327848
 >> iter 2000, loss: 9.564545
 >> iter 3000, loss: 6.191209
 >> iter 4000, loss: 3.615504
 >> iter 5000, loss: 1.864106
 >> iter 6000, loss: 1.038007
 >> iter 7000, loss: 0.607766
 >> iter 8000, loss: 0.321805
 >> iter 9000, loss: 0.203536
 >> iter 10000, loss: 0.138115
   Number of active neurons: 10
 >> iter 11000, loss: 0.113084
 >> iter 12000, loss: 0.077188
 >> iter 13000, loss: 0.088603
 >> iter 14000, loss: 0.053190
 >> iter 15000, loss: 0.037428
 >> iter 16000, loss: 0.025276
 >> iter 17000, loss: 0.029086
 >> iter 18000, loss: 0.016930
 >> iter 19000, loss: 0.078376
 >> iter 20000, loss: 0.082947
   Number of active neurons: 10
 >> iter 21000, loss: 0.052008
 >> iter 22000, loss: 0.042361
 >> iter 23000, loss: 0.048222
 >> iter 24000, loss: 0.066954
 >> iter 25000, loss: 0.029165
 >> iter 26000, loss: 0.089444
 >> iter 27000, loss: 0.038105
 >> iter 28000, loss: 0.022949
 >> iter 29000, loss: 0.011894
 >> iter 30000, loss: 0.007026
   Number of active neurons: 10
 >> iter 31000, loss: 0.051774
 >> iter 32000, loss: 0.022741
 >> iter 33000, loss: 0.012529
 >> iter 34000, loss: 0.049797
 >> iter 35000, loss: 0.026667
 >> iter 36000, loss: 0.025035
 >> iter 37000, loss: 0.012187
 >> iter 38000, loss: 0.006951
 >> iter 39000, loss: 0.011595
 >> iter 40000, loss: 0.006310
   Number of active neurons: 10
 >> iter 41000, loss: 0.026630
 >> iter 42000, loss: 0.011838
 >> iter 43000, loss: 0.020787
 >> iter 44000, loss: 0.009627
 >> iter 45000, loss: 0.010442
 >> iter 46000, loss: 0.005684
 >> iter 47000, loss: 0.003749
 >> iter 48000, loss: 0.003142
 >> iter 49000, loss: 0.003113
 >> iter 50000, loss: 0.002523
   Number of active neurons: 10
 >> iter 51000, loss: 0.064227
 >> iter 52000, loss: 0.030431
 >> iter 53000, loss: 0.012950
 >> iter 54000, loss: 0.048509
 >> iter 55000, loss: 0.031915
 >> iter 56000, loss: 0.024226
 >> iter 57000, loss: 0.010843
 >> iter 58000, loss: 0.028945
 >> iter 59000, loss: 0.043342
 >> iter 60000, loss: 0.018390
   Number of active neurons: 10
 >> iter 61000, loss: 0.016834
 >> iter 62000, loss: 0.093713
 >> iter 63000, loss: 0.052211
 >> iter 64000, loss: 0.021223
 >> iter 65000, loss: 0.009591
 >> iter 66000, loss: 0.005311
 >> iter 67000, loss: 0.003471
 >> iter 68000, loss: 0.002478
 >> iter 69000, loss: 0.008419
 >> iter 70000, loss: 0.010884
   Number of active neurons: 10
 >> iter 71000, loss: 0.039536
 >> iter 72000, loss: 0.028560
 >> iter 73000, loss: 0.021687
 >> iter 74000, loss: 0.009772
 >> iter 75000, loss: 0.005058
 >> iter 76000, loss: 0.003191
 >> iter 77000, loss: 0.002397
 >> iter 78000, loss: 0.002969
 >> iter 79000, loss: 0.002304
 >> iter 80000, loss: 0.012725
   Number of active neurons: 10
 >> iter 81000, loss: 0.005992
 >> iter 82000, loss: 0.003606
 >> iter 83000, loss: 0.008709
 >> iter 84000, loss: 0.004609
 >> iter 85000, loss: 0.002829
 >> iter 86000, loss: 0.001930
 >> iter 87000, loss: 0.001720
 >> iter 88000, loss: 0.001414
 >> iter 89000, loss: 0.001270
 >> iter 90000, loss: 0.016738
   Number of active neurons: 10
 >> iter 91000, loss: 0.007437
 >> iter 92000, loss: 0.005241
 >> iter 93000, loss: 0.066156
 >> iter 94000, loss: 0.037496
 >> iter 95000, loss: 0.015134
 >> iter 96000, loss: 0.019286
 >> iter 97000, loss: 0.023317
 >> iter 98000, loss: 0.011524
 >> iter 99000, loss: 0.005328
 >> iter 100000, loss: 0.002936
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.804291
 >> iter 2000, loss: 9.618645
 >> iter 3000, loss: 5.294573
 >> iter 4000, loss: 2.316357
 >> iter 5000, loss: 1.023602
 >> iter 6000, loss: 0.439305
 >> iter 7000, loss: 0.224698
 >> iter 8000, loss: 0.163390
 >> iter 9000, loss: 0.128102
 >> iter 10000, loss: 0.129763
   Number of active neurons: 10
 >> iter 11000, loss: 0.124638
 >> iter 12000, loss: 0.058449
 >> iter 13000, loss: 0.061634
 >> iter 14000, loss: 0.139502
 >> iter 15000, loss: 0.123987
 >> iter 16000, loss: 0.052295
 >> iter 17000, loss: 0.034055
 >> iter 18000, loss: 0.070100
 >> iter 19000, loss: 0.032618
 >> iter 20000, loss: 0.022842
   Number of active neurons: 10
 >> iter 21000, loss: 0.107509
 >> iter 22000, loss: 0.085369
 >> iter 23000, loss: 0.056800
 >> iter 24000, loss: 0.026155
 >> iter 25000, loss: 0.013833
 >> iter 26000, loss: 0.048480
 >> iter 27000, loss: 0.104662
 >> iter 28000, loss: 0.073021
 >> iter 29000, loss: 0.031309
 >> iter 30000, loss: 0.014999
   Number of active neurons: 10
 >> iter 31000, loss: 0.045795
 >> iter 32000, loss: 0.039373
 >> iter 33000, loss: 0.018020
 >> iter 34000, loss: 0.021970
 >> iter 35000, loss: 0.026952
 >> iter 36000, loss: 0.063165
 >> iter 37000, loss: 0.059896
 >> iter 38000, loss: 0.049124
 >> iter 39000, loss: 0.074789
 >> iter 40000, loss: 0.054765
   Number of active neurons: 10
 >> iter 41000, loss: 0.033076
 >> iter 42000, loss: 0.035460
 >> iter 43000, loss: 0.015808
 >> iter 44000, loss: 0.008257
 >> iter 45000, loss: 0.005219
 >> iter 46000, loss: 0.003851
 >> iter 47000, loss: 0.003306
 >> iter 48000, loss: 0.068667
 >> iter 49000, loss: 0.028139
 >> iter 50000, loss: 0.062085
   Number of active neurons: 10
 >> iter 51000, loss: 0.029861
 >> iter 52000, loss: 0.034167
 >> iter 53000, loss: 0.014830
 >> iter 54000, loss: 0.012644
 >> iter 55000, loss: 0.007143
 >> iter 56000, loss: 0.004238
 >> iter 57000, loss: 0.003127
 >> iter 58000, loss: 0.023193
 >> iter 59000, loss: 0.010228
 >> iter 60000, loss: 0.009564
   Number of active neurons: 10
 >> iter 61000, loss: 0.004925
 >> iter 62000, loss: 0.011009
 >> iter 63000, loss: 0.005435
 >> iter 64000, loss: 0.049267
 >> iter 65000, loss: 0.019971
 >> iter 66000, loss: 0.009958
 >> iter 67000, loss: 0.005094
 >> iter 68000, loss: 0.003175
 >> iter 69000, loss: 0.002458
 >> iter 70000, loss: 0.002060
   Number of active neurons: 10
 >> iter 71000, loss: 0.001936
 >> iter 72000, loss: 0.001742
 >> iter 73000, loss: 0.041331
 >> iter 74000, loss: 0.016550
 >> iter 75000, loss: 0.007815
 >> iter 76000, loss: 0.068413
 >> iter 77000, loss: 0.035891
 >> iter 78000, loss: 0.028180
 >> iter 79000, loss: 0.011873
 >> iter 80000, loss: 0.005697
   Number of active neurons: 10
 >> iter 81000, loss: 0.025180
 >> iter 82000, loss: 0.040680
 >> iter 83000, loss: 0.054326
 >> iter 84000, loss: 0.022413
 >> iter 85000, loss: 0.009876
 >> iter 86000, loss: 0.004985
 >> iter 87000, loss: 0.004570
 >> iter 88000, loss: 0.015362
 >> iter 89000, loss: 0.006963
 >> iter 90000, loss: 0.018441
   Number of active neurons: 10
 >> iter 91000, loss: 0.008055
 >> iter 92000, loss: 0.027901
 >> iter 93000, loss: 0.292459
 >> iter 94000, loss: 0.113433
 >> iter 95000, loss: 0.080081
 >> iter 96000, loss: 0.105617
 >> iter 97000, loss: 0.055510
 >> iter 98000, loss: 0.022943
 >> iter 99000, loss: 0.026736
 >> iter 100000, loss: 0.013349
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.179400
 >> iter 2000, loss: 9.624304
 >> iter 3000, loss: 5.985874
 >> iter 4000, loss: 2.820625
 >> iter 5000, loss: 1.251687
 >> iter 6000, loss: 0.526007
 >> iter 7000, loss: 0.270853
 >> iter 8000, loss: 0.187821
 >> iter 9000, loss: 0.092113
 >> iter 10000, loss: 0.076915
   Number of active neurons: 10
 >> iter 11000, loss: 0.037112
 >> iter 12000, loss: 0.038187
 >> iter 13000, loss: 0.028723
 >> iter 14000, loss: 0.019170
 >> iter 15000, loss: 0.065028
 >> iter 16000, loss: 0.027763
 >> iter 17000, loss: 0.054608
 >> iter 18000, loss: 0.045839
 >> iter 19000, loss: 0.027336
 >> iter 20000, loss: 0.149481
   Number of active neurons: 10
 >> iter 21000, loss: 0.068696
 >> iter 22000, loss: 0.034492
 >> iter 23000, loss: 0.099605
 >> iter 24000, loss: 0.041373
 >> iter 25000, loss: 0.076926
 >> iter 26000, loss: 0.067050
 >> iter 27000, loss: 0.045837
 >> iter 28000, loss: 0.020765
 >> iter 29000, loss: 0.011002
 >> iter 30000, loss: 0.066934
   Number of active neurons: 10
 >> iter 31000, loss: 0.044436
 >> iter 32000, loss: 0.019973
 >> iter 33000, loss: 0.015055
 >> iter 34000, loss: 0.008066
 >> iter 35000, loss: 0.005283
 >> iter 36000, loss: 0.003929
 >> iter 37000, loss: 0.003519
 >> iter 38000, loss: 0.003337
 >> iter 39000, loss: 0.026896
 >> iter 40000, loss: 0.059540
   Number of active neurons: 10
 >> iter 41000, loss: 0.024857
 >> iter 42000, loss: 0.041636
 >> iter 43000, loss: 0.028494
 >> iter 44000, loss: 0.012500
 >> iter 45000, loss: 0.006474
 >> iter 46000, loss: 0.004257
 >> iter 47000, loss: 0.024683
 >> iter 48000, loss: 0.010571
 >> iter 49000, loss: 0.045338
 >> iter 50000, loss: 0.036917
   Number of active neurons: 10
 >> iter 51000, loss: 0.050951
 >> iter 52000, loss: 0.020942
 >> iter 53000, loss: 0.010128
 >> iter 54000, loss: 0.040474
 >> iter 55000, loss: 0.016688
 >> iter 56000, loss: 0.019240
 >> iter 57000, loss: 0.008699
 >> iter 58000, loss: 0.004495
 >> iter 59000, loss: 0.003192
 >> iter 60000, loss: 0.002425
   Number of active neurons: 10
 >> iter 61000, loss: 0.002059
 >> iter 62000, loss: 0.001847
 >> iter 63000, loss: 0.002205
 >> iter 64000, loss: 0.028631
 >> iter 65000, loss: 0.011710
 >> iter 66000, loss: 0.005358
 >> iter 67000, loss: 0.002980
 >> iter 68000, loss: 0.001993
 >> iter 69000, loss: 0.042875
 >> iter 70000, loss: 0.017219
   Number of active neurons: 10
 >> iter 71000, loss: 0.010203
 >> iter 72000, loss: 0.005120
 >> iter 73000, loss: 0.007488
 >> iter 74000, loss: 0.003749
 >> iter 75000, loss: 0.003121
 >> iter 76000, loss: 0.002089
 >> iter 77000, loss: 0.001815
 >> iter 78000, loss: 0.024649
 >> iter 79000, loss: 0.010244
 >> iter 80000, loss: 0.004834
   Number of active neurons: 10
 >> iter 81000, loss: 0.002836
 >> iter 82000, loss: 0.002162
 >> iter 83000, loss: 0.001610
 >> iter 84000, loss: 0.001372
 >> iter 85000, loss: 0.001292
 >> iter 86000, loss: 0.015594
 >> iter 87000, loss: 0.006588
 >> iter 88000, loss: 0.008401
 >> iter 89000, loss: 0.003888
 >> iter 90000, loss: 0.014445
   Number of active neurons: 10
 >> iter 91000, loss: 0.023949
 >> iter 92000, loss: 0.010100
 >> iter 93000, loss: 0.004607
 >> iter 94000, loss: 0.002419
 >> iter 95000, loss: 0.002690
 >> iter 96000, loss: 0.001827
 >> iter 97000, loss: 0.001449
 >> iter 98000, loss: 0.001403
 >> iter 99000, loss: 0.001169
 >> iter 100000, loss: 0.001077
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.448736
 >> iter 2000, loss: 9.639841
 >> iter 3000, loss: 6.381931
 >> iter 4000, loss: 4.151794
 >> iter 5000, loss: 3.074880
 >> iter 6000, loss: 2.503186
 >> iter 7000, loss: 1.807712
 >> iter 8000, loss: 1.202832
 >> iter 9000, loss: 0.766750
 >> iter 10000, loss: 0.445247
   Number of active neurons: 10
 >> iter 11000, loss: 0.219421
 >> iter 12000, loss: 0.186829
 >> iter 13000, loss: 0.100763
 >> iter 14000, loss: 0.085690
 >> iter 15000, loss: 0.157290
 >> iter 16000, loss: 0.095244
 >> iter 17000, loss: 0.118598
 >> iter 18000, loss: 0.144461
 >> iter 19000, loss: 0.098220
 >> iter 20000, loss: 0.209668
   Number of active neurons: 10
 >> iter 21000, loss: 0.185072
 >> iter 22000, loss: 0.175189
 >> iter 23000, loss: 0.078655
 >> iter 24000, loss: 0.164507
 >> iter 25000, loss: 0.099413
 >> iter 26000, loss: 0.133018
 >> iter 27000, loss: 0.088599
 >> iter 28000, loss: 0.082483
 >> iter 29000, loss: 0.059810
 >> iter 30000, loss: 0.106901
   Number of active neurons: 10
 >> iter 31000, loss: 0.052992
 >> iter 32000, loss: 0.024159
 >> iter 33000, loss: 0.012298
 >> iter 34000, loss: 0.054366
 >> iter 35000, loss: 0.031939
 >> iter 36000, loss: 0.041107
 >> iter 37000, loss: 0.083080
 >> iter 38000, loss: 0.043391
 >> iter 39000, loss: 0.046933
 >> iter 40000, loss: 0.091351
   Number of active neurons: 10
 >> iter 41000, loss: 0.107137
 >> iter 42000, loss: 0.068587
 >> iter 43000, loss: 0.064114
 >> iter 44000, loss: 0.050023
 >> iter 45000, loss: 0.029993
 >> iter 46000, loss: 0.014030
 >> iter 47000, loss: 0.007804
 >> iter 48000, loss: 0.005337
 >> iter 49000, loss: 0.003984
 >> iter 50000, loss: 0.003639
   Number of active neurons: 10
 >> iter 51000, loss: 0.017706
 >> iter 52000, loss: 0.105364
 >> iter 53000, loss: 0.092764
 >> iter 54000, loss: 0.062606
 >> iter 55000, loss: 0.039842
 >> iter 56000, loss: 0.037089
 >> iter 57000, loss: 0.034222
 >> iter 58000, loss: 0.023699
 >> iter 59000, loss: 0.011630
 >> iter 60000, loss: 0.007375
   Number of active neurons: 10
 >> iter 61000, loss: 0.004440
 >> iter 62000, loss: 0.034674
 >> iter 63000, loss: 0.016784
 >> iter 64000, loss: 0.011844
 >> iter 65000, loss: 0.006403
 >> iter 66000, loss: 0.008968
 >> iter 67000, loss: 0.052781
 >> iter 68000, loss: 0.021603
 >> iter 69000, loss: 0.034339
 >> iter 70000, loss: 0.014771
   Number of active neurons: 10
 >> iter 71000, loss: 0.009839
 >> iter 72000, loss: 0.063295
 >> iter 73000, loss: 0.025316
 >> iter 74000, loss: 0.010949
 >> iter 75000, loss: 0.014105
 >> iter 76000, loss: 0.006678
 >> iter 77000, loss: 0.024562
 >> iter 78000, loss: 0.010845
 >> iter 79000, loss: 0.005461
 >> iter 80000, loss: 0.003340
   Number of active neurons: 10
 >> iter 81000, loss: 0.002468
 >> iter 82000, loss: 0.002966
 >> iter 83000, loss: 0.048478
 >> iter 84000, loss: 0.019218
 >> iter 85000, loss: 0.008261
 >> iter 86000, loss: 0.004087
 >> iter 87000, loss: 0.002533
 >> iter 88000, loss: 0.020782
 >> iter 89000, loss: 0.025684
 >> iter 90000, loss: 0.010540
   Number of active neurons: 10
 >> iter 91000, loss: 0.004892
 >> iter 92000, loss: 0.002693
 >> iter 93000, loss: 0.001883
 >> iter 94000, loss: 0.001492
 >> iter 95000, loss: 0.001339
 >> iter 96000, loss: 0.008835
 >> iter 97000, loss: 0.004260
 >> iter 98000, loss: 0.002344
 >> iter 99000, loss: 0.001602
 >> iter 100000, loss: 0.030424
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.342742
 >> iter 2000, loss: 10.040153
 >> iter 3000, loss: 5.941161
 >> iter 4000, loss: 3.019976
 >> iter 5000, loss: 1.373674
 >> iter 6000, loss: 0.812747
 >> iter 7000, loss: 0.450718
 >> iter 8000, loss: 0.259166
 >> iter 9000, loss: 0.187367
 >> iter 10000, loss: 0.182863
   Number of active neurons: 10
 >> iter 11000, loss: 0.112920
 >> iter 12000, loss: 0.092534
 >> iter 13000, loss: 0.126185
 >> iter 14000, loss: 0.123743
 >> iter 15000, loss: 0.071749
 >> iter 16000, loss: 0.093356
 >> iter 17000, loss: 0.044724
 >> iter 18000, loss: 0.128615
 >> iter 19000, loss: 0.083170
 >> iter 20000, loss: 0.140229
   Number of active neurons: 10
 >> iter 21000, loss: 0.060069
 >> iter 22000, loss: 0.028246
 >> iter 23000, loss: 0.016997
 >> iter 24000, loss: 0.025929
 >> iter 25000, loss: 0.014402
 >> iter 26000, loss: 0.022455
 >> iter 27000, loss: 0.016200
 >> iter 28000, loss: 0.009590
 >> iter 29000, loss: 0.006987
 >> iter 30000, loss: 0.085849
   Number of active neurons: 10
 >> iter 31000, loss: 0.046605
 >> iter 32000, loss: 0.026557
 >> iter 33000, loss: 0.033700
 >> iter 34000, loss: 0.037079
 >> iter 35000, loss: 0.017299
 >> iter 36000, loss: 0.022446
 >> iter 37000, loss: 0.011105
 >> iter 38000, loss: 0.006499
 >> iter 39000, loss: 0.030900
 >> iter 40000, loss: 0.013868
   Number of active neurons: 10
 >> iter 41000, loss: 0.007594
 >> iter 42000, loss: 0.011161
 >> iter 43000, loss: 0.010613
 >> iter 44000, loss: 0.055097
 >> iter 45000, loss: 0.035189
 >> iter 46000, loss: 0.026195
 >> iter 47000, loss: 0.019700
 >> iter 48000, loss: 0.009632
 >> iter 49000, loss: 0.005944
 >> iter 50000, loss: 0.004160
   Number of active neurons: 10
 >> iter 51000, loss: 0.014054
 >> iter 52000, loss: 0.015893
 >> iter 53000, loss: 0.008115
 >> iter 54000, loss: 0.004745
 >> iter 55000, loss: 0.003545
 >> iter 56000, loss: 0.003000
 >> iter 57000, loss: 0.002838
 >> iter 58000, loss: 0.004276
 >> iter 59000, loss: 0.003305
 >> iter 60000, loss: 0.009660
   Number of active neurons: 10
 >> iter 61000, loss: 0.005080
 >> iter 62000, loss: 0.003208
 >> iter 63000, loss: 0.002621
 >> iter 64000, loss: 0.017579
 >> iter 65000, loss: 0.007898
 >> iter 66000, loss: 0.004201
 >> iter 67000, loss: 0.003396
 >> iter 68000, loss: 0.002445
 >> iter 69000, loss: 0.010910
 >> iter 70000, loss: 0.005411
   Number of active neurons: 10
 >> iter 71000, loss: 0.034857
 >> iter 72000, loss: 0.014505
 >> iter 73000, loss: 0.016989
 >> iter 74000, loss: 0.021571
 >> iter 75000, loss: 0.033153
 >> iter 76000, loss: 0.033952
 >> iter 77000, loss: 0.014314
 >> iter 78000, loss: 0.006598
 >> iter 79000, loss: 0.003753
 >> iter 80000, loss: 0.002609
   Number of active neurons: 10
 >> iter 81000, loss: 0.002157
 >> iter 82000, loss: 0.001957
 >> iter 83000, loss: 0.021235
 >> iter 84000, loss: 0.009063
 >> iter 85000, loss: 0.004730
 >> iter 86000, loss: 0.002828
 >> iter 87000, loss: 0.002181
 >> iter 88000, loss: 0.001767
 >> iter 89000, loss: 0.001684
 >> iter 90000, loss: 0.001557
   Number of active neurons: 10
 >> iter 91000, loss: 0.036228
 >> iter 92000, loss: 0.015099
 >> iter 93000, loss: 0.023843
 >> iter 94000, loss: 0.009892
 >> iter 95000, loss: 0.004791
 >> iter 96000, loss: 0.002734
 >> iter 97000, loss: 0.002060
 >> iter 98000, loss: 0.015366
 >> iter 99000, loss: 0.006690
 >> iter 100000, loss: 0.003430
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.350418
 >> iter 2000, loss: 9.503402
 >> iter 3000, loss: 5.487202
 >> iter 4000, loss: 2.630411
 >> iter 5000, loss: 1.332678
 >> iter 6000, loss: 0.700409
 >> iter 7000, loss: 0.409151
 >> iter 8000, loss: 0.274987
 >> iter 9000, loss: 0.193759
 >> iter 10000, loss: 0.197904
   Number of active neurons: 10
 >> iter 11000, loss: 0.101121
 >> iter 12000, loss: 0.045089
 >> iter 13000, loss: 0.038076
 >> iter 14000, loss: 0.022331
 >> iter 15000, loss: 0.019460
 >> iter 16000, loss: 0.027685
 >> iter 17000, loss: 0.070308
 >> iter 18000, loss: 0.085264
 >> iter 19000, loss: 0.071446
 >> iter 20000, loss: 0.037072
   Number of active neurons: 10
 >> iter 21000, loss: 0.017611
 >> iter 22000, loss: 0.044320
 >> iter 23000, loss: 0.030817
 >> iter 24000, loss: 0.094730
 >> iter 25000, loss: 0.104180
 >> iter 26000, loss: 0.042905
 >> iter 27000, loss: 0.019524
 >> iter 28000, loss: 0.010121
 >> iter 29000, loss: 0.006560
 >> iter 30000, loss: 0.004622
   Number of active neurons: 10
 >> iter 31000, loss: 0.030736
 >> iter 32000, loss: 0.013972
 >> iter 33000, loss: 0.014473
 >> iter 34000, loss: 0.008070
 >> iter 35000, loss: 0.004912
 >> iter 36000, loss: 0.003775
 >> iter 37000, loss: 0.003040
 >> iter 38000, loss: 0.005169
 >> iter 39000, loss: 0.031482
 >> iter 40000, loss: 0.026987
   Number of active neurons: 10
 >> iter 41000, loss: 0.011763
 >> iter 42000, loss: 0.006335
 >> iter 43000, loss: 0.003744
 >> iter 44000, loss: 0.002681
 >> iter 45000, loss: 0.020867
 >> iter 46000, loss: 0.009643
 >> iter 47000, loss: 0.012205
 >> iter 48000, loss: 0.005684
 >> iter 49000, loss: 0.055648
 >> iter 50000, loss: 0.022277
   Number of active neurons: 10
 >> iter 51000, loss: 0.010028
 >> iter 52000, loss: 0.005433
 >> iter 53000, loss: 0.010836
 >> iter 54000, loss: 0.020399
 >> iter 55000, loss: 0.008806
 >> iter 56000, loss: 0.004258
 >> iter 57000, loss: 0.002741
 >> iter 58000, loss: 0.013580
 >> iter 59000, loss: 0.009836
 >> iter 60000, loss: 0.004542
   Number of active neurons: 10
 >> iter 61000, loss: 0.002778
 >> iter 62000, loss: 0.001862
 >> iter 63000, loss: 0.001699
 >> iter 64000, loss: 0.001317
 >> iter 65000, loss: 0.015886
 >> iter 66000, loss: 0.006971
 >> iter 67000, loss: 0.021833
 >> iter 68000, loss: 0.008945
 >> iter 69000, loss: 0.004068
 >> iter 70000, loss: 0.002278
   Number of active neurons: 10
 >> iter 71000, loss: 0.001564
 >> iter 72000, loss: 0.008572
 >> iter 73000, loss: 0.004234
 >> iter 74000, loss: 0.002454
 >> iter 75000, loss: 0.014051
 >> iter 76000, loss: 0.065342
 >> iter 77000, loss: 0.025615
 >> iter 78000, loss: 0.091530
 >> iter 79000, loss: 0.035272
 >> iter 80000, loss: 0.014149
   Number of active neurons: 10
 >> iter 81000, loss: 0.006440
 >> iter 82000, loss: 0.003354
 >> iter 83000, loss: 0.002517
 >> iter 84000, loss: 0.081603
 >> iter 85000, loss: 0.049629
 >> iter 86000, loss: 0.025294
 >> iter 87000, loss: 0.014866
 >> iter 88000, loss: 0.020595
 >> iter 89000, loss: 0.028350
 >> iter 90000, loss: 0.012414
   Number of active neurons: 10
 >> iter 91000, loss: 0.005861
 >> iter 92000, loss: 0.003276
 >> iter 93000, loss: 0.002947
 >> iter 94000, loss: 0.002829
 >> iter 95000, loss: 0.005768
 >> iter 96000, loss: 0.004217
 >> iter 97000, loss: 0.002472
 >> iter 98000, loss: 0.001736
 >> iter 99000, loss: 0.001408
 >> iter 100000, loss: 0.001237
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.399188
 >> iter 2000, loss: 9.683253
 >> iter 3000, loss: 4.929488
 >> iter 4000, loss: 2.111428
 >> iter 5000, loss: 1.045178
 >> iter 6000, loss: 0.428660
 >> iter 7000, loss: 0.516088
 >> iter 8000, loss: 0.295151
 >> iter 9000, loss: 0.192492
 >> iter 10000, loss: 0.129417
   Number of active neurons: 10
 >> iter 11000, loss: 0.082211
 >> iter 12000, loss: 0.056275
 >> iter 13000, loss: 0.033858
 >> iter 14000, loss: 0.130325
 >> iter 15000, loss: 0.116643
 >> iter 16000, loss: 0.084821
 >> iter 17000, loss: 0.065804
 >> iter 18000, loss: 0.061066
 >> iter 19000, loss: 0.030928
 >> iter 20000, loss: 0.048148
   Number of active neurons: 10
 >> iter 21000, loss: 0.024800
 >> iter 22000, loss: 0.044014
 >> iter 23000, loss: 0.021893
 >> iter 24000, loss: 0.036773
 >> iter 25000, loss: 0.065519
 >> iter 26000, loss: 0.029317
 >> iter 27000, loss: 0.052799
 >> iter 28000, loss: 0.082394
 >> iter 29000, loss: 0.035764
 >> iter 30000, loss: 0.094304
   Number of active neurons: 10
 >> iter 31000, loss: 0.115102
 >> iter 32000, loss: 0.047603
 >> iter 33000, loss: 0.022066
 >> iter 34000, loss: 0.011826
 >> iter 35000, loss: 0.007630
 >> iter 36000, loss: 0.005833
 >> iter 37000, loss: 0.005078
 >> iter 38000, loss: 0.018513
 >> iter 39000, loss: 0.017432
 >> iter 40000, loss: 0.084802
   Number of active neurons: 10
 >> iter 41000, loss: 0.133927
 >> iter 42000, loss: 0.053592
 >> iter 43000, loss: 0.032877
 >> iter 44000, loss: 0.088194
 >> iter 45000, loss: 0.151118
 >> iter 46000, loss: 0.060514
 >> iter 47000, loss: 0.124887
 >> iter 48000, loss: 0.051758
 >> iter 49000, loss: 0.023390
 >> iter 50000, loss: 0.036025
   Number of active neurons: 10
 >> iter 51000, loss: 0.017717
 >> iter 52000, loss: 0.009433
 >> iter 53000, loss: 0.006336
 >> iter 54000, loss: 0.006182
 >> iter 55000, loss: 0.004697
 >> iter 56000, loss: 0.005452
 >> iter 57000, loss: 0.032913
 >> iter 58000, loss: 0.044041
 >> iter 59000, loss: 0.037031
 >> iter 60000, loss: 0.063022
   Number of active neurons: 10
 >> iter 61000, loss: 0.026637
 >> iter 62000, loss: 0.012283
 >> iter 63000, loss: 0.032138
 >> iter 64000, loss: 0.020613
 >> iter 65000, loss: 0.092793
 >> iter 66000, loss: 0.068020
 >> iter 67000, loss: 0.049425
 >> iter 68000, loss: 0.021333
 >> iter 69000, loss: 0.027676
 >> iter 70000, loss: 0.012552
   Number of active neurons: 10
 >> iter 71000, loss: 0.006975
 >> iter 72000, loss: 0.004459
 >> iter 73000, loss: 0.004191
 >> iter 74000, loss: 0.077773
 >> iter 75000, loss: 0.031513
 >> iter 76000, loss: 0.013763
 >> iter 77000, loss: 0.007079
 >> iter 78000, loss: 0.004374
 >> iter 79000, loss: 0.003574
 >> iter 80000, loss: 0.002975
   Number of active neurons: 10
 >> iter 81000, loss: 0.047428
 >> iter 82000, loss: 0.019798
 >> iter 83000, loss: 0.021036
 >> iter 84000, loss: 0.009813
 >> iter 85000, loss: 0.005368
 >> iter 86000, loss: 0.004201
 >> iter 87000, loss: 0.075970
 >> iter 88000, loss: 0.029972
 >> iter 89000, loss: 0.017429
 >> iter 90000, loss: 0.008198
   Number of active neurons: 10
 >> iter 91000, loss: 0.004753
 >> iter 92000, loss: 0.113496
 >> iter 93000, loss: 0.047828
 >> iter 94000, loss: 0.020942
 >> iter 95000, loss: 0.009682
 >> iter 96000, loss: 0.034753
 >> iter 97000, loss: 0.015648
 >> iter 98000, loss: 0.008217
 >> iter 99000, loss: 0.048285
 >> iter 100000, loss: 0.019876
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 3.37977468169
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.307660
 >> iter 2000, loss: 9.535889
 >> iter 3000, loss: 6.306723
 >> iter 4000, loss: 4.426449
 >> iter 5000, loss: 3.117536
 >> iter 6000, loss: 2.394498
 >> iter 7000, loss: 1.888962
 >> iter 8000, loss: 1.423121
 >> iter 9000, loss: 0.939735
 >> iter 10000, loss: 0.591965
   Number of active neurons: 10
 >> iter 11000, loss: 0.644833
 >> iter 12000, loss: 0.434108
 >> iter 13000, loss: 0.268886
 >> iter 14000, loss: 0.242410
 >> iter 15000, loss: 0.208803
 >> iter 16000, loss: 0.205245
 >> iter 17000, loss: 0.197529
 >> iter 18000, loss: 0.106754
 >> iter 19000, loss: 0.282573
 >> iter 20000, loss: 0.217649
   Number of active neurons: 10
 >> iter 21000, loss: 0.103244
 >> iter 22000, loss: 0.195397
 >> iter 23000, loss: 0.133178
 >> iter 24000, loss: 0.114040
 >> iter 25000, loss: 0.067890
 >> iter 26000, loss: 0.093610
 >> iter 27000, loss: 0.160198
 >> iter 28000, loss: 0.084971
 >> iter 29000, loss: 0.047618
 >> iter 30000, loss: 0.025295
   Number of active neurons: 10
 >> iter 31000, loss: 0.014556
 >> iter 32000, loss: 0.028984
 >> iter 33000, loss: 0.086274
 >> iter 34000, loss: 0.042387
 >> iter 35000, loss: 0.031314
 >> iter 36000, loss: 0.062079
 >> iter 37000, loss: 0.038343
 >> iter 38000, loss: 0.025366
 >> iter 39000, loss: 0.012417
 >> iter 40000, loss: 0.012657
   Number of active neurons: 10
 >> iter 41000, loss: 0.007209
 >> iter 42000, loss: 0.058245
 >> iter 43000, loss: 0.057984
 >> iter 44000, loss: 0.030000
 >> iter 45000, loss: 0.019999
 >> iter 46000, loss: 0.015910
 >> iter 47000, loss: 0.008078
 >> iter 48000, loss: 0.004790
 >> iter 49000, loss: 0.003445
 >> iter 50000, loss: 0.002862
   Number of active neurons: 10
 >> iter 51000, loss: 0.002493
 >> iter 52000, loss: 0.002225
 >> iter 53000, loss: 0.002113
 >> iter 54000, loss: 0.001915
 >> iter 55000, loss: 0.001868
 >> iter 56000, loss: 0.001734
 >> iter 57000, loss: 0.001649
 >> iter 58000, loss: 0.001538
 >> iter 59000, loss: 0.001528
 >> iter 60000, loss: 0.001446
   Number of active neurons: 10
 >> iter 61000, loss: 0.001373
 >> iter 62000, loss: 0.006807
 >> iter 63000, loss: 0.003411
 >> iter 64000, loss: 0.048542
 >> iter 65000, loss: 0.019003
 >> iter 66000, loss: 0.007981
 >> iter 67000, loss: 0.003982
 >> iter 68000, loss: 0.002364
 >> iter 69000, loss: 0.001709
 >> iter 70000, loss: 0.002145
   Number of active neurons: 10
 >> iter 71000, loss: 0.110610
 >> iter 72000, loss: 0.086380
 >> iter 73000, loss: 0.034766
 >> iter 74000, loss: 0.014693
 >> iter 75000, loss: 0.008704
 >> iter 76000, loss: 0.022185
 >> iter 77000, loss: 0.009728
 >> iter 78000, loss: 0.010321
 >> iter 79000, loss: 0.005550
 >> iter 80000, loss: 0.009262
   Number of active neurons: 10
 >> iter 81000, loss: 0.007853
 >> iter 82000, loss: 0.004018
 >> iter 83000, loss: 0.010968
 >> iter 84000, loss: 0.029374
 >> iter 85000, loss: 0.025396
 >> iter 86000, loss: 0.011116
 >> iter 87000, loss: 0.005212
 >> iter 88000, loss: 0.002925
 >> iter 89000, loss: 0.002040
 >> iter 90000, loss: 0.001669
   Number of active neurons: 10
 >> iter 91000, loss: 0.001475
 >> iter 92000, loss: 0.001870
 >> iter 93000, loss: 0.001784
 >> iter 94000, loss: 0.001401
 >> iter 95000, loss: 0.012725
 >> iter 96000, loss: 0.029661
 >> iter 97000, loss: 0.012490
 >> iter 98000, loss: 0.005480
 >> iter 99000, loss: 0.002911
 >> iter 100000, loss: 0.014444
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.608095
 >> iter 2000, loss: 9.704678
 >> iter 3000, loss: 5.239473
 >> iter 4000, loss: 2.530010
 >> iter 5000, loss: 1.321286
 >> iter 6000, loss: 0.650979
 >> iter 7000, loss: 0.627520
 >> iter 8000, loss: 0.507432
 >> iter 9000, loss: 0.241567
 >> iter 10000, loss: 0.178567
   Number of active neurons: 10
 >> iter 11000, loss: 0.297897
 >> iter 12000, loss: 0.148284
 >> iter 13000, loss: 0.155504
 >> iter 14000, loss: 0.118880
 >> iter 15000, loss: 0.064686
 >> iter 16000, loss: 0.066949
 >> iter 17000, loss: 0.102717
 >> iter 18000, loss: 0.061896
 >> iter 19000, loss: 0.119559
 >> iter 20000, loss: 0.121178
   Number of active neurons: 10
 >> iter 21000, loss: 0.052386
 >> iter 22000, loss: 0.024191
 >> iter 23000, loss: 0.026182
 >> iter 24000, loss: 0.075749
 >> iter 25000, loss: 0.055601
 >> iter 26000, loss: 0.024612
 >> iter 27000, loss: 0.024176
 >> iter 28000, loss: 0.064746
 >> iter 29000, loss: 0.083558
 >> iter 30000, loss: 0.035929
   Number of active neurons: 10
 >> iter 31000, loss: 0.018072
 >> iter 32000, loss: 0.016173
 >> iter 33000, loss: 0.025747
 >> iter 34000, loss: 0.012483
 >> iter 35000, loss: 0.007030
 >> iter 36000, loss: 0.031271
 >> iter 37000, loss: 0.015642
 >> iter 38000, loss: 0.010502
 >> iter 39000, loss: 0.006080
 >> iter 40000, loss: 0.004044
   Number of active neurons: 10
 >> iter 41000, loss: 0.044265
 >> iter 42000, loss: 0.027984
 >> iter 43000, loss: 0.026458
 >> iter 44000, loss: 0.012059
 >> iter 45000, loss: 0.006141
 >> iter 46000, loss: 0.003942
 >> iter 47000, loss: 0.003274
 >> iter 48000, loss: 0.002509
 >> iter 49000, loss: 0.002487
 >> iter 50000, loss: 0.002108
   Number of active neurons: 10
 >> iter 51000, loss: 0.048270
 >> iter 52000, loss: 0.019193
 >> iter 53000, loss: 0.008299
 >> iter 54000, loss: 0.004350
 >> iter 55000, loss: 0.002917
 >> iter 56000, loss: 0.002302
 >> iter 57000, loss: 0.002013
 >> iter 58000, loss: 0.001747
 >> iter 59000, loss: 0.001603
 >> iter 60000, loss: 0.008300
   Number of active neurons: 10
 >> iter 61000, loss: 0.004133
 >> iter 62000, loss: 0.002456
 >> iter 63000, loss: 0.011866
 >> iter 64000, loss: 0.005509
 >> iter 65000, loss: 0.002894
 >> iter 66000, loss: 0.001922
 >> iter 67000, loss: 0.006094
 >> iter 68000, loss: 0.003124
 >> iter 69000, loss: 0.045719
 >> iter 70000, loss: 0.032841
   Number of active neurons: 10
 >> iter 71000, loss: 0.013233
 >> iter 72000, loss: 0.017811
 >> iter 73000, loss: 0.007879
 >> iter 74000, loss: 0.004286
 >> iter 75000, loss: 0.038450
 >> iter 76000, loss: 0.015989
 >> iter 77000, loss: 0.006964
 >> iter 78000, loss: 0.003544
 >> iter 79000, loss: 0.002333
 >> iter 80000, loss: 0.001757
   Number of active neurons: 10
 >> iter 81000, loss: 0.001570
 >> iter 82000, loss: 0.001495
 >> iter 83000, loss: 0.001348
 >> iter 84000, loss: 0.001365
 >> iter 85000, loss: 0.001229
 >> iter 86000, loss: 0.001139
 >> iter 87000, loss: 0.001137
 >> iter 88000, loss: 0.001628
 >> iter 89000, loss: 0.001278
 >> iter 90000, loss: 0.001076
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.231431
 >> iter 2000, loss: 9.336707
 >> iter 3000, loss: 4.935365
 >> iter 4000, loss: 2.137197
 >> iter 5000, loss: 1.056347
 >> iter 6000, loss: 0.538301
 >> iter 7000, loss: 0.334308
 >> iter 8000, loss: 0.222796
 >> iter 9000, loss: 0.137408
 >> iter 10000, loss: 0.197688
   Number of active neurons: 10
 >> iter 11000, loss: 0.228433
 >> iter 12000, loss: 0.130440
 >> iter 13000, loss: 0.062141
 >> iter 14000, loss: 0.052813
 >> iter 15000, loss: 0.047078
 >> iter 16000, loss: 0.059930
 >> iter 17000, loss: 0.035257
 >> iter 18000, loss: 0.020770
 >> iter 19000, loss: 0.014644
 >> iter 20000, loss: 0.011788
   Number of active neurons: 10
 >> iter 21000, loss: 0.017411
 >> iter 22000, loss: 0.011257
 >> iter 23000, loss: 0.009154
 >> iter 24000, loss: 0.011686
 >> iter 25000, loss: 0.029829
 >> iter 26000, loss: 0.045107
 >> iter 27000, loss: 0.033812
 >> iter 28000, loss: 0.074671
 >> iter 29000, loss: 0.042476
 >> iter 30000, loss: 0.020044
   Number of active neurons: 10
 >> iter 31000, loss: 0.011230
 >> iter 32000, loss: 0.007212
 >> iter 33000, loss: 0.051783
 >> iter 34000, loss: 0.023100
 >> iter 35000, loss: 0.012286
 >> iter 36000, loss: 0.023381
 >> iter 37000, loss: 0.012044
 >> iter 38000, loss: 0.007679
 >> iter 39000, loss: 0.031601
 >> iter 40000, loss: 0.023828
   Number of active neurons: 10
 >> iter 41000, loss: 0.042963
 >> iter 42000, loss: 0.018948
 >> iter 43000, loss: 0.017199
 >> iter 44000, loss: 0.049357
 >> iter 45000, loss: 0.021527
 >> iter 46000, loss: 0.010763
 >> iter 47000, loss: 0.006403
 >> iter 48000, loss: 0.004465
 >> iter 49000, loss: 0.003735
 >> iter 50000, loss: 0.003074
   Number of active neurons: 10
 >> iter 51000, loss: 0.003071
 >> iter 52000, loss: 0.077266
 >> iter 53000, loss: 0.049264
 >> iter 54000, loss: 0.021121
 >> iter 55000, loss: 0.010044
 >> iter 56000, loss: 0.055348
 >> iter 57000, loss: 0.029454
 >> iter 58000, loss: 0.047526
 >> iter 59000, loss: 0.054257
 >> iter 60000, loss: 0.033046
   Number of active neurons: 10
 >> iter 61000, loss: 0.023230
 >> iter 62000, loss: 0.042689
 >> iter 63000, loss: 0.034672
 >> iter 64000, loss: 0.015478
 >> iter 65000, loss: 0.011041
 >> iter 66000, loss: 0.054486
 >> iter 67000, loss: 0.030064
 >> iter 68000, loss: 0.079163
 >> iter 69000, loss: 0.033837
 >> iter 70000, loss: 0.021063
   Number of active neurons: 10
 >> iter 71000, loss: 0.041863
 >> iter 72000, loss: 0.095446
 >> iter 73000, loss: 0.073313
 >> iter 74000, loss: 0.031266
 >> iter 75000, loss: 0.063441
 >> iter 76000, loss: 0.070273
 >> iter 77000, loss: 0.069813
 >> iter 78000, loss: 0.029065
 >> iter 79000, loss: 0.013644
 >> iter 80000, loss: 0.009724
   Number of active neurons: 10
 >> iter 81000, loss: 0.006256
 >> iter 82000, loss: 0.004607
 >> iter 83000, loss: 0.003670
 >> iter 84000, loss: 0.003149
 >> iter 85000, loss: 0.002843
 >> iter 86000, loss: 0.002623
 >> iter 87000, loss: 0.002508
 >> iter 88000, loss: 0.002338
 >> iter 89000, loss: 0.002734
 >> iter 90000, loss: 0.002282
   Number of active neurons: 10
 >> iter 91000, loss: 0.007829
 >> iter 92000, loss: 0.027580
 >> iter 93000, loss: 0.016277
 >> iter 94000, loss: 0.008049
 >> iter 95000, loss: 0.004487
 >> iter 96000, loss: 0.003321
 >> iter 97000, loss: 0.008495
 >> iter 98000, loss: 0.004823
 >> iter 99000, loss: 0.003215
 >> iter 100000, loss: 0.002310
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455184
   Number of active neurons: 0
 >> iter 1000, loss: 16.416417
 >> iter 2000, loss: 9.293399
 >> iter 3000, loss: 5.974450
 >> iter 4000, loss: 3.691642
 >> iter 5000, loss: 1.998096
 >> iter 6000, loss: 1.245969
 >> iter 7000, loss: 0.827876
 >> iter 8000, loss: 0.497760
 >> iter 9000, loss: 0.394671
 >> iter 10000, loss: 0.377108
   Number of active neurons: 10
 >> iter 11000, loss: 0.390495
 >> iter 12000, loss: 0.220642
 >> iter 13000, loss: 0.130772
 >> iter 14000, loss: 0.136694
 >> iter 15000, loss: 0.091110
 >> iter 16000, loss: 0.233003
 >> iter 17000, loss: 0.148046
 >> iter 18000, loss: 0.104739
 >> iter 19000, loss: 0.191188
 >> iter 20000, loss: 0.197373
   Number of active neurons: 10
 >> iter 21000, loss: 0.151647
 >> iter 22000, loss: 0.067635
 >> iter 23000, loss: 0.038564
 >> iter 24000, loss: 0.096541
 >> iter 25000, loss: 0.065871
 >> iter 26000, loss: 0.228040
 >> iter 27000, loss: 0.115105
 >> iter 28000, loss: 0.066084
 >> iter 29000, loss: 0.056878
 >> iter 30000, loss: 0.133710
   Number of active neurons: 10
 >> iter 31000, loss: 0.115291
 >> iter 32000, loss: 0.132563
 >> iter 33000, loss: 0.077712
 >> iter 34000, loss: 0.033998
 >> iter 35000, loss: 0.028032
 >> iter 36000, loss: 0.039332
 >> iter 37000, loss: 0.024841
 >> iter 38000, loss: 0.068394
 >> iter 39000, loss: 0.092629
 >> iter 40000, loss: 0.092888
   Number of active neurons: 10
 >> iter 41000, loss: 0.122404
 >> iter 42000, loss: 0.070255
 >> iter 43000, loss: 0.041144
 >> iter 44000, loss: 0.035715
 >> iter 45000, loss: 0.018463
 >> iter 46000, loss: 0.009815
 >> iter 47000, loss: 0.028770
 >> iter 48000, loss: 0.048026
 >> iter 49000, loss: 0.077590
 >> iter 50000, loss: 0.080597
   Number of active neurons: 10
 >> iter 51000, loss: 0.040845
 >> iter 52000, loss: 0.017713
 >> iter 53000, loss: 0.051254
 >> iter 54000, loss: 0.028282
 >> iter 55000, loss: 0.053742
 >> iter 56000, loss: 0.023999
 >> iter 57000, loss: 0.011626
 >> iter 58000, loss: 0.012548
 >> iter 59000, loss: 0.097161
 >> iter 60000, loss: 0.073609
   Number of active neurons: 10
 >> iter 61000, loss: 0.055413
 >> iter 62000, loss: 0.046608
 >> iter 63000, loss: 0.055282
 >> iter 64000, loss: 0.093020
 >> iter 65000, loss: 0.050394
 >> iter 66000, loss: 0.030932
 >> iter 67000, loss: 0.013929
 >> iter 68000, loss: 0.055794
 >> iter 69000, loss: 0.086721
 >> iter 70000, loss: 0.041408
   Number of active neurons: 10
 >> iter 71000, loss: 0.035330
 >> iter 72000, loss: 0.023932
 >> iter 73000, loss: 0.058015
 >> iter 74000, loss: 0.029442
 >> iter 75000, loss: 0.013153
 >> iter 76000, loss: 0.062398
 >> iter 77000, loss: 0.032726
 >> iter 78000, loss: 0.037140
 >> iter 79000, loss: 0.019062
 >> iter 80000, loss: 0.013332
   Number of active neurons: 10
 >> iter 81000, loss: 0.007578
 >> iter 82000, loss: 0.005898
 >> iter 83000, loss: 0.004078
 >> iter 84000, loss: 0.002879
 >> iter 85000, loss: 0.002386
 >> iter 86000, loss: 0.009036
 >> iter 87000, loss: 0.014692
 >> iter 88000, loss: 0.072105
 >> iter 89000, loss: 0.035460
 >> iter 90000, loss: 0.014455
   Number of active neurons: 10
 >> iter 91000, loss: 0.012694
 >> iter 92000, loss: 0.006038
 >> iter 93000, loss: 0.003391
 >> iter 94000, loss: 0.002305
 >> iter 95000, loss: 0.026319
 >> iter 96000, loss: 0.076730
 >> iter 97000, loss: 0.030348
 >> iter 98000, loss: 0.012626
 >> iter 99000, loss: 0.005950
 >> iter 100000, loss: 0.003320
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.470023
 >> iter 2000, loss: 9.775963
 >> iter 3000, loss: 6.469516
 >> iter 4000, loss: 3.536662
 >> iter 5000, loss: 1.619652
 >> iter 6000, loss: 0.850017
 >> iter 7000, loss: 0.414014
 >> iter 8000, loss: 0.166899
 >> iter 9000, loss: 0.077963
 >> iter 10000, loss: 0.097954
   Number of active neurons: 10
 >> iter 11000, loss: 0.121798
 >> iter 12000, loss: 0.150198
 >> iter 13000, loss: 0.112965
 >> iter 14000, loss: 0.148346
 >> iter 15000, loss: 0.068429
 >> iter 16000, loss: 0.068513
 >> iter 17000, loss: 0.067344
 >> iter 18000, loss: 0.069784
 >> iter 19000, loss: 0.031811
 >> iter 20000, loss: 0.017455
   Number of active neurons: 10
 >> iter 21000, loss: 0.072599
 >> iter 22000, loss: 0.037049
 >> iter 23000, loss: 0.065933
 >> iter 24000, loss: 0.033936
 >> iter 25000, loss: 0.016761
 >> iter 26000, loss: 0.022191
 >> iter 27000, loss: 0.012689
 >> iter 28000, loss: 0.006895
 >> iter 29000, loss: 0.017862
 >> iter 30000, loss: 0.014226
   Number of active neurons: 10
 >> iter 31000, loss: 0.008056
 >> iter 32000, loss: 0.023368
 >> iter 33000, loss: 0.011723
 >> iter 34000, loss: 0.006560
 >> iter 35000, loss: 0.004335
 >> iter 36000, loss: 0.003339
 >> iter 37000, loss: 0.002630
 >> iter 38000, loss: 0.002483
 >> iter 39000, loss: 0.008561
 >> iter 40000, loss: 0.032349
   Number of active neurons: 10
 >> iter 41000, loss: 0.013699
 >> iter 42000, loss: 0.006431
 >> iter 43000, loss: 0.003528
 >> iter 44000, loss: 0.002455
 >> iter 45000, loss: 0.036165
 >> iter 46000, loss: 0.014845
 >> iter 47000, loss: 0.007084
 >> iter 48000, loss: 0.003676
 >> iter 49000, loss: 0.003855
 >> iter 50000, loss: 0.002965
   Number of active neurons: 10
 >> iter 51000, loss: 0.002231
 >> iter 52000, loss: 0.001765
 >> iter 53000, loss: 0.003124
 >> iter 54000, loss: 0.002813
 >> iter 55000, loss: 0.010332
 >> iter 56000, loss: 0.004812
 >> iter 57000, loss: 0.002664
 >> iter 58000, loss: 0.001878
 >> iter 59000, loss: 0.001603
 >> iter 60000, loss: 0.001308
   Number of active neurons: 10
 >> iter 61000, loss: 0.001243
 >> iter 62000, loss: 0.001063
 >> iter 63000, loss: 0.001764
 >> iter 64000, loss: 0.001377
 >> iter 65000, loss: 0.019354
 >> iter 66000, loss: 0.007877
 >> iter 67000, loss: 0.003485
 >> iter 68000, loss: 0.001942
 >> iter 69000, loss: 0.003272
 >> iter 70000, loss: 0.001921
   Number of active neurons: 10
 >> iter 71000, loss: 0.001236
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.682788
 >> iter 2000, loss: 9.457376
 >> iter 3000, loss: 4.843159
 >> iter 4000, loss: 2.071279
 >> iter 5000, loss: 0.970247
 >> iter 6000, loss: 0.461918
 >> iter 7000, loss: 0.253819
 >> iter 8000, loss: 0.172316
 >> iter 9000, loss: 0.193279
 >> iter 10000, loss: 0.111947
   Number of active neurons: 10
 >> iter 11000, loss: 0.108738
 >> iter 12000, loss: 0.091017
 >> iter 13000, loss: 0.075072
 >> iter 14000, loss: 0.071617
 >> iter 15000, loss: 0.101124
 >> iter 16000, loss: 0.051840
 >> iter 17000, loss: 0.050632
 >> iter 18000, loss: 0.170749
 >> iter 19000, loss: 0.114989
 >> iter 20000, loss: 0.078350
   Number of active neurons: 10
 >> iter 21000, loss: 0.035001
 >> iter 22000, loss: 0.032415
 >> iter 23000, loss: 0.016830
 >> iter 24000, loss: 0.021404
 >> iter 25000, loss: 0.011385
 >> iter 26000, loss: 0.013201
 >> iter 27000, loss: 0.007779
 >> iter 28000, loss: 0.005340
 >> iter 29000, loss: 0.054022
 >> iter 30000, loss: 0.072760
   Number of active neurons: 10
 >> iter 31000, loss: 0.069732
 >> iter 32000, loss: 0.028910
 >> iter 33000, loss: 0.013876
 >> iter 34000, loss: 0.007471
 >> iter 35000, loss: 0.044902
 >> iter 36000, loss: 0.019788
 >> iter 37000, loss: 0.010143
 >> iter 38000, loss: 0.020725
 >> iter 39000, loss: 0.032694
 >> iter 40000, loss: 0.014164
   Number of active neurons: 10
 >> iter 41000, loss: 0.030950
 >> iter 42000, loss: 0.028306
 >> iter 43000, loss: 0.034111
 >> iter 44000, loss: 0.014978
 >> iter 45000, loss: 0.008599
 >> iter 46000, loss: 0.068559
 >> iter 47000, loss: 0.028326
 >> iter 48000, loss: 0.012379
 >> iter 49000, loss: 0.013292
 >> iter 50000, loss: 0.006550
   Number of active neurons: 10
 >> iter 51000, loss: 0.004309
 >> iter 52000, loss: 0.003126
 >> iter 53000, loss: 0.002611
 >> iter 54000, loss: 0.002292
 >> iter 55000, loss: 0.002090
 >> iter 56000, loss: 0.003427
 >> iter 57000, loss: 0.018660
 >> iter 58000, loss: 0.037991
 >> iter 59000, loss: 0.026911
 >> iter 60000, loss: 0.011522
   Number of active neurons: 10
 >> iter 61000, loss: 0.005503
 >> iter 62000, loss: 0.003290
 >> iter 63000, loss: 0.027654
 >> iter 64000, loss: 0.024210
 >> iter 65000, loss: 0.010613
 >> iter 66000, loss: 0.005202
 >> iter 67000, loss: 0.011211
 >> iter 68000, loss: 0.020994
 >> iter 69000, loss: 0.030390
 >> iter 70000, loss: 0.012708
   Number of active neurons: 10
 >> iter 71000, loss: 0.006291
 >> iter 72000, loss: 0.003456
 >> iter 73000, loss: 0.002344
 >> iter 74000, loss: 0.001898
 >> iter 75000, loss: 0.001677
 >> iter 76000, loss: 0.001510
 >> iter 77000, loss: 0.001506
 >> iter 78000, loss: 0.001484
 >> iter 79000, loss: 0.003265
 >> iter 80000, loss: 0.002030
   Number of active neurons: 10
 >> iter 81000, loss: 0.001549
 >> iter 82000, loss: 0.001308
 >> iter 83000, loss: 0.001243
 >> iter 84000, loss: 0.001142
 >> iter 85000, loss: 0.001124
 >> iter 86000, loss: 0.001062
 >> iter 87000, loss: 0.001101
 >> iter 88000, loss: 0.001165
 >> iter 89000, loss: 0.209203
 >> iter 90000, loss: 0.114940
   Number of active neurons: 10
 >> iter 91000, loss: 0.079661
 >> iter 92000, loss: 0.030638
 >> iter 93000, loss: 0.026615
 >> iter 94000, loss: 0.010942
 >> iter 95000, loss: 0.030610
 >> iter 96000, loss: 0.012401
 >> iter 97000, loss: 0.022396
 >> iter 98000, loss: 0.009292
 >> iter 99000, loss: 0.037332
 >> iter 100000, loss: 0.015487
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.194723
 >> iter 2000, loss: 9.535861
 >> iter 3000, loss: 5.136763
 >> iter 4000, loss: 2.165138
 >> iter 5000, loss: 0.897408
 >> iter 6000, loss: 0.399406
 >> iter 7000, loss: 0.203462
 >> iter 8000, loss: 0.093826
 >> iter 9000, loss: 0.196174
 >> iter 10000, loss: 0.103294
   Number of active neurons: 10
 >> iter 11000, loss: 0.123780
 >> iter 12000, loss: 0.074802
 >> iter 13000, loss: 0.056374
 >> iter 14000, loss: 0.034475
 >> iter 15000, loss: 0.026649
 >> iter 16000, loss: 0.052822
 >> iter 17000, loss: 0.089764
 >> iter 18000, loss: 0.040562
 >> iter 19000, loss: 0.019600
 >> iter 20000, loss: 0.011262
   Number of active neurons: 10
 >> iter 21000, loss: 0.018699
 >> iter 22000, loss: 0.014246
 >> iter 23000, loss: 0.008773
 >> iter 24000, loss: 0.025571
 >> iter 25000, loss: 0.012148
 >> iter 26000, loss: 0.007740
 >> iter 27000, loss: 0.005673
 >> iter 28000, loss: 0.005098
 >> iter 29000, loss: 0.003881
 >> iter 30000, loss: 0.008837
   Number of active neurons: 10
 >> iter 31000, loss: 0.033819
 >> iter 32000, loss: 0.014903
 >> iter 33000, loss: 0.007316
 >> iter 34000, loss: 0.004226
 >> iter 35000, loss: 0.014962
 >> iter 36000, loss: 0.007446
 >> iter 37000, loss: 0.034847
 >> iter 38000, loss: 0.014793
 >> iter 39000, loss: 0.006976
 >> iter 40000, loss: 0.005341
   Number of active neurons: 10
 >> iter 41000, loss: 0.003898
 >> iter 42000, loss: 0.002834
 >> iter 43000, loss: 0.043352
 >> iter 44000, loss: 0.017427
 >> iter 45000, loss: 0.007673
 >> iter 46000, loss: 0.016747
 >> iter 47000, loss: 0.007943
 >> iter 48000, loss: 0.004288
 >> iter 49000, loss: 0.002722
 >> iter 50000, loss: 0.002015
   Number of active neurons: 10
 >> iter 51000, loss: 0.016897
 >> iter 52000, loss: 0.008027
 >> iter 53000, loss: 0.004391
 >> iter 54000, loss: 0.047057
 >> iter 55000, loss: 0.037986
 >> iter 56000, loss: 0.015411
 >> iter 57000, loss: 0.006826
 >> iter 58000, loss: 0.004593
 >> iter 59000, loss: 0.002750
 >> iter 60000, loss: 0.004687
   Number of active neurons: 10
 >> iter 61000, loss: 0.002658
 >> iter 62000, loss: 0.005407
 >> iter 63000, loss: 0.002878
 >> iter 64000, loss: 0.001926
 >> iter 65000, loss: 0.001591
 >> iter 66000, loss: 0.001549
 >> iter 67000, loss: 0.001443
 >> iter 68000, loss: 0.001293
 >> iter 69000, loss: 0.001231
 >> iter 70000, loss: 0.001137
   Number of active neurons: 10
 >> iter 71000, loss: 0.009307
 >> iter 72000, loss: 0.044761
 >> iter 73000, loss: 0.017415
 >> iter 74000, loss: 0.026528
 >> iter 75000, loss: 0.010688
 >> iter 76000, loss: 0.004841
 >> iter 77000, loss: 0.002703
 >> iter 78000, loss: 0.001816
 >> iter 79000, loss: 0.001529
 >> iter 80000, loss: 0.002432
   Number of active neurons: 10
 >> iter 81000, loss: 0.003502
 >> iter 82000, loss: 0.002236
 >> iter 83000, loss: 0.001620
 >> iter 84000, loss: 0.001255
 >> iter 85000, loss: 0.001217
 >> iter 86000, loss: 0.002292
 >> iter 87000, loss: 0.013825
 >> iter 88000, loss: 0.005873
 >> iter 89000, loss: 0.002823
 >> iter 90000, loss: 0.014280
   Number of active neurons: 10
 >> iter 91000, loss: 0.014649
 >> iter 92000, loss: 0.006040
 >> iter 93000, loss: 0.003515
 >> iter 94000, loss: 0.020688
 >> iter 95000, loss: 0.065425
 >> iter 96000, loss: 0.024960
 >> iter 97000, loss: 0.009999
 >> iter 98000, loss: 0.004551
 >> iter 99000, loss: 0.002450
 >> iter 100000, loss: 0.001604
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.282851
 >> iter 2000, loss: 9.913171
 >> iter 3000, loss: 6.940146
 >> iter 4000, loss: 3.750555
 >> iter 5000, loss: 1.648831
 >> iter 6000, loss: 0.738340
 >> iter 7000, loss: 0.356281
 >> iter 8000, loss: 0.192574
 >> iter 9000, loss: 0.186496
 >> iter 10000, loss: 0.109672
   Number of active neurons: 10
 >> iter 11000, loss: 0.060339
 >> iter 12000, loss: 0.042049
 >> iter 13000, loss: 0.020729
 >> iter 14000, loss: 0.039965
 >> iter 15000, loss: 0.019944
 >> iter 16000, loss: 0.082865
 >> iter 17000, loss: 0.037849
 >> iter 18000, loss: 0.046312
 >> iter 19000, loss: 0.031360
 >> iter 20000, loss: 0.015474
   Number of active neurons: 10
 >> iter 21000, loss: 0.040101
 >> iter 22000, loss: 0.061334
 >> iter 23000, loss: 0.025515
 >> iter 24000, loss: 0.062956
 >> iter 25000, loss: 0.096973
 >> iter 26000, loss: 0.040519
 >> iter 27000, loss: 0.018748
 >> iter 28000, loss: 0.009469
 >> iter 29000, loss: 0.021479
 >> iter 30000, loss: 0.009998
   Number of active neurons: 10
 >> iter 31000, loss: 0.033563
 >> iter 32000, loss: 0.014947
 >> iter 33000, loss: 0.007810
 >> iter 34000, loss: 0.004971
 >> iter 35000, loss: 0.003521
 >> iter 36000, loss: 0.018288
 >> iter 37000, loss: 0.030289
 >> iter 38000, loss: 0.140161
 >> iter 39000, loss: 0.054928
 >> iter 40000, loss: 0.022085
   Number of active neurons: 10
 >> iter 41000, loss: 0.009811
 >> iter 42000, loss: 0.033474
 >> iter 43000, loss: 0.014141
 >> iter 44000, loss: 0.008799
 >> iter 45000, loss: 0.031576
 >> iter 46000, loss: 0.013176
 >> iter 47000, loss: 0.007491
 >> iter 48000, loss: 0.004220
 >> iter 49000, loss: 0.003014
 >> iter 50000, loss: 0.002304
   Number of active neurons: 10
 >> iter 51000, loss: 0.001978
 >> iter 52000, loss: 0.001719
 >> iter 53000, loss: 0.001595
 >> iter 54000, loss: 0.002153
 >> iter 55000, loss: 0.001966
 >> iter 56000, loss: 0.001782
 >> iter 57000, loss: 0.025693
 >> iter 58000, loss: 0.036317
 >> iter 59000, loss: 0.014848
 >> iter 60000, loss: 0.006689
   Number of active neurons: 10
 >> iter 61000, loss: 0.003581
 >> iter 62000, loss: 0.002383
 >> iter 63000, loss: 0.001688
 >> iter 64000, loss: 0.001422
 >> iter 65000, loss: 0.004930
 >> iter 66000, loss: 0.002773
 >> iter 67000, loss: 0.001758
 >> iter 68000, loss: 0.001350
 >> iter 69000, loss: 0.001196
 >> iter 70000, loss: 0.001192
   Number of active neurons: 10
 >> iter 71000, loss: 0.012746
 >> iter 72000, loss: 0.006777
 >> iter 73000, loss: 0.003218
 >> iter 74000, loss: 0.002039
 >> iter 75000, loss: 0.001394
 >> iter 76000, loss: 0.001154
 >> iter 77000, loss: 0.001035
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.456091
 >> iter 2000, loss: 9.376177
 >> iter 3000, loss: 4.273780
 >> iter 4000, loss: 1.797700
 >> iter 5000, loss: 0.827362
 >> iter 6000, loss: 0.360251
 >> iter 7000, loss: 0.204395
 >> iter 8000, loss: 0.145718
 >> iter 9000, loss: 0.174178
 >> iter 10000, loss: 0.075083
   Number of active neurons: 10
 >> iter 11000, loss: 0.035476
 >> iter 12000, loss: 0.085392
 >> iter 13000, loss: 0.040153
 >> iter 14000, loss: 0.022689
 >> iter 15000, loss: 0.025008
 >> iter 16000, loss: 0.032900
 >> iter 17000, loss: 0.033184
 >> iter 18000, loss: 0.045718
 >> iter 19000, loss: 0.043770
 >> iter 20000, loss: 0.029356
   Number of active neurons: 10
 >> iter 21000, loss: 0.021359
 >> iter 22000, loss: 0.087539
 >> iter 23000, loss: 0.066925
 >> iter 24000, loss: 0.029913
 >> iter 25000, loss: 0.013994
 >> iter 26000, loss: 0.027895
 >> iter 27000, loss: 0.017750
 >> iter 28000, loss: 0.013289
 >> iter 29000, loss: 0.007444
 >> iter 30000, loss: 0.045406
   Number of active neurons: 10
 >> iter 31000, loss: 0.129392
 >> iter 32000, loss: 0.072484
 >> iter 33000, loss: 0.030003
 >> iter 34000, loss: 0.013466
 >> iter 35000, loss: 0.007218
 >> iter 36000, loss: 0.018901
 >> iter 37000, loss: 0.009162
 >> iter 38000, loss: 0.006310
 >> iter 39000, loss: 0.090740
 >> iter 40000, loss: 0.052017
   Number of active neurons: 10
 >> iter 41000, loss: 0.072590
 >> iter 42000, loss: 0.030698
 >> iter 43000, loss: 0.013815
 >> iter 44000, loss: 0.007962
 >> iter 45000, loss: 0.005297
 >> iter 46000, loss: 0.003960
 >> iter 47000, loss: 0.003571
 >> iter 48000, loss: 0.044546
 >> iter 49000, loss: 0.081792
 >> iter 50000, loss: 0.032777
   Number of active neurons: 10
 >> iter 51000, loss: 0.024311
 >> iter 52000, loss: 0.078353
 >> iter 53000, loss: 0.073863
 >> iter 54000, loss: 0.042717
 >> iter 55000, loss: 0.036010
 >> iter 56000, loss: 0.015574
 >> iter 57000, loss: 0.067642
 >> iter 58000, loss: 0.034035
 >> iter 59000, loss: 0.015057
 >> iter 60000, loss: 0.007636
   Number of active neurons: 10
 >> iter 61000, loss: 0.027653
 >> iter 62000, loss: 0.020697
 >> iter 63000, loss: 0.020594
 >> iter 64000, loss: 0.010248
 >> iter 65000, loss: 0.005717
 >> iter 66000, loss: 0.003816
 >> iter 67000, loss: 0.003075
 >> iter 68000, loss: 0.002821
 >> iter 69000, loss: 0.002510
 >> iter 70000, loss: 0.012632
   Number of active neurons: 10
 >> iter 71000, loss: 0.006657
 >> iter 72000, loss: 0.003789
 >> iter 73000, loss: 0.002647
 >> iter 74000, loss: 0.002178
 >> iter 75000, loss: 0.001883
 >> iter 76000, loss: 0.001749
 >> iter 77000, loss: 0.001664
 >> iter 78000, loss: 0.001565
 >> iter 79000, loss: 0.001579
 >> iter 80000, loss: 0.001401
   Number of active neurons: 10
 >> iter 81000, loss: 0.001373
 >> iter 82000, loss: 0.001350
 >> iter 83000, loss: 0.005412
 >> iter 84000, loss: 0.003073
 >> iter 85000, loss: 0.001973
 >> iter 86000, loss: 0.019620
 >> iter 87000, loss: 0.008042
 >> iter 88000, loss: 0.012467
 >> iter 89000, loss: 0.010771
 >> iter 90000, loss: 0.004786
   Number of active neurons: 10
 >> iter 91000, loss: 0.050016
 >> iter 92000, loss: 0.033311
 >> iter 93000, loss: 0.039465
 >> iter 94000, loss: 0.015571
 >> iter 95000, loss: 0.006719
 >> iter 96000, loss: 0.003440
 >> iter 97000, loss: 0.039299
 >> iter 98000, loss: 0.025657
 >> iter 99000, loss: 0.010771
 >> iter 100000, loss: 0.005445
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 16.810178
 >> iter 2000, loss: 9.760624
 >> iter 3000, loss: 6.562699
 >> iter 4000, loss: 4.597218
 >> iter 5000, loss: 2.735607
 >> iter 6000, loss: 1.668287
 >> iter 7000, loss: 0.961101
 >> iter 8000, loss: 0.746844
 >> iter 9000, loss: 0.404202
 >> iter 10000, loss: 0.257658
   Number of active neurons: 10
 >> iter 11000, loss: 0.176121
 >> iter 12000, loss: 0.145359
 >> iter 13000, loss: 0.180891
 >> iter 14000, loss: 0.172574
 >> iter 15000, loss: 0.147999
 >> iter 16000, loss: 0.129790
 >> iter 17000, loss: 0.153928
 >> iter 18000, loss: 0.135606
 >> iter 19000, loss: 0.141757
 >> iter 20000, loss: 0.091099
   Number of active neurons: 10
 >> iter 21000, loss: 0.092073
 >> iter 22000, loss: 0.083672
 >> iter 23000, loss: 0.136871
 >> iter 24000, loss: 0.123523
 >> iter 25000, loss: 0.056585
 >> iter 26000, loss: 0.069181
 >> iter 27000, loss: 0.102168
 >> iter 28000, loss: 0.104072
 >> iter 29000, loss: 0.112801
 >> iter 30000, loss: 0.058904
   Number of active neurons: 10
 >> iter 31000, loss: 0.066534
 >> iter 32000, loss: 0.032527
 >> iter 33000, loss: 0.047821
 >> iter 34000, loss: 0.052081
 >> iter 35000, loss: 0.061565
 >> iter 36000, loss: 0.065513
 >> iter 37000, loss: 0.031525
 >> iter 38000, loss: 0.070561
 >> iter 39000, loss: 0.047200
 >> iter 40000, loss: 0.023024
   Number of active neurons: 10
 >> iter 41000, loss: 0.023352
 >> iter 42000, loss: 0.015076
 >> iter 43000, loss: 0.058711
 >> iter 44000, loss: 0.035979
 >> iter 45000, loss: 0.017519
 >> iter 46000, loss: 0.011847
 >> iter 47000, loss: 0.007990
 >> iter 48000, loss: 0.052914
 >> iter 49000, loss: 0.078285
 >> iter 50000, loss: 0.067348
   Number of active neurons: 10
 >> iter 51000, loss: 0.030881
 >> iter 52000, loss: 0.041307
 >> iter 53000, loss: 0.050899
 >> iter 54000, loss: 0.026391
 >> iter 55000, loss: 0.098184
 >> iter 56000, loss: 0.080398
 >> iter 57000, loss: 0.034056
 >> iter 58000, loss: 0.040705
 >> iter 59000, loss: 0.022029
 >> iter 60000, loss: 0.011356
   Number of active neurons: 10
 >> iter 61000, loss: 0.007336
 >> iter 62000, loss: 0.005585
 >> iter 63000, loss: 0.046685
 >> iter 64000, loss: 0.026290
 >> iter 65000, loss: 0.065305
 >> iter 66000, loss: 0.051700
 >> iter 67000, loss: 0.022004
 >> iter 68000, loss: 0.010870
 >> iter 69000, loss: 0.006446
 >> iter 70000, loss: 0.005135
   Number of active neurons: 10
 >> iter 71000, loss: 0.047355
 >> iter 72000, loss: 0.045027
 >> iter 73000, loss: 0.033892
 >> iter 74000, loss: 0.079734
 >> iter 75000, loss: 0.055330
 >> iter 76000, loss: 0.024147
 >> iter 77000, loss: 0.012248
 >> iter 78000, loss: 0.008411
 >> iter 79000, loss: 0.006023
 >> iter 80000, loss: 0.011419
   Number of active neurons: 10
 >> iter 81000, loss: 0.086298
 >> iter 82000, loss: 0.045657
 >> iter 83000, loss: 0.019773
 >> iter 84000, loss: 0.010041
 >> iter 85000, loss: 0.006111
 >> iter 86000, loss: 0.004523
 >> iter 87000, loss: 0.036531
 >> iter 88000, loss: 0.016785
 >> iter 89000, loss: 0.055356
 >> iter 90000, loss: 0.058927
   Number of active neurons: 10
 >> iter 91000, loss: 0.036952
 >> iter 92000, loss: 0.089450
 >> iter 93000, loss: 0.046609
 >> iter 94000, loss: 0.019994
 >> iter 95000, loss: 0.025845
 >> iter 96000, loss: 0.083732
 >> iter 97000, loss: 0.034082
 >> iter 98000, loss: 0.033090
 >> iter 99000, loss: 0.029586
 >> iter 100000, loss: 0.023467
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.386414
 >> iter 2000, loss: 9.880595
 >> iter 3000, loss: 5.988442
 >> iter 4000, loss: 2.704036
 >> iter 5000, loss: 1.201312
 >> iter 6000, loss: 0.526059
 >> iter 7000, loss: 0.269426
 >> iter 8000, loss: 0.131895
 >> iter 9000, loss: 0.101958
 >> iter 10000, loss: 0.061072
   Number of active neurons: 10
 >> iter 11000, loss: 0.080894
 >> iter 12000, loss: 0.075361
 >> iter 13000, loss: 0.063898
 >> iter 14000, loss: 0.089057
 >> iter 15000, loss: 0.116047
 >> iter 16000, loss: 0.061343
 >> iter 17000, loss: 0.042180
 >> iter 18000, loss: 0.072944
 >> iter 19000, loss: 0.137563
 >> iter 20000, loss: 0.066715
   Number of active neurons: 10
 >> iter 21000, loss: 0.113979
 >> iter 22000, loss: 0.049212
 >> iter 23000, loss: 0.092931
 >> iter 24000, loss: 0.083295
 >> iter 25000, loss: 0.037452
 >> iter 26000, loss: 0.035533
 >> iter 27000, loss: 0.035226
 >> iter 28000, loss: 0.027088
 >> iter 29000, loss: 0.025274
 >> iter 30000, loss: 0.013020
   Number of active neurons: 10
 >> iter 31000, loss: 0.007950
 >> iter 32000, loss: 0.006807
 >> iter 33000, loss: 0.005591
 >> iter 34000, loss: 0.004591
 >> iter 35000, loss: 0.004648
 >> iter 36000, loss: 0.023744
 >> iter 37000, loss: 0.033840
 >> iter 38000, loss: 0.024372
 >> iter 39000, loss: 0.074843
 >> iter 40000, loss: 0.043330
   Number of active neurons: 10
 >> iter 41000, loss: 0.077891
 >> iter 42000, loss: 0.037106
 >> iter 43000, loss: 0.020029
 >> iter 44000, loss: 0.035087
 >> iter 45000, loss: 0.040124
 >> iter 46000, loss: 0.017488
 >> iter 47000, loss: 0.083298
 >> iter 48000, loss: 0.046434
 >> iter 49000, loss: 0.019997
 >> iter 50000, loss: 0.133190
   Number of active neurons: 10
 >> iter 51000, loss: 0.053271
 >> iter 52000, loss: 0.142048
 >> iter 53000, loss: 0.087894
 >> iter 54000, loss: 0.127290
 >> iter 55000, loss: 0.069688
 >> iter 56000, loss: 0.029862
 >> iter 57000, loss: 0.025029
 >> iter 58000, loss: 0.053623
 >> iter 59000, loss: 0.023272
 >> iter 60000, loss: 0.011382
   Number of active neurons: 10
 >> iter 61000, loss: 0.006789
 >> iter 62000, loss: 0.004850
 >> iter 63000, loss: 0.004686
 >> iter 64000, loss: 0.019108
 >> iter 65000, loss: 0.010635
 >> iter 66000, loss: 0.006073
 >> iter 67000, loss: 0.004403
 >> iter 68000, loss: 0.003506
 >> iter 69000, loss: 0.002998
 >> iter 70000, loss: 0.011123
   Number of active neurons: 10
 >> iter 71000, loss: 0.005774
 >> iter 72000, loss: 0.003616
 >> iter 73000, loss: 0.002837
 >> iter 74000, loss: 0.002502
 >> iter 75000, loss: 0.002288
 >> iter 76000, loss: 0.004634
 >> iter 77000, loss: 0.003162
 >> iter 78000, loss: 0.002376
 >> iter 79000, loss: 0.002039
 >> iter 80000, loss: 0.057643
   Number of active neurons: 10
 >> iter 81000, loss: 0.091664
 >> iter 82000, loss: 0.036461
 >> iter 83000, loss: 0.015228
 >> iter 84000, loss: 0.007206
 >> iter 85000, loss: 0.004127
 >> iter 86000, loss: 0.024971
 >> iter 87000, loss: 0.010656
 >> iter 88000, loss: 0.005291
 >> iter 89000, loss: 0.036721
 >> iter 90000, loss: 0.015052
   Number of active neurons: 10
 >> iter 91000, loss: 0.014251
 >> iter 92000, loss: 0.006608
 >> iter 93000, loss: 0.003779
 >> iter 94000, loss: 0.002705
 >> iter 95000, loss: 0.015666
 >> iter 96000, loss: 0.007022
 >> iter 97000, loss: 0.003738
 >> iter 98000, loss: 0.002552
 >> iter 99000, loss: 0.002002
 >> iter 100000, loss: 0.001749
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

