 > Problema: tomita2nueva
 > Args:
   - Hidden size: 6
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.376725
 >> iter 2000, loss: 4.363985
 >> iter 3000, loss: 1.716042
 >> iter 4000, loss: 0.683693
 >> iter 5000, loss: 0.307054
 >> iter 6000, loss: 0.149850
 >> iter 7000, loss: 0.091574
 >> iter 8000, loss: 0.073698
 >> iter 9000, loss: 0.063566
 >> iter 10000, loss: 0.076859
   Number of active neurons: 5
 >> iter 11000, loss: 0.085774
 >> iter 12000, loss: 0.062062
 >> iter 13000, loss: 0.040692
 >> iter 14000, loss: 0.042660
 >> iter 15000, loss: 0.062049
 >> iter 16000, loss: 0.048892
 >> iter 17000, loss: 0.056770
 >> iter 18000, loss: 0.058500
 >> iter 19000, loss: 0.078083
 >> iter 20000, loss: 0.076608
   Number of active neurons: 5
 >> iter 21000, loss: 0.061698
 >> iter 22000, loss: 0.059852
 >> iter 23000, loss: 0.058202
 >> iter 24000, loss: 0.060469
 >> iter 25000, loss: 0.046241
 >> iter 26000, loss: 0.044041
 >> iter 27000, loss: 0.043830
 >> iter 28000, loss: 0.051399
 >> iter 29000, loss: 0.069440
 >> iter 30000, loss: 0.058474
   Number of active neurons: 4
 >> iter 31000, loss: 0.072547
 >> iter 32000, loss: 0.048171
 >> iter 33000, loss: 0.056372
 >> iter 34000, loss: 0.051683
 >> iter 35000, loss: 0.054294
 >> iter 36000, loss: 0.065279
 >> iter 37000, loss: 0.056291
 >> iter 38000, loss: 0.042687
 >> iter 39000, loss: 0.035284
 >> iter 40000, loss: 0.042528
   Number of active neurons: 3
 >> iter 41000, loss: 0.082374
 >> iter 42000, loss: 0.061655
 >> iter 43000, loss: 0.052287
 >> iter 44000, loss: 0.050276
 >> iter 45000, loss: 0.055223
 >> iter 46000, loss: 0.048974
 >> iter 47000, loss: 0.041703
 >> iter 48000, loss: 0.039642
 >> iter 49000, loss: 0.042430
 >> iter 50000, loss: 0.033747
   Number of active neurons: 2
 >> iter 51000, loss: 0.048652
 >> iter 52000, loss: 0.061162
 >> iter 53000, loss: 0.048126
 >> iter 54000, loss: 0.041144
 >> iter 55000, loss: 0.048653
 >> iter 56000, loss: 0.034095
 >> iter 57000, loss: 0.039874
 >> iter 58000, loss: 0.051787
 >> iter 59000, loss: 0.055764
 >> iter 60000, loss: 0.051304
   Number of active neurons: 2
 >> iter 61000, loss: 0.048776
 >> iter 62000, loss: 0.048186
 >> iter 63000, loss: 0.050754
 >> iter 64000, loss: 0.064444
 >> iter 65000, loss: 0.055891
 >> iter 66000, loss: 0.045218
 >> iter 67000, loss: 0.044815
 >> iter 68000, loss: 0.040500
 >> iter 69000, loss: 0.043986
 >> iter 70000, loss: 0.051612
   Number of active neurons: 2
 >> iter 71000, loss: 0.042501
 >> iter 72000, loss: 0.037237
 >> iter 73000, loss: 0.081127
 >> iter 74000, loss: 0.049952
 >> iter 75000, loss: 0.036171
 >> iter 76000, loss: 0.065232
 >> iter 77000, loss: 0.055123
 >> iter 78000, loss: 0.051112
 >> iter 79000, loss: 0.038619
 >> iter 80000, loss: 0.034116
   Number of active neurons: 2
 >> iter 81000, loss: 0.042034
 >> iter 82000, loss: 0.041577
 >> iter 83000, loss: 0.086973
 >> iter 84000, loss: 0.075446
 >> iter 85000, loss: 0.065916
 >> iter 86000, loss: 0.055663
 >> iter 87000, loss: 0.052616
 >> iter 88000, loss: 0.040260
 >> iter 89000, loss: 0.049657
 >> iter 90000, loss: 0.058191
   Number of active neurons: 2
 >> iter 91000, loss: 0.061910
 >> iter 92000, loss: 0.061473
 >> iter 93000, loss: 0.039373
 >> iter 94000, loss: 0.051722
 >> iter 95000, loss: 0.039069
 >> iter 96000, loss: 0.046837
 >> iter 97000, loss: 0.039837
 >> iter 98000, loss: 0.030367
 >> iter 99000, loss: 0.035025
 >> iter 100000, loss: 0.045283
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.355936
 >> iter 2000, loss: 4.371642
 >> iter 3000, loss: 1.669859
 >> iter 4000, loss: 0.662271
 >> iter 5000, loss: 0.283734
 >> iter 6000, loss: 0.147985
 >> iter 7000, loss: 0.104321
 >> iter 8000, loss: 0.078596
 >> iter 9000, loss: 0.061372
 >> iter 10000, loss: 0.042794
   Number of active neurons: 4
 >> iter 11000, loss: 0.046401
 >> iter 12000, loss: 0.052899
 >> iter 13000, loss: 0.063790
 >> iter 14000, loss: 0.053935
 >> iter 15000, loss: 0.039123
 >> iter 16000, loss: 0.047189
 >> iter 17000, loss: 0.067972
 >> iter 18000, loss: 0.069919
 >> iter 19000, loss: 0.053906
 >> iter 20000, loss: 0.058245
   Number of active neurons: 4
 >> iter 21000, loss: 0.053653
 >> iter 22000, loss: 0.046908
 >> iter 23000, loss: 0.036617
 >> iter 24000, loss: 0.061941
 >> iter 25000, loss: 0.068089
 >> iter 26000, loss: 0.067454
 >> iter 27000, loss: 0.067108
 >> iter 28000, loss: 0.062346
 >> iter 29000, loss: 0.056312
 >> iter 30000, loss: 0.053182
   Number of active neurons: 4
 >> iter 31000, loss: 0.036927
 >> iter 32000, loss: 0.056922
 >> iter 33000, loss: 0.048636
 >> iter 34000, loss: 0.063768
 >> iter 35000, loss: 0.042306
 >> iter 36000, loss: 0.041727
 >> iter 37000, loss: 0.064057
 >> iter 38000, loss: 0.062468
 >> iter 39000, loss: 0.043557
 >> iter 40000, loss: 0.041417
   Number of active neurons: 4
 >> iter 41000, loss: 0.041336
 >> iter 42000, loss: 0.046982
 >> iter 43000, loss: 0.065830
 >> iter 44000, loss: 0.050019
 >> iter 45000, loss: 0.051229
 >> iter 46000, loss: 0.053189
 >> iter 47000, loss: 0.056765
 >> iter 48000, loss: 0.064875
 >> iter 49000, loss: 0.050086
 >> iter 50000, loss: 0.055129
   Number of active neurons: 4
 >> iter 51000, loss: 0.046016
 >> iter 52000, loss: 0.040214
 >> iter 53000, loss: 0.053004
 >> iter 54000, loss: 0.050280
 >> iter 55000, loss: 0.058968
 >> iter 56000, loss: 0.072972
 >> iter 57000, loss: 0.048072
 >> iter 58000, loss: 0.067647
 >> iter 59000, loss: 0.045694
 >> iter 60000, loss: 0.053962
   Number of active neurons: 4
 >> iter 61000, loss: 0.058605
 >> iter 62000, loss: 0.039416
 >> iter 63000, loss: 0.034706
 >> iter 64000, loss: 0.062315
 >> iter 65000, loss: 0.043980
 >> iter 66000, loss: 0.041770
 >> iter 67000, loss: 0.040939
 >> iter 68000, loss: 0.052761
 >> iter 69000, loss: 0.040553
 >> iter 70000, loss: 0.038832
   Number of active neurons: 4
 >> iter 71000, loss: 0.041452
 >> iter 72000, loss: 0.042036
 >> iter 73000, loss: 0.047542
 >> iter 74000, loss: 0.039319
 >> iter 75000, loss: 0.044946
 >> iter 76000, loss: 0.047250
 >> iter 77000, loss: 0.050725
 >> iter 78000, loss: 0.076194
 >> iter 79000, loss: 0.064462
 >> iter 80000, loss: 0.054224
   Number of active neurons: 4
 >> iter 81000, loss: 0.054203
 >> iter 82000, loss: 0.049865
 >> iter 83000, loss: 0.047613
 >> iter 84000, loss: 0.043530
 >> iter 85000, loss: 0.047755
 >> iter 86000, loss: 0.053075
 >> iter 87000, loss: 0.052514
 >> iter 88000, loss: 0.043531
 >> iter 89000, loss: 0.036717
 >> iter 90000, loss: 0.053063
   Number of active neurons: 4
 >> iter 91000, loss: 0.078266
 >> iter 92000, loss: 0.052085
 >> iter 93000, loss: 0.042467
 >> iter 94000, loss: 0.048576
 >> iter 95000, loss: 0.042422
 >> iter 96000, loss: 0.048506
 >> iter 97000, loss: 0.051034
 >> iter 98000, loss: 0.033901
 >> iter 99000, loss: 0.052420
 >> iter 100000, loss: 0.049262
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.381748
 >> iter 2000, loss: 4.405647
 >> iter 3000, loss: 1.728026
 >> iter 4000, loss: 0.695922
 >> iter 5000, loss: 0.308724
 >> iter 6000, loss: 0.148001
 >> iter 7000, loss: 0.097283
 >> iter 8000, loss: 0.083804
 >> iter 9000, loss: 0.084124
 >> iter 10000, loss: 0.074588
   Number of active neurons: 6
 >> iter 11000, loss: 0.060607
 >> iter 12000, loss: 0.044279
 >> iter 13000, loss: 0.049138
 >> iter 14000, loss: 0.057104
 >> iter 15000, loss: 0.061368
 >> iter 16000, loss: 0.067395
 >> iter 17000, loss: 0.058196
 >> iter 18000, loss: 0.047688
 >> iter 19000, loss: 0.057585
 >> iter 20000, loss: 0.053882
   Number of active neurons: 6
 >> iter 21000, loss: 0.062158
 >> iter 22000, loss: 0.046062
 >> iter 23000, loss: 0.045375
 >> iter 24000, loss: 0.051236
 >> iter 25000, loss: 0.041578
 >> iter 26000, loss: 0.034497
 >> iter 27000, loss: 0.037605
 >> iter 28000, loss: 0.040852
 >> iter 29000, loss: 0.061489
 >> iter 30000, loss: 0.064174
   Number of active neurons: 6
 >> iter 31000, loss: 0.049567
 >> iter 32000, loss: 0.061142
 >> iter 33000, loss: 0.063040
 >> iter 34000, loss: 0.057008
 >> iter 35000, loss: 0.038254
 >> iter 36000, loss: 0.038925
 >> iter 37000, loss: 0.048775
 >> iter 38000, loss: 0.062729
 >> iter 39000, loss: 0.057825
 >> iter 40000, loss: 0.053800
   Number of active neurons: 5
 >> iter 41000, loss: 0.073037
 >> iter 42000, loss: 0.060920
 >> iter 43000, loss: 0.049275
 >> iter 44000, loss: 0.045307
 >> iter 45000, loss: 0.047802
 >> iter 46000, loss: 0.044374
 >> iter 47000, loss: 0.043813
 >> iter 48000, loss: 0.043639
 >> iter 49000, loss: 0.055569
 >> iter 50000, loss: 0.046596
   Number of active neurons: 5
 >> iter 51000, loss: 0.041117
 >> iter 52000, loss: 0.050810
 >> iter 53000, loss: 0.040478
 >> iter 54000, loss: 0.043963
 >> iter 55000, loss: 0.043248
 >> iter 56000, loss: 0.044946
 >> iter 57000, loss: 0.059377
 >> iter 58000, loss: 0.060189
 >> iter 59000, loss: 0.049661
 >> iter 60000, loss: 0.044697
   Number of active neurons: 5
 >> iter 61000, loss: 0.040801
 >> iter 62000, loss: 0.058833
 >> iter 63000, loss: 0.056262
 >> iter 64000, loss: 0.049923
 >> iter 65000, loss: 0.067113
 >> iter 66000, loss: 0.052917
 >> iter 67000, loss: 0.055962
 >> iter 68000, loss: 0.043725
 >> iter 69000, loss: 0.060559
 >> iter 70000, loss: 0.054214
   Number of active neurons: 4
 >> iter 71000, loss: 0.056110
 >> iter 72000, loss: 0.057363
 >> iter 73000, loss: 0.075064
 >> iter 74000, loss: 0.066509
 >> iter 75000, loss: 0.054245
 >> iter 76000, loss: 0.044845
 >> iter 77000, loss: 0.068765
 >> iter 78000, loss: 0.060903
 >> iter 79000, loss: 0.053623
 >> iter 80000, loss: 0.048310
   Number of active neurons: 4
 >> iter 81000, loss: 0.044231
 >> iter 82000, loss: 0.045088
 >> iter 83000, loss: 0.050179
 >> iter 84000, loss: 0.055833
 >> iter 85000, loss: 0.061170
 >> iter 86000, loss: 0.066677
 >> iter 87000, loss: 0.065286
 >> iter 88000, loss: 0.055428
 >> iter 89000, loss: 0.059985
 >> iter 90000, loss: 0.048639
   Number of active neurons: 4
 >> iter 91000, loss: 0.050172
 >> iter 92000, loss: 0.050759
 >> iter 93000, loss: 0.042533
 >> iter 94000, loss: 0.042261
 >> iter 95000, loss: 0.062955
 >> iter 96000, loss: 0.051089
 >> iter 97000, loss: 0.051429
 >> iter 98000, loss: 0.053840
 >> iter 99000, loss: 0.052575
 >> iter 100000, loss: 0.072547
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.282863
 >> iter 2000, loss: 4.337802
 >> iter 3000, loss: 1.722963
 >> iter 4000, loss: 0.687042
 >> iter 5000, loss: 0.329864
 >> iter 6000, loss: 0.160915
 >> iter 7000, loss: 0.095722
 >> iter 8000, loss: 0.085740
 >> iter 9000, loss: 0.084895
 >> iter 10000, loss: 0.071879
   Number of active neurons: 6
 >> iter 11000, loss: 0.049062
 >> iter 12000, loss: 0.058785
 >> iter 13000, loss: 0.059883
 >> iter 14000, loss: 0.049649
 >> iter 15000, loss: 0.064080
 >> iter 16000, loss: 0.050213
 >> iter 17000, loss: 0.057816
 >> iter 18000, loss: 0.051533
 >> iter 19000, loss: 0.066867
 >> iter 20000, loss: 0.080912
   Number of active neurons: 5
 >> iter 21000, loss: 0.060648
 >> iter 22000, loss: 0.060020
 >> iter 23000, loss: 0.040861
 >> iter 24000, loss: 0.037754
 >> iter 25000, loss: 0.041249
 >> iter 26000, loss: 0.049850
 >> iter 27000, loss: 0.056234
 >> iter 28000, loss: 0.051336
 >> iter 29000, loss: 0.044951
 >> iter 30000, loss: 0.040376
   Number of active neurons: 4
 >> iter 31000, loss: 0.046709
 >> iter 32000, loss: 0.040192
 >> iter 33000, loss: 0.040622
 >> iter 34000, loss: 0.061093
 >> iter 35000, loss: 0.045388
 >> iter 36000, loss: 0.044321
 >> iter 37000, loss: 0.047163
 >> iter 38000, loss: 0.034583
 >> iter 39000, loss: 0.054547
 >> iter 40000, loss: 0.036355
   Number of active neurons: 4
 >> iter 41000, loss: 0.051239
 >> iter 42000, loss: 0.045664
 >> iter 43000, loss: 0.050823
 >> iter 44000, loss: 0.061671
 >> iter 45000, loss: 0.061288
 >> iter 46000, loss: 0.048738
 >> iter 47000, loss: 0.044669
 >> iter 48000, loss: 0.039564
 >> iter 49000, loss: 0.062183
 >> iter 50000, loss: 0.045141
   Number of active neurons: 4
 >> iter 51000, loss: 0.071201
 >> iter 52000, loss: 0.060586
 >> iter 53000, loss: 0.047214
 >> iter 54000, loss: 0.045625
 >> iter 55000, loss: 0.050522
 >> iter 56000, loss: 0.055489
 >> iter 57000, loss: 0.051395
 >> iter 58000, loss: 0.038612
 >> iter 59000, loss: 0.060387
 >> iter 60000, loss: 0.064477
   Number of active neurons: 4
 >> iter 61000, loss: 0.057615
 >> iter 62000, loss: 0.043796
 >> iter 63000, loss: 0.051837
 >> iter 64000, loss: 0.058039
 >> iter 65000, loss: 0.047328
 >> iter 66000, loss: 0.045911
 >> iter 67000, loss: 0.049873
 >> iter 68000, loss: 0.049797
 >> iter 69000, loss: 0.040350
 >> iter 70000, loss: 0.036648
   Number of active neurons: 4
 >> iter 71000, loss: 0.057095
 >> iter 72000, loss: 0.054233
 >> iter 73000, loss: 0.052212
 >> iter 74000, loss: 0.041200
 >> iter 75000, loss: 0.036718
 >> iter 76000, loss: 0.049218
 >> iter 77000, loss: 0.064658
 >> iter 78000, loss: 0.048426
 >> iter 79000, loss: 0.050174
 >> iter 80000, loss: 0.046461
   Number of active neurons: 3
 >> iter 81000, loss: 0.046324
 >> iter 82000, loss: 0.039945
 >> iter 83000, loss: 0.050702
 >> iter 84000, loss: 0.054144
 >> iter 85000, loss: 0.047946
 >> iter 86000, loss: 0.047712
 >> iter 87000, loss: 0.031306
 >> iter 88000, loss: 0.036894
 >> iter 89000, loss: 0.046600
 >> iter 90000, loss: 0.038169
   Number of active neurons: 2
 >> iter 91000, loss: 0.057975
 >> iter 92000, loss: 0.064129
 >> iter 93000, loss: 0.060689
 >> iter 94000, loss: 0.045487
 >> iter 95000, loss: 0.058127
 >> iter 96000, loss: 0.044764
 >> iter 97000, loss: 0.061572
 >> iter 98000, loss: 0.059018
 >> iter 99000, loss: 0.045098
 >> iter 100000, loss: 0.041111
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.503561
 >> iter 2000, loss: 4.565646
 >> iter 3000, loss: 1.843007
 >> iter 4000, loss: 0.755525
 >> iter 5000, loss: 0.372748
 >> iter 6000, loss: 0.204327
 >> iter 7000, loss: 0.113687
 >> iter 8000, loss: 0.089520
 >> iter 9000, loss: 0.078797
 >> iter 10000, loss: 0.071271
   Number of active neurons: 6
 >> iter 11000, loss: 0.093147
 >> iter 12000, loss: 0.087096
 >> iter 13000, loss: 0.061406
 >> iter 14000, loss: 0.064347
 >> iter 15000, loss: 0.056636
 >> iter 16000, loss: 0.060842
 >> iter 17000, loss: 0.057468
 >> iter 18000, loss: 0.074378
 >> iter 19000, loss: 0.064031
 >> iter 20000, loss: 0.045209
   Number of active neurons: 5
 >> iter 21000, loss: 0.050786
 >> iter 22000, loss: 0.055099
 >> iter 23000, loss: 0.055132
 >> iter 24000, loss: 0.046537
 >> iter 25000, loss: 0.044891
 >> iter 26000, loss: 0.047863
 >> iter 27000, loss: 0.066019
 >> iter 28000, loss: 0.060132
 >> iter 29000, loss: 0.060331
 >> iter 30000, loss: 0.043091
   Number of active neurons: 5
 >> iter 31000, loss: 0.047969
 >> iter 32000, loss: 0.036736
 >> iter 33000, loss: 0.040991
 >> iter 34000, loss: 0.057607
 >> iter 35000, loss: 0.059599
 >> iter 36000, loss: 0.070690
 >> iter 37000, loss: 0.052224
 >> iter 38000, loss: 0.049142
 >> iter 39000, loss: 0.048888
 >> iter 40000, loss: 0.051450
   Number of active neurons: 5
 >> iter 41000, loss: 0.044903
 >> iter 42000, loss: 0.033484
 >> iter 43000, loss: 0.044367
 >> iter 44000, loss: 0.066887
 >> iter 45000, loss: 0.044412
 >> iter 46000, loss: 0.050182
 >> iter 47000, loss: 0.043940
 >> iter 48000, loss: 0.040806
 >> iter 49000, loss: 0.035477
 >> iter 50000, loss: 0.045375
   Number of active neurons: 4
 >> iter 51000, loss: 0.041360
 >> iter 52000, loss: 0.040787
 >> iter 53000, loss: 0.044426
 >> iter 54000, loss: 0.055467
 >> iter 55000, loss: 0.045554
 >> iter 56000, loss: 0.053639
 >> iter 57000, loss: 0.053889
 >> iter 58000, loss: 0.070454
 >> iter 59000, loss: 0.051461
 >> iter 60000, loss: 0.042524
   Number of active neurons: 4
 >> iter 61000, loss: 0.046936
 >> iter 62000, loss: 0.065654
 >> iter 63000, loss: 0.077717
 >> iter 64000, loss: 0.053655
 >> iter 65000, loss: 0.047760
 >> iter 66000, loss: 0.038628
 >> iter 67000, loss: 0.046690
 >> iter 68000, loss: 0.042075
 >> iter 69000, loss: 0.038310
 >> iter 70000, loss: 0.044193
   Number of active neurons: 4
 >> iter 71000, loss: 0.067463
 >> iter 72000, loss: 0.051167
 >> iter 73000, loss: 0.042441
 >> iter 74000, loss: 0.041741
 >> iter 75000, loss: 0.053635
 >> iter 76000, loss: 0.039875
 >> iter 77000, loss: 0.043003
 >> iter 78000, loss: 0.033753
 >> iter 79000, loss: 0.063617
 >> iter 80000, loss: 0.076634
   Number of active neurons: 4
 >> iter 81000, loss: 0.051515
 >> iter 82000, loss: 0.041954
 >> iter 83000, loss: 0.041657
 >> iter 84000, loss: 0.040001
 >> iter 85000, loss: 0.048978
 >> iter 86000, loss: 0.056451
 >> iter 87000, loss: 0.049853
 >> iter 88000, loss: 0.044767
 >> iter 89000, loss: 0.051110
 >> iter 90000, loss: 0.040482
   Number of active neurons: 3
 >> iter 91000, loss: 0.052509
 >> iter 92000, loss: 0.051665
 >> iter 93000, loss: 0.040391
 >> iter 94000, loss: 0.037784
 >> iter 95000, loss: 0.047750
 >> iter 96000, loss: 0.054372
 >> iter 97000, loss: 0.035856
 >> iter 98000, loss: 0.052631
 >> iter 99000, loss: 0.051428
 >> iter 100000, loss: 0.041468
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.409750
 >> iter 2000, loss: 4.402407
 >> iter 3000, loss: 1.695902
 >> iter 4000, loss: 0.688673
 >> iter 5000, loss: 0.298914
 >> iter 6000, loss: 0.147592
 >> iter 7000, loss: 0.104777
 >> iter 8000, loss: 0.109593
 >> iter 9000, loss: 0.081742
 >> iter 10000, loss: 0.074095
   Number of active neurons: 6
 >> iter 11000, loss: 0.060481
 >> iter 12000, loss: 0.067128
 >> iter 13000, loss: 0.057718
 >> iter 14000, loss: 0.058172
 >> iter 15000, loss: 0.064308
 >> iter 16000, loss: 0.079856
 >> iter 17000, loss: 0.070364
 >> iter 18000, loss: 0.075033
 >> iter 19000, loss: 0.056488
 >> iter 20000, loss: 0.048863
   Number of active neurons: 6
 >> iter 21000, loss: 0.043038
 >> iter 22000, loss: 0.045954
 >> iter 23000, loss: 0.038374
 >> iter 24000, loss: 0.046153
 >> iter 25000, loss: 0.051596
 >> iter 26000, loss: 0.062742
 >> iter 27000, loss: 0.071429
 >> iter 28000, loss: 0.056080
 >> iter 29000, loss: 0.077224
 >> iter 30000, loss: 0.071047
   Number of active neurons: 5
 >> iter 31000, loss: 0.072258
 >> iter 32000, loss: 0.066082
 >> iter 33000, loss: 0.047505
 >> iter 34000, loss: 0.053990
 >> iter 35000, loss: 0.059009
 >> iter 36000, loss: 0.064870
 >> iter 37000, loss: 0.060769
 >> iter 38000, loss: 0.050986
 >> iter 39000, loss: 0.052743
 >> iter 40000, loss: 0.047901
   Number of active neurons: 4
 >> iter 41000, loss: 0.062315
 >> iter 42000, loss: 0.070722
 >> iter 43000, loss: 0.053918
 >> iter 44000, loss: 0.058760
 >> iter 45000, loss: 0.044244
 >> iter 46000, loss: 0.056181
 >> iter 47000, loss: 0.057556
 >> iter 48000, loss: 0.067126
 >> iter 49000, loss: 0.048540
 >> iter 50000, loss: 0.051910
   Number of active neurons: 4
 >> iter 51000, loss: 0.057662
 >> iter 52000, loss: 0.055282
 >> iter 53000, loss: 0.048897
 >> iter 54000, loss: 0.041821
 >> iter 55000, loss: 0.047695
 >> iter 56000, loss: 0.040312
 >> iter 57000, loss: 0.042086
 >> iter 58000, loss: 0.069086
 >> iter 59000, loss: 0.061597
 >> iter 60000, loss: 0.046708
   Number of active neurons: 4
 >> iter 61000, loss: 0.060813
 >> iter 62000, loss: 0.043369
 >> iter 63000, loss: 0.048150
 >> iter 64000, loss: 0.037219
 >> iter 65000, loss: 0.045061
 >> iter 66000, loss: 0.045105
 >> iter 67000, loss: 0.037048
 >> iter 68000, loss: 0.035434
 >> iter 69000, loss: 0.035584
 >> iter 70000, loss: 0.038243
   Number of active neurons: 3
 >> iter 71000, loss: 0.044091
 >> iter 72000, loss: 0.039281
 >> iter 73000, loss: 0.042087
 >> iter 74000, loss: 0.047707
 >> iter 75000, loss: 0.051635
 >> iter 76000, loss: 0.037646
 >> iter 77000, loss: 0.044915
 >> iter 78000, loss: 0.061288
 >> iter 79000, loss: 0.046291
 >> iter 80000, loss: 0.042236
   Number of active neurons: 3
 >> iter 81000, loss: 0.032933
 >> iter 82000, loss: 0.045860
 >> iter 83000, loss: 0.053893
 >> iter 84000, loss: 0.046620
 >> iter 85000, loss: 0.034614
 >> iter 86000, loss: 0.048413
 >> iter 87000, loss: 0.053957
 >> iter 88000, loss: 0.042030
 >> iter 89000, loss: 0.049209
 >> iter 90000, loss: 0.053247
   Number of active neurons: 3
 >> iter 91000, loss: 0.036408
 >> iter 92000, loss: 0.035439
 >> iter 93000, loss: 0.039761
 >> iter 94000, loss: 0.040827
 >> iter 95000, loss: 0.040968
 >> iter 96000, loss: 0.033401
 >> iter 97000, loss: 0.035423
 >> iter 98000, loss: 0.034944
 >> iter 99000, loss: 0.069749
 >> iter 100000, loss: 0.047901
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.428103
 >> iter 2000, loss: 4.344188
 >> iter 3000, loss: 1.692198
 >> iter 4000, loss: 0.662482
 >> iter 5000, loss: 0.281335
 >> iter 6000, loss: 0.140088
 >> iter 7000, loss: 0.094996
 >> iter 8000, loss: 0.067617
 >> iter 9000, loss: 0.060609
 >> iter 10000, loss: 0.066948
   Number of active neurons: 4
 >> iter 11000, loss: 0.056179
 >> iter 12000, loss: 0.063540
 >> iter 13000, loss: 0.067382
 >> iter 14000, loss: 0.058119
 >> iter 15000, loss: 0.056116
 >> iter 16000, loss: 0.069267
 >> iter 17000, loss: 0.048846
 >> iter 18000, loss: 0.061643
 >> iter 19000, loss: 0.058062
 >> iter 20000, loss: 0.062107
   Number of active neurons: 4
 >> iter 21000, loss: 0.049780
 >> iter 22000, loss: 0.034440
 >> iter 23000, loss: 0.032363
 >> iter 24000, loss: 0.050868
 >> iter 25000, loss: 0.051071
 >> iter 26000, loss: 0.049347
 >> iter 27000, loss: 0.047366
 >> iter 28000, loss: 0.058336
 >> iter 29000, loss: 0.052535
 >> iter 30000, loss: 0.042118
   Number of active neurons: 3
 >> iter 31000, loss: 0.058438
 >> iter 32000, loss: 0.058933
 >> iter 33000, loss: 0.052325
 >> iter 34000, loss: 0.037533
 >> iter 35000, loss: 0.036899
 >> iter 36000, loss: 0.043022
 >> iter 37000, loss: 0.055912
 >> iter 38000, loss: 0.044503
 >> iter 39000, loss: 0.087121
 >> iter 40000, loss: 0.052785
   Number of active neurons: 3
 >> iter 41000, loss: 0.079590
 >> iter 42000, loss: 0.062396
 >> iter 43000, loss: 0.057850
 >> iter 44000, loss: 0.063803
 >> iter 45000, loss: 0.051181
 >> iter 46000, loss: 0.035721
 >> iter 47000, loss: 0.040934
 >> iter 48000, loss: 0.053926
 >> iter 49000, loss: 0.068996
 >> iter 50000, loss: 0.058278
   Number of active neurons: 3
 >> iter 51000, loss: 0.048684
 >> iter 52000, loss: 0.039000
 >> iter 53000, loss: 0.062338
 >> iter 54000, loss: 0.069597
 >> iter 55000, loss: 0.045813
 >> iter 56000, loss: 0.058924
 >> iter 57000, loss: 0.068509
 >> iter 58000, loss: 0.079717
 >> iter 59000, loss: 0.057111
 >> iter 60000, loss: 0.061113
   Number of active neurons: 3
 >> iter 61000, loss: 0.054201
 >> iter 62000, loss: 0.065858
 >> iter 63000, loss: 0.053790
 >> iter 64000, loss: 0.042146
 >> iter 65000, loss: 0.041241
 >> iter 66000, loss: 0.047856
 >> iter 67000, loss: 0.052324
 >> iter 68000, loss: 0.046775
 >> iter 69000, loss: 0.045122
 >> iter 70000, loss: 0.041254
   Number of active neurons: 3
 >> iter 71000, loss: 0.039145
 >> iter 72000, loss: 0.038032
 >> iter 73000, loss: 0.050025
 >> iter 74000, loss: 0.047072
 >> iter 75000, loss: 0.065175
 >> iter 76000, loss: 0.057757
 >> iter 77000, loss: 0.043000
 >> iter 78000, loss: 0.066495
 >> iter 79000, loss: 0.054051
 >> iter 80000, loss: 0.047671
   Number of active neurons: 3
 >> iter 81000, loss: 0.044015
 >> iter 82000, loss: 0.045630
 >> iter 83000, loss: 0.035842
 >> iter 84000, loss: 0.044160
 >> iter 85000, loss: 0.060895
 >> iter 86000, loss: 0.052532
 >> iter 87000, loss: 0.046311
 >> iter 88000, loss: 0.050418
 >> iter 89000, loss: 0.050358
 >> iter 90000, loss: 0.044495
   Number of active neurons: 3
 >> iter 91000, loss: 0.050143
 >> iter 92000, loss: 0.065456
 >> iter 93000, loss: 0.043928
 >> iter 94000, loss: 0.035310
 >> iter 95000, loss: 0.050051
 >> iter 96000, loss: 0.052469
 >> iter 97000, loss: 0.056487
 >> iter 98000, loss: 0.038136
 >> iter 99000, loss: 0.035112
 >> iter 100000, loss: 0.040307
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.380483
 >> iter 2000, loss: 4.385010
 >> iter 3000, loss: 1.685768
 >> iter 4000, loss: 0.674672
 >> iter 5000, loss: 0.302558
 >> iter 6000, loss: 0.169435
 >> iter 7000, loss: 0.100114
 >> iter 8000, loss: 0.082581
 >> iter 9000, loss: 0.068450
 >> iter 10000, loss: 0.066592
   Number of active neurons: 6
 >> iter 11000, loss: 0.067009
 >> iter 12000, loss: 0.082592
 >> iter 13000, loss: 0.060967
 >> iter 14000, loss: 0.066164
 >> iter 15000, loss: 0.064043
 >> iter 16000, loss: 0.059661
 >> iter 17000, loss: 0.052532
 >> iter 18000, loss: 0.063344
 >> iter 19000, loss: 0.081255
 >> iter 20000, loss: 0.070659
   Number of active neurons: 6
 >> iter 21000, loss: 0.065068
 >> iter 22000, loss: 0.063718
 >> iter 23000, loss: 0.068817
 >> iter 24000, loss: 0.064244
 >> iter 25000, loss: 0.067810
 >> iter 26000, loss: 0.054965
 >> iter 27000, loss: 0.060273
 >> iter 28000, loss: 0.054505
 >> iter 29000, loss: 0.070423
 >> iter 30000, loss: 0.067423
   Number of active neurons: 6
 >> iter 31000, loss: 0.048886
 >> iter 32000, loss: 0.050787
 >> iter 33000, loss: 0.048722
 >> iter 34000, loss: 0.056889
 >> iter 35000, loss: 0.054713
 >> iter 36000, loss: 0.048954
 >> iter 37000, loss: 0.064545
 >> iter 38000, loss: 0.044496
 >> iter 39000, loss: 0.059994
 >> iter 40000, loss: 0.070897
   Number of active neurons: 6
 >> iter 41000, loss: 0.073666
 >> iter 42000, loss: 0.065446
 >> iter 43000, loss: 0.076491
 >> iter 44000, loss: 0.060303
 >> iter 45000, loss: 0.066614
 >> iter 46000, loss: 0.056160
 >> iter 47000, loss: 0.044380
 >> iter 48000, loss: 0.049898
 >> iter 49000, loss: 0.041819
 >> iter 50000, loss: 0.039603
   Number of active neurons: 5
 >> iter 51000, loss: 0.044647
 >> iter 52000, loss: 0.047581
 >> iter 53000, loss: 0.042158
 >> iter 54000, loss: 0.046359
 >> iter 55000, loss: 0.056281
 >> iter 56000, loss: 0.047494
 >> iter 57000, loss: 0.058709
 >> iter 58000, loss: 0.047501
 >> iter 59000, loss: 0.037527
 >> iter 60000, loss: 0.035469
   Number of active neurons: 5
 >> iter 61000, loss: 0.055461
 >> iter 62000, loss: 0.047876
 >> iter 63000, loss: 0.056669
 >> iter 64000, loss: 0.075984
 >> iter 65000, loss: 0.060444
 >> iter 66000, loss: 0.062169
 >> iter 67000, loss: 0.050857
 >> iter 68000, loss: 0.051675
 >> iter 69000, loss: 0.045006
 >> iter 70000, loss: 0.052984
   Number of active neurons: 3
 >> iter 71000, loss: 0.055548
 >> iter 72000, loss: 0.049536
 >> iter 73000, loss: 0.032992
 >> iter 74000, loss: 0.039960
 >> iter 75000, loss: 0.039280
 >> iter 76000, loss: 0.039903
 >> iter 77000, loss: 0.039364
 >> iter 78000, loss: 0.039013
 >> iter 79000, loss: 0.042628
 >> iter 80000, loss: 0.042187
   Number of active neurons: 2
 >> iter 81000, loss: 0.054443
 >> iter 82000, loss: 0.034979
 >> iter 83000, loss: 0.025482
 >> iter 84000, loss: 0.053593
 >> iter 85000, loss: 0.049895
 >> iter 86000, loss: 0.050061
 >> iter 87000, loss: 0.052507
 >> iter 88000, loss: 0.056636
 >> iter 89000, loss: 0.050936
 >> iter 90000, loss: 0.038545
   Number of active neurons: 2
 >> iter 91000, loss: 0.026033
 >> iter 92000, loss: 0.023535
 >> iter 93000, loss: 0.044564
 >> iter 94000, loss: 0.055780
 >> iter 95000, loss: 0.042206
 >> iter 96000, loss: 0.045143
 >> iter 97000, loss: 0.036429
 >> iter 98000, loss: 0.037543
 >> iter 99000, loss: 0.033601
 >> iter 100000, loss: 0.028936
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.285842
 >> iter 2000, loss: 4.319585
 >> iter 3000, loss: 1.674551
 >> iter 4000, loss: 0.667708
 >> iter 5000, loss: 0.300701
 >> iter 6000, loss: 0.162712
 >> iter 7000, loss: 0.095142
 >> iter 8000, loss: 0.069317
 >> iter 9000, loss: 0.059549
 >> iter 10000, loss: 0.071627
   Number of active neurons: 5
 >> iter 11000, loss: 0.062482
 >> iter 12000, loss: 0.081145
 >> iter 13000, loss: 0.073457
 >> iter 14000, loss: 0.058380
 >> iter 15000, loss: 0.057506
 >> iter 16000, loss: 0.062434
 >> iter 17000, loss: 0.066253
 >> iter 18000, loss: 0.075007
 >> iter 19000, loss: 0.054538
 >> iter 20000, loss: 0.038990
   Number of active neurons: 5
 >> iter 21000, loss: 0.034690
 >> iter 22000, loss: 0.039062
 >> iter 23000, loss: 0.047296
 >> iter 24000, loss: 0.050077
 >> iter 25000, loss: 0.067940
 >> iter 26000, loss: 0.051886
 >> iter 27000, loss: 0.059622
 >> iter 28000, loss: 0.057774
 >> iter 29000, loss: 0.055937
 >> iter 30000, loss: 0.044049
   Number of active neurons: 5
 >> iter 31000, loss: 0.035690
 >> iter 32000, loss: 0.047329
 >> iter 33000, loss: 0.049368
 >> iter 34000, loss: 0.043448
 >> iter 35000, loss: 0.052644
 >> iter 36000, loss: 0.041909
 >> iter 37000, loss: 0.043262
 >> iter 38000, loss: 0.037564
 >> iter 39000, loss: 0.057652
 >> iter 40000, loss: 0.073502
   Number of active neurons: 4
 >> iter 41000, loss: 0.054717
 >> iter 42000, loss: 0.042475
 >> iter 43000, loss: 0.059032
 >> iter 44000, loss: 0.048038
 >> iter 45000, loss: 0.051582
 >> iter 46000, loss: 0.049756
 >> iter 47000, loss: 0.049854
 >> iter 48000, loss: 0.056042
 >> iter 49000, loss: 0.038712
 >> iter 50000, loss: 0.054713
   Number of active neurons: 4
 >> iter 51000, loss: 0.034654
 >> iter 52000, loss: 0.036449
 >> iter 53000, loss: 0.037802
 >> iter 54000, loss: 0.071679
 >> iter 55000, loss: 0.075282
 >> iter 56000, loss: 0.049218
 >> iter 57000, loss: 0.048397
 >> iter 58000, loss: 0.072621
 >> iter 59000, loss: 0.059782
 >> iter 60000, loss: 0.047844
   Number of active neurons: 4
 >> iter 61000, loss: 0.066533
 >> iter 62000, loss: 0.073185
 >> iter 63000, loss: 0.060203
 >> iter 64000, loss: 0.050975
 >> iter 65000, loss: 0.043606
 >> iter 66000, loss: 0.046073
 >> iter 67000, loss: 0.041617
 >> iter 68000, loss: 0.037114
 >> iter 69000, loss: 0.042358
 >> iter 70000, loss: 0.043159
   Number of active neurons: 4
 >> iter 71000, loss: 0.058733
 >> iter 72000, loss: 0.048897
 >> iter 73000, loss: 0.034622
 >> iter 74000, loss: 0.061760
 >> iter 75000, loss: 0.051278
 >> iter 76000, loss: 0.057246
 >> iter 77000, loss: 0.065435
 >> iter 78000, loss: 0.053313
 >> iter 79000, loss: 0.048634
 >> iter 80000, loss: 0.052352
   Number of active neurons: 3
 >> iter 81000, loss: 0.037227
 >> iter 82000, loss: 0.048631
 >> iter 83000, loss: 0.043434
 >> iter 84000, loss: 0.042845
 >> iter 85000, loss: 0.039990
 >> iter 86000, loss: 0.042211
 >> iter 87000, loss: 0.042383
 >> iter 88000, loss: 0.034596
 >> iter 89000, loss: 0.050818
 >> iter 90000, loss: 0.045390
   Number of active neurons: 3
 >> iter 91000, loss: 0.059268
 >> iter 92000, loss: 0.053743
 >> iter 93000, loss: 0.048800
 >> iter 94000, loss: 0.035764
 >> iter 95000, loss: 0.042099
 >> iter 96000, loss: 0.033671
 >> iter 97000, loss: 0.036182
 >> iter 98000, loss: 0.045130
 >> iter 99000, loss: 0.042153
 >> iter 100000, loss: 0.042347
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.399939
 >> iter 2000, loss: 4.402431
 >> iter 3000, loss: 1.710389
 >> iter 4000, loss: 0.680457
 >> iter 5000, loss: 0.285395
 >> iter 6000, loss: 0.155116
 >> iter 7000, loss: 0.111349
 >> iter 8000, loss: 0.088846
 >> iter 9000, loss: 0.082981
 >> iter 10000, loss: 0.060220
   Number of active neurons: 5
 >> iter 11000, loss: 0.056913
 >> iter 12000, loss: 0.063237
 >> iter 13000, loss: 0.052227
 >> iter 14000, loss: 0.057495
 >> iter 15000, loss: 0.062402
 >> iter 16000, loss: 0.054850
 >> iter 17000, loss: 0.043939
 >> iter 18000, loss: 0.045537
 >> iter 19000, loss: 0.044569
 >> iter 20000, loss: 0.054178
   Number of active neurons: 5
 >> iter 21000, loss: 0.056506
 >> iter 22000, loss: 0.056495
 >> iter 23000, loss: 0.062466
 >> iter 24000, loss: 0.048761
 >> iter 25000, loss: 0.047456
 >> iter 26000, loss: 0.052994
 >> iter 27000, loss: 0.064463
 >> iter 28000, loss: 0.052409
 >> iter 29000, loss: 0.054572
 >> iter 30000, loss: 0.053711
   Number of active neurons: 5
 >> iter 31000, loss: 0.049265
 >> iter 32000, loss: 0.051334
 >> iter 33000, loss: 0.059186
 >> iter 34000, loss: 0.061403
 >> iter 35000, loss: 0.055502
 >> iter 36000, loss: 0.062037
 >> iter 37000, loss: 0.063190
 >> iter 38000, loss: 0.061759
 >> iter 39000, loss: 0.047215
 >> iter 40000, loss: 0.049149
   Number of active neurons: 5
 >> iter 41000, loss: 0.049917
 >> iter 42000, loss: 0.060317
 >> iter 43000, loss: 0.046639
 >> iter 44000, loss: 0.045897
 >> iter 45000, loss: 0.040086
 >> iter 46000, loss: 0.049643
 >> iter 47000, loss: 0.044999
 >> iter 48000, loss: 0.045417
 >> iter 49000, loss: 0.061132
 >> iter 50000, loss: 0.077689
   Number of active neurons: 5
 >> iter 51000, loss: 0.057996
 >> iter 52000, loss: 0.063973
 >> iter 53000, loss: 0.064076
 >> iter 54000, loss: 0.065216
 >> iter 55000, loss: 0.045746
 >> iter 56000, loss: 0.076705
 >> iter 57000, loss: 0.058679
 >> iter 58000, loss: 0.064847
 >> iter 59000, loss: 0.059151
 >> iter 60000, loss: 0.069988
   Number of active neurons: 4
 >> iter 61000, loss: 0.069735
 >> iter 62000, loss: 0.067166
 >> iter 63000, loss: 0.053479
 >> iter 64000, loss: 0.049859
 >> iter 65000, loss: 0.046199
 >> iter 66000, loss: 0.078056
 >> iter 67000, loss: 0.048426
 >> iter 68000, loss: 0.058153
 >> iter 69000, loss: 0.055437
 >> iter 70000, loss: 0.055236
   Number of active neurons: 4
 >> iter 71000, loss: 0.041095
 >> iter 72000, loss: 0.040516
 >> iter 73000, loss: 0.037031
 >> iter 74000, loss: 0.042575
 >> iter 75000, loss: 0.041241
 >> iter 76000, loss: 0.051773
 >> iter 77000, loss: 0.051885
 >> iter 78000, loss: 0.048860
 >> iter 79000, loss: 0.059245
 >> iter 80000, loss: 0.058670
   Number of active neurons: 4
 >> iter 81000, loss: 0.069727
 >> iter 82000, loss: 0.055521
 >> iter 83000, loss: 0.046281
 >> iter 84000, loss: 0.067277
 >> iter 85000, loss: 0.058049
 >> iter 86000, loss: 0.036675
 >> iter 87000, loss: 0.031437
 >> iter 88000, loss: 0.038851
 >> iter 89000, loss: 0.062454
 >> iter 90000, loss: 0.061595
   Number of active neurons: 3
 >> iter 91000, loss: 0.045327
 >> iter 92000, loss: 0.056345
 >> iter 93000, loss: 0.061619
 >> iter 94000, loss: 0.041026
 >> iter 95000, loss: 0.042825
 >> iter 96000, loss: 0.061881
 >> iter 97000, loss: 0.043557
 >> iter 98000, loss: 0.036317
 >> iter 99000, loss: 0.033709
 >> iter 100000, loss: 0.036551
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.351231
 >> iter 2000, loss: 4.328173
 >> iter 3000, loss: 1.681741
 >> iter 4000, loss: 0.661947
 >> iter 5000, loss: 0.291724
 >> iter 6000, loss: 0.140179
 >> iter 7000, loss: 0.088147
 >> iter 8000, loss: 0.077516
 >> iter 9000, loss: 0.059989
 >> iter 10000, loss: 0.061200
   Number of active neurons: 4
 >> iter 11000, loss: 0.072127
 >> iter 12000, loss: 0.064609
 >> iter 13000, loss: 0.061491
 >> iter 14000, loss: 0.053761
 >> iter 15000, loss: 0.072013
 >> iter 16000, loss: 0.061275
 >> iter 17000, loss: 0.063125
 >> iter 18000, loss: 0.050469
 >> iter 19000, loss: 0.062910
 >> iter 20000, loss: 0.044960
   Number of active neurons: 4
 >> iter 21000, loss: 0.050568
 >> iter 22000, loss: 0.046780
 >> iter 23000, loss: 0.055363
 >> iter 24000, loss: 0.046886
 >> iter 25000, loss: 0.041832
 >> iter 26000, loss: 0.051567
 >> iter 27000, loss: 0.046230
 >> iter 28000, loss: 0.038161
 >> iter 29000, loss: 0.038500
 >> iter 30000, loss: 0.050289
   Number of active neurons: 4
 >> iter 31000, loss: 0.054011
 >> iter 32000, loss: 0.052076
 >> iter 33000, loss: 0.059281
 >> iter 34000, loss: 0.046928
 >> iter 35000, loss: 0.043505
 >> iter 36000, loss: 0.062299
 >> iter 37000, loss: 0.067070
 >> iter 38000, loss: 0.090004
 >> iter 39000, loss: 0.054203
 >> iter 40000, loss: 0.046480
   Number of active neurons: 3
 >> iter 41000, loss: 0.040733
 >> iter 42000, loss: 0.052243
 >> iter 43000, loss: 0.038941
 >> iter 44000, loss: 0.045353
 >> iter 45000, loss: 0.053589
 >> iter 46000, loss: 0.036170
 >> iter 47000, loss: 0.034879
 >> iter 48000, loss: 0.040106
 >> iter 49000, loss: 0.047042
 >> iter 50000, loss: 0.059997
   Number of active neurons: 3
 >> iter 51000, loss: 0.044672
 >> iter 52000, loss: 0.057021
 >> iter 53000, loss: 0.062464
 >> iter 54000, loss: 0.039362
 >> iter 55000, loss: 0.053967
 >> iter 56000, loss: 0.069290
 >> iter 57000, loss: 0.057425
 >> iter 58000, loss: 0.044241
 >> iter 59000, loss: 0.043368
 >> iter 60000, loss: 0.061787
   Number of active neurons: 3
 >> iter 61000, loss: 0.060724
 >> iter 62000, loss: 0.047607
 >> iter 63000, loss: 0.078873
 >> iter 64000, loss: 0.046141
 >> iter 65000, loss: 0.078206
 >> iter 66000, loss: 0.063844
 >> iter 67000, loss: 0.047828
 >> iter 68000, loss: 0.063572
 >> iter 69000, loss: 0.068609
 >> iter 70000, loss: 0.055707
   Number of active neurons: 3
 >> iter 71000, loss: 0.039115
 >> iter 72000, loss: 0.057987
 >> iter 73000, loss: 0.039774
 >> iter 74000, loss: 0.060510
 >> iter 75000, loss: 0.061412
 >> iter 76000, loss: 0.050511
 >> iter 77000, loss: 0.044229
 >> iter 78000, loss: 0.059935
 >> iter 79000, loss: 0.049406
 >> iter 80000, loss: 0.039592
   Number of active neurons: 3
 >> iter 81000, loss: 0.033488
 >> iter 82000, loss: 0.043058
 >> iter 83000, loss: 0.041523
 >> iter 84000, loss: 0.046728
 >> iter 85000, loss: 0.050930
 >> iter 86000, loss: 0.038548
 >> iter 87000, loss: 0.034321
 >> iter 88000, loss: 0.042969
 >> iter 89000, loss: 0.051726
 >> iter 90000, loss: 0.047192
   Number of active neurons: 3
 >> iter 91000, loss: 0.062499
 >> iter 92000, loss: 0.045885
 >> iter 93000, loss: 0.036940
 >> iter 94000, loss: 0.040830
 >> iter 95000, loss: 0.041246
 >> iter 96000, loss: 0.045354
 >> iter 97000, loss: 0.051940
 >> iter 98000, loss: 0.046243
 >> iter 99000, loss: 0.051987
 >> iter 100000, loss: 0.044385
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.367978
 >> iter 2000, loss: 4.373909
 >> iter 3000, loss: 1.729874
 >> iter 4000, loss: 0.703978
 >> iter 5000, loss: 0.313333
 >> iter 6000, loss: 0.157923
 >> iter 7000, loss: 0.088768
 >> iter 8000, loss: 0.067555
 >> iter 9000, loss: 0.062978
 >> iter 10000, loss: 0.047366
   Number of active neurons: 4
 >> iter 11000, loss: 0.070673
 >> iter 12000, loss: 0.051908
 >> iter 13000, loss: 0.039539
 >> iter 14000, loss: 0.040942
 >> iter 15000, loss: 0.051714
 >> iter 16000, loss: 0.061439
 >> iter 17000, loss: 0.048124
 >> iter 18000, loss: 0.047173
 >> iter 19000, loss: 0.056282
 >> iter 20000, loss: 0.054239
   Number of active neurons: 3
 >> iter 21000, loss: 0.045645
 >> iter 22000, loss: 0.054135
 >> iter 23000, loss: 0.074290
 >> iter 24000, loss: 0.056774
 >> iter 25000, loss: 0.037594
 >> iter 26000, loss: 0.057918
 >> iter 27000, loss: 0.038583
 >> iter 28000, loss: 0.038385
 >> iter 29000, loss: 0.050750
 >> iter 30000, loss: 0.071764
   Number of active neurons: 3
 >> iter 31000, loss: 0.049054
 >> iter 32000, loss: 0.047922
 >> iter 33000, loss: 0.065382
 >> iter 34000, loss: 0.074048
 >> iter 35000, loss: 0.050492
 >> iter 36000, loss: 0.044267
 >> iter 37000, loss: 0.043285
 >> iter 38000, loss: 0.050000
 >> iter 39000, loss: 0.047001
 >> iter 40000, loss: 0.045820
   Number of active neurons: 3
 >> iter 41000, loss: 0.055853
 >> iter 42000, loss: 0.044912
 >> iter 43000, loss: 0.046100
 >> iter 44000, loss: 0.033741
 >> iter 45000, loss: 0.037023
 >> iter 46000, loss: 0.032259
 >> iter 47000, loss: 0.030124
 >> iter 48000, loss: 0.054533
 >> iter 49000, loss: 0.065037
 >> iter 50000, loss: 0.053099
   Number of active neurons: 3
 >> iter 51000, loss: 0.044600
 >> iter 52000, loss: 0.043776
 >> iter 53000, loss: 0.050842
 >> iter 54000, loss: 0.065116
 >> iter 55000, loss: 0.054890
 >> iter 56000, loss: 0.053926
 >> iter 57000, loss: 0.051813
 >> iter 58000, loss: 0.054665
 >> iter 59000, loss: 0.056292
 >> iter 60000, loss: 0.064091
   Number of active neurons: 3
 >> iter 61000, loss: 0.057582
 >> iter 62000, loss: 0.039615
 >> iter 63000, loss: 0.058962
 >> iter 64000, loss: 0.052992
 >> iter 65000, loss: 0.037567
 >> iter 66000, loss: 0.048047
 >> iter 67000, loss: 0.050837
 >> iter 68000, loss: 0.032510
 >> iter 69000, loss: 0.034895
 >> iter 70000, loss: 0.071222
   Number of active neurons: 3
 >> iter 71000, loss: 0.061773
 >> iter 72000, loss: 0.062701
 >> iter 73000, loss: 0.064697
 >> iter 74000, loss: 0.046140
 >> iter 75000, loss: 0.048698
 >> iter 76000, loss: 0.055251
 >> iter 77000, loss: 0.046362
 >> iter 78000, loss: 0.044132
 >> iter 79000, loss: 0.059491
 >> iter 80000, loss: 0.054018
   Number of active neurons: 3
 >> iter 81000, loss: 0.049016
 >> iter 82000, loss: 0.056209
 >> iter 83000, loss: 0.045465
 >> iter 84000, loss: 0.042364
 >> iter 85000, loss: 0.058228
 >> iter 86000, loss: 0.054920
 >> iter 87000, loss: 0.041433
 >> iter 88000, loss: 0.042390
 >> iter 89000, loss: 0.053453
 >> iter 90000, loss: 0.046167
   Number of active neurons: 3
 >> iter 91000, loss: 0.061444
 >> iter 92000, loss: 0.068380
 >> iter 93000, loss: 0.049135
 >> iter 94000, loss: 0.048801
 >> iter 95000, loss: 0.046329
 >> iter 96000, loss: 0.056886
 >> iter 97000, loss: 0.045162
 >> iter 98000, loss: 0.059600
 >> iter 99000, loss: 0.045072
 >> iter 100000, loss: 0.049292
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 11.379390
 >> iter 2000, loss: 4.385927
 >> iter 3000, loss: 1.700429
 >> iter 4000, loss: 0.676554
 >> iter 5000, loss: 0.300019
 >> iter 6000, loss: 0.187793
 >> iter 7000, loss: 0.115412
 >> iter 8000, loss: 0.068372
 >> iter 9000, loss: 0.071352
 >> iter 10000, loss: 0.058600
   Number of active neurons: 5
 >> iter 11000, loss: 0.065420
 >> iter 12000, loss: 0.077838
 >> iter 13000, loss: 0.059014
 >> iter 14000, loss: 0.041197
 >> iter 15000, loss: 0.050328
 >> iter 16000, loss: 0.067409
 >> iter 17000, loss: 0.045724
 >> iter 18000, loss: 0.051296
 >> iter 19000, loss: 0.053428
 >> iter 20000, loss: 0.048319
   Number of active neurons: 5
 >> iter 21000, loss: 0.059705
 >> iter 22000, loss: 0.045092
 >> iter 23000, loss: 0.051029
 >> iter 24000, loss: 0.062183
 >> iter 25000, loss: 0.046089
 >> iter 26000, loss: 0.049404
 >> iter 27000, loss: 0.036758
 >> iter 28000, loss: 0.035751
 >> iter 29000, loss: 0.050081
 >> iter 30000, loss: 0.048566
   Number of active neurons: 4
 >> iter 31000, loss: 0.060895
 >> iter 32000, loss: 0.041058
 >> iter 33000, loss: 0.039542
 >> iter 34000, loss: 0.048688
 >> iter 35000, loss: 0.041630
 >> iter 36000, loss: 0.051370
 >> iter 37000, loss: 0.047201
 >> iter 38000, loss: 0.047681
 >> iter 39000, loss: 0.054721
 >> iter 40000, loss: 0.054854
   Number of active neurons: 4
 >> iter 41000, loss: 0.042189
 >> iter 42000, loss: 0.039766
 >> iter 43000, loss: 0.032959
 >> iter 44000, loss: 0.036293
 >> iter 45000, loss: 0.046927
 >> iter 46000, loss: 0.045783
 >> iter 47000, loss: 0.056280
 >> iter 48000, loss: 0.055129
 >> iter 49000, loss: 0.059925
 >> iter 50000, loss: 0.051282
   Number of active neurons: 4
 >> iter 51000, loss: 0.047215
 >> iter 52000, loss: 0.041743
 >> iter 53000, loss: 0.040999
 >> iter 54000, loss: 0.058149
 >> iter 55000, loss: 0.049052
 >> iter 56000, loss: 0.057523
 >> iter 57000, loss: 0.058230
 >> iter 58000, loss: 0.059896
 >> iter 59000, loss: 0.051573
 >> iter 60000, loss: 0.060695
   Number of active neurons: 3
 >> iter 61000, loss: 0.056347
 >> iter 62000, loss: 0.065327
 >> iter 63000, loss: 0.073444
 >> iter 64000, loss: 0.052523
 >> iter 65000, loss: 0.046104
 >> iter 66000, loss: 0.039006
 >> iter 67000, loss: 0.038555
 >> iter 68000, loss: 0.048249
 >> iter 69000, loss: 0.042747
 >> iter 70000, loss: 0.033305
   Number of active neurons: 3
 >> iter 71000, loss: 0.050522
 >> iter 72000, loss: 0.037383
 >> iter 73000, loss: 0.035898
 >> iter 74000, loss: 0.041617
 >> iter 75000, loss: 0.045282
 >> iter 76000, loss: 0.032159
 >> iter 77000, loss: 0.050178
 >> iter 78000, loss: 0.048167
 >> iter 79000, loss: 0.053445
 >> iter 80000, loss: 0.051443
   Number of active neurons: 3
 >> iter 81000, loss: 0.046017
 >> iter 82000, loss: 0.039828
 >> iter 83000, loss: 0.036597
 >> iter 84000, loss: 0.038810
 >> iter 85000, loss: 0.056861
 >> iter 86000, loss: 0.060727
 >> iter 87000, loss: 0.057067
 >> iter 88000, loss: 0.045636
 >> iter 89000, loss: 0.049270
 >> iter 90000, loss: 0.041146
   Number of active neurons: 3
 >> iter 91000, loss: 0.062202
 >> iter 92000, loss: 0.057366
 >> iter 93000, loss: 0.051909
 >> iter 94000, loss: 0.046221
 >> iter 95000, loss: 0.060626
 >> iter 96000, loss: 0.049474
 >> iter 97000, loss: 0.041068
 >> iter 98000, loss: 0.043808
 >> iter 99000, loss: 0.043293
 >> iter 100000, loss: 0.050046
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.393362
 >> iter 2000, loss: 4.388107
 >> iter 3000, loss: 1.699997
 >> iter 4000, loss: 0.699406
 >> iter 5000, loss: 0.307197
 >> iter 6000, loss: 0.134884
 >> iter 7000, loss: 0.099696
 >> iter 8000, loss: 0.075262
 >> iter 9000, loss: 0.061040
 >> iter 10000, loss: 0.059716
   Number of active neurons: 5
 >> iter 11000, loss: 0.053852
 >> iter 12000, loss: 0.070841
 >> iter 13000, loss: 0.066383
 >> iter 14000, loss: 0.074506
 >> iter 15000, loss: 0.050939
 >> iter 16000, loss: 0.063816
 >> iter 17000, loss: 0.059828
 >> iter 18000, loss: 0.055886
 >> iter 19000, loss: 0.060807
 >> iter 20000, loss: 0.043768
   Number of active neurons: 5
 >> iter 21000, loss: 0.059648
 >> iter 22000, loss: 0.069243
 >> iter 23000, loss: 0.067190
 >> iter 24000, loss: 0.070035
 >> iter 25000, loss: 0.065345
 >> iter 26000, loss: 0.052102
 >> iter 27000, loss: 0.041862
 >> iter 28000, loss: 0.053313
 >> iter 29000, loss: 0.082774
 >> iter 30000, loss: 0.058851
   Number of active neurons: 4
 >> iter 31000, loss: 0.044368
 >> iter 32000, loss: 0.056309
 >> iter 33000, loss: 0.053514
 >> iter 34000, loss: 0.048538
 >> iter 35000, loss: 0.039264
 >> iter 36000, loss: 0.039626
 >> iter 37000, loss: 0.041558
 >> iter 38000, loss: 0.040143
 >> iter 39000, loss: 0.040031
 >> iter 40000, loss: 0.044468
   Number of active neurons: 3
 >> iter 41000, loss: 0.069346
 >> iter 42000, loss: 0.049159
 >> iter 43000, loss: 0.070317
 >> iter 44000, loss: 0.046861
 >> iter 45000, loss: 0.046792
 >> iter 46000, loss: 0.042614
 >> iter 47000, loss: 0.049862
 >> iter 48000, loss: 0.048433
 >> iter 49000, loss: 0.036052
 >> iter 50000, loss: 0.043659
   Number of active neurons: 3
 >> iter 51000, loss: 0.057760
 >> iter 52000, loss: 0.059041
 >> iter 53000, loss: 0.051522
 >> iter 54000, loss: 0.043952
 >> iter 55000, loss: 0.055753
 >> iter 56000, loss: 0.056324
 >> iter 57000, loss: 0.047397
 >> iter 58000, loss: 0.044160
 >> iter 59000, loss: 0.049412
 >> iter 60000, loss: 0.048800
   Number of active neurons: 3
 >> iter 61000, loss: 0.050368
 >> iter 62000, loss: 0.043777
 >> iter 63000, loss: 0.040938
 >> iter 64000, loss: 0.043719
 >> iter 65000, loss: 0.046411
 >> iter 66000, loss: 0.046668
 >> iter 67000, loss: 0.040418
 >> iter 68000, loss: 0.043912
 >> iter 69000, loss: 0.047478
 >> iter 70000, loss: 0.043986
   Number of active neurons: 3
 >> iter 71000, loss: 0.039424
 >> iter 72000, loss: 0.040964
 >> iter 73000, loss: 0.053491
 >> iter 74000, loss: 0.043186
 >> iter 75000, loss: 0.035108
 >> iter 76000, loss: 0.062134
 >> iter 77000, loss: 0.045631
 >> iter 78000, loss: 0.053690
 >> iter 79000, loss: 0.038272
 >> iter 80000, loss: 0.042008
   Number of active neurons: 3
 >> iter 81000, loss: 0.051466
 >> iter 82000, loss: 0.039895
 >> iter 83000, loss: 0.038140
 >> iter 84000, loss: 0.042099
 >> iter 85000, loss: 0.054061
 >> iter 86000, loss: 0.041663
 >> iter 87000, loss: 0.049725
 >> iter 88000, loss: 0.063752
 >> iter 89000, loss: 0.044182
 >> iter 90000, loss: 0.047957
   Number of active neurons: 3
 >> iter 91000, loss: 0.040118
 >> iter 92000, loss: 0.047064
 >> iter 93000, loss: 0.048539
 >> iter 94000, loss: 0.041807
 >> iter 95000, loss: 0.043432
 >> iter 96000, loss: 0.033993
 >> iter 97000, loss: 0.034148
 >> iter 98000, loss: 0.057018
 >> iter 99000, loss: 0.057068
 >> iter 100000, loss: 0.062244
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.516248
 >> iter 2000, loss: 4.448952
 >> iter 3000, loss: 1.724151
 >> iter 4000, loss: 0.694684
 >> iter 5000, loss: 0.294411
 >> iter 6000, loss: 0.142348
 >> iter 7000, loss: 0.102494
 >> iter 8000, loss: 0.081910
 >> iter 9000, loss: 0.073161
 >> iter 10000, loss: 0.065255
   Number of active neurons: 5
 >> iter 11000, loss: 0.060807
 >> iter 12000, loss: 0.055715
 >> iter 13000, loss: 0.071112
 >> iter 14000, loss: 0.063330
 >> iter 15000, loss: 0.071784
 >> iter 16000, loss: 0.073734
 >> iter 17000, loss: 0.052176
 >> iter 18000, loss: 0.058895
 >> iter 19000, loss: 0.053914
 >> iter 20000, loss: 0.064387
   Number of active neurons: 5
 >> iter 21000, loss: 0.058598
 >> iter 22000, loss: 0.067369
 >> iter 23000, loss: 0.061303
 >> iter 24000, loss: 0.053959
 >> iter 25000, loss: 0.051035
 >> iter 26000, loss: 0.047300
 >> iter 27000, loss: 0.050063
 >> iter 28000, loss: 0.063922
 >> iter 29000, loss: 0.051484
 >> iter 30000, loss: 0.051591
   Number of active neurons: 5
 >> iter 31000, loss: 0.052819
 >> iter 32000, loss: 0.050338
 >> iter 33000, loss: 0.055496
 >> iter 34000, loss: 0.058917
 >> iter 35000, loss: 0.058118
 >> iter 36000, loss: 0.056390
 >> iter 37000, loss: 0.072296
 >> iter 38000, loss: 0.049603
 >> iter 39000, loss: 0.061601
 >> iter 40000, loss: 0.049946
   Number of active neurons: 4
 >> iter 41000, loss: 0.045733
 >> iter 42000, loss: 0.043856
 >> iter 43000, loss: 0.049602
 >> iter 44000, loss: 0.036852
 >> iter 45000, loss: 0.044101
 >> iter 46000, loss: 0.037396
 >> iter 47000, loss: 0.061532
 >> iter 48000, loss: 0.054397
 >> iter 49000, loss: 0.040703
 >> iter 50000, loss: 0.048964
   Number of active neurons: 4
 >> iter 51000, loss: 0.045505
 >> iter 52000, loss: 0.045934
 >> iter 53000, loss: 0.060475
 >> iter 54000, loss: 0.059798
 >> iter 55000, loss: 0.058091
 >> iter 56000, loss: 0.060459
 >> iter 57000, loss: 0.064964
 >> iter 58000, loss: 0.063758
 >> iter 59000, loss: 0.051297
 >> iter 60000, loss: 0.038949
   Number of active neurons: 3
 >> iter 61000, loss: 0.046122
 >> iter 62000, loss: 0.034602
 >> iter 63000, loss: 0.043022
 >> iter 64000, loss: 0.056196
 >> iter 65000, loss: 0.038761
 >> iter 66000, loss: 0.052181
 >> iter 67000, loss: 0.047192
 >> iter 68000, loss: 0.046314
 >> iter 69000, loss: 0.034811
 >> iter 70000, loss: 0.039112
   Number of active neurons: 3
 >> iter 71000, loss: 0.049672
 >> iter 72000, loss: 0.060507
 >> iter 73000, loss: 0.054491
 >> iter 74000, loss: 0.033877
 >> iter 75000, loss: 0.048697
 >> iter 76000, loss: 0.066251
 >> iter 77000, loss: 0.047404
 >> iter 78000, loss: 0.052189
 >> iter 79000, loss: 0.045900
 >> iter 80000, loss: 0.035434
   Number of active neurons: 3
 >> iter 81000, loss: 0.042873
 >> iter 82000, loss: 0.039848
 >> iter 83000, loss: 0.045989
 >> iter 84000, loss: 0.066375
 >> iter 85000, loss: 0.052202
 >> iter 86000, loss: 0.036096
 >> iter 87000, loss: 0.045493
 >> iter 88000, loss: 0.049174
 >> iter 89000, loss: 0.043356
 >> iter 90000, loss: 0.044476
   Number of active neurons: 2
 >> iter 91000, loss: 0.041296
 >> iter 92000, loss: 0.039216
 >> iter 93000, loss: 0.037503
 >> iter 94000, loss: 0.037608
 >> iter 95000, loss: 0.036713
 >> iter 96000, loss: 0.033821
 >> iter 97000, loss: 0.044587
 >> iter 98000, loss: 0.045236
 >> iter 99000, loss: 0.036203
 >> iter 100000, loss: 0.041288
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.467530
 >> iter 2000, loss: 4.466767
 >> iter 3000, loss: 1.747751
 >> iter 4000, loss: 0.729206
 >> iter 5000, loss: 0.325526
 >> iter 6000, loss: 0.162238
 >> iter 7000, loss: 0.106671
 >> iter 8000, loss: 0.089968
 >> iter 9000, loss: 0.061310
 >> iter 10000, loss: 0.077081
   Number of active neurons: 6
 >> iter 11000, loss: 0.063444
 >> iter 12000, loss: 0.053997
 >> iter 13000, loss: 0.058405
 >> iter 14000, loss: 0.051735
 >> iter 15000, loss: 0.062980
 >> iter 16000, loss: 0.056324
 >> iter 17000, loss: 0.065859
 >> iter 18000, loss: 0.050028
 >> iter 19000, loss: 0.057974
 >> iter 20000, loss: 0.051838
   Number of active neurons: 6
 >> iter 21000, loss: 0.055749
 >> iter 22000, loss: 0.040552
 >> iter 23000, loss: 0.047736
 >> iter 24000, loss: 0.050892
 >> iter 25000, loss: 0.078812
 >> iter 26000, loss: 0.058849
 >> iter 27000, loss: 0.073214
 >> iter 28000, loss: 0.059931
 >> iter 29000, loss: 0.044614
 >> iter 30000, loss: 0.047670
   Number of active neurons: 6
 >> iter 31000, loss: 0.048320
 >> iter 32000, loss: 0.041346
 >> iter 33000, loss: 0.054330
 >> iter 34000, loss: 0.053447
 >> iter 35000, loss: 0.054102
 >> iter 36000, loss: 0.053930
 >> iter 37000, loss: 0.061232
 >> iter 38000, loss: 0.048234
 >> iter 39000, loss: 0.067769
 >> iter 40000, loss: 0.066031
   Number of active neurons: 4
 >> iter 41000, loss: 0.061720
 >> iter 42000, loss: 0.068973
 >> iter 43000, loss: 0.043768
 >> iter 44000, loss: 0.048535
 >> iter 45000, loss: 0.055895
 >> iter 46000, loss: 0.052678
 >> iter 47000, loss: 0.052612
 >> iter 48000, loss: 0.051606
 >> iter 49000, loss: 0.056227
 >> iter 50000, loss: 0.057608
   Number of active neurons: 4
 >> iter 51000, loss: 0.065313
 >> iter 52000, loss: 0.045287
 >> iter 53000, loss: 0.035350
 >> iter 54000, loss: 0.061039
 >> iter 55000, loss: 0.044800
 >> iter 56000, loss: 0.038818
 >> iter 57000, loss: 0.036329
 >> iter 58000, loss: 0.051409
 >> iter 59000, loss: 0.069929
 >> iter 60000, loss: 0.051464
   Number of active neurons: 4
 >> iter 61000, loss: 0.045804
 >> iter 62000, loss: 0.037798
 >> iter 63000, loss: 0.058831
 >> iter 64000, loss: 0.067082
 >> iter 65000, loss: 0.065094
 >> iter 66000, loss: 0.063368
 >> iter 67000, loss: 0.041787
 >> iter 68000, loss: 0.067099
 >> iter 69000, loss: 0.060428
 >> iter 70000, loss: 0.051280
   Number of active neurons: 3
 >> iter 71000, loss: 0.044818
 >> iter 72000, loss: 0.048695
 >> iter 73000, loss: 0.048124
 >> iter 74000, loss: 0.042820
 >> iter 75000, loss: 0.030822
 >> iter 76000, loss: 0.029533
 >> iter 77000, loss: 0.039293
 >> iter 78000, loss: 0.043709
 >> iter 79000, loss: 0.036142
 >> iter 80000, loss: 0.042650
   Number of active neurons: 2
 >> iter 81000, loss: 0.034484
 >> iter 82000, loss: 0.038854
 >> iter 83000, loss: 0.042498
 >> iter 84000, loss: 0.054927
 >> iter 85000, loss: 0.048580
 >> iter 86000, loss: 0.031420
 >> iter 87000, loss: 0.041101
 >> iter 88000, loss: 0.033192
 >> iter 89000, loss: 0.038948
 >> iter 90000, loss: 0.035869
   Number of active neurons: 2
 >> iter 91000, loss: 0.053712
 >> iter 92000, loss: 0.034433
 >> iter 93000, loss: 0.049559
 >> iter 94000, loss: 0.038992
 >> iter 95000, loss: 0.061919
 >> iter 96000, loss: 0.050075
 >> iter 97000, loss: 0.034318
 >> iter 98000, loss: 0.032818
 >> iter 99000, loss: 0.029882
 >> iter 100000, loss: 0.032103
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.368066
 >> iter 2000, loss: 4.375484
 >> iter 3000, loss: 1.688435
 >> iter 4000, loss: 0.666579
 >> iter 5000, loss: 0.294551
 >> iter 6000, loss: 0.141509
 >> iter 7000, loss: 0.086441
 >> iter 8000, loss: 0.061133
 >> iter 9000, loss: 0.074637
 >> iter 10000, loss: 0.082744
   Number of active neurons: 5
 >> iter 11000, loss: 0.073586
 >> iter 12000, loss: 0.063340
 >> iter 13000, loss: 0.051921
 >> iter 14000, loss: 0.041881
 >> iter 15000, loss: 0.057851
 >> iter 16000, loss: 0.071116
 >> iter 17000, loss: 0.069436
 >> iter 18000, loss: 0.059401
 >> iter 19000, loss: 0.047508
 >> iter 20000, loss: 0.044628
   Number of active neurons: 4
 >> iter 21000, loss: 0.041231
 >> iter 22000, loss: 0.041369
 >> iter 23000, loss: 0.047453
 >> iter 24000, loss: 0.046008
 >> iter 25000, loss: 0.060181
 >> iter 26000, loss: 0.040149
 >> iter 27000, loss: 0.041544
 >> iter 28000, loss: 0.043154
 >> iter 29000, loss: 0.038776
 >> iter 30000, loss: 0.043107
   Number of active neurons: 4
 >> iter 31000, loss: 0.054291
 >> iter 32000, loss: 0.047180
 >> iter 33000, loss: 0.070268
 >> iter 34000, loss: 0.062547
 >> iter 35000, loss: 0.056011
 >> iter 36000, loss: 0.049337
 >> iter 37000, loss: 0.040043
 >> iter 38000, loss: 0.050581
 >> iter 39000, loss: 0.043147
 >> iter 40000, loss: 0.059674
   Number of active neurons: 4
 >> iter 41000, loss: 0.042992
 >> iter 42000, loss: 0.041750
 >> iter 43000, loss: 0.058854
 >> iter 44000, loss: 0.052355
 >> iter 45000, loss: 0.060595
 >> iter 46000, loss: 0.044252
 >> iter 47000, loss: 0.053455
 >> iter 48000, loss: 0.044023
 >> iter 49000, loss: 0.044383
 >> iter 50000, loss: 0.049361
   Number of active neurons: 4
 >> iter 51000, loss: 0.045200
 >> iter 52000, loss: 0.042862
 >> iter 53000, loss: 0.049108
 >> iter 54000, loss: 0.058138
 >> iter 55000, loss: 0.071260
 >> iter 56000, loss: 0.048433
 >> iter 57000, loss: 0.046884
 >> iter 58000, loss: 0.042796
 >> iter 59000, loss: 0.032129
 >> iter 60000, loss: 0.041046
   Number of active neurons: 4
 >> iter 61000, loss: 0.037266
 >> iter 62000, loss: 0.048204
 >> iter 63000, loss: 0.070084
 >> iter 64000, loss: 0.060873
 >> iter 65000, loss: 0.037153
 >> iter 66000, loss: 0.053452
 >> iter 67000, loss: 0.041827
 >> iter 68000, loss: 0.091315
 >> iter 69000, loss: 0.062485
 >> iter 70000, loss: 0.048420
   Number of active neurons: 4
 >> iter 71000, loss: 0.040791
 >> iter 72000, loss: 0.050370
 >> iter 73000, loss: 0.053205
 >> iter 74000, loss: 0.070267
 >> iter 75000, loss: 0.050689
 >> iter 76000, loss: 0.043662
 >> iter 77000, loss: 0.051435
 >> iter 78000, loss: 0.041273
 >> iter 79000, loss: 0.048010
 >> iter 80000, loss: 0.064794
   Number of active neurons: 4
 >> iter 81000, loss: 0.046726
 >> iter 82000, loss: 0.036169
 >> iter 83000, loss: 0.053944
 >> iter 84000, loss: 0.061150
 >> iter 85000, loss: 0.049992
 >> iter 86000, loss: 0.063905
 >> iter 87000, loss: 0.060613
 >> iter 88000, loss: 0.048443
 >> iter 89000, loss: 0.045988
 >> iter 90000, loss: 0.037817
   Number of active neurons: 4
 >> iter 91000, loss: 0.042891
 >> iter 92000, loss: 0.040366
 >> iter 93000, loss: 0.048267
 >> iter 94000, loss: 0.038626
 >> iter 95000, loss: 0.035681
 >> iter 96000, loss: 0.052184
 >> iter 97000, loss: 0.051779
 >> iter 98000, loss: 0.039970
 >> iter 99000, loss: 0.032599
 >> iter 100000, loss: 0.045607
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455182
   Number of active neurons: 0
 >> iter 1000, loss: 11.337893
 >> iter 2000, loss: 4.354721
 >> iter 3000, loss: 1.688611
 >> iter 4000, loss: 0.670989
 >> iter 5000, loss: 0.309323
 >> iter 6000, loss: 0.150096
 >> iter 7000, loss: 0.107834
 >> iter 8000, loss: 0.077394
 >> iter 9000, loss: 0.071682
 >> iter 10000, loss: 0.056857
   Number of active neurons: 6
 >> iter 11000, loss: 0.053160
 >> iter 12000, loss: 0.091090
 >> iter 13000, loss: 0.064892
 >> iter 14000, loss: 0.054902
 >> iter 15000, loss: 0.059173
 >> iter 16000, loss: 0.059613
 >> iter 17000, loss: 0.047296
 >> iter 18000, loss: 0.040927
 >> iter 19000, loss: 0.053337
 >> iter 20000, loss: 0.048432
   Number of active neurons: 6
 >> iter 21000, loss: 0.039091
 >> iter 22000, loss: 0.037678
 >> iter 23000, loss: 0.075685
 >> iter 24000, loss: 0.051445
 >> iter 25000, loss: 0.061998
 >> iter 26000, loss: 0.060956
 >> iter 27000, loss: 0.048340
 >> iter 28000, loss: 0.036780
 >> iter 29000, loss: 0.058532
 >> iter 30000, loss: 0.049813
   Number of active neurons: 6
 >> iter 31000, loss: 0.055687
 >> iter 32000, loss: 0.046045
 >> iter 33000, loss: 0.051783
 >> iter 34000, loss: 0.046532
 >> iter 35000, loss: 0.053100
 >> iter 36000, loss: 0.044920
 >> iter 37000, loss: 0.061520
 >> iter 38000, loss: 0.057030
 >> iter 39000, loss: 0.040529
 >> iter 40000, loss: 0.071904
   Number of active neurons: 4
 >> iter 41000, loss: 0.061332
 >> iter 42000, loss: 0.042957
 >> iter 43000, loss: 0.065637
 >> iter 44000, loss: 0.046273
 >> iter 45000, loss: 0.049878
 >> iter 46000, loss: 0.055886
 >> iter 47000, loss: 0.047674
 >> iter 48000, loss: 0.047321
 >> iter 49000, loss: 0.044037
 >> iter 50000, loss: 0.068519
   Number of active neurons: 3
 >> iter 51000, loss: 0.060499
 >> iter 52000, loss: 0.047097
 >> iter 53000, loss: 0.047744
 >> iter 54000, loss: 0.049395
 >> iter 55000, loss: 0.053941
 >> iter 56000, loss: 0.063115
 >> iter 57000, loss: 0.047016
 >> iter 58000, loss: 0.036832
 >> iter 59000, loss: 0.045680
 >> iter 60000, loss: 0.059374
   Number of active neurons: 3
 >> iter 61000, loss: 0.042814
 >> iter 62000, loss: 0.060155
 >> iter 63000, loss: 0.063992
 >> iter 64000, loss: 0.078217
 >> iter 65000, loss: 0.068680
 >> iter 66000, loss: 0.061256
 >> iter 67000, loss: 0.055149
 >> iter 68000, loss: 0.043577
 >> iter 69000, loss: 0.049643
 >> iter 70000, loss: 0.039121
   Number of active neurons: 3
 >> iter 71000, loss: 0.038499
 >> iter 72000, loss: 0.046841
 >> iter 73000, loss: 0.066685
 >> iter 74000, loss: 0.042928
 >> iter 75000, loss: 0.050629
 >> iter 76000, loss: 0.054641
 >> iter 77000, loss: 0.047413
 >> iter 78000, loss: 0.035152
 >> iter 79000, loss: 0.035792
 >> iter 80000, loss: 0.037819
   Number of active neurons: 3
 >> iter 81000, loss: 0.059999
 >> iter 82000, loss: 0.076321
 >> iter 83000, loss: 0.057172
 >> iter 84000, loss: 0.045401
 >> iter 85000, loss: 0.053422
 >> iter 86000, loss: 0.041449
 >> iter 87000, loss: 0.060821
 >> iter 88000, loss: 0.059457
 >> iter 89000, loss: 0.046311
 >> iter 90000, loss: 0.043257
   Number of active neurons: 3
 >> iter 91000, loss: 0.045755
 >> iter 92000, loss: 0.046019
 >> iter 93000, loss: 0.043561
 >> iter 94000, loss: 0.053271
 >> iter 95000, loss: 0.034964
 >> iter 96000, loss: 0.047793
 >> iter 97000, loss: 0.044481
 >> iter 98000, loss: 0.058160
 >> iter 99000, loss: 0.061874
 >> iter 100000, loss: 0.055642
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.341863
 >> iter 2000, loss: 4.386059
 >> iter 3000, loss: 1.709185
 >> iter 4000, loss: 0.681223
 >> iter 5000, loss: 0.313011
 >> iter 6000, loss: 0.172564
 >> iter 7000, loss: 0.100607
 >> iter 8000, loss: 0.082748
 >> iter 9000, loss: 0.058869
 >> iter 10000, loss: 0.051512
   Number of active neurons: 5
 >> iter 11000, loss: 0.049624
 >> iter 12000, loss: 0.052629
 >> iter 13000, loss: 0.047885
 >> iter 14000, loss: 0.071304
 >> iter 15000, loss: 0.054935
 >> iter 16000, loss: 0.053413
 >> iter 17000, loss: 0.070496
 >> iter 18000, loss: 0.052684
 >> iter 19000, loss: 0.051435
 >> iter 20000, loss: 0.043080
   Number of active neurons: 5
 >> iter 21000, loss: 0.061224
 >> iter 22000, loss: 0.086707
 >> iter 23000, loss: 0.072007
 >> iter 24000, loss: 0.062596
 >> iter 25000, loss: 0.045618
 >> iter 26000, loss: 0.058200
 >> iter 27000, loss: 0.065027
 >> iter 28000, loss: 0.051683
 >> iter 29000, loss: 0.054174
 >> iter 30000, loss: 0.064626
   Number of active neurons: 5
 >> iter 31000, loss: 0.048318
 >> iter 32000, loss: 0.058108
 >> iter 33000, loss: 0.044067
 >> iter 34000, loss: 0.052231
 >> iter 35000, loss: 0.059039
 >> iter 36000, loss: 0.047259
 >> iter 37000, loss: 0.052381
 >> iter 38000, loss: 0.048417
 >> iter 39000, loss: 0.061337
 >> iter 40000, loss: 0.074756
   Number of active neurons: 5
 >> iter 41000, loss: 0.052025
 >> iter 42000, loss: 0.047368
 >> iter 43000, loss: 0.056594
 >> iter 44000, loss: 0.061424
 >> iter 45000, loss: 0.050037
 >> iter 46000, loss: 0.041870
 >> iter 47000, loss: 0.041705
 >> iter 48000, loss: 0.038172
 >> iter 49000, loss: 0.042327
 >> iter 50000, loss: 0.057648
   Number of active neurons: 3
 >> iter 51000, loss: 0.052188
 >> iter 52000, loss: 0.056410
 >> iter 53000, loss: 0.045201
 >> iter 54000, loss: 0.045344
 >> iter 55000, loss: 0.047773
 >> iter 56000, loss: 0.054085
 >> iter 57000, loss: 0.072694
 >> iter 58000, loss: 0.068538
 >> iter 59000, loss: 0.044628
 >> iter 60000, loss: 0.033006
   Number of active neurons: 3
 >> iter 61000, loss: 0.047677
 >> iter 62000, loss: 0.039488
 >> iter 63000, loss: 0.045167
 >> iter 64000, loss: 0.035019
 >> iter 65000, loss: 0.068968
 >> iter 66000, loss: 0.076582
 >> iter 67000, loss: 0.070622
 >> iter 68000, loss: 0.050207
 >> iter 69000, loss: 0.036371
 >> iter 70000, loss: 0.041123
   Number of active neurons: 3
 >> iter 71000, loss: 0.047162
 >> iter 72000, loss: 0.042243
 >> iter 73000, loss: 0.055270
 >> iter 74000, loss: 0.066826
 >> iter 75000, loss: 0.070402
 >> iter 76000, loss: 0.045314
 >> iter 77000, loss: 0.058211
 >> iter 78000, loss: 0.050030
 >> iter 79000, loss: 0.059835
 >> iter 80000, loss: 0.059235
   Number of active neurons: 3
 >> iter 81000, loss: 0.041126
 >> iter 82000, loss: 0.030061
 >> iter 83000, loss: 0.028938
 >> iter 84000, loss: 0.035226
 >> iter 85000, loss: 0.055450
 >> iter 86000, loss: 0.051253
 >> iter 87000, loss: 0.044871
 >> iter 88000, loss: 0.054214
 >> iter 89000, loss: 0.055403
 >> iter 90000, loss: 0.051422
   Number of active neurons: 3
 >> iter 91000, loss: 0.049248
 >> iter 92000, loss: 0.058625
 >> iter 93000, loss: 0.057246
 >> iter 94000, loss: 0.044902
 >> iter 95000, loss: 0.042640
 >> iter 96000, loss: 0.037713
 >> iter 97000, loss: 0.055668
 >> iter 98000, loss: 0.047417
 >> iter 99000, loss: 0.056666
 >> iter 100000, loss: 0.044033
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.449203
 >> iter 2000, loss: 4.429484
 >> iter 3000, loss: 1.729958
 >> iter 4000, loss: 0.700991
 >> iter 5000, loss: 0.333927
 >> iter 6000, loss: 0.153349
 >> iter 7000, loss: 0.107880
 >> iter 8000, loss: 0.075967
 >> iter 9000, loss: 0.057070
 >> iter 10000, loss: 0.057789
   Number of active neurons: 6
 >> iter 11000, loss: 0.045727
 >> iter 12000, loss: 0.052426
 >> iter 13000, loss: 0.049677
 >> iter 14000, loss: 0.048439
 >> iter 15000, loss: 0.049094
 >> iter 16000, loss: 0.065382
 >> iter 17000, loss: 0.062487
 >> iter 18000, loss: 0.063632
 >> iter 19000, loss: 0.063613
 >> iter 20000, loss: 0.047991
   Number of active neurons: 6
 >> iter 21000, loss: 0.054187
 >> iter 22000, loss: 0.037192
 >> iter 23000, loss: 0.057617
 >> iter 24000, loss: 0.046616
 >> iter 25000, loss: 0.066073
 >> iter 26000, loss: 0.043747
 >> iter 27000, loss: 0.040282
 >> iter 28000, loss: 0.046734
 >> iter 29000, loss: 0.051919
 >> iter 30000, loss: 0.057018
   Number of active neurons: 3
 >> iter 31000, loss: 0.059321
 >> iter 32000, loss: 0.056363
 >> iter 33000, loss: 0.046529
 >> iter 34000, loss: 0.034760
 >> iter 35000, loss: 0.033780
 >> iter 36000, loss: 0.043142
 >> iter 37000, loss: 0.049092
 >> iter 38000, loss: 0.036014
 >> iter 39000, loss: 0.051425
 >> iter 40000, loss: 0.048261
   Number of active neurons: 3
 >> iter 41000, loss: 0.046950
 >> iter 42000, loss: 0.047419
 >> iter 43000, loss: 0.055804
 >> iter 44000, loss: 0.047694
 >> iter 45000, loss: 0.041751
 >> iter 46000, loss: 0.065486
 >> iter 47000, loss: 0.057537
 >> iter 48000, loss: 0.056829
 >> iter 49000, loss: 0.065189
 >> iter 50000, loss: 0.041226
   Number of active neurons: 3
 >> iter 51000, loss: 0.031666
 >> iter 52000, loss: 0.042317
 >> iter 53000, loss: 0.036934
 >> iter 54000, loss: 0.048804
 >> iter 55000, loss: 0.067081
 >> iter 56000, loss: 0.066523
 >> iter 57000, loss: 0.055509
 >> iter 58000, loss: 0.043979
 >> iter 59000, loss: 0.043282
 >> iter 60000, loss: 0.059580
   Number of active neurons: 3
 >> iter 61000, loss: 0.045272
 >> iter 62000, loss: 0.039582
 >> iter 63000, loss: 0.035593
 >> iter 64000, loss: 0.059921
 >> iter 65000, loss: 0.059049
 >> iter 66000, loss: 0.042047
 >> iter 67000, loss: 0.051029
 >> iter 68000, loss: 0.068193
 >> iter 69000, loss: 0.045517
 >> iter 70000, loss: 0.046559
   Number of active neurons: 3
 >> iter 71000, loss: 0.043152
 >> iter 72000, loss: 0.069981
 >> iter 73000, loss: 0.057360
 >> iter 74000, loss: 0.059358
 >> iter 75000, loss: 0.043783
 >> iter 76000, loss: 0.046140
 >> iter 77000, loss: 0.041410
 >> iter 78000, loss: 0.049105
 >> iter 79000, loss: 0.039668
 >> iter 80000, loss: 0.047588
   Number of active neurons: 3
 >> iter 81000, loss: 0.038085
 >> iter 82000, loss: 0.070158
 >> iter 83000, loss: 0.062092
 >> iter 84000, loss: 0.045916
 >> iter 85000, loss: 0.034240
 >> iter 86000, loss: 0.039841
 >> iter 87000, loss: 0.052362
 >> iter 88000, loss: 0.043300
 >> iter 89000, loss: 0.048360
 >> iter 90000, loss: 0.037528
   Number of active neurons: 3
 >> iter 91000, loss: 0.038592
 >> iter 92000, loss: 0.061245
 >> iter 93000, loss: 0.052959
 >> iter 94000, loss: 0.058706
 >> iter 95000, loss: 0.043572
 >> iter 96000, loss: 0.047031
 >> iter 97000, loss: 0.071237
 >> iter 98000, loss: 0.056969
 >> iter 99000, loss: 0.054130
 >> iter 100000, loss: 0.038150
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

