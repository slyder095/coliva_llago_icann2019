 > Problema: tomita3nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.6
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.931746
 >> iter 2000, loss: 10.966544
 >> iter 3000, loss: 4.657647
 >> iter 4000, loss: 2.025392
 >> iter 5000, loss: 1.111242
 >> iter 6000, loss: 0.484906
 >> iter 7000, loss: 0.268934
 >> iter 8000, loss: 0.217014
 >> iter 9000, loss: 0.116322
 >> iter 10000, loss: 0.055668
   Number of active neurons: 10
 >> iter 11000, loss: 0.032539
 >> iter 12000, loss: 0.177734
 >> iter 13000, loss: 0.079259
 >> iter 14000, loss: 0.037685
 >> iter 15000, loss: 0.027152
 >> iter 16000, loss: 0.045018
 >> iter 17000, loss: 0.021675
 >> iter 18000, loss: 0.054740
 >> iter 19000, loss: 0.024590
 >> iter 20000, loss: 0.026769
   Number of active neurons: 10
 >> iter 21000, loss: 0.014943
 >> iter 22000, loss: 0.011761
 >> iter 23000, loss: 0.011276
 >> iter 24000, loss: 0.009347
 >> iter 25000, loss: 0.006660
 >> iter 26000, loss: 0.005528
 >> iter 27000, loss: 0.005511
 >> iter 28000, loss: 0.094195
 >> iter 29000, loss: 0.038147
 >> iter 30000, loss: 0.016886
   Number of active neurons: 10
 >> iter 31000, loss: 0.008737
 >> iter 32000, loss: 0.006042
 >> iter 33000, loss: 0.004370
 >> iter 34000, loss: 0.003789
 >> iter 35000, loss: 0.011786
 >> iter 36000, loss: 0.009098
 >> iter 37000, loss: 0.011076
 >> iter 38000, loss: 0.013047
 >> iter 39000, loss: 0.007165
 >> iter 40000, loss: 0.004989
   Number of active neurons: 10
 >> iter 41000, loss: 0.004067
 >> iter 42000, loss: 0.070916
 >> iter 43000, loss: 0.028155
 >> iter 44000, loss: 0.012106
 >> iter 45000, loss: 0.006061
 >> iter 46000, loss: 0.004125
 >> iter 47000, loss: 0.003193
 >> iter 48000, loss: 0.003158
 >> iter 49000, loss: 0.009778
 >> iter 50000, loss: 0.006521
   Number of active neurons: 10
 >> iter 51000, loss: 0.004905
 >> iter 52000, loss: 0.003125
 >> iter 53000, loss: 0.002310
 >> iter 54000, loss: 0.001987
 >> iter 55000, loss: 0.001828
 >> iter 56000, loss: 0.005667
 >> iter 57000, loss: 0.003549
 >> iter 58000, loss: 0.002403
 >> iter 59000, loss: 0.025696
 >> iter 60000, loss: 0.010645
   Number of active neurons: 10
 >> iter 61000, loss: 0.005196
 >> iter 62000, loss: 0.002941
 >> iter 63000, loss: 0.002293
 >> iter 64000, loss: 0.001760
 >> iter 65000, loss: 0.001569
 >> iter 66000, loss: 0.007350
 >> iter 67000, loss: 0.004164
 >> iter 68000, loss: 0.002605
 >> iter 69000, loss: 0.002012
 >> iter 70000, loss: 0.002124
   Number of active neurons: 10
 >> iter 71000, loss: 0.001697
 >> iter 72000, loss: 0.001467
 >> iter 73000, loss: 0.040992
 >> iter 74000, loss: 0.057114
 >> iter 75000, loss: 0.022150
 >> iter 76000, loss: 0.009129
 >> iter 77000, loss: 0.004246
 >> iter 78000, loss: 0.002761
 >> iter 79000, loss: 0.002188
 >> iter 80000, loss: 0.001669
   Number of active neurons: 10
 >> iter 81000, loss: 0.001435
 >> iter 82000, loss: 0.001259
 >> iter 83000, loss: 0.001274
 >> iter 84000, loss: 0.001570
 >> iter 85000, loss: 0.001387
 >> iter 86000, loss: 0.001220
 >> iter 87000, loss: 0.001438
 >> iter 88000, loss: 0.016653
 >> iter 89000, loss: 0.007414
 >> iter 90000, loss: 0.003669
   Number of active neurons: 10
 >> iter 91000, loss: 0.002259
 >> iter 92000, loss: 0.003168
 >> iter 93000, loss: 0.002375
 >> iter 94000, loss: 0.003493
 >> iter 95000, loss: 0.002242
 >> iter 96000, loss: 0.001565
 >> iter 97000, loss: 0.007580
 >> iter 98000, loss: 0.003716
 >> iter 99000, loss: 0.002165
 >> iter 100000, loss: 0.073219
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.841213
 >> iter 2000, loss: 11.005715
 >> iter 3000, loss: 5.538656
 >> iter 4000, loss: 2.588171
 >> iter 5000, loss: 1.372599
 >> iter 6000, loss: 0.729813
 >> iter 7000, loss: 0.402201
 >> iter 8000, loss: 0.291847
 >> iter 9000, loss: 0.264761
 >> iter 10000, loss: 0.231972
   Number of active neurons: 10
 >> iter 11000, loss: 0.107030
 >> iter 12000, loss: 0.179969
 >> iter 13000, loss: 0.106114
 >> iter 14000, loss: 0.182312
 >> iter 15000, loss: 0.081414
 >> iter 16000, loss: 0.040814
 >> iter 17000, loss: 0.023706
 >> iter 18000, loss: 0.086200
 >> iter 19000, loss: 0.189197
 >> iter 20000, loss: 0.104099
   Number of active neurons: 10
 >> iter 21000, loss: 0.155413
 >> iter 22000, loss: 0.067614
 >> iter 23000, loss: 0.195656
 >> iter 24000, loss: 0.093009
 >> iter 25000, loss: 0.093593
 >> iter 26000, loss: 0.041329
 >> iter 27000, loss: 0.051058
 >> iter 28000, loss: 0.025194
 >> iter 29000, loss: 0.013116
 >> iter 30000, loss: 0.012764
   Number of active neurons: 10
 >> iter 31000, loss: 0.008518
 >> iter 32000, loss: 0.025763
 >> iter 33000, loss: 0.013780
 >> iter 34000, loss: 0.007694
 >> iter 35000, loss: 0.006531
 >> iter 36000, loss: 0.021856
 >> iter 37000, loss: 0.023937
 >> iter 38000, loss: 0.012325
 >> iter 39000, loss: 0.027351
 >> iter 40000, loss: 0.109602
   Number of active neurons: 10
 >> iter 41000, loss: 0.044810
 >> iter 42000, loss: 0.020417
 >> iter 43000, loss: 0.011379
 >> iter 44000, loss: 0.020784
 >> iter 45000, loss: 0.010023
 >> iter 46000, loss: 0.009598
 >> iter 47000, loss: 0.007738
 >> iter 48000, loss: 0.004893
 >> iter 49000, loss: 0.027400
 >> iter 50000, loss: 0.011784
   Number of active neurons: 10
 >> iter 51000, loss: 0.006080
 >> iter 52000, loss: 0.003771
 >> iter 53000, loss: 0.002861
 >> iter 54000, loss: 0.002595
 >> iter 55000, loss: 0.008566
 >> iter 56000, loss: 0.032913
 >> iter 57000, loss: 0.096464
 >> iter 58000, loss: 0.043811
 >> iter 59000, loss: 0.037101
 >> iter 60000, loss: 0.016670
   Number of active neurons: 10
 >> iter 61000, loss: 0.179156
 >> iter 62000, loss: 0.070115
 >> iter 63000, loss: 0.058835
 >> iter 64000, loss: 0.024787
 >> iter 65000, loss: 0.011552
 >> iter 66000, loss: 0.064116
 >> iter 67000, loss: 0.025958
 >> iter 68000, loss: 0.011449
 >> iter 69000, loss: 0.029621
 >> iter 70000, loss: 0.033347
   Number of active neurons: 10
 >> iter 71000, loss: 0.044217
 >> iter 72000, loss: 0.022412
 >> iter 73000, loss: 0.034718
 >> iter 74000, loss: 0.137820
 >> iter 75000, loss: 0.055281
 >> iter 76000, loss: 0.023975
 >> iter 77000, loss: 0.010968
 >> iter 78000, loss: 0.006096
 >> iter 79000, loss: 0.015796
 >> iter 80000, loss: 0.011280
   Number of active neurons: 10
 >> iter 81000, loss: 0.015469
 >> iter 82000, loss: 0.009280
 >> iter 83000, loss: 0.018990
 >> iter 84000, loss: 0.017479
 >> iter 85000, loss: 0.008692
 >> iter 86000, loss: 0.004946
 >> iter 87000, loss: 0.011588
 >> iter 88000, loss: 0.007382
 >> iter 89000, loss: 0.004145
 >> iter 90000, loss: 0.002894
   Number of active neurons: 10
 >> iter 91000, loss: 0.014788
 >> iter 92000, loss: 0.012251
 >> iter 93000, loss: 0.006194
 >> iter 94000, loss: 0.007032
 >> iter 95000, loss: 0.003589
 >> iter 96000, loss: 0.002229
 >> iter 97000, loss: 0.001968
 >> iter 98000, loss: 0.001531
 >> iter 99000, loss: 0.001510
 >> iter 100000, loss: 0.003811
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.874688
 >> iter 2000, loss: 9.917010
 >> iter 3000, loss: 4.482995
 >> iter 4000, loss: 1.989075
 >> iter 5000, loss: 1.104564
 >> iter 6000, loss: 0.541373
 >> iter 7000, loss: 0.234402
 >> iter 8000, loss: 0.198624
 >> iter 9000, loss: 0.312288
 >> iter 10000, loss: 0.167728
   Number of active neurons: 10
 >> iter 11000, loss: 0.099232
 >> iter 12000, loss: 0.084532
 >> iter 13000, loss: 0.064487
 >> iter 14000, loss: 0.308062
 >> iter 15000, loss: 0.194916
 >> iter 16000, loss: 0.116532
 >> iter 17000, loss: 0.050227
 >> iter 18000, loss: 0.024253
 >> iter 19000, loss: 0.017522
 >> iter 20000, loss: 0.041056
   Number of active neurons: 10
 >> iter 21000, loss: 0.116795
 >> iter 22000, loss: 0.096645
 >> iter 23000, loss: 0.041051
 >> iter 24000, loss: 0.025858
 >> iter 25000, loss: 0.051408
 >> iter 26000, loss: 0.037334
 >> iter 27000, loss: 0.021943
 >> iter 28000, loss: 0.030120
 >> iter 29000, loss: 0.014743
 >> iter 30000, loss: 0.016062
   Number of active neurons: 10
 >> iter 31000, loss: 0.035664
 >> iter 32000, loss: 0.016167
 >> iter 33000, loss: 0.035347
 >> iter 34000, loss: 0.016042
 >> iter 35000, loss: 0.056681
 >> iter 36000, loss: 0.023643
 >> iter 37000, loss: 0.024919
 >> iter 38000, loss: 0.011698
 >> iter 39000, loss: 0.006459
 >> iter 40000, loss: 0.004166
   Number of active neurons: 10
 >> iter 41000, loss: 0.003417
 >> iter 42000, loss: 0.004509
 >> iter 43000, loss: 0.018350
 >> iter 44000, loss: 0.010754
 >> iter 45000, loss: 0.007660
 >> iter 46000, loss: 0.055057
 >> iter 47000, loss: 0.024052
 >> iter 48000, loss: 0.010679
 >> iter 49000, loss: 0.006616
 >> iter 50000, loss: 0.004061
   Number of active neurons: 10
 >> iter 51000, loss: 0.044139
 >> iter 52000, loss: 0.018616
 >> iter 53000, loss: 0.008742
 >> iter 54000, loss: 0.005144
 >> iter 55000, loss: 0.003160
 >> iter 56000, loss: 0.003125
 >> iter 57000, loss: 0.002833
 >> iter 58000, loss: 0.002365
 >> iter 59000, loss: 0.002353
 >> iter 60000, loss: 0.002374
   Number of active neurons: 10
 >> iter 61000, loss: 0.008421
 >> iter 62000, loss: 0.004303
 >> iter 63000, loss: 0.002773
 >> iter 64000, loss: 0.002046
 >> iter 65000, loss: 0.002207
 >> iter 66000, loss: 0.001733
 >> iter 67000, loss: 0.001625
 >> iter 68000, loss: 0.001529
 >> iter 69000, loss: 0.002224
 >> iter 70000, loss: 0.001779
   Number of active neurons: 10
 >> iter 71000, loss: 0.074230
 >> iter 72000, loss: 0.028348
 >> iter 73000, loss: 0.011422
 >> iter 74000, loss: 0.005197
 >> iter 75000, loss: 0.002656
 >> iter 76000, loss: 0.001849
 >> iter 77000, loss: 0.002119
 >> iter 78000, loss: 0.066337
 >> iter 79000, loss: 0.025909
 >> iter 80000, loss: 0.097639
   Number of active neurons: 10
 >> iter 81000, loss: 0.038561
 >> iter 82000, loss: 0.015932
 >> iter 83000, loss: 0.006963
 >> iter 84000, loss: 0.003808
 >> iter 85000, loss: 0.002701
 >> iter 86000, loss: 0.001890
 >> iter 87000, loss: 0.001562
 >> iter 88000, loss: 0.001675
 >> iter 89000, loss: 0.071879
 >> iter 90000, loss: 0.028256
   Number of active neurons: 10
 >> iter 91000, loss: 0.022773
 >> iter 92000, loss: 0.009667
 >> iter 93000, loss: 0.007276
 >> iter 94000, loss: 0.003661
 >> iter 95000, loss: 0.002186
 >> iter 96000, loss: 0.012377
 >> iter 97000, loss: 0.005485
 >> iter 98000, loss: 0.005028
 >> iter 99000, loss: 0.002952
 >> iter 100000, loss: 0.001876
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.046532
 >> iter 2000, loss: 11.401452
 >> iter 3000, loss: 4.781064
 >> iter 4000, loss: 1.865220
 >> iter 5000, loss: 0.791702
 >> iter 6000, loss: 0.344526
 >> iter 7000, loss: 0.206767
 >> iter 8000, loss: 0.123326
 >> iter 9000, loss: 0.368796
 >> iter 10000, loss: 0.174131
   Number of active neurons: 10
 >> iter 11000, loss: 0.072269
 >> iter 12000, loss: 0.077237
 >> iter 13000, loss: 0.143660
 >> iter 14000, loss: 0.141254
 >> iter 15000, loss: 0.059939
 >> iter 16000, loss: 0.027337
 >> iter 17000, loss: 0.042040
 >> iter 18000, loss: 0.027511
 >> iter 19000, loss: 0.017544
 >> iter 20000, loss: 0.025843
   Number of active neurons: 10
 >> iter 21000, loss: 0.012358
 >> iter 22000, loss: 0.007050
 >> iter 23000, loss: 0.004960
 >> iter 24000, loss: 0.004142
 >> iter 25000, loss: 0.003835
 >> iter 26000, loss: 0.003260
 >> iter 27000, loss: 0.002905
 >> iter 28000, loss: 0.002862
 >> iter 29000, loss: 0.002584
 >> iter 30000, loss: 0.002824
   Number of active neurons: 10
 >> iter 31000, loss: 0.002551
 >> iter 32000, loss: 0.002418
 >> iter 33000, loss: 0.002229
 >> iter 34000, loss: 0.002051
 >> iter 35000, loss: 0.001967
 >> iter 36000, loss: 0.001864
 >> iter 37000, loss: 0.001791
 >> iter 38000, loss: 0.001850
 >> iter 39000, loss: 0.002560
 >> iter 40000, loss: 0.003508
   Number of active neurons: 10
 >> iter 41000, loss: 0.005882
 >> iter 42000, loss: 0.003506
 >> iter 43000, loss: 0.002307
 >> iter 44000, loss: 0.001914
 >> iter 45000, loss: 0.021704
 >> iter 46000, loss: 0.009031
 >> iter 47000, loss: 0.090894
 >> iter 48000, loss: 0.055632
 >> iter 49000, loss: 0.021863
 >> iter 50000, loss: 0.022075
   Number of active neurons: 10
 >> iter 51000, loss: 0.014920
 >> iter 52000, loss: 0.035303
 >> iter 53000, loss: 0.015156
 >> iter 54000, loss: 0.007033
 >> iter 55000, loss: 0.006466
 >> iter 56000, loss: 0.003859
 >> iter 57000, loss: 0.076585
 >> iter 58000, loss: 0.029614
 >> iter 59000, loss: 0.012232
 >> iter 60000, loss: 0.005651
   Number of active neurons: 10
 >> iter 61000, loss: 0.003167
 >> iter 62000, loss: 0.008081
 >> iter 63000, loss: 0.004255
 >> iter 64000, loss: 0.002569
 >> iter 65000, loss: 0.001874
 >> iter 66000, loss: 0.001783
 >> iter 67000, loss: 0.001601
 >> iter 68000, loss: 0.001414
 >> iter 69000, loss: 0.001370
 >> iter 70000, loss: 0.001310
   Number of active neurons: 10
 >> iter 71000, loss: 0.001164
 >> iter 72000, loss: 0.001154
 >> iter 73000, loss: 0.001291
 >> iter 74000, loss: 0.001123
 >> iter 75000, loss: 0.001198
 >> iter 76000, loss: 0.001055
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.958336
 >> iter 2000, loss: 10.792065
 >> iter 3000, loss: 4.544345
 >> iter 4000, loss: 1.794789
 >> iter 5000, loss: 0.760331
 >> iter 6000, loss: 0.345394
 >> iter 7000, loss: 0.170360
 >> iter 8000, loss: 0.247466
 >> iter 9000, loss: 0.104097
 >> iter 10000, loss: 0.158268
   Number of active neurons: 10
 >> iter 11000, loss: 0.069310
 >> iter 12000, loss: 0.043483
 >> iter 13000, loss: 0.026552
 >> iter 14000, loss: 0.062406
 >> iter 15000, loss: 0.029955
 >> iter 16000, loss: 0.065348
 >> iter 17000, loss: 0.029670
 >> iter 18000, loss: 0.015377
 >> iter 19000, loss: 0.010540
 >> iter 20000, loss: 0.008769
   Number of active neurons: 10
 >> iter 21000, loss: 0.006757
 >> iter 22000, loss: 0.005711
 >> iter 23000, loss: 0.005266
 >> iter 24000, loss: 0.004720
 >> iter 25000, loss: 0.004510
 >> iter 26000, loss: 0.004241
 >> iter 27000, loss: 0.057557
 >> iter 28000, loss: 0.024774
 >> iter 29000, loss: 0.011826
 >> iter 30000, loss: 0.006947
   Number of active neurons: 10
 >> iter 31000, loss: 0.016845
 >> iter 32000, loss: 0.010549
 >> iter 33000, loss: 0.008310
 >> iter 34000, loss: 0.005079
 >> iter 35000, loss: 0.025280
 >> iter 36000, loss: 0.013931
 >> iter 37000, loss: 0.020568
 >> iter 38000, loss: 0.009657
 >> iter 39000, loss: 0.005481
 >> iter 40000, loss: 0.008006
   Number of active neurons: 10
 >> iter 41000, loss: 0.004725
 >> iter 42000, loss: 0.003561
 >> iter 43000, loss: 0.003383
 >> iter 44000, loss: 0.034559
 >> iter 45000, loss: 0.117279
 >> iter 46000, loss: 0.045998
 >> iter 47000, loss: 0.019180
 >> iter 48000, loss: 0.009197
 >> iter 49000, loss: 0.005009
 >> iter 50000, loss: 0.003532
   Number of active neurons: 10
 >> iter 51000, loss: 0.002738
 >> iter 52000, loss: 0.002415
 >> iter 53000, loss: 0.002288
 >> iter 54000, loss: 0.002110
 >> iter 55000, loss: 0.002362
 >> iter 56000, loss: 0.004535
 >> iter 57000, loss: 0.003065
 >> iter 58000, loss: 0.002351
 >> iter 59000, loss: 0.002612
 >> iter 60000, loss: 0.098169
   Number of active neurons: 10
 >> iter 61000, loss: 0.038074
 >> iter 62000, loss: 0.016895
 >> iter 63000, loss: 0.007736
 >> iter 64000, loss: 0.004493
 >> iter 65000, loss: 0.002981
 >> iter 66000, loss: 0.002309
 >> iter 67000, loss: 0.002790
 >> iter 68000, loss: 0.002502
 >> iter 69000, loss: 0.001999
 >> iter 70000, loss: 0.002014
   Number of active neurons: 10
 >> iter 71000, loss: 0.001768
 >> iter 72000, loss: 0.001618
 >> iter 73000, loss: 0.001568
 >> iter 74000, loss: 0.001509
 >> iter 75000, loss: 0.073272
 >> iter 76000, loss: 0.040523
 >> iter 77000, loss: 0.016066
 >> iter 78000, loss: 0.006968
 >> iter 79000, loss: 0.066353
 >> iter 80000, loss: 0.025568
   Number of active neurons: 10
 >> iter 81000, loss: 0.010560
 >> iter 82000, loss: 0.004976
 >> iter 83000, loss: 0.002893
 >> iter 84000, loss: 0.002062
 >> iter 85000, loss: 0.001872
 >> iter 86000, loss: 0.001662
 >> iter 87000, loss: 0.001548
 >> iter 88000, loss: 0.014678
 >> iter 89000, loss: 0.006736
 >> iter 90000, loss: 0.003476
   Number of active neurons: 10
 >> iter 91000, loss: 0.002417
 >> iter 92000, loss: 0.002628
 >> iter 93000, loss: 0.003255
 >> iter 94000, loss: 0.002393
 >> iter 95000, loss: 0.002270
 >> iter 96000, loss: 0.001660
 >> iter 97000, loss: 0.001477
 >> iter 98000, loss: 0.001458
 >> iter 99000, loss: 0.001420
 >> iter 100000, loss: 0.001273
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.858883
 >> iter 2000, loss: 9.887268
 >> iter 3000, loss: 4.403448
 >> iter 4000, loss: 1.985797
 >> iter 5000, loss: 0.936694
 >> iter 6000, loss: 0.428799
 >> iter 7000, loss: 0.182347
 >> iter 8000, loss: 0.134190
 >> iter 9000, loss: 0.065349
 >> iter 10000, loss: 0.245841
   Number of active neurons: 10
 >> iter 11000, loss: 0.109575
 >> iter 12000, loss: 0.066991
 >> iter 13000, loss: 0.113580
 >> iter 14000, loss: 0.068269
 >> iter 15000, loss: 0.035167
 >> iter 16000, loss: 0.039251
 >> iter 17000, loss: 0.031562
 >> iter 18000, loss: 0.046669
 >> iter 19000, loss: 0.027938
 >> iter 20000, loss: 0.015398
   Number of active neurons: 10
 >> iter 21000, loss: 0.016675
 >> iter 22000, loss: 0.010343
 >> iter 23000, loss: 0.025372
 >> iter 24000, loss: 0.013556
 >> iter 25000, loss: 0.014560
 >> iter 26000, loss: 0.009572
 >> iter 27000, loss: 0.036666
 >> iter 28000, loss: 0.018245
 >> iter 29000, loss: 0.022842
 >> iter 30000, loss: 0.036173
   Number of active neurons: 10
 >> iter 31000, loss: 0.030937
 >> iter 32000, loss: 0.014528
 >> iter 33000, loss: 0.007841
 >> iter 34000, loss: 0.005188
 >> iter 35000, loss: 0.004388
 >> iter 36000, loss: 0.004880
 >> iter 37000, loss: 0.021916
 >> iter 38000, loss: 0.014323
 >> iter 39000, loss: 0.024278
 >> iter 40000, loss: 0.011010
   Number of active neurons: 10
 >> iter 41000, loss: 0.027715
 >> iter 42000, loss: 0.012326
 >> iter 43000, loss: 0.006503
 >> iter 44000, loss: 0.006145
 >> iter 45000, loss: 0.004004
 >> iter 46000, loss: 0.003089
 >> iter 47000, loss: 0.004234
 >> iter 48000, loss: 0.003131
 >> iter 49000, loss: 0.002648
 >> iter 50000, loss: 0.002453
   Number of active neurons: 10
 >> iter 51000, loss: 0.003562
 >> iter 52000, loss: 0.002754
 >> iter 53000, loss: 0.002384
 >> iter 54000, loss: 0.002207
 >> iter 55000, loss: 0.002436
 >> iter 56000, loss: 0.002087
 >> iter 57000, loss: 0.001976
 >> iter 58000, loss: 0.001980
 >> iter 59000, loss: 0.001804
 >> iter 60000, loss: 0.001973
   Number of active neurons: 10
 >> iter 61000, loss: 0.001911
 >> iter 62000, loss: 0.001805
 >> iter 63000, loss: 0.002605
 >> iter 64000, loss: 0.003564
 >> iter 65000, loss: 0.002448
 >> iter 66000, loss: 0.002622
 >> iter 67000, loss: 0.001902
 >> iter 68000, loss: 0.001775
 >> iter 69000, loss: 0.001609
 >> iter 70000, loss: 0.022986
   Number of active neurons: 10
 >> iter 71000, loss: 0.009599
 >> iter 72000, loss: 0.006321
 >> iter 73000, loss: 0.003411
 >> iter 74000, loss: 0.002231
 >> iter 75000, loss: 0.001735
 >> iter 76000, loss: 0.001534
 >> iter 77000, loss: 0.001455
 >> iter 78000, loss: 0.001375
 >> iter 79000, loss: 0.010559
 >> iter 80000, loss: 0.005068
   Number of active neurons: 10
 >> iter 81000, loss: 0.010415
 >> iter 82000, loss: 0.009013
 >> iter 83000, loss: 0.004258
 >> iter 84000, loss: 0.004206
 >> iter 85000, loss: 0.003069
 >> iter 86000, loss: 0.002140
 >> iter 87000, loss: 0.001687
 >> iter 88000, loss: 0.001507
 >> iter 89000, loss: 0.001466
 >> iter 90000, loss: 0.001349
   Number of active neurons: 10
 >> iter 91000, loss: 0.055792
 >> iter 92000, loss: 0.021908
 >> iter 93000, loss: 0.016423
 >> iter 94000, loss: 0.006951
 >> iter 95000, loss: 0.011700
 >> iter 96000, loss: 0.005081
 >> iter 97000, loss: 0.002813
 >> iter 98000, loss: 0.001796
 >> iter 99000, loss: 0.001383
 >> iter 100000, loss: 0.001185
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.659520
 >> iter 2000, loss: 10.387125
 >> iter 3000, loss: 4.819917
 >> iter 4000, loss: 2.461294
 >> iter 5000, loss: 1.121457
 >> iter 6000, loss: 0.604054
 >> iter 7000, loss: 0.417131
 >> iter 8000, loss: 0.179610
 >> iter 9000, loss: 0.159884
 >> iter 10000, loss: 0.148038
   Number of active neurons: 10
 >> iter 11000, loss: 0.296820
 >> iter 12000, loss: 0.254493
 >> iter 13000, loss: 0.268399
 >> iter 14000, loss: 0.118398
 >> iter 15000, loss: 0.143191
 >> iter 16000, loss: 0.098359
 >> iter 17000, loss: 0.067470
 >> iter 18000, loss: 0.160750
 >> iter 19000, loss: 0.067730
 >> iter 20000, loss: 0.128611
   Number of active neurons: 10
 >> iter 21000, loss: 0.054072
 >> iter 22000, loss: 0.079331
 >> iter 23000, loss: 0.124791
 >> iter 24000, loss: 0.054998
 >> iter 25000, loss: 0.026438
 >> iter 26000, loss: 0.015384
 >> iter 27000, loss: 0.009840
 >> iter 28000, loss: 0.007058
 >> iter 29000, loss: 0.026282
 >> iter 30000, loss: 0.013478
   Number of active neurons: 10
 >> iter 31000, loss: 0.035907
 >> iter 32000, loss: 0.077181
 >> iter 33000, loss: 0.192620
 >> iter 34000, loss: 0.077167
 >> iter 35000, loss: 0.078184
 >> iter 36000, loss: 0.034534
 >> iter 37000, loss: 0.030964
 >> iter 38000, loss: 0.015567
 >> iter 39000, loss: 0.008886
 >> iter 40000, loss: 0.023129
   Number of active neurons: 10
 >> iter 41000, loss: 0.049383
 >> iter 42000, loss: 0.069409
 >> iter 43000, loss: 0.067029
 >> iter 44000, loss: 0.069844
 >> iter 45000, loss: 0.040814
 >> iter 46000, loss: 0.019575
 >> iter 47000, loss: 0.010939
 >> iter 48000, loss: 0.012638
 >> iter 49000, loss: 0.007935
 >> iter 50000, loss: 0.075784
   Number of active neurons: 10
 >> iter 51000, loss: 0.031905
 >> iter 52000, loss: 0.014803
 >> iter 53000, loss: 0.018544
 >> iter 54000, loss: 0.013156
 >> iter 55000, loss: 0.033212
 >> iter 56000, loss: 0.014099
 >> iter 57000, loss: 0.013763
 >> iter 58000, loss: 0.007088
 >> iter 59000, loss: 0.004310
 >> iter 60000, loss: 0.005861
   Number of active neurons: 10
 >> iter 61000, loss: 0.003858
 >> iter 62000, loss: 0.004083
 >> iter 63000, loss: 0.004027
 >> iter 64000, loss: 0.003302
 >> iter 65000, loss: 0.003967
 >> iter 66000, loss: 0.004234
 >> iter 67000, loss: 0.002726
 >> iter 68000, loss: 0.002588
 >> iter 69000, loss: 0.002132
 >> iter 70000, loss: 0.001878
   Number of active neurons: 10
 >> iter 71000, loss: 0.031347
 >> iter 72000, loss: 0.013054
 >> iter 73000, loss: 0.010418
 >> iter 74000, loss: 0.004910
 >> iter 75000, loss: 0.030749
 >> iter 76000, loss: 0.012615
 >> iter 77000, loss: 0.007180
 >> iter 78000, loss: 0.008246
 >> iter 79000, loss: 0.012441
 >> iter 80000, loss: 0.014034
   Number of active neurons: 10
 >> iter 81000, loss: 0.006334
 >> iter 82000, loss: 0.035337
 >> iter 83000, loss: 0.015030
 >> iter 84000, loss: 0.006777
 >> iter 85000, loss: 0.103679
 >> iter 86000, loss: 0.044824
 >> iter 87000, loss: 0.017985
 >> iter 88000, loss: 0.009412
 >> iter 89000, loss: 0.009801
 >> iter 90000, loss: 0.017658
   Number of active neurons: 10
 >> iter 91000, loss: 0.048169
 >> iter 92000, loss: 0.019694
 >> iter 93000, loss: 0.102694
 >> iter 94000, loss: 0.041452
 >> iter 95000, loss: 0.017577
 >> iter 96000, loss: 0.007760
 >> iter 97000, loss: 0.004063
 >> iter 98000, loss: 0.002476
 >> iter 99000, loss: 0.002380
 >> iter 100000, loss: 0.001943
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.908438
 >> iter 2000, loss: 10.059832
 >> iter 3000, loss: 4.571210
 >> iter 4000, loss: 1.842074
 >> iter 5000, loss: 0.767078
 >> iter 6000, loss: 0.327815
 >> iter 7000, loss: 0.165971
 >> iter 8000, loss: 0.180148
 >> iter 9000, loss: 0.077023
 >> iter 10000, loss: 0.036282
   Number of active neurons: 10
 >> iter 11000, loss: 0.139282
 >> iter 12000, loss: 0.158093
 >> iter 13000, loss: 0.066985
 >> iter 14000, loss: 0.031692
 >> iter 15000, loss: 0.016426
 >> iter 16000, loss: 0.013579
 >> iter 17000, loss: 0.009324
 >> iter 18000, loss: 0.007271
 >> iter 19000, loss: 0.039102
 >> iter 20000, loss: 0.018477
   Number of active neurons: 10
 >> iter 21000, loss: 0.009943
 >> iter 22000, loss: 0.058020
 >> iter 23000, loss: 0.026675
 >> iter 24000, loss: 0.018583
 >> iter 25000, loss: 0.009425
 >> iter 26000, loss: 0.006347
 >> iter 27000, loss: 0.004493
 >> iter 28000, loss: 0.004004
 >> iter 29000, loss: 0.004213
 >> iter 30000, loss: 0.003459
   Number of active neurons: 10
 >> iter 31000, loss: 0.004617
 >> iter 32000, loss: 0.003615
 >> iter 33000, loss: 0.004176
 >> iter 34000, loss: 0.003140
 >> iter 35000, loss: 0.002684
 >> iter 36000, loss: 0.002613
 >> iter 37000, loss: 0.002275
 >> iter 38000, loss: 0.002092
 >> iter 39000, loss: 0.001978
 >> iter 40000, loss: 0.001871
   Number of active neurons: 10
 >> iter 41000, loss: 0.001917
 >> iter 42000, loss: 0.001970
 >> iter 43000, loss: 0.001747
 >> iter 44000, loss: 0.002117
 >> iter 45000, loss: 0.002257
 >> iter 46000, loss: 0.002061
 >> iter 47000, loss: 0.035801
 >> iter 48000, loss: 0.062311
 >> iter 49000, loss: 0.024298
 >> iter 50000, loss: 0.010375
   Number of active neurons: 10
 >> iter 51000, loss: 0.086926
 >> iter 52000, loss: 0.033559
 >> iter 53000, loss: 0.065012
 >> iter 54000, loss: 0.025813
 >> iter 55000, loss: 0.011008
 >> iter 56000, loss: 0.005335
 >> iter 57000, loss: 0.004618
 >> iter 58000, loss: 0.004599
 >> iter 59000, loss: 0.003156
 >> iter 60000, loss: 0.031897
   Number of active neurons: 10
 >> iter 61000, loss: 0.013014
 >> iter 62000, loss: 0.042253
 >> iter 63000, loss: 0.022261
 >> iter 64000, loss: 0.009622
 >> iter 65000, loss: 0.005094
 >> iter 66000, loss: 0.003465
 >> iter 67000, loss: 0.002551
 >> iter 68000, loss: 0.001982
 >> iter 69000, loss: 0.001669
 >> iter 70000, loss: 0.002097
   Number of active neurons: 10
 >> iter 71000, loss: 0.009034
 >> iter 72000, loss: 0.004670
 >> iter 73000, loss: 0.002714
 >> iter 74000, loss: 0.001889
 >> iter 75000, loss: 0.001977
 >> iter 76000, loss: 0.001702
 >> iter 77000, loss: 0.001724
 >> iter 78000, loss: 0.001381
 >> iter 79000, loss: 0.001451
 >> iter 80000, loss: 0.001316
   Number of active neurons: 10
 >> iter 81000, loss: 0.001200
 >> iter 82000, loss: 0.001491
 >> iter 83000, loss: 0.001495
 >> iter 84000, loss: 0.077849
 >> iter 85000, loss: 0.029594
 >> iter 86000, loss: 0.011636
 >> iter 87000, loss: 0.026697
 >> iter 88000, loss: 0.010764
 >> iter 89000, loss: 0.004885
 >> iter 90000, loss: 0.003781
   Number of active neurons: 10
 >> iter 91000, loss: 0.002225
 >> iter 92000, loss: 0.001578
 >> iter 93000, loss: 0.001265
 >> iter 94000, loss: 0.001226
 >> iter 95000, loss: 0.001125
 >> iter 96000, loss: 0.001151
 >> iter 97000, loss: 0.001120
 >> iter 98000, loss: 0.001038
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 19.095495
 >> iter 2000, loss: 9.675328
 >> iter 3000, loss: 3.937554
 >> iter 4000, loss: 1.517531
 >> iter 5000, loss: 0.593122
 >> iter 6000, loss: 0.281404
 >> iter 7000, loss: 0.114761
 >> iter 8000, loss: 0.051082
 >> iter 9000, loss: 0.140452
 >> iter 10000, loss: 0.059622
   Number of active neurons: 10
 >> iter 11000, loss: 0.137503
 >> iter 12000, loss: 0.079237
 >> iter 13000, loss: 0.070678
 >> iter 14000, loss: 0.038985
 >> iter 15000, loss: 0.019312
 >> iter 16000, loss: 0.035289
 >> iter 17000, loss: 0.017364
 >> iter 18000, loss: 0.010398
 >> iter 19000, loss: 0.006809
 >> iter 20000, loss: 0.005201
   Number of active neurons: 10
 >> iter 21000, loss: 0.004504
 >> iter 22000, loss: 0.011946
 >> iter 23000, loss: 0.119633
 >> iter 24000, loss: 0.051961
 >> iter 25000, loss: 0.021983
 >> iter 26000, loss: 0.011919
 >> iter 27000, loss: 0.028976
 >> iter 28000, loss: 0.162827
 >> iter 29000, loss: 0.063626
 >> iter 30000, loss: 0.025813
   Number of active neurons: 10
 >> iter 31000, loss: 0.014401
 >> iter 32000, loss: 0.007425
 >> iter 33000, loss: 0.004559
 >> iter 34000, loss: 0.033567
 >> iter 35000, loss: 0.018474
 >> iter 36000, loss: 0.008808
 >> iter 37000, loss: 0.004904
 >> iter 38000, loss: 0.003566
 >> iter 39000, loss: 0.030406
 >> iter 40000, loss: 0.014412
   Number of active neurons: 10
 >> iter 41000, loss: 0.012402
 >> iter 42000, loss: 0.006198
 >> iter 43000, loss: 0.003708
 >> iter 44000, loss: 0.002597
 >> iter 45000, loss: 0.002194
 >> iter 46000, loss: 0.001982
 >> iter 47000, loss: 0.002199
 >> iter 48000, loss: 0.001984
 >> iter 49000, loss: 0.001821
 >> iter 50000, loss: 0.001662
   Number of active neurons: 10
 >> iter 51000, loss: 0.001961
 >> iter 52000, loss: 0.001652
 >> iter 53000, loss: 0.001472
 >> iter 54000, loss: 0.001415
 >> iter 55000, loss: 0.001815
 >> iter 56000, loss: 0.001767
 >> iter 57000, loss: 0.001517
 >> iter 58000, loss: 0.001586
 >> iter 59000, loss: 0.038146
 >> iter 60000, loss: 0.048816
   Number of active neurons: 10
 >> iter 61000, loss: 0.033927
 >> iter 62000, loss: 0.013785
 >> iter 63000, loss: 0.006211
 >> iter 64000, loss: 0.003196
 >> iter 65000, loss: 0.002088
 >> iter 66000, loss: 0.001575
 >> iter 67000, loss: 0.001361
 >> iter 68000, loss: 0.001229
 >> iter 69000, loss: 0.001177
 >> iter 70000, loss: 0.001123
   Number of active neurons: 10
 >> iter 71000, loss: 0.001142
 >> iter 72000, loss: 0.001040
 >> iter 73000, loss: 0.001059
 >> iter 74000, loss: 0.001052
 >> iter 75000, loss: 0.001031
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.785586
 >> iter 2000, loss: 10.273813
 >> iter 3000, loss: 5.247439
 >> iter 4000, loss: 2.569804
 >> iter 5000, loss: 1.134849
 >> iter 6000, loss: 0.740800
 >> iter 7000, loss: 0.404104
 >> iter 8000, loss: 0.275823
 >> iter 9000, loss: 0.338533
 >> iter 10000, loss: 0.266135
   Number of active neurons: 10
 >> iter 11000, loss: 0.455161
 >> iter 12000, loss: 0.330565
 >> iter 13000, loss: 0.227244
 >> iter 14000, loss: 0.104054
 >> iter 15000, loss: 0.051977
 >> iter 16000, loss: 0.048132
 >> iter 17000, loss: 0.025640
 >> iter 18000, loss: 0.140303
 >> iter 19000, loss: 0.065671
 >> iter 20000, loss: 0.040473
   Number of active neurons: 10
 >> iter 21000, loss: 0.021590
 >> iter 22000, loss: 0.108099
 >> iter 23000, loss: 0.110344
 >> iter 24000, loss: 0.054925
 >> iter 25000, loss: 0.113542
 >> iter 26000, loss: 0.062437
 >> iter 27000, loss: 0.041127
 >> iter 28000, loss: 0.021485
 >> iter 29000, loss: 0.030798
 >> iter 30000, loss: 0.014447
   Number of active neurons: 10
 >> iter 31000, loss: 0.007720
 >> iter 32000, loss: 0.007450
 >> iter 33000, loss: 0.012275
 >> iter 34000, loss: 0.006511
 >> iter 35000, loss: 0.016685
 >> iter 36000, loss: 0.008976
 >> iter 37000, loss: 0.023858
 >> iter 38000, loss: 0.014130
 >> iter 39000, loss: 0.077430
 >> iter 40000, loss: 0.034917
   Number of active neurons: 10
 >> iter 41000, loss: 0.016985
 >> iter 42000, loss: 0.007855
 >> iter 43000, loss: 0.004256
 >> iter 44000, loss: 0.017136
 >> iter 45000, loss: 0.007677
 >> iter 46000, loss: 0.004813
 >> iter 47000, loss: 0.003345
 >> iter 48000, loss: 0.023250
 >> iter 49000, loss: 0.011996
 >> iter 50000, loss: 0.006107
   Number of active neurons: 10
 >> iter 51000, loss: 0.003502
 >> iter 52000, loss: 0.003137
 >> iter 53000, loss: 0.002487
 >> iter 54000, loss: 0.002428
 >> iter 55000, loss: 0.003368
 >> iter 56000, loss: 0.022583
 >> iter 57000, loss: 0.009266
 >> iter 58000, loss: 0.019073
 >> iter 59000, loss: 0.008596
 >> iter 60000, loss: 0.026454
   Number of active neurons: 10
 >> iter 61000, loss: 0.013221
 >> iter 62000, loss: 0.005853
 >> iter 63000, loss: 0.038154
 >> iter 64000, loss: 0.027010
 >> iter 65000, loss: 0.165681
 >> iter 66000, loss: 0.110158
 >> iter 67000, loss: 0.042426
 >> iter 68000, loss: 0.016971
 >> iter 69000, loss: 0.008137
 >> iter 70000, loss: 0.005351
   Number of active neurons: 10
 >> iter 71000, loss: 0.026026
 >> iter 72000, loss: 0.019787
 >> iter 73000, loss: 0.010137
 >> iter 74000, loss: 0.021898
 >> iter 75000, loss: 0.062929
 >> iter 76000, loss: 0.026334
 >> iter 77000, loss: 0.011501
 >> iter 78000, loss: 0.142333
 >> iter 79000, loss: 0.057843
 >> iter 80000, loss: 0.022792
   Number of active neurons: 10
 >> iter 81000, loss: 0.010216
 >> iter 82000, loss: 0.005053
 >> iter 83000, loss: 0.010874
 >> iter 84000, loss: 0.005182
 >> iter 85000, loss: 0.003048
 >> iter 86000, loss: 0.002155
 >> iter 87000, loss: 0.002244
 >> iter 88000, loss: 0.001862
 >> iter 89000, loss: 0.002071
 >> iter 90000, loss: 0.001680
   Number of active neurons: 10
 >> iter 91000, loss: 0.031208
 >> iter 92000, loss: 0.044270
 >> iter 93000, loss: 0.018522
 >> iter 94000, loss: 0.009364
 >> iter 95000, loss: 0.007859
 >> iter 96000, loss: 0.003944
 >> iter 97000, loss: 0.002388
 >> iter 98000, loss: 0.001734
 >> iter 99000, loss: 0.001435
 >> iter 100000, loss: 0.001405
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.791342
 >> iter 2000, loss: 10.206829
 >> iter 3000, loss: 4.242362
 >> iter 4000, loss: 1.706295
 >> iter 5000, loss: 0.678743
 >> iter 6000, loss: 0.276874
 >> iter 7000, loss: 0.121766
 >> iter 8000, loss: 0.118184
 >> iter 9000, loss: 0.130804
 >> iter 10000, loss: 0.205888
   Number of active neurons: 10
 >> iter 11000, loss: 0.120577
 >> iter 12000, loss: 0.051523
 >> iter 13000, loss: 0.025060
 >> iter 14000, loss: 0.019682
 >> iter 15000, loss: 0.022795
 >> iter 16000, loss: 0.012328
 >> iter 17000, loss: 0.027191
 >> iter 18000, loss: 0.051823
 >> iter 19000, loss: 0.097221
 >> iter 20000, loss: 0.085469
   Number of active neurons: 10
 >> iter 21000, loss: 0.035598
 >> iter 22000, loss: 0.016588
 >> iter 23000, loss: 0.009046
 >> iter 24000, loss: 0.005884
 >> iter 25000, loss: 0.039686
 >> iter 26000, loss: 0.029595
 >> iter 27000, loss: 0.021776
 >> iter 28000, loss: 0.039973
 >> iter 29000, loss: 0.047993
 >> iter 30000, loss: 0.193221
   Number of active neurons: 10
 >> iter 31000, loss: 0.090394
 >> iter 32000, loss: 0.048816
 >> iter 33000, loss: 0.027950
 >> iter 34000, loss: 0.013349
 >> iter 35000, loss: 0.009077
 >> iter 36000, loss: 0.006165
 >> iter 37000, loss: 0.004460
 >> iter 38000, loss: 0.003667
 >> iter 39000, loss: 0.003434
 >> iter 40000, loss: 0.002999
   Number of active neurons: 10
 >> iter 41000, loss: 0.002784
 >> iter 42000, loss: 0.002557
 >> iter 43000, loss: 0.002385
 >> iter 44000, loss: 0.002699
 >> iter 45000, loss: 0.103963
 >> iter 46000, loss: 0.041146
 >> iter 47000, loss: 0.016945
 >> iter 48000, loss: 0.009750
 >> iter 49000, loss: 0.005149
 >> iter 50000, loss: 0.003611
   Number of active neurons: 10
 >> iter 51000, loss: 0.002696
 >> iter 52000, loss: 0.002309
 >> iter 53000, loss: 0.002316
 >> iter 54000, loss: 0.002013
 >> iter 55000, loss: 0.003142
 >> iter 56000, loss: 0.002426
 >> iter 57000, loss: 0.001995
 >> iter 58000, loss: 0.009346
 >> iter 59000, loss: 0.004682
 >> iter 60000, loss: 0.002804
   Number of active neurons: 10
 >> iter 61000, loss: 0.002058
 >> iter 62000, loss: 0.001713
 >> iter 63000, loss: 0.001542
 >> iter 64000, loss: 0.001482
 >> iter 65000, loss: 0.001470
 >> iter 66000, loss: 0.001735
 >> iter 67000, loss: 0.001866
 >> iter 68000, loss: 0.001469
 >> iter 69000, loss: 0.001345
 >> iter 70000, loss: 0.001278
   Number of active neurons: 10
 >> iter 71000, loss: 0.001217
 >> iter 72000, loss: 0.001185
 >> iter 73000, loss: 0.001170
 >> iter 74000, loss: 0.008443
 >> iter 75000, loss: 0.004261
 >> iter 76000, loss: 0.002409
 >> iter 77000, loss: 0.001589
 >> iter 78000, loss: 0.001274
 >> iter 79000, loss: 0.001209
 >> iter 80000, loss: 0.001140
   Number of active neurons: 10
 >> iter 81000, loss: 0.001145
 >> iter 82000, loss: 0.001078
 >> iter 83000, loss: 0.001952
 >> iter 84000, loss: 0.001421
 >> iter 85000, loss: 0.001676
 >> iter 86000, loss: 0.001326
 >> iter 87000, loss: 0.001077
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.350836
 >> iter 2000, loss: 11.047564
 >> iter 3000, loss: 4.812090
 >> iter 4000, loss: 1.944264
 >> iter 5000, loss: 0.889617
 >> iter 6000, loss: 0.521038
 >> iter 7000, loss: 0.283097
 >> iter 8000, loss: 0.120360
 >> iter 9000, loss: 0.122410
 >> iter 10000, loss: 0.077243
   Number of active neurons: 10
 >> iter 11000, loss: 0.041830
 >> iter 12000, loss: 0.039969
 >> iter 13000, loss: 0.141711
 >> iter 14000, loss: 0.064338
 >> iter 15000, loss: 0.037637
 >> iter 16000, loss: 0.156595
 >> iter 17000, loss: 0.138611
 >> iter 18000, loss: 0.098943
 >> iter 19000, loss: 0.043136
 >> iter 20000, loss: 0.021249
   Number of active neurons: 10
 >> iter 21000, loss: 0.012606
 >> iter 22000, loss: 0.012630
 >> iter 23000, loss: 0.008922
 >> iter 24000, loss: 0.006885
 >> iter 25000, loss: 0.006016
 >> iter 26000, loss: 0.005711
 >> iter 27000, loss: 0.006517
 >> iter 28000, loss: 0.005433
 >> iter 29000, loss: 0.008784
 >> iter 30000, loss: 0.005737
   Number of active neurons: 10
 >> iter 31000, loss: 0.004264
 >> iter 32000, loss: 0.003690
 >> iter 33000, loss: 0.006702
 >> iter 34000, loss: 0.004759
 >> iter 35000, loss: 0.003732
 >> iter 36000, loss: 0.004373
 >> iter 37000, loss: 0.003433
 >> iter 38000, loss: 0.071604
 >> iter 39000, loss: 0.030219
 >> iter 40000, loss: 0.023292
   Number of active neurons: 10
 >> iter 41000, loss: 0.011091
 >> iter 42000, loss: 0.005795
 >> iter 43000, loss: 0.003873
 >> iter 44000, loss: 0.003142
 >> iter 45000, loss: 0.002587
 >> iter 46000, loss: 0.002627
 >> iter 47000, loss: 0.002482
 >> iter 48000, loss: 0.002314
 >> iter 49000, loss: 0.002173
 >> iter 50000, loss: 0.002078
   Number of active neurons: 10
 >> iter 51000, loss: 0.006956
 >> iter 52000, loss: 0.003994
 >> iter 53000, loss: 0.004066
 >> iter 54000, loss: 0.004543
 >> iter 55000, loss: 0.002950
 >> iter 56000, loss: 0.002253
 >> iter 57000, loss: 0.001893
 >> iter 58000, loss: 0.002086
 >> iter 59000, loss: 0.066144
 >> iter 60000, loss: 0.027304
   Number of active neurons: 10
 >> iter 61000, loss: 0.011317
 >> iter 62000, loss: 0.005281
 >> iter 63000, loss: 0.003215
 >> iter 64000, loss: 0.009740
 >> iter 65000, loss: 0.007464
 >> iter 66000, loss: 0.003681
 >> iter 67000, loss: 0.002313
 >> iter 68000, loss: 0.001791
 >> iter 69000, loss: 0.001555
 >> iter 70000, loss: 0.022964
   Number of active neurons: 10
 >> iter 71000, loss: 0.009840
 >> iter 72000, loss: 0.004657
 >> iter 73000, loss: 0.002736
 >> iter 74000, loss: 0.001962
 >> iter 75000, loss: 0.001591
 >> iter 76000, loss: 0.001406
 >> iter 77000, loss: 0.001322
 >> iter 78000, loss: 0.001257
 >> iter 79000, loss: 0.029685
 >> iter 80000, loss: 0.011875
   Number of active neurons: 10
 >> iter 81000, loss: 0.010119
 >> iter 82000, loss: 0.005061
 >> iter 83000, loss: 0.002699
 >> iter 84000, loss: 0.021166
 >> iter 85000, loss: 0.008851
 >> iter 86000, loss: 0.004708
 >> iter 87000, loss: 0.002869
 >> iter 88000, loss: 0.007228
 >> iter 89000, loss: 0.003701
 >> iter 90000, loss: 0.002352
   Number of active neurons: 10
 >> iter 91000, loss: 0.001634
 >> iter 92000, loss: 0.001324
 >> iter 93000, loss: 0.001174
 >> iter 94000, loss: 0.001162
 >> iter 95000, loss: 0.038693
 >> iter 96000, loss: 0.015384
 >> iter 97000, loss: 0.006765
 >> iter 98000, loss: 0.004271
 >> iter 99000, loss: 0.003039
 >> iter 100000, loss: 0.003198
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.205215
 >> iter 2000, loss: 9.896663
 >> iter 3000, loss: 4.315087
 >> iter 4000, loss: 2.036888
 >> iter 5000, loss: 1.013574
 >> iter 6000, loss: 0.566627
 >> iter 7000, loss: 0.539747
 >> iter 8000, loss: 0.224416
 >> iter 9000, loss: 0.162897
 >> iter 10000, loss: 0.077234
   Number of active neurons: 10
 >> iter 11000, loss: 0.070191
 >> iter 12000, loss: 0.040890
 >> iter 13000, loss: 0.024638
 >> iter 14000, loss: 0.061892
 >> iter 15000, loss: 0.164654
 >> iter 16000, loss: 0.137760
 >> iter 17000, loss: 0.077365
 >> iter 18000, loss: 0.044658
 >> iter 19000, loss: 0.048778
 >> iter 20000, loss: 0.030897
   Number of active neurons: 10
 >> iter 21000, loss: 0.121825
 >> iter 22000, loss: 0.063383
 >> iter 23000, loss: 0.049919
 >> iter 24000, loss: 0.023699
 >> iter 25000, loss: 0.049372
 >> iter 26000, loss: 0.023971
 >> iter 27000, loss: 0.012649
 >> iter 28000, loss: 0.008393
 >> iter 29000, loss: 0.005685
 >> iter 30000, loss: 0.004466
   Number of active neurons: 10
 >> iter 31000, loss: 0.004031
 >> iter 32000, loss: 0.004156
 >> iter 33000, loss: 0.003512
 >> iter 34000, loss: 0.003508
 >> iter 35000, loss: 0.038201
 >> iter 36000, loss: 0.024687
 >> iter 37000, loss: 0.012166
 >> iter 38000, loss: 0.009558
 >> iter 39000, loss: 0.021825
 >> iter 40000, loss: 0.011333
   Number of active neurons: 10
 >> iter 41000, loss: 0.010772
 >> iter 42000, loss: 0.005629
 >> iter 43000, loss: 0.003629
 >> iter 44000, loss: 0.015038
 >> iter 45000, loss: 0.006994
 >> iter 46000, loss: 0.004252
 >> iter 47000, loss: 0.002937
 >> iter 48000, loss: 0.002154
 >> iter 49000, loss: 0.001863
 >> iter 50000, loss: 0.001767
   Number of active neurons: 10
 >> iter 51000, loss: 0.001667
 >> iter 52000, loss: 0.001548
 >> iter 53000, loss: 0.001501
 >> iter 54000, loss: 0.001405
 >> iter 55000, loss: 0.001391
 >> iter 56000, loss: 0.001432
 >> iter 57000, loss: 0.001387
 >> iter 58000, loss: 0.001381
 >> iter 59000, loss: 0.001292
 >> iter 60000, loss: 0.091259
   Number of active neurons: 10
 >> iter 61000, loss: 0.034910
 >> iter 62000, loss: 0.047285
 >> iter 63000, loss: 0.018477
 >> iter 64000, loss: 0.007791
 >> iter 65000, loss: 0.003728
 >> iter 66000, loss: 0.002174
 >> iter 67000, loss: 0.001926
 >> iter 68000, loss: 0.001666
 >> iter 69000, loss: 0.001320
 >> iter 70000, loss: 0.001411
   Number of active neurons: 10
 >> iter 71000, loss: 0.001303
 >> iter 72000, loss: 0.001193
 >> iter 73000, loss: 0.001148
 >> iter 74000, loss: 0.001065
 >> iter 75000, loss: 0.001209
 >> iter 76000, loss: 0.001100
 >> iter 77000, loss: 0.001094
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.930856
 >> iter 2000, loss: 9.799566
 >> iter 3000, loss: 3.861970
 >> iter 4000, loss: 1.644673
 >> iter 5000, loss: 0.746900
 >> iter 6000, loss: 0.304564
 >> iter 7000, loss: 0.141510
 >> iter 8000, loss: 0.064299
 >> iter 9000, loss: 0.034476
 >> iter 10000, loss: 0.110692
   Number of active neurons: 10
 >> iter 11000, loss: 0.090100
 >> iter 12000, loss: 0.068148
 >> iter 13000, loss: 0.069634
 >> iter 14000, loss: 0.181130
 >> iter 15000, loss: 0.073934
 >> iter 16000, loss: 0.033808
 >> iter 17000, loss: 0.021852
 >> iter 18000, loss: 0.024541
 >> iter 19000, loss: 0.059210
 >> iter 20000, loss: 0.030433
   Number of active neurons: 10
 >> iter 21000, loss: 0.018431
 >> iter 22000, loss: 0.012092
 >> iter 23000, loss: 0.008302
 >> iter 24000, loss: 0.008987
 >> iter 25000, loss: 0.006413
 >> iter 26000, loss: 0.037160
 >> iter 27000, loss: 0.061769
 >> iter 28000, loss: 0.025759
 >> iter 29000, loss: 0.012419
 >> iter 30000, loss: 0.007139
   Number of active neurons: 10
 >> iter 31000, loss: 0.005036
 >> iter 32000, loss: 0.004217
 >> iter 33000, loss: 0.016184
 >> iter 34000, loss: 0.008538
 >> iter 35000, loss: 0.005888
 >> iter 36000, loss: 0.004275
 >> iter 37000, loss: 0.003739
 >> iter 38000, loss: 0.003332
 >> iter 39000, loss: 0.002952
 >> iter 40000, loss: 0.004318
   Number of active neurons: 10
 >> iter 41000, loss: 0.004848
 >> iter 42000, loss: 0.003569
 >> iter 43000, loss: 0.002838
 >> iter 44000, loss: 0.002538
 >> iter 45000, loss: 0.002296
 >> iter 46000, loss: 0.002214
 >> iter 47000, loss: 0.002134
 >> iter 48000, loss: 0.002023
 >> iter 49000, loss: 0.002132
 >> iter 50000, loss: 0.002491
   Number of active neurons: 10
 >> iter 51000, loss: 0.002122
 >> iter 52000, loss: 0.002147
 >> iter 53000, loss: 0.001913
 >> iter 54000, loss: 0.001919
 >> iter 55000, loss: 0.001793
 >> iter 56000, loss: 0.002531
 >> iter 57000, loss: 0.001973
 >> iter 58000, loss: 0.001732
 >> iter 59000, loss: 0.001642
 >> iter 60000, loss: 0.085091
   Number of active neurons: 10
 >> iter 61000, loss: 0.032822
 >> iter 62000, loss: 0.013326
 >> iter 63000, loss: 0.016359
 >> iter 64000, loss: 0.007648
 >> iter 65000, loss: 0.003998
 >> iter 66000, loss: 0.002866
 >> iter 67000, loss: 0.040558
 >> iter 68000, loss: 0.016014
 >> iter 69000, loss: 0.008915
 >> iter 70000, loss: 0.005345
   Number of active neurons: 10
 >> iter 71000, loss: 0.003234
 >> iter 72000, loss: 0.003723
 >> iter 73000, loss: 0.003218
 >> iter 74000, loss: 0.007145
 >> iter 75000, loss: 0.003662
 >> iter 76000, loss: 0.002395
 >> iter 77000, loss: 0.001873
 >> iter 78000, loss: 0.001533
 >> iter 79000, loss: 0.076229
 >> iter 80000, loss: 0.029253
   Number of active neurons: 10
 >> iter 81000, loss: 0.011736
 >> iter 82000, loss: 0.005426
 >> iter 83000, loss: 0.002914
 >> iter 84000, loss: 0.001918
 >> iter 85000, loss: 0.001613
 >> iter 86000, loss: 0.001439
 >> iter 87000, loss: 0.001323
 >> iter 88000, loss: 0.001620
 >> iter 89000, loss: 0.001423
 >> iter 90000, loss: 0.001254
   Number of active neurons: 10
 >> iter 91000, loss: 0.001209
 >> iter 92000, loss: 0.001519
 >> iter 93000, loss: 0.001273
 >> iter 94000, loss: 0.001242
 >> iter 95000, loss: 0.001542
 >> iter 96000, loss: 0.001316
 >> iter 97000, loss: 0.001374
 >> iter 98000, loss: 0.001198
 >> iter 99000, loss: 0.001140
 >> iter 100000, loss: 0.001068
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.775168
 >> iter 2000, loss: 12.209310
 >> iter 3000, loss: 5.299413
 >> iter 4000, loss: 2.191387
 >> iter 5000, loss: 0.985365
 >> iter 6000, loss: 0.479623
 >> iter 7000, loss: 0.226379
 >> iter 8000, loss: 0.178083
 >> iter 9000, loss: 0.086923
 >> iter 10000, loss: 0.170599
   Number of active neurons: 10
 >> iter 11000, loss: 0.095441
 >> iter 12000, loss: 0.051581
 >> iter 13000, loss: 0.031861
 >> iter 14000, loss: 0.022853
 >> iter 15000, loss: 0.017152
 >> iter 16000, loss: 0.055983
 >> iter 17000, loss: 0.026960
 >> iter 18000, loss: 0.015681
 >> iter 19000, loss: 0.026267
 >> iter 20000, loss: 0.015519
   Number of active neurons: 10
 >> iter 21000, loss: 0.010405
 >> iter 22000, loss: 0.008004
 >> iter 23000, loss: 0.007537
 >> iter 24000, loss: 0.015791
 >> iter 25000, loss: 0.009427
 >> iter 26000, loss: 0.006966
 >> iter 27000, loss: 0.119182
 >> iter 28000, loss: 0.098160
 >> iter 29000, loss: 0.047714
 >> iter 30000, loss: 0.021246
   Number of active neurons: 10
 >> iter 31000, loss: 0.011165
 >> iter 32000, loss: 0.016380
 >> iter 33000, loss: 0.016600
 >> iter 34000, loss: 0.008998
 >> iter 35000, loss: 0.005788
 >> iter 36000, loss: 0.004552
 >> iter 37000, loss: 0.003854
 >> iter 38000, loss: 0.003751
 >> iter 39000, loss: 0.047638
 >> iter 40000, loss: 0.019988
   Number of active neurons: 10
 >> iter 41000, loss: 0.009499
 >> iter 42000, loss: 0.005781
 >> iter 43000, loss: 0.004116
 >> iter 44000, loss: 0.003334
 >> iter 45000, loss: 0.003045
 >> iter 46000, loss: 0.002795
 >> iter 47000, loss: 0.002732
 >> iter 48000, loss: 0.002565
 >> iter 49000, loss: 0.002476
 >> iter 50000, loss: 0.002356
   Number of active neurons: 10
 >> iter 51000, loss: 0.002304
 >> iter 52000, loss: 0.002253
 >> iter 53000, loss: 0.002218
 >> iter 54000, loss: 0.002188
 >> iter 55000, loss: 0.002097
 >> iter 56000, loss: 0.002045
 >> iter 57000, loss: 0.001996
 >> iter 58000, loss: 0.001897
 >> iter 59000, loss: 0.016074
 >> iter 60000, loss: 0.007523
   Number of active neurons: 10
 >> iter 61000, loss: 0.004150
 >> iter 62000, loss: 0.002649
 >> iter 63000, loss: 0.002133
 >> iter 64000, loss: 0.001872
 >> iter 65000, loss: 0.001730
 >> iter 66000, loss: 0.001715
 >> iter 67000, loss: 0.018140
 >> iter 68000, loss: 0.007886
 >> iter 69000, loss: 0.003968
 >> iter 70000, loss: 0.007024
   Number of active neurons: 10
 >> iter 71000, loss: 0.003891
 >> iter 72000, loss: 0.002493
 >> iter 73000, loss: 0.001898
 >> iter 74000, loss: 0.001631
 >> iter 75000, loss: 0.001764
 >> iter 76000, loss: 0.001576
 >> iter 77000, loss: 0.001654
 >> iter 78000, loss: 0.001445
 >> iter 79000, loss: 0.001325
 >> iter 80000, loss: 0.001274
   Number of active neurons: 10
 >> iter 81000, loss: 0.001277
 >> iter 82000, loss: 0.001257
 >> iter 83000, loss: 0.010134
 >> iter 84000, loss: 0.004693
 >> iter 85000, loss: 0.002596
 >> iter 86000, loss: 0.001756
 >> iter 87000, loss: 0.001442
 >> iter 88000, loss: 0.001270
 >> iter 89000, loss: 0.001202
 >> iter 90000, loss: 0.001150
   Number of active neurons: 10
 >> iter 91000, loss: 0.001107
 >> iter 92000, loss: 0.001074
 >> iter 93000, loss: 0.001102
 >> iter 94000, loss: 0.001153
 >> iter 95000, loss: 0.001058
 >> iter 96000, loss: 0.001070
 >> iter 97000, loss: 0.001013
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.853263
 >> iter 2000, loss: 10.163616
 >> iter 3000, loss: 4.836300
 >> iter 4000, loss: 2.163205
 >> iter 5000, loss: 1.182575
 >> iter 6000, loss: 0.562438
 >> iter 7000, loss: 0.398640
 >> iter 8000, loss: 0.333325
 >> iter 9000, loss: 0.154986
 >> iter 10000, loss: 0.146536
   Number of active neurons: 10
 >> iter 11000, loss: 0.099674
 >> iter 12000, loss: 0.133286
 >> iter 13000, loss: 0.166982
 >> iter 14000, loss: 0.139063
 >> iter 15000, loss: 0.063352
 >> iter 16000, loss: 0.036598
 >> iter 17000, loss: 0.080491
 >> iter 18000, loss: 0.077194
 >> iter 19000, loss: 0.138896
 >> iter 20000, loss: 0.086229
   Number of active neurons: 10
 >> iter 21000, loss: 0.115174
 >> iter 22000, loss: 0.047908
 >> iter 23000, loss: 0.071051
 >> iter 24000, loss: 0.033365
 >> iter 25000, loss: 0.022497
 >> iter 26000, loss: 0.062613
 >> iter 27000, loss: 0.108439
 >> iter 28000, loss: 0.088527
 >> iter 29000, loss: 0.041382
 >> iter 30000, loss: 0.053938
   Number of active neurons: 10
 >> iter 31000, loss: 0.053781
 >> iter 32000, loss: 0.050597
 >> iter 33000, loss: 0.039268
 >> iter 34000, loss: 0.035813
 >> iter 35000, loss: 0.109334
 >> iter 36000, loss: 0.043949
 >> iter 37000, loss: 0.018921
 >> iter 38000, loss: 0.013254
 >> iter 39000, loss: 0.018616
 >> iter 40000, loss: 0.097818
   Number of active neurons: 10
 >> iter 41000, loss: 0.068259
 >> iter 42000, loss: 0.028772
 >> iter 43000, loss: 0.013828
 >> iter 44000, loss: 0.007027
 >> iter 45000, loss: 0.008325
 >> iter 46000, loss: 0.005121
 >> iter 47000, loss: 0.015269
 >> iter 48000, loss: 0.007578
 >> iter 49000, loss: 0.004977
 >> iter 50000, loss: 0.016059
   Number of active neurons: 10
 >> iter 51000, loss: 0.119167
 >> iter 52000, loss: 0.156184
 >> iter 53000, loss: 0.066310
 >> iter 54000, loss: 0.026773
 >> iter 55000, loss: 0.042471
 >> iter 56000, loss: 0.042244
 >> iter 57000, loss: 0.018260
 >> iter 58000, loss: 0.019951
 >> iter 59000, loss: 0.009291
 >> iter 60000, loss: 0.008531
   Number of active neurons: 10
 >> iter 61000, loss: 0.104369
 >> iter 62000, loss: 0.046757
 >> iter 63000, loss: 0.019139
 >> iter 64000, loss: 0.014747
 >> iter 65000, loss: 0.007314
 >> iter 66000, loss: 0.004362
 >> iter 67000, loss: 0.005622
 >> iter 68000, loss: 0.002999
 >> iter 69000, loss: 0.018865
 >> iter 70000, loss: 0.022273
   Number of active neurons: 10
 >> iter 71000, loss: 0.009381
 >> iter 72000, loss: 0.004738
 >> iter 73000, loss: 0.003328
 >> iter 74000, loss: 0.034102
 >> iter 75000, loss: 0.042672
 >> iter 76000, loss: 0.035476
 >> iter 77000, loss: 0.014812
 >> iter 78000, loss: 0.007170
 >> iter 79000, loss: 0.003818
 >> iter 80000, loss: 0.003281
   Number of active neurons: 10
 >> iter 81000, loss: 0.014572
 >> iter 82000, loss: 0.006786
 >> iter 83000, loss: 0.003494
 >> iter 84000, loss: 0.012674
 >> iter 85000, loss: 0.062381
 >> iter 86000, loss: 0.040951
 >> iter 87000, loss: 0.044857
 >> iter 88000, loss: 0.018169
 >> iter 89000, loss: 0.008119
 >> iter 90000, loss: 0.005387
   Number of active neurons: 10
 >> iter 91000, loss: 0.003049
 >> iter 92000, loss: 0.002093
 >> iter 93000, loss: 0.010570
 >> iter 94000, loss: 0.009904
 >> iter 95000, loss: 0.004562
 >> iter 96000, loss: 0.012146
 >> iter 97000, loss: 0.010779
 >> iter 98000, loss: 0.004780
 >> iter 99000, loss: 0.002554
 >> iter 100000, loss: 0.001601
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.945360
 >> iter 2000, loss: 9.737734
 >> iter 3000, loss: 3.978482
 >> iter 4000, loss: 1.795322
 >> iter 5000, loss: 0.795373
 >> iter 6000, loss: 0.360757
 >> iter 7000, loss: 0.147907
 >> iter 8000, loss: 0.185289
 >> iter 9000, loss: 0.161707
 >> iter 10000, loss: 0.241497
   Number of active neurons: 10
 >> iter 11000, loss: 0.178286
 >> iter 12000, loss: 0.077636
 >> iter 13000, loss: 0.072530
 >> iter 14000, loss: 0.060400
 >> iter 15000, loss: 0.031303
 >> iter 16000, loss: 0.069248
 >> iter 17000, loss: 0.031622
 >> iter 18000, loss: 0.037655
 >> iter 19000, loss: 0.214405
 >> iter 20000, loss: 0.127878
   Number of active neurons: 10
 >> iter 21000, loss: 0.052669
 >> iter 22000, loss: 0.023299
 >> iter 23000, loss: 0.011613
 >> iter 24000, loss: 0.046859
 >> iter 25000, loss: 0.056739
 >> iter 26000, loss: 0.027128
 >> iter 27000, loss: 0.013278
 >> iter 28000, loss: 0.008216
 >> iter 29000, loss: 0.092446
 >> iter 30000, loss: 0.152719
   Number of active neurons: 10
 >> iter 31000, loss: 0.060151
 >> iter 32000, loss: 0.025143
 >> iter 33000, loss: 0.011699
 >> iter 34000, loss: 0.006368
 >> iter 35000, loss: 0.004190
 >> iter 36000, loss: 0.003385
 >> iter 37000, loss: 0.003067
 >> iter 38000, loss: 0.003115
 >> iter 39000, loss: 0.002691
 >> iter 40000, loss: 0.002436
   Number of active neurons: 10
 >> iter 41000, loss: 0.002256
 >> iter 42000, loss: 0.034957
 >> iter 43000, loss: 0.019972
 >> iter 44000, loss: 0.008954
 >> iter 45000, loss: 0.004699
 >> iter 46000, loss: 0.002974
 >> iter 47000, loss: 0.002314
 >> iter 48000, loss: 0.002131
 >> iter 49000, loss: 0.001953
 >> iter 50000, loss: 0.001746
   Number of active neurons: 10
 >> iter 51000, loss: 0.113665
 >> iter 52000, loss: 0.043989
 >> iter 53000, loss: 0.018414
 >> iter 54000, loss: 0.008039
 >> iter 55000, loss: 0.004218
 >> iter 56000, loss: 0.006921
 >> iter 57000, loss: 0.003924
 >> iter 58000, loss: 0.006319
 >> iter 59000, loss: 0.004138
 >> iter 60000, loss: 0.002414
   Number of active neurons: 10
 >> iter 61000, loss: 0.001741
 >> iter 62000, loss: 0.001616
 >> iter 63000, loss: 0.001553
 >> iter 64000, loss: 0.001323
 >> iter 65000, loss: 0.001247
 >> iter 66000, loss: 0.001184
 >> iter 67000, loss: 0.001094
 >> iter 68000, loss: 0.001466
 >> iter 69000, loss: 0.001251
 >> iter 70000, loss: 0.001083
   Number of active neurons: 10
 >> iter 71000, loss: 0.001335
 >> iter 72000, loss: 0.001080
 >> iter 73000, loss: 0.001088
 >> iter 74000, loss: 0.001430
 >> iter 75000, loss: 0.001162
 >> iter 76000, loss: 0.001061
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.305006
 >> iter 2000, loss: 9.895883
 >> iter 3000, loss: 4.162105
 >> iter 4000, loss: 1.639098
 >> iter 5000, loss: 0.655422
 >> iter 6000, loss: 0.267665
 >> iter 7000, loss: 0.240389
 >> iter 8000, loss: 0.130150
 >> iter 9000, loss: 0.066571
 >> iter 10000, loss: 0.032658
   Number of active neurons: 10
 >> iter 11000, loss: 0.085794
 >> iter 12000, loss: 0.042044
 >> iter 13000, loss: 0.020160
 >> iter 14000, loss: 0.064841
 >> iter 15000, loss: 0.037506
 >> iter 16000, loss: 0.019531
 >> iter 17000, loss: 0.011527
 >> iter 18000, loss: 0.008461
 >> iter 19000, loss: 0.005977
 >> iter 20000, loss: 0.032445
   Number of active neurons: 10
 >> iter 21000, loss: 0.014836
 >> iter 22000, loss: 0.008926
 >> iter 23000, loss: 0.005808
 >> iter 24000, loss: 0.039588
 >> iter 25000, loss: 0.016849
 >> iter 26000, loss: 0.008222
 >> iter 27000, loss: 0.005210
 >> iter 28000, loss: 0.003975
 >> iter 29000, loss: 0.010955
 >> iter 30000, loss: 0.006138
   Number of active neurons: 10
 >> iter 31000, loss: 0.003854
 >> iter 32000, loss: 0.003140
 >> iter 33000, loss: 0.002710
 >> iter 34000, loss: 0.003176
 >> iter 35000, loss: 0.002552
 >> iter 36000, loss: 0.002662
 >> iter 37000, loss: 0.029176
 >> iter 38000, loss: 0.012611
 >> iter 39000, loss: 0.005948
 >> iter 40000, loss: 0.003685
   Number of active neurons: 10
 >> iter 41000, loss: 0.029201
 >> iter 42000, loss: 0.015450
 >> iter 43000, loss: 0.006941
 >> iter 44000, loss: 0.003781
 >> iter 45000, loss: 0.002856
 >> iter 46000, loss: 0.039328
 >> iter 47000, loss: 0.016432
 >> iter 48000, loss: 0.008764
 >> iter 49000, loss: 0.004440
 >> iter 50000, loss: 0.002767
   Number of active neurons: 10
 >> iter 51000, loss: 0.003368
 >> iter 52000, loss: 0.002418
 >> iter 53000, loss: 0.001891
 >> iter 54000, loss: 0.002019
 >> iter 55000, loss: 0.001858
 >> iter 56000, loss: 0.001905
 >> iter 57000, loss: 0.001391
 >> iter 58000, loss: 0.001240
 >> iter 59000, loss: 0.006855
 >> iter 60000, loss: 0.003316
   Number of active neurons: 10
 >> iter 61000, loss: 0.097528
 >> iter 62000, loss: 0.037533
 >> iter 63000, loss: 0.014652
 >> iter 64000, loss: 0.006239
 >> iter 65000, loss: 0.003130
 >> iter 66000, loss: 0.001972
 >> iter 67000, loss: 0.001455
 >> iter 68000, loss: 0.001210
 >> iter 69000, loss: 0.011383
 >> iter 70000, loss: 0.011988
   Number of active neurons: 10
 >> iter 71000, loss: 0.005218
 >> iter 72000, loss: 0.002704
 >> iter 73000, loss: 0.001715
 >> iter 74000, loss: 0.001409
 >> iter 75000, loss: 0.031313
 >> iter 76000, loss: 0.012402
 >> iter 77000, loss: 0.005312
 >> iter 78000, loss: 0.002660
 >> iter 79000, loss: 0.034269
 >> iter 80000, loss: 0.013722
   Number of active neurons: 10
 >> iter 81000, loss: 0.005868
 >> iter 82000, loss: 0.003223
 >> iter 83000, loss: 0.001975
 >> iter 84000, loss: 0.001423
 >> iter 85000, loss: 0.001210
 >> iter 86000, loss: 0.001094
 >> iter 87000, loss: 0.017306
 >> iter 88000, loss: 0.007275
 >> iter 89000, loss: 0.003688
 >> iter 90000, loss: 0.002030
   Number of active neurons: 10
 >> iter 91000, loss: 0.001597
 >> iter 92000, loss: 0.017585
 >> iter 93000, loss: 0.007467
 >> iter 94000, loss: 0.003403
 >> iter 95000, loss: 0.001883
 >> iter 96000, loss: 0.001586
 >> iter 97000, loss: 0.001202
 >> iter 98000, loss: 0.110942
 >> iter 99000, loss: 0.042258
 >> iter 100000, loss: 0.016388
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.122273
 >> iter 2000, loss: 10.274388
 >> iter 3000, loss: 4.283567
 >> iter 4000, loss: 1.712089
 >> iter 5000, loss: 0.736354
 >> iter 6000, loss: 0.320121
 >> iter 7000, loss: 0.157308
 >> iter 8000, loss: 0.129775
 >> iter 9000, loss: 0.105568
 >> iter 10000, loss: 0.048214
   Number of active neurons: 10
 >> iter 11000, loss: 0.066673
 >> iter 12000, loss: 0.031730
 >> iter 13000, loss: 0.050851
 >> iter 14000, loss: 0.025602
 >> iter 15000, loss: 0.074539
 >> iter 16000, loss: 0.073001
 >> iter 17000, loss: 0.055895
 >> iter 18000, loss: 0.098571
 >> iter 19000, loss: 0.055866
 >> iter 20000, loss: 0.029600
   Number of active neurons: 10
 >> iter 21000, loss: 0.015783
 >> iter 22000, loss: 0.011496
 >> iter 23000, loss: 0.007794
 >> iter 24000, loss: 0.005877
 >> iter 25000, loss: 0.046584
 >> iter 26000, loss: 0.035542
 >> iter 27000, loss: 0.032310
 >> iter 28000, loss: 0.015044
 >> iter 29000, loss: 0.008064
 >> iter 30000, loss: 0.005310
   Number of active neurons: 10
 >> iter 31000, loss: 0.004190
 >> iter 32000, loss: 0.005104
 >> iter 33000, loss: 0.014784
 >> iter 34000, loss: 0.008146
 >> iter 35000, loss: 0.008840
 >> iter 36000, loss: 0.005040
 >> iter 37000, loss: 0.003507
 >> iter 38000, loss: 0.002842
 >> iter 39000, loss: 0.008394
 >> iter 40000, loss: 0.004683
   Number of active neurons: 10
 >> iter 41000, loss: 0.004179
 >> iter 42000, loss: 0.003133
 >> iter 43000, loss: 0.002609
 >> iter 44000, loss: 0.002419
 >> iter 45000, loss: 0.002143
 >> iter 46000, loss: 0.002224
 >> iter 47000, loss: 0.002049
 >> iter 48000, loss: 0.001904
 >> iter 49000, loss: 0.001865
 >> iter 50000, loss: 0.001901
   Number of active neurons: 10
 >> iter 51000, loss: 0.001780
 >> iter 52000, loss: 0.002934
 >> iter 53000, loss: 0.002471
 >> iter 54000, loss: 0.009580
 >> iter 55000, loss: 0.004901
 >> iter 56000, loss: 0.002885
 >> iter 57000, loss: 0.002073
 >> iter 58000, loss: 0.001775
 >> iter 59000, loss: 0.001647
 >> iter 60000, loss: 0.001526
   Number of active neurons: 10
 >> iter 61000, loss: 0.001438
 >> iter 62000, loss: 0.001414
 >> iter 63000, loss: 0.001498
 >> iter 64000, loss: 0.001459
 >> iter 65000, loss: 0.001330
 >> iter 66000, loss: 0.001283
 >> iter 67000, loss: 0.001348
 >> iter 68000, loss: 0.001952
 >> iter 69000, loss: 0.001713
 >> iter 70000, loss: 0.001346
   Number of active neurons: 10
 >> iter 71000, loss: 0.001183
 >> iter 72000, loss: 0.001152
 >> iter 73000, loss: 0.001131
 >> iter 74000, loss: 0.052518
 >> iter 75000, loss: 0.027459
 >> iter 76000, loss: 0.010892
 >> iter 77000, loss: 0.004850
 >> iter 78000, loss: 0.002588
 >> iter 79000, loss: 0.003145
 >> iter 80000, loss: 0.002100
   Number of active neurons: 10
 >> iter 81000, loss: 0.001572
 >> iter 82000, loss: 0.001617
 >> iter 83000, loss: 0.001310
 >> iter 84000, loss: 0.001253
 >> iter 85000, loss: 0.001140
 >> iter 86000, loss: 0.001078
 >> iter 87000, loss: 0.001075
 >> iter 88000, loss: 0.025986
 >> iter 89000, loss: 0.025629
 >> iter 90000, loss: 0.010085
   Number of active neurons: 10
 >> iter 91000, loss: 0.004441
 >> iter 92000, loss: 0.002285
 >> iter 93000, loss: 0.022678
 >> iter 94000, loss: 0.009191
 >> iter 95000, loss: 0.024487
 >> iter 96000, loss: 0.010293
 >> iter 97000, loss: 0.046118
 >> iter 98000, loss: 0.024199
 >> iter 99000, loss: 0.009696
 >> iter 100000, loss: 0.004619
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.911879
 >> iter 2000, loss: 9.958600
 >> iter 3000, loss: 4.279609
 >> iter 4000, loss: 1.772057
 >> iter 5000, loss: 0.740389
 >> iter 6000, loss: 0.303315
 >> iter 7000, loss: 0.128405
 >> iter 8000, loss: 0.098993
 >> iter 9000, loss: 0.064329
 >> iter 10000, loss: 0.056297
   Number of active neurons: 10
 >> iter 11000, loss: 0.084206
 >> iter 12000, loss: 0.037938
 >> iter 13000, loss: 0.019547
 >> iter 14000, loss: 0.011952
 >> iter 15000, loss: 0.043394
 >> iter 16000, loss: 0.020078
 >> iter 17000, loss: 0.017626
 >> iter 18000, loss: 0.010487
 >> iter 19000, loss: 0.125973
 >> iter 20000, loss: 0.051773
   Number of active neurons: 10
 >> iter 21000, loss: 0.022791
 >> iter 22000, loss: 0.011319
 >> iter 23000, loss: 0.007668
 >> iter 24000, loss: 0.005200
 >> iter 25000, loss: 0.004630
 >> iter 26000, loss: 0.007549
 >> iter 27000, loss: 0.005734
 >> iter 28000, loss: 0.004416
 >> iter 29000, loss: 0.005232
 >> iter 30000, loss: 0.003768
   Number of active neurons: 10
 >> iter 31000, loss: 0.003211
 >> iter 32000, loss: 0.002665
 >> iter 33000, loss: 0.002446
 >> iter 34000, loss: 0.002222
 >> iter 35000, loss: 0.002710
 >> iter 36000, loss: 0.032214
 >> iter 37000, loss: 0.014513
 >> iter 38000, loss: 0.006951
 >> iter 39000, loss: 0.003921
 >> iter 40000, loss: 0.127718
   Number of active neurons: 10
 >> iter 41000, loss: 0.048592
 >> iter 42000, loss: 0.019903
 >> iter 43000, loss: 0.026724
 >> iter 44000, loss: 0.011243
 >> iter 45000, loss: 0.005410
 >> iter 46000, loss: 0.003167
 >> iter 47000, loss: 0.002338
 >> iter 48000, loss: 0.002046
 >> iter 49000, loss: 0.002057
 >> iter 50000, loss: 0.001676
   Number of active neurons: 10
 >> iter 51000, loss: 0.008384
 >> iter 52000, loss: 0.015318
 >> iter 53000, loss: 0.023485
 >> iter 54000, loss: 0.013616
 >> iter 55000, loss: 0.023257
 >> iter 56000, loss: 0.014856
 >> iter 57000, loss: 0.006740
 >> iter 58000, loss: 0.003515
 >> iter 59000, loss: 0.002299
 >> iter 60000, loss: 0.001741
   Number of active neurons: 10
 >> iter 61000, loss: 0.001684
 >> iter 62000, loss: 0.001478
 >> iter 63000, loss: 0.014235
 >> iter 64000, loss: 0.011629
 >> iter 65000, loss: 0.005461
 >> iter 66000, loss: 0.003043
 >> iter 67000, loss: 0.001955
 >> iter 68000, loss: 0.001535
 >> iter 69000, loss: 0.001339
 >> iter 70000, loss: 0.001213
   Number of active neurons: 10
 >> iter 71000, loss: 0.001176
 >> iter 72000, loss: 0.001128
 >> iter 73000, loss: 0.001194
 >> iter 74000, loss: 0.001114
 >> iter 75000, loss: 0.001045
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

