 > Problema: tomita4nueva
 > Args:
   - Hidden size: 18
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.538360
 >> iter 2000, loss: 9.267547
 >> iter 3000, loss: 4.354837
 >> iter 4000, loss: 2.044486
 >> iter 5000, loss: 1.168795
 >> iter 6000, loss: 0.767965
 >> iter 7000, loss: 0.513728
 >> iter 8000, loss: 0.406206
 >> iter 9000, loss: 0.366635
 >> iter 10000, loss: 0.359980
   Number of active neurons: 4
 >> iter 11000, loss: 0.383128
 >> iter 12000, loss: 0.356681
 >> iter 13000, loss: 0.343066
 >> iter 14000, loss: 0.345909
 >> iter 15000, loss: 0.306570
 >> iter 16000, loss: 0.331810
 >> iter 17000, loss: 0.358134
 >> iter 18000, loss: 0.467529
 >> iter 19000, loss: 0.414337
 >> iter 20000, loss: 0.205668
   Number of active neurons: 4
 >> iter 21000, loss: 0.249856
 >> iter 22000, loss: 0.208082
 >> iter 23000, loss: 0.277311
 >> iter 24000, loss: 0.260948
 >> iter 25000, loss: 0.411491
 >> iter 26000, loss: 0.329893
 >> iter 27000, loss: 0.347537
 >> iter 28000, loss: 0.232647
 >> iter 29000, loss: 0.265471
 >> iter 30000, loss: 0.240549
   Number of active neurons: 4
 >> iter 31000, loss: 0.146572
 >> iter 32000, loss: 0.243979
 >> iter 33000, loss: 0.314534
 >> iter 34000, loss: 0.328143
 >> iter 35000, loss: 0.265790
 >> iter 36000, loss: 0.275123
 >> iter 37000, loss: 0.386082
 >> iter 38000, loss: 0.337670
 >> iter 39000, loss: 0.268358
 >> iter 40000, loss: 0.195878
   Number of active neurons: 4
 >> iter 41000, loss: 0.295032
 >> iter 42000, loss: 0.157073
 >> iter 43000, loss: 0.286489
 >> iter 44000, loss: 0.288126
 >> iter 45000, loss: 0.196363
 >> iter 46000, loss: 0.271827
 >> iter 47000, loss: 0.186107
 >> iter 48000, loss: 0.190661
 >> iter 49000, loss: 0.164231
 >> iter 50000, loss: 0.397534
   Number of active neurons: 4
 >> iter 51000, loss: 0.319859
 >> iter 52000, loss: 0.295190
 >> iter 53000, loss: 0.379448
 >> iter 54000, loss: 0.202624
 >> iter 55000, loss: 0.197454
 >> iter 56000, loss: 0.271855
 >> iter 57000, loss: 0.264836
 >> iter 58000, loss: 0.128921
 >> iter 59000, loss: 0.360790
 >> iter 60000, loss: 0.411340
   Number of active neurons: 4
 >> iter 61000, loss: 0.306100
 >> iter 62000, loss: 0.366527
 >> iter 63000, loss: 0.220123
 >> iter 64000, loss: 0.325860
 >> iter 65000, loss: 0.353972
 >> iter 66000, loss: 0.226538
 >> iter 67000, loss: 0.324730
 >> iter 68000, loss: 0.218935
 >> iter 69000, loss: 0.196463
 >> iter 70000, loss: 0.155164
   Number of active neurons: 4
 >> iter 71000, loss: 0.177083
 >> iter 72000, loss: 0.239804
 >> iter 73000, loss: 0.153954
 >> iter 74000, loss: 0.227220
 >> iter 75000, loss: 0.280309
 >> iter 76000, loss: 0.452710
 >> iter 77000, loss: 0.331960
 >> iter 78000, loss: 0.200408
 >> iter 79000, loss: 0.301624
 >> iter 80000, loss: 0.204834
   Number of active neurons: 4
 >> iter 81000, loss: 0.288445
 >> iter 82000, loss: 0.426510
 >> iter 83000, loss: 0.293056
 >> iter 84000, loss: 0.331705
 >> iter 85000, loss: 0.166621
 >> iter 86000, loss: 0.204006
 >> iter 87000, loss: 0.207188
 >> iter 88000, loss: 0.199761
 >> iter 89000, loss: 0.226832
 >> iter 90000, loss: 0.119626
   Number of active neurons: 4
 >> iter 91000, loss: 0.165427
 >> iter 92000, loss: 0.149851
 >> iter 93000, loss: 0.279578
 >> iter 94000, loss: 0.317663
 >> iter 95000, loss: 0.271460
 >> iter 96000, loss: 0.416453
 >> iter 97000, loss: 0.244398
 >> iter 98000, loss: 0.290042
 >> iter 99000, loss: 0.212085
 >> iter 100000, loss: 0.323204
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.583284
 >> iter 2000, loss: 8.505940
 >> iter 3000, loss: 4.098370
 >> iter 4000, loss: 1.862919
 >> iter 5000, loss: 0.966501
 >> iter 6000, loss: 0.779891
 >> iter 7000, loss: 0.483610
 >> iter 8000, loss: 0.537685
 >> iter 9000, loss: 0.505634
 >> iter 10000, loss: 0.447623
   Number of active neurons: 4
 >> iter 11000, loss: 0.354932
 >> iter 12000, loss: 0.491449
 >> iter 13000, loss: 0.318425
 >> iter 14000, loss: 0.317726
 >> iter 15000, loss: 0.408893
 >> iter 16000, loss: 0.312099
 >> iter 17000, loss: 0.232656
 >> iter 18000, loss: 0.286538
 >> iter 19000, loss: 0.440310
 >> iter 20000, loss: 0.289354
   Number of active neurons: 4
 >> iter 21000, loss: 0.216318
 >> iter 22000, loss: 0.423817
 >> iter 23000, loss: 0.336694
 >> iter 24000, loss: 0.413428
 >> iter 25000, loss: 0.419551
 >> iter 26000, loss: 0.359329
 >> iter 27000, loss: 0.317822
 >> iter 28000, loss: 0.426671
 >> iter 29000, loss: 0.321195
 >> iter 30000, loss: 0.401951
   Number of active neurons: 4
 >> iter 31000, loss: 0.263392
 >> iter 32000, loss: 0.315582
 >> iter 33000, loss: 0.339709
 >> iter 34000, loss: 0.287231
 >> iter 35000, loss: 0.280266
 >> iter 36000, loss: 0.288240
 >> iter 37000, loss: 0.237498
 >> iter 38000, loss: 0.265716
 >> iter 39000, loss: 0.200942
 >> iter 40000, loss: 0.139223
   Number of active neurons: 4
 >> iter 41000, loss: 0.218972
 >> iter 42000, loss: 0.327292
 >> iter 43000, loss: 0.298391
 >> iter 44000, loss: 0.475225
 >> iter 45000, loss: 0.256940
 >> iter 46000, loss: 0.370500
 >> iter 47000, loss: 0.460581
 >> iter 48000, loss: 0.427503
 >> iter 49000, loss: 0.391622
 >> iter 50000, loss: 0.395953
   Number of active neurons: 4
 >> iter 51000, loss: 0.326904
 >> iter 52000, loss: 0.227055
 >> iter 53000, loss: 0.201971
 >> iter 54000, loss: 0.235524
 >> iter 55000, loss: 0.280213
 >> iter 56000, loss: 0.137099
 >> iter 57000, loss: 0.121740
 >> iter 58000, loss: 0.310838
 >> iter 59000, loss: 0.162463
 >> iter 60000, loss: 0.299602
   Number of active neurons: 3
 >> iter 61000, loss: 0.271467
 >> iter 62000, loss: 0.369227
 >> iter 63000, loss: 0.314465
 >> iter 64000, loss: 0.226078
 >> iter 65000, loss: 0.362941
 >> iter 66000, loss: 0.211399
 >> iter 67000, loss: 0.237945
 >> iter 68000, loss: 0.320010
 >> iter 69000, loss: 0.317307
 >> iter 70000, loss: 0.279214
   Number of active neurons: 3
 >> iter 71000, loss: 0.167844
 >> iter 72000, loss: 0.183670
 >> iter 73000, loss: 0.367621
 >> iter 74000, loss: 0.492982
 >> iter 75000, loss: 0.318622
 >> iter 76000, loss: 0.207567
 >> iter 77000, loss: 0.316747
 >> iter 78000, loss: 0.421328
 >> iter 79000, loss: 0.306944
 >> iter 80000, loss: 0.250366
   Number of active neurons: 3
 >> iter 81000, loss: 0.346440
 >> iter 82000, loss: 0.263184
 >> iter 83000, loss: 0.262104
 >> iter 84000, loss: 0.258132
 >> iter 85000, loss: 0.205344
 >> iter 86000, loss: 0.285428
 >> iter 87000, loss: 0.343329
 >> iter 88000, loss: 0.265388
 >> iter 89000, loss: 0.252943
 >> iter 90000, loss: 0.315067
   Number of active neurons: 3
 >> iter 91000, loss: 0.240578
 >> iter 92000, loss: 0.141049
 >> iter 93000, loss: 0.107003
 >> iter 94000, loss: 0.107342
 >> iter 95000, loss: 0.242721
 >> iter 96000, loss: 0.224276
 >> iter 97000, loss: 0.173683
 >> iter 98000, loss: 0.460220
 >> iter 99000, loss: 0.323964
 >> iter 100000, loss: 0.196237
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.941295
 >> iter 2000, loss: 9.940146
 >> iter 3000, loss: 4.575913
 >> iter 4000, loss: 2.225485
 >> iter 5000, loss: 1.381068
 >> iter 6000, loss: 1.002329
 >> iter 7000, loss: 0.800459
 >> iter 8000, loss: 0.827183
 >> iter 9000, loss: 0.510850
 >> iter 10000, loss: 0.579689
   Number of active neurons: 7
 >> iter 11000, loss: 0.684284
 >> iter 12000, loss: 0.583880
 >> iter 13000, loss: 0.556308
 >> iter 14000, loss: 0.409582
 >> iter 15000, loss: 0.363738
 >> iter 16000, loss: 0.522968
 >> iter 17000, loss: 0.411663
 >> iter 18000, loss: 0.540905
 >> iter 19000, loss: 0.717036
 >> iter 20000, loss: 0.682582
   Number of active neurons: 6
 >> iter 21000, loss: 0.506693
 >> iter 22000, loss: 0.476284
 >> iter 23000, loss: 0.585177
 >> iter 24000, loss: 0.650514
 >> iter 25000, loss: 0.580021
 >> iter 26000, loss: 0.320398
 >> iter 27000, loss: 0.462308
 >> iter 28000, loss: 0.683686
 >> iter 29000, loss: 0.383484
 >> iter 30000, loss: 0.397288
   Number of active neurons: 5
 >> iter 31000, loss: 0.491925
 >> iter 32000, loss: 0.524296
 >> iter 33000, loss: 0.529511
 >> iter 34000, loss: 0.712773
 >> iter 35000, loss: 0.637301
 >> iter 36000, loss: 0.584104
 >> iter 37000, loss: 0.600500
 >> iter 38000, loss: 0.644226
 >> iter 39000, loss: 0.760217
 >> iter 40000, loss: 0.539122
   Number of active neurons: 4
 >> iter 41000, loss: 0.424816
 >> iter 42000, loss: 0.509691
 >> iter 43000, loss: 0.495429
 >> iter 44000, loss: 0.426414
 >> iter 45000, loss: 0.474251
 >> iter 46000, loss: 0.374429
 >> iter 47000, loss: 0.395078
 >> iter 48000, loss: 0.649107
 >> iter 49000, loss: 0.507490
 >> iter 50000, loss: 0.398161
   Number of active neurons: 4
 >> iter 51000, loss: 0.373833
 >> iter 52000, loss: 0.610431
 >> iter 53000, loss: 0.480637
 >> iter 54000, loss: 0.380426
 >> iter 55000, loss: 0.383948
 >> iter 56000, loss: 0.252502
 >> iter 57000, loss: 0.369351
 >> iter 58000, loss: 0.492082
 >> iter 59000, loss: 0.442114
 >> iter 60000, loss: 0.555592
   Number of active neurons: 4
 >> iter 61000, loss: 0.588575
 >> iter 62000, loss: 0.637758
 >> iter 63000, loss: 0.478642
 >> iter 64000, loss: 0.303229
 >> iter 65000, loss: 0.423942
 >> iter 66000, loss: 0.484129
 >> iter 67000, loss: 0.377226
 >> iter 68000, loss: 0.328242
 >> iter 69000, loss: 0.302346
 >> iter 70000, loss: 0.457859
   Number of active neurons: 4
 >> iter 71000, loss: 0.468703
 >> iter 72000, loss: 0.409266
 >> iter 73000, loss: 0.290738
 >> iter 74000, loss: 0.456409
 >> iter 75000, loss: 0.519352
 >> iter 76000, loss: 0.422725
 >> iter 77000, loss: 0.851227
 >> iter 78000, loss: 0.570993
 >> iter 79000, loss: 0.576584
 >> iter 80000, loss: 0.508969
   Number of active neurons: 4
 >> iter 81000, loss: 0.419790
 >> iter 82000, loss: 0.607113
 >> iter 83000, loss: 0.639059
 >> iter 84000, loss: 0.569536
 >> iter 85000, loss: 0.414312
 >> iter 86000, loss: 0.331750
 >> iter 87000, loss: 0.334965
 >> iter 88000, loss: 0.843531
 >> iter 89000, loss: 0.493257
 >> iter 90000, loss: 0.504149
   Number of active neurons: 4
 >> iter 91000, loss: 0.332801
 >> iter 92000, loss: 0.443304
 >> iter 93000, loss: 0.513877
 >> iter 94000, loss: 0.443592
 >> iter 95000, loss: 0.379452
 >> iter 96000, loss: 0.767986
 >> iter 97000, loss: 0.748711
 >> iter 98000, loss: 0.660856
 >> iter 99000, loss: 0.399231
 >> iter 100000, loss: 0.393179
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.598363
 >> iter 2000, loss: 8.940621
 >> iter 3000, loss: 3.989635
 >> iter 4000, loss: 1.762552
 >> iter 5000, loss: 0.966314
 >> iter 6000, loss: 0.658932
 >> iter 7000, loss: 0.593154
 >> iter 8000, loss: 0.454933
 >> iter 9000, loss: 0.344085
 >> iter 10000, loss: 0.204842
   Number of active neurons: 6
 >> iter 11000, loss: 0.283983
 >> iter 12000, loss: 0.304404
 >> iter 13000, loss: 0.295397
 >> iter 14000, loss: 0.394525
 >> iter 15000, loss: 0.461612
 >> iter 16000, loss: 0.461073
 >> iter 17000, loss: 0.394822
 >> iter 18000, loss: 0.364736
 >> iter 19000, loss: 0.445700
 >> iter 20000, loss: 0.415467
   Number of active neurons: 6
 >> iter 21000, loss: 0.288370
 >> iter 22000, loss: 0.278369
 >> iter 23000, loss: 0.431069
 >> iter 24000, loss: 0.507930
 >> iter 25000, loss: 0.437040
 >> iter 26000, loss: 0.399154
 >> iter 27000, loss: 0.292383
 >> iter 28000, loss: 0.390138
 >> iter 29000, loss: 0.429754
 >> iter 30000, loss: 0.207701
   Number of active neurons: 6
 >> iter 31000, loss: 0.299860
 >> iter 32000, loss: 0.312879
 >> iter 33000, loss: 0.217043
 >> iter 34000, loss: 0.401473
 >> iter 35000, loss: 0.391183
 >> iter 36000, loss: 0.255277
 >> iter 37000, loss: 0.370941
 >> iter 38000, loss: 0.241477
 >> iter 39000, loss: 0.250140
 >> iter 40000, loss: 0.200368
   Number of active neurons: 5
 >> iter 41000, loss: 0.372021
 >> iter 42000, loss: 0.177485
 >> iter 43000, loss: 0.299397
 >> iter 44000, loss: 0.194556
 >> iter 45000, loss: 0.280746
 >> iter 46000, loss: 0.208583
 >> iter 47000, loss: 0.268516
 >> iter 48000, loss: 0.337179
 >> iter 49000, loss: 0.308112
 >> iter 50000, loss: 0.327509
   Number of active neurons: 5
 >> iter 51000, loss: 0.358639
 >> iter 52000, loss: 0.308523
 >> iter 53000, loss: 0.283859
 >> iter 54000, loss: 0.358349
 >> iter 55000, loss: 0.287588
 >> iter 56000, loss: 0.218542
 >> iter 57000, loss: 0.242482
 >> iter 58000, loss: 0.487900
 >> iter 59000, loss: 0.429586
 >> iter 60000, loss: 0.374120
   Number of active neurons: 5
 >> iter 61000, loss: 0.223989
 >> iter 62000, loss: 0.241842
 >> iter 63000, loss: 0.375186
 >> iter 64000, loss: 0.335586
 >> iter 65000, loss: 0.280631
 >> iter 66000, loss: 0.317277
 >> iter 67000, loss: 0.174714
 >> iter 68000, loss: 0.158347
 >> iter 69000, loss: 0.163158
 >> iter 70000, loss: 0.263457
   Number of active neurons: 5
 >> iter 71000, loss: 0.387595
 >> iter 72000, loss: 0.183710
 >> iter 73000, loss: 0.392909
 >> iter 74000, loss: 0.271264
 >> iter 75000, loss: 0.385637
 >> iter 76000, loss: 0.233986
 >> iter 77000, loss: 0.360273
 >> iter 78000, loss: 0.276427
 >> iter 79000, loss: 0.157131
 >> iter 80000, loss: 0.197619
   Number of active neurons: 4
 >> iter 81000, loss: 0.226234
 >> iter 82000, loss: 0.128747
 >> iter 83000, loss: 0.227193
 >> iter 84000, loss: 0.410532
 >> iter 85000, loss: 0.426352
 >> iter 86000, loss: 0.278761
 >> iter 87000, loss: 0.165946
 >> iter 88000, loss: 0.185102
 >> iter 89000, loss: 0.238196
 >> iter 90000, loss: 0.223257
   Number of active neurons: 4
 >> iter 91000, loss: 0.148360
 >> iter 92000, loss: 0.140705
 >> iter 93000, loss: 0.167671
 >> iter 94000, loss: 0.301357
 >> iter 95000, loss: 0.350041
 >> iter 96000, loss: 0.227719
 >> iter 97000, loss: 0.257052
 >> iter 98000, loss: 0.286153
 >> iter 99000, loss: 0.294866
 >> iter 100000, loss: 0.270912
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.820614
 >> iter 2000, loss: 9.842514
 >> iter 3000, loss: 4.552282
 >> iter 4000, loss: 2.344714
 >> iter 5000, loss: 1.132424
 >> iter 6000, loss: 0.698196
 >> iter 7000, loss: 0.399697
 >> iter 8000, loss: 0.397499
 >> iter 9000, loss: 0.478863
 >> iter 10000, loss: 0.490921
   Number of active neurons: 4
 >> iter 11000, loss: 0.340402
 >> iter 12000, loss: 0.557733
 >> iter 13000, loss: 0.534639
 >> iter 14000, loss: 0.388941
 >> iter 15000, loss: 0.235942
 >> iter 16000, loss: 0.357742
 >> iter 17000, loss: 0.323650
 >> iter 18000, loss: 0.400859
 >> iter 19000, loss: 0.462635
 >> iter 20000, loss: 0.458231
   Number of active neurons: 4
 >> iter 21000, loss: 0.426642
 >> iter 22000, loss: 0.442253
 >> iter 23000, loss: 0.610276
 >> iter 24000, loss: 0.538185
 >> iter 25000, loss: 0.410395
 >> iter 26000, loss: 0.480173
 >> iter 27000, loss: 0.635885
 >> iter 28000, loss: 0.324156
 >> iter 29000, loss: 0.303171
 >> iter 30000, loss: 0.229602
   Number of active neurons: 4
 >> iter 31000, loss: 0.288793
 >> iter 32000, loss: 0.259143
 >> iter 33000, loss: 0.688323
 >> iter 34000, loss: 0.530232
 >> iter 35000, loss: 0.445870
 >> iter 36000, loss: 0.367221
 >> iter 37000, loss: 0.429034
 >> iter 38000, loss: 0.377473
 >> iter 39000, loss: 0.376061
 >> iter 40000, loss: 0.223772
   Number of active neurons: 4
 >> iter 41000, loss: 0.293341
 >> iter 42000, loss: 0.459116
 >> iter 43000, loss: 0.461485
 >> iter 44000, loss: 0.364830
 >> iter 45000, loss: 0.257783
 >> iter 46000, loss: 0.261199
 >> iter 47000, loss: 0.442194
 >> iter 48000, loss: 0.416061
 >> iter 49000, loss: 0.322597
 >> iter 50000, loss: 0.266725
   Number of active neurons: 4
 >> iter 51000, loss: 0.263475
 >> iter 52000, loss: 0.337896
 >> iter 53000, loss: 0.431264
 >> iter 54000, loss: 0.318436
 >> iter 55000, loss: 0.389113
 >> iter 56000, loss: 0.483418
 >> iter 57000, loss: 0.455343
 >> iter 58000, loss: 0.306524
 >> iter 59000, loss: 0.338483
 >> iter 60000, loss: 0.258492
   Number of active neurons: 4
 >> iter 61000, loss: 0.447411
 >> iter 62000, loss: 0.294094
 >> iter 63000, loss: 0.301388
 >> iter 64000, loss: 0.230612
 >> iter 65000, loss: 0.224366
 >> iter 66000, loss: 0.241974
 >> iter 67000, loss: 0.212460
 >> iter 68000, loss: 0.344388
 >> iter 69000, loss: 0.303090
 >> iter 70000, loss: 0.472058
   Number of active neurons: 4
 >> iter 71000, loss: 0.375464
 >> iter 72000, loss: 0.401940
 >> iter 73000, loss: 0.392456
 >> iter 74000, loss: 0.322199
 >> iter 75000, loss: 0.448720
 >> iter 76000, loss: 0.282690
 >> iter 77000, loss: 0.171001
 >> iter 78000, loss: 0.222394
 >> iter 79000, loss: 0.335470
 >> iter 80000, loss: 0.239221
   Number of active neurons: 3
 >> iter 81000, loss: 0.226746
 >> iter 82000, loss: 0.317591
 >> iter 83000, loss: 0.269238
 >> iter 84000, loss: 0.268799
 >> iter 85000, loss: 0.313663
 >> iter 86000, loss: 0.374287
 >> iter 87000, loss: 0.424504
 >> iter 88000, loss: 0.360068
 >> iter 89000, loss: 0.341639
 >> iter 90000, loss: 0.287803
   Number of active neurons: 3
 >> iter 91000, loss: 0.168273
 >> iter 92000, loss: 0.362738
 >> iter 93000, loss: 0.317906
 >> iter 94000, loss: 0.400003
 >> iter 95000, loss: 0.266028
 >> iter 96000, loss: 0.224027
 >> iter 97000, loss: 0.248015
 >> iter 98000, loss: 0.355693
 >> iter 99000, loss: 0.289131
 >> iter 100000, loss: 0.247185
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.790416
 >> iter 2000, loss: 8.603421
 >> iter 3000, loss: 3.717946
 >> iter 4000, loss: 1.929456
 >> iter 5000, loss: 1.002437
 >> iter 6000, loss: 0.615915
 >> iter 7000, loss: 0.331091
 >> iter 8000, loss: 0.339584
 >> iter 9000, loss: 0.209630
 >> iter 10000, loss: 0.298724
   Number of active neurons: 7
 >> iter 11000, loss: 0.241799
 >> iter 12000, loss: 0.280004
 >> iter 13000, loss: 0.345268
 >> iter 14000, loss: 0.527949
 >> iter 15000, loss: 0.343772
 >> iter 16000, loss: 0.476570
 >> iter 17000, loss: 0.479571
 >> iter 18000, loss: 0.306162
 >> iter 19000, loss: 0.259983
 >> iter 20000, loss: 0.236038
   Number of active neurons: 7
 >> iter 21000, loss: 0.488774
 >> iter 22000, loss: 0.384591
 >> iter 23000, loss: 0.315217
 >> iter 24000, loss: 0.208087
 >> iter 25000, loss: 0.140626
 >> iter 26000, loss: 0.405344
 >> iter 27000, loss: 0.397999
 >> iter 28000, loss: 0.266071
 >> iter 29000, loss: 0.335385
 >> iter 30000, loss: 0.535736
   Number of active neurons: 5
 >> iter 31000, loss: 0.317162
 >> iter 32000, loss: 0.180993
 >> iter 33000, loss: 0.380809
 >> iter 34000, loss: 0.229658
 >> iter 35000, loss: 0.214085
 >> iter 36000, loss: 0.267847
 >> iter 37000, loss: 0.214967
 >> iter 38000, loss: 0.267617
 >> iter 39000, loss: 0.387205
 >> iter 40000, loss: 0.261746
   Number of active neurons: 4
 >> iter 41000, loss: 0.241097
 >> iter 42000, loss: 0.196737
 >> iter 43000, loss: 0.273451
 >> iter 44000, loss: 0.347201
 >> iter 45000, loss: 0.410053
 >> iter 46000, loss: 0.534185
 >> iter 47000, loss: 0.352668
 >> iter 48000, loss: 0.238619
 >> iter 49000, loss: 0.190197
 >> iter 50000, loss: 0.166176
   Number of active neurons: 4
 >> iter 51000, loss: 0.208842
 >> iter 52000, loss: 0.205668
 >> iter 53000, loss: 0.307797
 >> iter 54000, loss: 0.224670
 >> iter 55000, loss: 0.171817
 >> iter 56000, loss: 0.227460
 >> iter 57000, loss: 0.387235
 >> iter 58000, loss: 0.195153
 >> iter 59000, loss: 0.311675
 >> iter 60000, loss: 0.237657
   Number of active neurons: 3
 >> iter 61000, loss: 0.425372
 >> iter 62000, loss: 0.264504
 >> iter 63000, loss: 0.232184
 >> iter 64000, loss: 0.214330
 >> iter 65000, loss: 0.261452
 >> iter 66000, loss: 0.350923
 >> iter 67000, loss: 0.254230
 >> iter 68000, loss: 0.209354
 >> iter 69000, loss: 0.140107
 >> iter 70000, loss: 0.368801
   Number of active neurons: 3
 >> iter 71000, loss: 0.314909
 >> iter 72000, loss: 0.247005
 >> iter 73000, loss: 0.219296
 >> iter 74000, loss: 0.213499
 >> iter 75000, loss: 0.325716
 >> iter 76000, loss: 0.217895
 >> iter 77000, loss: 0.214125
 >> iter 78000, loss: 0.157263
 >> iter 79000, loss: 0.311945
 >> iter 80000, loss: 0.214646
   Number of active neurons: 3
 >> iter 81000, loss: 0.526236
 >> iter 82000, loss: 0.330492
 >> iter 83000, loss: 0.189318
 >> iter 84000, loss: 0.336333
 >> iter 85000, loss: 0.372469
 >> iter 86000, loss: 0.232417
 >> iter 87000, loss: 0.197724
 >> iter 88000, loss: 0.265664
 >> iter 89000, loss: 0.338339
 >> iter 90000, loss: 0.258469
   Number of active neurons: 3
 >> iter 91000, loss: 0.200190
 >> iter 92000, loss: 0.291099
 >> iter 93000, loss: 0.224513
 >> iter 94000, loss: 0.137034
 >> iter 95000, loss: 0.171847
 >> iter 96000, loss: 0.100712
 >> iter 97000, loss: 0.296987
 >> iter 98000, loss: 0.311090
 >> iter 99000, loss: 0.273463
 >> iter 100000, loss: 0.277473
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.509245
 >> iter 2000, loss: 8.939712
 >> iter 3000, loss: 4.139924
 >> iter 4000, loss: 2.248585
 >> iter 5000, loss: 1.388936
 >> iter 6000, loss: 0.871821
 >> iter 7000, loss: 0.462715
 >> iter 8000, loss: 0.866811
 >> iter 9000, loss: 0.550464
 >> iter 10000, loss: 0.372819
   Number of active neurons: 5
 >> iter 11000, loss: 0.302470
 >> iter 12000, loss: 0.575100
 >> iter 13000, loss: 0.325443
 >> iter 14000, loss: 0.538043
 >> iter 15000, loss: 0.437788
 >> iter 16000, loss: 0.416409
 >> iter 17000, loss: 0.279123
 >> iter 18000, loss: 0.499292
 >> iter 19000, loss: 0.387226
 >> iter 20000, loss: 0.329676
   Number of active neurons: 4
 >> iter 21000, loss: 0.441313
 >> iter 22000, loss: 0.314444
 >> iter 23000, loss: 0.362437
 >> iter 24000, loss: 0.287868
 >> iter 25000, loss: 0.488935
 >> iter 26000, loss: 0.417630
 >> iter 27000, loss: 0.473612
 >> iter 28000, loss: 0.349409
 >> iter 29000, loss: 0.352167
 >> iter 30000, loss: 0.287792
   Number of active neurons: 3
 >> iter 31000, loss: 0.382384
 >> iter 32000, loss: 0.218333
 >> iter 33000, loss: 0.381840
 >> iter 34000, loss: 0.266605
 >> iter 35000, loss: 0.273084
 >> iter 36000, loss: 0.265454
 >> iter 37000, loss: 0.359509
 >> iter 38000, loss: 0.424030
 >> iter 39000, loss: 0.348765
 >> iter 40000, loss: 0.173873
   Number of active neurons: 3
 >> iter 41000, loss: 0.377040
 >> iter 42000, loss: 0.287683
 >> iter 43000, loss: 0.362447
 >> iter 44000, loss: 0.508872
 >> iter 45000, loss: 0.254981
 >> iter 46000, loss: 0.145638
 >> iter 47000, loss: 0.308788
 >> iter 48000, loss: 0.351157
 >> iter 49000, loss: 0.340250
 >> iter 50000, loss: 0.398391
   Number of active neurons: 3
 >> iter 51000, loss: 0.254481
 >> iter 52000, loss: 0.211812
 >> iter 53000, loss: 0.343515
 >> iter 54000, loss: 0.335192
 >> iter 55000, loss: 0.330142
 >> iter 56000, loss: 0.266411
 >> iter 57000, loss: 0.250440
 >> iter 58000, loss: 0.267701
 >> iter 59000, loss: 0.298395
 >> iter 60000, loss: 0.342612
   Number of active neurons: 3
 >> iter 61000, loss: 0.281396
 >> iter 62000, loss: 0.209766
 >> iter 63000, loss: 0.168477
 >> iter 64000, loss: 0.232990
 >> iter 65000, loss: 0.335960
 >> iter 66000, loss: 0.213362
 >> iter 67000, loss: 0.167135
 >> iter 68000, loss: 0.365673
 >> iter 69000, loss: 0.326901
 >> iter 70000, loss: 0.191311
   Number of active neurons: 3
 >> iter 71000, loss: 0.247583
 >> iter 72000, loss: 0.217057
 >> iter 73000, loss: 0.312498
 >> iter 74000, loss: 0.221733
 >> iter 75000, loss: 0.392586
 >> iter 76000, loss: 0.321210
 >> iter 77000, loss: 0.404939
 >> iter 78000, loss: 0.340630
 >> iter 79000, loss: 0.340126
 >> iter 80000, loss: 0.324926
   Number of active neurons: 3
 >> iter 81000, loss: 0.430720
 >> iter 82000, loss: 0.334669
 >> iter 83000, loss: 0.297049
 >> iter 84000, loss: 0.166575
 >> iter 85000, loss: 0.123937
 >> iter 86000, loss: 0.174111
 >> iter 87000, loss: 0.152321
 >> iter 88000, loss: 0.335290
 >> iter 89000, loss: 0.338275
 >> iter 90000, loss: 0.263328
   Number of active neurons: 3
 >> iter 91000, loss: 0.310298
 >> iter 92000, loss: 0.306187
 >> iter 93000, loss: 0.423017
 >> iter 94000, loss: 0.283827
 >> iter 95000, loss: 0.218338
 >> iter 96000, loss: 0.356094
 >> iter 97000, loss: 0.274967
 >> iter 98000, loss: 0.282999
 >> iter 99000, loss: 0.213778
 >> iter 100000, loss: 0.199458
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 17.783550
 >> iter 2000, loss: 9.271812
 >> iter 3000, loss: 4.030645
 >> iter 4000, loss: 2.020597
 >> iter 5000, loss: 1.272716
 >> iter 6000, loss: 0.925111
 >> iter 7000, loss: 0.612923
 >> iter 8000, loss: 0.518735
 >> iter 9000, loss: 0.571239
 >> iter 10000, loss: 0.456518
   Number of active neurons: 4
 >> iter 11000, loss: 0.563798
 >> iter 12000, loss: 0.533432
 >> iter 13000, loss: 0.529784
 >> iter 14000, loss: 0.605014
 >> iter 15000, loss: 0.405903
 >> iter 16000, loss: 0.366840
 >> iter 17000, loss: 0.345139
 >> iter 18000, loss: 0.457755
 >> iter 19000, loss: 0.359964
 >> iter 20000, loss: 0.263921
   Number of active neurons: 4
 >> iter 21000, loss: 0.184012
 >> iter 22000, loss: 0.427131
 >> iter 23000, loss: 0.339975
 >> iter 24000, loss: 0.452461
 >> iter 25000, loss: 0.512715
 >> iter 26000, loss: 0.675938
 >> iter 27000, loss: 0.397729
 >> iter 28000, loss: 0.419924
 >> iter 29000, loss: 0.456240
 >> iter 30000, loss: 0.281755
   Number of active neurons: 4
 >> iter 31000, loss: 0.271182
 >> iter 32000, loss: 0.448579
 >> iter 33000, loss: 0.397907
 >> iter 34000, loss: 0.294907
 >> iter 35000, loss: 0.210160
 >> iter 36000, loss: 0.436009
 >> iter 37000, loss: 0.419656
 >> iter 38000, loss: 0.374859
 >> iter 39000, loss: 0.458550
 >> iter 40000, loss: 0.376270
   Number of active neurons: 4
 >> iter 41000, loss: 0.514340
 >> iter 42000, loss: 0.397069
 >> iter 43000, loss: 0.425334
 >> iter 44000, loss: 0.254728
 >> iter 45000, loss: 0.408563
 >> iter 46000, loss: 0.303940
 >> iter 47000, loss: 0.380610
 >> iter 48000, loss: 0.423365
 >> iter 49000, loss: 0.594384
 >> iter 50000, loss: 0.457208
   Number of active neurons: 4
 >> iter 51000, loss: 0.290568
 >> iter 52000, loss: 0.381506
 >> iter 53000, loss: 0.473107
 >> iter 54000, loss: 0.417159
 >> iter 55000, loss: 0.295250
 >> iter 56000, loss: 0.502841
 >> iter 57000, loss: 0.444990
 >> iter 58000, loss: 0.404605
 >> iter 59000, loss: 0.363267
 >> iter 60000, loss: 0.381725
   Number of active neurons: 4
 >> iter 61000, loss: 0.400325
 >> iter 62000, loss: 0.451390
 >> iter 63000, loss: 0.615349
 >> iter 64000, loss: 0.471050
 >> iter 65000, loss: 0.245025
 >> iter 66000, loss: 0.339427
 >> iter 67000, loss: 0.418032
 >> iter 68000, loss: 0.288539
 >> iter 69000, loss: 0.246296
 >> iter 70000, loss: 0.428246
   Number of active neurons: 4
 >> iter 71000, loss: 0.339508
 >> iter 72000, loss: 0.389622
 >> iter 73000, loss: 0.765763
 >> iter 74000, loss: 0.540688
 >> iter 75000, loss: 0.493560
 >> iter 76000, loss: 0.441132
 >> iter 77000, loss: 0.294105
 >> iter 78000, loss: 0.382045
 >> iter 79000, loss: 0.284952
 >> iter 80000, loss: 0.418016
   Number of active neurons: 4
 >> iter 81000, loss: 0.300644
 >> iter 82000, loss: 0.194962
 >> iter 83000, loss: 0.401178
 >> iter 84000, loss: 0.265571
 >> iter 85000, loss: 0.249177
 >> iter 86000, loss: 0.309661
 >> iter 87000, loss: 0.340725
 >> iter 88000, loss: 0.596205
 >> iter 89000, loss: 0.393598
 >> iter 90000, loss: 0.383668
   Number of active neurons: 4
 >> iter 91000, loss: 0.225745
 >> iter 92000, loss: 0.272619
 >> iter 93000, loss: 0.274332
 >> iter 94000, loss: 0.408083
 >> iter 95000, loss: 0.300593
 >> iter 96000, loss: 0.289785
 >> iter 97000, loss: 0.412173
 >> iter 98000, loss: 0.422366
 >> iter 99000, loss: 0.252415
 >> iter 100000, loss: 0.382846
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.335453
 >> iter 2000, loss: 8.594913
 >> iter 3000, loss: 3.965835
 >> iter 4000, loss: 1.852048
 >> iter 5000, loss: 1.239285
 >> iter 6000, loss: 0.936938
 >> iter 7000, loss: 0.784084
 >> iter 8000, loss: 0.813220
 >> iter 9000, loss: 0.452981
 >> iter 10000, loss: 0.639776
   Number of active neurons: 5
 >> iter 11000, loss: 0.543578
 >> iter 12000, loss: 0.533458
 >> iter 13000, loss: 0.353696
 >> iter 14000, loss: 0.424195
 >> iter 15000, loss: 0.672491
 >> iter 16000, loss: 0.586690
 >> iter 17000, loss: 0.500184
 >> iter 18000, loss: 0.381098
 >> iter 19000, loss: 0.290936
 >> iter 20000, loss: 0.394258
   Number of active neurons: 5
 >> iter 21000, loss: 0.440903
 >> iter 22000, loss: 0.546488
 >> iter 23000, loss: 0.527637
 >> iter 24000, loss: 0.542835
 >> iter 25000, loss: 0.462438
 >> iter 26000, loss: 0.710092
 >> iter 27000, loss: 0.685449
 >> iter 28000, loss: 0.520080
 >> iter 29000, loss: 0.717124
 >> iter 30000, loss: 0.694729
   Number of active neurons: 5
 >> iter 31000, loss: 0.395667
 >> iter 32000, loss: 0.505811
 >> iter 33000, loss: 0.434252
 >> iter 34000, loss: 0.428007
 >> iter 35000, loss: 0.379184
 >> iter 36000, loss: 0.557365
 >> iter 37000, loss: 0.429506
 >> iter 38000, loss: 0.510086
 >> iter 39000, loss: 0.477396
 >> iter 40000, loss: 0.555639
   Number of active neurons: 5
 >> iter 41000, loss: 0.536994
 >> iter 42000, loss: 0.570475
 >> iter 43000, loss: 0.603245
 >> iter 44000, loss: 0.490894
 >> iter 45000, loss: 0.251752
 >> iter 46000, loss: 0.485371
 >> iter 47000, loss: 0.329398
 >> iter 48000, loss: 0.457171
 >> iter 49000, loss: 0.465826
 >> iter 50000, loss: 0.606899
   Number of active neurons: 5
 >> iter 51000, loss: 0.493329
 >> iter 52000, loss: 0.462316
 >> iter 53000, loss: 0.345037
 >> iter 54000, loss: 0.277997
 >> iter 55000, loss: 0.445824
 >> iter 56000, loss: 0.750331
 >> iter 57000, loss: 0.591413
 >> iter 58000, loss: 0.550309
 >> iter 59000, loss: 0.514981
 >> iter 60000, loss: 0.506665
   Number of active neurons: 5
 >> iter 61000, loss: 0.490041
 >> iter 62000, loss: 0.489686
 >> iter 63000, loss: 0.384725
 >> iter 64000, loss: 0.571873
 >> iter 65000, loss: 0.562465
 >> iter 66000, loss: 0.682089
 >> iter 67000, loss: 0.642131
 >> iter 68000, loss: 0.627965
 >> iter 69000, loss: 0.598032
 >> iter 70000, loss: 0.509770
   Number of active neurons: 5
 >> iter 71000, loss: 0.419236
 >> iter 72000, loss: 0.471626
 >> iter 73000, loss: 0.438392
 >> iter 74000, loss: 0.603347
 >> iter 75000, loss: 0.602879
 >> iter 76000, loss: 0.547699
 >> iter 77000, loss: 0.468812
 >> iter 78000, loss: 0.365292
 >> iter 79000, loss: 0.410223
 >> iter 80000, loss: 0.581992
   Number of active neurons: 5
 >> iter 81000, loss: 0.423567
 >> iter 82000, loss: 0.474591
 >> iter 83000, loss: 0.432587
 >> iter 84000, loss: 0.474752
 >> iter 85000, loss: 0.423068
 >> iter 86000, loss: 0.544207
 >> iter 87000, loss: 0.516912
 >> iter 88000, loss: 0.544135
 >> iter 89000, loss: 0.397532
 >> iter 90000, loss: 0.554704
   Number of active neurons: 5
 >> iter 91000, loss: 0.508349
 >> iter 92000, loss: 0.663483
 >> iter 93000, loss: 0.661855
 >> iter 94000, loss: 0.574658
 >> iter 95000, loss: 0.357999
 >> iter 96000, loss: 0.673680
 >> iter 97000, loss: 0.477303
 >> iter 98000, loss: 0.401819
 >> iter 99000, loss: 0.414116
 >> iter 100000, loss: 0.479804
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.740615
 >> iter 2000, loss: 9.074114
 >> iter 3000, loss: 4.133468
 >> iter 4000, loss: 2.070096
 >> iter 5000, loss: 1.288740
 >> iter 6000, loss: 0.830057
 >> iter 7000, loss: 0.481625
 >> iter 8000, loss: 0.416514
 >> iter 9000, loss: 0.551907
 >> iter 10000, loss: 0.515816
   Number of active neurons: 6
 >> iter 11000, loss: 0.435143
 >> iter 12000, loss: 0.319501
 >> iter 13000, loss: 0.532403
 >> iter 14000, loss: 0.545029
 >> iter 15000, loss: 0.448152
 >> iter 16000, loss: 0.424837
 >> iter 17000, loss: 0.305723
 >> iter 18000, loss: 0.318586
 >> iter 19000, loss: 0.391076
 >> iter 20000, loss: 0.351290
   Number of active neurons: 6
 >> iter 21000, loss: 0.410853
 >> iter 22000, loss: 0.332820
 >> iter 23000, loss: 0.237564
 >> iter 24000, loss: 0.459357
 >> iter 25000, loss: 0.288487
 >> iter 26000, loss: 0.180358
 >> iter 27000, loss: 0.297002
 >> iter 28000, loss: 0.257142
 >> iter 29000, loss: 0.331994
 >> iter 30000, loss: 0.330230
   Number of active neurons: 4
 >> iter 31000, loss: 0.265737
 >> iter 32000, loss: 0.443576
 >> iter 33000, loss: 0.252778
 >> iter 34000, loss: 0.295232
 >> iter 35000, loss: 0.190665
 >> iter 36000, loss: 0.311758
 >> iter 37000, loss: 0.275106
 >> iter 38000, loss: 0.185219
 >> iter 39000, loss: 0.366157
 >> iter 40000, loss: 0.295880
   Number of active neurons: 4
 >> iter 41000, loss: 0.238373
 >> iter 42000, loss: 0.370231
 >> iter 43000, loss: 0.243366
 >> iter 44000, loss: 0.495232
 >> iter 45000, loss: 0.356136
 >> iter 46000, loss: 0.311856
 >> iter 47000, loss: 0.349260
 >> iter 48000, loss: 0.255387
 >> iter 49000, loss: 0.338064
 >> iter 50000, loss: 0.328899
   Number of active neurons: 4
 >> iter 51000, loss: 0.356493
 >> iter 52000, loss: 0.222196
 >> iter 53000, loss: 0.301285
 >> iter 54000, loss: 0.344869
 >> iter 55000, loss: 0.306881
 >> iter 56000, loss: 0.435997
 >> iter 57000, loss: 0.350693
 >> iter 58000, loss: 0.294623
 >> iter 59000, loss: 0.223500
 >> iter 60000, loss: 0.219079
   Number of active neurons: 4
 >> iter 61000, loss: 0.219430
 >> iter 62000, loss: 0.350971
 >> iter 63000, loss: 0.254227
 >> iter 64000, loss: 0.321384
 >> iter 65000, loss: 0.331593
 >> iter 66000, loss: 0.566032
 >> iter 67000, loss: 0.558207
 >> iter 68000, loss: 0.493130
 >> iter 69000, loss: 0.540924
 >> iter 70000, loss: 0.553938
   Number of active neurons: 4
 >> iter 71000, loss: 0.408962
 >> iter 72000, loss: 0.336832
 >> iter 73000, loss: 0.206877
 >> iter 74000, loss: 0.260850
 >> iter 75000, loss: 0.274742
 >> iter 76000, loss: 0.282984
 >> iter 77000, loss: 0.192736
 >> iter 78000, loss: 0.335436
 >> iter 79000, loss: 0.488297
 >> iter 80000, loss: 0.308165
   Number of active neurons: 4
 >> iter 81000, loss: 0.310555
 >> iter 82000, loss: 0.327921
 >> iter 83000, loss: 0.246717
 >> iter 84000, loss: 0.254394
 >> iter 85000, loss: 0.215296
 >> iter 86000, loss: 0.385018
 >> iter 87000, loss: 0.293403
 >> iter 88000, loss: 0.206575
 >> iter 89000, loss: 0.276526
 >> iter 90000, loss: 0.171724
   Number of active neurons: 4
 >> iter 91000, loss: 0.286038
 >> iter 92000, loss: 0.329554
 >> iter 93000, loss: 0.335928
 >> iter 94000, loss: 0.442951
 >> iter 95000, loss: 0.444312
 >> iter 96000, loss: 0.314811
 >> iter 97000, loss: 0.329031
 >> iter 98000, loss: 0.272642
 >> iter 99000, loss: 0.207206
 >> iter 100000, loss: 0.215990
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.335650
 >> iter 2000, loss: 8.588872
 >> iter 3000, loss: 3.688413
 >> iter 4000, loss: 1.648157
 >> iter 5000, loss: 0.894152
 >> iter 6000, loss: 0.523534
 >> iter 7000, loss: 0.550764
 >> iter 8000, loss: 0.443755
 >> iter 9000, loss: 0.554190
 >> iter 10000, loss: 0.428111
   Number of active neurons: 6
 >> iter 11000, loss: 0.411991
 >> iter 12000, loss: 0.507964
 >> iter 13000, loss: 0.432754
 >> iter 14000, loss: 0.282151
 >> iter 15000, loss: 0.426339
 >> iter 16000, loss: 0.351585
 >> iter 17000, loss: 0.193319
 >> iter 18000, loss: 0.231552
 >> iter 19000, loss: 0.386431
 >> iter 20000, loss: 0.513025
   Number of active neurons: 6
 >> iter 21000, loss: 0.433681
 >> iter 22000, loss: 0.203041
 >> iter 23000, loss: 0.252444
 >> iter 24000, loss: 0.258489
 >> iter 25000, loss: 0.358483
 >> iter 26000, loss: 0.433715
 >> iter 27000, loss: 0.266660
 >> iter 28000, loss: 0.420326
 >> iter 29000, loss: 0.435127
 >> iter 30000, loss: 0.474548
   Number of active neurons: 5
 >> iter 31000, loss: 0.272324
 >> iter 32000, loss: 0.266628
 >> iter 33000, loss: 0.283550
 >> iter 34000, loss: 0.271273
 >> iter 35000, loss: 0.258732
 >> iter 36000, loss: 0.362486
 >> iter 37000, loss: 0.323624
 >> iter 38000, loss: 0.245390
 >> iter 39000, loss: 0.201811
 >> iter 40000, loss: 0.241512
   Number of active neurons: 4
 >> iter 41000, loss: 0.230622
 >> iter 42000, loss: 0.264205
 >> iter 43000, loss: 0.248118
 >> iter 44000, loss: 0.508653
 >> iter 45000, loss: 0.348522
 >> iter 46000, loss: 0.215290
 >> iter 47000, loss: 0.407984
 >> iter 48000, loss: 0.379509
 >> iter 49000, loss: 0.206015
 >> iter 50000, loss: 0.198476
   Number of active neurons: 4
 >> iter 51000, loss: 0.219502
 >> iter 52000, loss: 0.318185
 >> iter 53000, loss: 0.170759
 >> iter 54000, loss: 0.321832
 >> iter 55000, loss: 0.301455
 >> iter 56000, loss: 0.177001
 >> iter 57000, loss: 0.218354
 >> iter 58000, loss: 0.181246
 >> iter 59000, loss: 0.236427
 >> iter 60000, loss: 0.181260
   Number of active neurons: 4
 >> iter 61000, loss: 0.237206
 >> iter 62000, loss: 0.375157
 >> iter 63000, loss: 0.236166
 >> iter 64000, loss: 0.280077
 >> iter 65000, loss: 0.165044
 >> iter 66000, loss: 0.098365
 >> iter 67000, loss: 0.072469
 >> iter 68000, loss: 0.141424
 >> iter 69000, loss: 0.487016
 >> iter 70000, loss: 0.291787
   Number of active neurons: 4
 >> iter 71000, loss: 0.138645
 >> iter 72000, loss: 0.140621
 >> iter 73000, loss: 0.225368
 >> iter 74000, loss: 0.234699
 >> iter 75000, loss: 0.256644
 >> iter 76000, loss: 0.205874
 >> iter 77000, loss: 0.167153
 >> iter 78000, loss: 0.223464
 >> iter 79000, loss: 0.450168
 >> iter 80000, loss: 0.442831
   Number of active neurons: 4
 >> iter 81000, loss: 0.362373
 >> iter 82000, loss: 0.374527
 >> iter 83000, loss: 0.306906
 >> iter 84000, loss: 0.230184
 >> iter 85000, loss: 0.233910
 >> iter 86000, loss: 0.170820
 >> iter 87000, loss: 0.181335
 >> iter 88000, loss: 0.210581
 >> iter 89000, loss: 0.214737
 >> iter 90000, loss: 0.161583
   Number of active neurons: 4
 >> iter 91000, loss: 0.156823
 >> iter 92000, loss: 0.132096
 >> iter 93000, loss: 0.122648
 >> iter 94000, loss: 0.072474
 >> iter 95000, loss: 0.181718
 >> iter 96000, loss: 0.157349
 >> iter 97000, loss: 0.246094
 >> iter 98000, loss: 0.209108
 >> iter 99000, loss: 0.249602
 >> iter 100000, loss: 0.226905
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.128588
 >> iter 2000, loss: 8.143181
 >> iter 3000, loss: 3.558068
 >> iter 4000, loss: 1.916858
 >> iter 5000, loss: 0.952455
 >> iter 6000, loss: 0.652579
 >> iter 7000, loss: 0.672480
 >> iter 8000, loss: 0.400653
 >> iter 9000, loss: 0.527978
 >> iter 10000, loss: 0.471697
   Number of active neurons: 5
 >> iter 11000, loss: 0.376570
 >> iter 12000, loss: 0.276710
 >> iter 13000, loss: 0.246967
 >> iter 14000, loss: 0.289686
 >> iter 15000, loss: 0.410125
 >> iter 16000, loss: 0.295156
 >> iter 17000, loss: 0.401950
 >> iter 18000, loss: 0.207524
 >> iter 19000, loss: 0.336816
 >> iter 20000, loss: 0.345094
   Number of active neurons: 4
 >> iter 21000, loss: 0.390856
 >> iter 22000, loss: 0.389256
 >> iter 23000, loss: 0.325334
 >> iter 24000, loss: 0.267519
 >> iter 25000, loss: 0.367555
 >> iter 26000, loss: 0.378193
 >> iter 27000, loss: 0.444720
 >> iter 28000, loss: 0.386830
 >> iter 29000, loss: 0.229198
 >> iter 30000, loss: 0.322440
   Number of active neurons: 4
 >> iter 31000, loss: 0.390315
 >> iter 32000, loss: 0.238896
 >> iter 33000, loss: 0.272681
 >> iter 34000, loss: 0.249330
 >> iter 35000, loss: 0.430278
 >> iter 36000, loss: 0.421998
 >> iter 37000, loss: 0.338745
 >> iter 38000, loss: 0.271538
 >> iter 39000, loss: 0.405965
 >> iter 40000, loss: 0.398144
   Number of active neurons: 4
 >> iter 41000, loss: 0.494675
 >> iter 42000, loss: 0.339833
 >> iter 43000, loss: 0.283403
 >> iter 44000, loss: 0.219060
 >> iter 45000, loss: 0.309065
 >> iter 46000, loss: 0.338945
 >> iter 47000, loss: 0.299701
 >> iter 48000, loss: 0.220780
 >> iter 49000, loss: 0.340755
 >> iter 50000, loss: 0.462429
   Number of active neurons: 4
 >> iter 51000, loss: 0.420084
 >> iter 52000, loss: 0.460272
 >> iter 53000, loss: 0.360880
 >> iter 54000, loss: 0.400189
 >> iter 55000, loss: 0.600669
 >> iter 56000, loss: 0.467548
 >> iter 57000, loss: 0.352791
 >> iter 58000, loss: 0.557114
 >> iter 59000, loss: 0.644960
 >> iter 60000, loss: 0.511969
   Number of active neurons: 4
 >> iter 61000, loss: 0.342485
 >> iter 62000, loss: 0.284675
 >> iter 63000, loss: 0.407768
 >> iter 64000, loss: 0.344089
 >> iter 65000, loss: 0.325334
 >> iter 66000, loss: 0.222248
 >> iter 67000, loss: 0.317331
 >> iter 68000, loss: 0.248688
 >> iter 69000, loss: 0.415894
 >> iter 70000, loss: 0.320999
   Number of active neurons: 4
 >> iter 71000, loss: 0.377137
 >> iter 72000, loss: 0.348372
 >> iter 73000, loss: 0.326353
 >> iter 74000, loss: 0.433530
 >> iter 75000, loss: 0.243937
 >> iter 76000, loss: 0.368879
 >> iter 77000, loss: 0.228848
 >> iter 78000, loss: 0.275394
 >> iter 79000, loss: 0.246516
 >> iter 80000, loss: 0.378720
   Number of active neurons: 4
 >> iter 81000, loss: 0.336406
 >> iter 82000, loss: 0.407071
 >> iter 83000, loss: 0.294533
 >> iter 84000, loss: 0.263454
 >> iter 85000, loss: 0.173393
 >> iter 86000, loss: 0.262840
 >> iter 87000, loss: 0.283283
 >> iter 88000, loss: 0.239400
 >> iter 89000, loss: 0.214304
 >> iter 90000, loss: 0.340547
   Number of active neurons: 3
 >> iter 91000, loss: 0.340098
 >> iter 92000, loss: 0.266484
 >> iter 93000, loss: 0.224514
 >> iter 94000, loss: 0.267706
 >> iter 95000, loss: 0.273043
 >> iter 96000, loss: 0.232458
 >> iter 97000, loss: 0.351253
 >> iter 98000, loss: 0.428840
 >> iter 99000, loss: 0.357674
 >> iter 100000, loss: 0.364479
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.441723
 >> iter 2000, loss: 9.641601
 >> iter 3000, loss: 4.470655
 >> iter 4000, loss: 2.013467
 >> iter 5000, loss: 1.213438
 >> iter 6000, loss: 0.826680
 >> iter 7000, loss: 0.521088
 >> iter 8000, loss: 0.318607
 >> iter 9000, loss: 0.330390
 >> iter 10000, loss: 0.320175
   Number of active neurons: 3
 >> iter 11000, loss: 0.268998
 >> iter 12000, loss: 0.326951
 >> iter 13000, loss: 0.517804
 >> iter 14000, loss: 0.303225
 >> iter 15000, loss: 0.266687
 >> iter 16000, loss: 0.304196
 >> iter 17000, loss: 0.267291
 >> iter 18000, loss: 0.278854
 >> iter 19000, loss: 0.225409
 >> iter 20000, loss: 0.320139
   Number of active neurons: 3
 >> iter 21000, loss: 0.383339
 >> iter 22000, loss: 0.261900
 >> iter 23000, loss: 0.205759
 >> iter 24000, loss: 0.187839
 >> iter 25000, loss: 0.262250
 >> iter 26000, loss: 0.199036
 >> iter 27000, loss: 0.198374
 >> iter 28000, loss: 0.170421
 >> iter 29000, loss: 0.330254
 >> iter 30000, loss: 0.273905
   Number of active neurons: 3
 >> iter 31000, loss: 0.663715
 >> iter 32000, loss: 0.510946
 >> iter 33000, loss: 0.309909
 >> iter 34000, loss: 0.189621
 >> iter 35000, loss: 0.226352
 >> iter 36000, loss: 0.260244
 >> iter 37000, loss: 0.483399
 >> iter 38000, loss: 0.439467
 >> iter 39000, loss: 0.404674
 >> iter 40000, loss: 0.223786
   Number of active neurons: 3
 >> iter 41000, loss: 0.225592
 >> iter 42000, loss: 0.269232
 >> iter 43000, loss: 0.253336
 >> iter 44000, loss: 0.251788
 >> iter 45000, loss: 0.267967
 >> iter 46000, loss: 0.329612
 >> iter 47000, loss: 0.218280
 >> iter 48000, loss: 0.205057
 >> iter 49000, loss: 0.232026
 >> iter 50000, loss: 0.237111
   Number of active neurons: 3
 >> iter 51000, loss: 0.258322
 >> iter 52000, loss: 0.221808
 >> iter 53000, loss: 0.181076
 >> iter 54000, loss: 0.154792
 >> iter 55000, loss: 0.210493
 >> iter 56000, loss: 0.375657
 >> iter 57000, loss: 0.318103
 >> iter 58000, loss: 0.363031
 >> iter 59000, loss: 0.270841
 >> iter 60000, loss: 0.235083
   Number of active neurons: 3
 >> iter 61000, loss: 0.234973
 >> iter 62000, loss: 0.213804
 >> iter 63000, loss: 0.216203
 >> iter 64000, loss: 0.141878
 >> iter 65000, loss: 0.374130
 >> iter 66000, loss: 0.257873
 >> iter 67000, loss: 0.509178
 >> iter 68000, loss: 0.405017
 >> iter 69000, loss: 0.264942
 >> iter 70000, loss: 0.359665
   Number of active neurons: 3
 >> iter 71000, loss: 0.203563
 >> iter 72000, loss: 0.115710
 >> iter 73000, loss: 0.153731
 >> iter 74000, loss: 0.279890
 >> iter 75000, loss: 0.408040
 >> iter 76000, loss: 0.210406
 >> iter 77000, loss: 0.194099
 >> iter 78000, loss: 0.257130
 >> iter 79000, loss: 0.192991
 >> iter 80000, loss: 0.276014
   Number of active neurons: 3
 >> iter 81000, loss: 0.178494
 >> iter 82000, loss: 0.205941
 >> iter 83000, loss: 0.166913
 >> iter 84000, loss: 0.382240
 >> iter 85000, loss: 0.207650
 >> iter 86000, loss: 0.262558
 >> iter 87000, loss: 0.147006
 >> iter 88000, loss: 0.171087
 >> iter 89000, loss: 0.170520
 >> iter 90000, loss: 0.275394
   Number of active neurons: 3
 >> iter 91000, loss: 0.156074
 >> iter 92000, loss: 0.174134
 >> iter 93000, loss: 0.491486
 >> iter 94000, loss: 0.311033
 >> iter 95000, loss: 0.336370
 >> iter 96000, loss: 0.269708
 >> iter 97000, loss: 0.185481
 >> iter 98000, loss: 0.222380
 >> iter 99000, loss: 0.420134
 >> iter 100000, loss: 0.276107
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.446194
 >> iter 2000, loss: 8.402370
 >> iter 3000, loss: 3.654511
 >> iter 4000, loss: 1.722653
 >> iter 5000, loss: 0.895012
 >> iter 6000, loss: 0.532839
 >> iter 7000, loss: 0.338634
 >> iter 8000, loss: 0.452801
 >> iter 9000, loss: 0.365719
 >> iter 10000, loss: 0.231939
   Number of active neurons: 5
 >> iter 11000, loss: 0.299222
 >> iter 12000, loss: 0.270209
 >> iter 13000, loss: 0.350131
 >> iter 14000, loss: 0.440777
 >> iter 15000, loss: 0.326324
 >> iter 16000, loss: 0.272341
 >> iter 17000, loss: 0.275525
 >> iter 18000, loss: 0.677411
 >> iter 19000, loss: 0.531897
 >> iter 20000, loss: 0.301650
   Number of active neurons: 5
 >> iter 21000, loss: 0.349429
 >> iter 22000, loss: 0.308564
 >> iter 23000, loss: 0.288182
 >> iter 24000, loss: 0.529700
 >> iter 25000, loss: 0.483807
 >> iter 26000, loss: 0.474580
 >> iter 27000, loss: 0.390831
 >> iter 28000, loss: 0.287255
 >> iter 29000, loss: 0.328662
 >> iter 30000, loss: 0.257038
   Number of active neurons: 5
 >> iter 31000, loss: 0.365028
 >> iter 32000, loss: 0.417061
 >> iter 33000, loss: 0.418962
 >> iter 34000, loss: 0.624002
 >> iter 35000, loss: 0.452471
 >> iter 36000, loss: 0.266641
 >> iter 37000, loss: 0.199036
 >> iter 38000, loss: 0.304194
 >> iter 39000, loss: 0.383744
 >> iter 40000, loss: 0.335667
   Number of active neurons: 5
 >> iter 41000, loss: 0.273321
 >> iter 42000, loss: 0.167142
 >> iter 43000, loss: 0.360231
 >> iter 44000, loss: 0.321531
 >> iter 45000, loss: 0.316202
 >> iter 46000, loss: 0.338458
 >> iter 47000, loss: 0.340001
 >> iter 48000, loss: 0.169448
 >> iter 49000, loss: 0.183327
 >> iter 50000, loss: 0.162423
   Number of active neurons: 5
 >> iter 51000, loss: 0.322231
 >> iter 52000, loss: 0.153152
 >> iter 53000, loss: 0.324519
 >> iter 54000, loss: 0.225410
 >> iter 55000, loss: 0.145250
 >> iter 56000, loss: 0.253460
 >> iter 57000, loss: 0.340302
 >> iter 58000, loss: 0.252674
 >> iter 59000, loss: 0.315196
 >> iter 60000, loss: 0.352239
   Number of active neurons: 3
 >> iter 61000, loss: 0.280312
 >> iter 62000, loss: 0.165000
 >> iter 63000, loss: 0.229124
 >> iter 64000, loss: 0.239587
 >> iter 65000, loss: 0.250098
 >> iter 66000, loss: 0.259583
 >> iter 67000, loss: 0.293095
 >> iter 68000, loss: 0.208624
 >> iter 69000, loss: 0.183019
 >> iter 70000, loss: 0.250145
   Number of active neurons: 3
 >> iter 71000, loss: 0.312956
 >> iter 72000, loss: 0.268340
 >> iter 73000, loss: 0.247087
 >> iter 74000, loss: 0.298058
 >> iter 75000, loss: 0.171606
 >> iter 76000, loss: 0.291759
 >> iter 77000, loss: 0.314772
 >> iter 78000, loss: 0.225753
 >> iter 79000, loss: 0.296508
 >> iter 80000, loss: 0.200171
   Number of active neurons: 3
 >> iter 81000, loss: 0.162520
 >> iter 82000, loss: 0.199710
 >> iter 83000, loss: 0.268331
 >> iter 84000, loss: 0.292769
 >> iter 85000, loss: 0.319772
 >> iter 86000, loss: 0.320922
 >> iter 87000, loss: 0.382676
 >> iter 88000, loss: 0.207587
 >> iter 89000, loss: 0.222385
 >> iter 90000, loss: 0.263476
   Number of active neurons: 3
 >> iter 91000, loss: 0.287707
 >> iter 92000, loss: 0.380194
 >> iter 93000, loss: 0.447918
 >> iter 94000, loss: 0.195294
 >> iter 95000, loss: 0.363085
 >> iter 96000, loss: 0.271264
 >> iter 97000, loss: 0.253021
 >> iter 98000, loss: 0.314180
 >> iter 99000, loss: 0.267707
 >> iter 100000, loss: 0.171120
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.329777
 >> iter 2000, loss: 10.130481
 >> iter 3000, loss: 5.232529
 >> iter 4000, loss: 2.531037
 >> iter 5000, loss: 1.349817
 >> iter 6000, loss: 0.942714
 >> iter 7000, loss: 0.836607
 >> iter 8000, loss: 1.075002
 >> iter 9000, loss: 0.691563
 >> iter 10000, loss: 0.568899
   Number of active neurons: 5
 >> iter 11000, loss: 0.513412
 >> iter 12000, loss: 0.495047
 >> iter 13000, loss: 0.520869
 >> iter 14000, loss: 0.417972
 >> iter 15000, loss: 0.529994
 >> iter 16000, loss: 0.588793
 >> iter 17000, loss: 0.624055
 >> iter 18000, loss: 0.301489
 >> iter 19000, loss: 0.444165
 >> iter 20000, loss: 0.585011
   Number of active neurons: 4
 >> iter 21000, loss: 0.553720
 >> iter 22000, loss: 0.477068
 >> iter 23000, loss: 0.381830
 >> iter 24000, loss: 0.609292
 >> iter 25000, loss: 0.404483
 >> iter 26000, loss: 0.586924
 >> iter 27000, loss: 0.574103
 >> iter 28000, loss: 0.542141
 >> iter 29000, loss: 0.502237
 >> iter 30000, loss: 0.640305
   Number of active neurons: 4
 >> iter 31000, loss: 0.376874
 >> iter 32000, loss: 0.419889
 >> iter 33000, loss: 0.650961
 >> iter 34000, loss: 0.407191
 >> iter 35000, loss: 0.746336
 >> iter 36000, loss: 0.519901
 >> iter 37000, loss: 0.410651
 >> iter 38000, loss: 0.281443
 >> iter 39000, loss: 0.484755
 >> iter 40000, loss: 0.839251
   Number of active neurons: 4
 >> iter 41000, loss: 0.826516
 >> iter 42000, loss: 0.624776
 >> iter 43000, loss: 0.638391
 >> iter 44000, loss: 0.483131
 >> iter 45000, loss: 0.396900
 >> iter 46000, loss: 0.303295
 >> iter 47000, loss: 0.224041
 >> iter 48000, loss: 0.492933
 >> iter 49000, loss: 0.474066
 >> iter 50000, loss: 0.638623
   Number of active neurons: 4
 >> iter 51000, loss: 0.428505
 >> iter 52000, loss: 0.407664
 >> iter 53000, loss: 0.362403
 >> iter 54000, loss: 0.463713
 >> iter 55000, loss: 0.529848
 >> iter 56000, loss: 0.383483
 >> iter 57000, loss: 0.409592
 >> iter 58000, loss: 0.600359
 >> iter 59000, loss: 0.598858
 >> iter 60000, loss: 0.863024
   Number of active neurons: 4
 >> iter 61000, loss: 0.644790
 >> iter 62000, loss: 0.679852
 >> iter 63000, loss: 0.476399
 >> iter 64000, loss: 0.585548
 >> iter 65000, loss: 0.637235
 >> iter 66000, loss: 0.518157
 >> iter 67000, loss: 0.515198
 >> iter 68000, loss: 0.441172
 >> iter 69000, loss: 0.362236
 >> iter 70000, loss: 0.458702
   Number of active neurons: 4
 >> iter 71000, loss: 0.422237
 >> iter 72000, loss: 0.374753
 >> iter 73000, loss: 0.271197
 >> iter 74000, loss: 0.610013
 >> iter 75000, loss: 0.595842
 >> iter 76000, loss: 0.471026
 >> iter 77000, loss: 0.567230
 >> iter 78000, loss: 0.504091
 >> iter 79000, loss: 0.419627
 >> iter 80000, loss: 0.365666
   Number of active neurons: 4
 >> iter 81000, loss: 0.420744
 >> iter 82000, loss: 0.529193
 >> iter 83000, loss: 0.515543
 >> iter 84000, loss: 0.464059
 >> iter 85000, loss: 0.450044
 >> iter 86000, loss: 0.546943
 >> iter 87000, loss: 0.562027
 >> iter 88000, loss: 0.574731
 >> iter 89000, loss: 0.536666
 >> iter 90000, loss: 0.473326
   Number of active neurons: 4
 >> iter 91000, loss: 0.486632
 >> iter 92000, loss: 0.526175
 >> iter 93000, loss: 0.474281
 >> iter 94000, loss: 0.456367
 >> iter 95000, loss: 0.421109
 >> iter 96000, loss: 0.370369
 >> iter 97000, loss: 0.477438
 >> iter 98000, loss: 0.512696
 >> iter 99000, loss: 0.674437
 >> iter 100000, loss: 0.573116
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 17.470425
 >> iter 2000, loss: 9.286619
 >> iter 3000, loss: 4.390300
 >> iter 4000, loss: 2.084341
 >> iter 5000, loss: 1.315826
 >> iter 6000, loss: 0.880857
 >> iter 7000, loss: 0.513897
 >> iter 8000, loss: 0.386840
 >> iter 9000, loss: 0.313138
 >> iter 10000, loss: 0.392923
   Number of active neurons: 10
 >> iter 11000, loss: 0.213639
 >> iter 12000, loss: 0.405575
 >> iter 13000, loss: 0.317033
 >> iter 14000, loss: 0.301492
 >> iter 15000, loss: 0.309984
 >> iter 16000, loss: 0.385081
 >> iter 17000, loss: 0.332902
 >> iter 18000, loss: 0.269089
 >> iter 19000, loss: 0.323373
 >> iter 20000, loss: 0.188611
   Number of active neurons: 9
 >> iter 21000, loss: 0.173118
 >> iter 22000, loss: 0.168156
 >> iter 23000, loss: 0.334242
 >> iter 24000, loss: 0.321988
 >> iter 25000, loss: 0.282896
 >> iter 26000, loss: 0.186340
 >> iter 27000, loss: 0.153620
 >> iter 28000, loss: 0.217394
 >> iter 29000, loss: 0.181733
 >> iter 30000, loss: 0.283767
   Number of active neurons: 6
 >> iter 31000, loss: 0.231818
 >> iter 32000, loss: 0.313168
 >> iter 33000, loss: 0.235500
 >> iter 34000, loss: 0.165804
 >> iter 35000, loss: 0.204539
 >> iter 36000, loss: 0.202724
 >> iter 37000, loss: 0.342569
 >> iter 38000, loss: 0.198135
 >> iter 39000, loss: 0.203360
 >> iter 40000, loss: 0.455872
   Number of active neurons: 6
 >> iter 41000, loss: 0.420834
 >> iter 42000, loss: 0.381376
 >> iter 43000, loss: 0.351185
 >> iter 44000, loss: 0.229958
 >> iter 45000, loss: 0.272732
 >> iter 46000, loss: 0.165785
 >> iter 47000, loss: 0.190717
 >> iter 48000, loss: 0.277725
 >> iter 49000, loss: 0.281105
 >> iter 50000, loss: 0.321075
   Number of active neurons: 6
 >> iter 51000, loss: 0.424048
 >> iter 52000, loss: 0.351583
 >> iter 53000, loss: 0.350390
 >> iter 54000, loss: 0.218057
 >> iter 55000, loss: 0.227578
 >> iter 56000, loss: 0.197429
 >> iter 57000, loss: 0.176670
 >> iter 58000, loss: 0.156893
 >> iter 59000, loss: 0.169526
 >> iter 60000, loss: 0.100658
   Number of active neurons: 6
 >> iter 61000, loss: 0.162254
 >> iter 62000, loss: 0.308100
 >> iter 63000, loss: 0.265504
 >> iter 64000, loss: 0.257936
 >> iter 65000, loss: 0.148842
 >> iter 66000, loss: 0.298645
 >> iter 67000, loss: 0.282047
 >> iter 68000, loss: 0.236464
 >> iter 69000, loss: 0.165569
 >> iter 70000, loss: 0.273438
   Number of active neurons: 5
 >> iter 71000, loss: 0.315794
 >> iter 72000, loss: 0.420204
 >> iter 73000, loss: 0.245977
 >> iter 74000, loss: 0.227294
 >> iter 75000, loss: 0.271478
 >> iter 76000, loss: 0.320524
 >> iter 77000, loss: 0.191811
 >> iter 78000, loss: 0.294067
 >> iter 79000, loss: 0.276558
 >> iter 80000, loss: 0.187862
   Number of active neurons: 5
 >> iter 81000, loss: 0.139451
 >> iter 82000, loss: 0.351353
 >> iter 83000, loss: 0.242897
 >> iter 84000, loss: 0.162098
 >> iter 85000, loss: 0.328115
 >> iter 86000, loss: 0.189984
 >> iter 87000, loss: 0.116252
 >> iter 88000, loss: 0.106213
 >> iter 89000, loss: 0.245871
 >> iter 90000, loss: 0.266351
   Number of active neurons: 5
 >> iter 91000, loss: 0.248469
 >> iter 92000, loss: 0.262434
 >> iter 93000, loss: 0.260808
 >> iter 94000, loss: 0.214799
 >> iter 95000, loss: 0.161327
 >> iter 96000, loss: 0.277143
 >> iter 97000, loss: 0.172294
 >> iter 98000, loss: 0.196286
 >> iter 99000, loss: 0.264409
 >> iter 100000, loss: 0.190460
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.368288
 >> iter 2000, loss: 8.094539
 >> iter 3000, loss: 3.470616
 >> iter 4000, loss: 1.635074
 >> iter 5000, loss: 0.901997
 >> iter 6000, loss: 0.510342
 >> iter 7000, loss: 0.505428
 >> iter 8000, loss: 0.346347
 >> iter 9000, loss: 0.399724
 >> iter 10000, loss: 0.500187
   Number of active neurons: 5
 >> iter 11000, loss: 0.458543
 >> iter 12000, loss: 0.463766
 >> iter 13000, loss: 0.470024
 >> iter 14000, loss: 0.258888
 >> iter 15000, loss: 0.470020
 >> iter 16000, loss: 0.407682
 >> iter 17000, loss: 0.290616
 >> iter 18000, loss: 0.342295
 >> iter 19000, loss: 0.315476
 >> iter 20000, loss: 0.265882
   Number of active neurons: 5
 >> iter 21000, loss: 0.404606
 >> iter 22000, loss: 0.266821
 >> iter 23000, loss: 0.283042
 >> iter 24000, loss: 0.477882
 >> iter 25000, loss: 0.417108
 >> iter 26000, loss: 0.390219
 >> iter 27000, loss: 0.294759
 >> iter 28000, loss: 0.276187
 >> iter 29000, loss: 0.324416
 >> iter 30000, loss: 0.607664
   Number of active neurons: 5
 >> iter 31000, loss: 0.407115
 >> iter 32000, loss: 0.376112
 >> iter 33000, loss: 0.200049
 >> iter 34000, loss: 0.184639
 >> iter 35000, loss: 0.263296
 >> iter 36000, loss: 0.239780
 >> iter 37000, loss: 0.475999
 >> iter 38000, loss: 0.293504
 >> iter 39000, loss: 0.325971
 >> iter 40000, loss: 0.242121
   Number of active neurons: 5
 >> iter 41000, loss: 0.170060
 >> iter 42000, loss: 0.096468
 >> iter 43000, loss: 0.244889
 >> iter 44000, loss: 0.314138
 >> iter 45000, loss: 0.353821
 >> iter 46000, loss: 0.279877
 >> iter 47000, loss: 0.237289
 >> iter 48000, loss: 0.252797
 >> iter 49000, loss: 0.260869
 >> iter 50000, loss: 0.269604
   Number of active neurons: 5
 >> iter 51000, loss: 0.210705
 >> iter 52000, loss: 0.221398
 >> iter 53000, loss: 0.142194
 >> iter 54000, loss: 0.142705
 >> iter 55000, loss: 0.135958
 >> iter 56000, loss: 0.187130
 >> iter 57000, loss: 0.217033
 >> iter 58000, loss: 0.148320
 >> iter 59000, loss: 0.111117
 >> iter 60000, loss: 0.260065
   Number of active neurons: 4
 >> iter 61000, loss: 0.244461
 >> iter 62000, loss: 0.291096
 >> iter 63000, loss: 0.292145
 >> iter 64000, loss: 0.248480
 >> iter 65000, loss: 0.282141
 >> iter 66000, loss: 0.134694
 >> iter 67000, loss: 0.180513
 >> iter 68000, loss: 0.229053
 >> iter 69000, loss: 0.178746
 >> iter 70000, loss: 0.359902
   Number of active neurons: 4
 >> iter 71000, loss: 0.291187
 >> iter 72000, loss: 0.232162
 >> iter 73000, loss: 0.329160
 >> iter 74000, loss: 0.199380
 >> iter 75000, loss: 0.120257
 >> iter 76000, loss: 0.585765
 >> iter 77000, loss: 0.292623
 >> iter 78000, loss: 0.189609
 >> iter 79000, loss: 0.200397
 >> iter 80000, loss: 0.158536
   Number of active neurons: 3
 >> iter 81000, loss: 0.251946
 >> iter 82000, loss: 0.240561
 >> iter 83000, loss: 0.236518
 >> iter 84000, loss: 0.291663
 >> iter 85000, loss: 0.408520
 >> iter 86000, loss: 0.357403
 >> iter 87000, loss: 0.244775
 >> iter 88000, loss: 0.321249
 >> iter 89000, loss: 0.264589
 >> iter 90000, loss: 0.364236
   Number of active neurons: 3
 >> iter 91000, loss: 0.321558
 >> iter 92000, loss: 0.437823
 >> iter 93000, loss: 0.274077
 >> iter 94000, loss: 0.237499
 >> iter 95000, loss: 0.236140
 >> iter 96000, loss: 0.279610
 >> iter 97000, loss: 0.217938
 >> iter 98000, loss: 0.144704
 >> iter 99000, loss: 0.428157
 >> iter 100000, loss: 0.451938
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.462244
 >> iter 2000, loss: 9.353730
 >> iter 3000, loss: 4.614916
 >> iter 4000, loss: 2.010481
 >> iter 5000, loss: 1.064133
 >> iter 6000, loss: 0.735444
 >> iter 7000, loss: 0.460180
 >> iter 8000, loss: 0.434676
 >> iter 9000, loss: 0.251529
 >> iter 10000, loss: 0.305151
   Number of active neurons: 4
 >> iter 11000, loss: 0.357191
 >> iter 12000, loss: 0.404839
 >> iter 13000, loss: 0.372348
 >> iter 14000, loss: 0.231356
 >> iter 15000, loss: 0.370329
 >> iter 16000, loss: 0.234205
 >> iter 17000, loss: 0.256133
 >> iter 18000, loss: 0.160646
 >> iter 19000, loss: 0.111617
 >> iter 20000, loss: 0.183495
   Number of active neurons: 4
 >> iter 21000, loss: 0.249032
 >> iter 22000, loss: 0.375784
 >> iter 23000, loss: 0.322635
 >> iter 24000, loss: 0.406419
 >> iter 25000, loss: 0.399107
 >> iter 26000, loss: 0.436187
 >> iter 27000, loss: 0.283956
 >> iter 28000, loss: 0.183063
 >> iter 29000, loss: 0.391771
 >> iter 30000, loss: 0.349700
   Number of active neurons: 3
 >> iter 31000, loss: 0.282584
 >> iter 32000, loss: 0.267135
 >> iter 33000, loss: 0.216348
 >> iter 34000, loss: 0.157787
 >> iter 35000, loss: 0.424779
 >> iter 36000, loss: 0.443635
 >> iter 37000, loss: 0.330603
 >> iter 38000, loss: 0.195658
 >> iter 39000, loss: 0.206579
 >> iter 40000, loss: 0.413167
   Number of active neurons: 3
 >> iter 41000, loss: 0.351345
 >> iter 42000, loss: 0.272653
 >> iter 43000, loss: 0.377895
 >> iter 44000, loss: 0.437663
 >> iter 45000, loss: 0.256124
 >> iter 46000, loss: 0.238571
 >> iter 47000, loss: 0.178232
 >> iter 48000, loss: 0.336200
 >> iter 49000, loss: 0.265804
 >> iter 50000, loss: 0.184480
   Number of active neurons: 3
 >> iter 51000, loss: 0.120089
 >> iter 52000, loss: 0.169197
 >> iter 53000, loss: 0.193821
 >> iter 54000, loss: 0.236227
 >> iter 55000, loss: 0.145777
 >> iter 56000, loss: 0.186591
 >> iter 57000, loss: 0.219759
 >> iter 58000, loss: 0.286802
 >> iter 59000, loss: 0.247351
 >> iter 60000, loss: 0.242666
   Number of active neurons: 3
 >> iter 61000, loss: 0.207357
 >> iter 62000, loss: 0.244028
 >> iter 63000, loss: 0.223512
 >> iter 64000, loss: 0.315564
 >> iter 65000, loss: 0.281790
 >> iter 66000, loss: 0.297446
 >> iter 67000, loss: 0.289792
 >> iter 68000, loss: 0.299826
 >> iter 69000, loss: 0.283952
 >> iter 70000, loss: 0.416424
   Number of active neurons: 3
 >> iter 71000, loss: 0.288360
 >> iter 72000, loss: 0.200055
 >> iter 73000, loss: 0.323413
 >> iter 74000, loss: 0.163639
 >> iter 75000, loss: 0.193686
 >> iter 76000, loss: 0.171145
 >> iter 77000, loss: 0.125720
 >> iter 78000, loss: 0.198722
 >> iter 79000, loss: 0.250468
 >> iter 80000, loss: 0.444489
   Number of active neurons: 3
 >> iter 81000, loss: 0.317788
 >> iter 82000, loss: 0.497939
 >> iter 83000, loss: 0.285699
 >> iter 84000, loss: 0.210709
 >> iter 85000, loss: 0.229470
 >> iter 86000, loss: 0.157662
 >> iter 87000, loss: 0.150891
 >> iter 88000, loss: 0.204658
 >> iter 89000, loss: 0.401579
 >> iter 90000, loss: 0.380462
   Number of active neurons: 3
 >> iter 91000, loss: 0.308561
 >> iter 92000, loss: 0.195593
 >> iter 93000, loss: 0.222858
 >> iter 94000, loss: 0.309187
 >> iter 95000, loss: 0.312386
 >> iter 96000, loss: 0.393423
 >> iter 97000, loss: 0.400283
 >> iter 98000, loss: 0.220826
 >> iter 99000, loss: 0.223217
 >> iter 100000, loss: 0.451935
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.946463
 >> iter 2000, loss: 8.832637
 >> iter 3000, loss: 4.208436
 >> iter 4000, loss: 2.008317
 >> iter 5000, loss: 0.911036
 >> iter 6000, loss: 0.836699
 >> iter 7000, loss: 0.439358
 >> iter 8000, loss: 0.257599
 >> iter 9000, loss: 0.266220
 >> iter 10000, loss: 0.189391
   Number of active neurons: 5
 >> iter 11000, loss: 0.269392
 >> iter 12000, loss: 0.529699
 >> iter 13000, loss: 0.323553
 >> iter 14000, loss: 0.441473
 >> iter 15000, loss: 0.230188
 >> iter 16000, loss: 0.384742
 >> iter 17000, loss: 0.296183
 >> iter 18000, loss: 0.265704
 >> iter 19000, loss: 0.447185
 >> iter 20000, loss: 0.267366
   Number of active neurons: 5
 >> iter 21000, loss: 0.477704
 >> iter 22000, loss: 0.276794
 >> iter 23000, loss: 0.196766
 >> iter 24000, loss: 0.204405
 >> iter 25000, loss: 0.322141
 >> iter 26000, loss: 0.200979
 >> iter 27000, loss: 0.362537
 >> iter 28000, loss: 0.371860
 >> iter 29000, loss: 0.210769
 >> iter 30000, loss: 0.395552
   Number of active neurons: 5
 >> iter 31000, loss: 0.257613
 >> iter 32000, loss: 0.377489
 >> iter 33000, loss: 0.355901
 >> iter 34000, loss: 0.377888
 >> iter 35000, loss: 0.298218
 >> iter 36000, loss: 0.302985
 >> iter 37000, loss: 0.213989
 >> iter 38000, loss: 0.173490
 >> iter 39000, loss: 0.272186
 >> iter 40000, loss: 0.497958
   Number of active neurons: 5
 >> iter 41000, loss: 0.330621
 >> iter 42000, loss: 0.210123
 >> iter 43000, loss: 0.234563
 >> iter 44000, loss: 0.313094
 >> iter 45000, loss: 0.428656
 >> iter 46000, loss: 0.198347
 >> iter 47000, loss: 0.219200
 >> iter 48000, loss: 0.200811
 >> iter 49000, loss: 0.238852
 >> iter 50000, loss: 0.289252
   Number of active neurons: 5
 >> iter 51000, loss: 0.305070
 >> iter 52000, loss: 0.253434
 >> iter 53000, loss: 0.171255
 >> iter 54000, loss: 0.252803
 >> iter 55000, loss: 0.148755
 >> iter 56000, loss: 0.381222
 >> iter 57000, loss: 0.259154
 >> iter 58000, loss: 0.223030
 >> iter 59000, loss: 0.413959
 >> iter 60000, loss: 0.308950
   Number of active neurons: 4
 >> iter 61000, loss: 0.233599
 >> iter 62000, loss: 0.198487
 >> iter 63000, loss: 0.114758
 >> iter 64000, loss: 0.412638
 >> iter 65000, loss: 0.243077
 >> iter 66000, loss: 0.147915
 >> iter 67000, loss: 0.253474
 >> iter 68000, loss: 0.131822
 >> iter 69000, loss: 0.455452
 >> iter 70000, loss: 0.254837
   Number of active neurons: 3
 >> iter 71000, loss: 0.159317
 >> iter 72000, loss: 0.160145
 >> iter 73000, loss: 0.375331
 >> iter 74000, loss: 0.254331
 >> iter 75000, loss: 0.162741
 >> iter 76000, loss: 0.322069
 >> iter 77000, loss: 0.295197
 >> iter 78000, loss: 0.276021
 >> iter 79000, loss: 0.311865
 >> iter 80000, loss: 0.253860
   Number of active neurons: 4
 >> iter 81000, loss: 0.240439
 >> iter 82000, loss: 0.173164
 >> iter 83000, loss: 0.229708
 >> iter 84000, loss: 0.313053
 >> iter 85000, loss: 0.295634
 >> iter 86000, loss: 0.318847
 >> iter 87000, loss: 0.222295
 >> iter 88000, loss: 0.192003
 >> iter 89000, loss: 0.253434
 >> iter 90000, loss: 0.285100
   Number of active neurons: 3
 >> iter 91000, loss: 0.210474
 >> iter 92000, loss: 0.176323
 >> iter 93000, loss: 0.146039
 >> iter 94000, loss: 0.224929
 >> iter 95000, loss: 0.149324
 >> iter 96000, loss: 0.128998
 >> iter 97000, loss: 0.140674
 >> iter 98000, loss: 0.184818
 >> iter 99000, loss: 0.230860
 >> iter 100000, loss: 0.213380
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.104144
 >> iter 2000, loss: 10.234711
 >> iter 3000, loss: 4.864857
 >> iter 4000, loss: 2.373812
 >> iter 5000, loss: 1.127684
 >> iter 6000, loss: 0.887540
 >> iter 7000, loss: 0.876623
 >> iter 8000, loss: 0.721762
 >> iter 9000, loss: 0.417944
 >> iter 10000, loss: 0.267273
   Number of active neurons: 8
 >> iter 11000, loss: 0.180453
 >> iter 12000, loss: 0.385469
 >> iter 13000, loss: 0.411659
 >> iter 14000, loss: 0.433051
 >> iter 15000, loss: 0.374324
 >> iter 16000, loss: 0.213709
 >> iter 17000, loss: 0.115369
 >> iter 18000, loss: 0.196743
 >> iter 19000, loss: 0.350427
 >> iter 20000, loss: 0.268845
   Number of active neurons: 7
 >> iter 21000, loss: 0.222108
 >> iter 22000, loss: 0.259627
 >> iter 23000, loss: 0.172371
 >> iter 24000, loss: 0.398455
 >> iter 25000, loss: 0.305403
 >> iter 26000, loss: 0.286416
 >> iter 27000, loss: 0.150253
 >> iter 28000, loss: 0.276167
 >> iter 29000, loss: 0.366043
 >> iter 30000, loss: 0.227611
   Number of active neurons: 5
 >> iter 31000, loss: 0.334139
 >> iter 32000, loss: 0.373657
 >> iter 33000, loss: 0.288834
 >> iter 34000, loss: 0.264393
 >> iter 35000, loss: 0.209497
 >> iter 36000, loss: 0.294263
 >> iter 37000, loss: 0.232077
 >> iter 38000, loss: 0.191639
 >> iter 39000, loss: 0.185405
 >> iter 40000, loss: 0.280395
   Number of active neurons: 4
 >> iter 41000, loss: 0.308233
 >> iter 42000, loss: 0.317020
 >> iter 43000, loss: 0.282308
 >> iter 44000, loss: 0.277797
 >> iter 45000, loss: 0.204772
 >> iter 46000, loss: 0.316715
 >> iter 47000, loss: 0.218725
 >> iter 48000, loss: 0.245569
 >> iter 49000, loss: 0.142719
 >> iter 50000, loss: 0.197251
   Number of active neurons: 3
 >> iter 51000, loss: 0.198924
 >> iter 52000, loss: 0.153874
 >> iter 53000, loss: 0.356843
 >> iter 54000, loss: 0.246586
 >> iter 55000, loss: 0.205016
 >> iter 56000, loss: 0.320530
 >> iter 57000, loss: 0.262095
 >> iter 58000, loss: 0.314926
 >> iter 59000, loss: 0.210640
 >> iter 60000, loss: 0.156951
   Number of active neurons: 3
 >> iter 61000, loss: 0.271838
 >> iter 62000, loss: 0.164233
 >> iter 63000, loss: 0.116630
 >> iter 64000, loss: 0.163234
 >> iter 65000, loss: 0.275644
 >> iter 66000, loss: 0.315629
 >> iter 67000, loss: 0.173858
 >> iter 68000, loss: 0.237777
 >> iter 69000, loss: 0.368812
 >> iter 70000, loss: 0.285124
   Number of active neurons: 3
 >> iter 71000, loss: 0.278282
 >> iter 72000, loss: 0.280189
 >> iter 73000, loss: 0.261617
 >> iter 74000, loss: 0.219786
 >> iter 75000, loss: 0.310479
 >> iter 76000, loss: 0.362411
 >> iter 77000, loss: 0.260513
 >> iter 78000, loss: 0.396293
 >> iter 79000, loss: 0.242094
 >> iter 80000, loss: 0.144184
   Number of active neurons: 3
 >> iter 81000, loss: 0.177337
 >> iter 82000, loss: 0.251775
 >> iter 83000, loss: 0.211523
 >> iter 84000, loss: 0.281284
 >> iter 85000, loss: 0.138350
 >> iter 86000, loss: 0.279888
 >> iter 87000, loss: 0.259467
 >> iter 88000, loss: 0.249019
 >> iter 89000, loss: 0.189054
 >> iter 90000, loss: 0.272873
   Number of active neurons: 3
 >> iter 91000, loss: 0.346558
 >> iter 92000, loss: 0.317739
 >> iter 93000, loss: 0.276613
 >> iter 94000, loss: 0.192828
 >> iter 95000, loss: 0.378506
 >> iter 96000, loss: 0.230462
 >> iter 97000, loss: 0.245005
 >> iter 98000, loss: 0.179652
 >> iter 99000, loss: 0.267470
 >> iter 100000, loss: 0.232148
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

