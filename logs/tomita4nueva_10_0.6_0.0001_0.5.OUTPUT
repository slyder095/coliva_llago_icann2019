 > Problema: tomita4nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.594082
 >> iter 2000, loss: 8.864409
 >> iter 3000, loss: 4.204332
 >> iter 4000, loss: 2.137425
 >> iter 5000, loss: 1.111026
 >> iter 6000, loss: 0.625747
 >> iter 7000, loss: 0.463722
 >> iter 8000, loss: 0.348688
 >> iter 9000, loss: 0.369375
 >> iter 10000, loss: 0.389906
   Number of active neurons: 4
 >> iter 11000, loss: 0.249945
 >> iter 12000, loss: 0.202949
 >> iter 13000, loss: 0.302114
 >> iter 14000, loss: 0.250232
 >> iter 15000, loss: 0.496652
 >> iter 16000, loss: 0.417012
 >> iter 17000, loss: 0.394437
 >> iter 18000, loss: 0.236258
 >> iter 19000, loss: 0.171872
 >> iter 20000, loss: 0.391749
   Number of active neurons: 4
 >> iter 21000, loss: 0.256983
 >> iter 22000, loss: 0.325867
 >> iter 23000, loss: 0.292429
 >> iter 24000, loss: 0.239051
 >> iter 25000, loss: 0.166444
 >> iter 26000, loss: 0.279659
 >> iter 27000, loss: 0.293013
 >> iter 28000, loss: 0.232935
 >> iter 29000, loss: 0.298314
 >> iter 30000, loss: 0.331343
   Number of active neurons: 4
 >> iter 31000, loss: 0.232029
 >> iter 32000, loss: 0.281738
 >> iter 33000, loss: 0.166816
 >> iter 34000, loss: 0.285857
 >> iter 35000, loss: 0.323527
 >> iter 36000, loss: 0.326337
 >> iter 37000, loss: 0.288326
 >> iter 38000, loss: 0.183827
 >> iter 39000, loss: 0.285473
 >> iter 40000, loss: 0.225368
   Number of active neurons: 4
 >> iter 41000, loss: 0.309276
 >> iter 42000, loss: 0.218812
 >> iter 43000, loss: 0.149487
 >> iter 44000, loss: 0.255819
 >> iter 45000, loss: 0.279792
 >> iter 46000, loss: 0.359703
 >> iter 47000, loss: 0.179476
 >> iter 48000, loss: 0.288819
 >> iter 49000, loss: 0.262762
 >> iter 50000, loss: 0.256810
   Number of active neurons: 4
 >> iter 51000, loss: 0.311184
 >> iter 52000, loss: 0.226586
 >> iter 53000, loss: 0.348216
 >> iter 54000, loss: 0.190159
 >> iter 55000, loss: 0.139314
 >> iter 56000, loss: 0.177345
 >> iter 57000, loss: 0.163571
 >> iter 58000, loss: 0.210952
 >> iter 59000, loss: 0.482437
 >> iter 60000, loss: 0.256550
   Number of active neurons: 4
 >> iter 61000, loss: 0.412697
 >> iter 62000, loss: 0.305277
 >> iter 63000, loss: 0.259624
 >> iter 64000, loss: 0.158679
 >> iter 65000, loss: 0.285601
 >> iter 66000, loss: 0.268219
 >> iter 67000, loss: 0.276560
 >> iter 68000, loss: 0.235168
 >> iter 69000, loss: 0.178994
 >> iter 70000, loss: 0.126561
   Number of active neurons: 4
 >> iter 71000, loss: 0.316694
 >> iter 72000, loss: 0.550239
 >> iter 73000, loss: 0.421813
 >> iter 74000, loss: 0.277663
 >> iter 75000, loss: 0.257749
 >> iter 76000, loss: 0.278332
 >> iter 77000, loss: 0.267945
 >> iter 78000, loss: 0.229559
 >> iter 79000, loss: 0.237260
 >> iter 80000, loss: 0.362235
   Number of active neurons: 4
 >> iter 81000, loss: 0.217159
 >> iter 82000, loss: 0.190117
 >> iter 83000, loss: 0.245942
 >> iter 84000, loss: 0.253812
 >> iter 85000, loss: 0.235538
 >> iter 86000, loss: 0.223799
 >> iter 87000, loss: 0.282755
 >> iter 88000, loss: 0.267657
 >> iter 89000, loss: 0.301922
 >> iter 90000, loss: 0.271665
   Number of active neurons: 4
 >> iter 91000, loss: 0.224261
 >> iter 92000, loss: 0.201459
 >> iter 93000, loss: 0.277893
 >> iter 94000, loss: 0.206608
 >> iter 95000, loss: 0.275506
 >> iter 96000, loss: 0.208212
 >> iter 97000, loss: 0.461123
 >> iter 98000, loss: 0.427107
 >> iter 99000, loss: 0.307744
 >> iter 100000, loss: 0.446138
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.138539
 >> iter 2000, loss: 9.167023
 >> iter 3000, loss: 4.286725
 >> iter 4000, loss: 2.035750
 >> iter 5000, loss: 0.995348
 >> iter 6000, loss: 0.719675
 >> iter 7000, loss: 0.503285
 >> iter 8000, loss: 0.485574
 >> iter 9000, loss: 0.380321
 >> iter 10000, loss: 0.290818
   Number of active neurons: 4
 >> iter 11000, loss: 0.445361
 >> iter 12000, loss: 0.409519
 >> iter 13000, loss: 0.552136
 >> iter 14000, loss: 0.436951
 >> iter 15000, loss: 0.237261
 >> iter 16000, loss: 0.315995
 >> iter 17000, loss: 0.412010
 >> iter 18000, loss: 0.314714
 >> iter 19000, loss: 0.388319
 >> iter 20000, loss: 0.356431
   Number of active neurons: 4
 >> iter 21000, loss: 0.270773
 >> iter 22000, loss: 0.257575
 >> iter 23000, loss: 0.393187
 >> iter 24000, loss: 0.435838
 >> iter 25000, loss: 0.421685
 >> iter 26000, loss: 0.272667
 >> iter 27000, loss: 0.576691
 >> iter 28000, loss: 0.419037
 >> iter 29000, loss: 0.297087
 >> iter 30000, loss: 0.266470
   Number of active neurons: 4
 >> iter 31000, loss: 0.235558
 >> iter 32000, loss: 0.282547
 >> iter 33000, loss: 0.352051
 >> iter 34000, loss: 0.281619
 >> iter 35000, loss: 0.331861
 >> iter 36000, loss: 0.238575
 >> iter 37000, loss: 0.195262
 >> iter 38000, loss: 0.358281
 >> iter 39000, loss: 0.368751
 >> iter 40000, loss: 0.308646
   Number of active neurons: 3
 >> iter 41000, loss: 0.351718
 >> iter 42000, loss: 0.232082
 >> iter 43000, loss: 0.199785
 >> iter 44000, loss: 0.285202
 >> iter 45000, loss: 0.286607
 >> iter 46000, loss: 0.246180
 >> iter 47000, loss: 0.411188
 >> iter 48000, loss: 0.377042
 >> iter 49000, loss: 0.247757
 >> iter 50000, loss: 0.199935
   Number of active neurons: 3
 >> iter 51000, loss: 0.186602
 >> iter 52000, loss: 0.301296
 >> iter 53000, loss: 0.260954
 >> iter 54000, loss: 0.321198
 >> iter 55000, loss: 0.190124
 >> iter 56000, loss: 0.118787
 >> iter 57000, loss: 0.185531
 >> iter 58000, loss: 0.176871
 >> iter 59000, loss: 0.197567
 >> iter 60000, loss: 0.134874
   Number of active neurons: 3
 >> iter 61000, loss: 0.172713
 >> iter 62000, loss: 0.192433
 >> iter 63000, loss: 0.176411
 >> iter 64000, loss: 0.323493
 >> iter 65000, loss: 0.208735
 >> iter 66000, loss: 0.240512
 >> iter 67000, loss: 0.168656
 >> iter 68000, loss: 0.261463
 >> iter 69000, loss: 0.236744
 >> iter 70000, loss: 0.178721
   Number of active neurons: 3
 >> iter 71000, loss: 0.273263
 >> iter 72000, loss: 0.200156
 >> iter 73000, loss: 0.151081
 >> iter 74000, loss: 0.190373
 >> iter 75000, loss: 0.247171
 >> iter 76000, loss: 0.171808
 >> iter 77000, loss: 0.248077
 >> iter 78000, loss: 0.250745
 >> iter 79000, loss: 0.216174
 >> iter 80000, loss: 0.174809
   Number of active neurons: 3
 >> iter 81000, loss: 0.306161
 >> iter 82000, loss: 0.317117
 >> iter 83000, loss: 0.177275
 >> iter 84000, loss: 0.117694
 >> iter 85000, loss: 0.223327
 >> iter 86000, loss: 0.232697
 >> iter 87000, loss: 0.181975
 >> iter 88000, loss: 0.101563
 >> iter 89000, loss: 0.204173
 >> iter 90000, loss: 0.328569
   Number of active neurons: 3
 >> iter 91000, loss: 0.383817
 >> iter 92000, loss: 0.203079
 >> iter 93000, loss: 0.298184
 >> iter 94000, loss: 0.201035
 >> iter 95000, loss: 0.152379
 >> iter 96000, loss: 0.219583
 >> iter 97000, loss: 0.260408
 >> iter 98000, loss: 0.230080
 >> iter 99000, loss: 0.218022
 >> iter 100000, loss: 0.296730
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.105674
 >> iter 2000, loss: 8.907898
 >> iter 3000, loss: 4.067877
 >> iter 4000, loss: 2.046155
 >> iter 5000, loss: 1.302362
 >> iter 6000, loss: 0.918928
 >> iter 7000, loss: 0.733269
 >> iter 8000, loss: 0.740131
 >> iter 9000, loss: 0.758059
 >> iter 10000, loss: 0.634709
   Number of active neurons: 6
 >> iter 11000, loss: 0.796692
 >> iter 12000, loss: 0.556970
 >> iter 13000, loss: 0.407931
 >> iter 14000, loss: 0.294123
 >> iter 15000, loss: 0.463429
 >> iter 16000, loss: 0.353184
 >> iter 17000, loss: 0.346231
 >> iter 18000, loss: 0.341716
 >> iter 19000, loss: 0.410786
 >> iter 20000, loss: 0.371494
   Number of active neurons: 6
 >> iter 21000, loss: 0.538252
 >> iter 22000, loss: 0.420200
 >> iter 23000, loss: 0.413806
 >> iter 24000, loss: 0.497630
 >> iter 25000, loss: 0.695135
 >> iter 26000, loss: 0.377270
 >> iter 27000, loss: 0.775748
 >> iter 28000, loss: 0.456614
 >> iter 29000, loss: 0.575800
 >> iter 30000, loss: 0.451589
   Number of active neurons: 6
 >> iter 31000, loss: 0.408300
 >> iter 32000, loss: 0.547227
 >> iter 33000, loss: 0.734949
 >> iter 34000, loss: 0.541334
 >> iter 35000, loss: 0.537838
 >> iter 36000, loss: 0.603701
 >> iter 37000, loss: 0.626795
 >> iter 38000, loss: 0.777118
 >> iter 39000, loss: 0.559323
 >> iter 40000, loss: 0.471246
   Number of active neurons: 5
 >> iter 41000, loss: 0.398733
 >> iter 42000, loss: 0.407435
 >> iter 43000, loss: 0.412393
 >> iter 44000, loss: 0.429412
 >> iter 45000, loss: 0.338473
 >> iter 46000, loss: 0.243386
 >> iter 47000, loss: 0.279597
 >> iter 48000, loss: 0.395793
 >> iter 49000, loss: 0.471603
 >> iter 50000, loss: 0.436199
   Number of active neurons: 5
 >> iter 51000, loss: 0.375227
 >> iter 52000, loss: 0.485896
 >> iter 53000, loss: 0.493445
 >> iter 54000, loss: 0.450670
 >> iter 55000, loss: 0.603247
 >> iter 56000, loss: 0.399193
 >> iter 57000, loss: 0.354534
 >> iter 58000, loss: 0.385363
 >> iter 59000, loss: 0.396868
 >> iter 60000, loss: 0.416169
   Number of active neurons: 5
 >> iter 61000, loss: 0.571408
 >> iter 62000, loss: 0.465811
 >> iter 63000, loss: 0.387937
 >> iter 64000, loss: 0.396909
 >> iter 65000, loss: 0.541341
 >> iter 66000, loss: 0.482864
 >> iter 67000, loss: 0.351389
 >> iter 68000, loss: 0.321744
 >> iter 69000, loss: 0.319414
 >> iter 70000, loss: 0.336121
   Number of active neurons: 5
 >> iter 71000, loss: 0.440213
 >> iter 72000, loss: 0.418134
 >> iter 73000, loss: 0.330906
 >> iter 74000, loss: 0.513397
 >> iter 75000, loss: 0.348628
 >> iter 76000, loss: 0.388828
 >> iter 77000, loss: 0.540719
 >> iter 78000, loss: 0.420532
 >> iter 79000, loss: 0.541854
 >> iter 80000, loss: 0.569457
   Number of active neurons: 4
 >> iter 81000, loss: 0.322765
 >> iter 82000, loss: 0.427371
 >> iter 83000, loss: 0.508883
 >> iter 84000, loss: 0.337073
 >> iter 85000, loss: 0.493436
 >> iter 86000, loss: 0.474734
 >> iter 87000, loss: 0.479269
 >> iter 88000, loss: 0.718942
 >> iter 89000, loss: 0.527385
 >> iter 90000, loss: 0.606031
   Number of active neurons: 4
 >> iter 91000, loss: 0.569482
 >> iter 92000, loss: 0.563020
 >> iter 93000, loss: 0.574306
 >> iter 94000, loss: 0.374289
 >> iter 95000, loss: 0.344631
 >> iter 96000, loss: 0.578425
 >> iter 97000, loss: 0.571227
 >> iter 98000, loss: 0.518071
 >> iter 99000, loss: 0.398402
 >> iter 100000, loss: 0.283533
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 20.524742
 >> iter 2000, loss: 17.515464
 >> iter 3000, loss: 11.478222
 >> iter 4000, loss: 5.442930
 >> iter 5000, loss: 2.719077
 >> iter 6000, loss: 1.409172
 >> iter 7000, loss: 1.043548
 >> iter 8000, loss: 0.769945
 >> iter 9000, loss: 0.749175
 >> iter 10000, loss: 0.610278
   Number of active neurons: 6
 >> iter 11000, loss: 0.723778
 >> iter 12000, loss: 0.727342
 >> iter 13000, loss: 0.584111
 >> iter 14000, loss: 0.326133
 >> iter 15000, loss: 0.331648
 >> iter 16000, loss: 0.462241
 >> iter 17000, loss: 0.452922
 >> iter 18000, loss: 0.478657
 >> iter 19000, loss: 0.569654
 >> iter 20000, loss: 0.868518
   Number of active neurons: 5
 >> iter 21000, loss: 0.691132
 >> iter 22000, loss: 0.511643
 >> iter 23000, loss: 0.515764
 >> iter 24000, loss: 0.424236
 >> iter 25000, loss: 0.336757
 >> iter 26000, loss: 0.388627
 >> iter 27000, loss: 0.393158
 >> iter 28000, loss: 0.477956
 >> iter 29000, loss: 0.619250
 >> iter 30000, loss: 0.347994
   Number of active neurons: 5
 >> iter 31000, loss: 0.358090
 >> iter 32000, loss: 0.515015
 >> iter 33000, loss: 0.587394
 >> iter 34000, loss: 0.382175
 >> iter 35000, loss: 0.392477
 >> iter 36000, loss: 0.553039
 >> iter 37000, loss: 0.300612
 >> iter 38000, loss: 0.492631
 >> iter 39000, loss: 0.635799
 >> iter 40000, loss: 0.480018
   Number of active neurons: 5
 >> iter 41000, loss: 0.343710
 >> iter 42000, loss: 0.419864
 >> iter 43000, loss: 0.627642
 >> iter 44000, loss: 0.472834
 >> iter 45000, loss: 0.427644
 >> iter 46000, loss: 0.337287
 >> iter 47000, loss: 0.490748
 >> iter 48000, loss: 0.386847
 >> iter 49000, loss: 0.451429
 >> iter 50000, loss: 0.504530
   Number of active neurons: 4
 >> iter 51000, loss: 0.394006
 >> iter 52000, loss: 0.462962
 >> iter 53000, loss: 0.553562
 >> iter 54000, loss: 0.401001
 >> iter 55000, loss: 0.463678
 >> iter 56000, loss: 0.383258
 >> iter 57000, loss: 0.385381
 >> iter 58000, loss: 0.240965
 >> iter 59000, loss: 0.501493
 >> iter 60000, loss: 0.505056
   Number of active neurons: 4
 >> iter 61000, loss: 0.357145
 >> iter 62000, loss: 0.244137
 >> iter 63000, loss: 0.312677
 >> iter 64000, loss: 0.347555
 >> iter 65000, loss: 0.382466
 >> iter 66000, loss: 0.469109
 >> iter 67000, loss: 0.326850
 >> iter 68000, loss: 0.825049
 >> iter 69000, loss: 0.496225
 >> iter 70000, loss: 0.356343
   Number of active neurons: 4
 >> iter 71000, loss: 0.466193
 >> iter 72000, loss: 0.643151
 >> iter 73000, loss: 0.386758
 >> iter 74000, loss: 0.365571
 >> iter 75000, loss: 0.578267
 >> iter 76000, loss: 0.554893
 >> iter 77000, loss: 0.588424
 >> iter 78000, loss: 0.352292
 >> iter 79000, loss: 0.390386
 >> iter 80000, loss: 0.367335
   Number of active neurons: 4
 >> iter 81000, loss: 0.354685
 >> iter 82000, loss: 0.309714
 >> iter 83000, loss: 0.320602
 >> iter 84000, loss: 0.275093
 >> iter 85000, loss: 0.481634
 >> iter 86000, loss: 0.385126
 >> iter 87000, loss: 0.706372
 >> iter 88000, loss: 0.500220
 >> iter 89000, loss: 0.303278
 >> iter 90000, loss: 0.409205
   Number of active neurons: 4
 >> iter 91000, loss: 0.428918
 >> iter 92000, loss: 0.395433
 >> iter 93000, loss: 0.500086
 >> iter 94000, loss: 0.474166
 >> iter 95000, loss: 0.446210
 >> iter 96000, loss: 0.413770
 >> iter 97000, loss: 0.298701
 >> iter 98000, loss: 0.235892
 >> iter 99000, loss: 0.324829
 >> iter 100000, loss: 0.367825
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.582652
 >> iter 2000, loss: 9.438177
 >> iter 3000, loss: 4.319262
 >> iter 4000, loss: 2.086509
 >> iter 5000, loss: 1.271218
 >> iter 6000, loss: 0.784750
 >> iter 7000, loss: 0.781206
 >> iter 8000, loss: 0.625242
 >> iter 9000, loss: 0.683857
 >> iter 10000, loss: 0.551285
   Number of active neurons: 4
 >> iter 11000, loss: 0.543691
 >> iter 12000, loss: 0.473974
 >> iter 13000, loss: 0.832267
 >> iter 14000, loss: 0.569622
 >> iter 15000, loss: 0.713639
 >> iter 16000, loss: 0.583902
 >> iter 17000, loss: 0.463215
 >> iter 18000, loss: 0.399021
 >> iter 19000, loss: 0.481718
 >> iter 20000, loss: 0.530344
   Number of active neurons: 4
 >> iter 21000, loss: 0.359405
 >> iter 22000, loss: 0.477692
 >> iter 23000, loss: 0.500200
 >> iter 24000, loss: 0.461122
 >> iter 25000, loss: 0.420954
 >> iter 26000, loss: 0.580941
 >> iter 27000, loss: 0.490284
 >> iter 28000, loss: 0.405339
 >> iter 29000, loss: 0.473293
 >> iter 30000, loss: 0.493938
   Number of active neurons: 4
 >> iter 31000, loss: 0.473734
 >> iter 32000, loss: 0.478685
 >> iter 33000, loss: 0.600272
 >> iter 34000, loss: 0.547699
 >> iter 35000, loss: 0.467555
 >> iter 36000, loss: 0.404370
 >> iter 37000, loss: 0.555329
 >> iter 38000, loss: 0.480747
 >> iter 39000, loss: 0.369993
 >> iter 40000, loss: 0.380346
   Number of active neurons: 4
 >> iter 41000, loss: 0.404338
 >> iter 42000, loss: 0.550676
 >> iter 43000, loss: 0.553313
 >> iter 44000, loss: 0.446921
 >> iter 45000, loss: 0.338964
 >> iter 46000, loss: 0.473504
 >> iter 47000, loss: 0.493362
 >> iter 48000, loss: 0.442761
 >> iter 49000, loss: 0.347145
 >> iter 50000, loss: 0.608650
   Number of active neurons: 4
 >> iter 51000, loss: 0.451734
 >> iter 52000, loss: 0.536488
 >> iter 53000, loss: 0.505499
 >> iter 54000, loss: 0.620355
 >> iter 55000, loss: 0.512687
 >> iter 56000, loss: 0.447567
 >> iter 57000, loss: 0.671616
 >> iter 58000, loss: 0.481977
 >> iter 59000, loss: 0.403276
 >> iter 60000, loss: 0.550804
   Number of active neurons: 4
 >> iter 61000, loss: 0.626087
 >> iter 62000, loss: 0.622199
 >> iter 63000, loss: 0.716581
 >> iter 64000, loss: 0.522577
 >> iter 65000, loss: 0.486528
 >> iter 66000, loss: 0.683092
 >> iter 67000, loss: 0.608235
 >> iter 68000, loss: 0.661374
 >> iter 69000, loss: 0.510263
 >> iter 70000, loss: 0.439584
   Number of active neurons: 4
 >> iter 71000, loss: 0.581283
 >> iter 72000, loss: 0.693986
 >> iter 73000, loss: 0.576610
 >> iter 74000, loss: 0.394925
 >> iter 75000, loss: 0.236748
 >> iter 76000, loss: 0.328409
 >> iter 77000, loss: 0.341221
 >> iter 78000, loss: 0.311301
 >> iter 79000, loss: 0.404584
 >> iter 80000, loss: 0.431552
   Number of active neurons: 4
 >> iter 81000, loss: 0.385320
 >> iter 82000, loss: 0.404123
 >> iter 83000, loss: 0.514229
 >> iter 84000, loss: 0.745266
 >> iter 85000, loss: 0.481155
 >> iter 86000, loss: 0.503154
 >> iter 87000, loss: 0.346407
 >> iter 88000, loss: 0.554667
 >> iter 89000, loss: 0.390679
 >> iter 90000, loss: 0.288807
   Number of active neurons: 4
 >> iter 91000, loss: 0.425316
 >> iter 92000, loss: 0.431007
 >> iter 93000, loss: 0.541585
 >> iter 94000, loss: 0.394591
 >> iter 95000, loss: 0.319664
 >> iter 96000, loss: 0.450092
 >> iter 97000, loss: 0.630360
 >> iter 98000, loss: 0.598679
 >> iter 99000, loss: 0.382896
 >> iter 100000, loss: 0.188811
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.717172
 >> iter 2000, loss: 9.467429
 >> iter 3000, loss: 4.844712
 >> iter 4000, loss: 2.527497
 >> iter 5000, loss: 1.368263
 >> iter 6000, loss: 0.899471
 >> iter 7000, loss: 0.453481
 >> iter 8000, loss: 0.614221
 >> iter 9000, loss: 0.549417
 >> iter 10000, loss: 0.612120
   Number of active neurons: 5
 >> iter 11000, loss: 0.486525
 >> iter 12000, loss: 0.428487
 >> iter 13000, loss: 0.398495
 >> iter 14000, loss: 0.543611
 >> iter 15000, loss: 0.486692
 >> iter 16000, loss: 0.366429
 >> iter 17000, loss: 0.439009
 >> iter 18000, loss: 0.585483
 >> iter 19000, loss: 0.501560
 >> iter 20000, loss: 0.313458
   Number of active neurons: 4
 >> iter 21000, loss: 0.405918
 >> iter 22000, loss: 0.433476
 >> iter 23000, loss: 0.374468
 >> iter 24000, loss: 0.494576
 >> iter 25000, loss: 0.337721
 >> iter 26000, loss: 0.286709
 >> iter 27000, loss: 0.287039
 >> iter 28000, loss: 0.313951
 >> iter 29000, loss: 0.326087
 >> iter 30000, loss: 0.418873
   Number of active neurons: 4
 >> iter 31000, loss: 0.386165
 >> iter 32000, loss: 0.611437
 >> iter 33000, loss: 0.478270
 >> iter 34000, loss: 0.431900
 >> iter 35000, loss: 0.538853
 >> iter 36000, loss: 0.369879
 >> iter 37000, loss: 0.237574
 >> iter 38000, loss: 0.362172
 >> iter 39000, loss: 0.288152
 >> iter 40000, loss: 0.233296
   Number of active neurons: 4
 >> iter 41000, loss: 0.602401
 >> iter 42000, loss: 0.471679
 >> iter 43000, loss: 0.374189
 >> iter 44000, loss: 0.306974
 >> iter 45000, loss: 0.356766
 >> iter 46000, loss: 0.210417
 >> iter 47000, loss: 0.338212
 >> iter 48000, loss: 0.312479
 >> iter 49000, loss: 0.319056
 >> iter 50000, loss: 0.374136
   Number of active neurons: 4
 >> iter 51000, loss: 0.401647
 >> iter 52000, loss: 0.395639
 >> iter 53000, loss: 0.239073
 >> iter 54000, loss: 0.387569
 >> iter 55000, loss: 0.337982
 >> iter 56000, loss: 0.413622
 >> iter 57000, loss: 0.335534
 >> iter 58000, loss: 0.287173
 >> iter 59000, loss: 0.180586
 >> iter 60000, loss: 0.292647
   Number of active neurons: 4
 >> iter 61000, loss: 0.420898
 >> iter 62000, loss: 0.340435
 >> iter 63000, loss: 0.453319
 >> iter 64000, loss: 0.294425
 >> iter 65000, loss: 0.284699
 >> iter 66000, loss: 0.250386
 >> iter 67000, loss: 0.496702
 >> iter 68000, loss: 0.375954
 >> iter 69000, loss: 0.309583
 >> iter 70000, loss: 0.480975
   Number of active neurons: 3
 >> iter 71000, loss: 0.329146
 >> iter 72000, loss: 0.424590
 >> iter 73000, loss: 0.368501
 >> iter 74000, loss: 0.400093
 >> iter 75000, loss: 0.410393
 >> iter 76000, loss: 0.388949
 >> iter 77000, loss: 0.467930
 >> iter 78000, loss: 0.317808
 >> iter 79000, loss: 0.291897
 >> iter 80000, loss: 0.424536
   Number of active neurons: 3
 >> iter 81000, loss: 0.315810
 >> iter 82000, loss: 0.331490
 >> iter 83000, loss: 0.323520
 >> iter 84000, loss: 0.320574
 >> iter 85000, loss: 0.333119
 >> iter 86000, loss: 0.399360
 >> iter 87000, loss: 0.439510
 >> iter 88000, loss: 0.363880
 >> iter 89000, loss: 0.499606
 >> iter 90000, loss: 0.354100
   Number of active neurons: 3
 >> iter 91000, loss: 0.377524
 >> iter 92000, loss: 0.333909
 >> iter 93000, loss: 0.259578
 >> iter 94000, loss: 0.271681
 >> iter 95000, loss: 0.185148
 >> iter 96000, loss: 0.199547
 >> iter 97000, loss: 0.125780
 >> iter 98000, loss: 0.248344
 >> iter 99000, loss: 0.286313
 >> iter 100000, loss: 0.246118
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.291661
 >> iter 2000, loss: 9.209594
 >> iter 3000, loss: 4.446261
 >> iter 4000, loss: 2.160228
 >> iter 5000, loss: 1.488490
 >> iter 6000, loss: 0.808944
 >> iter 7000, loss: 0.737824
 >> iter 8000, loss: 0.707230
 >> iter 9000, loss: 0.654266
 >> iter 10000, loss: 0.479575
   Number of active neurons: 4
 >> iter 11000, loss: 0.488724
 >> iter 12000, loss: 0.478488
 >> iter 13000, loss: 0.485954
 >> iter 14000, loss: 0.574043
 >> iter 15000, loss: 0.502683
 >> iter 16000, loss: 0.401692
 >> iter 17000, loss: 0.516489
 >> iter 18000, loss: 0.573553
 >> iter 19000, loss: 0.575622
 >> iter 20000, loss: 0.554487
   Number of active neurons: 4
 >> iter 21000, loss: 0.404786
 >> iter 22000, loss: 0.329069
 >> iter 23000, loss: 0.322378
 >> iter 24000, loss: 0.405055
 >> iter 25000, loss: 0.486545
 >> iter 26000, loss: 0.532284
 >> iter 27000, loss: 0.445638
 >> iter 28000, loss: 0.578778
 >> iter 29000, loss: 0.355940
 >> iter 30000, loss: 0.409668
   Number of active neurons: 4
 >> iter 31000, loss: 0.331632
 >> iter 32000, loss: 0.332492
 >> iter 33000, loss: 0.383284
 >> iter 34000, loss: 0.354817
 >> iter 35000, loss: 0.475696
 >> iter 36000, loss: 0.478005
 >> iter 37000, loss: 0.643290
 >> iter 38000, loss: 0.553889
 >> iter 39000, loss: 0.481442
 >> iter 40000, loss: 0.470620
   Number of active neurons: 4
 >> iter 41000, loss: 0.544094
 >> iter 42000, loss: 0.533119
 >> iter 43000, loss: 0.636296
 >> iter 44000, loss: 0.581174
 >> iter 45000, loss: 0.509995
 >> iter 46000, loss: 0.556742
 >> iter 47000, loss: 0.472692
 >> iter 48000, loss: 0.777116
 >> iter 49000, loss: 0.551175
 >> iter 50000, loss: 0.393265
   Number of active neurons: 4
 >> iter 51000, loss: 0.573893
 >> iter 52000, loss: 0.315472
 >> iter 53000, loss: 0.391773
 >> iter 54000, loss: 0.627702
 >> iter 55000, loss: 0.683711
 >> iter 56000, loss: 0.754612
 >> iter 57000, loss: 0.511173
 >> iter 58000, loss: 0.563959
 >> iter 59000, loss: 0.533838
 >> iter 60000, loss: 0.599550
   Number of active neurons: 4
 >> iter 61000, loss: 0.410546
 >> iter 62000, loss: 0.634873
 >> iter 63000, loss: 0.687455
 >> iter 64000, loss: 0.511950
 >> iter 65000, loss: 0.785377
 >> iter 66000, loss: 0.420666
 >> iter 67000, loss: 0.356268
 >> iter 68000, loss: 0.309189
 >> iter 69000, loss: 0.516560
 >> iter 70000, loss: 0.585842
   Number of active neurons: 4
 >> iter 71000, loss: 0.373345
 >> iter 72000, loss: 0.443768
 >> iter 73000, loss: 0.545412
 >> iter 74000, loss: 0.555197
 >> iter 75000, loss: 0.613672
 >> iter 76000, loss: 0.591232
 >> iter 77000, loss: 0.442582
 >> iter 78000, loss: 0.304457
 >> iter 79000, loss: 0.279077
 >> iter 80000, loss: 0.545931
   Number of active neurons: 4
 >> iter 81000, loss: 0.501946
 >> iter 82000, loss: 0.316359
 >> iter 83000, loss: 0.424192
 >> iter 84000, loss: 0.391573
 >> iter 85000, loss: 0.426354
 >> iter 86000, loss: 0.528269
 >> iter 87000, loss: 0.381535
 >> iter 88000, loss: 0.459404
 >> iter 89000, loss: 0.430347
 >> iter 90000, loss: 0.383334
   Number of active neurons: 4
 >> iter 91000, loss: 0.263806
 >> iter 92000, loss: 0.320558
 >> iter 93000, loss: 0.394880
 >> iter 94000, loss: 0.393930
 >> iter 95000, loss: 0.494867
 >> iter 96000, loss: 0.661994
 >> iter 97000, loss: 0.414101
 >> iter 98000, loss: 0.519376
 >> iter 99000, loss: 0.542017
 >> iter 100000, loss: 0.480528
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.353754
 >> iter 2000, loss: 10.680609
 >> iter 3000, loss: 5.068141
 >> iter 4000, loss: 2.650499
 >> iter 5000, loss: 1.312030
 >> iter 6000, loss: 1.127254
 >> iter 7000, loss: 0.893068
 >> iter 8000, loss: 0.612609
 >> iter 9000, loss: 0.654734
 >> iter 10000, loss: 0.423432
   Number of active neurons: 6
 >> iter 11000, loss: 0.428527
 >> iter 12000, loss: 0.408150
 >> iter 13000, loss: 0.443499
 >> iter 14000, loss: 0.513204
 >> iter 15000, loss: 0.525024
 >> iter 16000, loss: 0.348776
 >> iter 17000, loss: 0.359856
 >> iter 18000, loss: 0.304116
 >> iter 19000, loss: 0.457498
 >> iter 20000, loss: 0.334087
   Number of active neurons: 6
 >> iter 21000, loss: 0.351526
 >> iter 22000, loss: 0.368070
 >> iter 23000, loss: 0.345080
 >> iter 24000, loss: 0.445186
 >> iter 25000, loss: 0.352021
 >> iter 26000, loss: 0.203172
 >> iter 27000, loss: 0.387238
 >> iter 28000, loss: 0.381227
 >> iter 29000, loss: 0.366938
 >> iter 30000, loss: 0.293221
   Number of active neurons: 6
 >> iter 31000, loss: 0.282566
 >> iter 32000, loss: 0.318582
 >> iter 33000, loss: 0.263696
 >> iter 34000, loss: 0.310313
 >> iter 35000, loss: 0.593491
 >> iter 36000, loss: 0.416377
 >> iter 37000, loss: 0.367757
 >> iter 38000, loss: 0.435452
 >> iter 39000, loss: 0.535768
 >> iter 40000, loss: 0.414297
   Number of active neurons: 5
 >> iter 41000, loss: 0.279830
 >> iter 42000, loss: 0.440344
 >> iter 43000, loss: 0.385546
 >> iter 44000, loss: 0.346907
 >> iter 45000, loss: 0.369935
 >> iter 46000, loss: 0.432589
 >> iter 47000, loss: 0.446188
 >> iter 48000, loss: 0.461834
 >> iter 49000, loss: 0.352150
 >> iter 50000, loss: 0.728926
   Number of active neurons: 4
 >> iter 51000, loss: 0.688748
 >> iter 52000, loss: 0.421413
 >> iter 53000, loss: 0.411140
 >> iter 54000, loss: 0.377355
 >> iter 55000, loss: 0.383706
 >> iter 56000, loss: 0.507480
 >> iter 57000, loss: 0.447420
 >> iter 58000, loss: 0.435736
 >> iter 59000, loss: 0.330725
 >> iter 60000, loss: 0.521971
   Number of active neurons: 6
 >> iter 61000, loss: 0.795498
 >> iter 62000, loss: 0.513127
 >> iter 63000, loss: 0.458828
 >> iter 64000, loss: 0.492176
 >> iter 65000, loss: 0.545406
 >> iter 66000, loss: 0.406156
 >> iter 67000, loss: 0.345518
 >> iter 68000, loss: 0.525661
 >> iter 69000, loss: 0.608808
 >> iter 70000, loss: 0.537105
   Number of active neurons: 7
 >> iter 71000, loss: 0.529010
 >> iter 72000, loss: 0.705083
 >> iter 73000, loss: 0.579539
 >> iter 74000, loss: 0.485073
 >> iter 75000, loss: 0.430901
 >> iter 76000, loss: 0.354449
 >> iter 77000, loss: 0.476618
 >> iter 78000, loss: 0.712716
 >> iter 79000, loss: 0.399939
 >> iter 80000, loss: 0.567317
   Number of active neurons: 8
 >> iter 81000, loss: 0.322270
 >> iter 82000, loss: 0.353418
 >> iter 83000, loss: 0.472653
 >> iter 84000, loss: 0.524762
 >> iter 85000, loss: 0.298222
 >> iter 86000, loss: 0.298680
 >> iter 87000, loss: 0.427580
 >> iter 88000, loss: 0.472463
 >> iter 89000, loss: 0.386843
 >> iter 90000, loss: 0.488776
   Number of active neurons: 10
 >> iter 91000, loss: 0.441677
 >> iter 92000, loss: 0.456955
 >> iter 93000, loss: 0.437764
 >> iter 94000, loss: 0.303506
 >> iter 95000, loss: 0.398482
 >> iter 96000, loss: 0.364779
 >> iter 97000, loss: 0.335143
 >> iter 98000, loss: 0.276182
 >> iter 99000, loss: 0.355774
 >> iter 100000, loss: 0.412309
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.813513
 >> iter 2000, loss: 9.350841
 >> iter 3000, loss: 4.517316
 >> iter 4000, loss: 2.558388
 >> iter 5000, loss: 1.341076
 >> iter 6000, loss: 1.160511
 >> iter 7000, loss: 0.878345
 >> iter 8000, loss: 0.686636
 >> iter 9000, loss: 0.522978
 >> iter 10000, loss: 0.532912
   Number of active neurons: 5
 >> iter 11000, loss: 0.434306
 >> iter 12000, loss: 0.499938
 >> iter 13000, loss: 0.408379
 >> iter 14000, loss: 0.883941
 >> iter 15000, loss: 0.619251
 >> iter 16000, loss: 0.836069
 >> iter 17000, loss: 0.641196
 >> iter 18000, loss: 0.603663
 >> iter 19000, loss: 0.565250
 >> iter 20000, loss: 0.488999
   Number of active neurons: 5
 >> iter 21000, loss: 0.402381
 >> iter 22000, loss: 0.481725
 >> iter 23000, loss: 0.501548
 >> iter 24000, loss: 0.645266
 >> iter 25000, loss: 0.455592
 >> iter 26000, loss: 0.468043
 >> iter 27000, loss: 0.589152
 >> iter 28000, loss: 0.374225
 >> iter 29000, loss: 0.512517
 >> iter 30000, loss: 0.615149
   Number of active neurons: 5
 >> iter 31000, loss: 0.583662
 >> iter 32000, loss: 0.701213
 >> iter 33000, loss: 0.433131
 >> iter 34000, loss: 0.497055
 >> iter 35000, loss: 0.362069
 >> iter 36000, loss: 0.352875
 >> iter 37000, loss: 0.480419
 >> iter 38000, loss: 0.333076
 >> iter 39000, loss: 0.390514
 >> iter 40000, loss: 0.438731
   Number of active neurons: 4
 >> iter 41000, loss: 0.636480
 >> iter 42000, loss: 0.365224
 >> iter 43000, loss: 0.379044
 >> iter 44000, loss: 0.603351
 >> iter 45000, loss: 0.577844
 >> iter 46000, loss: 0.437138
 >> iter 47000, loss: 0.372571
 >> iter 48000, loss: 0.650271
 >> iter 49000, loss: 0.598631
 >> iter 50000, loss: 0.545923
   Number of active neurons: 4
 >> iter 51000, loss: 0.518680
 >> iter 52000, loss: 0.466357
 >> iter 53000, loss: 0.718040
 >> iter 54000, loss: 0.447879
 >> iter 55000, loss: 0.351512
 >> iter 56000, loss: 0.415957
 >> iter 57000, loss: 0.509235
 >> iter 58000, loss: 0.471073
 >> iter 59000, loss: 0.439087
 >> iter 60000, loss: 0.403437
   Number of active neurons: 3
 >> iter 61000, loss: 0.573976
 >> iter 62000, loss: 0.724613
 >> iter 63000, loss: 0.591196
 >> iter 64000, loss: 0.318665
 >> iter 65000, loss: 0.407073
 >> iter 66000, loss: 0.447871
 >> iter 67000, loss: 0.513580
 >> iter 68000, loss: 0.577218
 >> iter 69000, loss: 0.581211
 >> iter 70000, loss: 0.430769
   Number of active neurons: 3
 >> iter 71000, loss: 0.565962
 >> iter 72000, loss: 0.546850
 >> iter 73000, loss: 0.437846
 >> iter 74000, loss: 0.460023
 >> iter 75000, loss: 0.374602
 >> iter 76000, loss: 0.518643
 >> iter 77000, loss: 0.609469
 >> iter 78000, loss: 0.764845
 >> iter 79000, loss: 0.493771
 >> iter 80000, loss: 0.831391
   Number of active neurons: 3
 >> iter 81000, loss: 0.502706
 >> iter 82000, loss: 0.740888
 >> iter 83000, loss: 0.653449
 >> iter 84000, loss: 0.414828
 >> iter 85000, loss: 0.430084
 >> iter 86000, loss: 0.566038
 >> iter 87000, loss: 0.651510
 >> iter 88000, loss: 0.732085
 >> iter 89000, loss: 0.429628
 >> iter 90000, loss: 0.664124
   Number of active neurons: 3
 >> iter 91000, loss: 0.501182
 >> iter 92000, loss: 0.566385
 >> iter 93000, loss: 0.544441
 >> iter 94000, loss: 0.447776
 >> iter 95000, loss: 0.448601
 >> iter 96000, loss: 0.414139
 >> iter 97000, loss: 0.614955
 >> iter 98000, loss: 0.506712
 >> iter 99000, loss: 0.451809
 >> iter 100000, loss: 0.397301
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.900554
 >> iter 2000, loss: 11.229290
 >> iter 3000, loss: 6.448830
 >> iter 4000, loss: 3.045390
 >> iter 5000, loss: 1.927900
 >> iter 6000, loss: 1.098567
 >> iter 7000, loss: 0.700458
 >> iter 8000, loss: 0.579987
 >> iter 9000, loss: 0.420692
 >> iter 10000, loss: 0.420482
   Number of active neurons: 7
 >> iter 11000, loss: 0.396782
 >> iter 12000, loss: 0.418014
 >> iter 13000, loss: 0.325729
 >> iter 14000, loss: 0.171839
 >> iter 15000, loss: 0.484652
 >> iter 16000, loss: 0.406027
 >> iter 17000, loss: 0.249590
 >> iter 18000, loss: 0.322098
 >> iter 19000, loss: 0.323246
 >> iter 20000, loss: 0.408017
   Number of active neurons: 7
 >> iter 21000, loss: 0.343306
 >> iter 22000, loss: 0.368515
 >> iter 23000, loss: 0.458268
 >> iter 24000, loss: 0.216672
 >> iter 25000, loss: 0.261936
 >> iter 26000, loss: 0.367884
 >> iter 27000, loss: 0.351368
 >> iter 28000, loss: 0.367709
 >> iter 29000, loss: 0.318930
 >> iter 30000, loss: 0.452544
   Number of active neurons: 5
 >> iter 31000, loss: 0.241541
 >> iter 32000, loss: 0.355141
 >> iter 33000, loss: 0.370504
 >> iter 34000, loss: 0.263537
 >> iter 35000, loss: 0.469285
 >> iter 36000, loss: 0.442198
 >> iter 37000, loss: 0.450786
 >> iter 38000, loss: 0.513111
 >> iter 39000, loss: 0.348901
 >> iter 40000, loss: 0.329112
   Number of active neurons: 5
 >> iter 41000, loss: 0.296727
 >> iter 42000, loss: 0.332731
 >> iter 43000, loss: 0.442793
 >> iter 44000, loss: 0.330272
 >> iter 45000, loss: 0.369944
 >> iter 46000, loss: 0.286050
 >> iter 47000, loss: 0.348851
 >> iter 48000, loss: 0.315018
 >> iter 49000, loss: 0.240724
 >> iter 50000, loss: 0.245121
   Number of active neurons: 5
 >> iter 51000, loss: 0.445241
 >> iter 52000, loss: 0.352703
 >> iter 53000, loss: 0.314349
 >> iter 54000, loss: 0.429305
 >> iter 55000, loss: 0.339287
 >> iter 56000, loss: 0.352357
 >> iter 57000, loss: 0.352704
 >> iter 58000, loss: 0.625473
 >> iter 59000, loss: 0.294243
 >> iter 60000, loss: 0.294345
   Number of active neurons: 5
 >> iter 61000, loss: 0.323742
 >> iter 62000, loss: 0.546984
 >> iter 63000, loss: 0.425631
 >> iter 64000, loss: 0.426983
 >> iter 65000, loss: 0.283586
 >> iter 66000, loss: 0.404016
 >> iter 67000, loss: 0.301498
 >> iter 68000, loss: 0.283017
 >> iter 69000, loss: 0.422553
 >> iter 70000, loss: 0.393140
   Number of active neurons: 5
 >> iter 71000, loss: 0.281812
 >> iter 72000, loss: 0.395542
 >> iter 73000, loss: 0.326123
 >> iter 74000, loss: 0.429313
 >> iter 75000, loss: 0.400047
 >> iter 76000, loss: 0.294656
 >> iter 77000, loss: 0.330269
 >> iter 78000, loss: 0.316736
 >> iter 79000, loss: 0.181398
 >> iter 80000, loss: 0.457695
   Number of active neurons: 4
 >> iter 81000, loss: 0.638715
 >> iter 82000, loss: 0.335097
 >> iter 83000, loss: 0.404285
 >> iter 84000, loss: 0.313244
 >> iter 85000, loss: 0.479006
 >> iter 86000, loss: 0.433746
 >> iter 87000, loss: 0.289226
 >> iter 88000, loss: 0.583431
 >> iter 89000, loss: 0.362120
 >> iter 90000, loss: 0.183710
   Number of active neurons: 4
 >> iter 91000, loss: 0.179692
 >> iter 92000, loss: 0.229494
 >> iter 93000, loss: 0.216339
 >> iter 94000, loss: 0.236392
 >> iter 95000, loss: 0.338163
 >> iter 96000, loss: 0.281919
 >> iter 97000, loss: 0.287304
 >> iter 98000, loss: 0.458563
 >> iter 99000, loss: 0.250962
 >> iter 100000, loss: 0.340153
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.048533
 >> iter 2000, loss: 12.689286
 >> iter 3000, loss: 6.481414
 >> iter 4000, loss: 2.970489
 >> iter 5000, loss: 1.480450
 >> iter 6000, loss: 0.949764
 >> iter 7000, loss: 0.896017
 >> iter 8000, loss: 0.614533
 >> iter 9000, loss: 0.340335
 >> iter 10000, loss: 0.245477
   Number of active neurons: 6
 >> iter 11000, loss: 0.544152
 >> iter 12000, loss: 0.578038
 >> iter 13000, loss: 0.403754
 >> iter 14000, loss: 0.269480
 >> iter 15000, loss: 0.277038
 >> iter 16000, loss: 0.277387
 >> iter 17000, loss: 0.280344
 >> iter 18000, loss: 0.548806
 >> iter 19000, loss: 0.607393
 >> iter 20000, loss: 0.515266
   Number of active neurons: 6
 >> iter 21000, loss: 0.754784
 >> iter 22000, loss: 0.613493
 >> iter 23000, loss: 0.420430
 >> iter 24000, loss: 0.401619
 >> iter 25000, loss: 0.287326
 >> iter 26000, loss: 0.262192
 >> iter 27000, loss: 0.355024
 >> iter 28000, loss: 0.298032
 >> iter 29000, loss: 0.333706
 >> iter 30000, loss: 0.301684
   Number of active neurons: 5
 >> iter 31000, loss: 0.522501
 >> iter 32000, loss: 0.424636
 >> iter 33000, loss: 0.435745
 >> iter 34000, loss: 0.480634
 >> iter 35000, loss: 0.542690
 >> iter 36000, loss: 0.458258
 >> iter 37000, loss: 0.556830
 >> iter 38000, loss: 0.322366
 >> iter 39000, loss: 0.374453
 >> iter 40000, loss: 0.535203
   Number of active neurons: 5
 >> iter 41000, loss: 0.380803
 >> iter 42000, loss: 0.433457
 >> iter 43000, loss: 0.452129
 >> iter 44000, loss: 0.348026
 >> iter 45000, loss: 0.413497
 >> iter 46000, loss: 0.328374
 >> iter 47000, loss: 0.338272
 >> iter 48000, loss: 0.390806
 >> iter 49000, loss: 0.408619
 >> iter 50000, loss: 0.425898
   Number of active neurons: 5
 >> iter 51000, loss: 0.320206
 >> iter 52000, loss: 0.267833
 >> iter 53000, loss: 0.307542
 >> iter 54000, loss: 0.301021
 >> iter 55000, loss: 0.226132
 >> iter 56000, loss: 0.156871
 >> iter 57000, loss: 0.191954
 >> iter 58000, loss: 0.222781
 >> iter 59000, loss: 0.298844
 >> iter 60000, loss: 0.318221
   Number of active neurons: 5
 >> iter 61000, loss: 0.264514
 >> iter 62000, loss: 0.178736
 >> iter 63000, loss: 0.318673
 >> iter 64000, loss: 0.393815
 >> iter 65000, loss: 0.432797
 >> iter 66000, loss: 0.516106
 >> iter 67000, loss: 0.296412
 >> iter 68000, loss: 0.182440
 >> iter 69000, loss: 0.310719
 >> iter 70000, loss: 0.322690
   Number of active neurons: 4
 >> iter 71000, loss: 0.365316
 >> iter 72000, loss: 0.256326
 >> iter 73000, loss: 0.208401
 >> iter 74000, loss: 0.452158
 >> iter 75000, loss: 0.461363
 >> iter 76000, loss: 0.203069
 >> iter 77000, loss: 0.381782
 >> iter 78000, loss: 0.393788
 >> iter 79000, loss: 0.354794
 >> iter 80000, loss: 0.504265
   Number of active neurons: 3
 >> iter 81000, loss: 0.327637
 >> iter 82000, loss: 0.258313
 >> iter 83000, loss: 0.356463
 >> iter 84000, loss: 0.188930
 >> iter 85000, loss: 0.357546
 >> iter 86000, loss: 0.304306
 >> iter 87000, loss: 0.266151
 >> iter 88000, loss: 0.224322
 >> iter 89000, loss: 0.246639
 >> iter 90000, loss: 0.276110
   Number of active neurons: 3
 >> iter 91000, loss: 0.357098
 >> iter 92000, loss: 0.259408
 >> iter 93000, loss: 0.307303
 >> iter 94000, loss: 0.242276
 >> iter 95000, loss: 0.253532
 >> iter 96000, loss: 0.240224
 >> iter 97000, loss: 0.188206
 >> iter 98000, loss: 0.297714
 >> iter 99000, loss: 0.361005
 >> iter 100000, loss: 0.282787
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.675476
 >> iter 2000, loss: 8.998729
 >> iter 3000, loss: 4.244430
 >> iter 4000, loss: 2.154453
 >> iter 5000, loss: 0.988231
 >> iter 6000, loss: 0.765129
 >> iter 7000, loss: 0.529818
 >> iter 8000, loss: 0.393391
 >> iter 9000, loss: 0.303179
 >> iter 10000, loss: 0.504846
   Number of active neurons: 6
 >> iter 11000, loss: 0.276379
 >> iter 12000, loss: 0.245428
 >> iter 13000, loss: 0.381729
 >> iter 14000, loss: 0.371810
 >> iter 15000, loss: 0.505200
 >> iter 16000, loss: 0.308807
 >> iter 17000, loss: 0.232517
 >> iter 18000, loss: 0.367387
 >> iter 19000, loss: 0.211828
 >> iter 20000, loss: 0.216903
   Number of active neurons: 5
 >> iter 21000, loss: 0.302436
 >> iter 22000, loss: 0.363048
 >> iter 23000, loss: 0.213257
 >> iter 24000, loss: 0.123899
 >> iter 25000, loss: 0.154924
 >> iter 26000, loss: 0.191464
 >> iter 27000, loss: 0.266001
 >> iter 28000, loss: 0.141054
 >> iter 29000, loss: 0.234531
 >> iter 30000, loss: 0.428412
   Number of active neurons: 5
 >> iter 31000, loss: 0.350197
 >> iter 32000, loss: 0.380018
 >> iter 33000, loss: 0.349967
 >> iter 34000, loss: 0.227100
 >> iter 35000, loss: 0.370756
 >> iter 36000, loss: 0.566614
 >> iter 37000, loss: 0.276166
 >> iter 38000, loss: 0.283415
 >> iter 39000, loss: 0.258532
 >> iter 40000, loss: 0.217752
   Number of active neurons: 4
 >> iter 41000, loss: 0.169738
 >> iter 42000, loss: 0.244331
 >> iter 43000, loss: 0.250887
 >> iter 44000, loss: 0.188854
 >> iter 45000, loss: 0.314204
 >> iter 46000, loss: 0.203459
 >> iter 47000, loss: 0.260826
 >> iter 48000, loss: 0.180697
 >> iter 49000, loss: 0.257013
 >> iter 50000, loss: 0.174155
   Number of active neurons: 4
 >> iter 51000, loss: 0.284542
 >> iter 52000, loss: 0.231340
 >> iter 53000, loss: 0.214623
 >> iter 54000, loss: 0.182448
 >> iter 55000, loss: 0.207420
 >> iter 56000, loss: 0.193795
 >> iter 57000, loss: 0.405202
 >> iter 58000, loss: 0.272269
 >> iter 59000, loss: 0.176008
 >> iter 60000, loss: 0.217395
   Number of active neurons: 4
 >> iter 61000, loss: 0.293474
 >> iter 62000, loss: 0.171648
 >> iter 63000, loss: 0.160423
 >> iter 64000, loss: 0.150938
 >> iter 65000, loss: 0.369009
 >> iter 66000, loss: 0.311486
 >> iter 67000, loss: 0.401371
 >> iter 68000, loss: 0.277614
 >> iter 69000, loss: 0.274088
 >> iter 70000, loss: 0.217475
   Number of active neurons: 4
 >> iter 71000, loss: 0.324389
 >> iter 72000, loss: 0.172635
 >> iter 73000, loss: 0.141787
 >> iter 74000, loss: 0.227911
 >> iter 75000, loss: 0.392181
 >> iter 76000, loss: 0.232985
 >> iter 77000, loss: 0.197670
 >> iter 78000, loss: 0.300551
 >> iter 79000, loss: 0.321926
 >> iter 80000, loss: 0.300708
   Number of active neurons: 4
 >> iter 81000, loss: 0.196317
 >> iter 82000, loss: 0.262523
 >> iter 83000, loss: 0.479036
 >> iter 84000, loss: 0.311073
 >> iter 85000, loss: 0.166719
 >> iter 86000, loss: 0.179109
 >> iter 87000, loss: 0.215991
 >> iter 88000, loss: 0.119993
 >> iter 89000, loss: 0.217957
 >> iter 90000, loss: 0.250320
   Number of active neurons: 3
 >> iter 91000, loss: 0.155180
 >> iter 92000, loss: 0.148832
 >> iter 93000, loss: 0.190538
 >> iter 94000, loss: 0.402912
 >> iter 95000, loss: 0.262120
 >> iter 96000, loss: 0.306732
 >> iter 97000, loss: 0.206502
 >> iter 98000, loss: 0.224413
 >> iter 99000, loss: 0.237741
 >> iter 100000, loss: 0.195061
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 17.193338
 >> iter 2000, loss: 8.612951
 >> iter 3000, loss: 4.147117
 >> iter 4000, loss: 2.259112
 >> iter 5000, loss: 1.162193
 >> iter 6000, loss: 0.868987
 >> iter 7000, loss: 0.852318
 >> iter 8000, loss: 0.882365
 >> iter 9000, loss: 0.544101
 >> iter 10000, loss: 0.701297
   Number of active neurons: 4
 >> iter 11000, loss: 0.531868
 >> iter 12000, loss: 0.511731
 >> iter 13000, loss: 0.518874
 >> iter 14000, loss: 0.410878
 >> iter 15000, loss: 0.501588
 >> iter 16000, loss: 0.263431
 >> iter 17000, loss: 0.352057
 >> iter 18000, loss: 0.486022
 >> iter 19000, loss: 0.681101
 >> iter 20000, loss: 0.711372
   Number of active neurons: 4
 >> iter 21000, loss: 0.667112
 >> iter 22000, loss: 0.502671
 >> iter 23000, loss: 0.448406
 >> iter 24000, loss: 0.583204
 >> iter 25000, loss: 0.400735
 >> iter 26000, loss: 0.488299
 >> iter 27000, loss: 0.526068
 >> iter 28000, loss: 0.637916
 >> iter 29000, loss: 0.341729
 >> iter 30000, loss: 0.450334
   Number of active neurons: 4
 >> iter 31000, loss: 0.392661
 >> iter 32000, loss: 0.673099
 >> iter 33000, loss: 0.587116
 >> iter 34000, loss: 0.503206
 >> iter 35000, loss: 0.498336
 >> iter 36000, loss: 0.320874
 >> iter 37000, loss: 0.284600
 >> iter 38000, loss: 0.322432
 >> iter 39000, loss: 0.598520
 >> iter 40000, loss: 0.434635
   Number of active neurons: 4
 >> iter 41000, loss: 0.324959
 >> iter 42000, loss: 0.430329
 >> iter 43000, loss: 0.348560
 >> iter 44000, loss: 0.339319
 >> iter 45000, loss: 0.442276
 >> iter 46000, loss: 0.330651
 >> iter 47000, loss: 0.479204
 >> iter 48000, loss: 0.523353
 >> iter 49000, loss: 0.655345
 >> iter 50000, loss: 0.404704
   Number of active neurons: 4
 >> iter 51000, loss: 0.286960
 >> iter 52000, loss: 0.363918
 >> iter 53000, loss: 0.509998
 >> iter 54000, loss: 0.578584
 >> iter 55000, loss: 0.581864
 >> iter 56000, loss: 0.521183
 >> iter 57000, loss: 0.490247
 >> iter 58000, loss: 0.370385
 >> iter 59000, loss: 0.264370
 >> iter 60000, loss: 0.182817
   Number of active neurons: 4
 >> iter 61000, loss: 0.482797
 >> iter 62000, loss: 0.584509
 >> iter 63000, loss: 0.449792
 >> iter 64000, loss: 0.504768
 >> iter 65000, loss: 0.497228
 >> iter 66000, loss: 0.636948
 >> iter 67000, loss: 0.410639
 >> iter 68000, loss: 0.721114
 >> iter 69000, loss: 0.376078
 >> iter 70000, loss: 0.639606
   Number of active neurons: 4
 >> iter 71000, loss: 0.473576
 >> iter 72000, loss: 0.393541
 >> iter 73000, loss: 0.379714
 >> iter 74000, loss: 0.509456
 >> iter 75000, loss: 0.298905
 >> iter 76000, loss: 0.398684
 >> iter 77000, loss: 0.317578
 >> iter 78000, loss: 0.413871
 >> iter 79000, loss: 0.586471
 >> iter 80000, loss: 0.531695
   Number of active neurons: 4
 >> iter 81000, loss: 0.555069
 >> iter 82000, loss: 0.368542
 >> iter 83000, loss: 0.371238
 >> iter 84000, loss: 0.247223
 >> iter 85000, loss: 0.481742
 >> iter 86000, loss: 0.562604
 >> iter 87000, loss: 0.483861
 >> iter 88000, loss: 0.537686
 >> iter 89000, loss: 0.498425
 >> iter 90000, loss: 0.677403
   Number of active neurons: 4
 >> iter 91000, loss: 0.399599
 >> iter 92000, loss: 0.683710
 >> iter 93000, loss: 0.530037
 >> iter 94000, loss: 0.510048
 >> iter 95000, loss: 0.542705
 >> iter 96000, loss: 0.308507
 >> iter 97000, loss: 0.471136
 >> iter 98000, loss: 0.459024
 >> iter 99000, loss: 0.467367
 >> iter 100000, loss: 0.365609
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.885829
 >> iter 2000, loss: 9.865268
 >> iter 3000, loss: 4.846750
 >> iter 4000, loss: 2.540225
 >> iter 5000, loss: 1.270976
 >> iter 6000, loss: 0.920895
 >> iter 7000, loss: 0.768087
 >> iter 8000, loss: 0.663245
 >> iter 9000, loss: 0.410704
 >> iter 10000, loss: 0.417049
   Number of active neurons: 4
 >> iter 11000, loss: 0.308585
 >> iter 12000, loss: 0.260600
 >> iter 13000, loss: 0.376402
 >> iter 14000, loss: 0.344818
 >> iter 15000, loss: 0.260617
 >> iter 16000, loss: 0.356184
 >> iter 17000, loss: 0.250705
 >> iter 18000, loss: 0.409030
 >> iter 19000, loss: 0.315414
 >> iter 20000, loss: 0.411057
   Number of active neurons: 4
 >> iter 21000, loss: 0.281778
 >> iter 22000, loss: 0.557419
 >> iter 23000, loss: 0.414004
 >> iter 24000, loss: 0.332210
 >> iter 25000, loss: 0.447155
 >> iter 26000, loss: 0.364299
 >> iter 27000, loss: 0.394003
 >> iter 28000, loss: 0.319115
 >> iter 29000, loss: 0.220345
 >> iter 30000, loss: 0.210685
   Number of active neurons: 4
 >> iter 31000, loss: 0.311997
 >> iter 32000, loss: 0.642085
 >> iter 33000, loss: 0.531693
 >> iter 34000, loss: 0.437837
 >> iter 35000, loss: 0.389812
 >> iter 36000, loss: 0.272675
 >> iter 37000, loss: 0.225467
 >> iter 38000, loss: 0.270940
 >> iter 39000, loss: 0.379709
 >> iter 40000, loss: 0.232654
   Number of active neurons: 4
 >> iter 41000, loss: 0.287234
 >> iter 42000, loss: 0.335970
 >> iter 43000, loss: 0.266802
 >> iter 44000, loss: 0.308917
 >> iter 45000, loss: 0.242469
 >> iter 46000, loss: 0.210117
 >> iter 47000, loss: 0.439553
 >> iter 48000, loss: 0.294390
 >> iter 49000, loss: 0.330451
 >> iter 50000, loss: 0.431786
   Number of active neurons: 4
 >> iter 51000, loss: 0.263487
 >> iter 52000, loss: 0.332226
 >> iter 53000, loss: 0.326449
 >> iter 54000, loss: 0.166014
 >> iter 55000, loss: 0.198848
 >> iter 56000, loss: 0.270002
 >> iter 57000, loss: 0.368616
 >> iter 58000, loss: 0.269295
 >> iter 59000, loss: 0.297919
 >> iter 60000, loss: 0.215367
   Number of active neurons: 4
 >> iter 61000, loss: 0.247609
 >> iter 62000, loss: 0.193229
 >> iter 63000, loss: 0.395441
 >> iter 64000, loss: 0.406665
 >> iter 65000, loss: 0.181258
 >> iter 66000, loss: 0.152617
 >> iter 67000, loss: 0.111749
 >> iter 68000, loss: 0.254709
 >> iter 69000, loss: 0.209666
 >> iter 70000, loss: 0.221477
   Number of active neurons: 4
 >> iter 71000, loss: 0.238564
 >> iter 72000, loss: 0.246975
 >> iter 73000, loss: 0.370827
 >> iter 74000, loss: 0.226144
 >> iter 75000, loss: 0.185876
 >> iter 76000, loss: 0.208682
 >> iter 77000, loss: 0.249643
 >> iter 78000, loss: 0.279270
 >> iter 79000, loss: 0.500842
 >> iter 80000, loss: 0.324029
   Number of active neurons: 4
 >> iter 81000, loss: 0.243528
 >> iter 82000, loss: 0.198085
 >> iter 83000, loss: 0.261511
 >> iter 84000, loss: 0.225049
 >> iter 85000, loss: 0.196048
 >> iter 86000, loss: 0.244202
 >> iter 87000, loss: 0.314299
 >> iter 88000, loss: 0.417746
 >> iter 89000, loss: 0.325590
 >> iter 90000, loss: 0.341177
   Number of active neurons: 4
 >> iter 91000, loss: 0.313230
 >> iter 92000, loss: 0.354861
 >> iter 93000, loss: 0.378975
 >> iter 94000, loss: 0.366435
 >> iter 95000, loss: 0.460453
 >> iter 96000, loss: 0.490133
 >> iter 97000, loss: 0.409169
 >> iter 98000, loss: 0.422773
 >> iter 99000, loss: 0.301146
 >> iter 100000, loss: 0.284632
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.734997
 >> iter 2000, loss: 8.549303
 >> iter 3000, loss: 3.830637
 >> iter 4000, loss: 1.836946
 >> iter 5000, loss: 0.877155
 >> iter 6000, loss: 0.619279
 >> iter 7000, loss: 0.634336
 >> iter 8000, loss: 0.379939
 >> iter 9000, loss: 0.448386
 >> iter 10000, loss: 0.385447
   Number of active neurons: 5
 >> iter 11000, loss: 0.330804
 >> iter 12000, loss: 0.473603
 >> iter 13000, loss: 0.308069
 >> iter 14000, loss: 0.290487
 >> iter 15000, loss: 0.470201
 >> iter 16000, loss: 0.367965
 >> iter 17000, loss: 0.250693
 >> iter 18000, loss: 0.251679
 >> iter 19000, loss: 0.473877
 >> iter 20000, loss: 0.322991
   Number of active neurons: 4
 >> iter 21000, loss: 0.297781
 >> iter 22000, loss: 0.392440
 >> iter 23000, loss: 0.352615
 >> iter 24000, loss: 0.249670
 >> iter 25000, loss: 0.228089
 >> iter 26000, loss: 0.200699
 >> iter 27000, loss: 0.159751
 >> iter 28000, loss: 0.151623
 >> iter 29000, loss: 0.111956
 >> iter 30000, loss: 0.297509
   Number of active neurons: 3
 >> iter 31000, loss: 0.320157
 >> iter 32000, loss: 0.391640
 >> iter 33000, loss: 0.180392
 >> iter 34000, loss: 0.336092
 >> iter 35000, loss: 0.309629
 >> iter 36000, loss: 0.224305
 >> iter 37000, loss: 0.189098
 >> iter 38000, loss: 0.207068
 >> iter 39000, loss: 0.485491
 >> iter 40000, loss: 0.312662
   Number of active neurons: 3
 >> iter 41000, loss: 0.262926
 >> iter 42000, loss: 0.219662
 >> iter 43000, loss: 0.274020
 >> iter 44000, loss: 0.229968
 >> iter 45000, loss: 0.222058
 >> iter 46000, loss: 0.267904
 >> iter 47000, loss: 0.281344
 >> iter 48000, loss: 0.226765
 >> iter 49000, loss: 0.350090
 >> iter 50000, loss: 0.517486
   Number of active neurons: 3
 >> iter 51000, loss: 0.281239
 >> iter 52000, loss: 0.204294
 >> iter 53000, loss: 0.231798
 >> iter 54000, loss: 0.297902
 >> iter 55000, loss: 0.395064
 >> iter 56000, loss: 0.250317
 >> iter 57000, loss: 0.313124
 >> iter 58000, loss: 0.175506
 >> iter 59000, loss: 0.225581
 >> iter 60000, loss: 0.259845
   Number of active neurons: 3
 >> iter 61000, loss: 0.246526
 >> iter 62000, loss: 0.323567
 >> iter 63000, loss: 0.164145
 >> iter 64000, loss: 0.159901
 >> iter 65000, loss: 0.436818
 >> iter 66000, loss: 0.572299
 >> iter 67000, loss: 0.482156
 >> iter 68000, loss: 0.512456
 >> iter 69000, loss: 0.355865
 >> iter 70000, loss: 0.279936
   Number of active neurons: 3
 >> iter 71000, loss: 0.152545
 >> iter 72000, loss: 0.294749
 >> iter 73000, loss: 0.277801
 >> iter 74000, loss: 0.220336
 >> iter 75000, loss: 0.145582
 >> iter 76000, loss: 0.353893
 >> iter 77000, loss: 0.233038
 >> iter 78000, loss: 0.300185
 >> iter 79000, loss: 0.307461
 >> iter 80000, loss: 0.392626
   Number of active neurons: 3
 >> iter 81000, loss: 0.261821
 >> iter 82000, loss: 0.309538
 >> iter 83000, loss: 0.178059
 >> iter 84000, loss: 0.121989
 >> iter 85000, loss: 0.106749
 >> iter 86000, loss: 0.112405
 >> iter 87000, loss: 0.203073
 >> iter 88000, loss: 0.235666
 >> iter 89000, loss: 0.250593
 >> iter 90000, loss: 0.133833
   Number of active neurons: 3
 >> iter 91000, loss: 0.151203
 >> iter 92000, loss: 0.173655
 >> iter 93000, loss: 0.147556
 >> iter 94000, loss: 0.192168
 >> iter 95000, loss: 0.147381
 >> iter 96000, loss: 0.158072
 >> iter 97000, loss: 0.148163
 >> iter 98000, loss: 0.474608
 >> iter 99000, loss: 0.328879
 >> iter 100000, loss: 0.189393
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.587741
 >> iter 2000, loss: 8.353021
 >> iter 3000, loss: 3.762794
 >> iter 4000, loss: 1.877133
 >> iter 5000, loss: 1.165034
 >> iter 6000, loss: 0.732765
 >> iter 7000, loss: 0.548407
 >> iter 8000, loss: 0.376207
 >> iter 9000, loss: 0.353506
 >> iter 10000, loss: 0.333726
   Number of active neurons: 4
 >> iter 11000, loss: 0.324358
 >> iter 12000, loss: 0.397530
 >> iter 13000, loss: 0.257146
 >> iter 14000, loss: 0.313113
 >> iter 15000, loss: 0.314843
 >> iter 16000, loss: 0.233588
 >> iter 17000, loss: 0.273369
 >> iter 18000, loss: 0.217429
 >> iter 19000, loss: 0.165919
 >> iter 20000, loss: 0.180838
   Number of active neurons: 4
 >> iter 21000, loss: 0.418758
 >> iter 22000, loss: 0.321041
 >> iter 23000, loss: 0.287248
 >> iter 24000, loss: 0.280186
 >> iter 25000, loss: 0.353181
 >> iter 26000, loss: 0.393341
 >> iter 27000, loss: 0.332985
 >> iter 28000, loss: 0.294050
 >> iter 29000, loss: 0.160044
 >> iter 30000, loss: 0.227058
   Number of active neurons: 3
 >> iter 31000, loss: 0.300295
 >> iter 32000, loss: 0.224601
 >> iter 33000, loss: 0.193828
 >> iter 34000, loss: 0.201076
 >> iter 35000, loss: 0.260013
 >> iter 36000, loss: 0.319013
 >> iter 37000, loss: 0.234537
 >> iter 38000, loss: 0.248841
 >> iter 39000, loss: 0.275316
 >> iter 40000, loss: 0.268842
   Number of active neurons: 3
 >> iter 41000, loss: 0.189868
 >> iter 42000, loss: 0.317091
 >> iter 43000, loss: 0.371614
 >> iter 44000, loss: 0.243380
 >> iter 45000, loss: 0.258554
 >> iter 46000, loss: 0.207629
 >> iter 47000, loss: 0.240415
 >> iter 48000, loss: 0.295201
 >> iter 49000, loss: 0.211825
 >> iter 50000, loss: 0.242031
   Number of active neurons: 3
 >> iter 51000, loss: 0.278833
 >> iter 52000, loss: 0.303975
 >> iter 53000, loss: 0.226622
 >> iter 54000, loss: 0.424082
 >> iter 55000, loss: 0.302417
 >> iter 56000, loss: 0.424662
 >> iter 57000, loss: 0.255816
 >> iter 58000, loss: 0.170375
 >> iter 59000, loss: 0.165274
 >> iter 60000, loss: 0.211357
   Number of active neurons: 3
 >> iter 61000, loss: 0.333327
 >> iter 62000, loss: 0.365469
 >> iter 63000, loss: 0.180156
 >> iter 64000, loss: 0.094385
 >> iter 65000, loss: 0.305757
 >> iter 66000, loss: 0.277158
 >> iter 67000, loss: 0.213170
 >> iter 68000, loss: 0.298080
 >> iter 69000, loss: 0.377658
 >> iter 70000, loss: 0.263265
   Number of active neurons: 3
 >> iter 71000, loss: 0.225013
 >> iter 72000, loss: 0.378511
 >> iter 73000, loss: 0.449337
 >> iter 74000, loss: 0.270225
 >> iter 75000, loss: 0.239815
 >> iter 76000, loss: 0.328937
 >> iter 77000, loss: 0.241999
 >> iter 78000, loss: 0.112165
 >> iter 79000, loss: 0.192725
 >> iter 80000, loss: 0.225506
   Number of active neurons: 3
 >> iter 81000, loss: 0.123778
 >> iter 82000, loss: 0.239857
 >> iter 83000, loss: 0.429224
 >> iter 84000, loss: 0.355046
 >> iter 85000, loss: 0.207536
 >> iter 86000, loss: 0.286929
 >> iter 87000, loss: 0.191086
 >> iter 88000, loss: 0.254609
 >> iter 89000, loss: 0.117996
 >> iter 90000, loss: 0.174940
   Number of active neurons: 3
 >> iter 91000, loss: 0.127282
 >> iter 92000, loss: 0.228131
 >> iter 93000, loss: 0.264783
 >> iter 94000, loss: 0.300441
 >> iter 95000, loss: 0.215431
 >> iter 96000, loss: 0.311590
 >> iter 97000, loss: 0.226687
 >> iter 98000, loss: 0.264228
 >> iter 99000, loss: 0.344088
 >> iter 100000, loss: 0.293844
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.591971
 >> iter 2000, loss: 9.609247
 >> iter 3000, loss: 4.879025
 >> iter 4000, loss: 2.735088
 >> iter 5000, loss: 1.590642
 >> iter 6000, loss: 0.952011
 >> iter 7000, loss: 0.876066
 >> iter 8000, loss: 0.569987
 >> iter 9000, loss: 0.322892
 >> iter 10000, loss: 0.435763
   Number of active neurons: 5
 >> iter 11000, loss: 0.436556
 >> iter 12000, loss: 0.414607
 >> iter 13000, loss: 0.434088
 >> iter 14000, loss: 0.556113
 >> iter 15000, loss: 0.611965
 >> iter 16000, loss: 0.389152
 >> iter 17000, loss: 0.290503
 >> iter 18000, loss: 0.445274
 >> iter 19000, loss: 0.348656
 >> iter 20000, loss: 0.219599
   Number of active neurons: 5
 >> iter 21000, loss: 0.345095
 >> iter 22000, loss: 0.467999
 >> iter 23000, loss: 0.363709
 >> iter 24000, loss: 0.228749
 >> iter 25000, loss: 0.321226
 >> iter 26000, loss: 0.435124
 >> iter 27000, loss: 0.440446
 >> iter 28000, loss: 0.499896
 >> iter 29000, loss: 0.361603
 >> iter 30000, loss: 0.494640
   Number of active neurons: 3
 >> iter 31000, loss: 0.336953
 >> iter 32000, loss: 0.288431
 >> iter 33000, loss: 0.343805
 >> iter 34000, loss: 0.206863
 >> iter 35000, loss: 0.234996
 >> iter 36000, loss: 0.327233
 >> iter 37000, loss: 0.354169
 >> iter 38000, loss: 0.397524
 >> iter 39000, loss: 0.455994
 >> iter 40000, loss: 0.385858
   Number of active neurons: 4
 >> iter 41000, loss: 0.281007
 >> iter 42000, loss: 0.436366
 >> iter 43000, loss: 0.446257
 >> iter 44000, loss: 0.230348
 >> iter 45000, loss: 0.273699
 >> iter 46000, loss: 0.236417
 >> iter 47000, loss: 0.226215
 >> iter 48000, loss: 0.288689
 >> iter 49000, loss: 0.286758
 >> iter 50000, loss: 0.459080
   Number of active neurons: 3
 >> iter 51000, loss: 0.255320
 >> iter 52000, loss: 0.324044
 >> iter 53000, loss: 0.193997
 >> iter 54000, loss: 0.290198
 >> iter 55000, loss: 0.339321
 >> iter 56000, loss: 0.245945
 >> iter 57000, loss: 0.329891
 >> iter 58000, loss: 0.334098
 >> iter 59000, loss: 0.300663
 >> iter 60000, loss: 0.154233
   Number of active neurons: 3
 >> iter 61000, loss: 0.250934
 >> iter 62000, loss: 0.151566
 >> iter 63000, loss: 0.275418
 >> iter 64000, loss: 0.322371
 >> iter 65000, loss: 0.365602
 >> iter 66000, loss: 0.269786
 >> iter 67000, loss: 0.298824
 >> iter 68000, loss: 0.528482
 >> iter 69000, loss: 0.372402
 >> iter 70000, loss: 0.367732
   Number of active neurons: 3
 >> iter 71000, loss: 0.542230
 >> iter 72000, loss: 0.383315
 >> iter 73000, loss: 0.330477
 >> iter 74000, loss: 0.189979
 >> iter 75000, loss: 0.129683
 >> iter 76000, loss: 0.439904
 >> iter 77000, loss: 0.324475
 >> iter 78000, loss: 0.444825
 >> iter 79000, loss: 0.383671
 >> iter 80000, loss: 0.220081
   Number of active neurons: 3
 >> iter 81000, loss: 0.397321
 >> iter 82000, loss: 0.417680
 >> iter 83000, loss: 0.258139
 >> iter 84000, loss: 0.198651
 >> iter 85000, loss: 0.135251
 >> iter 86000, loss: 0.161608
 >> iter 87000, loss: 0.139122
 >> iter 88000, loss: 0.286655
 >> iter 89000, loss: 0.292294
 >> iter 90000, loss: 0.191921
   Number of active neurons: 3
 >> iter 91000, loss: 0.152452
 >> iter 92000, loss: 0.214850
 >> iter 93000, loss: 0.201507
 >> iter 94000, loss: 0.358891
 >> iter 95000, loss: 0.418473
 >> iter 96000, loss: 0.432374
 >> iter 97000, loss: 0.314281
 >> iter 98000, loss: 0.252116
 >> iter 99000, loss: 0.152132
 >> iter 100000, loss: 0.139267
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.545029
 >> iter 2000, loss: 11.030924
 >> iter 3000, loss: 5.210145
 >> iter 4000, loss: 2.380412
 >> iter 5000, loss: 1.178761
 >> iter 6000, loss: 0.584812
 >> iter 7000, loss: 0.378766
 >> iter 8000, loss: 0.474656
 >> iter 9000, loss: 0.349257
 >> iter 10000, loss: 0.216935
   Number of active neurons: 4
 >> iter 11000, loss: 0.483880
 >> iter 12000, loss: 0.333686
 >> iter 13000, loss: 0.160053
 >> iter 14000, loss: 0.271433
 >> iter 15000, loss: 0.277114
 >> iter 16000, loss: 0.156442
 >> iter 17000, loss: 0.201199
 >> iter 18000, loss: 0.179276
 >> iter 19000, loss: 0.239529
 >> iter 20000, loss: 0.288198
   Number of active neurons: 3
 >> iter 21000, loss: 0.141713
 >> iter 22000, loss: 0.102630
 >> iter 23000, loss: 0.470043
 >> iter 24000, loss: 0.341654
 >> iter 25000, loss: 0.354129
 >> iter 26000, loss: 0.211452
 >> iter 27000, loss: 0.215584
 >> iter 28000, loss: 0.331217
 >> iter 29000, loss: 0.170034
 >> iter 30000, loss: 0.264605
   Number of active neurons: 3
 >> iter 31000, loss: 0.210220
 >> iter 32000, loss: 0.166680
 >> iter 33000, loss: 0.239495
 >> iter 34000, loss: 0.339931
 >> iter 35000, loss: 0.238777
 >> iter 36000, loss: 0.154901
 >> iter 37000, loss: 0.254131
 >> iter 38000, loss: 0.246238
 >> iter 39000, loss: 0.413622
 >> iter 40000, loss: 0.425233
   Number of active neurons: 3
 >> iter 41000, loss: 0.311004
 >> iter 42000, loss: 0.329792
 >> iter 43000, loss: 0.178538
 >> iter 44000, loss: 0.149529
 >> iter 45000, loss: 0.221992
 >> iter 46000, loss: 0.250088
 >> iter 47000, loss: 0.220254
 >> iter 48000, loss: 0.119367
 >> iter 49000, loss: 0.106709
 >> iter 50000, loss: 0.147762
   Number of active neurons: 3
 >> iter 51000, loss: 0.452394
 >> iter 52000, loss: 0.347698
 >> iter 53000, loss: 0.395755
 >> iter 54000, loss: 0.325524
 >> iter 55000, loss: 0.289622
 >> iter 56000, loss: 0.340215
 >> iter 57000, loss: 0.209651
 >> iter 58000, loss: 0.365687
 >> iter 59000, loss: 0.306381
 >> iter 60000, loss: 0.146262
   Number of active neurons: 3
 >> iter 61000, loss: 0.159659
 >> iter 62000, loss: 0.167325
 >> iter 63000, loss: 0.388116
 >> iter 64000, loss: 0.216771
 >> iter 65000, loss: 0.292579
 >> iter 66000, loss: 0.167089
 >> iter 67000, loss: 0.251283
 >> iter 68000, loss: 0.281309
 >> iter 69000, loss: 0.187606
 >> iter 70000, loss: 0.255435
   Number of active neurons: 3
 >> iter 71000, loss: 0.256462
 >> iter 72000, loss: 0.379340
 >> iter 73000, loss: 0.376294
 >> iter 74000, loss: 0.303917
 >> iter 75000, loss: 0.264057
 >> iter 76000, loss: 0.168091
 >> iter 77000, loss: 0.216901
 >> iter 78000, loss: 0.204989
 >> iter 79000, loss: 0.289478
 >> iter 80000, loss: 0.197124
   Number of active neurons: 3
 >> iter 81000, loss: 0.158372
 >> iter 82000, loss: 0.202445
 >> iter 83000, loss: 0.100620
 >> iter 84000, loss: 0.184275
 >> iter 85000, loss: 0.178088
 >> iter 86000, loss: 0.230133
 >> iter 87000, loss: 0.283524
 >> iter 88000, loss: 0.190890
 >> iter 89000, loss: 0.278216
 >> iter 90000, loss: 0.426953
   Number of active neurons: 3
 >> iter 91000, loss: 0.255464
 >> iter 92000, loss: 0.255037
 >> iter 93000, loss: 0.176825
 >> iter 94000, loss: 0.134590
 >> iter 95000, loss: 0.121789
 >> iter 96000, loss: 0.266383
 >> iter 97000, loss: 0.175780
 >> iter 98000, loss: 0.331327
 >> iter 99000, loss: 0.234248
 >> iter 100000, loss: 0.194794
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.848729
 >> iter 2000, loss: 10.776637
 >> iter 3000, loss: 5.902283
 >> iter 4000, loss: 3.081882
 >> iter 5000, loss: 1.778979
 >> iter 6000, loss: 1.059713
 >> iter 7000, loss: 0.765664
 >> iter 8000, loss: 0.820413
 >> iter 9000, loss: 0.696944
 >> iter 10000, loss: 0.880813
   Number of active neurons: 7
 >> iter 11000, loss: 0.766228
 >> iter 12000, loss: 0.703985
 >> iter 13000, loss: 0.705929
 >> iter 14000, loss: 0.509369
 >> iter 15000, loss: 0.555572
 >> iter 16000, loss: 0.314720
 >> iter 17000, loss: 0.300276
 >> iter 18000, loss: 0.279059
 >> iter 19000, loss: 0.431096
 >> iter 20000, loss: 0.815163
   Number of active neurons: 7
 >> iter 21000, loss: 0.582968
 >> iter 22000, loss: 0.478237
 >> iter 23000, loss: 0.611041
 >> iter 24000, loss: 0.608429
 >> iter 25000, loss: 0.542534
 >> iter 26000, loss: 0.497563
 >> iter 27000, loss: 0.422790
 >> iter 28000, loss: 0.518550
 >> iter 29000, loss: 0.530161
 >> iter 30000, loss: 0.534247
   Number of active neurons: 8
 >> iter 31000, loss: 0.575355
 >> iter 32000, loss: 0.546933
 >> iter 33000, loss: 0.486745
 >> iter 34000, loss: 0.327407
 >> iter 35000, loss: 0.377117
 >> iter 36000, loss: 0.549026
 >> iter 37000, loss: 0.523260
 >> iter 38000, loss: 0.532344
 >> iter 39000, loss: 0.481154
 >> iter 40000, loss: 0.411802
   Number of active neurons: 4
 >> iter 41000, loss: 0.368266
 >> iter 42000, loss: 0.632534
 >> iter 43000, loss: 0.426878
 >> iter 44000, loss: 0.358075
 >> iter 45000, loss: 0.262216
 >> iter 46000, loss: 0.372594
 >> iter 47000, loss: 0.395660
 >> iter 48000, loss: 0.361391
 >> iter 49000, loss: 0.527731
 >> iter 50000, loss: 0.599438
   Number of active neurons: 7
 >> iter 51000, loss: 0.448763
 >> iter 52000, loss: 0.638307
 >> iter 53000, loss: 0.563708
 >> iter 54000, loss: 0.494644
 >> iter 55000, loss: 0.660437
 >> iter 56000, loss: 0.572970
 >> iter 57000, loss: 0.408022
 >> iter 58000, loss: 0.541451
 >> iter 59000, loss: 0.406491
 >> iter 60000, loss: 0.337948
   Number of active neurons: 7
 >> iter 61000, loss: 0.429513
 >> iter 62000, loss: 0.391607
 >> iter 63000, loss: 0.285635
 >> iter 64000, loss: 0.312515
 >> iter 65000, loss: 0.210107
 >> iter 66000, loss: 0.366838
 >> iter 67000, loss: 0.428233
 >> iter 68000, loss: 0.291832
 >> iter 69000, loss: 0.323217
 >> iter 70000, loss: 0.576090
   Number of active neurons: 7
 >> iter 71000, loss: 0.593928
 >> iter 72000, loss: 0.450037
 >> iter 73000, loss: 0.340789
 >> iter 74000, loss: 0.455382
 >> iter 75000, loss: 0.459755
 >> iter 76000, loss: 0.587331
 >> iter 77000, loss: 0.611540
 >> iter 78000, loss: 0.384335
 >> iter 79000, loss: 0.520659
 >> iter 80000, loss: 0.479588
   Number of active neurons: 5
 >> iter 81000, loss: 0.363859
 >> iter 82000, loss: 0.518615
 >> iter 83000, loss: 0.416922
 >> iter 84000, loss: 0.632957
 >> iter 85000, loss: 0.553896
 >> iter 86000, loss: 0.370036
 >> iter 87000, loss: 0.192548
 >> iter 88000, loss: 0.379793
 >> iter 89000, loss: 0.283917
 >> iter 90000, loss: 0.448242
   Number of active neurons: 9
 >> iter 91000, loss: 0.389269
 >> iter 92000, loss: 0.511738
 >> iter 93000, loss: 0.380506
 >> iter 94000, loss: 0.395054
 >> iter 95000, loss: 0.380867
 >> iter 96000, loss: 0.429150
 >> iter 97000, loss: 0.393039
 >> iter 98000, loss: 0.488368
 >> iter 99000, loss: 0.559756
 >> iter 100000, loss: 0.340783
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 18.489077
 >> iter 2000, loss: 10.857783
 >> iter 3000, loss: 5.499523
 >> iter 4000, loss: 2.792665
 >> iter 5000, loss: 1.488466
 >> iter 6000, loss: 1.053357
 >> iter 7000, loss: 0.662011
 >> iter 8000, loss: 0.736629
 >> iter 9000, loss: 0.531342
 >> iter 10000, loss: 0.472032
   Number of active neurons: 9
 >> iter 11000, loss: 0.507476
 >> iter 12000, loss: 0.522091
 >> iter 13000, loss: 0.453734
 >> iter 14000, loss: 0.685912
 >> iter 15000, loss: 0.593385
 >> iter 16000, loss: 0.687537
 >> iter 17000, loss: 0.623768
 >> iter 18000, loss: 0.637055
 >> iter 19000, loss: 0.549362
 >> iter 20000, loss: 0.406657
   Number of active neurons: 9
 >> iter 21000, loss: 0.393701
 >> iter 22000, loss: 0.382969
 >> iter 23000, loss: 0.303117
 >> iter 24000, loss: 0.345797
 >> iter 25000, loss: 0.550016
 >> iter 26000, loss: 0.488269
 >> iter 27000, loss: 0.383990
 >> iter 28000, loss: 0.347757
 >> iter 29000, loss: 0.449194
 >> iter 30000, loss: 0.395225
   Number of active neurons: 9
 >> iter 31000, loss: 0.711336
 >> iter 32000, loss: 0.698379
 >> iter 33000, loss: 0.585313
 >> iter 34000, loss: 0.523153
 >> iter 35000, loss: 0.340139
 >> iter 36000, loss: 0.339062
 >> iter 37000, loss: 0.385996
 >> iter 38000, loss: 0.356261
 >> iter 39000, loss: 0.384425
 >> iter 40000, loss: 0.400275
   Number of active neurons: 6
 >> iter 41000, loss: 0.314569
 >> iter 42000, loss: 0.349786
 >> iter 43000, loss: 0.389769
 >> iter 44000, loss: 0.439465
 >> iter 45000, loss: 0.455741
 >> iter 46000, loss: 0.513180
 >> iter 47000, loss: 0.407106
 >> iter 48000, loss: 0.436341
 >> iter 49000, loss: 0.383670
 >> iter 50000, loss: 0.617113
   Number of active neurons: 5
 >> iter 51000, loss: 0.381739
 >> iter 52000, loss: 0.466598
 >> iter 53000, loss: 0.327730
 >> iter 54000, loss: 0.426374
 >> iter 55000, loss: 0.525310
 >> iter 56000, loss: 0.717738
 >> iter 57000, loss: 0.585641
 >> iter 58000, loss: 0.475323
 >> iter 59000, loss: 0.409996
 >> iter 60000, loss: 0.584912
   Number of active neurons: 6
 >> iter 61000, loss: 0.558888
 >> iter 62000, loss: 0.524526
 >> iter 63000, loss: 0.635573
 >> iter 64000, loss: 0.566268
 >> iter 65000, loss: 0.667580
 >> iter 66000, loss: 0.684358
 >> iter 67000, loss: 0.557780
 >> iter 68000, loss: 0.532436
 >> iter 69000, loss: 0.665357
 >> iter 70000, loss: 0.549056
   Number of active neurons: 7
 >> iter 71000, loss: 0.500625
 >> iter 72000, loss: 0.516106
 >> iter 73000, loss: 0.536423
 >> iter 74000, loss: 0.321199
 >> iter 75000, loss: 0.509871
 >> iter 76000, loss: 0.289717
 >> iter 77000, loss: 0.265089
 >> iter 78000, loss: 0.524983
 >> iter 79000, loss: 0.342219
 >> iter 80000, loss: 0.384798
   Number of active neurons: 9
 >> iter 81000, loss: 0.617364
 >> iter 82000, loss: 0.529810
 >> iter 83000, loss: 0.383321
 >> iter 84000, loss: 0.467841
 >> iter 85000, loss: 0.514690
 >> iter 86000, loss: 0.542698
 >> iter 87000, loss: 0.277781
 >> iter 88000, loss: 0.316577
 >> iter 89000, loss: 0.263527
 >> iter 90000, loss: 0.593290
   Number of active neurons: 10
 >> iter 91000, loss: 0.379345
 >> iter 92000, loss: 0.432496
 >> iter 93000, loss: 0.552192
 >> iter 94000, loss: 0.459035
 >> iter 95000, loss: 0.501099
 >> iter 96000, loss: 0.386633
 >> iter 97000, loss: 0.350413
 >> iter 98000, loss: 0.384215
 >> iter 99000, loss: 0.344967
 >> iter 100000, loss: 0.432222
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

