 > Problema: tomita7nueva
 > Args:
   - Hidden size: 20
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 16.560645
 >> iter 2000, loss: 9.443280
 >> iter 3000, loss: 5.258256
 >> iter 4000, loss: 2.649297
 >> iter 5000, loss: 1.382746
 >> iter 6000, loss: 0.836347
 >> iter 7000, loss: 0.615127
 >> iter 8000, loss: 0.460531
 >> iter 9000, loss: 0.388786
 >> iter 10000, loss: 0.331319
   Number of active neurons: 7
 >> iter 11000, loss: 0.316145
 >> iter 12000, loss: 0.319513
 >> iter 13000, loss: 0.342870
 >> iter 14000, loss: 0.320917
 >> iter 15000, loss: 0.331928
 >> iter 16000, loss: 0.384217
 >> iter 17000, loss: 0.461954
 >> iter 18000, loss: 0.358962
 >> iter 19000, loss: 0.423493
 >> iter 20000, loss: 0.436231
   Number of active neurons: 7
 >> iter 21000, loss: 0.377569
 >> iter 22000, loss: 0.387623
 >> iter 23000, loss: 0.358195
 >> iter 24000, loss: 0.339437
 >> iter 25000, loss: 0.263799
 >> iter 26000, loss: 0.384927
 >> iter 27000, loss: 0.439478
 >> iter 28000, loss: 0.351593
 >> iter 29000, loss: 0.303636
 >> iter 30000, loss: 0.302441
   Number of active neurons: 7
 >> iter 31000, loss: 0.334359
 >> iter 32000, loss: 0.274152
 >> iter 33000, loss: 0.382031
 >> iter 34000, loss: 0.287642
 >> iter 35000, loss: 0.366605
 >> iter 36000, loss: 0.301700
 >> iter 37000, loss: 0.426075
 >> iter 38000, loss: 0.410938
 >> iter 39000, loss: 0.425697
 >> iter 40000, loss: 0.253482
   Number of active neurons: 7
 >> iter 41000, loss: 0.319115
 >> iter 42000, loss: 0.411956
 >> iter 43000, loss: 0.363706
 >> iter 44000, loss: 0.406014
 >> iter 45000, loss: 0.394801
 >> iter 46000, loss: 0.298429
 >> iter 47000, loss: 0.223140
 >> iter 48000, loss: 0.372504
 >> iter 49000, loss: 0.396472
 >> iter 50000, loss: 0.432648
   Number of active neurons: 7
 >> iter 51000, loss: 0.295549
 >> iter 52000, loss: 0.321625
 >> iter 53000, loss: 0.309808
 >> iter 54000, loss: 0.325427
 >> iter 55000, loss: 0.313772
 >> iter 56000, loss: 0.364869
 >> iter 57000, loss: 0.299385
 >> iter 58000, loss: 0.280962
 >> iter 59000, loss: 0.323778
 >> iter 60000, loss: 0.260335
   Number of active neurons: 7
 >> iter 61000, loss: 0.225080
 >> iter 62000, loss: 0.365768
 >> iter 63000, loss: 0.403214
 >> iter 64000, loss: 0.418039
 >> iter 65000, loss: 0.417540
 >> iter 66000, loss: 0.291678
 >> iter 67000, loss: 0.266117
 >> iter 68000, loss: 0.393186
 >> iter 69000, loss: 0.271239
 >> iter 70000, loss: 0.294579
   Number of active neurons: 7
 >> iter 71000, loss: 0.271718
 >> iter 72000, loss: 0.309490
 >> iter 73000, loss: 0.390227
 >> iter 74000, loss: 0.385301
 >> iter 75000, loss: 0.412497
 >> iter 76000, loss: 0.407769
 >> iter 77000, loss: 0.455212
 >> iter 78000, loss: 0.397494
 >> iter 79000, loss: 0.346753
 >> iter 80000, loss: 0.318549
   Number of active neurons: 7
 >> iter 81000, loss: 0.411982
 >> iter 82000, loss: 0.286735
 >> iter 83000, loss: 0.342445
 >> iter 84000, loss: 0.270528
 >> iter 85000, loss: 0.295366
 >> iter 86000, loss: 0.237063
 >> iter 87000, loss: 0.309976
 >> iter 88000, loss: 0.327738
 >> iter 89000, loss: 0.317054
 >> iter 90000, loss: 0.260114
   Number of active neurons: 7
 >> iter 91000, loss: 0.259552
 >> iter 92000, loss: 0.208757
 >> iter 93000, loss: 0.150234
 >> iter 94000, loss: 0.264051
 >> iter 95000, loss: 0.271254
 >> iter 96000, loss: 0.317002
 >> iter 97000, loss: 0.211372
 >> iter 98000, loss: 0.275150
 >> iter 99000, loss: 0.343601
 >> iter 100000, loss: 0.250298
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.793869
 >> iter 2000, loss: 9.745547
 >> iter 3000, loss: 5.911139
 >> iter 4000, loss: 2.873538
 >> iter 5000, loss: 1.372293
 >> iter 6000, loss: 0.715210
 >> iter 7000, loss: 0.365369
 >> iter 8000, loss: 0.236947
 >> iter 9000, loss: 0.189266
 >> iter 10000, loss: 0.221972
   Number of active neurons: 8
 >> iter 11000, loss: 0.277910
 >> iter 12000, loss: 0.273273
 >> iter 13000, loss: 0.335342
 >> iter 14000, loss: 0.282064
 >> iter 15000, loss: 0.196238
 >> iter 16000, loss: 0.233027
 >> iter 17000, loss: 0.258091
 >> iter 18000, loss: 0.313785
 >> iter 19000, loss: 0.169661
 >> iter 20000, loss: 0.226940
   Number of active neurons: 8
 >> iter 21000, loss: 0.269199
 >> iter 22000, loss: 0.331695
 >> iter 23000, loss: 0.326070
 >> iter 24000, loss: 0.266542
 >> iter 25000, loss: 0.264182
 >> iter 26000, loss: 0.269254
 >> iter 27000, loss: 0.223204
 >> iter 28000, loss: 0.231662
 >> iter 29000, loss: 0.231796
 >> iter 30000, loss: 0.257998
   Number of active neurons: 8
 >> iter 31000, loss: 0.247038
 >> iter 32000, loss: 0.235517
 >> iter 33000, loss: 0.237738
 >> iter 34000, loss: 0.300146
 >> iter 35000, loss: 0.257744
 >> iter 36000, loss: 0.267436
 >> iter 37000, loss: 0.271980
 >> iter 38000, loss: 0.274828
 >> iter 39000, loss: 0.310892
 >> iter 40000, loss: 0.383676
   Number of active neurons: 8
 >> iter 41000, loss: 0.315327
 >> iter 42000, loss: 0.245012
 >> iter 43000, loss: 0.351821
 >> iter 44000, loss: 0.288333
 >> iter 45000, loss: 0.217057
 >> iter 46000, loss: 0.318024
 >> iter 47000, loss: 0.301645
 >> iter 48000, loss: 0.248099
 >> iter 49000, loss: 0.248743
 >> iter 50000, loss: 0.219153
   Number of active neurons: 8
 >> iter 51000, loss: 0.184579
 >> iter 52000, loss: 0.291974
 >> iter 53000, loss: 0.389980
 >> iter 54000, loss: 0.345275
 >> iter 55000, loss: 0.287559
 >> iter 56000, loss: 0.289656
 >> iter 57000, loss: 0.251431
 >> iter 58000, loss: 0.254947
 >> iter 59000, loss: 0.273087
 >> iter 60000, loss: 0.242959
   Number of active neurons: 8
 >> iter 61000, loss: 0.183898
 >> iter 62000, loss: 0.282470
 >> iter 63000, loss: 0.237184
 >> iter 64000, loss: 0.207685
 >> iter 65000, loss: 0.181240
 >> iter 66000, loss: 0.292214
 >> iter 67000, loss: 0.297711
 >> iter 68000, loss: 0.169039
 >> iter 69000, loss: 0.383705
 >> iter 70000, loss: 0.331271
   Number of active neurons: 8
 >> iter 71000, loss: 0.276296
 >> iter 72000, loss: 0.236603
 >> iter 73000, loss: 0.306698
 >> iter 74000, loss: 0.303694
 >> iter 75000, loss: 0.276250
 >> iter 76000, loss: 0.213639
 >> iter 77000, loss: 0.300985
 >> iter 78000, loss: 0.204938
 >> iter 79000, loss: 0.246758
 >> iter 80000, loss: 0.279466
   Number of active neurons: 8
 >> iter 81000, loss: 0.184143
 >> iter 82000, loss: 0.207003
 >> iter 83000, loss: 0.304914
 >> iter 84000, loss: 0.411871
 >> iter 85000, loss: 0.245273
 >> iter 86000, loss: 0.303404
 >> iter 87000, loss: 0.246322
 >> iter 88000, loss: 0.271222
 >> iter 89000, loss: 0.313108
 >> iter 90000, loss: 0.315660
   Number of active neurons: 8
 >> iter 91000, loss: 0.307617
 >> iter 92000, loss: 0.244257
 >> iter 93000, loss: 0.248618
 >> iter 94000, loss: 0.246275
 >> iter 95000, loss: 0.198134
 >> iter 96000, loss: 0.234376
 >> iter 97000, loss: 0.247932
 >> iter 98000, loss: 0.375886
 >> iter 99000, loss: 0.259208
 >> iter 100000, loss: 0.309359
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00199998000021
   - Test - A: 0.0
   - Test - B: 18.2121191921
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.796007
 >> iter 2000, loss: 10.774730
 >> iter 3000, loss: 5.336335
 >> iter 4000, loss: 2.447029
 >> iter 5000, loss: 1.309921
 >> iter 6000, loss: 0.730754
 >> iter 7000, loss: 0.399305
 >> iter 8000, loss: 0.414717
 >> iter 9000, loss: 0.399208
 >> iter 10000, loss: 0.466492
   Number of active neurons: 13
 >> iter 11000, loss: 0.415187
 >> iter 12000, loss: 0.522898
 >> iter 13000, loss: 0.433256
 >> iter 14000, loss: 0.375293
 >> iter 15000, loss: 0.361165
 >> iter 16000, loss: 0.379302
 >> iter 17000, loss: 0.351419
 >> iter 18000, loss: 0.405523
 >> iter 19000, loss: 0.464295
 >> iter 20000, loss: 0.517556
   Number of active neurons: 12
 >> iter 21000, loss: 0.409727
 >> iter 22000, loss: 0.325004
 >> iter 23000, loss: 0.449140
 >> iter 24000, loss: 0.351582
 >> iter 25000, loss: 0.422334
 >> iter 26000, loss: 0.419122
 >> iter 27000, loss: 0.367361
 >> iter 28000, loss: 0.297017
 >> iter 29000, loss: 0.310054
 >> iter 30000, loss: 0.380740
   Number of active neurons: 10
 >> iter 31000, loss: 0.242444
 >> iter 32000, loss: 0.214443
 >> iter 33000, loss: 0.293436
 >> iter 34000, loss: 0.262435
 >> iter 35000, loss: 0.305169
 >> iter 36000, loss: 0.253969
 >> iter 37000, loss: 0.275835
 >> iter 38000, loss: 0.234679
 >> iter 39000, loss: 0.312742
 >> iter 40000, loss: 0.283210
   Number of active neurons: 10
 >> iter 41000, loss: 0.382732
 >> iter 42000, loss: 0.349709
 >> iter 43000, loss: 0.310235
 >> iter 44000, loss: 0.333473
 >> iter 45000, loss: 0.300100
 >> iter 46000, loss: 0.295655
 >> iter 47000, loss: 0.310763
 >> iter 48000, loss: 0.457506
 >> iter 49000, loss: 0.378743
 >> iter 50000, loss: 0.329803
   Number of active neurons: 9
 >> iter 51000, loss: 0.321590
 >> iter 52000, loss: 0.301641
 >> iter 53000, loss: 0.360585
 >> iter 54000, loss: 0.399123
 >> iter 55000, loss: 0.448910
 >> iter 56000, loss: 0.424584
 >> iter 57000, loss: 0.341371
 >> iter 58000, loss: 0.401567
 >> iter 59000, loss: 0.418822
 >> iter 60000, loss: 0.456164
   Number of active neurons: 8
 >> iter 61000, loss: 0.474690
 >> iter 62000, loss: 0.390306
 >> iter 63000, loss: 0.379154
 >> iter 64000, loss: 0.356361
 >> iter 65000, loss: 0.405363
 >> iter 66000, loss: 0.357262
 >> iter 67000, loss: 0.386896
 >> iter 68000, loss: 0.261027
 >> iter 69000, loss: 0.243797
 >> iter 70000, loss: 0.285049
   Number of active neurons: 8
 >> iter 71000, loss: 0.399611
 >> iter 72000, loss: 0.458144
 >> iter 73000, loss: 0.352706
 >> iter 74000, loss: 0.428453
 >> iter 75000, loss: 0.296950
 >> iter 76000, loss: 0.484933
 >> iter 77000, loss: 0.415623
 >> iter 78000, loss: 0.356000
 >> iter 79000, loss: 0.306047
 >> iter 80000, loss: 0.396959
   Number of active neurons: 8
 >> iter 81000, loss: 0.325896
 >> iter 82000, loss: 0.364069
 >> iter 83000, loss: 0.376628
 >> iter 84000, loss: 0.394228
 >> iter 85000, loss: 0.289655
 >> iter 86000, loss: 0.273466
 >> iter 87000, loss: 0.317135
 >> iter 88000, loss: 0.383813
 >> iter 89000, loss: 0.286206
 >> iter 90000, loss: 0.285461
   Number of active neurons: 8
 >> iter 91000, loss: 0.260293
 >> iter 92000, loss: 0.301358
 >> iter 93000, loss: 0.275439
 >> iter 94000, loss: 0.210336
 >> iter 95000, loss: 0.446091
 >> iter 96000, loss: 0.291498
 >> iter 97000, loss: 0.271706
 >> iter 98000, loss: 0.227421
 >> iter 99000, loss: 0.267122
 >> iter 100000, loss: 0.373103
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.878207
 >> iter 2000, loss: 10.027911
 >> iter 3000, loss: 6.656748
 >> iter 4000, loss: 4.351873
 >> iter 5000, loss: 2.672211
 >> iter 6000, loss: 1.573358
 >> iter 7000, loss: 1.346880
 >> iter 8000, loss: 0.990131
 >> iter 9000, loss: 0.721253
 >> iter 10000, loss: 0.530080
   Number of active neurons: 8
 >> iter 11000, loss: 0.692024
 >> iter 12000, loss: 0.668023
 >> iter 13000, loss: 0.513782
 >> iter 14000, loss: 0.334232
 >> iter 15000, loss: 0.481162
 >> iter 16000, loss: 0.497667
 >> iter 17000, loss: 0.544009
 >> iter 18000, loss: 0.701488
 >> iter 19000, loss: 0.610960
 >> iter 20000, loss: 0.519095
   Number of active neurons: 8
 >> iter 21000, loss: 0.560508
 >> iter 22000, loss: 0.632586
 >> iter 23000, loss: 0.550942
 >> iter 24000, loss: 0.413750
 >> iter 25000, loss: 0.487748
 >> iter 26000, loss: 0.450382
 >> iter 27000, loss: 0.529792
 >> iter 28000, loss: 0.386368
 >> iter 29000, loss: 0.419977
 >> iter 30000, loss: 0.381896
   Number of active neurons: 7
 >> iter 31000, loss: 0.489716
 >> iter 32000, loss: 0.573941
 >> iter 33000, loss: 0.467785
 >> iter 34000, loss: 0.523930
 >> iter 35000, loss: 0.531888
 >> iter 36000, loss: 0.614768
 >> iter 37000, loss: 0.554345
 >> iter 38000, loss: 0.390745
 >> iter 39000, loss: 0.467978
 >> iter 40000, loss: 0.461624
   Number of active neurons: 7
 >> iter 41000, loss: 0.485848
 >> iter 42000, loss: 0.492705
 >> iter 43000, loss: 0.484639
 >> iter 44000, loss: 0.571999
 >> iter 45000, loss: 0.494981
 >> iter 46000, loss: 0.615057
 >> iter 47000, loss: 0.631932
 >> iter 48000, loss: 0.492434
 >> iter 49000, loss: 0.465791
 >> iter 50000, loss: 0.678264
   Number of active neurons: 7
 >> iter 51000, loss: 0.489078
 >> iter 52000, loss: 0.360581
 >> iter 53000, loss: 0.528195
 >> iter 54000, loss: 0.550303
 >> iter 55000, loss: 0.501673
 >> iter 56000, loss: 0.433719
 >> iter 57000, loss: 0.345794
 >> iter 58000, loss: 0.447793
 >> iter 59000, loss: 0.493765
 >> iter 60000, loss: 0.423976
   Number of active neurons: 6
 >> iter 61000, loss: 0.419656
 >> iter 62000, loss: 0.460948
 >> iter 63000, loss: 0.503419
 >> iter 64000, loss: 0.594869
 >> iter 65000, loss: 0.474557
 >> iter 66000, loss: 0.346239
 >> iter 67000, loss: 0.396217
 >> iter 68000, loss: 0.429214
 >> iter 69000, loss: 0.619774
 >> iter 70000, loss: 0.505394
   Number of active neurons: 5
 >> iter 71000, loss: 0.573759
 >> iter 72000, loss: 0.520931
 >> iter 73000, loss: 0.557270
 >> iter 74000, loss: 0.461743
 >> iter 75000, loss: 0.431733
 >> iter 76000, loss: 0.355519
 >> iter 77000, loss: 0.388875
 >> iter 78000, loss: 0.430752
 >> iter 79000, loss: 0.385672
 >> iter 80000, loss: 0.458906
   Number of active neurons: 5
 >> iter 81000, loss: 0.538353
 >> iter 82000, loss: 0.482479
 >> iter 83000, loss: 0.475723
 >> iter 84000, loss: 0.300442
 >> iter 85000, loss: 0.391544
 >> iter 86000, loss: 0.410838
 >> iter 87000, loss: 0.412353
 >> iter 88000, loss: 0.583000
 >> iter 89000, loss: 0.614871
 >> iter 90000, loss: 0.457811
   Number of active neurons: 5
 >> iter 91000, loss: 0.412489
 >> iter 92000, loss: 0.534380
 >> iter 93000, loss: 0.587844
 >> iter 94000, loss: 0.553809
 >> iter 95000, loss: 0.561282
 >> iter 96000, loss: 0.582460
 >> iter 97000, loss: 0.585523
 >> iter 98000, loss: 0.465448
 >> iter 99000, loss: 0.520860
 >> iter 100000, loss: 0.469227
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 1.08659422705
   - Test - B: 19.058729418
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 16.692569
 >> iter 2000, loss: 9.996795
 >> iter 3000, loss: 5.426767
 >> iter 4000, loss: 2.822310
 >> iter 5000, loss: 1.369316
 >> iter 6000, loss: 0.977419
 >> iter 7000, loss: 0.772841
 >> iter 8000, loss: 0.430073
 >> iter 9000, loss: 0.363499
 >> iter 10000, loss: 0.362176
   Number of active neurons: 14
 >> iter 11000, loss: 0.394225
 >> iter 12000, loss: 0.376973
 >> iter 13000, loss: 0.377380
 >> iter 14000, loss: 0.404675
 >> iter 15000, loss: 0.402919
 >> iter 16000, loss: 0.359563
 >> iter 17000, loss: 0.318817
 >> iter 18000, loss: 0.384877
 >> iter 19000, loss: 0.469638
 >> iter 20000, loss: 0.320918
   Number of active neurons: 11
 >> iter 21000, loss: 0.231239
 >> iter 22000, loss: 0.261898
 >> iter 23000, loss: 0.320726
 >> iter 24000, loss: 0.285187
 >> iter 25000, loss: 0.265075
 >> iter 26000, loss: 0.265406
 >> iter 27000, loss: 0.246875
 >> iter 28000, loss: 0.313256
 >> iter 29000, loss: 0.320516
 >> iter 30000, loss: 0.225510
   Number of active neurons: 11
 >> iter 31000, loss: 0.264373
 >> iter 32000, loss: 0.311791
 >> iter 33000, loss: 0.248784
 >> iter 34000, loss: 0.280757
 >> iter 35000, loss: 0.389215
 >> iter 36000, loss: 0.352793
 >> iter 37000, loss: 0.281563
 >> iter 38000, loss: 0.213858
 >> iter 39000, loss: 0.278929
 >> iter 40000, loss: 0.325479
   Number of active neurons: 8
 >> iter 41000, loss: 0.335479
 >> iter 42000, loss: 0.253353
 >> iter 43000, loss: 0.426103
 >> iter 44000, loss: 0.365359
 >> iter 45000, loss: 0.374662
 >> iter 46000, loss: 0.281292
 >> iter 47000, loss: 0.243586
 >> iter 48000, loss: 0.337248
 >> iter 49000, loss: 0.275068
 >> iter 50000, loss: 0.273256
   Number of active neurons: 7
 >> iter 51000, loss: 0.299037
 >> iter 52000, loss: 0.215074
 >> iter 53000, loss: 0.415023
 >> iter 54000, loss: 0.421122
 >> iter 55000, loss: 0.457854
 >> iter 56000, loss: 0.312509
 >> iter 57000, loss: 0.351973
 >> iter 58000, loss: 0.258550
 >> iter 59000, loss: 0.304450
 >> iter 60000, loss: 0.259967
   Number of active neurons: 7
 >> iter 61000, loss: 0.252308
 >> iter 62000, loss: 0.283141
 >> iter 63000, loss: 0.389929
 >> iter 64000, loss: 0.374178
 >> iter 65000, loss: 0.422425
 >> iter 66000, loss: 0.308533
 >> iter 67000, loss: 0.336229
 >> iter 68000, loss: 0.365683
 >> iter 69000, loss: 0.258613
 >> iter 70000, loss: 0.237373
   Number of active neurons: 7
 >> iter 71000, loss: 0.281124
 >> iter 72000, loss: 0.309418
 >> iter 73000, loss: 0.303091
 >> iter 74000, loss: 0.401546
 >> iter 75000, loss: 0.403565
 >> iter 76000, loss: 0.308441
 >> iter 77000, loss: 0.254680
 >> iter 78000, loss: 0.242688
 >> iter 79000, loss: 0.291287
 >> iter 80000, loss: 0.296412
   Number of active neurons: 7
 >> iter 81000, loss: 0.267270
 >> iter 82000, loss: 0.375027
 >> iter 83000, loss: 0.370548
 >> iter 84000, loss: 0.275194
 >> iter 85000, loss: 0.319549
 >> iter 86000, loss: 0.371191
 >> iter 87000, loss: 0.339806
 >> iter 88000, loss: 0.280556
 >> iter 89000, loss: 0.396242
 >> iter 90000, loss: 0.238932
   Number of active neurons: 7
 >> iter 91000, loss: 0.181077
 >> iter 92000, loss: 0.222003
 >> iter 93000, loss: 0.146075
 >> iter 94000, loss: 0.259663
 >> iter 95000, loss: 0.332199
 >> iter 96000, loss: 0.247504
 >> iter 97000, loss: 0.256766
 >> iter 98000, loss: 0.204276
 >> iter 99000, loss: 0.278421
 >> iter 100000, loss: 0.325035
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.643776
 >> iter 2000, loss: 9.859969
 >> iter 3000, loss: 6.632259
 >> iter 4000, loss: 4.844458
 >> iter 5000, loss: 3.341535
 >> iter 6000, loss: 2.190166
 >> iter 7000, loss: 1.523408
 >> iter 8000, loss: 1.061206
 >> iter 9000, loss: 0.697400
 >> iter 10000, loss: 0.658925
   Number of active neurons: 8
 >> iter 11000, loss: 0.612610
 >> iter 12000, loss: 0.482388
 >> iter 13000, loss: 0.434594
 >> iter 14000, loss: 0.547453
 >> iter 15000, loss: 0.381005
 >> iter 16000, loss: 0.345738
 >> iter 17000, loss: 0.331962
 >> iter 18000, loss: 0.486415
 >> iter 19000, loss: 0.503848
 >> iter 20000, loss: 0.525943
   Number of active neurons: 8
 >> iter 21000, loss: 0.518054
 >> iter 22000, loss: 0.589431
 >> iter 23000, loss: 0.587112
 >> iter 24000, loss: 0.631414
 >> iter 25000, loss: 0.462235
 >> iter 26000, loss: 0.355463
 >> iter 27000, loss: 0.491101
 >> iter 28000, loss: 0.532402
 >> iter 29000, loss: 0.620903
 >> iter 30000, loss: 0.448703
   Number of active neurons: 6
 >> iter 31000, loss: 0.440417
 >> iter 32000, loss: 0.491212
 >> iter 33000, loss: 0.480778
 >> iter 34000, loss: 0.479131
 >> iter 35000, loss: 0.418377
 >> iter 36000, loss: 0.499454
 >> iter 37000, loss: 0.592820
 >> iter 38000, loss: 0.577134
 >> iter 39000, loss: 0.552020
 >> iter 40000, loss: 0.541826
   Number of active neurons: 6
 >> iter 41000, loss: 0.542992
 >> iter 42000, loss: 0.508566
 >> iter 43000, loss: 0.565765
 >> iter 44000, loss: 0.582927
 >> iter 45000, loss: 0.394866
 >> iter 46000, loss: 0.481804
 >> iter 47000, loss: 0.523362
 >> iter 48000, loss: 0.521733
 >> iter 49000, loss: 0.604520
 >> iter 50000, loss: 0.519556
   Number of active neurons: 6
 >> iter 51000, loss: 0.423006
 >> iter 52000, loss: 0.503198
 >> iter 53000, loss: 0.616658
 >> iter 54000, loss: 0.517065
 >> iter 55000, loss: 0.474831
 >> iter 56000, loss: 0.519708
 >> iter 57000, loss: 0.576300
 >> iter 58000, loss: 0.583964
 >> iter 59000, loss: 0.750978
 >> iter 60000, loss: 0.560554
   Number of active neurons: 6
 >> iter 61000, loss: 0.496961
 >> iter 62000, loss: 0.522821
 >> iter 63000, loss: 0.471690
 >> iter 64000, loss: 0.494500
 >> iter 65000, loss: 0.596962
 >> iter 66000, loss: 0.514725
 >> iter 67000, loss: 0.477901
 >> iter 68000, loss: 0.525938
 >> iter 69000, loss: 0.498555
 >> iter 70000, loss: 0.586741
   Number of active neurons: 6
 >> iter 71000, loss: 0.415488
 >> iter 72000, loss: 0.585405
 >> iter 73000, loss: 0.624142
 >> iter 74000, loss: 0.492901
 >> iter 75000, loss: 0.712526
 >> iter 76000, loss: 0.618547
 >> iter 77000, loss: 0.565335
 >> iter 78000, loss: 0.585438
 >> iter 79000, loss: 0.567703
 >> iter 80000, loss: 0.486278
   Number of active neurons: 5
 >> iter 81000, loss: 0.461250
 >> iter 82000, loss: 0.496363
 >> iter 83000, loss: 0.424510
 >> iter 84000, loss: 0.418758
 >> iter 85000, loss: 0.392889
 >> iter 86000, loss: 0.383279
 >> iter 87000, loss: 0.409493
 >> iter 88000, loss: 0.425975
 >> iter 89000, loss: 0.436360
 >> iter 90000, loss: 0.390944
   Number of active neurons: 5
 >> iter 91000, loss: 0.348388
 >> iter 92000, loss: 0.540439
 >> iter 93000, loss: 0.541433
 >> iter 94000, loss: 0.575134
 >> iter 95000, loss: 0.488645
 >> iter 96000, loss: 0.481948
 >> iter 97000, loss: 0.499936
 >> iter 98000, loss: 0.440912
 >> iter 99000, loss: 0.493736
 >> iter 100000, loss: 0.387696
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.471080
 >> iter 2000, loss: 10.628473
 >> iter 3000, loss: 7.142592
 >> iter 4000, loss: 4.051208
 >> iter 5000, loss: 2.008516
 >> iter 6000, loss: 1.228472
 >> iter 7000, loss: 0.986528
 >> iter 8000, loss: 0.947447
 >> iter 9000, loss: 0.546487
 >> iter 10000, loss: 0.369338
   Number of active neurons: 11
 >> iter 11000, loss: 0.516373
 >> iter 12000, loss: 0.539834
 >> iter 13000, loss: 0.315586
 >> iter 14000, loss: 0.416378
 >> iter 15000, loss: 0.387743
 >> iter 16000, loss: 0.344312
 >> iter 17000, loss: 0.485693
 >> iter 18000, loss: 0.322369
 >> iter 19000, loss: 0.436867
 >> iter 20000, loss: 0.426538
   Number of active neurons: 10
 >> iter 21000, loss: 0.523554
 >> iter 22000, loss: 0.517392
 >> iter 23000, loss: 0.422348
 >> iter 24000, loss: 0.511238
 >> iter 25000, loss: 0.351102
 >> iter 26000, loss: 0.497601
 >> iter 27000, loss: 0.401748
 >> iter 28000, loss: 0.370826
 >> iter 29000, loss: 0.328977
 >> iter 30000, loss: 0.372276
   Number of active neurons: 9
 >> iter 31000, loss: 0.750952
 >> iter 32000, loss: 0.523404
 >> iter 33000, loss: 0.366240
 >> iter 34000, loss: 0.364726
 >> iter 35000, loss: 0.373025
 >> iter 36000, loss: 0.347309
 >> iter 37000, loss: 0.369205
 >> iter 38000, loss: 0.331574
 >> iter 39000, loss: 0.383816
 >> iter 40000, loss: 0.416358
   Number of active neurons: 9
 >> iter 41000, loss: 0.324187
 >> iter 42000, loss: 0.327916
 >> iter 43000, loss: 0.559580
 >> iter 44000, loss: 0.501784
 >> iter 45000, loss: 0.523795
 >> iter 46000, loss: 0.446655
 >> iter 47000, loss: 0.451084
 >> iter 48000, loss: 0.330428
 >> iter 49000, loss: 0.314629
 >> iter 50000, loss: 0.473355
   Number of active neurons: 8
 >> iter 51000, loss: 0.523949
 >> iter 52000, loss: 0.380892
 >> iter 53000, loss: 0.450926
 >> iter 54000, loss: 0.334046
 >> iter 55000, loss: 0.300063
 >> iter 56000, loss: 0.330045
 >> iter 57000, loss: 0.522750
 >> iter 58000, loss: 0.364488
 >> iter 59000, loss: 0.472727
 >> iter 60000, loss: 0.409323
   Number of active neurons: 8
 >> iter 61000, loss: 0.368341
 >> iter 62000, loss: 0.463061
 >> iter 63000, loss: 0.390775
 >> iter 64000, loss: 0.586737
 >> iter 65000, loss: 0.570349
 >> iter 66000, loss: 0.355456
 >> iter 67000, loss: 0.340703
 >> iter 68000, loss: 0.263704
 >> iter 69000, loss: 0.259844
 >> iter 70000, loss: 0.186336
   Number of active neurons: 8
 >> iter 71000, loss: 0.331346
 >> iter 72000, loss: 0.263809
 >> iter 73000, loss: 0.280035
 >> iter 74000, loss: 0.482218
 >> iter 75000, loss: 0.376621
 >> iter 76000, loss: 0.292290
 >> iter 77000, loss: 0.434522
 >> iter 78000, loss: 0.340400
 >> iter 79000, loss: 0.360480
 >> iter 80000, loss: 0.336300
   Number of active neurons: 8
 >> iter 81000, loss: 0.479201
 >> iter 82000, loss: 0.357200
 >> iter 83000, loss: 0.281709
 >> iter 84000, loss: 0.386218
 >> iter 85000, loss: 0.316047
 >> iter 86000, loss: 0.251007
 >> iter 87000, loss: 0.348820
 >> iter 88000, loss: 0.272570
 >> iter 89000, loss: 0.220636
 >> iter 90000, loss: 0.288268
   Number of active neurons: 8
 >> iter 91000, loss: 0.385829
 >> iter 92000, loss: 0.278559
 >> iter 93000, loss: 0.300808
 >> iter 94000, loss: 0.267910
 >> iter 95000, loss: 0.420403
 >> iter 96000, loss: 0.338374
 >> iter 97000, loss: 0.301239
 >> iter 98000, loss: 0.311509
 >> iter 99000, loss: 0.226030
 >> iter 100000, loss: 0.250043
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.345384
 >> iter 2000, loss: 9.418876
 >> iter 3000, loss: 5.170847
 >> iter 4000, loss: 2.307627
 >> iter 5000, loss: 1.156671
 >> iter 6000, loss: 0.670397
 >> iter 7000, loss: 0.439905
 >> iter 8000, loss: 0.391981
 >> iter 9000, loss: 0.285075
 >> iter 10000, loss: 0.250697
   Number of active neurons: 10
 >> iter 11000, loss: 0.280663
 >> iter 12000, loss: 0.322442
 >> iter 13000, loss: 0.281226
 >> iter 14000, loss: 0.199577
 >> iter 15000, loss: 0.310711
 >> iter 16000, loss: 0.267208
 >> iter 17000, loss: 0.283905
 >> iter 18000, loss: 0.296665
 >> iter 19000, loss: 0.329757
 >> iter 20000, loss: 0.218109
   Number of active neurons: 9
 >> iter 21000, loss: 0.376240
 >> iter 22000, loss: 0.258797
 >> iter 23000, loss: 0.341518
 >> iter 24000, loss: 0.340187
 >> iter 25000, loss: 0.269397
 >> iter 26000, loss: 0.375586
 >> iter 27000, loss: 0.308171
 >> iter 28000, loss: 0.281887
 >> iter 29000, loss: 0.272575
 >> iter 30000, loss: 0.258849
   Number of active neurons: 9
 >> iter 31000, loss: 0.279391
 >> iter 32000, loss: 0.220375
 >> iter 33000, loss: 0.279369
 >> iter 34000, loss: 0.273966
 >> iter 35000, loss: 0.285932
 >> iter 36000, loss: 0.334622
 >> iter 37000, loss: 0.312190
 >> iter 38000, loss: 0.300636
 >> iter 39000, loss: 0.378350
 >> iter 40000, loss: 0.413899
   Number of active neurons: 9
 >> iter 41000, loss: 0.339154
 >> iter 42000, loss: 0.328938
 >> iter 43000, loss: 0.292840
 >> iter 44000, loss: 0.345598
 >> iter 45000, loss: 0.316688
 >> iter 46000, loss: 0.340769
 >> iter 47000, loss: 0.279954
 >> iter 48000, loss: 0.238785
 >> iter 49000, loss: 0.230018
 >> iter 50000, loss: 0.297548
   Number of active neurons: 9
 >> iter 51000, loss: 0.305738
 >> iter 52000, loss: 0.350690
 >> iter 53000, loss: 0.255652
 >> iter 54000, loss: 0.364301
 >> iter 55000, loss: 0.279273
 >> iter 56000, loss: 0.273231
 >> iter 57000, loss: 0.219290
 >> iter 58000, loss: 0.224850
 >> iter 59000, loss: 0.243738
 >> iter 60000, loss: 0.247349
   Number of active neurons: 8
 >> iter 61000, loss: 0.240365
 >> iter 62000, loss: 0.320999
 >> iter 63000, loss: 0.281166
 >> iter 64000, loss: 0.270791
 >> iter 65000, loss: 0.194002
 >> iter 66000, loss: 0.175665
 >> iter 67000, loss: 0.267004
 >> iter 68000, loss: 0.226881
 >> iter 69000, loss: 0.229164
 >> iter 70000, loss: 0.159372
   Number of active neurons: 8
 >> iter 71000, loss: 0.317788
 >> iter 72000, loss: 0.371125
 >> iter 73000, loss: 0.279077
 >> iter 74000, loss: 0.206595
 >> iter 75000, loss: 0.202360
 >> iter 76000, loss: 0.183960
 >> iter 77000, loss: 0.149614
 >> iter 78000, loss: 0.285693
 >> iter 79000, loss: 0.180766
 >> iter 80000, loss: 0.219233
   Number of active neurons: 8
 >> iter 81000, loss: 0.280955
 >> iter 82000, loss: 0.187571
 >> iter 83000, loss: 0.285045
 >> iter 84000, loss: 0.253155
 >> iter 85000, loss: 0.262866
 >> iter 86000, loss: 0.294186
 >> iter 87000, loss: 0.160553
 >> iter 88000, loss: 0.264834
 >> iter 89000, loss: 0.195204
 >> iter 90000, loss: 0.162230
   Number of active neurons: 8
 >> iter 91000, loss: 0.186509
 >> iter 92000, loss: 0.165942
 >> iter 93000, loss: 0.159773
 >> iter 94000, loss: 0.176403
 >> iter 95000, loss: 0.166394
 >> iter 96000, loss: 0.396985
 >> iter 97000, loss: 0.305021
 >> iter 98000, loss: 0.182573
 >> iter 99000, loss: 0.179423
 >> iter 100000, loss: 0.203710
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 16.749152
 >> iter 2000, loss: 9.846033
 >> iter 3000, loss: 5.818024
 >> iter 4000, loss: 2.744327
 >> iter 5000, loss: 1.378973
 >> iter 6000, loss: 0.757062
 >> iter 7000, loss: 0.535735
 >> iter 8000, loss: 0.462924
 >> iter 9000, loss: 0.425740
 >> iter 10000, loss: 0.328550
   Number of active neurons: 8
 >> iter 11000, loss: 0.357258
 >> iter 12000, loss: 0.315419
 >> iter 13000, loss: 0.224804
 >> iter 14000, loss: 0.259245
 >> iter 15000, loss: 0.309549
 >> iter 16000, loss: 0.319826
 >> iter 17000, loss: 0.287997
 >> iter 18000, loss: 0.245189
 >> iter 19000, loss: 0.358779
 >> iter 20000, loss: 0.375806
   Number of active neurons: 8
 >> iter 21000, loss: 0.266124
 >> iter 22000, loss: 0.218909
 >> iter 23000, loss: 0.285600
 >> iter 24000, loss: 0.233440
 >> iter 25000, loss: 0.254327
 >> iter 26000, loss: 0.238622
 >> iter 27000, loss: 0.223977
 >> iter 28000, loss: 0.294042
 >> iter 29000, loss: 0.306394
 >> iter 30000, loss: 0.419759
   Number of active neurons: 8
 >> iter 31000, loss: 0.288296
 >> iter 32000, loss: 0.325761
 >> iter 33000, loss: 0.266126
 >> iter 34000, loss: 0.209743
 >> iter 35000, loss: 0.251121
 >> iter 36000, loss: 0.258013
 >> iter 37000, loss: 0.212824
 >> iter 38000, loss: 0.236141
 >> iter 39000, loss: 0.220169
 >> iter 40000, loss: 0.303513
   Number of active neurons: 7
 >> iter 41000, loss: 0.241481
 >> iter 42000, loss: 0.230943
 >> iter 43000, loss: 0.223360
 >> iter 44000, loss: 0.336920
 >> iter 45000, loss: 0.306538
 >> iter 46000, loss: 0.276628
 >> iter 47000, loss: 0.198051
 >> iter 48000, loss: 0.180854
 >> iter 49000, loss: 0.228893
 >> iter 50000, loss: 0.206693
   Number of active neurons: 7
 >> iter 51000, loss: 0.278698
 >> iter 52000, loss: 0.173335
 >> iter 53000, loss: 0.220124
 >> iter 54000, loss: 0.263170
 >> iter 55000, loss: 0.263608
 >> iter 56000, loss: 0.225158
 >> iter 57000, loss: 0.173817
 >> iter 58000, loss: 0.189519
 >> iter 59000, loss: 0.344332
 >> iter 60000, loss: 0.461855
   Number of active neurons: 7
 >> iter 61000, loss: 0.343459
 >> iter 62000, loss: 0.380973
 >> iter 63000, loss: 0.299598
 >> iter 64000, loss: 0.307052
 >> iter 65000, loss: 0.341203
 >> iter 66000, loss: 0.207514
 >> iter 67000, loss: 0.211188
 >> iter 68000, loss: 0.197798
 >> iter 69000, loss: 0.191282
 >> iter 70000, loss: 0.252651
   Number of active neurons: 7
 >> iter 71000, loss: 0.226594
 >> iter 72000, loss: 0.257253
 >> iter 73000, loss: 0.169186
 >> iter 74000, loss: 0.168527
 >> iter 75000, loss: 0.329781
 >> iter 76000, loss: 0.272729
 >> iter 77000, loss: 0.297416
 >> iter 78000, loss: 0.359518
 >> iter 79000, loss: 0.247298
 >> iter 80000, loss: 0.194600
   Number of active neurons: 6
 >> iter 81000, loss: 0.334528
 >> iter 82000, loss: 0.235182
 >> iter 83000, loss: 0.143871
 >> iter 84000, loss: 0.188050
 >> iter 85000, loss: 0.241437
 >> iter 86000, loss: 0.230440
 >> iter 87000, loss: 0.279503
 >> iter 88000, loss: 0.221914
 >> iter 89000, loss: 0.269632
 >> iter 90000, loss: 0.224291
   Number of active neurons: 6
 >> iter 91000, loss: 0.187672
 >> iter 92000, loss: 0.202408
 >> iter 93000, loss: 0.225414
 >> iter 94000, loss: 0.248384
 >> iter 95000, loss: 0.305218
 >> iter 96000, loss: 0.254419
 >> iter 97000, loss: 0.288343
 >> iter 98000, loss: 0.187632
 >> iter 99000, loss: 0.271600
 >> iter 100000, loss: 0.263228
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 16.908367
 >> iter 2000, loss: 9.823658
 >> iter 3000, loss: 4.865715
 >> iter 4000, loss: 2.177178
 >> iter 5000, loss: 1.007824
 >> iter 6000, loss: 0.488425
 >> iter 7000, loss: 0.412350
 >> iter 8000, loss: 0.340686
 >> iter 9000, loss: 0.194902
 >> iter 10000, loss: 0.312236
   Number of active neurons: 10
 >> iter 11000, loss: 0.253553
 >> iter 12000, loss: 0.219877
 >> iter 13000, loss: 0.263730
 >> iter 14000, loss: 0.261630
 >> iter 15000, loss: 0.273124
 >> iter 16000, loss: 0.250154
 >> iter 17000, loss: 0.238213
 >> iter 18000, loss: 0.231126
 >> iter 19000, loss: 0.275979
 >> iter 20000, loss: 0.214909
   Number of active neurons: 10
 >> iter 21000, loss: 0.230886
 >> iter 22000, loss: 0.211581
 >> iter 23000, loss: 0.268623
 >> iter 24000, loss: 0.207958
 >> iter 25000, loss: 0.199122
 >> iter 26000, loss: 0.323971
 >> iter 27000, loss: 0.292924
 >> iter 28000, loss: 0.268482
 >> iter 29000, loss: 0.240915
 >> iter 30000, loss: 0.230566
   Number of active neurons: 10
 >> iter 31000, loss: 0.222857
 >> iter 32000, loss: 0.235773
 >> iter 33000, loss: 0.192168
 >> iter 34000, loss: 0.212245
 >> iter 35000, loss: 0.197151
 >> iter 36000, loss: 0.325055
 >> iter 37000, loss: 0.263112
 >> iter 38000, loss: 0.300734
 >> iter 39000, loss: 0.223701
 >> iter 40000, loss: 0.207790
   Number of active neurons: 10
 >> iter 41000, loss: 0.352361
 >> iter 42000, loss: 0.257003
 >> iter 43000, loss: 0.283581
 >> iter 44000, loss: 0.243641
 >> iter 45000, loss: 0.330296
 >> iter 46000, loss: 0.320714
 >> iter 47000, loss: 0.246018
 >> iter 48000, loss: 0.293992
 >> iter 49000, loss: 0.291194
 >> iter 50000, loss: 0.237585
   Number of active neurons: 10
 >> iter 51000, loss: 0.261679
 >> iter 52000, loss: 0.313061
 >> iter 53000, loss: 0.202426
 >> iter 54000, loss: 0.212616
 >> iter 55000, loss: 0.284931
 >> iter 56000, loss: 0.382935
 >> iter 57000, loss: 0.352771
 >> iter 58000, loss: 0.326438
 >> iter 59000, loss: 0.461742
 >> iter 60000, loss: 0.342206
   Number of active neurons: 10
 >> iter 61000, loss: 0.256425
 >> iter 62000, loss: 0.333618
 >> iter 63000, loss: 0.413895
 >> iter 64000, loss: 0.303764
 >> iter 65000, loss: 0.264717
 >> iter 66000, loss: 0.344193
 >> iter 67000, loss: 0.310525
 >> iter 68000, loss: 0.259939
 >> iter 69000, loss: 0.301252
 >> iter 70000, loss: 0.311634
   Number of active neurons: 9
 >> iter 71000, loss: 0.454313
 >> iter 72000, loss: 0.388459
 >> iter 73000, loss: 0.283806
 >> iter 74000, loss: 0.282891
 >> iter 75000, loss: 0.219686
 >> iter 76000, loss: 0.191830
 >> iter 77000, loss: 0.250959
 >> iter 78000, loss: 0.208717
 >> iter 79000, loss: 0.287390
 >> iter 80000, loss: 0.259937
   Number of active neurons: 9
 >> iter 81000, loss: 0.234021
 >> iter 82000, loss: 0.263484
 >> iter 83000, loss: 0.292793
 >> iter 84000, loss: 0.227556
 >> iter 85000, loss: 0.247508
 >> iter 86000, loss: 0.221816
 >> iter 87000, loss: 0.188343
 >> iter 88000, loss: 0.228388
 >> iter 89000, loss: 0.196034
 >> iter 90000, loss: 0.178129
   Number of active neurons: 9
 >> iter 91000, loss: 0.190741
 >> iter 92000, loss: 0.382933
 >> iter 93000, loss: 0.296995
 >> iter 94000, loss: 0.433152
 >> iter 95000, loss: 0.407113
 >> iter 96000, loss: 0.250970
 >> iter 97000, loss: 0.266144
 >> iter 98000, loss: 0.245493
 >> iter 99000, loss: 0.278796
 >> iter 100000, loss: 0.233905
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 16.598215
 >> iter 2000, loss: 9.758357
 >> iter 3000, loss: 5.207272
 >> iter 4000, loss: 2.274598
 >> iter 5000, loss: 1.143332
 >> iter 6000, loss: 0.609249
 >> iter 7000, loss: 0.375988
 >> iter 8000, loss: 0.272282
 >> iter 9000, loss: 0.317176
 >> iter 10000, loss: 0.415638
   Number of active neurons: 12
 >> iter 11000, loss: 0.275121
 >> iter 12000, loss: 0.275435
 >> iter 13000, loss: 0.392916
 >> iter 14000, loss: 0.353497
 >> iter 15000, loss: 0.315066
 >> iter 16000, loss: 0.360636
 >> iter 17000, loss: 0.226223
 >> iter 18000, loss: 0.316214
 >> iter 19000, loss: 0.306499
 >> iter 20000, loss: 0.440226
   Number of active neurons: 11
 >> iter 21000, loss: 0.308898
 >> iter 22000, loss: 0.336915
 >> iter 23000, loss: 0.355009
 >> iter 24000, loss: 0.295137
 >> iter 25000, loss: 0.425360
 >> iter 26000, loss: 0.384130
 >> iter 27000, loss: 0.392973
 >> iter 28000, loss: 0.298538
 >> iter 29000, loss: 0.315554
 >> iter 30000, loss: 0.272857
   Number of active neurons: 10
 >> iter 31000, loss: 0.450995
 >> iter 32000, loss: 0.330491
 >> iter 33000, loss: 0.349918
 >> iter 34000, loss: 0.261672
 >> iter 35000, loss: 0.268561
 >> iter 36000, loss: 0.290321
 >> iter 37000, loss: 0.311993
 >> iter 38000, loss: 0.233992
 >> iter 39000, loss: 0.233653
 >> iter 40000, loss: 0.263296
   Number of active neurons: 10
 >> iter 41000, loss: 0.260020
 >> iter 42000, loss: 0.257706
 >> iter 43000, loss: 0.161439
 >> iter 44000, loss: 0.186062
 >> iter 45000, loss: 0.283962
 >> iter 46000, loss: 0.280552
 >> iter 47000, loss: 0.305838
 >> iter 48000, loss: 0.306937
 >> iter 49000, loss: 0.240501
 >> iter 50000, loss: 0.296167
   Number of active neurons: 9
 >> iter 51000, loss: 0.440451
 >> iter 52000, loss: 0.292829
 >> iter 53000, loss: 0.203973
 >> iter 54000, loss: 0.148395
 >> iter 55000, loss: 0.203791
 >> iter 56000, loss: 0.220081
 >> iter 57000, loss: 0.288373
 >> iter 58000, loss: 0.327258
 >> iter 59000, loss: 0.282150
 >> iter 60000, loss: 0.378745
   Number of active neurons: 9
 >> iter 61000, loss: 0.346188
 >> iter 62000, loss: 0.323694
 >> iter 63000, loss: 0.290069
 >> iter 64000, loss: 0.235066
 >> iter 65000, loss: 0.325673
 >> iter 66000, loss: 0.261844
 >> iter 67000, loss: 0.348896
 >> iter 68000, loss: 0.347850
 >> iter 69000, loss: 0.289473
 >> iter 70000, loss: 0.239327
   Number of active neurons: 8
 >> iter 71000, loss: 0.190194
 >> iter 72000, loss: 0.145302
 >> iter 73000, loss: 0.235604
 >> iter 74000, loss: 0.236953
 >> iter 75000, loss: 0.148416
 >> iter 76000, loss: 0.311605
 >> iter 77000, loss: 0.320311
 >> iter 78000, loss: 0.280221
 >> iter 79000, loss: 0.303851
 >> iter 80000, loss: 0.306322
   Number of active neurons: 8
 >> iter 81000, loss: 0.222505
 >> iter 82000, loss: 0.202437
 >> iter 83000, loss: 0.286441
 >> iter 84000, loss: 0.216859
 >> iter 85000, loss: 0.179134
 >> iter 86000, loss: 0.190490
 >> iter 87000, loss: 0.264547
 >> iter 88000, loss: 0.249622
 >> iter 89000, loss: 0.307726
 >> iter 90000, loss: 0.326341
   Number of active neurons: 8
 >> iter 91000, loss: 0.322602
 >> iter 92000, loss: 0.280282
 >> iter 93000, loss: 0.225288
 >> iter 94000, loss: 0.182835
 >> iter 95000, loss: 0.237441
 >> iter 96000, loss: 0.215149
 >> iter 97000, loss: 0.257244
 >> iter 98000, loss: 0.345028
 >> iter 99000, loss: 0.277612
 >> iter 100000, loss: 0.366995
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.553849
 >> iter 2000, loss: 9.900001
 >> iter 3000, loss: 5.732511
 >> iter 4000, loss: 3.061384
 >> iter 5000, loss: 2.034367
 >> iter 6000, loss: 1.067422
 >> iter 7000, loss: 0.803654
 >> iter 8000, loss: 0.695746
 >> iter 9000, loss: 0.523465
 >> iter 10000, loss: 0.331054
   Number of active neurons: 9
 >> iter 11000, loss: 0.459666
 >> iter 12000, loss: 0.296291
 >> iter 13000, loss: 0.291316
 >> iter 14000, loss: 0.437089
 >> iter 15000, loss: 0.390023
 >> iter 16000, loss: 0.350548
 >> iter 17000, loss: 0.341606
 >> iter 18000, loss: 0.282005
 >> iter 19000, loss: 0.250613
 >> iter 20000, loss: 0.228761
   Number of active neurons: 9
 >> iter 21000, loss: 0.226568
 >> iter 22000, loss: 0.247030
 >> iter 23000, loss: 0.374844
 >> iter 24000, loss: 0.230850
 >> iter 25000, loss: 0.182829
 >> iter 26000, loss: 0.196588
 >> iter 27000, loss: 0.337457
 >> iter 28000, loss: 0.307557
 >> iter 29000, loss: 0.222156
 >> iter 30000, loss: 0.231037
   Number of active neurons: 9
 >> iter 31000, loss: 0.216216
 >> iter 32000, loss: 0.353593
 >> iter 33000, loss: 0.386390
 >> iter 34000, loss: 0.293393
 >> iter 35000, loss: 0.207867
 >> iter 36000, loss: 0.398576
 >> iter 37000, loss: 0.343622
 >> iter 38000, loss: 0.374574
 >> iter 39000, loss: 0.329108
 >> iter 40000, loss: 0.359955
   Number of active neurons: 9
 >> iter 41000, loss: 0.349267
 >> iter 42000, loss: 0.355000
 >> iter 43000, loss: 0.340124
 >> iter 44000, loss: 0.311528
 >> iter 45000, loss: 0.382445
 >> iter 46000, loss: 0.384094
 >> iter 47000, loss: 0.302678
 >> iter 48000, loss: 0.370080
 >> iter 49000, loss: 0.282519
 >> iter 50000, loss: 0.325696
   Number of active neurons: 9
 >> iter 51000, loss: 0.425302
 >> iter 52000, loss: 0.442858
 >> iter 53000, loss: 0.322496
 >> iter 54000, loss: 0.364015
 >> iter 55000, loss: 0.414765
 >> iter 56000, loss: 0.343431
 >> iter 57000, loss: 0.230964
 >> iter 58000, loss: 0.411225
 >> iter 59000, loss: 0.277844
 >> iter 60000, loss: 0.284172
   Number of active neurons: 9
 >> iter 61000, loss: 0.249052
 >> iter 62000, loss: 0.278109
 >> iter 63000, loss: 0.267276
 >> iter 64000, loss: 0.327148
 >> iter 65000, loss: 0.322425
 >> iter 66000, loss: 0.309954
 >> iter 67000, loss: 0.282137
 >> iter 68000, loss: 0.302662
 >> iter 69000, loss: 0.391832
 >> iter 70000, loss: 0.267782
   Number of active neurons: 8
 >> iter 71000, loss: 0.258934
 >> iter 72000, loss: 0.400360
 >> iter 73000, loss: 0.382988
 >> iter 74000, loss: 0.332386
 >> iter 75000, loss: 0.286558
 >> iter 76000, loss: 0.259740
 >> iter 77000, loss: 0.357920
 >> iter 78000, loss: 0.253019
 >> iter 79000, loss: 0.297646
 >> iter 80000, loss: 0.379047
   Number of active neurons: 8
 >> iter 81000, loss: 0.310890
 >> iter 82000, loss: 0.300298
 >> iter 83000, loss: 0.268046
 >> iter 84000, loss: 0.313850
 >> iter 85000, loss: 0.259999
 >> iter 86000, loss: 0.407854
 >> iter 87000, loss: 0.377814
 >> iter 88000, loss: 0.301858
 >> iter 89000, loss: 0.287058
 >> iter 90000, loss: 0.367173
   Number of active neurons: 8
 >> iter 91000, loss: 0.336604
 >> iter 92000, loss: 0.306734
 >> iter 93000, loss: 0.268170
 >> iter 94000, loss: 0.289866
 >> iter 95000, loss: 0.260676
 >> iter 96000, loss: 0.275623
 >> iter 97000, loss: 0.201692
 >> iter 98000, loss: 0.281826
 >> iter 99000, loss: 0.257782
 >> iter 100000, loss: 0.323756
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.585080
 >> iter 2000, loss: 9.798508
 >> iter 3000, loss: 6.681528
 >> iter 4000, loss: 3.889575
 >> iter 5000, loss: 2.163522
 >> iter 6000, loss: 1.271978
 >> iter 7000, loss: 0.738709
 >> iter 8000, loss: 0.640894
 >> iter 9000, loss: 0.424920
 >> iter 10000, loss: 0.434334
   Number of active neurons: 10
 >> iter 11000, loss: 0.322984
 >> iter 12000, loss: 0.220612
 >> iter 13000, loss: 0.263233
 >> iter 14000, loss: 0.430767
 >> iter 15000, loss: 0.362491
 >> iter 16000, loss: 0.419649
 >> iter 17000, loss: 0.394295
 >> iter 18000, loss: 0.429982
 >> iter 19000, loss: 0.393394
 >> iter 20000, loss: 0.316165
   Number of active neurons: 10
 >> iter 21000, loss: 0.336309
 >> iter 22000, loss: 0.271691
 >> iter 23000, loss: 0.402708
 >> iter 24000, loss: 0.374577
 >> iter 25000, loss: 0.474817
 >> iter 26000, loss: 0.269670
 >> iter 27000, loss: 0.344909
 >> iter 28000, loss: 0.335857
 >> iter 29000, loss: 0.268735
 >> iter 30000, loss: 0.332237
   Number of active neurons: 7
 >> iter 31000, loss: 0.323737
 >> iter 32000, loss: 0.345112
 >> iter 33000, loss: 0.295361
 >> iter 34000, loss: 0.210828
 >> iter 35000, loss: 0.180485
 >> iter 36000, loss: 0.241904
 >> iter 37000, loss: 0.185589
 >> iter 38000, loss: 0.287204
 >> iter 39000, loss: 0.292932
 >> iter 40000, loss: 0.243706
   Number of active neurons: 6
 >> iter 41000, loss: 0.278991
 >> iter 42000, loss: 0.256729
 >> iter 43000, loss: 0.382221
 >> iter 44000, loss: 0.267671
 >> iter 45000, loss: 0.333347
 >> iter 46000, loss: 0.356998
 >> iter 47000, loss: 0.324381
 >> iter 48000, loss: 0.239324
 >> iter 49000, loss: 0.342466
 >> iter 50000, loss: 0.310265
   Number of active neurons: 5
 >> iter 51000, loss: 0.326971
 >> iter 52000, loss: 0.274972
 >> iter 53000, loss: 0.366949
 >> iter 54000, loss: 0.367198
 >> iter 55000, loss: 0.536498
 >> iter 56000, loss: 0.476539
 >> iter 57000, loss: 0.383273
 >> iter 58000, loss: 0.439961
 >> iter 59000, loss: 0.556477
 >> iter 60000, loss: 0.411474
   Number of active neurons: 5
 >> iter 61000, loss: 0.372962
 >> iter 62000, loss: 0.397918
 >> iter 63000, loss: 0.382554
 >> iter 64000, loss: 0.365579
 >> iter 65000, loss: 0.390708
 >> iter 66000, loss: 0.426266
 >> iter 67000, loss: 0.261023
 >> iter 68000, loss: 0.263382
 >> iter 69000, loss: 0.432168
 >> iter 70000, loss: 0.388803
   Number of active neurons: 5
 >> iter 71000, loss: 0.358621
 >> iter 72000, loss: 0.347186
 >> iter 73000, loss: 0.333135
 >> iter 74000, loss: 0.460643
 >> iter 75000, loss: 0.576257
 >> iter 76000, loss: 0.516662
 >> iter 77000, loss: 0.525374
 >> iter 78000, loss: 0.483621
 >> iter 79000, loss: 0.537417
 >> iter 80000, loss: 0.413858
   Number of active neurons: 5
 >> iter 81000, loss: 0.507888
 >> iter 82000, loss: 0.499217
 >> iter 83000, loss: 0.439814
 >> iter 84000, loss: 0.469333
 >> iter 85000, loss: 0.346522
 >> iter 86000, loss: 0.506754
 >> iter 87000, loss: 0.584596
 >> iter 88000, loss: 0.441248
 >> iter 89000, loss: 0.357389
 >> iter 90000, loss: 0.453613
   Number of active neurons: 5
 >> iter 91000, loss: 0.414635
 >> iter 92000, loss: 0.321128
 >> iter 93000, loss: 0.306531
 >> iter 94000, loss: 0.383608
 >> iter 95000, loss: 0.312333
 >> iter 96000, loss: 0.305335
 >> iter 97000, loss: 0.342711
 >> iter 98000, loss: 0.325427
 >> iter 99000, loss: 0.361234
 >> iter 100000, loss: 0.313612
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.637839
 >> iter 2000, loss: 9.957819
 >> iter 3000, loss: 5.932456
 >> iter 4000, loss: 2.661337
 >> iter 5000, loss: 1.272847
 >> iter 6000, loss: 0.617002
 >> iter 7000, loss: 0.352357
 >> iter 8000, loss: 0.310715
 >> iter 9000, loss: 0.297668
 >> iter 10000, loss: 0.371412
   Number of active neurons: 11
 >> iter 11000, loss: 0.413788
 >> iter 12000, loss: 0.363887
 >> iter 13000, loss: 0.280428
 >> iter 14000, loss: 0.386416
 >> iter 15000, loss: 0.235850
 >> iter 16000, loss: 0.153794
 >> iter 17000, loss: 0.184494
 >> iter 18000, loss: 0.213381
 >> iter 19000, loss: 0.376218
 >> iter 20000, loss: 0.276713
   Number of active neurons: 10
 >> iter 21000, loss: 0.275731
 >> iter 22000, loss: 0.318996
 >> iter 23000, loss: 0.340717
 >> iter 24000, loss: 0.238590
 >> iter 25000, loss: 0.430312
 >> iter 26000, loss: 0.343987
 >> iter 27000, loss: 0.236867
 >> iter 28000, loss: 0.313394
 >> iter 29000, loss: 0.347667
 >> iter 30000, loss: 0.328774
   Number of active neurons: 10
 >> iter 31000, loss: 0.410959
 >> iter 32000, loss: 0.378700
 >> iter 33000, loss: 0.354064
 >> iter 34000, loss: 0.269992
 >> iter 35000, loss: 0.308165
 >> iter 36000, loss: 0.422895
 >> iter 37000, loss: 0.260289
 >> iter 38000, loss: 0.229520
 >> iter 39000, loss: 0.209386
 >> iter 40000, loss: 0.372018
   Number of active neurons: 10
 >> iter 41000, loss: 0.333887
 >> iter 42000, loss: 0.310661
 >> iter 43000, loss: 0.253892
 >> iter 44000, loss: 0.284761
 >> iter 45000, loss: 0.240124
 >> iter 46000, loss: 0.198919
 >> iter 47000, loss: 0.303010
 >> iter 48000, loss: 0.250820
 >> iter 49000, loss: 0.361503
 >> iter 50000, loss: 0.287240
   Number of active neurons: 10
 >> iter 51000, loss: 0.536289
 >> iter 52000, loss: 0.332671
 >> iter 53000, loss: 0.359243
 >> iter 54000, loss: 0.383468
 >> iter 55000, loss: 0.298425
 >> iter 56000, loss: 0.281866
 >> iter 57000, loss: 0.421869
 >> iter 58000, loss: 0.243545
 >> iter 59000, loss: 0.350686
 >> iter 60000, loss: 0.371221
   Number of active neurons: 9
 >> iter 61000, loss: 0.350046
 >> iter 62000, loss: 0.284109
 >> iter 63000, loss: 0.362271
 >> iter 64000, loss: 0.327048
 >> iter 65000, loss: 0.242508
 >> iter 66000, loss: 0.244557
 >> iter 67000, loss: 0.227541
 >> iter 68000, loss: 0.185399
 >> iter 69000, loss: 0.193886
 >> iter 70000, loss: 0.339047
   Number of active neurons: 9
 >> iter 71000, loss: 0.348954
 >> iter 72000, loss: 0.343123
 >> iter 73000, loss: 0.336896
 >> iter 74000, loss: 0.302930
 >> iter 75000, loss: 0.422153
 >> iter 76000, loss: 0.259215
 >> iter 77000, loss: 0.249307
 >> iter 78000, loss: 0.411305
 >> iter 79000, loss: 0.274641
 >> iter 80000, loss: 0.209178
   Number of active neurons: 9
 >> iter 81000, loss: 0.256422
 >> iter 82000, loss: 0.242704
 >> iter 83000, loss: 0.186523
 >> iter 84000, loss: 0.221540
 >> iter 85000, loss: 0.373206
 >> iter 86000, loss: 0.310564
 >> iter 87000, loss: 0.329602
 >> iter 88000, loss: 0.223627
 >> iter 89000, loss: 0.168590
 >> iter 90000, loss: 0.173521
   Number of active neurons: 8
 >> iter 91000, loss: 0.297725
 >> iter 92000, loss: 0.240941
 >> iter 93000, loss: 0.442909
 >> iter 94000, loss: 0.308048
 >> iter 95000, loss: 0.281906
 >> iter 96000, loss: 0.269120
 >> iter 97000, loss: 0.202802
 >> iter 98000, loss: 0.217122
 >> iter 99000, loss: 0.299117
 >> iter 100000, loss: 0.374526
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.410325
 >> iter 2000, loss: 10.377452
 >> iter 3000, loss: 5.553282
 >> iter 4000, loss: 2.786481
 >> iter 5000, loss: 1.339229
 >> iter 6000, loss: 0.871525
 >> iter 7000, loss: 0.532086
 >> iter 8000, loss: 0.358763
 >> iter 9000, loss: 0.419900
 >> iter 10000, loss: 0.471588
   Number of active neurons: 9
 >> iter 11000, loss: 0.428677
 >> iter 12000, loss: 0.355531
 >> iter 13000, loss: 0.282363
 >> iter 14000, loss: 0.308233
 >> iter 15000, loss: 0.447287
 >> iter 16000, loss: 0.428625
 >> iter 17000, loss: 0.421182
 >> iter 18000, loss: 0.402190
 >> iter 19000, loss: 0.398065
 >> iter 20000, loss: 0.331580
   Number of active neurons: 9
 >> iter 21000, loss: 0.402815
 >> iter 22000, loss: 0.284555
 >> iter 23000, loss: 0.261357
 >> iter 24000, loss: 0.346941
 >> iter 25000, loss: 0.335669
 >> iter 26000, loss: 0.405241
 >> iter 27000, loss: 0.420196
 >> iter 28000, loss: 0.352002
 >> iter 29000, loss: 0.372330
 >> iter 30000, loss: 0.323282
   Number of active neurons: 9
 >> iter 31000, loss: 0.340133
 >> iter 32000, loss: 0.289087
 >> iter 33000, loss: 0.328029
 >> iter 34000, loss: 0.259124
 >> iter 35000, loss: 0.353861
 >> iter 36000, loss: 0.300568
 >> iter 37000, loss: 0.430152
 >> iter 38000, loss: 0.355636
 >> iter 39000, loss: 0.317000
 >> iter 40000, loss: 0.369048
   Number of active neurons: 9
 >> iter 41000, loss: 0.426223
 >> iter 42000, loss: 0.298979
 >> iter 43000, loss: 0.470922
 >> iter 44000, loss: 0.341668
 >> iter 45000, loss: 0.330959
 >> iter 46000, loss: 0.372178
 >> iter 47000, loss: 0.318073
 >> iter 48000, loss: 0.410579
 >> iter 49000, loss: 0.418559
 >> iter 50000, loss: 0.407560
   Number of active neurons: 9
 >> iter 51000, loss: 0.432184
 >> iter 52000, loss: 0.357541
 >> iter 53000, loss: 0.327058
 >> iter 54000, loss: 0.306846
 >> iter 55000, loss: 0.304621
 >> iter 56000, loss: 0.317700
 >> iter 57000, loss: 0.305419
 >> iter 58000, loss: 0.294100
 >> iter 59000, loss: 0.265761
 >> iter 60000, loss: 0.291618
   Number of active neurons: 9
 >> iter 61000, loss: 0.278024
 >> iter 62000, loss: 0.329165
 >> iter 63000, loss: 0.333810
 >> iter 64000, loss: 0.386467
 >> iter 65000, loss: 0.369765
 >> iter 66000, loss: 0.371502
 >> iter 67000, loss: 0.283663
 >> iter 68000, loss: 0.318846
 >> iter 69000, loss: 0.282361
 >> iter 70000, loss: 0.218407
   Number of active neurons: 8
 >> iter 71000, loss: 0.199334
 >> iter 72000, loss: 0.237105
 >> iter 73000, loss: 0.275832
 >> iter 74000, loss: 0.293550
 >> iter 75000, loss: 0.338519
 >> iter 76000, loss: 0.375910
 >> iter 77000, loss: 0.263322
 >> iter 78000, loss: 0.343615
 >> iter 79000, loss: 0.353685
 >> iter 80000, loss: 0.317294
   Number of active neurons: 8
 >> iter 81000, loss: 0.353294
 >> iter 82000, loss: 0.386364
 >> iter 83000, loss: 0.398253
 >> iter 84000, loss: 0.305026
 >> iter 85000, loss: 0.334031
 >> iter 86000, loss: 0.338785
 >> iter 87000, loss: 0.253692
 >> iter 88000, loss: 0.249240
 >> iter 89000, loss: 0.337908
 >> iter 90000, loss: 0.318676
   Number of active neurons: 8
 >> iter 91000, loss: 0.378941
 >> iter 92000, loss: 0.271337
 >> iter 93000, loss: 0.356266
 >> iter 94000, loss: 0.281164
 >> iter 95000, loss: 0.290212
 >> iter 96000, loss: 0.337136
 >> iter 97000, loss: 0.303806
 >> iter 98000, loss: 0.259641
 >> iter 99000, loss: 0.445455
 >> iter 100000, loss: 0.351119
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 11.645890274
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 16.999162
 >> iter 2000, loss: 10.295021
 >> iter 3000, loss: 6.320524
 >> iter 4000, loss: 3.412524
 >> iter 5000, loss: 1.788403
 >> iter 6000, loss: 1.024622
 >> iter 7000, loss: 0.757812
 >> iter 8000, loss: 0.555336
 >> iter 9000, loss: 0.442930
 >> iter 10000, loss: 0.440961
   Number of active neurons: 8
 >> iter 11000, loss: 0.414356
 >> iter 12000, loss: 0.357319
 >> iter 13000, loss: 0.347101
 >> iter 14000, loss: 0.362384
 >> iter 15000, loss: 0.385322
 >> iter 16000, loss: 0.358819
 >> iter 17000, loss: 0.342722
 >> iter 18000, loss: 0.264189
 >> iter 19000, loss: 0.239111
 >> iter 20000, loss: 0.177717
   Number of active neurons: 8
 >> iter 21000, loss: 0.284057
 >> iter 22000, loss: 0.270406
 >> iter 23000, loss: 0.267323
 >> iter 24000, loss: 0.297701
 >> iter 25000, loss: 0.244285
 >> iter 26000, loss: 0.344956
 >> iter 27000, loss: 0.325657
 >> iter 28000, loss: 0.329813
 >> iter 29000, loss: 0.310090
 >> iter 30000, loss: 0.215981
   Number of active neurons: 6
 >> iter 31000, loss: 0.307411
 >> iter 32000, loss: 0.399075
 >> iter 33000, loss: 0.278325
 >> iter 34000, loss: 0.252740
 >> iter 35000, loss: 0.309856
 >> iter 36000, loss: 0.269058
 >> iter 37000, loss: 0.214969
 >> iter 38000, loss: 0.182900
 >> iter 39000, loss: 0.205927
 >> iter 40000, loss: 0.244192
   Number of active neurons: 6
 >> iter 41000, loss: 0.249023
 >> iter 42000, loss: 0.222468
 >> iter 43000, loss: 0.243373
 >> iter 44000, loss: 0.252567
 >> iter 45000, loss: 0.192638
 >> iter 46000, loss: 0.328914
 >> iter 47000, loss: 0.239254
 >> iter 48000, loss: 0.309298
 >> iter 49000, loss: 0.274556
 >> iter 50000, loss: 0.294524
   Number of active neurons: 6
 >> iter 51000, loss: 0.169882
 >> iter 52000, loss: 0.147601
 >> iter 53000, loss: 0.184049
 >> iter 54000, loss: 0.182698
 >> iter 55000, loss: 0.221885
 >> iter 56000, loss: 0.391357
 >> iter 57000, loss: 0.261529
 >> iter 58000, loss: 0.347162
 >> iter 59000, loss: 0.308897
 >> iter 60000, loss: 0.230821
   Number of active neurons: 6
 >> iter 61000, loss: 0.448136
 >> iter 62000, loss: 0.358093
 >> iter 63000, loss: 0.206560
 >> iter 64000, loss: 0.215539
 >> iter 65000, loss: 0.313536
 >> iter 66000, loss: 0.290535
 >> iter 67000, loss: 0.446391
 >> iter 68000, loss: 0.354718
 >> iter 69000, loss: 0.383598
 >> iter 70000, loss: 0.352461
   Number of active neurons: 6
 >> iter 71000, loss: 0.268054
 >> iter 72000, loss: 0.242189
 >> iter 73000, loss: 0.241564
 >> iter 74000, loss: 0.355850
 >> iter 75000, loss: 0.318262
 >> iter 76000, loss: 0.284437
 >> iter 77000, loss: 0.225340
 >> iter 78000, loss: 0.244717
 >> iter 79000, loss: 0.263735
 >> iter 80000, loss: 0.189007
   Number of active neurons: 5
 >> iter 81000, loss: 0.273252
 >> iter 82000, loss: 0.306095
 >> iter 83000, loss: 0.354940
 >> iter 84000, loss: 0.319387
 >> iter 85000, loss: 0.378116
 >> iter 86000, loss: 0.325520
 >> iter 87000, loss: 0.331236
 >> iter 88000, loss: 0.308041
 >> iter 89000, loss: 0.323788
 >> iter 90000, loss: 0.286804
   Number of active neurons: 5
 >> iter 91000, loss: 0.296897
 >> iter 92000, loss: 0.281362
 >> iter 93000, loss: 0.250344
 >> iter 94000, loss: 0.255255
 >> iter 95000, loss: 0.335218
 >> iter 96000, loss: 0.237176
 >> iter 97000, loss: 0.174666
 >> iter 98000, loss: 0.217668
 >> iter 99000, loss: 0.367319
 >> iter 100000, loss: 0.258162
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.709311
 >> iter 2000, loss: 9.891636
 >> iter 3000, loss: 5.712301
 >> iter 4000, loss: 2.552377
 >> iter 5000, loss: 1.200590
 >> iter 6000, loss: 0.696694
 >> iter 7000, loss: 0.589121
 >> iter 8000, loss: 0.375150
 >> iter 9000, loss: 0.491137
 >> iter 10000, loss: 0.294046
   Number of active neurons: 12
 >> iter 11000, loss: 0.279716
 >> iter 12000, loss: 0.183258
 >> iter 13000, loss: 0.304252
 >> iter 14000, loss: 0.288728
 >> iter 15000, loss: 0.291738
 >> iter 16000, loss: 0.342783
 >> iter 17000, loss: 0.217052
 >> iter 18000, loss: 0.378546
 >> iter 19000, loss: 0.281678
 >> iter 20000, loss: 0.261690
   Number of active neurons: 12
 >> iter 21000, loss: 0.218400
 >> iter 22000, loss: 0.201158
 >> iter 23000, loss: 0.267370
 >> iter 24000, loss: 0.262919
 >> iter 25000, loss: 0.205931
 >> iter 26000, loss: 0.248434
 >> iter 27000, loss: 0.319496
 >> iter 28000, loss: 0.331837
 >> iter 29000, loss: 0.188382
 >> iter 30000, loss: 0.357312
   Number of active neurons: 12
 >> iter 31000, loss: 0.245854
 >> iter 32000, loss: 0.201954
 >> iter 33000, loss: 0.187539
 >> iter 34000, loss: 0.214227
 >> iter 35000, loss: 0.175354
 >> iter 36000, loss: 0.237178
 >> iter 37000, loss: 0.240006
 >> iter 38000, loss: 0.317171
 >> iter 39000, loss: 0.326262
 >> iter 40000, loss: 0.267092
   Number of active neurons: 12
 >> iter 41000, loss: 0.250635
 >> iter 42000, loss: 0.168629
 >> iter 43000, loss: 0.197061
 >> iter 44000, loss: 0.204156
 >> iter 45000, loss: 0.208562
 >> iter 46000, loss: 0.346524
 >> iter 47000, loss: 0.234003
 >> iter 48000, loss: 0.392253
 >> iter 49000, loss: 0.303755
 >> iter 50000, loss: 0.210946
   Number of active neurons: 12
 >> iter 51000, loss: 0.178093
 >> iter 52000, loss: 0.227243
 >> iter 53000, loss: 0.353803
 >> iter 54000, loss: 0.302694
 >> iter 55000, loss: 0.298565
 >> iter 56000, loss: 0.210709
 >> iter 57000, loss: 0.270119
 >> iter 58000, loss: 0.220206
 >> iter 59000, loss: 0.215017
 >> iter 60000, loss: 0.285731
   Number of active neurons: 11
 >> iter 61000, loss: 0.383098
 >> iter 62000, loss: 0.228297
 >> iter 63000, loss: 0.236002
 >> iter 64000, loss: 0.198867
 >> iter 65000, loss: 0.359198
 >> iter 66000, loss: 0.245051
 >> iter 67000, loss: 0.283520
 >> iter 68000, loss: 0.208603
 >> iter 69000, loss: 0.257226
 >> iter 70000, loss: 0.308770
   Number of active neurons: 11
 >> iter 71000, loss: 0.311177
 >> iter 72000, loss: 0.223070
 >> iter 73000, loss: 0.265274
 >> iter 74000, loss: 0.286800
 >> iter 75000, loss: 0.226949
 >> iter 76000, loss: 0.257010
 >> iter 77000, loss: 0.205209
 >> iter 78000, loss: 0.218787
 >> iter 79000, loss: 0.212885
 >> iter 80000, loss: 0.209576
   Number of active neurons: 11
 >> iter 81000, loss: 0.229600
 >> iter 82000, loss: 0.274346
 >> iter 83000, loss: 0.252212
 >> iter 84000, loss: 0.207298
 >> iter 85000, loss: 0.231869
 >> iter 86000, loss: 0.294237
 >> iter 87000, loss: 0.229893
 >> iter 88000, loss: 0.208971
 >> iter 89000, loss: 0.287175
 >> iter 90000, loss: 0.312867
   Number of active neurons: 11
 >> iter 91000, loss: 0.249068
 >> iter 92000, loss: 0.229902
 >> iter 93000, loss: 0.262245
 >> iter 94000, loss: 0.216663
 >> iter 95000, loss: 0.241650
 >> iter 96000, loss: 0.167097
 >> iter 97000, loss: 0.164032
 >> iter 98000, loss: 0.119335
 >> iter 99000, loss: 0.322984
 >> iter 100000, loss: 0.254399
   Number of active neurons: 11
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 17.209233
 >> iter 2000, loss: 9.569309
 >> iter 3000, loss: 4.331986
 >> iter 4000, loss: 1.945558
 >> iter 5000, loss: 1.091663
 >> iter 6000, loss: 0.610129
 >> iter 7000, loss: 0.511872
 >> iter 8000, loss: 0.435586
 >> iter 9000, loss: 0.318871
 >> iter 10000, loss: 0.247551
   Number of active neurons: 11
 >> iter 11000, loss: 0.233154
 >> iter 12000, loss: 0.361656
 >> iter 13000, loss: 0.399950
 >> iter 14000, loss: 0.228426
 >> iter 15000, loss: 0.340818
 >> iter 16000, loss: 0.320606
 >> iter 17000, loss: 0.356560
 >> iter 18000, loss: 0.387086
 >> iter 19000, loss: 0.383266
 >> iter 20000, loss: 0.273722
   Number of active neurons: 11
 >> iter 21000, loss: 0.314618
 >> iter 22000, loss: 0.288019
 >> iter 23000, loss: 0.274729
 >> iter 24000, loss: 0.361404
 >> iter 25000, loss: 0.313455
 >> iter 26000, loss: 0.393907
 >> iter 27000, loss: 0.335306
 >> iter 28000, loss: 0.307377
 >> iter 29000, loss: 0.276460
 >> iter 30000, loss: 0.355112
   Number of active neurons: 10
 >> iter 31000, loss: 0.286881
 >> iter 32000, loss: 0.238918
 >> iter 33000, loss: 0.315505
 >> iter 34000, loss: 0.336354
 >> iter 35000, loss: 0.430683
 >> iter 36000, loss: 0.341783
 >> iter 37000, loss: 0.281536
 >> iter 38000, loss: 0.289669
 >> iter 39000, loss: 0.286851
 >> iter 40000, loss: 0.191007
   Number of active neurons: 9
 >> iter 41000, loss: 0.313345
 >> iter 42000, loss: 0.241379
 >> iter 43000, loss: 0.203813
 >> iter 44000, loss: 0.233530
 >> iter 45000, loss: 0.244183
 >> iter 46000, loss: 0.244154
 >> iter 47000, loss: 0.252327
 >> iter 48000, loss: 0.334243
 >> iter 49000, loss: 0.256191
 >> iter 50000, loss: 0.270461
   Number of active neurons: 7
 >> iter 51000, loss: 0.321614
 >> iter 52000, loss: 0.299999
 >> iter 53000, loss: 0.320957
 >> iter 54000, loss: 0.279220
 >> iter 55000, loss: 0.218343
 >> iter 56000, loss: 0.433224
 >> iter 57000, loss: 0.447013
 >> iter 58000, loss: 0.374177
 >> iter 59000, loss: 0.306408
 >> iter 60000, loss: 0.307221
   Number of active neurons: 7
 >> iter 61000, loss: 0.231732
 >> iter 62000, loss: 0.323066
 >> iter 63000, loss: 0.306488
 >> iter 64000, loss: 0.261424
 >> iter 65000, loss: 0.312862
 >> iter 66000, loss: 0.314228
 >> iter 67000, loss: 0.336995
 >> iter 68000, loss: 0.324271
 >> iter 69000, loss: 0.324929
 >> iter 70000, loss: 0.319402
   Number of active neurons: 6
 >> iter 71000, loss: 0.290736
 >> iter 72000, loss: 0.286209
 >> iter 73000, loss: 0.350329
 >> iter 74000, loss: 0.353398
 >> iter 75000, loss: 0.371313
 >> iter 76000, loss: 0.411835
 >> iter 77000, loss: 0.380367
 >> iter 78000, loss: 0.318115
 >> iter 79000, loss: 0.252300
 >> iter 80000, loss: 0.238387
   Number of active neurons: 6
 >> iter 81000, loss: 0.290397
 >> iter 82000, loss: 0.285228
 >> iter 83000, loss: 0.303047
 >> iter 84000, loss: 0.297647
 >> iter 85000, loss: 0.391814
 >> iter 86000, loss: 0.309511
 >> iter 87000, loss: 0.338007
 >> iter 88000, loss: 0.305199
 >> iter 89000, loss: 0.235232
 >> iter 90000, loss: 0.425543
   Number of active neurons: 5
 >> iter 91000, loss: 0.377514
 >> iter 92000, loss: 0.303571
 >> iter 93000, loss: 0.312140
 >> iter 94000, loss: 0.261414
 >> iter 95000, loss: 0.237230
 >> iter 96000, loss: 0.231943
 >> iter 97000, loss: 0.203699
 >> iter 98000, loss: 0.180160
 >> iter 99000, loss: 0.280486
 >> iter 100000, loss: 0.409069
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0219995600088
   - Test - Long: 0.0349982500875
   - Test - Big: 0.0519994800052
   - Test - A: 0.0
   - Test - B: 20.4319712019
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 16.700807
 >> iter 2000, loss: 9.885182
 >> iter 3000, loss: 6.910109
 >> iter 4000, loss: 3.668896
 >> iter 5000, loss: 1.850317
 >> iter 6000, loss: 0.994198
 >> iter 7000, loss: 0.519064
 >> iter 8000, loss: 0.591056
 >> iter 9000, loss: 0.529529
 >> iter 10000, loss: 0.473411
   Number of active neurons: 10
 >> iter 11000, loss: 0.360128
 >> iter 12000, loss: 0.418668
 >> iter 13000, loss: 0.354894
 >> iter 14000, loss: 0.367185
 >> iter 15000, loss: 0.293420
 >> iter 16000, loss: 0.240040
 >> iter 17000, loss: 0.260612
 >> iter 18000, loss: 0.153776
 >> iter 19000, loss: 0.297903
 >> iter 20000, loss: 0.295133
   Number of active neurons: 9
 >> iter 21000, loss: 0.275568
 >> iter 22000, loss: 0.222950
 >> iter 23000, loss: 0.164160
 >> iter 24000, loss: 0.387371
 >> iter 25000, loss: 0.328182
 >> iter 26000, loss: 0.317505
 >> iter 27000, loss: 0.252665
 >> iter 28000, loss: 0.258514
 >> iter 29000, loss: 0.294674
 >> iter 30000, loss: 0.312600
   Number of active neurons: 9
 >> iter 31000, loss: 0.364377
 >> iter 32000, loss: 0.310574
 >> iter 33000, loss: 0.317294
 >> iter 34000, loss: 0.327649
 >> iter 35000, loss: 0.243266
 >> iter 36000, loss: 0.246108
 >> iter 37000, loss: 0.286572
 >> iter 38000, loss: 0.350759
 >> iter 39000, loss: 0.289301
 >> iter 40000, loss: 0.299858
   Number of active neurons: 8
 >> iter 41000, loss: 0.321098
 >> iter 42000, loss: 0.300044
 >> iter 43000, loss: 0.219840
 >> iter 44000, loss: 0.263034
 >> iter 45000, loss: 0.315444
 >> iter 46000, loss: 0.284025
 >> iter 47000, loss: 0.232444
 >> iter 48000, loss: 0.257099
 >> iter 49000, loss: 0.216589
 >> iter 50000, loss: 0.151054
   Number of active neurons: 8
 >> iter 51000, loss: 0.242067
 >> iter 52000, loss: 0.366859
 >> iter 53000, loss: 0.325024
 >> iter 54000, loss: 0.311275
 >> iter 55000, loss: 0.375882
 >> iter 56000, loss: 0.388634
 >> iter 57000, loss: 0.353281
 >> iter 58000, loss: 0.279385
 >> iter 59000, loss: 0.306281
 >> iter 60000, loss: 0.316270
   Number of active neurons: 7
 >> iter 61000, loss: 0.293092
 >> iter 62000, loss: 0.253008
 >> iter 63000, loss: 0.160371
 >> iter 64000, loss: 0.197164
 >> iter 65000, loss: 0.271951
 >> iter 66000, loss: 0.219533
 >> iter 67000, loss: 0.289600
 >> iter 68000, loss: 0.226329
 >> iter 69000, loss: 0.280446
 >> iter 70000, loss: 0.322230
   Number of active neurons: 7
 >> iter 71000, loss: 0.368304
 >> iter 72000, loss: 0.383861
 >> iter 73000, loss: 0.420759
 >> iter 74000, loss: 0.384012
 >> iter 75000, loss: 0.358221
 >> iter 76000, loss: 0.324030
 >> iter 77000, loss: 0.226939
 >> iter 78000, loss: 0.250481
 >> iter 79000, loss: 0.338903
 >> iter 80000, loss: 0.236064
   Number of active neurons: 7
 >> iter 81000, loss: 0.381153
 >> iter 82000, loss: 0.366124
 >> iter 83000, loss: 0.274988
 >> iter 84000, loss: 0.221156
 >> iter 85000, loss: 0.332040
 >> iter 86000, loss: 0.271940
 >> iter 87000, loss: 0.324474
 >> iter 88000, loss: 0.289639
 >> iter 89000, loss: 0.272281
 >> iter 90000, loss: 0.316699
   Number of active neurons: 7
 >> iter 91000, loss: 0.223169
 >> iter 92000, loss: 0.290918
 >> iter 93000, loss: 0.271809
 >> iter 94000, loss: 0.233555
 >> iter 95000, loss: 0.271532
 >> iter 96000, loss: 0.242775
 >> iter 97000, loss: 0.330404
 >> iter 98000, loss: 0.314054
 >> iter 99000, loss: 0.276334
 >> iter 100000, loss: 0.304496
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.623315
 >> iter 2000, loss: 9.680607
 >> iter 3000, loss: 6.091228
 >> iter 4000, loss: 3.124184
 >> iter 5000, loss: 1.427779
 >> iter 6000, loss: 0.681126
 >> iter 7000, loss: 0.423015
 >> iter 8000, loss: 0.311775
 >> iter 9000, loss: 0.223079
 >> iter 10000, loss: 0.245381
   Number of active neurons: 10
 >> iter 11000, loss: 0.184124
 >> iter 12000, loss: 0.184493
 >> iter 13000, loss: 0.342610
 >> iter 14000, loss: 0.243915
 >> iter 15000, loss: 0.221113
 >> iter 16000, loss: 0.310081
 >> iter 17000, loss: 0.325961
 >> iter 18000, loss: 0.296046
 >> iter 19000, loss: 0.230596
 >> iter 20000, loss: 0.289806
   Number of active neurons: 10
 >> iter 21000, loss: 0.304353
 >> iter 22000, loss: 0.241844
 >> iter 23000, loss: 0.348695
 >> iter 24000, loss: 0.251840
 >> iter 25000, loss: 0.222858
 >> iter 26000, loss: 0.221297
 >> iter 27000, loss: 0.201077
 >> iter 28000, loss: 0.217890
 >> iter 29000, loss: 0.262449
 >> iter 30000, loss: 0.267267
   Number of active neurons: 10
 >> iter 31000, loss: 0.264883
 >> iter 32000, loss: 0.181373
 >> iter 33000, loss: 0.316088
 >> iter 34000, loss: 0.331675
 >> iter 35000, loss: 0.244127
 >> iter 36000, loss: 0.213854
 >> iter 37000, loss: 0.302604
 >> iter 38000, loss: 0.313150
 >> iter 39000, loss: 0.422270
 >> iter 40000, loss: 0.272666
   Number of active neurons: 10
 >> iter 41000, loss: 0.259981
 >> iter 42000, loss: 0.239497
 >> iter 43000, loss: 0.324120
 >> iter 44000, loss: 0.213480
 >> iter 45000, loss: 0.314286
 >> iter 46000, loss: 0.235763
 >> iter 47000, loss: 0.242817
 >> iter 48000, loss: 0.210298
 >> iter 49000, loss: 0.209672
 >> iter 50000, loss: 0.291660
   Number of active neurons: 10
 >> iter 51000, loss: 0.237731
 >> iter 52000, loss: 0.310229
 >> iter 53000, loss: 0.302704
 >> iter 54000, loss: 0.277383
 >> iter 55000, loss: 0.339719
 >> iter 56000, loss: 0.241447
 >> iter 57000, loss: 0.246709
 >> iter 58000, loss: 0.259087
 >> iter 59000, loss: 0.254938
 >> iter 60000, loss: 0.285753
   Number of active neurons: 10
 >> iter 61000, loss: 0.216621
 >> iter 62000, loss: 0.270700
 >> iter 63000, loss: 0.238106
 >> iter 64000, loss: 0.364710
 >> iter 65000, loss: 0.261302
 >> iter 66000, loss: 0.219174
 >> iter 67000, loss: 0.345726
 >> iter 68000, loss: 0.217186
 >> iter 69000, loss: 0.279332
 >> iter 70000, loss: 0.314176
   Number of active neurons: 10
 >> iter 71000, loss: 0.231005
 >> iter 72000, loss: 0.190709
 >> iter 73000, loss: 0.292319
 >> iter 74000, loss: 0.246754
 >> iter 75000, loss: 0.293371
 >> iter 76000, loss: 0.273836
 >> iter 77000, loss: 0.246174
 >> iter 78000, loss: 0.324409
 >> iter 79000, loss: 0.338857
 >> iter 80000, loss: 0.243760
   Number of active neurons: 9
 >> iter 81000, loss: 0.216494
 >> iter 82000, loss: 0.135668
 >> iter 83000, loss: 0.259347
 >> iter 84000, loss: 0.308628
 >> iter 85000, loss: 0.413117
 >> iter 86000, loss: 0.265611
 >> iter 87000, loss: 0.267551
 >> iter 88000, loss: 0.236329
 >> iter 89000, loss: 0.333908
 >> iter 90000, loss: 0.253282
   Number of active neurons: 9
 >> iter 91000, loss: 0.172127
 >> iter 92000, loss: 0.231870
 >> iter 93000, loss: 0.297197
 >> iter 94000, loss: 0.246699
 >> iter 95000, loss: 0.257079
 >> iter 96000, loss: 0.198344
 >> iter 97000, loss: 0.233575
 >> iter 98000, loss: 0.265406
 >> iter 99000, loss: 0.278371
 >> iter 100000, loss: 0.265857
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

