 > Problema: tomita7nueva
 > Args:
   - Hidden size: 6
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.929147
 >> iter 2000, loss: 11.368843
 >> iter 3000, loss: 7.399373
 >> iter 4000, loss: 4.068965
 >> iter 5000, loss: 2.359812
 >> iter 6000, loss: 1.748402
 >> iter 7000, loss: 1.258301
 >> iter 8000, loss: 1.212756
 >> iter 9000, loss: 0.895921
 >> iter 10000, loss: 0.825483
   Number of active neurons: 6
 >> iter 11000, loss: 0.704992
 >> iter 12000, loss: 0.749080
 >> iter 13000, loss: 0.750527
 >> iter 14000, loss: 0.586364
 >> iter 15000, loss: 0.505882
 >> iter 16000, loss: 0.566517
 >> iter 17000, loss: 0.508398
 >> iter 18000, loss: 0.573155
 >> iter 19000, loss: 0.746787
 >> iter 20000, loss: 0.620187
   Number of active neurons: 6
 >> iter 21000, loss: 0.840545
 >> iter 22000, loss: 0.560879
 >> iter 23000, loss: 0.640754
 >> iter 24000, loss: 0.692392
 >> iter 25000, loss: 0.633324
 >> iter 26000, loss: 0.649460
 >> iter 27000, loss: 0.640877
 >> iter 28000, loss: 0.528946
 >> iter 29000, loss: 0.619747
 >> iter 30000, loss: 0.685761
   Number of active neurons: 5
 >> iter 31000, loss: 0.813309
 >> iter 32000, loss: 0.779314
 >> iter 33000, loss: 0.767786
 >> iter 34000, loss: 0.607553
 >> iter 35000, loss: 0.706689
 >> iter 36000, loss: 0.637307
 >> iter 37000, loss: 0.550921
 >> iter 38000, loss: 0.663296
 >> iter 39000, loss: 0.656432
 >> iter 40000, loss: 0.532634
   Number of active neurons: 5
 >> iter 41000, loss: 0.609172
 >> iter 42000, loss: 0.611887
 >> iter 43000, loss: 0.616684
 >> iter 44000, loss: 0.681586
 >> iter 45000, loss: 0.593943
 >> iter 46000, loss: 0.403554
 >> iter 47000, loss: 0.591133
 >> iter 48000, loss: 0.663230
 >> iter 49000, loss: 0.473526
 >> iter 50000, loss: 0.587803
   Number of active neurons: 5
 >> iter 51000, loss: 0.572570
 >> iter 52000, loss: 0.474589
 >> iter 53000, loss: 0.598465
 >> iter 54000, loss: 0.544214
 >> iter 55000, loss: 0.615255
 >> iter 56000, loss: 0.557385
 >> iter 57000, loss: 0.556865
 >> iter 58000, loss: 0.588974
 >> iter 59000, loss: 0.519240
 >> iter 60000, loss: 0.511897
   Number of active neurons: 5
 >> iter 61000, loss: 0.545952
 >> iter 62000, loss: 0.600394
 >> iter 63000, loss: 0.552552
 >> iter 64000, loss: 0.571067
 >> iter 65000, loss: 0.599837
 >> iter 66000, loss: 0.559094
 >> iter 67000, loss: 0.458919
 >> iter 68000, loss: 0.459838
 >> iter 69000, loss: 0.506812
 >> iter 70000, loss: 0.530153
   Number of active neurons: 5
 >> iter 71000, loss: 0.482595
 >> iter 72000, loss: 0.495926
 >> iter 73000, loss: 0.588591
 >> iter 74000, loss: 0.461768
 >> iter 75000, loss: 0.414815
 >> iter 76000, loss: 0.458059
 >> iter 77000, loss: 0.347155
 >> iter 78000, loss: 0.345242
 >> iter 79000, loss: 0.288116
 >> iter 80000, loss: 0.347373
   Number of active neurons: 5
 >> iter 81000, loss: 0.295352
 >> iter 82000, loss: 0.346122
 >> iter 83000, loss: 0.396776
 >> iter 84000, loss: 0.337342
 >> iter 85000, loss: 0.382741
 >> iter 86000, loss: 0.405192
 >> iter 87000, loss: 0.407200
 >> iter 88000, loss: 0.354925
 >> iter 89000, loss: 0.373689
 >> iter 90000, loss: 0.292786
   Number of active neurons: 4
 >> iter 91000, loss: 0.482294
 >> iter 92000, loss: 0.314089
 >> iter 93000, loss: 0.418488
 >> iter 94000, loss: 0.538686
 >> iter 95000, loss: 0.487495
 >> iter 96000, loss: 0.395228
 >> iter 97000, loss: 0.391878
 >> iter 98000, loss: 0.395653
 >> iter 99000, loss: 0.343717
 >> iter 100000, loss: 0.391704
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.069208
 >> iter 2000, loss: 9.609626
 >> iter 3000, loss: 5.170737
 >> iter 4000, loss: 2.798460
 >> iter 5000, loss: 1.878927
 >> iter 6000, loss: 1.154339
 >> iter 7000, loss: 0.930051
 >> iter 8000, loss: 0.606837
 >> iter 9000, loss: 0.567199
 >> iter 10000, loss: 0.455873
   Number of active neurons: 4
 >> iter 11000, loss: 0.568708
 >> iter 12000, loss: 0.446236
 >> iter 13000, loss: 0.447909
 >> iter 14000, loss: 0.450429
 >> iter 15000, loss: 0.649108
 >> iter 16000, loss: 0.554210
 >> iter 17000, loss: 0.564137
 >> iter 18000, loss: 0.460029
 >> iter 19000, loss: 0.488685
 >> iter 20000, loss: 0.495160
   Number of active neurons: 4
 >> iter 21000, loss: 0.458007
 >> iter 22000, loss: 0.481075
 >> iter 23000, loss: 0.473850
 >> iter 24000, loss: 0.465631
 >> iter 25000, loss: 0.541387
 >> iter 26000, loss: 0.501420
 >> iter 27000, loss: 0.424744
 >> iter 28000, loss: 0.390757
 >> iter 29000, loss: 0.330485
 >> iter 30000, loss: 0.423858
   Number of active neurons: 4
 >> iter 31000, loss: 0.377357
 >> iter 32000, loss: 0.389190
 >> iter 33000, loss: 0.530500
 >> iter 34000, loss: 0.384161
 >> iter 35000, loss: 0.470661
 >> iter 36000, loss: 0.510488
 >> iter 37000, loss: 0.473779
 >> iter 38000, loss: 0.399995
 >> iter 39000, loss: 0.381656
 >> iter 40000, loss: 0.406063
   Number of active neurons: 4
 >> iter 41000, loss: 0.383811
 >> iter 42000, loss: 0.486269
 >> iter 43000, loss: 0.546436
 >> iter 44000, loss: 0.708399
 >> iter 45000, loss: 0.657883
 >> iter 46000, loss: 0.569030
 >> iter 47000, loss: 0.580522
 >> iter 48000, loss: 0.718700
 >> iter 49000, loss: 0.509777
 >> iter 50000, loss: 0.425390
   Number of active neurons: 4
 >> iter 51000, loss: 0.342248
 >> iter 52000, loss: 0.526865
 >> iter 53000, loss: 0.426445
 >> iter 54000, loss: 0.536957
 >> iter 55000, loss: 0.577768
 >> iter 56000, loss: 0.649678
 >> iter 57000, loss: 0.699063
 >> iter 58000, loss: 0.693926
 >> iter 59000, loss: 0.787173
 >> iter 60000, loss: 0.745011
   Number of active neurons: 4
 >> iter 61000, loss: 0.671993
 >> iter 62000, loss: 0.664560
 >> iter 63000, loss: 0.608249
 >> iter 64000, loss: 0.728879
 >> iter 65000, loss: 0.734426
 >> iter 66000, loss: 0.579373
 >> iter 67000, loss: 0.600501
 >> iter 68000, loss: 0.464457
 >> iter 69000, loss: 0.625908
 >> iter 70000, loss: 0.610790
   Number of active neurons: 4
 >> iter 71000, loss: 0.439548
 >> iter 72000, loss: 0.746380
 >> iter 73000, loss: 0.665929
 >> iter 74000, loss: 0.579397
 >> iter 75000, loss: 0.583226
 >> iter 76000, loss: 0.501986
 >> iter 77000, loss: 0.493994
 >> iter 78000, loss: 0.478110
 >> iter 79000, loss: 0.580825
 >> iter 80000, loss: 0.598524
   Number of active neurons: 4
 >> iter 81000, loss: 0.571922
 >> iter 82000, loss: 0.487284
 >> iter 83000, loss: 0.336468
 >> iter 84000, loss: 0.456478
 >> iter 85000, loss: 0.492927
 >> iter 86000, loss: 0.635298
 >> iter 87000, loss: 0.399118
 >> iter 88000, loss: 0.523143
 >> iter 89000, loss: 0.500836
 >> iter 90000, loss: 0.558833
   Number of active neurons: 4
 >> iter 91000, loss: 0.543702
 >> iter 92000, loss: 0.631514
 >> iter 93000, loss: 0.748414
 >> iter 94000, loss: 0.628509
 >> iter 95000, loss: 0.617651
 >> iter 96000, loss: 0.631941
 >> iter 97000, loss: 0.533336
 >> iter 98000, loss: 0.470075
 >> iter 99000, loss: 0.421587
 >> iter 100000, loss: 0.509621
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.537775
 >> iter 2000, loss: 11.689727
 >> iter 3000, loss: 7.735350
 >> iter 4000, loss: 4.238744
 >> iter 5000, loss: 2.067590
 >> iter 6000, loss: 1.089471
 >> iter 7000, loss: 0.623033
 >> iter 8000, loss: 0.436661
 >> iter 9000, loss: 0.462878
 >> iter 10000, loss: 0.321736
   Number of active neurons: 6
 >> iter 11000, loss: 0.361080
 >> iter 12000, loss: 0.331128
 >> iter 13000, loss: 0.283910
 >> iter 14000, loss: 0.328192
 >> iter 15000, loss: 0.355375
 >> iter 16000, loss: 0.328729
 >> iter 17000, loss: 0.281846
 >> iter 18000, loss: 0.236881
 >> iter 19000, loss: 0.275436
 >> iter 20000, loss: 0.313303
   Number of active neurons: 5
 >> iter 21000, loss: 0.296310
 >> iter 22000, loss: 0.352615
 >> iter 23000, loss: 0.465239
 >> iter 24000, loss: 0.356530
 >> iter 25000, loss: 0.327948
 >> iter 26000, loss: 0.229305
 >> iter 27000, loss: 0.254761
 >> iter 28000, loss: 0.298940
 >> iter 29000, loss: 0.404462
 >> iter 30000, loss: 0.298254
   Number of active neurons: 5
 >> iter 31000, loss: 0.263285
 >> iter 32000, loss: 0.330025
 >> iter 33000, loss: 0.384447
 >> iter 34000, loss: 0.350770
 >> iter 35000, loss: 0.338762
 >> iter 36000, loss: 0.328680
 >> iter 37000, loss: 0.366640
 >> iter 38000, loss: 0.381285
 >> iter 39000, loss: 0.481524
 >> iter 40000, loss: 0.539044
   Number of active neurons: 5
 >> iter 41000, loss: 0.376433
 >> iter 42000, loss: 0.355375
 >> iter 43000, loss: 0.327429
 >> iter 44000, loss: 0.264808
 >> iter 45000, loss: 0.325776
 >> iter 46000, loss: 0.417106
 >> iter 47000, loss: 0.269700
 >> iter 48000, loss: 0.305830
 >> iter 49000, loss: 0.342171
 >> iter 50000, loss: 0.322878
   Number of active neurons: 5
 >> iter 51000, loss: 0.383468
 >> iter 52000, loss: 0.352246
 >> iter 53000, loss: 0.294099
 >> iter 54000, loss: 0.381525
 >> iter 55000, loss: 0.404186
 >> iter 56000, loss: 0.277183
 >> iter 57000, loss: 0.265300
 >> iter 58000, loss: 0.334735
 >> iter 59000, loss: 0.235164
 >> iter 60000, loss: 0.343544
   Number of active neurons: 4
 >> iter 61000, loss: 0.427698
 >> iter 62000, loss: 0.448699
 >> iter 63000, loss: 0.436291
 >> iter 64000, loss: 0.407816
 >> iter 65000, loss: 0.344870
 >> iter 66000, loss: 0.316924
 >> iter 67000, loss: 0.349147
 >> iter 68000, loss: 0.432844
 >> iter 69000, loss: 0.324685
 >> iter 70000, loss: 0.379218
   Number of active neurons: 4
 >> iter 71000, loss: 0.579589
 >> iter 72000, loss: 0.346225
 >> iter 73000, loss: 0.350504
 >> iter 74000, loss: 0.283757
 >> iter 75000, loss: 0.378804
 >> iter 76000, loss: 0.365549
 >> iter 77000, loss: 0.287800
 >> iter 78000, loss: 0.286005
 >> iter 79000, loss: 0.364179
 >> iter 80000, loss: 0.278435
   Number of active neurons: 4
 >> iter 81000, loss: 0.368202
 >> iter 82000, loss: 0.309693
 >> iter 83000, loss: 0.347603
 >> iter 84000, loss: 0.357598
 >> iter 85000, loss: 0.337372
 >> iter 86000, loss: 0.433861
 >> iter 87000, loss: 0.404952
 >> iter 88000, loss: 0.320686
 >> iter 89000, loss: 0.388044
 >> iter 90000, loss: 0.451522
   Number of active neurons: 4
 >> iter 91000, loss: 0.435691
 >> iter 92000, loss: 0.362034
 >> iter 93000, loss: 0.268786
 >> iter 94000, loss: 0.246142
 >> iter 95000, loss: 0.375286
 >> iter 96000, loss: 0.305274
 >> iter 97000, loss: 0.311566
 >> iter 98000, loss: 0.356673
 >> iter 99000, loss: 0.368213
 >> iter 100000, loss: 0.367503
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.214324
 >> iter 2000, loss: 11.265189
 >> iter 3000, loss: 6.672537
 >> iter 4000, loss: 3.984134
 >> iter 5000, loss: 2.773758
 >> iter 6000, loss: 2.033151
 >> iter 7000, loss: 1.406450
 >> iter 8000, loss: 1.453710
 >> iter 9000, loss: 0.930345
 >> iter 10000, loss: 0.541469
   Number of active neurons: 6
 >> iter 11000, loss: 0.368960
 >> iter 12000, loss: 0.471449
 >> iter 13000, loss: 0.346139
 >> iter 14000, loss: 0.513907
 >> iter 15000, loss: 0.721192
 >> iter 16000, loss: 0.481461
 >> iter 17000, loss: 0.409328
 >> iter 18000, loss: 0.427286
 >> iter 19000, loss: 0.376426
 >> iter 20000, loss: 0.324824
   Number of active neurons: 6
 >> iter 21000, loss: 0.384811
 >> iter 22000, loss: 0.439784
 >> iter 23000, loss: 0.424224
 >> iter 24000, loss: 0.406376
 >> iter 25000, loss: 0.483371
 >> iter 26000, loss: 0.506427
 >> iter 27000, loss: 0.578613
 >> iter 28000, loss: 0.353455
 >> iter 29000, loss: 0.449252
 >> iter 30000, loss: 0.374628
   Number of active neurons: 6
 >> iter 31000, loss: 0.304403
 >> iter 32000, loss: 0.219845
 >> iter 33000, loss: 0.334136
 >> iter 34000, loss: 0.499208
 >> iter 35000, loss: 0.526012
 >> iter 36000, loss: 0.452045
 >> iter 37000, loss: 0.336567
 >> iter 38000, loss: 0.319577
 >> iter 39000, loss: 0.382763
 >> iter 40000, loss: 0.416704
   Number of active neurons: 6
 >> iter 41000, loss: 0.366803
 >> iter 42000, loss: 0.279178
 >> iter 43000, loss: 0.258657
 >> iter 44000, loss: 0.396107
 >> iter 45000, loss: 0.384696
 >> iter 46000, loss: 0.349515
 >> iter 47000, loss: 0.274585
 >> iter 48000, loss: 0.224354
 >> iter 49000, loss: 0.275053
 >> iter 50000, loss: 0.340422
   Number of active neurons: 6
 >> iter 51000, loss: 0.404428
 >> iter 52000, loss: 0.375845
 >> iter 53000, loss: 0.445384
 >> iter 54000, loss: 0.383583
 >> iter 55000, loss: 0.375972
 >> iter 56000, loss: 0.388309
 >> iter 57000, loss: 0.440066
 >> iter 58000, loss: 0.462057
 >> iter 59000, loss: 0.292225
 >> iter 60000, loss: 0.348426
   Number of active neurons: 6
 >> iter 61000, loss: 0.414903
 >> iter 62000, loss: 0.363603
 >> iter 63000, loss: 0.364900
 >> iter 64000, loss: 0.341021
 >> iter 65000, loss: 0.297343
 >> iter 66000, loss: 0.266959
 >> iter 67000, loss: 0.400577
 >> iter 68000, loss: 0.298425
 >> iter 69000, loss: 0.333026
 >> iter 70000, loss: 0.427365
   Number of active neurons: 6
 >> iter 71000, loss: 0.455312
 >> iter 72000, loss: 0.305762
 >> iter 73000, loss: 0.376099
 >> iter 74000, loss: 0.364093
 >> iter 75000, loss: 0.414954
 >> iter 76000, loss: 0.415344
 >> iter 77000, loss: 0.382815
 >> iter 78000, loss: 0.438325
 >> iter 79000, loss: 0.457181
 >> iter 80000, loss: 0.418141
   Number of active neurons: 6
 >> iter 81000, loss: 0.464855
 >> iter 82000, loss: 0.445970
 >> iter 83000, loss: 0.537468
 >> iter 84000, loss: 0.391782
 >> iter 85000, loss: 0.437757
 >> iter 86000, loss: 0.354128
 >> iter 87000, loss: 0.400470
 >> iter 88000, loss: 0.472912
 >> iter 89000, loss: 0.396806
 >> iter 90000, loss: 0.464357
   Number of active neurons: 6
 >> iter 91000, loss: 0.463098
 >> iter 92000, loss: 0.398375
 >> iter 93000, loss: 0.451366
 >> iter 94000, loss: 0.370454
 >> iter 95000, loss: 0.351934
 >> iter 96000, loss: 0.346951
 >> iter 97000, loss: 0.257168
 >> iter 98000, loss: 0.369501
 >> iter 99000, loss: 0.380304
 >> iter 100000, loss: 0.542861
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.689898
 >> iter 2000, loss: 11.466693
 >> iter 3000, loss: 7.212585
 >> iter 4000, loss: 4.110532
 >> iter 5000, loss: 2.371917
 >> iter 6000, loss: 1.526965
 >> iter 7000, loss: 1.089258
 >> iter 8000, loss: 0.715056
 >> iter 9000, loss: 0.674563
 >> iter 10000, loss: 0.476441
   Number of active neurons: 5
 >> iter 11000, loss: 0.661573
 >> iter 12000, loss: 0.912287
 >> iter 13000, loss: 0.784447
 >> iter 14000, loss: 0.618906
 >> iter 15000, loss: 0.570389
 >> iter 16000, loss: 0.549343
 >> iter 17000, loss: 0.550105
 >> iter 18000, loss: 0.475537
 >> iter 19000, loss: 0.616178
 >> iter 20000, loss: 0.563331
   Number of active neurons: 4
 >> iter 21000, loss: 0.579457
 >> iter 22000, loss: 0.545539
 >> iter 23000, loss: 0.494590
 >> iter 24000, loss: 0.487148
 >> iter 25000, loss: 0.765191
 >> iter 26000, loss: 0.577219
 >> iter 27000, loss: 0.456046
 >> iter 28000, loss: 0.425241
 >> iter 29000, loss: 0.559702
 >> iter 30000, loss: 0.490098
   Number of active neurons: 4
 >> iter 31000, loss: 0.335480
 >> iter 32000, loss: 0.444138
 >> iter 33000, loss: 0.490809
 >> iter 34000, loss: 0.389026
 >> iter 35000, loss: 0.531541
 >> iter 36000, loss: 0.424548
 >> iter 37000, loss: 0.431842
 >> iter 38000, loss: 0.397874
 >> iter 39000, loss: 0.476184
 >> iter 40000, loss: 0.644730
   Number of active neurons: 4
 >> iter 41000, loss: 0.606010
 >> iter 42000, loss: 0.513058
 >> iter 43000, loss: 0.589432
 >> iter 44000, loss: 0.486745
 >> iter 45000, loss: 0.493262
 >> iter 46000, loss: 0.452321
 >> iter 47000, loss: 0.384901
 >> iter 48000, loss: 0.440261
 >> iter 49000, loss: 0.478844
 >> iter 50000, loss: 0.441131
   Number of active neurons: 4
 >> iter 51000, loss: 0.447197
 >> iter 52000, loss: 0.321037
 >> iter 53000, loss: 0.444720
 >> iter 54000, loss: 0.394481
 >> iter 55000, loss: 0.499538
 >> iter 56000, loss: 0.456773
 >> iter 57000, loss: 0.500048
 >> iter 58000, loss: 0.512146
 >> iter 59000, loss: 0.415742
 >> iter 60000, loss: 0.468941
   Number of active neurons: 4
 >> iter 61000, loss: 0.522353
 >> iter 62000, loss: 0.388265
 >> iter 63000, loss: 0.454872
 >> iter 64000, loss: 0.594621
 >> iter 65000, loss: 0.714347
 >> iter 66000, loss: 0.626048
 >> iter 67000, loss: 0.619797
 >> iter 68000, loss: 0.633544
 >> iter 69000, loss: 0.604165
 >> iter 70000, loss: 0.450763
   Number of active neurons: 5
 >> iter 71000, loss: 0.468788
 >> iter 72000, loss: 0.673322
 >> iter 73000, loss: 0.474285
 >> iter 74000, loss: 0.399002
 >> iter 75000, loss: 0.516078
 >> iter 76000, loss: 0.600321
 >> iter 77000, loss: 0.598320
 >> iter 78000, loss: 0.558675
 >> iter 79000, loss: 0.594077
 >> iter 80000, loss: 0.471040
   Number of active neurons: 4
 >> iter 81000, loss: 0.451461
 >> iter 82000, loss: 0.524526
 >> iter 83000, loss: 0.567120
 >> iter 84000, loss: 0.595733
 >> iter 85000, loss: 0.561584
 >> iter 86000, loss: 0.631208
 >> iter 87000, loss: 0.617746
 >> iter 88000, loss: 0.505015
 >> iter 89000, loss: 0.441559
 >> iter 90000, loss: 0.613421
   Number of active neurons: 4
 >> iter 91000, loss: 0.404676
 >> iter 92000, loss: 0.522854
 >> iter 93000, loss: 0.527220
 >> iter 94000, loss: 0.416570
 >> iter 95000, loss: 0.435936
 >> iter 96000, loss: 0.495083
 >> iter 97000, loss: 0.489242
 >> iter 98000, loss: 0.593306
 >> iter 99000, loss: 0.625755
 >> iter 100000, loss: 0.503455
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.202632
 >> iter 2000, loss: 11.209561
 >> iter 3000, loss: 7.604488
 >> iter 4000, loss: 4.825853
 >> iter 5000, loss: 2.639223
 >> iter 6000, loss: 1.557632
 >> iter 7000, loss: 0.919448
 >> iter 8000, loss: 0.804731
 >> iter 9000, loss: 0.668181
 >> iter 10000, loss: 0.516026
   Number of active neurons: 6
 >> iter 11000, loss: 0.562672
 >> iter 12000, loss: 0.557946
 >> iter 13000, loss: 0.639056
 >> iter 14000, loss: 0.542525
 >> iter 15000, loss: 0.530240
 >> iter 16000, loss: 0.515341
 >> iter 17000, loss: 0.566663
 >> iter 18000, loss: 0.615845
 >> iter 19000, loss: 0.603184
 >> iter 20000, loss: 0.651419
   Number of active neurons: 6
 >> iter 21000, loss: 0.788584
 >> iter 22000, loss: 0.729597
 >> iter 23000, loss: 0.630434
 >> iter 24000, loss: 0.862164
 >> iter 25000, loss: 0.828268
 >> iter 26000, loss: 0.673635
 >> iter 27000, loss: 0.730386
 >> iter 28000, loss: 0.780784
 >> iter 29000, loss: 0.772231
 >> iter 30000, loss: 0.774266
   Number of active neurons: 5
 >> iter 31000, loss: 0.719500
 >> iter 32000, loss: 0.724652
 >> iter 33000, loss: 0.739716
 >> iter 34000, loss: 0.806654
 >> iter 35000, loss: 0.780265
 >> iter 36000, loss: 0.803797
 >> iter 37000, loss: 0.811115
 >> iter 38000, loss: 0.659969
 >> iter 39000, loss: 0.822026
 >> iter 40000, loss: 0.891947
   Number of active neurons: 5
 >> iter 41000, loss: 0.891794
 >> iter 42000, loss: 0.765446
 >> iter 43000, loss: 0.583692
 >> iter 44000, loss: 0.529190
 >> iter 45000, loss: 0.608009
 >> iter 46000, loss: 0.764234
 >> iter 47000, loss: 0.651659
 >> iter 48000, loss: 0.745800
 >> iter 49000, loss: 0.801255
 >> iter 50000, loss: 0.859060
   Number of active neurons: 4
 >> iter 51000, loss: 0.886440
 >> iter 52000, loss: 0.783135
 >> iter 53000, loss: 0.881970
 >> iter 54000, loss: 0.866427
 >> iter 55000, loss: 0.832584
 >> iter 56000, loss: 0.775775
 >> iter 57000, loss: 0.731595
 >> iter 58000, loss: 0.622227
 >> iter 59000, loss: 0.516845
 >> iter 60000, loss: 0.633395
   Number of active neurons: 4
 >> iter 61000, loss: 0.537930
 >> iter 62000, loss: 0.638674
 >> iter 63000, loss: 0.767181
 >> iter 64000, loss: 0.670029
 >> iter 65000, loss: 0.743429
 >> iter 66000, loss: 0.770848
 >> iter 67000, loss: 0.754543
 >> iter 68000, loss: 0.688932
 >> iter 69000, loss: 0.632972
 >> iter 70000, loss: 0.638715
   Number of active neurons: 4
 >> iter 71000, loss: 0.656808
 >> iter 72000, loss: 0.588527
 >> iter 73000, loss: 0.696522
 >> iter 74000, loss: 0.506646
 >> iter 75000, loss: 0.517716
 >> iter 76000, loss: 0.541618
 >> iter 77000, loss: 0.525744
 >> iter 78000, loss: 0.508507
 >> iter 79000, loss: 0.515944
 >> iter 80000, loss: 0.555115
   Number of active neurons: 4
 >> iter 81000, loss: 0.604162
 >> iter 82000, loss: 0.508783
 >> iter 83000, loss: 0.602700
 >> iter 84000, loss: 0.675238
 >> iter 85000, loss: 0.600417
 >> iter 86000, loss: 0.761598
 >> iter 87000, loss: 0.759671
 >> iter 88000, loss: 0.719439
 >> iter 89000, loss: 0.589465
 >> iter 90000, loss: 0.548396
   Number of active neurons: 4
 >> iter 91000, loss: 0.470591
 >> iter 92000, loss: 0.778848
 >> iter 93000, loss: 0.527103
 >> iter 94000, loss: 0.644013
 >> iter 95000, loss: 0.502704
 >> iter 96000, loss: 0.326407
 >> iter 97000, loss: 0.356148
 >> iter 98000, loss: 0.460704
 >> iter 99000, loss: 0.432633
 >> iter 100000, loss: 0.378962
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 17.275823
 >> iter 2000, loss: 10.819376
 >> iter 3000, loss: 6.750144
 >> iter 4000, loss: 3.646758
 >> iter 5000, loss: 2.252446
 >> iter 6000, loss: 1.379128
 >> iter 7000, loss: 1.006365
 >> iter 8000, loss: 0.895497
 >> iter 9000, loss: 0.640940
 >> iter 10000, loss: 0.434057
   Number of active neurons: 5
 >> iter 11000, loss: 0.362112
 >> iter 12000, loss: 0.274539
 >> iter 13000, loss: 0.283785
 >> iter 14000, loss: 0.359692
 >> iter 15000, loss: 0.398255
 >> iter 16000, loss: 0.460569
 >> iter 17000, loss: 0.334421
 >> iter 18000, loss: 0.364534
 >> iter 19000, loss: 0.385392
 >> iter 20000, loss: 0.355535
   Number of active neurons: 5
 >> iter 21000, loss: 0.320870
 >> iter 22000, loss: 0.254856
 >> iter 23000, loss: 0.299937
 >> iter 24000, loss: 0.399024
 >> iter 25000, loss: 0.365200
 >> iter 26000, loss: 0.435880
 >> iter 27000, loss: 0.378729
 >> iter 28000, loss: 0.460963
 >> iter 29000, loss: 0.335189
 >> iter 30000, loss: 0.334012
   Number of active neurons: 5
 >> iter 31000, loss: 0.508097
 >> iter 32000, loss: 0.457053
 >> iter 33000, loss: 0.379987
 >> iter 34000, loss: 0.488454
 >> iter 35000, loss: 0.389344
 >> iter 36000, loss: 0.304444
 >> iter 37000, loss: 0.340464
 >> iter 38000, loss: 0.385929
 >> iter 39000, loss: 0.419557
 >> iter 40000, loss: 0.462826
   Number of active neurons: 5
 >> iter 41000, loss: 0.558642
 >> iter 42000, loss: 0.371309
 >> iter 43000, loss: 0.488536
 >> iter 44000, loss: 0.576041
 >> iter 45000, loss: 0.561190
 >> iter 46000, loss: 0.557774
 >> iter 47000, loss: 0.490161
 >> iter 48000, loss: 0.479699
 >> iter 49000, loss: 0.536542
 >> iter 50000, loss: 0.418829
   Number of active neurons: 5
 >> iter 51000, loss: 0.500452
 >> iter 52000, loss: 0.520942
 >> iter 53000, loss: 0.481087
 >> iter 54000, loss: 0.490806
 >> iter 55000, loss: 0.450059
 >> iter 56000, loss: 0.473121
 >> iter 57000, loss: 0.409823
 >> iter 58000, loss: 0.494872
 >> iter 59000, loss: 0.406895
 >> iter 60000, loss: 0.431225
   Number of active neurons: 5
 >> iter 61000, loss: 0.478907
 >> iter 62000, loss: 0.356040
 >> iter 63000, loss: 0.407048
 >> iter 64000, loss: 0.332787
 >> iter 65000, loss: 0.381018
 >> iter 66000, loss: 0.341453
 >> iter 67000, loss: 0.409674
 >> iter 68000, loss: 0.590324
 >> iter 69000, loss: 0.477602
 >> iter 70000, loss: 0.433025
   Number of active neurons: 5
 >> iter 71000, loss: 0.726610
 >> iter 72000, loss: 0.610777
 >> iter 73000, loss: 0.500351
 >> iter 74000, loss: 0.396295
 >> iter 75000, loss: 0.513127
 >> iter 76000, loss: 0.487779
 >> iter 77000, loss: 0.345375
 >> iter 78000, loss: 0.319983
 >> iter 79000, loss: 0.382551
 >> iter 80000, loss: 0.288758
   Number of active neurons: 5
 >> iter 81000, loss: 0.364487
 >> iter 82000, loss: 0.550833
 >> iter 83000, loss: 0.622068
 >> iter 84000, loss: 0.481238
 >> iter 85000, loss: 0.456372
 >> iter 86000, loss: 0.415153
 >> iter 87000, loss: 0.397496
 >> iter 88000, loss: 0.430311
 >> iter 89000, loss: 0.391210
 >> iter 90000, loss: 0.317249
   Number of active neurons: 5
 >> iter 91000, loss: 0.476648
 >> iter 92000, loss: 0.364460
 >> iter 93000, loss: 0.382664
 >> iter 94000, loss: 0.443303
 >> iter 95000, loss: 0.433466
 >> iter 96000, loss: 0.465104
 >> iter 97000, loss: 0.647477
 >> iter 98000, loss: 0.497129
 >> iter 99000, loss: 0.504305
 >> iter 100000, loss: 0.443243
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 17.520298
 >> iter 2000, loss: 11.374928
 >> iter 3000, loss: 8.228262
 >> iter 4000, loss: 4.980078
 >> iter 5000, loss: 2.859323
 >> iter 6000, loss: 1.784863
 >> iter 7000, loss: 1.137882
 >> iter 8000, loss: 0.853389
 >> iter 9000, loss: 0.818839
 >> iter 10000, loss: 0.735883
   Number of active neurons: 6
 >> iter 11000, loss: 0.566457
 >> iter 12000, loss: 0.621898
 >> iter 13000, loss: 0.548618
 >> iter 14000, loss: 0.678044
 >> iter 15000, loss: 0.617446
 >> iter 16000, loss: 0.558215
 >> iter 17000, loss: 0.590815
 >> iter 18000, loss: 0.689772
 >> iter 19000, loss: 0.502840
 >> iter 20000, loss: 0.440131
   Number of active neurons: 6
 >> iter 21000, loss: 0.403485
 >> iter 22000, loss: 0.405033
 >> iter 23000, loss: 0.446845
 >> iter 24000, loss: 0.463282
 >> iter 25000, loss: 0.391718
 >> iter 26000, loss: 0.303296
 >> iter 27000, loss: 0.389987
 >> iter 28000, loss: 0.386727
 >> iter 29000, loss: 0.408425
 >> iter 30000, loss: 0.422453
   Number of active neurons: 6
 >> iter 31000, loss: 0.323569
 >> iter 32000, loss: 0.343775
 >> iter 33000, loss: 0.303311
 >> iter 34000, loss: 0.424066
 >> iter 35000, loss: 0.404845
 >> iter 36000, loss: 0.425579
 >> iter 37000, loss: 0.389348
 >> iter 38000, loss: 0.438881
 >> iter 39000, loss: 0.460081
 >> iter 40000, loss: 0.383844
   Number of active neurons: 5
 >> iter 41000, loss: 0.366078
 >> iter 42000, loss: 0.468814
 >> iter 43000, loss: 0.461392
 >> iter 44000, loss: 0.666435
 >> iter 45000, loss: 0.502263
 >> iter 46000, loss: 0.378201
 >> iter 47000, loss: 0.450419
 >> iter 48000, loss: 0.497891
 >> iter 49000, loss: 0.409186
 >> iter 50000, loss: 0.431599
   Number of active neurons: 5
 >> iter 51000, loss: 0.343518
 >> iter 52000, loss: 0.371608
 >> iter 53000, loss: 0.404754
 >> iter 54000, loss: 0.468523
 >> iter 55000, loss: 0.527557
 >> iter 56000, loss: 0.528816
 >> iter 57000, loss: 0.372455
 >> iter 58000, loss: 0.382262
 >> iter 59000, loss: 0.464689
 >> iter 60000, loss: 0.475207
   Number of active neurons: 5
 >> iter 61000, loss: 0.423134
 >> iter 62000, loss: 0.531905
 >> iter 63000, loss: 0.488721
 >> iter 64000, loss: 0.544563
 >> iter 65000, loss: 0.467437
 >> iter 66000, loss: 0.460726
 >> iter 67000, loss: 0.413418
 >> iter 68000, loss: 0.447215
 >> iter 69000, loss: 0.471323
 >> iter 70000, loss: 0.376457
   Number of active neurons: 4
 >> iter 71000, loss: 0.340237
 >> iter 72000, loss: 0.354290
 >> iter 73000, loss: 0.462047
 >> iter 74000, loss: 0.439381
 >> iter 75000, loss: 0.391642
 >> iter 76000, loss: 0.389399
 >> iter 77000, loss: 0.384408
 >> iter 78000, loss: 0.465968
 >> iter 79000, loss: 0.591515
 >> iter 80000, loss: 0.454127
   Number of active neurons: 4
 >> iter 81000, loss: 0.421955
 >> iter 82000, loss: 0.407759
 >> iter 83000, loss: 0.355853
 >> iter 84000, loss: 0.284668
 >> iter 85000, loss: 0.311402
 >> iter 86000, loss: 0.299313
 >> iter 87000, loss: 0.336425
 >> iter 88000, loss: 0.299828
 >> iter 89000, loss: 0.346421
 >> iter 90000, loss: 0.269039
   Number of active neurons: 4
 >> iter 91000, loss: 0.324730
 >> iter 92000, loss: 0.198109
 >> iter 93000, loss: 0.188351
 >> iter 94000, loss: 0.268123
 >> iter 95000, loss: 0.320592
 >> iter 96000, loss: 0.378231
 >> iter 97000, loss: 0.427321
 >> iter 98000, loss: 0.279949
 >> iter 99000, loss: 0.293217
 >> iter 100000, loss: 0.215499
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.035327
 >> iter 2000, loss: 12.579120
 >> iter 3000, loss: 10.693655
 >> iter 4000, loss: 9.542601
 >> iter 5000, loss: 7.543609
 >> iter 6000, loss: 3.885055
 >> iter 7000, loss: 1.939695
 >> iter 8000, loss: 1.204175
 >> iter 9000, loss: 0.809986
 >> iter 10000, loss: 0.578011
   Number of active neurons: 3
 >> iter 11000, loss: 0.461103
 >> iter 12000, loss: 0.411300
 >> iter 13000, loss: 0.275730
 >> iter 14000, loss: 0.363298
 >> iter 15000, loss: 0.373117
 >> iter 16000, loss: 0.304827
 >> iter 17000, loss: 0.253584
 >> iter 18000, loss: 0.333362
 >> iter 19000, loss: 0.340613
 >> iter 20000, loss: 0.399489
   Number of active neurons: 3
 >> iter 21000, loss: 0.274500
 >> iter 22000, loss: 0.273983
 >> iter 23000, loss: 0.301220
 >> iter 24000, loss: 0.253821
 >> iter 25000, loss: 0.307756
 >> iter 26000, loss: 0.382443
 >> iter 27000, loss: 0.306035
 >> iter 28000, loss: 0.204023
 >> iter 29000, loss: 0.271129
 >> iter 30000, loss: 0.328447
   Number of active neurons: 3
 >> iter 31000, loss: 0.428720
 >> iter 32000, loss: 0.354534
 >> iter 33000, loss: 0.354415
 >> iter 34000, loss: 0.382619
 >> iter 35000, loss: 0.311666
 >> iter 36000, loss: 0.240147
 >> iter 37000, loss: 0.300563
 >> iter 38000, loss: 0.384204
 >> iter 39000, loss: 0.299791
 >> iter 40000, loss: 0.335843
   Number of active neurons: 3
 >> iter 41000, loss: 0.382993
 >> iter 42000, loss: 0.346101
 >> iter 43000, loss: 0.495931
 >> iter 44000, loss: 0.416194
 >> iter 45000, loss: 0.434370
 >> iter 46000, loss: 0.376172
 >> iter 47000, loss: 0.350109
 >> iter 48000, loss: 0.374690
 >> iter 49000, loss: 0.346414
 >> iter 50000, loss: 0.251812
   Number of active neurons: 3
 >> iter 51000, loss: 0.255776
 >> iter 52000, loss: 0.274876
 >> iter 53000, loss: 0.318316
 >> iter 54000, loss: 0.405501
 >> iter 55000, loss: 0.379910
 >> iter 56000, loss: 0.440756
 >> iter 57000, loss: 0.369158
 >> iter 58000, loss: 0.316135
 >> iter 59000, loss: 0.207102
 >> iter 60000, loss: 0.369654
   Number of active neurons: 3
 >> iter 61000, loss: 0.454701
 >> iter 62000, loss: 0.364704
 >> iter 63000, loss: 0.334201
 >> iter 64000, loss: 0.513789
 >> iter 65000, loss: 0.409346
 >> iter 66000, loss: 0.329602
 >> iter 67000, loss: 0.336456
 >> iter 68000, loss: 0.321447
 >> iter 69000, loss: 0.430828
 >> iter 70000, loss: 0.405336
   Number of active neurons: 3
 >> iter 71000, loss: 0.391655
 >> iter 72000, loss: 0.437451
 >> iter 73000, loss: 0.472061
 >> iter 74000, loss: 0.479000
 >> iter 75000, loss: 0.487541
 >> iter 76000, loss: 0.453783
 >> iter 77000, loss: 0.390560
 >> iter 78000, loss: 0.479690
 >> iter 79000, loss: 0.485693
 >> iter 80000, loss: 0.452144
   Number of active neurons: 3
 >> iter 81000, loss: 0.410543
 >> iter 82000, loss: 0.462875
 >> iter 83000, loss: 0.472458
 >> iter 84000, loss: 0.363320
 >> iter 85000, loss: 0.319745
 >> iter 86000, loss: 0.411515
 >> iter 87000, loss: 0.356845
 >> iter 88000, loss: 0.358980
 >> iter 89000, loss: 0.416258
 >> iter 90000, loss: 0.430403
   Number of active neurons: 3
 >> iter 91000, loss: 0.354831
 >> iter 92000, loss: 0.390941
 >> iter 93000, loss: 0.491179
 >> iter 94000, loss: 0.521619
 >> iter 95000, loss: 0.459840
 >> iter 96000, loss: 0.404874
 >> iter 97000, loss: 0.417260
 >> iter 98000, loss: 0.419093
 >> iter 99000, loss: 0.361571
 >> iter 100000, loss: 0.330857
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.987728
 >> iter 2000, loss: 12.667093
 >> iter 3000, loss: 10.105899
 >> iter 4000, loss: 7.980204
 >> iter 5000, loss: 6.101679
 >> iter 6000, loss: 4.443172
 >> iter 7000, loss: 2.941652
 >> iter 8000, loss: 1.744710
 >> iter 9000, loss: 1.070612
 >> iter 10000, loss: 0.798970
   Number of active neurons: 5
 >> iter 11000, loss: 0.740417
 >> iter 12000, loss: 0.700181
 >> iter 13000, loss: 0.562770
 >> iter 14000, loss: 0.612159
 >> iter 15000, loss: 0.645079
 >> iter 16000, loss: 0.517174
 >> iter 17000, loss: 0.428465
 >> iter 18000, loss: 0.442053
 >> iter 19000, loss: 0.538493
 >> iter 20000, loss: 0.560903
   Number of active neurons: 5
 >> iter 21000, loss: 0.602999
 >> iter 22000, loss: 0.520583
 >> iter 23000, loss: 0.500940
 >> iter 24000, loss: 0.461193
 >> iter 25000, loss: 0.370473
 >> iter 26000, loss: 0.426552
 >> iter 27000, loss: 0.292789
 >> iter 28000, loss: 0.334531
 >> iter 29000, loss: 0.380674
 >> iter 30000, loss: 0.326343
   Number of active neurons: 4
 >> iter 31000, loss: 0.423856
 >> iter 32000, loss: 0.443476
 >> iter 33000, loss: 0.356841
 >> iter 34000, loss: 0.386844
 >> iter 35000, loss: 0.356105
 >> iter 36000, loss: 0.424303
 >> iter 37000, loss: 0.390352
 >> iter 38000, loss: 0.489901
 >> iter 39000, loss: 0.462821
 >> iter 40000, loss: 0.376839
   Number of active neurons: 4
 >> iter 41000, loss: 0.395899
 >> iter 42000, loss: 0.499343
 >> iter 43000, loss: 0.347619
 >> iter 44000, loss: 0.338989
 >> iter 45000, loss: 0.401554
 >> iter 46000, loss: 0.329702
 >> iter 47000, loss: 0.470821
 >> iter 48000, loss: 0.400909
 >> iter 49000, loss: 0.418079
 >> iter 50000, loss: 0.444497
   Number of active neurons: 4
 >> iter 51000, loss: 0.596733
 >> iter 52000, loss: 0.448848
 >> iter 53000, loss: 0.532947
 >> iter 54000, loss: 0.519077
 >> iter 55000, loss: 0.443677
 >> iter 56000, loss: 0.405719
 >> iter 57000, loss: 0.621088
 >> iter 58000, loss: 0.462899
 >> iter 59000, loss: 0.633669
 >> iter 60000, loss: 0.438449
   Number of active neurons: 4
 >> iter 61000, loss: 0.397939
 >> iter 62000, loss: 0.523681
 >> iter 63000, loss: 0.549366
 >> iter 64000, loss: 0.404842
 >> iter 65000, loss: 0.351375
 >> iter 66000, loss: 0.468398
 >> iter 67000, loss: 0.362150
 >> iter 68000, loss: 0.407990
 >> iter 69000, loss: 0.381386
 >> iter 70000, loss: 0.319345
   Number of active neurons: 4
 >> iter 71000, loss: 0.461293
 >> iter 72000, loss: 0.406075
 >> iter 73000, loss: 0.509213
 >> iter 74000, loss: 0.442662
 >> iter 75000, loss: 0.350407
 >> iter 76000, loss: 0.328919
 >> iter 77000, loss: 0.306052
 >> iter 78000, loss: 0.335466
 >> iter 79000, loss: 0.572261
 >> iter 80000, loss: 0.526552
   Number of active neurons: 4
 >> iter 81000, loss: 0.383342
 >> iter 82000, loss: 0.372655
 >> iter 83000, loss: 0.419965
 >> iter 84000, loss: 0.546007
 >> iter 85000, loss: 0.475551
 >> iter 86000, loss: 0.397095
 >> iter 87000, loss: 0.427005
 >> iter 88000, loss: 0.408429
 >> iter 89000, loss: 0.432172
 >> iter 90000, loss: 0.531831
   Number of active neurons: 4
 >> iter 91000, loss: 0.503188
 >> iter 92000, loss: 0.405689
 >> iter 93000, loss: 0.622747
 >> iter 94000, loss: 0.536050
 >> iter 95000, loss: 0.434345
 >> iter 96000, loss: 0.380376
 >> iter 97000, loss: 0.430257
 >> iter 98000, loss: 0.391177
 >> iter 99000, loss: 0.515018
 >> iter 100000, loss: 0.379767
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.669766
 >> iter 2000, loss: 11.021986
 >> iter 3000, loss: 8.584812
 >> iter 4000, loss: 6.467699
 >> iter 5000, loss: 3.964596
 >> iter 6000, loss: 2.213091
 >> iter 7000, loss: 1.497987
 >> iter 8000, loss: 1.132111
 >> iter 9000, loss: 1.047772
 >> iter 10000, loss: 0.682044
   Number of active neurons: 5
 >> iter 11000, loss: 0.584844
 >> iter 12000, loss: 0.731571
 >> iter 13000, loss: 0.620569
 >> iter 14000, loss: 0.686397
 >> iter 15000, loss: 0.755856
 >> iter 16000, loss: 0.548080
 >> iter 17000, loss: 0.457677
 >> iter 18000, loss: 0.472097
 >> iter 19000, loss: 0.511519
 >> iter 20000, loss: 0.523712
   Number of active neurons: 5
 >> iter 21000, loss: 0.531378
 >> iter 22000, loss: 0.483356
 >> iter 23000, loss: 0.434937
 >> iter 24000, loss: 0.389176
 >> iter 25000, loss: 0.406388
 >> iter 26000, loss: 0.322402
 >> iter 27000, loss: 0.603795
 >> iter 28000, loss: 0.742806
 >> iter 29000, loss: 0.598153
 >> iter 30000, loss: 0.568257
   Number of active neurons: 5
 >> iter 31000, loss: 0.481178
 >> iter 32000, loss: 0.582957
 >> iter 33000, loss: 0.522506
 >> iter 34000, loss: 0.613253
 >> iter 35000, loss: 0.567781
 >> iter 36000, loss: 0.461217
 >> iter 37000, loss: 0.369637
 >> iter 38000, loss: 0.626560
 >> iter 39000, loss: 0.422753
 >> iter 40000, loss: 0.502536
   Number of active neurons: 5
 >> iter 41000, loss: 0.581506
 >> iter 42000, loss: 0.628495
 >> iter 43000, loss: 0.555702
 >> iter 44000, loss: 0.517346
 >> iter 45000, loss: 0.341772
 >> iter 46000, loss: 0.316419
 >> iter 47000, loss: 0.273805
 >> iter 48000, loss: 0.372146
 >> iter 49000, loss: 0.435429
 >> iter 50000, loss: 0.470553
   Number of active neurons: 5
 >> iter 51000, loss: 0.606237
 >> iter 52000, loss: 0.456101
 >> iter 53000, loss: 0.563540
 >> iter 54000, loss: 0.500247
 >> iter 55000, loss: 0.489381
 >> iter 56000, loss: 0.443265
 >> iter 57000, loss: 0.425689
 >> iter 58000, loss: 0.442498
 >> iter 59000, loss: 0.460131
 >> iter 60000, loss: 0.460277
   Number of active neurons: 5
 >> iter 61000, loss: 0.488616
 >> iter 62000, loss: 0.356610
 >> iter 63000, loss: 0.372499
 >> iter 64000, loss: 0.595969
 >> iter 65000, loss: 0.498527
 >> iter 66000, loss: 0.483000
 >> iter 67000, loss: 0.549268
 >> iter 68000, loss: 0.419262
 >> iter 69000, loss: 0.358316
 >> iter 70000, loss: 0.458701
   Number of active neurons: 5
 >> iter 71000, loss: 0.579930
 >> iter 72000, loss: 0.426437
 >> iter 73000, loss: 0.414817
 >> iter 74000, loss: 0.289203
 >> iter 75000, loss: 0.347691
 >> iter 76000, loss: 0.404375
 >> iter 77000, loss: 0.454058
 >> iter 78000, loss: 0.465383
 >> iter 79000, loss: 0.471039
 >> iter 80000, loss: 0.487008
   Number of active neurons: 5
 >> iter 81000, loss: 0.607054
 >> iter 82000, loss: 0.568008
 >> iter 83000, loss: 0.538197
 >> iter 84000, loss: 0.418495
 >> iter 85000, loss: 0.597392
 >> iter 86000, loss: 0.447639
 >> iter 87000, loss: 0.488917
 >> iter 88000, loss: 0.460440
 >> iter 89000, loss: 0.430570
 >> iter 90000, loss: 0.446947
   Number of active neurons: 5
 >> iter 91000, loss: 0.550386
 >> iter 92000, loss: 0.527663
 >> iter 93000, loss: 0.435139
 >> iter 94000, loss: 0.512900
 >> iter 95000, loss: 0.444429
 >> iter 96000, loss: 0.342820
 >> iter 97000, loss: 0.448208
 >> iter 98000, loss: 0.544378
 >> iter 99000, loss: 0.369541
 >> iter 100000, loss: 0.647551
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.073768
 >> iter 2000, loss: 12.484648
 >> iter 3000, loss: 9.325658
 >> iter 4000, loss: 7.117658
 >> iter 5000, loss: 5.787142
 >> iter 6000, loss: 4.746735
 >> iter 7000, loss: 4.376382
 >> iter 8000, loss: 3.980518
 >> iter 9000, loss: 3.898443
 >> iter 10000, loss: 3.771635
   Number of active neurons: 3
 >> iter 11000, loss: 3.593023
 >> iter 12000, loss: 3.480362
 >> iter 13000, loss: 3.483851
 >> iter 14000, loss: 3.483803
 >> iter 15000, loss: 3.512621
 >> iter 16000, loss: 3.470917
 >> iter 17000, loss: 3.541716
 >> iter 18000, loss: 3.445254
 >> iter 19000, loss: 3.383513
 >> iter 20000, loss: 3.270638
   Number of active neurons: 3
 >> iter 21000, loss: 3.375410
 >> iter 22000, loss: 3.373730
 >> iter 23000, loss: 3.362375
 >> iter 24000, loss: 3.259188
 >> iter 25000, loss: 3.294081
   Number of active neurons: 3
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 26000, loss: 3.502427
 >> iter 27000, loss: 3.392166
 >> iter 28000, loss: 3.267496
 >> iter 29000, loss: 3.307996
 >> iter 30000, loss: 3.244024
   Number of active neurons: 5
 >> iter 31000, loss: 3.314720
 >> iter 32000, loss: 3.274576
 >> iter 33000, loss: 3.286577
 >> iter 34000, loss: 3.228130
 >> iter 35000, loss: 3.333619
   Number of active neurons: 3
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 36000, loss: 3.348041
 >> iter 37000, loss: 3.332717
 >> iter 38000, loss: 3.241249
 >> iter 39000, loss: 3.381645
 >> iter 40000, loss: 3.358893
   Number of active neurons: 3
   SHOCK
   Setting new limit to 275000.0 iters...
   Number of active neurons: 3
 >> iter 41000, loss: 3.620093
 >> iter 42000, loss: 3.446617
 >> iter 43000, loss: 3.406817
 >> iter 44000, loss: 3.397521
 >> iter 45000, loss: 3.401089
   Number of active neurons: 5
   SHOCK
   Setting new limit to 287500.0 iters...
 >> iter 46000, loss: 3.481928
 >> iter 47000, loss: 3.452938
 >> iter 48000, loss: 3.352262
 >> iter 49000, loss: 3.383374
 >> iter 50000, loss: 3.263605
   Number of active neurons: 6
 >> iter 51000, loss: 3.433841
 >> iter 52000, loss: 2.842975
 >> iter 53000, loss: 1.675661
 >> iter 54000, loss: 0.972232
 >> iter 55000, loss: 0.540392
 >> iter 56000, loss: 0.430451
 >> iter 57000, loss: 0.389688
 >> iter 58000, loss: 0.354968
 >> iter 59000, loss: 0.357287
 >> iter 60000, loss: 0.318741
   Number of active neurons: 6
 >> iter 61000, loss: 0.351393
 >> iter 62000, loss: 0.296535
 >> iter 63000, loss: 0.219236
 >> iter 64000, loss: 0.323022
 >> iter 65000, loss: 0.253547
 >> iter 66000, loss: 0.326044
 >> iter 67000, loss: 0.243890
 >> iter 68000, loss: 0.324828
 >> iter 69000, loss: 0.442003
 >> iter 70000, loss: 0.325046
   Number of active neurons: 6
 >> iter 71000, loss: 0.237308
 >> iter 72000, loss: 0.372942
 >> iter 73000, loss: 0.311756
 >> iter 74000, loss: 0.314158
 >> iter 75000, loss: 0.270636
 >> iter 76000, loss: 0.273814
 >> iter 77000, loss: 0.332491
 >> iter 78000, loss: 0.276941
 >> iter 79000, loss: 0.312499
 >> iter 80000, loss: 0.308982
   Number of active neurons: 6
 >> iter 81000, loss: 0.309853
 >> iter 82000, loss: 0.279196
 >> iter 83000, loss: 0.303093
 >> iter 84000, loss: 0.340761
 >> iter 85000, loss: 0.345974
 >> iter 86000, loss: 0.345212
 >> iter 87000, loss: 0.299282
 >> iter 88000, loss: 0.267104
 >> iter 89000, loss: 0.336013
 >> iter 90000, loss: 0.281504
   Number of active neurons: 6
 >> iter 91000, loss: 0.368538
 >> iter 92000, loss: 0.398097
 >> iter 93000, loss: 0.281051
 >> iter 94000, loss: 0.321650
 >> iter 95000, loss: 0.373033
 >> iter 96000, loss: 0.308697
 >> iter 97000, loss: 0.345004
 >> iter 98000, loss: 0.444930
 >> iter 99000, loss: 0.389566
 >> iter 100000, loss: 0.336668
   Number of active neurons: 5
 >> iter 101000, loss: 0.342086
 >> iter 102000, loss: 0.379003
 >> iter 103000, loss: 0.350139
 >> iter 104000, loss: 0.485788
 >> iter 105000, loss: 0.461823
 >> iter 106000, loss: 0.391091
 >> iter 107000, loss: 0.259841
 >> iter 108000, loss: 0.216369
 >> iter 109000, loss: 0.225703
 >> iter 110000, loss: 0.317935
   Number of active neurons: 5
 >> iter 111000, loss: 0.259853
 >> iter 112000, loss: 0.334199
 >> iter 113000, loss: 0.390647
 >> iter 114000, loss: 0.363108
 >> iter 115000, loss: 0.341997
 >> iter 116000, loss: 0.323513
 >> iter 117000, loss: 0.305422
 >> iter 118000, loss: 0.328321
 >> iter 119000, loss: 0.305806
 >> iter 120000, loss: 0.254464
   Number of active neurons: 5
 >> iter 121000, loss: 0.303621
 >> iter 122000, loss: 0.365688
 >> iter 123000, loss: 0.270473
 >> iter 124000, loss: 0.237370
 >> iter 125000, loss: 0.352749
 >> iter 126000, loss: 0.380253
 >> iter 127000, loss: 0.303014
 >> iter 128000, loss: 0.385528
 >> iter 129000, loss: 0.349086
 >> iter 130000, loss: 0.307698
   Number of active neurons: 5
 >> iter 131000, loss: 0.344681
 >> iter 132000, loss: 0.308444
 >> iter 133000, loss: 0.280899
 >> iter 134000, loss: 0.255956
 >> iter 135000, loss: 0.268943
 >> iter 136000, loss: 0.387566
 >> iter 137000, loss: 0.334317
 >> iter 138000, loss: 0.356910
 >> iter 139000, loss: 0.412782
 >> iter 140000, loss: 0.387916
   Number of active neurons: 5
 >> iter 141000, loss: 0.277838
 >> iter 142000, loss: 0.333056
 >> iter 143000, loss: 0.325701
 >> iter 144000, loss: 0.287368
 >> iter 145000, loss: 0.322154
 >> iter 146000, loss: 0.339938
 >> iter 147000, loss: 0.402735
 >> iter 148000, loss: 0.430031
 >> iter 149000, loss: 0.433801
 >> iter 150000, loss: 0.285491
   Number of active neurons: 5
 >> iter 151000, loss: 0.301318
 >> iter 152000, loss: 0.333289
 >> iter 153000, loss: 0.237669
 >> iter 154000, loss: 0.263086
 >> iter 155000, loss: 0.252221
 >> iter 156000, loss: 0.263413
 >> iter 157000, loss: 0.392385
 >> iter 158000, loss: 0.354253
 >> iter 159000, loss: 0.279373
 >> iter 160000, loss: 0.476018
   Number of active neurons: 5
 >> iter 161000, loss: 0.351179
 >> iter 162000, loss: 0.313366
 >> iter 163000, loss: 0.369877
 >> iter 164000, loss: 0.261901
 >> iter 165000, loss: 0.240746
 >> iter 166000, loss: 0.314765
 >> iter 167000, loss: 0.251463
 >> iter 168000, loss: 0.281390
 >> iter 169000, loss: 0.446158
 >> iter 170000, loss: 0.378986
   Number of active neurons: 5
 >> iter 171000, loss: 0.372239
 >> iter 172000, loss: 0.382859
 >> iter 173000, loss: 0.309377
 >> iter 174000, loss: 0.262139
 >> iter 175000, loss: 0.289050
 >> iter 176000, loss: 0.257742
 >> iter 177000, loss: 0.325578
 >> iter 178000, loss: 0.337288
 >> iter 179000, loss: 0.336571
 >> iter 180000, loss: 0.458406
   Number of active neurons: 5
 >> iter 181000, loss: 0.418569
 >> iter 182000, loss: 0.411245
 >> iter 183000, loss: 0.316035
 >> iter 184000, loss: 0.324691
 >> iter 185000, loss: 0.253618
 >> iter 186000, loss: 0.301511
 >> iter 187000, loss: 0.262721
 >> iter 188000, loss: 0.269533
 >> iter 189000, loss: 0.294971
 >> iter 190000, loss: 0.302034
   Number of active neurons: 5
 >> iter 191000, loss: 0.244005
 >> iter 192000, loss: 0.293149
 >> iter 193000, loss: 0.288088
 >> iter 194000, loss: 0.294843
 >> iter 195000, loss: 0.265780
 >> iter 196000, loss: 0.265809
 >> iter 197000, loss: 0.338556
 >> iter 198000, loss: 0.324846
 >> iter 199000, loss: 0.282366
 >> iter 200000, loss: 0.301268
   Number of active neurons: 5
 >> iter 201000, loss: 0.337423
 >> iter 202000, loss: 0.372774
 >> iter 203000, loss: 0.320432
 >> iter 204000, loss: 0.282948
 >> iter 205000, loss: 0.266694
 >> iter 206000, loss: 0.292095
 >> iter 207000, loss: 0.256726
 >> iter 208000, loss: 0.285381
 >> iter 209000, loss: 0.291125
 >> iter 210000, loss: 0.232788
   Number of active neurons: 5
 >> iter 211000, loss: 0.254094
 >> iter 212000, loss: 0.410412
 >> iter 213000, loss: 0.326160
 >> iter 214000, loss: 0.301729
 >> iter 215000, loss: 0.275634
 >> iter 216000, loss: 0.358535
 >> iter 217000, loss: 0.302870
 >> iter 218000, loss: 0.387667
 >> iter 219000, loss: 0.342260
 >> iter 220000, loss: 0.355027
   Number of active neurons: 5
 >> iter 221000, loss: 0.334118
 >> iter 222000, loss: 0.279349
 >> iter 223000, loss: 0.297344
 >> iter 224000, loss: 0.345449
 >> iter 225000, loss: 0.313397
 >> iter 226000, loss: 0.306020
 >> iter 227000, loss: 0.377973
 >> iter 228000, loss: 0.333239
 >> iter 229000, loss: 0.308477
 >> iter 230000, loss: 0.280863
   Number of active neurons: 5
 >> iter 231000, loss: 0.370142
 >> iter 232000, loss: 0.307603
 >> iter 233000, loss: 0.338157
 >> iter 234000, loss: 0.242742
 >> iter 235000, loss: 0.369735
 >> iter 236000, loss: 0.322489
 >> iter 237000, loss: 0.337367
 >> iter 238000, loss: 0.326634
 >> iter 239000, loss: 0.335723
 >> iter 240000, loss: 0.337372
   Number of active neurons: 5
 >> iter 241000, loss: 0.305481
 >> iter 242000, loss: 0.284236
 >> iter 243000, loss: 0.301750
 >> iter 244000, loss: 0.217846
 >> iter 245000, loss: 0.341666
 >> iter 246000, loss: 0.287986
 >> iter 247000, loss: 0.301207
 >> iter 248000, loss: 0.260944
 >> iter 249000, loss: 0.256661
 >> iter 250000, loss: 0.249069
   Number of active neurons: 5
 >> iter 251000, loss: 0.312821
 >> iter 252000, loss: 0.231985
 >> iter 253000, loss: 0.306357
 >> iter 254000, loss: 0.356224
 >> iter 255000, loss: 0.305504
 >> iter 256000, loss: 0.302765
 >> iter 257000, loss: 0.345880
 >> iter 258000, loss: 0.310057
 >> iter 259000, loss: 0.378581
 >> iter 260000, loss: 0.340511
   Number of active neurons: 5
 >> iter 261000, loss: 0.349140
 >> iter 262000, loss: 0.357386
 >> iter 263000, loss: 0.342475
 >> iter 264000, loss: 0.317225
 >> iter 265000, loss: 0.256635
 >> iter 266000, loss: 0.248302
 >> iter 267000, loss: 0.253395
 >> iter 268000, loss: 0.303767
 >> iter 269000, loss: 0.417723
 >> iter 270000, loss: 0.359124
   Number of active neurons: 5
 >> iter 271000, loss: 0.317316
 >> iter 272000, loss: 0.291421
 >> iter 273000, loss: 0.220954
 >> iter 274000, loss: 0.243924
 >> iter 275000, loss: 0.317626
 >> iter 276000, loss: 0.459372
 >> iter 277000, loss: 0.350638
 >> iter 278000, loss: 0.328476
 >> iter 279000, loss: 0.351622
 >> iter 280000, loss: 0.328704
   Number of active neurons: 5
 >> iter 281000, loss: 0.405145
 >> iter 282000, loss: 0.405474
 >> iter 283000, loss: 0.352883
 >> iter 284000, loss: 0.249427
 >> iter 285000, loss: 0.270805
 >> iter 286000, loss: 0.249304
 >> iter 287000, loss: 0.324548
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.978551
 >> iter 2000, loss: 13.506081
 >> iter 3000, loss: 11.549128
 >> iter 4000, loss: 8.776249
 >> iter 5000, loss: 7.576964
 >> iter 6000, loss: 6.776551
 >> iter 7000, loss: 6.299661
 >> iter 8000, loss: 5.685866
 >> iter 9000, loss: 6.276241
 >> iter 10000, loss: 5.886698
   Number of active neurons: 5
 >> iter 11000, loss: 3.758651
 >> iter 12000, loss: 2.045408
 >> iter 13000, loss: 1.124919
 >> iter 14000, loss: 0.681548
 >> iter 15000, loss: 0.518721
 >> iter 16000, loss: 0.438338
 >> iter 17000, loss: 0.430390
 >> iter 18000, loss: 0.458955
 >> iter 19000, loss: 0.398571
 >> iter 20000, loss: 0.345942
   Number of active neurons: 5
 >> iter 21000, loss: 0.345488
 >> iter 22000, loss: 0.259886
 >> iter 23000, loss: 0.433171
 >> iter 24000, loss: 0.424431
 >> iter 25000, loss: 0.408322
 >> iter 26000, loss: 0.377756
 >> iter 27000, loss: 0.525340
 >> iter 28000, loss: 0.475695
 >> iter 29000, loss: 0.425373
 >> iter 30000, loss: 0.422066
   Number of active neurons: 5
 >> iter 31000, loss: 0.453082
 >> iter 32000, loss: 0.524195
 >> iter 33000, loss: 0.323114
 >> iter 34000, loss: 0.371336
 >> iter 35000, loss: 0.406018
 >> iter 36000, loss: 0.479627
 >> iter 37000, loss: 0.314875
 >> iter 38000, loss: 0.323659
 >> iter 39000, loss: 0.369869
 >> iter 40000, loss: 0.369940
   Number of active neurons: 5
 >> iter 41000, loss: 0.558442
 >> iter 42000, loss: 0.441786
 >> iter 43000, loss: 0.407555
 >> iter 44000, loss: 0.562583
 >> iter 45000, loss: 0.456665
 >> iter 46000, loss: 0.370579
 >> iter 47000, loss: 0.297973
 >> iter 48000, loss: 0.441762
 >> iter 49000, loss: 0.372640
 >> iter 50000, loss: 0.411249
   Number of active neurons: 5
 >> iter 51000, loss: 0.327432
 >> iter 52000, loss: 0.414542
 >> iter 53000, loss: 0.323518
 >> iter 54000, loss: 0.387812
 >> iter 55000, loss: 0.495523
 >> iter 56000, loss: 0.423513
 >> iter 57000, loss: 0.364810
 >> iter 58000, loss: 0.375148
 >> iter 59000, loss: 0.520422
 >> iter 60000, loss: 0.339731
   Number of active neurons: 5
 >> iter 61000, loss: 0.373264
 >> iter 62000, loss: 0.454588
 >> iter 63000, loss: 0.421137
 >> iter 64000, loss: 0.459923
 >> iter 65000, loss: 0.514669
 >> iter 66000, loss: 0.584116
 >> iter 67000, loss: 0.550359
 >> iter 68000, loss: 0.554478
 >> iter 69000, loss: 0.504915
 >> iter 70000, loss: 0.412190
   Number of active neurons: 5
 >> iter 71000, loss: 0.376625
 >> iter 72000, loss: 0.517498
 >> iter 73000, loss: 0.402568
 >> iter 74000, loss: 0.345546
 >> iter 75000, loss: 0.397484
 >> iter 76000, loss: 0.406009
 >> iter 77000, loss: 0.540523
 >> iter 78000, loss: 0.611824
 >> iter 79000, loss: 0.607358
 >> iter 80000, loss: 0.407743
   Number of active neurons: 5
 >> iter 81000, loss: 0.388982
 >> iter 82000, loss: 0.377892
 >> iter 83000, loss: 0.442297
 >> iter 84000, loss: 0.453405
 >> iter 85000, loss: 0.455807
 >> iter 86000, loss: 0.330460
 >> iter 87000, loss: 0.384570
 >> iter 88000, loss: 0.441130
 >> iter 89000, loss: 0.394102
 >> iter 90000, loss: 0.376539
   Number of active neurons: 5
 >> iter 91000, loss: 0.442534
 >> iter 92000, loss: 0.499709
 >> iter 93000, loss: 0.583674
 >> iter 94000, loss: 0.494222
 >> iter 95000, loss: 0.454476
 >> iter 96000, loss: 0.444761
 >> iter 97000, loss: 0.599813
 >> iter 98000, loss: 0.637128
 >> iter 99000, loss: 0.578306
 >> iter 100000, loss: 0.464680
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.036278
 >> iter 2000, loss: 12.797533
 >> iter 3000, loss: 10.646239
 >> iter 4000, loss: 8.568517
 >> iter 5000, loss: 5.510183
 >> iter 6000, loss: 3.317069
 >> iter 7000, loss: 1.881621
 >> iter 8000, loss: 1.271809
 >> iter 9000, loss: 1.079044
 >> iter 10000, loss: 0.934566
   Number of active neurons: 6
 >> iter 11000, loss: 0.753629
 >> iter 12000, loss: 0.636040
 >> iter 13000, loss: 0.725075
 >> iter 14000, loss: 0.574616
 >> iter 15000, loss: 0.419374
 >> iter 16000, loss: 0.436634
 >> iter 17000, loss: 0.658009
 >> iter 18000, loss: 0.669514
 >> iter 19000, loss: 0.535793
 >> iter 20000, loss: 0.686735
   Number of active neurons: 6
 >> iter 21000, loss: 0.621590
 >> iter 22000, loss: 0.584350
 >> iter 23000, loss: 0.563590
 >> iter 24000, loss: 0.404639
 >> iter 25000, loss: 0.445200
 >> iter 26000, loss: 0.469041
 >> iter 27000, loss: 0.383826
 >> iter 28000, loss: 0.299863
 >> iter 29000, loss: 0.306666
 >> iter 30000, loss: 0.481261
   Number of active neurons: 6
 >> iter 31000, loss: 0.573306
 >> iter 32000, loss: 0.741159
 >> iter 33000, loss: 0.640850
 >> iter 34000, loss: 0.633317
 >> iter 35000, loss: 0.599773
 >> iter 36000, loss: 0.636515
 >> iter 37000, loss: 0.516818
 >> iter 38000, loss: 0.572658
 >> iter 39000, loss: 0.625513
 >> iter 40000, loss: 0.493059
   Number of active neurons: 5
 >> iter 41000, loss: 0.574810
 >> iter 42000, loss: 0.539571
 >> iter 43000, loss: 0.664503
 >> iter 44000, loss: 0.515872
 >> iter 45000, loss: 0.395600
 >> iter 46000, loss: 0.472083
 >> iter 47000, loss: 0.516725
 >> iter 48000, loss: 0.576300
 >> iter 49000, loss: 0.521307
 >> iter 50000, loss: 0.448821
   Number of active neurons: 5
 >> iter 51000, loss: 0.568563
 >> iter 52000, loss: 0.439918
 >> iter 53000, loss: 0.313469
 >> iter 54000, loss: 0.425731
 >> iter 55000, loss: 0.336622
 >> iter 56000, loss: 0.472443
 >> iter 57000, loss: 0.459139
 >> iter 58000, loss: 0.493733
 >> iter 59000, loss: 0.563966
 >> iter 60000, loss: 0.386799
   Number of active neurons: 5
 >> iter 61000, loss: 0.530074
 >> iter 62000, loss: 0.530558
 >> iter 63000, loss: 0.447141
 >> iter 64000, loss: 0.645778
 >> iter 65000, loss: 0.605597
 >> iter 66000, loss: 0.534713
 >> iter 67000, loss: 0.496692
 >> iter 68000, loss: 0.461761
 >> iter 69000, loss: 0.500649
 >> iter 70000, loss: 0.584705
   Number of active neurons: 5
 >> iter 71000, loss: 0.472441
 >> iter 72000, loss: 0.468395
 >> iter 73000, loss: 0.495670
 >> iter 74000, loss: 0.474098
 >> iter 75000, loss: 0.434730
 >> iter 76000, loss: 0.435613
 >> iter 77000, loss: 0.493305
 >> iter 78000, loss: 0.488798
 >> iter 79000, loss: 0.523217
 >> iter 80000, loss: 0.723426
   Number of active neurons: 4
 >> iter 81000, loss: 0.679899
 >> iter 82000, loss: 0.601422
 >> iter 83000, loss: 0.460435
 >> iter 84000, loss: 0.472839
 >> iter 85000, loss: 0.434769
 >> iter 86000, loss: 0.357368
 >> iter 87000, loss: 0.413529
 >> iter 88000, loss: 0.478159
 >> iter 89000, loss: 0.463335
 >> iter 90000, loss: 0.358122
   Number of active neurons: 4
 >> iter 91000, loss: 0.531467
 >> iter 92000, loss: 0.434415
 >> iter 93000, loss: 0.384120
 >> iter 94000, loss: 0.417563
 >> iter 95000, loss: 0.446309
 >> iter 96000, loss: 0.493409
 >> iter 97000, loss: 0.551172
 >> iter 98000, loss: 0.552964
 >> iter 99000, loss: 0.576023
 >> iter 100000, loss: 0.706633
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.165843
 >> iter 2000, loss: 11.599696
 >> iter 3000, loss: 7.589122
 >> iter 4000, loss: 4.807853
 >> iter 5000, loss: 2.908843
 >> iter 6000, loss: 1.770592
 >> iter 7000, loss: 1.187453
 >> iter 8000, loss: 0.839035
 >> iter 9000, loss: 0.878132
 >> iter 10000, loss: 0.754931
   Number of active neurons: 6
 >> iter 11000, loss: 0.645075
 >> iter 12000, loss: 0.655232
 >> iter 13000, loss: 0.609422
 >> iter 14000, loss: 0.518954
 >> iter 15000, loss: 0.508455
 >> iter 16000, loss: 0.456966
 >> iter 17000, loss: 0.457811
 >> iter 18000, loss: 0.458794
 >> iter 19000, loss: 0.576119
 >> iter 20000, loss: 0.445692
   Number of active neurons: 6
 >> iter 21000, loss: 0.458156
 >> iter 22000, loss: 0.654311
 >> iter 23000, loss: 0.580747
 >> iter 24000, loss: 0.491954
 >> iter 25000, loss: 0.463222
 >> iter 26000, loss: 0.402340
 >> iter 27000, loss: 0.456784
 >> iter 28000, loss: 0.404376
 >> iter 29000, loss: 0.316226
 >> iter 30000, loss: 0.403181
   Number of active neurons: 5
 >> iter 31000, loss: 0.427016
 >> iter 32000, loss: 0.375485
 >> iter 33000, loss: 0.400344
 >> iter 34000, loss: 0.373595
 >> iter 35000, loss: 0.457744
 >> iter 36000, loss: 0.485736
 >> iter 37000, loss: 0.568826
 >> iter 38000, loss: 0.494840
 >> iter 39000, loss: 0.511239
 >> iter 40000, loss: 0.463368
   Number of active neurons: 5
 >> iter 41000, loss: 0.640984
 >> iter 42000, loss: 0.583731
 >> iter 43000, loss: 0.451181
 >> iter 44000, loss: 0.468112
 >> iter 45000, loss: 0.423244
 >> iter 46000, loss: 0.459424
 >> iter 47000, loss: 0.519918
 >> iter 48000, loss: 0.418175
 >> iter 49000, loss: 0.359359
 >> iter 50000, loss: 0.395995
   Number of active neurons: 5
 >> iter 51000, loss: 0.433417
 >> iter 52000, loss: 0.467552
 >> iter 53000, loss: 0.589850
 >> iter 54000, loss: 0.488318
 >> iter 55000, loss: 0.565090
 >> iter 56000, loss: 0.479857
 >> iter 57000, loss: 0.433942
 >> iter 58000, loss: 0.405176
 >> iter 59000, loss: 0.484872
 >> iter 60000, loss: 0.440401
   Number of active neurons: 5
 >> iter 61000, loss: 0.365503
 >> iter 62000, loss: 0.291967
 >> iter 63000, loss: 0.399519
 >> iter 64000, loss: 0.410204
 >> iter 65000, loss: 0.406176
 >> iter 66000, loss: 0.500430
 >> iter 67000, loss: 0.445543
 >> iter 68000, loss: 0.393815
 >> iter 69000, loss: 0.465807
 >> iter 70000, loss: 0.483380
   Number of active neurons: 5
 >> iter 71000, loss: 0.509902
 >> iter 72000, loss: 0.404790
 >> iter 73000, loss: 0.565035
 >> iter 74000, loss: 0.461044
 >> iter 75000, loss: 0.450009
 >> iter 76000, loss: 0.401324
 >> iter 77000, loss: 0.432208
 >> iter 78000, loss: 0.476846
 >> iter 79000, loss: 0.489165
 >> iter 80000, loss: 0.511752
   Number of active neurons: 5
 >> iter 81000, loss: 0.319110
 >> iter 82000, loss: 0.402649
 >> iter 83000, loss: 0.480445
 >> iter 84000, loss: 0.498938
 >> iter 85000, loss: 0.436640
 >> iter 86000, loss: 0.331010
 >> iter 87000, loss: 0.386805
 >> iter 88000, loss: 0.337159
 >> iter 89000, loss: 0.412269
 >> iter 90000, loss: 0.460286
   Number of active neurons: 5
 >> iter 91000, loss: 0.420779
 >> iter 92000, loss: 0.587002
 >> iter 93000, loss: 0.456461
 >> iter 94000, loss: 0.544508
 >> iter 95000, loss: 0.545902
 >> iter 96000, loss: 0.457484
 >> iter 97000, loss: 0.403242
 >> iter 98000, loss: 0.478107
 >> iter 99000, loss: 0.451087
 >> iter 100000, loss: 0.433484
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.115390
 >> iter 2000, loss: 9.709360
 >> iter 3000, loss: 5.346786
 >> iter 4000, loss: 3.170404
 >> iter 5000, loss: 2.158401
 >> iter 6000, loss: 1.375942
 >> iter 7000, loss: 1.157318
 >> iter 8000, loss: 0.858565
 >> iter 9000, loss: 0.800741
 >> iter 10000, loss: 0.697188
   Number of active neurons: 4
 >> iter 11000, loss: 0.751588
 >> iter 12000, loss: 0.667784
 >> iter 13000, loss: 0.541157
 >> iter 14000, loss: 0.586938
 >> iter 15000, loss: 0.599105
 >> iter 16000, loss: 0.515229
 >> iter 17000, loss: 0.426005
 >> iter 18000, loss: 0.505844
 >> iter 19000, loss: 0.518489
 >> iter 20000, loss: 0.478023
   Number of active neurons: 4
 >> iter 21000, loss: 0.507268
 >> iter 22000, loss: 0.494291
 >> iter 23000, loss: 0.594946
 >> iter 24000, loss: 0.590792
 >> iter 25000, loss: 0.505074
 >> iter 26000, loss: 0.485221
 >> iter 27000, loss: 0.600095
 >> iter 28000, loss: 0.492854
 >> iter 29000, loss: 0.525558
 >> iter 30000, loss: 0.572961
   Number of active neurons: 4
 >> iter 31000, loss: 0.496325
 >> iter 32000, loss: 0.561671
 >> iter 33000, loss: 0.633283
 >> iter 34000, loss: 0.661469
 >> iter 35000, loss: 0.610161
 >> iter 36000, loss: 0.627342
 >> iter 37000, loss: 0.605864
 >> iter 38000, loss: 0.654387
 >> iter 39000, loss: 0.613164
 >> iter 40000, loss: 0.654389
   Number of active neurons: 4
 >> iter 41000, loss: 0.452453
 >> iter 42000, loss: 0.388046
 >> iter 43000, loss: 0.430288
 >> iter 44000, loss: 0.454160
 >> iter 45000, loss: 0.489463
 >> iter 46000, loss: 0.511520
 >> iter 47000, loss: 0.527689
 >> iter 48000, loss: 0.533701
 >> iter 49000, loss: 0.571618
 >> iter 50000, loss: 0.607818
   Number of active neurons: 4
 >> iter 51000, loss: 0.436795
 >> iter 52000, loss: 0.566175
 >> iter 53000, loss: 0.562181
 >> iter 54000, loss: 0.527138
 >> iter 55000, loss: 0.566817
 >> iter 56000, loss: 0.574502
 >> iter 57000, loss: 0.528744
 >> iter 58000, loss: 0.484494
 >> iter 59000, loss: 0.454096
 >> iter 60000, loss: 0.472665
   Number of active neurons: 4
 >> iter 61000, loss: 0.552181
 >> iter 62000, loss: 0.446882
 >> iter 63000, loss: 0.541841
 >> iter 64000, loss: 0.549807
 >> iter 65000, loss: 0.452213
 >> iter 66000, loss: 0.368243
 >> iter 67000, loss: 0.381894
 >> iter 68000, loss: 0.343167
 >> iter 69000, loss: 0.570987
 >> iter 70000, loss: 0.546032
   Number of active neurons: 4
 >> iter 71000, loss: 0.620046
 >> iter 72000, loss: 0.635470
 >> iter 73000, loss: 0.630847
 >> iter 74000, loss: 0.513767
 >> iter 75000, loss: 0.492708
 >> iter 76000, loss: 0.479824
 >> iter 77000, loss: 0.517919
 >> iter 78000, loss: 0.465823
 >> iter 79000, loss: 0.419914
 >> iter 80000, loss: 0.504668
   Number of active neurons: 4
 >> iter 81000, loss: 0.432774
 >> iter 82000, loss: 0.429087
 >> iter 83000, loss: 0.317576
 >> iter 84000, loss: 0.294113
 >> iter 85000, loss: 0.396757
 >> iter 86000, loss: 0.364805
 >> iter 87000, loss: 0.389684
 >> iter 88000, loss: 0.420389
 >> iter 89000, loss: 0.541090
 >> iter 90000, loss: 0.502896
   Number of active neurons: 4
 >> iter 91000, loss: 0.515799
 >> iter 92000, loss: 0.409191
 >> iter 93000, loss: 0.538900
 >> iter 94000, loss: 0.511793
 >> iter 95000, loss: 0.500798
 >> iter 96000, loss: 0.555887
 >> iter 97000, loss: 0.558018
 >> iter 98000, loss: 0.546157
 >> iter 99000, loss: 0.397602
 >> iter 100000, loss: 0.490050
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.603072
 >> iter 2000, loss: 12.385067
 >> iter 3000, loss: 9.865565
 >> iter 4000, loss: 8.482866
 >> iter 5000, loss: 7.217624
 >> iter 6000, loss: 5.252593
 >> iter 7000, loss: 4.202483
 >> iter 8000, loss: 3.814146
 >> iter 9000, loss: 3.488070
 >> iter 10000, loss: 3.395918
   Number of active neurons: 4
 >> iter 11000, loss: 3.327896
 >> iter 12000, loss: 3.291781
 >> iter 13000, loss: 3.308697
 >> iter 14000, loss: 3.235238
 >> iter 15000, loss: 3.218154
 >> iter 16000, loss: 3.223937
 >> iter 17000, loss: 3.235423
 >> iter 18000, loss: 3.206645
 >> iter 19000, loss: 3.282810
 >> iter 20000, loss: 3.382668
   Number of active neurons: 4
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 4
 >> iter 21000, loss: 4.153586
 >> iter 22000, loss: 3.744354
 >> iter 23000, loss: 3.659545
 >> iter 24000, loss: 3.568387
 >> iter 25000, loss: 2.516274
 >> iter 26000, loss: 1.468395
 >> iter 27000, loss: 1.062166
 >> iter 28000, loss: 0.890401
 >> iter 29000, loss: 0.873186
 >> iter 30000, loss: 0.868603
   Number of active neurons: 6
 >> iter 31000, loss: 0.757739
 >> iter 32000, loss: 0.640451
 >> iter 33000, loss: 0.536385
 >> iter 34000, loss: 0.584071
 >> iter 35000, loss: 0.495135
 >> iter 36000, loss: 0.525119
 >> iter 37000, loss: 0.710964
 >> iter 38000, loss: 0.690042
 >> iter 39000, loss: 0.672266
 >> iter 40000, loss: 0.607909
   Number of active neurons: 6
 >> iter 41000, loss: 0.544351
 >> iter 42000, loss: 0.478281
 >> iter 43000, loss: 0.282552
 >> iter 44000, loss: 0.442781
 >> iter 45000, loss: 0.542075
 >> iter 46000, loss: 0.483047
 >> iter 47000, loss: 0.598659
 >> iter 48000, loss: 0.612432
 >> iter 49000, loss: 0.596538
 >> iter 50000, loss: 0.484289
   Number of active neurons: 5
 >> iter 51000, loss: 0.481656
 >> iter 52000, loss: 0.581972
 >> iter 53000, loss: 0.536927
 >> iter 54000, loss: 0.581372
 >> iter 55000, loss: 0.563787
 >> iter 56000, loss: 0.671104
 >> iter 57000, loss: 0.785203
 >> iter 58000, loss: 0.623840
 >> iter 59000, loss: 0.560541
 >> iter 60000, loss: 0.567673
   Number of active neurons: 5
 >> iter 61000, loss: 0.542132
 >> iter 62000, loss: 0.534325
 >> iter 63000, loss: 0.502937
 >> iter 64000, loss: 0.679039
 >> iter 65000, loss: 0.643570
 >> iter 66000, loss: 0.609508
 >> iter 67000, loss: 0.722027
 >> iter 68000, loss: 0.649545
 >> iter 69000, loss: 0.498281
 >> iter 70000, loss: 0.593393
   Number of active neurons: 5
 >> iter 71000, loss: 0.551530
 >> iter 72000, loss: 0.577614
 >> iter 73000, loss: 0.595794
 >> iter 74000, loss: 0.650451
 >> iter 75000, loss: 0.495556
 >> iter 76000, loss: 0.456627
 >> iter 77000, loss: 0.529632
 >> iter 78000, loss: 0.508638
 >> iter 79000, loss: 0.656765
 >> iter 80000, loss: 0.584779
   Number of active neurons: 5
 >> iter 81000, loss: 0.483828
 >> iter 82000, loss: 0.479249
 >> iter 83000, loss: 0.445456
 >> iter 84000, loss: 0.424921
 >> iter 85000, loss: 0.618075
 >> iter 86000, loss: 0.472162
 >> iter 87000, loss: 0.482926
 >> iter 88000, loss: 0.573563
 >> iter 89000, loss: 0.556164
 >> iter 90000, loss: 0.520771
   Number of active neurons: 5
 >> iter 91000, loss: 0.474457
 >> iter 92000, loss: 0.435901
 >> iter 93000, loss: 0.521381
 >> iter 94000, loss: 0.493044
 >> iter 95000, loss: 0.447527
 >> iter 96000, loss: 0.396249
 >> iter 97000, loss: 0.443034
 >> iter 98000, loss: 0.426385
 >> iter 99000, loss: 0.414152
 >> iter 100000, loss: 0.556059
   Number of active neurons: 5
 >> iter 101000, loss: 0.560652
 >> iter 102000, loss: 0.478279
 >> iter 103000, loss: 0.508406
 >> iter 104000, loss: 0.466521
 >> iter 105000, loss: 0.434686
 >> iter 106000, loss: 0.459160
 >> iter 107000, loss: 0.353293
 >> iter 108000, loss: 0.568485
 >> iter 109000, loss: 0.431399
 >> iter 110000, loss: 0.473382
   Number of active neurons: 4
 >> iter 111000, loss: 0.440752
 >> iter 112000, loss: 0.451279
 >> iter 113000, loss: 0.415717
 >> iter 114000, loss: 0.550531
 >> iter 115000, loss: 0.486018
 >> iter 116000, loss: 0.437796
 >> iter 117000, loss: 0.457198
 >> iter 118000, loss: 0.474418
 >> iter 119000, loss: 0.479888
 >> iter 120000, loss: 0.560691
   Number of active neurons: 4
 >> iter 121000, loss: 0.397527
 >> iter 122000, loss: 0.376383
 >> iter 123000, loss: 0.576084
 >> iter 124000, loss: 0.559943
 >> iter 125000, loss: 0.599909
 >> iter 126000, loss: 0.475700
 >> iter 127000, loss: 0.541446
 >> iter 128000, loss: 0.415757
 >> iter 129000, loss: 0.529982
 >> iter 130000, loss: 0.579429
   Number of active neurons: 4
 >> iter 131000, loss: 0.658616
 >> iter 132000, loss: 0.532926
 >> iter 133000, loss: 0.553729
 >> iter 134000, loss: 0.468320
 >> iter 135000, loss: 0.471585
 >> iter 136000, loss: 0.587122
 >> iter 137000, loss: 0.500764
 >> iter 138000, loss: 0.663127
 >> iter 139000, loss: 0.636404
 >> iter 140000, loss: 0.659305
   Number of active neurons: 4
 >> iter 141000, loss: 0.624262
 >> iter 142000, loss: 0.416468
 >> iter 143000, loss: 0.442970
 >> iter 144000, loss: 0.436404
 >> iter 145000, loss: 0.592841
 >> iter 146000, loss: 0.414904
 >> iter 147000, loss: 0.427522
 >> iter 148000, loss: 0.431735
 >> iter 149000, loss: 0.485524
 >> iter 150000, loss: 0.449812
   Number of active neurons: 4
 >> iter 151000, loss: 0.490109
 >> iter 152000, loss: 0.508507
 >> iter 153000, loss: 0.372011
 >> iter 154000, loss: 0.403226
 >> iter 155000, loss: 0.542372
 >> iter 156000, loss: 0.467169
 >> iter 157000, loss: 0.532831
 >> iter 158000, loss: 0.564625
 >> iter 159000, loss: 0.581435
 >> iter 160000, loss: 0.548682
   Number of active neurons: 4
 >> iter 161000, loss: 0.603001
 >> iter 162000, loss: 0.636847
 >> iter 163000, loss: 0.578258
 >> iter 164000, loss: 0.513994
 >> iter 165000, loss: 0.403018
 >> iter 166000, loss: 0.555826
 >> iter 167000, loss: 0.536961
 >> iter 168000, loss: 0.504446
 >> iter 169000, loss: 0.394711
 >> iter 170000, loss: 0.377728
   Number of active neurons: 4
 >> iter 171000, loss: 0.464529
 >> iter 172000, loss: 0.383051
 >> iter 173000, loss: 0.478139
 >> iter 174000, loss: 0.523146
 >> iter 175000, loss: 0.432931
 >> iter 176000, loss: 0.397680
 >> iter 177000, loss: 0.506611
 >> iter 178000, loss: 0.441833
 >> iter 179000, loss: 0.471746
 >> iter 180000, loss: 0.432700
   Number of active neurons: 4
 >> iter 181000, loss: 0.518709
 >> iter 182000, loss: 0.519813
 >> iter 183000, loss: 0.503007
 >> iter 184000, loss: 0.461664
 >> iter 185000, loss: 0.402114
 >> iter 186000, loss: 0.396773
 >> iter 187000, loss: 0.459216
 >> iter 188000, loss: 0.470191
 >> iter 189000, loss: 0.539932
 >> iter 190000, loss: 0.424105
   Number of active neurons: 4
 >> iter 191000, loss: 0.434810
 >> iter 192000, loss: 0.481221
 >> iter 193000, loss: 0.347709
 >> iter 194000, loss: 0.344337
 >> iter 195000, loss: 0.404308
 >> iter 196000, loss: 0.415702
 >> iter 197000, loss: 0.407847
 >> iter 198000, loss: 0.449077
 >> iter 199000, loss: 0.459683
 >> iter 200000, loss: 0.552950
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.187617
 >> iter 2000, loss: 9.830358
 >> iter 3000, loss: 5.230612
 >> iter 4000, loss: 3.263639
 >> iter 5000, loss: 2.045618
 >> iter 6000, loss: 1.690088
 >> iter 7000, loss: 1.368245
 >> iter 8000, loss: 1.257280
 >> iter 9000, loss: 0.797227
 >> iter 10000, loss: 0.822668
   Number of active neurons: 5
 >> iter 11000, loss: 0.650056
 >> iter 12000, loss: 0.505228
 >> iter 13000, loss: 0.463819
 >> iter 14000, loss: 0.473890
 >> iter 15000, loss: 0.686774
 >> iter 16000, loss: 0.608700
 >> iter 17000, loss: 0.556588
 >> iter 18000, loss: 0.595479
 >> iter 19000, loss: 0.497020
 >> iter 20000, loss: 0.355491
   Number of active neurons: 5
 >> iter 21000, loss: 0.516555
 >> iter 22000, loss: 0.400223
 >> iter 23000, loss: 0.412968
 >> iter 24000, loss: 0.390478
 >> iter 25000, loss: 0.479609
 >> iter 26000, loss: 0.504981
 >> iter 27000, loss: 0.456332
 >> iter 28000, loss: 0.410190
 >> iter 29000, loss: 0.320609
 >> iter 30000, loss: 0.306258
   Number of active neurons: 5
 >> iter 31000, loss: 0.312694
 >> iter 32000, loss: 0.476350
 >> iter 33000, loss: 0.484508
 >> iter 34000, loss: 0.425582
 >> iter 35000, loss: 0.570088
 >> iter 36000, loss: 0.599693
 >> iter 37000, loss: 0.695872
 >> iter 38000, loss: 0.471176
 >> iter 39000, loss: 0.396793
 >> iter 40000, loss: 0.407589
   Number of active neurons: 5
 >> iter 41000, loss: 0.536633
 >> iter 42000, loss: 0.472508
 >> iter 43000, loss: 0.677761
 >> iter 44000, loss: 0.643026
 >> iter 45000, loss: 0.600959
 >> iter 46000, loss: 0.620418
 >> iter 47000, loss: 0.511516
 >> iter 48000, loss: 0.623061
 >> iter 49000, loss: 0.510046
 >> iter 50000, loss: 0.389468
   Number of active neurons: 5
 >> iter 51000, loss: 0.300387
 >> iter 52000, loss: 0.350284
 >> iter 53000, loss: 0.404186
 >> iter 54000, loss: 0.491928
 >> iter 55000, loss: 0.489420
 >> iter 56000, loss: 0.430492
 >> iter 57000, loss: 0.405621
 >> iter 58000, loss: 0.576163
 >> iter 59000, loss: 0.493583
 >> iter 60000, loss: 0.578457
   Number of active neurons: 5
 >> iter 61000, loss: 0.409571
 >> iter 62000, loss: 0.385510
 >> iter 63000, loss: 0.413902
 >> iter 64000, loss: 0.523758
 >> iter 65000, loss: 0.606741
 >> iter 66000, loss: 0.549400
 >> iter 67000, loss: 0.429388
 >> iter 68000, loss: 0.469540
 >> iter 69000, loss: 0.590053
 >> iter 70000, loss: 0.610554
   Number of active neurons: 5
 >> iter 71000, loss: 0.484270
 >> iter 72000, loss: 0.330403
 >> iter 73000, loss: 0.419486
 >> iter 74000, loss: 0.605170
 >> iter 75000, loss: 0.550901
 >> iter 76000, loss: 0.651455
 >> iter 77000, loss: 0.605273
 >> iter 78000, loss: 0.650049
 >> iter 79000, loss: 0.608848
 >> iter 80000, loss: 0.535996
   Number of active neurons: 5
 >> iter 81000, loss: 0.400909
 >> iter 82000, loss: 0.535394
 >> iter 83000, loss: 0.460385
 >> iter 84000, loss: 0.515360
 >> iter 85000, loss: 0.568827
 >> iter 86000, loss: 0.509308
 >> iter 87000, loss: 0.428997
 >> iter 88000, loss: 0.496500
 >> iter 89000, loss: 0.469303
 >> iter 90000, loss: 0.630453
   Number of active neurons: 5
 >> iter 91000, loss: 0.688989
 >> iter 92000, loss: 0.515381
 >> iter 93000, loss: 0.530759
 >> iter 94000, loss: 0.473937
 >> iter 95000, loss: 0.574283
 >> iter 96000, loss: 0.550887
 >> iter 97000, loss: 0.464626
 >> iter 98000, loss: 0.651436
 >> iter 99000, loss: 0.536932
 >> iter 100000, loss: 0.399595
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.04999900002
   - Test - Long: 0.0
   - Test - Big: 0.0579994200058
   - Test - A: 0.506632891141
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.124645
 >> iter 2000, loss: 11.069658
 >> iter 3000, loss: 7.864262
 >> iter 4000, loss: 5.163631
 >> iter 5000, loss: 3.364011
 >> iter 6000, loss: 2.231774
 >> iter 7000, loss: 1.772436
 >> iter 8000, loss: 1.190444
 >> iter 9000, loss: 0.718743
 >> iter 10000, loss: 0.789939
   Number of active neurons: 6
 >> iter 11000, loss: 0.771340
 >> iter 12000, loss: 0.642946
 >> iter 13000, loss: 0.626009
 >> iter 14000, loss: 0.741804
 >> iter 15000, loss: 0.615556
 >> iter 16000, loss: 0.649082
 >> iter 17000, loss: 0.714568
 >> iter 18000, loss: 0.730415
 >> iter 19000, loss: 0.631446
 >> iter 20000, loss: 0.753403
   Number of active neurons: 6
 >> iter 21000, loss: 0.733981
 >> iter 22000, loss: 0.726443
 >> iter 23000, loss: 0.648199
 >> iter 24000, loss: 0.607600
 >> iter 25000, loss: 0.618103
 >> iter 26000, loss: 0.660408
 >> iter 27000, loss: 0.547078
 >> iter 28000, loss: 0.546277
 >> iter 29000, loss: 0.452052
 >> iter 30000, loss: 0.367871
   Number of active neurons: 5
 >> iter 31000, loss: 0.380240
 >> iter 32000, loss: 0.282635
 >> iter 33000, loss: 0.454255
 >> iter 34000, loss: 0.621272
 >> iter 35000, loss: 0.583248
 >> iter 36000, loss: 0.516068
 >> iter 37000, loss: 0.444307
 >> iter 38000, loss: 0.507835
 >> iter 39000, loss: 0.668840
 >> iter 40000, loss: 0.551467
   Number of active neurons: 5
 >> iter 41000, loss: 0.747364
 >> iter 42000, loss: 0.646049
 >> iter 43000, loss: 0.562875
 >> iter 44000, loss: 0.555674
 >> iter 45000, loss: 0.577096
 >> iter 46000, loss: 0.436305
 >> iter 47000, loss: 0.499703
 >> iter 48000, loss: 0.434790
 >> iter 49000, loss: 0.342452
 >> iter 50000, loss: 0.391595
   Number of active neurons: 5
 >> iter 51000, loss: 0.440611
 >> iter 52000, loss: 0.403047
 >> iter 53000, loss: 0.390115
 >> iter 54000, loss: 0.379345
 >> iter 55000, loss: 0.373361
 >> iter 56000, loss: 0.330378
 >> iter 57000, loss: 0.355259
 >> iter 58000, loss: 0.380342
 >> iter 59000, loss: 0.410811
 >> iter 60000, loss: 0.492812
   Number of active neurons: 4
 >> iter 61000, loss: 0.411895
 >> iter 62000, loss: 0.395367
 >> iter 63000, loss: 0.367871
 >> iter 64000, loss: 0.471456
 >> iter 65000, loss: 0.465836
 >> iter 66000, loss: 0.535569
 >> iter 67000, loss: 0.371255
 >> iter 68000, loss: 0.451239
 >> iter 69000, loss: 0.617652
 >> iter 70000, loss: 0.597287
   Number of active neurons: 4
 >> iter 71000, loss: 0.577361
 >> iter 72000, loss: 0.415020
 >> iter 73000, loss: 0.499865
 >> iter 74000, loss: 0.582882
 >> iter 75000, loss: 0.493452
 >> iter 76000, loss: 0.466682
 >> iter 77000, loss: 0.463753
 >> iter 78000, loss: 0.357247
 >> iter 79000, loss: 0.362951
 >> iter 80000, loss: 0.352204
   Number of active neurons: 4
 >> iter 81000, loss: 0.315611
 >> iter 82000, loss: 0.649218
 >> iter 83000, loss: 0.512388
 >> iter 84000, loss: 0.477924
 >> iter 85000, loss: 0.486456
 >> iter 86000, loss: 0.608726
 >> iter 87000, loss: 0.612932
 >> iter 88000, loss: 0.555510
 >> iter 89000, loss: 0.516779
 >> iter 90000, loss: 0.460323
   Number of active neurons: 4
 >> iter 91000, loss: 0.454380
 >> iter 92000, loss: 0.526819
 >> iter 93000, loss: 0.623183
 >> iter 94000, loss: 0.610120
 >> iter 95000, loss: 0.665496
 >> iter 96000, loss: 0.734170
 >> iter 97000, loss: 0.604905
 >> iter 98000, loss: 0.558214
 >> iter 99000, loss: 0.591343
 >> iter 100000, loss: 0.588766
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.429622
 >> iter 2000, loss: 13.231638
 >> iter 3000, loss: 9.065812
 >> iter 4000, loss: 6.325316
 >> iter 5000, loss: 5.018162
 >> iter 6000, loss: 3.657755
 >> iter 7000, loss: 2.384554
 >> iter 8000, loss: 1.682492
 >> iter 9000, loss: 1.226648
 >> iter 10000, loss: 1.014917
   Number of active neurons: 6
 >> iter 11000, loss: 1.092699
 >> iter 12000, loss: 1.103974
 >> iter 13000, loss: 1.195066
 >> iter 14000, loss: 0.958300
 >> iter 15000, loss: 0.801556
 >> iter 16000, loss: 0.922439
 >> iter 17000, loss: 0.767505
 >> iter 18000, loss: 0.733381
 >> iter 19000, loss: 0.863577
 >> iter 20000, loss: 0.769291
   Number of active neurons: 6
 >> iter 21000, loss: 0.631131
 >> iter 22000, loss: 0.656963
 >> iter 23000, loss: 0.775870
 >> iter 24000, loss: 0.771107
 >> iter 25000, loss: 0.661148
 >> iter 26000, loss: 0.785958
 >> iter 27000, loss: 0.835582
 >> iter 28000, loss: 0.881569
 >> iter 29000, loss: 0.915738
 >> iter 30000, loss: 0.917393
   Number of active neurons: 6
 >> iter 31000, loss: 0.796103
 >> iter 32000, loss: 0.617389
 >> iter 33000, loss: 0.580022
 >> iter 34000, loss: 0.629188
 >> iter 35000, loss: 0.560375
 >> iter 36000, loss: 0.554329
 >> iter 37000, loss: 0.510576
 >> iter 38000, loss: 0.461491
 >> iter 39000, loss: 0.399490
 >> iter 40000, loss: 0.484064
   Number of active neurons: 5
 >> iter 41000, loss: 0.548582
 >> iter 42000, loss: 0.663769
 >> iter 43000, loss: 0.875487
 >> iter 44000, loss: 0.798446
 >> iter 45000, loss: 0.636359
 >> iter 46000, loss: 0.629344
 >> iter 47000, loss: 0.509388
 >> iter 48000, loss: 0.719411
 >> iter 49000, loss: 0.654212
 >> iter 50000, loss: 0.871601
   Number of active neurons: 5
 >> iter 51000, loss: 0.741132
 >> iter 52000, loss: 0.596841
 >> iter 53000, loss: 0.529988
 >> iter 54000, loss: 0.465638
 >> iter 55000, loss: 0.767349
 >> iter 56000, loss: 0.583976
 >> iter 57000, loss: 0.478803
 >> iter 58000, loss: 0.496359
 >> iter 59000, loss: 0.507014
 >> iter 60000, loss: 0.370060
   Number of active neurons: 5
 >> iter 61000, loss: 0.608260
 >> iter 62000, loss: 0.621923
 >> iter 63000, loss: 0.675462
 >> iter 64000, loss: 0.602724
 >> iter 65000, loss: 0.639455
 >> iter 66000, loss: 0.560501
 >> iter 67000, loss: 0.620200
 >> iter 68000, loss: 0.412421
 >> iter 69000, loss: 0.517918
 >> iter 70000, loss: 0.488956
   Number of active neurons: 5
 >> iter 71000, loss: 0.523597
 >> iter 72000, loss: 0.506488
 >> iter 73000, loss: 0.505620
 >> iter 74000, loss: 0.569371
 >> iter 75000, loss: 0.475271
 >> iter 76000, loss: 0.476422
 >> iter 77000, loss: 0.619429
 >> iter 78000, loss: 0.455572
 >> iter 79000, loss: 0.405511
 >> iter 80000, loss: 0.584036
   Number of active neurons: 5
 >> iter 81000, loss: 0.527536
 >> iter 82000, loss: 0.509821
 >> iter 83000, loss: 0.402148
 >> iter 84000, loss: 0.395800
 >> iter 85000, loss: 0.373388
 >> iter 86000, loss: 0.578004
 >> iter 87000, loss: 0.505054
 >> iter 88000, loss: 0.564846
 >> iter 89000, loss: 0.477815
 >> iter 90000, loss: 0.639942
   Number of active neurons: 5
 >> iter 91000, loss: 0.461891
 >> iter 92000, loss: 0.428389
 >> iter 93000, loss: 0.490688
 >> iter 94000, loss: 0.571882
 >> iter 95000, loss: 0.467258
 >> iter 96000, loss: 0.504363
 >> iter 97000, loss: 0.453769
 >> iter 98000, loss: 0.332428
 >> iter 99000, loss: 0.381842
 >> iter 100000, loss: 0.453661
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

