 > Problema: tomita2nueva
 > Args:
   - Hidden size: 14
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.356171
 >> iter 2000, loss: 4.456735
 >> iter 3000, loss: 1.757329
 >> iter 4000, loss: 0.743101
 >> iter 5000, loss: 0.339316
 >> iter 6000, loss: 0.184819
 >> iter 7000, loss: 0.129951
 >> iter 8000, loss: 0.084035
 >> iter 9000, loss: 0.081870
 >> iter 10000, loss: 0.079472
   Number of active neurons: 7
 >> iter 11000, loss: 0.069056
 >> iter 12000, loss: 0.054774
 >> iter 13000, loss: 0.050266
 >> iter 14000, loss: 0.058322
 >> iter 15000, loss: 0.060124
 >> iter 16000, loss: 0.052121
 >> iter 17000, loss: 0.056386
 >> iter 18000, loss: 0.054476
 >> iter 19000, loss: 0.061471
 >> iter 20000, loss: 0.060345
   Number of active neurons: 7
 >> iter 21000, loss: 0.049037
 >> iter 22000, loss: 0.041678
 >> iter 23000, loss: 0.042629
 >> iter 24000, loss: 0.046989
 >> iter 25000, loss: 0.063922
 >> iter 26000, loss: 0.061340
 >> iter 27000, loss: 0.040148
 >> iter 28000, loss: 0.060896
 >> iter 29000, loss: 0.069170
 >> iter 30000, loss: 0.051637
   Number of active neurons: 6
 >> iter 31000, loss: 0.054764
 >> iter 32000, loss: 0.055951
 >> iter 33000, loss: 0.038114
 >> iter 34000, loss: 0.034435
 >> iter 35000, loss: 0.043424
 >> iter 36000, loss: 0.055135
 >> iter 37000, loss: 0.044358
 >> iter 38000, loss: 0.049425
 >> iter 39000, loss: 0.045424
 >> iter 40000, loss: 0.047761
   Number of active neurons: 6
 >> iter 41000, loss: 0.043435
 >> iter 42000, loss: 0.048592
 >> iter 43000, loss: 0.043879
 >> iter 44000, loss: 0.056892
 >> iter 45000, loss: 0.047902
 >> iter 46000, loss: 0.055677
 >> iter 47000, loss: 0.065383
 >> iter 48000, loss: 0.055627
 >> iter 49000, loss: 0.074844
 >> iter 50000, loss: 0.063026
   Number of active neurons: 3
 >> iter 51000, loss: 0.060466
 >> iter 52000, loss: 0.040069
 >> iter 53000, loss: 0.058971
 >> iter 54000, loss: 0.048260
 >> iter 55000, loss: 0.039296
 >> iter 56000, loss: 0.040706
 >> iter 57000, loss: 0.035791
 >> iter 58000, loss: 0.053723
 >> iter 59000, loss: 0.043371
 >> iter 60000, loss: 0.043409
   Number of active neurons: 3
 >> iter 61000, loss: 0.051738
 >> iter 62000, loss: 0.041748
 >> iter 63000, loss: 0.048026
 >> iter 64000, loss: 0.049439
 >> iter 65000, loss: 0.037582
 >> iter 66000, loss: 0.034403
 >> iter 67000, loss: 0.033814
 >> iter 68000, loss: 0.037854
 >> iter 69000, loss: 0.047135
 >> iter 70000, loss: 0.058390
   Number of active neurons: 3
 >> iter 71000, loss: 0.039552
 >> iter 72000, loss: 0.052659
 >> iter 73000, loss: 0.043964
 >> iter 74000, loss: 0.037705
 >> iter 75000, loss: 0.045387
 >> iter 76000, loss: 0.039036
 >> iter 77000, loss: 0.040044
 >> iter 78000, loss: 0.039380
 >> iter 79000, loss: 0.058488
 >> iter 80000, loss: 0.046464
   Number of active neurons: 3
 >> iter 81000, loss: 0.043888
 >> iter 82000, loss: 0.049633
 >> iter 83000, loss: 0.055862
 >> iter 84000, loss: 0.057502
 >> iter 85000, loss: 0.054888
 >> iter 86000, loss: 0.055077
 >> iter 87000, loss: 0.039923
 >> iter 88000, loss: 0.034266
 >> iter 89000, loss: 0.031104
 >> iter 90000, loss: 0.041043
   Number of active neurons: 3
 >> iter 91000, loss: 0.046999
 >> iter 92000, loss: 0.055486
 >> iter 93000, loss: 0.048102
 >> iter 94000, loss: 0.048383
 >> iter 95000, loss: 0.037376
 >> iter 96000, loss: 0.034823
 >> iter 97000, loss: 0.058912
 >> iter 98000, loss: 0.054599
 >> iter 99000, loss: 0.072023
 >> iter 100000, loss: 0.048640
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.460383
 >> iter 2000, loss: 4.535211
 >> iter 3000, loss: 1.823700
 >> iter 4000, loss: 0.780362
 >> iter 5000, loss: 0.359725
 >> iter 6000, loss: 0.230256
 >> iter 7000, loss: 0.156686
 >> iter 8000, loss: 0.111321
 >> iter 9000, loss: 0.104464
 >> iter 10000, loss: 0.077296
   Number of active neurons: 11
 >> iter 11000, loss: 0.069240
 >> iter 12000, loss: 0.090296
 >> iter 13000, loss: 0.079472
 >> iter 14000, loss: 0.090974
 >> iter 15000, loss: 0.070644
 >> iter 16000, loss: 0.059332
 >> iter 17000, loss: 0.052662
 >> iter 18000, loss: 0.048673
 >> iter 19000, loss: 0.070314
 >> iter 20000, loss: 0.080623
   Number of active neurons: 6
 >> iter 21000, loss: 0.054931
 >> iter 22000, loss: 0.047018
 >> iter 23000, loss: 0.044148
 >> iter 24000, loss: 0.061109
 >> iter 25000, loss: 0.070363
 >> iter 26000, loss: 0.061873
 >> iter 27000, loss: 0.048950
 >> iter 28000, loss: 0.062859
 >> iter 29000, loss: 0.054670
 >> iter 30000, loss: 0.050884
   Number of active neurons: 5
 >> iter 31000, loss: 0.057392
 >> iter 32000, loss: 0.061320
 >> iter 33000, loss: 0.046937
 >> iter 34000, loss: 0.033877
 >> iter 35000, loss: 0.039681
 >> iter 36000, loss: 0.058096
 >> iter 37000, loss: 0.055192
 >> iter 38000, loss: 0.038543
 >> iter 39000, loss: 0.031132
 >> iter 40000, loss: 0.054524
   Number of active neurons: 3
 >> iter 41000, loss: 0.057295
 >> iter 42000, loss: 0.045464
 >> iter 43000, loss: 0.044464
 >> iter 44000, loss: 0.044818
 >> iter 45000, loss: 0.047109
 >> iter 46000, loss: 0.052553
 >> iter 47000, loss: 0.057013
 >> iter 48000, loss: 0.050712
 >> iter 49000, loss: 0.048298
 >> iter 50000, loss: 0.061084
   Number of active neurons: 3
 >> iter 51000, loss: 0.057445
 >> iter 52000, loss: 0.051427
 >> iter 53000, loss: 0.053307
 >> iter 54000, loss: 0.065535
 >> iter 55000, loss: 0.053276
 >> iter 56000, loss: 0.040057
 >> iter 57000, loss: 0.059293
 >> iter 58000, loss: 0.047957
 >> iter 59000, loss: 0.058034
 >> iter 60000, loss: 0.078904
   Number of active neurons: 3
 >> iter 61000, loss: 0.047267
 >> iter 62000, loss: 0.055452
 >> iter 63000, loss: 0.079851
 >> iter 64000, loss: 0.054897
 >> iter 65000, loss: 0.061832
 >> iter 66000, loss: 0.043002
 >> iter 67000, loss: 0.050036
 >> iter 68000, loss: 0.038884
 >> iter 69000, loss: 0.039116
 >> iter 70000, loss: 0.051002
   Number of active neurons: 3
 >> iter 71000, loss: 0.039925
 >> iter 72000, loss: 0.031837
 >> iter 73000, loss: 0.036947
 >> iter 74000, loss: 0.043451
 >> iter 75000, loss: 0.053435
 >> iter 76000, loss: 0.048714
 >> iter 77000, loss: 0.043994
 >> iter 78000, loss: 0.049110
 >> iter 79000, loss: 0.050176
 >> iter 80000, loss: 0.051524
   Number of active neurons: 3
 >> iter 81000, loss: 0.063797
 >> iter 82000, loss: 0.048022
 >> iter 83000, loss: 0.055172
 >> iter 84000, loss: 0.038460
 >> iter 85000, loss: 0.039018
 >> iter 86000, loss: 0.044020
 >> iter 87000, loss: 0.035763
 >> iter 88000, loss: 0.037728
 >> iter 89000, loss: 0.048456
 >> iter 90000, loss: 0.052721
   Number of active neurons: 3
 >> iter 91000, loss: 0.052112
 >> iter 92000, loss: 0.055186
 >> iter 93000, loss: 0.052952
 >> iter 94000, loss: 0.042903
 >> iter 95000, loss: 0.042730
 >> iter 96000, loss: 0.048990
 >> iter 97000, loss: 0.051590
 >> iter 98000, loss: 0.062519
 >> iter 99000, loss: 0.067182
 >> iter 100000, loss: 0.048166
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.236102
 >> iter 2000, loss: 4.367286
 >> iter 3000, loss: 1.743674
 >> iter 4000, loss: 0.694989
 >> iter 5000, loss: 0.323615
 >> iter 6000, loss: 0.153775
 >> iter 7000, loss: 0.100124
 >> iter 8000, loss: 0.103458
 >> iter 9000, loss: 0.065157
 >> iter 10000, loss: 0.082751
   Number of active neurons: 7
 >> iter 11000, loss: 0.075833
 >> iter 12000, loss: 0.078724
 >> iter 13000, loss: 0.061017
 >> iter 14000, loss: 0.087918
 >> iter 15000, loss: 0.069878
 >> iter 16000, loss: 0.069299
 >> iter 17000, loss: 0.080692
 >> iter 18000, loss: 0.084389
 >> iter 19000, loss: 0.084019
 >> iter 20000, loss: 0.060051
   Number of active neurons: 7
 >> iter 21000, loss: 0.058824
 >> iter 22000, loss: 0.049055
 >> iter 23000, loss: 0.049857
 >> iter 24000, loss: 0.092086
 >> iter 25000, loss: 0.060308
 >> iter 26000, loss: 0.058239
 >> iter 27000, loss: 0.071030
 >> iter 28000, loss: 0.051551
 >> iter 29000, loss: 0.058403
 >> iter 30000, loss: 0.056792
   Number of active neurons: 7
 >> iter 31000, loss: 0.096171
 >> iter 32000, loss: 0.070705
 >> iter 33000, loss: 0.066622
 >> iter 34000, loss: 0.053187
 >> iter 35000, loss: 0.046232
 >> iter 36000, loss: 0.055500
 >> iter 37000, loss: 0.046544
 >> iter 38000, loss: 0.056638
 >> iter 39000, loss: 0.049204
 >> iter 40000, loss: 0.058831
   Number of active neurons: 6
 >> iter 41000, loss: 0.047412
 >> iter 42000, loss: 0.042633
 >> iter 43000, loss: 0.078414
 >> iter 44000, loss: 0.055026
 >> iter 45000, loss: 0.050600
 >> iter 46000, loss: 0.062276
 >> iter 47000, loss: 0.065246
 >> iter 48000, loss: 0.047309
 >> iter 49000, loss: 0.060566
 >> iter 50000, loss: 0.041783
   Number of active neurons: 4
 >> iter 51000, loss: 0.048606
 >> iter 52000, loss: 0.041226
 >> iter 53000, loss: 0.053493
 >> iter 54000, loss: 0.042111
 >> iter 55000, loss: 0.037601
 >> iter 56000, loss: 0.047611
 >> iter 57000, loss: 0.054205
 >> iter 58000, loss: 0.039019
 >> iter 59000, loss: 0.041110
 >> iter 60000, loss: 0.052546
   Number of active neurons: 4
 >> iter 61000, loss: 0.050842
 >> iter 62000, loss: 0.057586
 >> iter 63000, loss: 0.054209
 >> iter 64000, loss: 0.061435
 >> iter 65000, loss: 0.049412
 >> iter 66000, loss: 0.050645
 >> iter 67000, loss: 0.063962
 >> iter 68000, loss: 0.049846
 >> iter 69000, loss: 0.047102
 >> iter 70000, loss: 0.048334
   Number of active neurons: 4
 >> iter 71000, loss: 0.040101
 >> iter 72000, loss: 0.059031
 >> iter 73000, loss: 0.059612
 >> iter 74000, loss: 0.051048
 >> iter 75000, loss: 0.035962
 >> iter 76000, loss: 0.046814
 >> iter 77000, loss: 0.064230
 >> iter 78000, loss: 0.066441
 >> iter 79000, loss: 0.073447
 >> iter 80000, loss: 0.068964
   Number of active neurons: 4
 >> iter 81000, loss: 0.047946
 >> iter 82000, loss: 0.047114
 >> iter 83000, loss: 0.042656
 >> iter 84000, loss: 0.048894
 >> iter 85000, loss: 0.046792
 >> iter 86000, loss: 0.043500
 >> iter 87000, loss: 0.071898
 >> iter 88000, loss: 0.050811
 >> iter 89000, loss: 0.074791
 >> iter 90000, loss: 0.055331
   Number of active neurons: 4
 >> iter 91000, loss: 0.047508
 >> iter 92000, loss: 0.044370
 >> iter 93000, loss: 0.047594
 >> iter 94000, loss: 0.054230
 >> iter 95000, loss: 0.071632
 >> iter 96000, loss: 0.059351
 >> iter 97000, loss: 0.048259
 >> iter 98000, loss: 0.038864
 >> iter 99000, loss: 0.038513
 >> iter 100000, loss: 0.042105
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 11.315703
 >> iter 2000, loss: 4.490981
 >> iter 3000, loss: 1.777960
 >> iter 4000, loss: 0.754471
 >> iter 5000, loss: 0.330407
 >> iter 6000, loss: 0.192202
 >> iter 7000, loss: 0.135829
 >> iter 8000, loss: 0.107716
 >> iter 9000, loss: 0.101785
 >> iter 10000, loss: 0.079592
   Number of active neurons: 9
 >> iter 11000, loss: 0.086213
 >> iter 12000, loss: 0.091153
 >> iter 13000, loss: 0.080052
 >> iter 14000, loss: 0.072026
 >> iter 15000, loss: 0.065392
 >> iter 16000, loss: 0.078124
 >> iter 17000, loss: 0.075988
 >> iter 18000, loss: 0.060266
 >> iter 19000, loss: 0.061014
 >> iter 20000, loss: 0.052005
   Number of active neurons: 6
 >> iter 21000, loss: 0.046668
 >> iter 22000, loss: 0.048920
 >> iter 23000, loss: 0.053500
 >> iter 24000, loss: 0.056913
 >> iter 25000, loss: 0.052938
 >> iter 26000, loss: 0.038188
 >> iter 27000, loss: 0.034240
 >> iter 28000, loss: 0.045261
 >> iter 29000, loss: 0.046273
 >> iter 30000, loss: 0.053405
   Number of active neurons: 5
 >> iter 31000, loss: 0.047092
 >> iter 32000, loss: 0.046626
 >> iter 33000, loss: 0.049784
 >> iter 34000, loss: 0.048496
 >> iter 35000, loss: 0.036759
 >> iter 36000, loss: 0.030814
 >> iter 37000, loss: 0.042709
 >> iter 38000, loss: 0.030303
 >> iter 39000, loss: 0.033151
 >> iter 40000, loss: 0.038638
   Number of active neurons: 4
 >> iter 41000, loss: 0.036687
 >> iter 42000, loss: 0.043308
 >> iter 43000, loss: 0.058331
 >> iter 44000, loss: 0.062603
 >> iter 45000, loss: 0.069454
 >> iter 46000, loss: 0.057431
 >> iter 47000, loss: 0.067731
 >> iter 48000, loss: 0.058255
 >> iter 49000, loss: 0.040899
 >> iter 50000, loss: 0.037847
   Number of active neurons: 3
 >> iter 51000, loss: 0.043653
 >> iter 52000, loss: 0.036167
 >> iter 53000, loss: 0.069113
 >> iter 54000, loss: 0.060176
 >> iter 55000, loss: 0.057398
 >> iter 56000, loss: 0.046705
 >> iter 57000, loss: 0.045735
 >> iter 58000, loss: 0.058101
 >> iter 59000, loss: 0.070697
 >> iter 60000, loss: 0.049884
   Number of active neurons: 3
 >> iter 61000, loss: 0.035812
 >> iter 62000, loss: 0.039929
 >> iter 63000, loss: 0.033208
 >> iter 64000, loss: 0.040676
 >> iter 65000, loss: 0.045528
 >> iter 66000, loss: 0.056629
 >> iter 67000, loss: 0.053692
 >> iter 68000, loss: 0.064946
 >> iter 69000, loss: 0.063472
 >> iter 70000, loss: 0.067502
   Number of active neurons: 3
 >> iter 71000, loss: 0.053660
 >> iter 72000, loss: 0.042285
 >> iter 73000, loss: 0.051569
 >> iter 74000, loss: 0.046169
 >> iter 75000, loss: 0.046785
 >> iter 76000, loss: 0.039255
 >> iter 77000, loss: 0.037100
 >> iter 78000, loss: 0.043527
 >> iter 79000, loss: 0.054598
 >> iter 80000, loss: 0.049163
   Number of active neurons: 3
 >> iter 81000, loss: 0.049598
 >> iter 82000, loss: 0.051186
 >> iter 83000, loss: 0.040303
 >> iter 84000, loss: 0.034465
 >> iter 85000, loss: 0.033293
 >> iter 86000, loss: 0.033060
 >> iter 87000, loss: 0.037704
 >> iter 88000, loss: 0.052050
 >> iter 89000, loss: 0.062992
 >> iter 90000, loss: 0.048317
   Number of active neurons: 2
 >> iter 91000, loss: 0.053798
 >> iter 92000, loss: 0.040761
 >> iter 93000, loss: 0.043265
 >> iter 94000, loss: 0.033072
 >> iter 95000, loss: 0.045622
 >> iter 96000, loss: 0.060237
 >> iter 97000, loss: 0.041470
 >> iter 98000, loss: 0.043636
 >> iter 99000, loss: 0.033281
 >> iter 100000, loss: 0.036891
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.423948
 >> iter 2000, loss: 4.475666
 >> iter 3000, loss: 1.798008
 >> iter 4000, loss: 0.734802
 >> iter 5000, loss: 0.383056
 >> iter 6000, loss: 0.210715
 >> iter 7000, loss: 0.124122
 >> iter 8000, loss: 0.079511
 >> iter 9000, loss: 0.083643
 >> iter 10000, loss: 0.075655
   Number of active neurons: 7
 >> iter 11000, loss: 0.065941
 >> iter 12000, loss: 0.068281
 >> iter 13000, loss: 0.077036
 >> iter 14000, loss: 0.069400
 >> iter 15000, loss: 0.072850
 >> iter 16000, loss: 0.061202
 >> iter 17000, loss: 0.053043
 >> iter 18000, loss: 0.052227
 >> iter 19000, loss: 0.067912
 >> iter 20000, loss: 0.052300
   Number of active neurons: 6
 >> iter 21000, loss: 0.063539
 >> iter 22000, loss: 0.062278
 >> iter 23000, loss: 0.046608
 >> iter 24000, loss: 0.049995
 >> iter 25000, loss: 0.048299
 >> iter 26000, loss: 0.048673
 >> iter 27000, loss: 0.052588
 >> iter 28000, loss: 0.077323
 >> iter 29000, loss: 0.056458
 >> iter 30000, loss: 0.042330
   Number of active neurons: 6
 >> iter 31000, loss: 0.044622
 >> iter 32000, loss: 0.069514
 >> iter 33000, loss: 0.065628
 >> iter 34000, loss: 0.044716
 >> iter 35000, loss: 0.047643
 >> iter 36000, loss: 0.053081
 >> iter 37000, loss: 0.045420
 >> iter 38000, loss: 0.059625
 >> iter 39000, loss: 0.046825
 >> iter 40000, loss: 0.042320
   Number of active neurons: 5
 >> iter 41000, loss: 0.048648
 >> iter 42000, loss: 0.053255
 >> iter 43000, loss: 0.048089
 >> iter 44000, loss: 0.062603
 >> iter 45000, loss: 0.065651
 >> iter 46000, loss: 0.067453
 >> iter 47000, loss: 0.049449
 >> iter 48000, loss: 0.060131
 >> iter 49000, loss: 0.040411
 >> iter 50000, loss: 0.052883
   Number of active neurons: 5
 >> iter 51000, loss: 0.070602
 >> iter 52000, loss: 0.050952
 >> iter 53000, loss: 0.047864
 >> iter 54000, loss: 0.060968
 >> iter 55000, loss: 0.050116
 >> iter 56000, loss: 0.041481
 >> iter 57000, loss: 0.042792
 >> iter 58000, loss: 0.045367
 >> iter 59000, loss: 0.043849
 >> iter 60000, loss: 0.044153
   Number of active neurons: 5
 >> iter 61000, loss: 0.057847
 >> iter 62000, loss: 0.061732
 >> iter 63000, loss: 0.051401
 >> iter 64000, loss: 0.068852
 >> iter 65000, loss: 0.054237
 >> iter 66000, loss: 0.051963
 >> iter 67000, loss: 0.053943
 >> iter 68000, loss: 0.057615
 >> iter 69000, loss: 0.057143
 >> iter 70000, loss: 0.062161
   Number of active neurons: 4
 >> iter 71000, loss: 0.049743
 >> iter 72000, loss: 0.053438
 >> iter 73000, loss: 0.041772
 >> iter 74000, loss: 0.032762
 >> iter 75000, loss: 0.043959
 >> iter 76000, loss: 0.057466
 >> iter 77000, loss: 0.060709
 >> iter 78000, loss: 0.059207
 >> iter 79000, loss: 0.045064
 >> iter 80000, loss: 0.040454
   Number of active neurons: 4
 >> iter 81000, loss: 0.037537
 >> iter 82000, loss: 0.053767
 >> iter 83000, loss: 0.044478
 >> iter 84000, loss: 0.048154
 >> iter 85000, loss: 0.054039
 >> iter 86000, loss: 0.045094
 >> iter 87000, loss: 0.040338
 >> iter 88000, loss: 0.037392
 >> iter 89000, loss: 0.038512
 >> iter 90000, loss: 0.031047
   Number of active neurons: 4
 >> iter 91000, loss: 0.038617
 >> iter 92000, loss: 0.035758
 >> iter 93000, loss: 0.043836
 >> iter 94000, loss: 0.074751
 >> iter 95000, loss: 0.046994
 >> iter 96000, loss: 0.036618
 >> iter 97000, loss: 0.040007
 >> iter 98000, loss: 0.055243
 >> iter 99000, loss: 0.046975
 >> iter 100000, loss: 0.035430
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.362816
 >> iter 2000, loss: 4.422465
 >> iter 3000, loss: 1.758431
 >> iter 4000, loss: 0.725978
 >> iter 5000, loss: 0.316836
 >> iter 6000, loss: 0.177065
 >> iter 7000, loss: 0.119011
 >> iter 8000, loss: 0.102501
 >> iter 9000, loss: 0.090649
 >> iter 10000, loss: 0.070257
   Number of active neurons: 9
 >> iter 11000, loss: 0.060643
 >> iter 12000, loss: 0.069032
 >> iter 13000, loss: 0.064582
 >> iter 14000, loss: 0.055465
 >> iter 15000, loss: 0.060518
 >> iter 16000, loss: 0.068299
 >> iter 17000, loss: 0.067518
 >> iter 18000, loss: 0.050522
 >> iter 19000, loss: 0.061137
 >> iter 20000, loss: 0.046877
   Number of active neurons: 6
 >> iter 21000, loss: 0.050711
 >> iter 22000, loss: 0.057391
 >> iter 23000, loss: 0.059603
 >> iter 24000, loss: 0.046281
 >> iter 25000, loss: 0.048531
 >> iter 26000, loss: 0.039053
 >> iter 27000, loss: 0.040278
 >> iter 28000, loss: 0.049375
 >> iter 29000, loss: 0.047184
 >> iter 30000, loss: 0.040225
   Number of active neurons: 4
 >> iter 31000, loss: 0.055627
 >> iter 32000, loss: 0.047547
 >> iter 33000, loss: 0.056381
 >> iter 34000, loss: 0.067930
 >> iter 35000, loss: 0.061267
 >> iter 36000, loss: 0.055872
 >> iter 37000, loss: 0.042046
 >> iter 38000, loss: 0.036912
 >> iter 39000, loss: 0.063280
 >> iter 40000, loss: 0.048160
   Number of active neurons: 3
 >> iter 41000, loss: 0.041602
 >> iter 42000, loss: 0.042433
 >> iter 43000, loss: 0.044069
 >> iter 44000, loss: 0.035498
 >> iter 45000, loss: 0.038813
 >> iter 46000, loss: 0.041893
 >> iter 47000, loss: 0.058463
 >> iter 48000, loss: 0.041459
 >> iter 49000, loss: 0.034878
 >> iter 50000, loss: 0.049362
   Number of active neurons: 3
 >> iter 51000, loss: 0.046215
 >> iter 52000, loss: 0.056035
 >> iter 53000, loss: 0.065381
 >> iter 54000, loss: 0.048189
 >> iter 55000, loss: 0.036325
 >> iter 56000, loss: 0.046909
 >> iter 57000, loss: 0.048852
 >> iter 58000, loss: 0.046426
 >> iter 59000, loss: 0.061670
 >> iter 60000, loss: 0.048525
   Number of active neurons: 3
 >> iter 61000, loss: 0.044559
 >> iter 62000, loss: 0.039746
 >> iter 63000, loss: 0.037016
 >> iter 64000, loss: 0.049320
 >> iter 65000, loss: 0.038598
 >> iter 66000, loss: 0.053031
 >> iter 67000, loss: 0.042413
 >> iter 68000, loss: 0.054946
 >> iter 69000, loss: 0.064829
 >> iter 70000, loss: 0.059545
   Number of active neurons: 2
 >> iter 71000, loss: 0.048626
 >> iter 72000, loss: 0.050056
 >> iter 73000, loss: 0.045868
 >> iter 74000, loss: 0.036845
 >> iter 75000, loss: 0.034655
 >> iter 76000, loss: 0.035843
 >> iter 77000, loss: 0.039236
 >> iter 78000, loss: 0.037568
 >> iter 79000, loss: 0.040451
 >> iter 80000, loss: 0.035737
   Number of active neurons: 2
 >> iter 81000, loss: 0.043717
 >> iter 82000, loss: 0.059856
 >> iter 83000, loss: 0.037521
 >> iter 84000, loss: 0.033897
 >> iter 85000, loss: 0.046922
 >> iter 86000, loss: 0.047368
 >> iter 87000, loss: 0.049520
 >> iter 88000, loss: 0.041209
 >> iter 89000, loss: 0.036977
 >> iter 90000, loss: 0.033851
   Number of active neurons: 2
 >> iter 91000, loss: 0.042749
 >> iter 92000, loss: 0.044870
 >> iter 93000, loss: 0.036672
 >> iter 94000, loss: 0.029489
 >> iter 95000, loss: 0.042095
 >> iter 96000, loss: 0.054502
 >> iter 97000, loss: 0.065509
 >> iter 98000, loss: 0.039993
 >> iter 99000, loss: 0.034206
 >> iter 100000, loss: 0.038394
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 11.288399
 >> iter 2000, loss: 4.435887
 >> iter 3000, loss: 1.781981
 >> iter 4000, loss: 0.754819
 >> iter 5000, loss: 0.386937
 >> iter 6000, loss: 0.201644
 >> iter 7000, loss: 0.138866
 >> iter 8000, loss: 0.118002
 >> iter 9000, loss: 0.087680
 >> iter 10000, loss: 0.092307
   Number of active neurons: 9
 >> iter 11000, loss: 0.088674
 >> iter 12000, loss: 0.072888
 >> iter 13000, loss: 0.075441
 >> iter 14000, loss: 0.069687
 >> iter 15000, loss: 0.085699
 >> iter 16000, loss: 0.063319
 >> iter 17000, loss: 0.061141
 >> iter 18000, loss: 0.049937
 >> iter 19000, loss: 0.062586
 >> iter 20000, loss: 0.059980
   Number of active neurons: 8
 >> iter 21000, loss: 0.054105
 >> iter 22000, loss: 0.052921
 >> iter 23000, loss: 0.072735
 >> iter 24000, loss: 0.063740
 >> iter 25000, loss: 0.061713
 >> iter 26000, loss: 0.060309
 >> iter 27000, loss: 0.084210
 >> iter 28000, loss: 0.070088
 >> iter 29000, loss: 0.055707
 >> iter 30000, loss: 0.045474
   Number of active neurons: 6
 >> iter 31000, loss: 0.071856
 >> iter 32000, loss: 0.061354
 >> iter 33000, loss: 0.060341
 >> iter 34000, loss: 0.042725
 >> iter 35000, loss: 0.042382
 >> iter 36000, loss: 0.049190
 >> iter 37000, loss: 0.047527
 >> iter 38000, loss: 0.069331
 >> iter 39000, loss: 0.062405
 >> iter 40000, loss: 0.067892
   Number of active neurons: 5
 >> iter 41000, loss: 0.062548
 >> iter 42000, loss: 0.046242
 >> iter 43000, loss: 0.043951
 >> iter 44000, loss: 0.046183
 >> iter 45000, loss: 0.046901
 >> iter 46000, loss: 0.048287
 >> iter 47000, loss: 0.057131
 >> iter 48000, loss: 0.041107
 >> iter 49000, loss: 0.063420
 >> iter 50000, loss: 0.051571
   Number of active neurons: 4
 >> iter 51000, loss: 0.062557
 >> iter 52000, loss: 0.053131
 >> iter 53000, loss: 0.057528
 >> iter 54000, loss: 0.047275
 >> iter 55000, loss: 0.053589
 >> iter 56000, loss: 0.053260
 >> iter 57000, loss: 0.054907
 >> iter 58000, loss: 0.043506
 >> iter 59000, loss: 0.036611
 >> iter 60000, loss: 0.040678
   Number of active neurons: 4
 >> iter 61000, loss: 0.033475
 >> iter 62000, loss: 0.029866
 >> iter 63000, loss: 0.040372
 >> iter 64000, loss: 0.044994
 >> iter 65000, loss: 0.042943
 >> iter 66000, loss: 0.031505
 >> iter 67000, loss: 0.061589
 >> iter 68000, loss: 0.043991
 >> iter 69000, loss: 0.046759
 >> iter 70000, loss: 0.048728
   Number of active neurons: 4
 >> iter 71000, loss: 0.049351
 >> iter 72000, loss: 0.058946
 >> iter 73000, loss: 0.048860
 >> iter 74000, loss: 0.056015
 >> iter 75000, loss: 0.061756
 >> iter 76000, loss: 0.061786
 >> iter 77000, loss: 0.047709
 >> iter 78000, loss: 0.039547
 >> iter 79000, loss: 0.039787
 >> iter 80000, loss: 0.046352
   Number of active neurons: 4
 >> iter 81000, loss: 0.049054
 >> iter 82000, loss: 0.065479
 >> iter 83000, loss: 0.060573
 >> iter 84000, loss: 0.054750
 >> iter 85000, loss: 0.054848
 >> iter 86000, loss: 0.038440
 >> iter 87000, loss: 0.037047
 >> iter 88000, loss: 0.061582
 >> iter 89000, loss: 0.052033
 >> iter 90000, loss: 0.063685
   Number of active neurons: 4
 >> iter 91000, loss: 0.048972
 >> iter 92000, loss: 0.044674
 >> iter 93000, loss: 0.042826
 >> iter 94000, loss: 0.050391
 >> iter 95000, loss: 0.053218
 >> iter 96000, loss: 0.052154
 >> iter 97000, loss: 0.073704
 >> iter 98000, loss: 0.052635
 >> iter 99000, loss: 0.052347
 >> iter 100000, loss: 0.053161
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455163
   Number of active neurons: 0
 >> iter 1000, loss: 11.308914
 >> iter 2000, loss: 4.440300
 >> iter 3000, loss: 1.748812
 >> iter 4000, loss: 0.710231
 >> iter 5000, loss: 0.334645
 >> iter 6000, loss: 0.167702
 >> iter 7000, loss: 0.106308
 >> iter 8000, loss: 0.106136
 >> iter 9000, loss: 0.112464
 >> iter 10000, loss: 0.085405
   Number of active neurons: 6
 >> iter 11000, loss: 0.072988
 >> iter 12000, loss: 0.061649
 >> iter 13000, loss: 0.075140
 >> iter 14000, loss: 0.066988
 >> iter 15000, loss: 0.063541
 >> iter 16000, loss: 0.055077
 >> iter 17000, loss: 0.054208
 >> iter 18000, loss: 0.063789
 >> iter 19000, loss: 0.050979
 >> iter 20000, loss: 0.060954
   Number of active neurons: 6
 >> iter 21000, loss: 0.066251
 >> iter 22000, loss: 0.068868
 >> iter 23000, loss: 0.075283
 >> iter 24000, loss: 0.067739
 >> iter 25000, loss: 0.079392
 >> iter 26000, loss: 0.068302
 >> iter 27000, loss: 0.084863
 >> iter 28000, loss: 0.056830
 >> iter 29000, loss: 0.059417
 >> iter 30000, loss: 0.051503
   Number of active neurons: 5
 >> iter 31000, loss: 0.070388
 >> iter 32000, loss: 0.065213
 >> iter 33000, loss: 0.055849
 >> iter 34000, loss: 0.060828
 >> iter 35000, loss: 0.049210
 >> iter 36000, loss: 0.038211
 >> iter 37000, loss: 0.090866
 >> iter 38000, loss: 0.082225
 >> iter 39000, loss: 0.062306
 >> iter 40000, loss: 0.048279
   Number of active neurons: 5
 >> iter 41000, loss: 0.060013
 >> iter 42000, loss: 0.052842
 >> iter 43000, loss: 0.052407
 >> iter 44000, loss: 0.072326
 >> iter 45000, loss: 0.054173
 >> iter 46000, loss: 0.053305
 >> iter 47000, loss: 0.056970
 >> iter 48000, loss: 0.055862
 >> iter 49000, loss: 0.056093
 >> iter 50000, loss: 0.042756
   Number of active neurons: 5
 >> iter 51000, loss: 0.037688
 >> iter 52000, loss: 0.039627
 >> iter 53000, loss: 0.037212
 >> iter 54000, loss: 0.049409
 >> iter 55000, loss: 0.067475
 >> iter 56000, loss: 0.053903
 >> iter 57000, loss: 0.050728
 >> iter 58000, loss: 0.052203
 >> iter 59000, loss: 0.070968
 >> iter 60000, loss: 0.063206
   Number of active neurons: 5
 >> iter 61000, loss: 0.062180
 >> iter 62000, loss: 0.057362
 >> iter 63000, loss: 0.054750
 >> iter 64000, loss: 0.047571
 >> iter 65000, loss: 0.046719
 >> iter 66000, loss: 0.052886
 >> iter 67000, loss: 0.052131
 >> iter 68000, loss: 0.049929
 >> iter 69000, loss: 0.040250
 >> iter 70000, loss: 0.064572
   Number of active neurons: 4
 >> iter 71000, loss: 0.058231
 >> iter 72000, loss: 0.058903
 >> iter 73000, loss: 0.050916
 >> iter 74000, loss: 0.049461
 >> iter 75000, loss: 0.059164
 >> iter 76000, loss: 0.047760
 >> iter 77000, loss: 0.034769
 >> iter 78000, loss: 0.046741
 >> iter 79000, loss: 0.041089
 >> iter 80000, loss: 0.055596
   Number of active neurons: 4
 >> iter 81000, loss: 0.052752
 >> iter 82000, loss: 0.073793
 >> iter 83000, loss: 0.045770
 >> iter 84000, loss: 0.039754
 >> iter 85000, loss: 0.031918
 >> iter 86000, loss: 0.041407
 >> iter 87000, loss: 0.041547
 >> iter 88000, loss: 0.036273
 >> iter 89000, loss: 0.047393
 >> iter 90000, loss: 0.055464
   Number of active neurons: 4
 >> iter 91000, loss: 0.051792
 >> iter 92000, loss: 0.037283
 >> iter 93000, loss: 0.036129
 >> iter 94000, loss: 0.044937
 >> iter 95000, loss: 0.071928
 >> iter 96000, loss: 0.049898
 >> iter 97000, loss: 0.041022
 >> iter 98000, loss: 0.047760
 >> iter 99000, loss: 0.056570
 >> iter 100000, loss: 0.079011
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.386596
 >> iter 2000, loss: 4.511570
 >> iter 3000, loss: 1.811685
 >> iter 4000, loss: 0.729074
 >> iter 5000, loss: 0.351144
 >> iter 6000, loss: 0.172632
 >> iter 7000, loss: 0.117854
 >> iter 8000, loss: 0.121751
 >> iter 9000, loss: 0.081254
 >> iter 10000, loss: 0.099006
   Number of active neurons: 9
 >> iter 11000, loss: 0.074460
 >> iter 12000, loss: 0.076017
 >> iter 13000, loss: 0.078585
 >> iter 14000, loss: 0.073862
 >> iter 15000, loss: 0.087736
 >> iter 16000, loss: 0.075858
 >> iter 17000, loss: 0.065834
 >> iter 18000, loss: 0.071083
 >> iter 19000, loss: 0.065421
 >> iter 20000, loss: 0.062526
   Number of active neurons: 9
 >> iter 21000, loss: 0.093666
 >> iter 22000, loss: 0.063565
 >> iter 23000, loss: 0.060760
 >> iter 24000, loss: 0.050578
 >> iter 25000, loss: 0.053478
 >> iter 26000, loss: 0.061114
 >> iter 27000, loss: 0.051160
 >> iter 28000, loss: 0.060179
 >> iter 29000, loss: 0.092672
 >> iter 30000, loss: 0.089688
   Number of active neurons: 7
 >> iter 31000, loss: 0.088905
 >> iter 32000, loss: 0.068695
 >> iter 33000, loss: 0.077151
 >> iter 34000, loss: 0.076210
 >> iter 35000, loss: 0.055024
 >> iter 36000, loss: 0.052101
 >> iter 37000, loss: 0.068005
 >> iter 38000, loss: 0.067387
 >> iter 39000, loss: 0.059821
 >> iter 40000, loss: 0.051306
   Number of active neurons: 7
 >> iter 41000, loss: 0.049695
 >> iter 42000, loss: 0.043532
 >> iter 43000, loss: 0.069586
 >> iter 44000, loss: 0.075479
 >> iter 45000, loss: 0.068007
 >> iter 46000, loss: 0.054055
 >> iter 47000, loss: 0.083933
 >> iter 48000, loss: 0.074990
 >> iter 49000, loss: 0.045913
 >> iter 50000, loss: 0.069905
   Number of active neurons: 6
 >> iter 51000, loss: 0.052590
 >> iter 52000, loss: 0.073667
 >> iter 53000, loss: 0.081414
 >> iter 54000, loss: 0.051819
 >> iter 55000, loss: 0.043013
 >> iter 56000, loss: 0.042229
 >> iter 57000, loss: 0.050815
 >> iter 58000, loss: 0.049711
 >> iter 59000, loss: 0.056827
 >> iter 60000, loss: 0.049224
   Number of active neurons: 5
 >> iter 61000, loss: 0.055401
 >> iter 62000, loss: 0.069222
 >> iter 63000, loss: 0.064886
 >> iter 64000, loss: 0.078831
 >> iter 65000, loss: 0.055934
 >> iter 66000, loss: 0.060689
 >> iter 67000, loss: 0.052192
 >> iter 68000, loss: 0.045732
 >> iter 69000, loss: 0.042423
 >> iter 70000, loss: 0.050074
   Number of active neurons: 5
 >> iter 71000, loss: 0.037826
 >> iter 72000, loss: 0.044911
 >> iter 73000, loss: 0.056339
 >> iter 74000, loss: 0.047446
 >> iter 75000, loss: 0.060378
 >> iter 76000, loss: 0.047490
 >> iter 77000, loss: 0.074153
 >> iter 78000, loss: 0.064353
 >> iter 79000, loss: 0.059740
 >> iter 80000, loss: 0.050031
   Number of active neurons: 5
 >> iter 81000, loss: 0.060765
 >> iter 82000, loss: 0.049572
 >> iter 83000, loss: 0.052326
 >> iter 84000, loss: 0.053024
 >> iter 85000, loss: 0.059953
 >> iter 86000, loss: 0.046155
 >> iter 87000, loss: 0.045681
 >> iter 88000, loss: 0.057501
 >> iter 89000, loss: 0.068673
 >> iter 90000, loss: 0.067415
   Number of active neurons: 5
 >> iter 91000, loss: 0.049684
 >> iter 92000, loss: 0.059483
 >> iter 93000, loss: 0.060924
 >> iter 94000, loss: 0.058283
 >> iter 95000, loss: 0.044735
 >> iter 96000, loss: 0.046265
 >> iter 97000, loss: 0.037427
 >> iter 98000, loss: 0.046722
 >> iter 99000, loss: 0.052973
 >> iter 100000, loss: 0.059735
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.292729
 >> iter 2000, loss: 4.385350
 >> iter 3000, loss: 1.731534
 >> iter 4000, loss: 0.743104
 >> iter 5000, loss: 0.339395
 >> iter 6000, loss: 0.177014
 >> iter 7000, loss: 0.141846
 >> iter 8000, loss: 0.122515
 >> iter 9000, loss: 0.103104
 >> iter 10000, loss: 0.085217
   Number of active neurons: 7
 >> iter 11000, loss: 0.072634
 >> iter 12000, loss: 0.061916
 >> iter 13000, loss: 0.074435
 >> iter 14000, loss: 0.068283
 >> iter 15000, loss: 0.060727
 >> iter 16000, loss: 0.056225
 >> iter 17000, loss: 0.053137
 >> iter 18000, loss: 0.055189
 >> iter 19000, loss: 0.050872
 >> iter 20000, loss: 0.042740
   Number of active neurons: 7
 >> iter 21000, loss: 0.052616
 >> iter 22000, loss: 0.045694
 >> iter 23000, loss: 0.051729
 >> iter 24000, loss: 0.054785
 >> iter 25000, loss: 0.059131
 >> iter 26000, loss: 0.056964
 >> iter 27000, loss: 0.061148
 >> iter 28000, loss: 0.048009
 >> iter 29000, loss: 0.079685
 >> iter 30000, loss: 0.068115
   Number of active neurons: 5
 >> iter 31000, loss: 0.049044
 >> iter 32000, loss: 0.037008
 >> iter 33000, loss: 0.058969
 >> iter 34000, loss: 0.054871
 >> iter 35000, loss: 0.065123
 >> iter 36000, loss: 0.046719
 >> iter 37000, loss: 0.087145
 >> iter 38000, loss: 0.069441
 >> iter 39000, loss: 0.058874
 >> iter 40000, loss: 0.048537
   Number of active neurons: 4
 >> iter 41000, loss: 0.054841
 >> iter 42000, loss: 0.047641
 >> iter 43000, loss: 0.051303
 >> iter 44000, loss: 0.047678
 >> iter 45000, loss: 0.049348
 >> iter 46000, loss: 0.047677
 >> iter 47000, loss: 0.052791
 >> iter 48000, loss: 0.047791
 >> iter 49000, loss: 0.053515
 >> iter 50000, loss: 0.040937
   Number of active neurons: 3
 >> iter 51000, loss: 0.041748
 >> iter 52000, loss: 0.059262
 >> iter 53000, loss: 0.063968
 >> iter 54000, loss: 0.061423
 >> iter 55000, loss: 0.040489
 >> iter 56000, loss: 0.054557
 >> iter 57000, loss: 0.074973
 >> iter 58000, loss: 0.073967
 >> iter 59000, loss: 0.052956
 >> iter 60000, loss: 0.038490
   Number of active neurons: 3
 >> iter 61000, loss: 0.041907
 >> iter 62000, loss: 0.051181
 >> iter 63000, loss: 0.038123
 >> iter 64000, loss: 0.048936
 >> iter 65000, loss: 0.060101
 >> iter 66000, loss: 0.062620
 >> iter 67000, loss: 0.044535
 >> iter 68000, loss: 0.049412
 >> iter 69000, loss: 0.037108
 >> iter 70000, loss: 0.051726
   Number of active neurons: 3
 >> iter 71000, loss: 0.070166
 >> iter 72000, loss: 0.048319
 >> iter 73000, loss: 0.069473
 >> iter 74000, loss: 0.053946
 >> iter 75000, loss: 0.059056
 >> iter 76000, loss: 0.044118
 >> iter 77000, loss: 0.048751
 >> iter 78000, loss: 0.045911
 >> iter 79000, loss: 0.057384
 >> iter 80000, loss: 0.044906
   Number of active neurons: 3
 >> iter 81000, loss: 0.037658
 >> iter 82000, loss: 0.054628
 >> iter 83000, loss: 0.054815
 >> iter 84000, loss: 0.037719
 >> iter 85000, loss: 0.047403
 >> iter 86000, loss: 0.042759
 >> iter 87000, loss: 0.052277
 >> iter 88000, loss: 0.044937
 >> iter 89000, loss: 0.061477
 >> iter 90000, loss: 0.044489
   Number of active neurons: 3
 >> iter 91000, loss: 0.057464
 >> iter 92000, loss: 0.048021
 >> iter 93000, loss: 0.041751
 >> iter 94000, loss: 0.043019
 >> iter 95000, loss: 0.031757
 >> iter 96000, loss: 0.052807
 >> iter 97000, loss: 0.042393
 >> iter 98000, loss: 0.032355
 >> iter 99000, loss: 0.050798
 >> iter 100000, loss: 0.043628
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455163
   Number of active neurons: 0
 >> iter 1000, loss: 11.244960
 >> iter 2000, loss: 4.409379
 >> iter 3000, loss: 1.739099
 >> iter 4000, loss: 0.718011
 >> iter 5000, loss: 0.340972
 >> iter 6000, loss: 0.220062
 >> iter 7000, loss: 0.131892
 >> iter 8000, loss: 0.094735
 >> iter 9000, loss: 0.084077
 >> iter 10000, loss: 0.078544
   Number of active neurons: 8
 >> iter 11000, loss: 0.103087
 >> iter 12000, loss: 0.092192
 >> iter 13000, loss: 0.089198
 >> iter 14000, loss: 0.085144
 >> iter 15000, loss: 0.105389
 >> iter 16000, loss: 0.073542
 >> iter 17000, loss: 0.065110
 >> iter 18000, loss: 0.068277
 >> iter 19000, loss: 0.066548
 >> iter 20000, loss: 0.067047
   Number of active neurons: 7
 >> iter 21000, loss: 0.073507
 >> iter 22000, loss: 0.055019
 >> iter 23000, loss: 0.074327
 >> iter 24000, loss: 0.067904
 >> iter 25000, loss: 0.054950
 >> iter 26000, loss: 0.059815
 >> iter 27000, loss: 0.078323
 >> iter 28000, loss: 0.055837
 >> iter 29000, loss: 0.097607
 >> iter 30000, loss: 0.065835
   Number of active neurons: 5
 >> iter 31000, loss: 0.062155
 >> iter 32000, loss: 0.051838
 >> iter 33000, loss: 0.049552
 >> iter 34000, loss: 0.040912
 >> iter 35000, loss: 0.037791
 >> iter 36000, loss: 0.054179
 >> iter 37000, loss: 0.048208
 >> iter 38000, loss: 0.054977
 >> iter 39000, loss: 0.065435
 >> iter 40000, loss: 0.047904
   Number of active neurons: 5
 >> iter 41000, loss: 0.051273
 >> iter 42000, loss: 0.052591
 >> iter 43000, loss: 0.053394
 >> iter 44000, loss: 0.047541
 >> iter 45000, loss: 0.045266
 >> iter 46000, loss: 0.037520
 >> iter 47000, loss: 0.045179
 >> iter 48000, loss: 0.047177
 >> iter 49000, loss: 0.063098
 >> iter 50000, loss: 0.055815
   Number of active neurons: 3
 >> iter 51000, loss: 0.043537
 >> iter 52000, loss: 0.053312
 >> iter 53000, loss: 0.047919
 >> iter 54000, loss: 0.037572
 >> iter 55000, loss: 0.039640
 >> iter 56000, loss: 0.041716
 >> iter 57000, loss: 0.041297
 >> iter 58000, loss: 0.046286
 >> iter 59000, loss: 0.049190
 >> iter 60000, loss: 0.042832
   Number of active neurons: 3
 >> iter 61000, loss: 0.043304
 >> iter 62000, loss: 0.060556
 >> iter 63000, loss: 0.053104
 >> iter 64000, loss: 0.050352
 >> iter 65000, loss: 0.057346
 >> iter 66000, loss: 0.055833
 >> iter 67000, loss: 0.057793
 >> iter 68000, loss: 0.057996
 >> iter 69000, loss: 0.044625
 >> iter 70000, loss: 0.037725
   Number of active neurons: 3
 >> iter 71000, loss: 0.041641
 >> iter 72000, loss: 0.037414
 >> iter 73000, loss: 0.069477
 >> iter 74000, loss: 0.049397
 >> iter 75000, loss: 0.050183
 >> iter 76000, loss: 0.044398
 >> iter 77000, loss: 0.057676
 >> iter 78000, loss: 0.075073
 >> iter 79000, loss: 0.057114
 >> iter 80000, loss: 0.051964
   Number of active neurons: 2
 >> iter 81000, loss: 0.080211
 >> iter 82000, loss: 0.050304
 >> iter 83000, loss: 0.048602
 >> iter 84000, loss: 0.043633
 >> iter 85000, loss: 0.049878
 >> iter 86000, loss: 0.042134
 >> iter 87000, loss: 0.037665
 >> iter 88000, loss: 0.030130
 >> iter 89000, loss: 0.043501
 >> iter 90000, loss: 0.060400
   Number of active neurons: 2
 >> iter 91000, loss: 0.054458
 >> iter 92000, loss: 0.043232
 >> iter 93000, loss: 0.043829
 >> iter 94000, loss: 0.047096
 >> iter 95000, loss: 0.041811
 >> iter 96000, loss: 0.041256
 >> iter 97000, loss: 0.031507
 >> iter 98000, loss: 0.042893
 >> iter 99000, loss: 0.028467
 >> iter 100000, loss: 0.047063
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 11.324280
 >> iter 2000, loss: 4.451595
 >> iter 3000, loss: 1.781966
 >> iter 4000, loss: 0.738174
 >> iter 5000, loss: 0.361045
 >> iter 6000, loss: 0.199068
 >> iter 7000, loss: 0.123632
 >> iter 8000, loss: 0.102648
 >> iter 9000, loss: 0.105099
 >> iter 10000, loss: 0.105500
   Number of active neurons: 7
 >> iter 11000, loss: 0.066197
 >> iter 12000, loss: 0.062303
 >> iter 13000, loss: 0.066604
 >> iter 14000, loss: 0.056782
 >> iter 15000, loss: 0.068862
 >> iter 16000, loss: 0.059343
 >> iter 17000, loss: 0.075563
 >> iter 18000, loss: 0.059725
 >> iter 19000, loss: 0.052027
 >> iter 20000, loss: 0.055967
   Number of active neurons: 7
 >> iter 21000, loss: 0.058944
 >> iter 22000, loss: 0.069949
 >> iter 23000, loss: 0.066729
 >> iter 24000, loss: 0.053348
 >> iter 25000, loss: 0.046163
 >> iter 26000, loss: 0.044300
 >> iter 27000, loss: 0.055295
 >> iter 28000, loss: 0.037964
 >> iter 29000, loss: 0.044376
 >> iter 30000, loss: 0.037582
   Number of active neurons: 4
 >> iter 31000, loss: 0.031741
 >> iter 32000, loss: 0.042744
 >> iter 33000, loss: 0.043397
 >> iter 34000, loss: 0.060549
 >> iter 35000, loss: 0.050039
 >> iter 36000, loss: 0.045115
 >> iter 37000, loss: 0.037606
 >> iter 38000, loss: 0.038056
 >> iter 39000, loss: 0.046056
 >> iter 40000, loss: 0.048290
   Number of active neurons: 4
 >> iter 41000, loss: 0.050703
 >> iter 42000, loss: 0.052867
 >> iter 43000, loss: 0.061034
 >> iter 44000, loss: 0.056136
 >> iter 45000, loss: 0.055833
 >> iter 46000, loss: 0.065245
 >> iter 47000, loss: 0.064197
 >> iter 48000, loss: 0.055216
 >> iter 49000, loss: 0.059720
 >> iter 50000, loss: 0.043013
   Number of active neurons: 4
 >> iter 51000, loss: 0.052118
 >> iter 52000, loss: 0.061468
 >> iter 53000, loss: 0.053958
 >> iter 54000, loss: 0.052142
 >> iter 55000, loss: 0.064823
 >> iter 56000, loss: 0.056518
 >> iter 57000, loss: 0.051562
 >> iter 58000, loss: 0.048342
 >> iter 59000, loss: 0.056083
 >> iter 60000, loss: 0.053896
   Number of active neurons: 4
 >> iter 61000, loss: 0.041038
 >> iter 62000, loss: 0.041692
 >> iter 63000, loss: 0.050423
 >> iter 64000, loss: 0.075653
 >> iter 65000, loss: 0.056061
 >> iter 66000, loss: 0.050212
 >> iter 67000, loss: 0.086851
 >> iter 68000, loss: 0.065147
 >> iter 69000, loss: 0.053318
 >> iter 70000, loss: 0.054925
   Number of active neurons: 3
 >> iter 71000, loss: 0.042234
 >> iter 72000, loss: 0.049593
 >> iter 73000, loss: 0.056081
 >> iter 74000, loss: 0.036918
 >> iter 75000, loss: 0.048035
 >> iter 76000, loss: 0.045292
 >> iter 77000, loss: 0.055063
 >> iter 78000, loss: 0.049687
 >> iter 79000, loss: 0.037787
 >> iter 80000, loss: 0.036192
   Number of active neurons: 3
 >> iter 81000, loss: 0.029017
 >> iter 82000, loss: 0.037342
 >> iter 83000, loss: 0.055661
 >> iter 84000, loss: 0.045158
 >> iter 85000, loss: 0.034292
 >> iter 86000, loss: 0.041190
 >> iter 87000, loss: 0.036945
 >> iter 88000, loss: 0.051572
 >> iter 89000, loss: 0.050936
 >> iter 90000, loss: 0.071555
   Number of active neurons: 3
 >> iter 91000, loss: 0.053072
 >> iter 92000, loss: 0.049664
 >> iter 93000, loss: 0.049977
 >> iter 94000, loss: 0.040444
 >> iter 95000, loss: 0.043774
 >> iter 96000, loss: 0.050540
 >> iter 97000, loss: 0.057999
 >> iter 98000, loss: 0.056440
 >> iter 99000, loss: 0.041082
 >> iter 100000, loss: 0.041769
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 11.313055
 >> iter 2000, loss: 4.411707
 >> iter 3000, loss: 1.734340
 >> iter 4000, loss: 0.701348
 >> iter 5000, loss: 0.335367
 >> iter 6000, loss: 0.181562
 >> iter 7000, loss: 0.143269
 >> iter 8000, loss: 0.097466
 >> iter 9000, loss: 0.085361
 >> iter 10000, loss: 0.077391
   Number of active neurons: 8
 >> iter 11000, loss: 0.090280
 >> iter 12000, loss: 0.077295
 >> iter 13000, loss: 0.059819
 >> iter 14000, loss: 0.067886
 >> iter 15000, loss: 0.048632
 >> iter 16000, loss: 0.045823
 >> iter 17000, loss: 0.055304
 >> iter 18000, loss: 0.063056
 >> iter 19000, loss: 0.062765
 >> iter 20000, loss: 0.055092
   Number of active neurons: 7
 >> iter 21000, loss: 0.062155
 >> iter 22000, loss: 0.062531
 >> iter 23000, loss: 0.076945
 >> iter 24000, loss: 0.070683
 >> iter 25000, loss: 0.055545
 >> iter 26000, loss: 0.066467
 >> iter 27000, loss: 0.058095
 >> iter 28000, loss: 0.049377
 >> iter 29000, loss: 0.058000
 >> iter 30000, loss: 0.059343
   Number of active neurons: 5
 >> iter 31000, loss: 0.056711
 >> iter 32000, loss: 0.045581
 >> iter 33000, loss: 0.046640
 >> iter 34000, loss: 0.035530
 >> iter 35000, loss: 0.054116
 >> iter 36000, loss: 0.047776
 >> iter 37000, loss: 0.053211
 >> iter 38000, loss: 0.041635
 >> iter 39000, loss: 0.043463
 >> iter 40000, loss: 0.041875
   Number of active neurons: 4
 >> iter 41000, loss: 0.056878
 >> iter 42000, loss: 0.051670
 >> iter 43000, loss: 0.046402
 >> iter 44000, loss: 0.053032
 >> iter 45000, loss: 0.063488
 >> iter 46000, loss: 0.054925
 >> iter 47000, loss: 0.055939
 >> iter 48000, loss: 0.047745
 >> iter 49000, loss: 0.039015
 >> iter 50000, loss: 0.032667
   Number of active neurons: 3
 >> iter 51000, loss: 0.044449
 >> iter 52000, loss: 0.058318
 >> iter 53000, loss: 0.054336
 >> iter 54000, loss: 0.049289
 >> iter 55000, loss: 0.052688
 >> iter 56000, loss: 0.037752
 >> iter 57000, loss: 0.049744
 >> iter 58000, loss: 0.057432
 >> iter 59000, loss: 0.053102
 >> iter 60000, loss: 0.038707
   Number of active neurons: 3
 >> iter 61000, loss: 0.051110
 >> iter 62000, loss: 0.057970
 >> iter 63000, loss: 0.058349
 >> iter 64000, loss: 0.044394
 >> iter 65000, loss: 0.042153
 >> iter 66000, loss: 0.055045
 >> iter 67000, loss: 0.064201
 >> iter 68000, loss: 0.039663
 >> iter 69000, loss: 0.046776
 >> iter 70000, loss: 0.081416
   Number of active neurons: 3
 >> iter 71000, loss: 0.045814
 >> iter 72000, loss: 0.058317
 >> iter 73000, loss: 0.047082
 >> iter 74000, loss: 0.047835
 >> iter 75000, loss: 0.044207
 >> iter 76000, loss: 0.040122
 >> iter 77000, loss: 0.037538
 >> iter 78000, loss: 0.045710
 >> iter 79000, loss: 0.047885
 >> iter 80000, loss: 0.047762
   Number of active neurons: 3
 >> iter 81000, loss: 0.056852
 >> iter 82000, loss: 0.053166
 >> iter 83000, loss: 0.057275
 >> iter 84000, loss: 0.060871
 >> iter 85000, loss: 0.043158
 >> iter 86000, loss: 0.048607
 >> iter 87000, loss: 0.050905
 >> iter 88000, loss: 0.038724
 >> iter 89000, loss: 0.050265
 >> iter 90000, loss: 0.053251
   Number of active neurons: 3
 >> iter 91000, loss: 0.046566
 >> iter 92000, loss: 0.039886
 >> iter 93000, loss: 0.042310
 >> iter 94000, loss: 0.042367
 >> iter 95000, loss: 0.042559
 >> iter 96000, loss: 0.050573
 >> iter 97000, loss: 0.039836
 >> iter 98000, loss: 0.034847
 >> iter 99000, loss: 0.064348
 >> iter 100000, loss: 0.039761
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.359564
 >> iter 2000, loss: 4.451329
 >> iter 3000, loss: 1.785754
 >> iter 4000, loss: 0.771446
 >> iter 5000, loss: 0.352806
 >> iter 6000, loss: 0.185087
 >> iter 7000, loss: 0.139650
 >> iter 8000, loss: 0.108012
 >> iter 9000, loss: 0.090437
 >> iter 10000, loss: 0.072707
   Number of active neurons: 8
 >> iter 11000, loss: 0.062716
 >> iter 12000, loss: 0.062768
 >> iter 13000, loss: 0.061566
 >> iter 14000, loss: 0.077238
 >> iter 15000, loss: 0.059158
 >> iter 16000, loss: 0.076596
 >> iter 17000, loss: 0.080402
 >> iter 18000, loss: 0.072631
 >> iter 19000, loss: 0.075766
 >> iter 20000, loss: 0.055813
   Number of active neurons: 6
 >> iter 21000, loss: 0.052884
 >> iter 22000, loss: 0.054691
 >> iter 23000, loss: 0.051530
 >> iter 24000, loss: 0.069491
 >> iter 25000, loss: 0.061707
 >> iter 26000, loss: 0.067263
 >> iter 27000, loss: 0.062311
 >> iter 28000, loss: 0.061017
 >> iter 29000, loss: 0.041294
 >> iter 30000, loss: 0.037841
   Number of active neurons: 5
 >> iter 31000, loss: 0.048286
 >> iter 32000, loss: 0.056450
 >> iter 33000, loss: 0.041264
 >> iter 34000, loss: 0.037147
 >> iter 35000, loss: 0.039932
 >> iter 36000, loss: 0.045807
 >> iter 37000, loss: 0.049222
 >> iter 38000, loss: 0.049664
 >> iter 39000, loss: 0.051664
 >> iter 40000, loss: 0.055389
   Number of active neurons: 5
 >> iter 41000, loss: 0.044884
 >> iter 42000, loss: 0.034829
 >> iter 43000, loss: 0.039882
 >> iter 44000, loss: 0.039106
 >> iter 45000, loss: 0.038793
 >> iter 46000, loss: 0.031528
 >> iter 47000, loss: 0.037604
 >> iter 48000, loss: 0.042042
 >> iter 49000, loss: 0.039504
 >> iter 50000, loss: 0.057116
   Number of active neurons: 3
 >> iter 51000, loss: 0.043975
 >> iter 52000, loss: 0.046576
 >> iter 53000, loss: 0.048178
 >> iter 54000, loss: 0.062353
 >> iter 55000, loss: 0.055281
 >> iter 56000, loss: 0.047494
 >> iter 57000, loss: 0.042501
 >> iter 58000, loss: 0.043566
 >> iter 59000, loss: 0.032008
 >> iter 60000, loss: 0.042556
   Number of active neurons: 3
 >> iter 61000, loss: 0.036613
 >> iter 62000, loss: 0.033096
 >> iter 63000, loss: 0.064200
 >> iter 64000, loss: 0.069299
 >> iter 65000, loss: 0.056903
 >> iter 66000, loss: 0.044832
 >> iter 67000, loss: 0.048758
 >> iter 68000, loss: 0.052898
 >> iter 69000, loss: 0.045461
 >> iter 70000, loss: 0.033854
   Number of active neurons: 3
 >> iter 71000, loss: 0.038756
 >> iter 72000, loss: 0.048638
 >> iter 73000, loss: 0.042182
 >> iter 74000, loss: 0.046767
 >> iter 75000, loss: 0.051163
 >> iter 76000, loss: 0.047909
 >> iter 77000, loss: 0.043224
 >> iter 78000, loss: 0.040927
 >> iter 79000, loss: 0.036868
 >> iter 80000, loss: 0.049005
   Number of active neurons: 3
 >> iter 81000, loss: 0.034820
 >> iter 82000, loss: 0.065187
 >> iter 83000, loss: 0.059717
 >> iter 84000, loss: 0.071470
 >> iter 85000, loss: 0.054406
 >> iter 86000, loss: 0.049702
 >> iter 87000, loss: 0.036849
 >> iter 88000, loss: 0.033871
 >> iter 89000, loss: 0.033243
 >> iter 90000, loss: 0.055209
   Number of active neurons: 3
 >> iter 91000, loss: 0.070438
 >> iter 92000, loss: 0.059704
 >> iter 93000, loss: 0.042177
 >> iter 94000, loss: 0.031833
 >> iter 95000, loss: 0.057700
 >> iter 96000, loss: 0.034231
 >> iter 97000, loss: 0.046669
 >> iter 98000, loss: 0.038288
 >> iter 99000, loss: 0.054991
 >> iter 100000, loss: 0.042393
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.363336
 >> iter 2000, loss: 4.470553
 >> iter 3000, loss: 1.780458
 >> iter 4000, loss: 0.735407
 >> iter 5000, loss: 0.353492
 >> iter 6000, loss: 0.168617
 >> iter 7000, loss: 0.124752
 >> iter 8000, loss: 0.085868
 >> iter 9000, loss: 0.099655
 >> iter 10000, loss: 0.072579
   Number of active neurons: 7
 >> iter 11000, loss: 0.066493
 >> iter 12000, loss: 0.070262
 >> iter 13000, loss: 0.068240
 >> iter 14000, loss: 0.072661
 >> iter 15000, loss: 0.060359
 >> iter 16000, loss: 0.052414
 >> iter 17000, loss: 0.069267
 >> iter 18000, loss: 0.055201
 >> iter 19000, loss: 0.049441
 >> iter 20000, loss: 0.041735
   Number of active neurons: 7
 >> iter 21000, loss: 0.050228
 >> iter 22000, loss: 0.060469
 >> iter 23000, loss: 0.057664
 >> iter 24000, loss: 0.052388
 >> iter 25000, loss: 0.063477
 >> iter 26000, loss: 0.047676
 >> iter 27000, loss: 0.048481
 >> iter 28000, loss: 0.045536
 >> iter 29000, loss: 0.048571
 >> iter 30000, loss: 0.063530
   Number of active neurons: 5
 >> iter 31000, loss: 0.059977
 >> iter 32000, loss: 0.065325
 >> iter 33000, loss: 0.058340
 >> iter 34000, loss: 0.043281
 >> iter 35000, loss: 0.049697
 >> iter 36000, loss: 0.050624
 >> iter 37000, loss: 0.044187
 >> iter 38000, loss: 0.043823
 >> iter 39000, loss: 0.033000
 >> iter 40000, loss: 0.070647
   Number of active neurons: 5
 >> iter 41000, loss: 0.055694
 >> iter 42000, loss: 0.072657
 >> iter 43000, loss: 0.045886
 >> iter 44000, loss: 0.041724
 >> iter 45000, loss: 0.042045
 >> iter 46000, loss: 0.037342
 >> iter 47000, loss: 0.041362
 >> iter 48000, loss: 0.046434
 >> iter 49000, loss: 0.041698
 >> iter 50000, loss: 0.037015
   Number of active neurons: 4
 >> iter 51000, loss: 0.056309
 >> iter 52000, loss: 0.044370
 >> iter 53000, loss: 0.043046
 >> iter 54000, loss: 0.040452
 >> iter 55000, loss: 0.045587
 >> iter 56000, loss: 0.049084
 >> iter 57000, loss: 0.046158
 >> iter 58000, loss: 0.042585
 >> iter 59000, loss: 0.045510
 >> iter 60000, loss: 0.035032
   Number of active neurons: 4
 >> iter 61000, loss: 0.062425
 >> iter 62000, loss: 0.055145
 >> iter 63000, loss: 0.070969
 >> iter 64000, loss: 0.053858
 >> iter 65000, loss: 0.055104
 >> iter 66000, loss: 0.071530
 >> iter 67000, loss: 0.065350
 >> iter 68000, loss: 0.044800
 >> iter 69000, loss: 0.042614
 >> iter 70000, loss: 0.058709
   Number of active neurons: 3
 >> iter 71000, loss: 0.057129
 >> iter 72000, loss: 0.048233
 >> iter 73000, loss: 0.041456
 >> iter 74000, loss: 0.042672
 >> iter 75000, loss: 0.035683
 >> iter 76000, loss: 0.040703
 >> iter 77000, loss: 0.034833
 >> iter 78000, loss: 0.029520
 >> iter 79000, loss: 0.040501
 >> iter 80000, loss: 0.042549
   Number of active neurons: 3
 >> iter 81000, loss: 0.056867
 >> iter 82000, loss: 0.041562
 >> iter 83000, loss: 0.054643
 >> iter 84000, loss: 0.054431
 >> iter 85000, loss: 0.046269
 >> iter 86000, loss: 0.071383
 >> iter 87000, loss: 0.063561
 >> iter 88000, loss: 0.047425
 >> iter 89000, loss: 0.044738
 >> iter 90000, loss: 0.044731
   Number of active neurons: 2
 >> iter 91000, loss: 0.035561
 >> iter 92000, loss: 0.027634
 >> iter 93000, loss: 0.043035
 >> iter 94000, loss: 0.060641
 >> iter 95000, loss: 0.053339
 >> iter 96000, loss: 0.049474
 >> iter 97000, loss: 0.034387
 >> iter 98000, loss: 0.028200
 >> iter 99000, loss: 0.046503
 >> iter 100000, loss: 0.038577
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455158
   Number of active neurons: 0
 >> iter 1000, loss: 11.323544
 >> iter 2000, loss: 4.443007
 >> iter 3000, loss: 1.766301
 >> iter 4000, loss: 0.714713
 >> iter 5000, loss: 0.343165
 >> iter 6000, loss: 0.187891
 >> iter 7000, loss: 0.141909
 >> iter 8000, loss: 0.094582
 >> iter 9000, loss: 0.111599
 >> iter 10000, loss: 0.108312
   Number of active neurons: 8
 >> iter 11000, loss: 0.079704
 >> iter 12000, loss: 0.074215
 >> iter 13000, loss: 0.075375
 >> iter 14000, loss: 0.078294
 >> iter 15000, loss: 0.071699
 >> iter 16000, loss: 0.056310
 >> iter 17000, loss: 0.069056
 >> iter 18000, loss: 0.054622
 >> iter 19000, loss: 0.089977
 >> iter 20000, loss: 0.073692
   Number of active neurons: 7
 >> iter 21000, loss: 0.072825
 >> iter 22000, loss: 0.064826
 >> iter 23000, loss: 0.081496
 >> iter 24000, loss: 0.062195
 >> iter 25000, loss: 0.069599
 >> iter 26000, loss: 0.059371
 >> iter 27000, loss: 0.066724
 >> iter 28000, loss: 0.054593
 >> iter 29000, loss: 0.058236
 >> iter 30000, loss: 0.044546
   Number of active neurons: 6
 >> iter 31000, loss: 0.055843
 >> iter 32000, loss: 0.053994
 >> iter 33000, loss: 0.047775
 >> iter 34000, loss: 0.064566
 >> iter 35000, loss: 0.062747
 >> iter 36000, loss: 0.069212
 >> iter 37000, loss: 0.060549
 >> iter 38000, loss: 0.065427
 >> iter 39000, loss: 0.058685
 >> iter 40000, loss: 0.066284
   Number of active neurons: 4
 >> iter 41000, loss: 0.069646
 >> iter 42000, loss: 0.068111
 >> iter 43000, loss: 0.056247
 >> iter 44000, loss: 0.054209
 >> iter 45000, loss: 0.051477
 >> iter 46000, loss: 0.070474
 >> iter 47000, loss: 0.061243
 >> iter 48000, loss: 0.060703
 >> iter 49000, loss: 0.080264
 >> iter 50000, loss: 0.053022
   Number of active neurons: 3
 >> iter 51000, loss: 0.066180
 >> iter 52000, loss: 0.051777
 >> iter 53000, loss: 0.060608
 >> iter 54000, loss: 0.055182
 >> iter 55000, loss: 0.050850
 >> iter 56000, loss: 0.062241
 >> iter 57000, loss: 0.055386
 >> iter 58000, loss: 0.047206
 >> iter 59000, loss: 0.041740
 >> iter 60000, loss: 0.055076
   Number of active neurons: 3
 >> iter 61000, loss: 0.052947
 >> iter 62000, loss: 0.055305
 >> iter 63000, loss: 0.058827
 >> iter 64000, loss: 0.047339
 >> iter 65000, loss: 0.067802
 >> iter 66000, loss: 0.058496
 >> iter 67000, loss: 0.043464
 >> iter 68000, loss: 0.047048
 >> iter 69000, loss: 0.054200
 >> iter 70000, loss: 0.043490
   Number of active neurons: 3
 >> iter 71000, loss: 0.038358
 >> iter 72000, loss: 0.030419
 >> iter 73000, loss: 0.046380
 >> iter 74000, loss: 0.043178
 >> iter 75000, loss: 0.033844
 >> iter 76000, loss: 0.055934
 >> iter 77000, loss: 0.043298
 >> iter 78000, loss: 0.033035
 >> iter 79000, loss: 0.041607
 >> iter 80000, loss: 0.041366
   Number of active neurons: 3
 >> iter 81000, loss: 0.028491
 >> iter 82000, loss: 0.049053
 >> iter 83000, loss: 0.051371
 >> iter 84000, loss: 0.045520
 >> iter 85000, loss: 0.043430
 >> iter 86000, loss: 0.036698
 >> iter 87000, loss: 0.056069
 >> iter 88000, loss: 0.046839
 >> iter 89000, loss: 0.034287
 >> iter 90000, loss: 0.036047
   Number of active neurons: 3
 >> iter 91000, loss: 0.038192
 >> iter 92000, loss: 0.044530
 >> iter 93000, loss: 0.050728
 >> iter 94000, loss: 0.048714
 >> iter 95000, loss: 0.043410
 >> iter 96000, loss: 0.062313
 >> iter 97000, loss: 0.055646
 >> iter 98000, loss: 0.041452
 >> iter 99000, loss: 0.034557
 >> iter 100000, loss: 0.049110
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.393190
 >> iter 2000, loss: 4.465635
 >> iter 3000, loss: 1.761543
 >> iter 4000, loss: 0.764150
 >> iter 5000, loss: 0.359768
 >> iter 6000, loss: 0.199511
 >> iter 7000, loss: 0.125623
 >> iter 8000, loss: 0.094576
 >> iter 9000, loss: 0.068526
 >> iter 10000, loss: 0.081540
   Number of active neurons: 8
 >> iter 11000, loss: 0.091759
 >> iter 12000, loss: 0.064623
 >> iter 13000, loss: 0.052999
 >> iter 14000, loss: 0.060840
 >> iter 15000, loss: 0.065542
 >> iter 16000, loss: 0.072500
 >> iter 17000, loss: 0.066396
 >> iter 18000, loss: 0.063267
 >> iter 19000, loss: 0.052207
 >> iter 20000, loss: 0.050571
   Number of active neurons: 5
 >> iter 21000, loss: 0.058369
 >> iter 22000, loss: 0.068304
 >> iter 23000, loss: 0.056289
 >> iter 24000, loss: 0.051405
 >> iter 25000, loss: 0.062206
 >> iter 26000, loss: 0.059834
 >> iter 27000, loss: 0.040186
 >> iter 28000, loss: 0.038071
 >> iter 29000, loss: 0.039559
 >> iter 30000, loss: 0.036198
   Number of active neurons: 5
 >> iter 31000, loss: 0.079609
 >> iter 32000, loss: 0.059885
 >> iter 33000, loss: 0.061341
 >> iter 34000, loss: 0.054448
 >> iter 35000, loss: 0.051701
 >> iter 36000, loss: 0.056385
 >> iter 37000, loss: 0.058106
 >> iter 38000, loss: 0.046377
 >> iter 39000, loss: 0.047975
 >> iter 40000, loss: 0.051073
   Number of active neurons: 4
 >> iter 41000, loss: 0.050364
 >> iter 42000, loss: 0.066526
 >> iter 43000, loss: 0.053779
 >> iter 44000, loss: 0.056972
 >> iter 45000, loss: 0.049514
 >> iter 46000, loss: 0.036032
 >> iter 47000, loss: 0.047493
 >> iter 48000, loss: 0.055397
 >> iter 49000, loss: 0.057260
 >> iter 50000, loss: 0.043345
   Number of active neurons: 4
 >> iter 51000, loss: 0.052201
 >> iter 52000, loss: 0.049744
 >> iter 53000, loss: 0.052121
 >> iter 54000, loss: 0.047485
 >> iter 55000, loss: 0.045072
 >> iter 56000, loss: 0.049602
 >> iter 57000, loss: 0.048159
 >> iter 58000, loss: 0.038773
 >> iter 59000, loss: 0.050872
 >> iter 60000, loss: 0.049999
   Number of active neurons: 3
 >> iter 61000, loss: 0.043746
 >> iter 62000, loss: 0.041935
 >> iter 63000, loss: 0.040885
 >> iter 64000, loss: 0.042360
 >> iter 65000, loss: 0.045372
 >> iter 66000, loss: 0.046517
 >> iter 67000, loss: 0.043794
 >> iter 68000, loss: 0.036651
 >> iter 69000, loss: 0.043762
 >> iter 70000, loss: 0.043600
   Number of active neurons: 3
 >> iter 71000, loss: 0.054610
 >> iter 72000, loss: 0.041419
 >> iter 73000, loss: 0.039950
 >> iter 74000, loss: 0.047812
 >> iter 75000, loss: 0.086031
 >> iter 76000, loss: 0.071829
 >> iter 77000, loss: 0.045265
 >> iter 78000, loss: 0.040140
 >> iter 79000, loss: 0.035850
 >> iter 80000, loss: 0.034732
   Number of active neurons: 3
 >> iter 81000, loss: 0.041976
 >> iter 82000, loss: 0.053339
 >> iter 83000, loss: 0.044622
 >> iter 84000, loss: 0.051044
 >> iter 85000, loss: 0.047064
 >> iter 86000, loss: 0.047814
 >> iter 87000, loss: 0.082022
 >> iter 88000, loss: 0.052219
 >> iter 89000, loss: 0.044467
 >> iter 90000, loss: 0.062691
   Number of active neurons: 3
 >> iter 91000, loss: 0.055733
 >> iter 92000, loss: 0.058798
 >> iter 93000, loss: 0.045775
 >> iter 94000, loss: 0.041582
 >> iter 95000, loss: 0.052153
 >> iter 96000, loss: 0.051473
 >> iter 97000, loss: 0.052139
 >> iter 98000, loss: 0.075414
 >> iter 99000, loss: 0.055653
 >> iter 100000, loss: 0.051451
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.356167
 >> iter 2000, loss: 4.411755
 >> iter 3000, loss: 1.775141
 >> iter 4000, loss: 0.720766
 >> iter 5000, loss: 0.340710
 >> iter 6000, loss: 0.174555
 >> iter 7000, loss: 0.108221
 >> iter 8000, loss: 0.083208
 >> iter 9000, loss: 0.076956
 >> iter 10000, loss: 0.095002
   Number of active neurons: 8
 >> iter 11000, loss: 0.068307
 >> iter 12000, loss: 0.066362
 >> iter 13000, loss: 0.084220
 >> iter 14000, loss: 0.061635
 >> iter 15000, loss: 0.072803
 >> iter 16000, loss: 0.059011
 >> iter 17000, loss: 0.074251
 >> iter 18000, loss: 0.056194
 >> iter 19000, loss: 0.059934
 >> iter 20000, loss: 0.048095
   Number of active neurons: 5
 >> iter 21000, loss: 0.059685
 >> iter 22000, loss: 0.048885
 >> iter 23000, loss: 0.047666
 >> iter 24000, loss: 0.042340
 >> iter 25000, loss: 0.044396
 >> iter 26000, loss: 0.061149
 >> iter 27000, loss: 0.067831
 >> iter 28000, loss: 0.057941
 >> iter 29000, loss: 0.062826
 >> iter 30000, loss: 0.050824
   Number of active neurons: 5
 >> iter 31000, loss: 0.046563
 >> iter 32000, loss: 0.047300
 >> iter 33000, loss: 0.047498
 >> iter 34000, loss: 0.074067
 >> iter 35000, loss: 0.059783
 >> iter 36000, loss: 0.049136
 >> iter 37000, loss: 0.039126
 >> iter 38000, loss: 0.047543
 >> iter 39000, loss: 0.063547
 >> iter 40000, loss: 0.074182
   Number of active neurons: 5
 >> iter 41000, loss: 0.060764
 >> iter 42000, loss: 0.050067
 >> iter 43000, loss: 0.063000
 >> iter 44000, loss: 0.063627
 >> iter 45000, loss: 0.051359
 >> iter 46000, loss: 0.049485
 >> iter 47000, loss: 0.070724
 >> iter 48000, loss: 0.058174
 >> iter 49000, loss: 0.059645
 >> iter 50000, loss: 0.052208
   Number of active neurons: 4
 >> iter 51000, loss: 0.045145
 >> iter 52000, loss: 0.054539
 >> iter 53000, loss: 0.048591
 >> iter 54000, loss: 0.049397
 >> iter 55000, loss: 0.054837
 >> iter 56000, loss: 0.045775
 >> iter 57000, loss: 0.045996
 >> iter 58000, loss: 0.060797
 >> iter 59000, loss: 0.083957
 >> iter 60000, loss: 0.059814
   Number of active neurons: 4
 >> iter 61000, loss: 0.052856
 >> iter 62000, loss: 0.043559
 >> iter 63000, loss: 0.048745
 >> iter 64000, loss: 0.072400
 >> iter 65000, loss: 0.048132
 >> iter 66000, loss: 0.047212
 >> iter 67000, loss: 0.040805
 >> iter 68000, loss: 0.047580
 >> iter 69000, loss: 0.046152
 >> iter 70000, loss: 0.048363
   Number of active neurons: 3
 >> iter 71000, loss: 0.050992
 >> iter 72000, loss: 0.046699
 >> iter 73000, loss: 0.045125
 >> iter 74000, loss: 0.051800
 >> iter 75000, loss: 0.052597
 >> iter 76000, loss: 0.041633
 >> iter 77000, loss: 0.036938
 >> iter 78000, loss: 0.046868
 >> iter 79000, loss: 0.041588
 >> iter 80000, loss: 0.065604
   Number of active neurons: 3
 >> iter 81000, loss: 0.075382
 >> iter 82000, loss: 0.044167
 >> iter 83000, loss: 0.039767
 >> iter 84000, loss: 0.037073
 >> iter 85000, loss: 0.070767
 >> iter 86000, loss: 0.064325
 >> iter 87000, loss: 0.043752
 >> iter 88000, loss: 0.051249
 >> iter 89000, loss: 0.060700
 >> iter 90000, loss: 0.059053
   Number of active neurons: 2
 >> iter 91000, loss: 0.061068
 >> iter 92000, loss: 0.040834
 >> iter 93000, loss: 0.047111
 >> iter 94000, loss: 0.041844
 >> iter 95000, loss: 0.052045
 >> iter 96000, loss: 0.056323
 >> iter 97000, loss: 0.045591
 >> iter 98000, loss: 0.049333
 >> iter 99000, loss: 0.047807
 >> iter 100000, loss: 0.056937
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.322476
 >> iter 2000, loss: 4.427827
 >> iter 3000, loss: 1.768030
 >> iter 4000, loss: 0.745408
 >> iter 5000, loss: 0.357669
 >> iter 6000, loss: 0.176748
 >> iter 7000, loss: 0.147172
 >> iter 8000, loss: 0.098751
 >> iter 9000, loss: 0.082274
 >> iter 10000, loss: 0.072783
   Number of active neurons: 9
 >> iter 11000, loss: 0.072774
 >> iter 12000, loss: 0.070547
 >> iter 13000, loss: 0.083507
 >> iter 14000, loss: 0.087925
 >> iter 15000, loss: 0.078039
 >> iter 16000, loss: 0.086633
 >> iter 17000, loss: 0.072658
 >> iter 18000, loss: 0.079705
 >> iter 19000, loss: 0.086006
 >> iter 20000, loss: 0.061732
   Number of active neurons: 8
 >> iter 21000, loss: 0.084142
 >> iter 22000, loss: 0.063785
 >> iter 23000, loss: 0.056523
 >> iter 24000, loss: 0.059764
 >> iter 25000, loss: 0.054217
 >> iter 26000, loss: 0.057778
 >> iter 27000, loss: 0.062978
 >> iter 28000, loss: 0.061069
 >> iter 29000, loss: 0.058646
 >> iter 30000, loss: 0.054435
   Number of active neurons: 4
 >> iter 31000, loss: 0.044162
 >> iter 32000, loss: 0.052338
 >> iter 33000, loss: 0.067630
 >> iter 34000, loss: 0.046150
 >> iter 35000, loss: 0.044654
 >> iter 36000, loss: 0.051393
 >> iter 37000, loss: 0.066741
 >> iter 38000, loss: 0.046978
 >> iter 39000, loss: 0.044716
 >> iter 40000, loss: 0.048072
   Number of active neurons: 4
 >> iter 41000, loss: 0.072836
 >> iter 42000, loss: 0.063060
 >> iter 43000, loss: 0.057713
 >> iter 44000, loss: 0.043458
 >> iter 45000, loss: 0.042438
 >> iter 46000, loss: 0.046333
 >> iter 47000, loss: 0.049398
 >> iter 48000, loss: 0.047018
 >> iter 49000, loss: 0.041408
 >> iter 50000, loss: 0.042710
   Number of active neurons: 4
 >> iter 51000, loss: 0.059588
 >> iter 52000, loss: 0.070537
 >> iter 53000, loss: 0.056690
 >> iter 54000, loss: 0.044098
 >> iter 55000, loss: 0.054793
 >> iter 56000, loss: 0.053905
 >> iter 57000, loss: 0.050512
 >> iter 58000, loss: 0.042490
 >> iter 59000, loss: 0.063295
 >> iter 60000, loss: 0.071892
   Number of active neurons: 4
 >> iter 61000, loss: 0.066812
 >> iter 62000, loss: 0.048418
 >> iter 63000, loss: 0.051475
 >> iter 64000, loss: 0.050849
 >> iter 65000, loss: 0.037835
 >> iter 66000, loss: 0.052856
 >> iter 67000, loss: 0.037041
 >> iter 68000, loss: 0.060195
 >> iter 69000, loss: 0.052576
 >> iter 70000, loss: 0.046980
   Number of active neurons: 4
 >> iter 71000, loss: 0.041409
 >> iter 72000, loss: 0.040334
 >> iter 73000, loss: 0.040077
 >> iter 74000, loss: 0.051059
 >> iter 75000, loss: 0.047546
 >> iter 76000, loss: 0.043783
 >> iter 77000, loss: 0.059730
 >> iter 78000, loss: 0.055196
 >> iter 79000, loss: 0.078171
 >> iter 80000, loss: 0.044063
   Number of active neurons: 3
 >> iter 81000, loss: 0.052724
 >> iter 82000, loss: 0.045606
 >> iter 83000, loss: 0.041307
 >> iter 84000, loss: 0.048269
 >> iter 85000, loss: 0.045372
 >> iter 86000, loss: 0.046730
 >> iter 87000, loss: 0.062546
 >> iter 88000, loss: 0.052672
 >> iter 89000, loss: 0.049245
 >> iter 90000, loss: 0.069413
   Number of active neurons: 3
 >> iter 91000, loss: 0.044547
 >> iter 92000, loss: 0.037644
 >> iter 93000, loss: 0.037305
 >> iter 94000, loss: 0.029579
 >> iter 95000, loss: 0.027667
 >> iter 96000, loss: 0.040488
 >> iter 97000, loss: 0.047511
 >> iter 98000, loss: 0.042169
 >> iter 99000, loss: 0.035684
 >> iter 100000, loss: 0.038839
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.338796
 >> iter 2000, loss: 4.413824
 >> iter 3000, loss: 1.736431
 >> iter 4000, loss: 0.730863
 >> iter 5000, loss: 0.324726
 >> iter 6000, loss: 0.186170
 >> iter 7000, loss: 0.155550
 >> iter 8000, loss: 0.105717
 >> iter 9000, loss: 0.079387
 >> iter 10000, loss: 0.083946
   Number of active neurons: 7
 >> iter 11000, loss: 0.090465
 >> iter 12000, loss: 0.064214
 >> iter 13000, loss: 0.065496
 >> iter 14000, loss: 0.066794
 >> iter 15000, loss: 0.054105
 >> iter 16000, loss: 0.064535
 >> iter 17000, loss: 0.058307
 >> iter 18000, loss: 0.064627
 >> iter 19000, loss: 0.060818
 >> iter 20000, loss: 0.046671
   Number of active neurons: 6
 >> iter 21000, loss: 0.055548
 >> iter 22000, loss: 0.050311
 >> iter 23000, loss: 0.043988
 >> iter 24000, loss: 0.049801
 >> iter 25000, loss: 0.050753
 >> iter 26000, loss: 0.042421
 >> iter 27000, loss: 0.066023
 >> iter 28000, loss: 0.064260
 >> iter 29000, loss: 0.054690
 >> iter 30000, loss: 0.043029
   Number of active neurons: 5
 >> iter 31000, loss: 0.038150
 >> iter 32000, loss: 0.032917
 >> iter 33000, loss: 0.040830
 >> iter 34000, loss: 0.046671
 >> iter 35000, loss: 0.051592
 >> iter 36000, loss: 0.046300
 >> iter 37000, loss: 0.043227
 >> iter 38000, loss: 0.051676
 >> iter 39000, loss: 0.051939
 >> iter 40000, loss: 0.052629
   Number of active neurons: 4
 >> iter 41000, loss: 0.052727
 >> iter 42000, loss: 0.057853
 >> iter 43000, loss: 0.047784
 >> iter 44000, loss: 0.053188
 >> iter 45000, loss: 0.077054
 >> iter 46000, loss: 0.053636
 >> iter 47000, loss: 0.043357
 >> iter 48000, loss: 0.037213
 >> iter 49000, loss: 0.037677
 >> iter 50000, loss: 0.045850
   Number of active neurons: 4
 >> iter 51000, loss: 0.045197
 >> iter 52000, loss: 0.043624
 >> iter 53000, loss: 0.048995
 >> iter 54000, loss: 0.050455
 >> iter 55000, loss: 0.041745
 >> iter 56000, loss: 0.052218
 >> iter 57000, loss: 0.051222
 >> iter 58000, loss: 0.033726
 >> iter 59000, loss: 0.035151
 >> iter 60000, loss: 0.050663
   Number of active neurons: 4
 >> iter 61000, loss: 0.047200
 >> iter 62000, loss: 0.038084
 >> iter 63000, loss: 0.049365
 >> iter 64000, loss: 0.043342
 >> iter 65000, loss: 0.053535
 >> iter 66000, loss: 0.045402
 >> iter 67000, loss: 0.047396
 >> iter 68000, loss: 0.044500
 >> iter 69000, loss: 0.036338
 >> iter 70000, loss: 0.051029
   Number of active neurons: 3
 >> iter 71000, loss: 0.061856
 >> iter 72000, loss: 0.063534
 >> iter 73000, loss: 0.054560
 >> iter 74000, loss: 0.055374
 >> iter 75000, loss: 0.045206
 >> iter 76000, loss: 0.048801
 >> iter 77000, loss: 0.043812
 >> iter 78000, loss: 0.042416
 >> iter 79000, loss: 0.063852
 >> iter 80000, loss: 0.056331
   Number of active neurons: 3
 >> iter 81000, loss: 0.040767
 >> iter 82000, loss: 0.043106
 >> iter 83000, loss: 0.040188
 >> iter 84000, loss: 0.053859
 >> iter 85000, loss: 0.052257
 >> iter 86000, loss: 0.046697
 >> iter 87000, loss: 0.043821
 >> iter 88000, loss: 0.040945
 >> iter 89000, loss: 0.060931
 >> iter 90000, loss: 0.066597
   Number of active neurons: 3
 >> iter 91000, loss: 0.066726
 >> iter 92000, loss: 0.049703
 >> iter 93000, loss: 0.043417
 >> iter 94000, loss: 0.031070
 >> iter 95000, loss: 0.034972
 >> iter 96000, loss: 0.053041
 >> iter 97000, loss: 0.073071
 >> iter 98000, loss: 0.053397
 >> iter 99000, loss: 0.058014
 >> iter 100000, loss: 0.053474
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

