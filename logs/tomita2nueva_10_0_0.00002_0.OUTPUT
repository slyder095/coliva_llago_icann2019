 > Problema: tomita2nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 2e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 10.855306
 >> iter 2000, loss: 4.011508
 >> iter 3000, loss: 1.485598
 >> iter 4000, loss: 0.553756
 >> iter 5000, loss: 0.210229
 >> iter 6000, loss: 0.082930
 >> iter 7000, loss: 0.035938
 >> iter 8000, loss: 0.018109
 >> iter 9000, loss: 0.011544
 >> iter 10000, loss: 0.008739
   Number of active neurons: 8
 >> iter 11000, loss: 0.007763
 >> iter 12000, loss: 0.007067
 >> iter 13000, loss: 0.006898
 >> iter 14000, loss: 0.006538
 >> iter 15000, loss: 0.006571
 >> iter 16000, loss: 0.006247
 >> iter 17000, loss: 0.006322
 >> iter 18000, loss: 0.006047
 >> iter 19000, loss: 0.006136
 >> iter 20000, loss: 0.005896
   Number of active neurons: 8
 >> iter 21000, loss: 0.005986
 >> iter 22000, loss: 0.005768
 >> iter 23000, loss: 0.005864
 >> iter 24000, loss: 0.005662
 >> iter 25000, loss: 0.005754
 >> iter 26000, loss: 0.005575
 >> iter 27000, loss: 0.005682
 >> iter 28000, loss: 0.005516
 >> iter 29000, loss: 0.005603
 >> iter 30000, loss: 0.005446
   Number of active neurons: 8
 >> iter 31000, loss: 0.005533
 >> iter 32000, loss: 0.005394
 >> iter 33000, loss: 0.005492
 >> iter 34000, loss: 0.005382
 >> iter 35000, loss: 0.005475
 >> iter 36000, loss: 0.005378
 >> iter 37000, loss: 0.005476
 >> iter 38000, loss: 0.005385
 >> iter 39000, loss: 0.005479
 >> iter 40000, loss: 0.005398
   Number of active neurons: 7
 >> iter 41000, loss: 0.005475
 >> iter 42000, loss: 0.005389
 >> iter 43000, loss: 0.005465
 >> iter 44000, loss: 0.005387
 >> iter 45000, loss: 0.005457
 >> iter 46000, loss: 0.005374
 >> iter 47000, loss: 0.005445
 >> iter 48000, loss: 0.005361
 >> iter 49000, loss: 0.005435
 >> iter 50000, loss: 0.005348
   Number of active neurons: 6
 >> iter 51000, loss: 0.005414
 >> iter 52000, loss: 0.005334
 >> iter 53000, loss: 0.005388
 >> iter 54000, loss: 0.005314
 >> iter 55000, loss: 0.005362
 >> iter 56000, loss: 0.005287
 >> iter 57000, loss: 0.005330
 >> iter 58000, loss: 0.005253
 >> iter 59000, loss: 0.005294
 >> iter 60000, loss: 0.005221
   Number of active neurons: 6
 >> iter 61000, loss: 0.005268
 >> iter 62000, loss: 0.005189
 >> iter 63000, loss: 0.005231
 >> iter 64000, loss: 0.005157
 >> iter 65000, loss: 0.005191
 >> iter 66000, loss: 0.005112
 >> iter 67000, loss: 0.005139
 >> iter 68000, loss: 0.005069
 >> iter 69000, loss: 0.005088
 >> iter 70000, loss: 0.005023
   Number of active neurons: 6
 >> iter 71000, loss: 0.005039
 >> iter 72000, loss: 0.004973
 >> iter 73000, loss: 0.004992
 >> iter 74000, loss: 0.004922
 >> iter 75000, loss: 0.004940
 >> iter 76000, loss: 0.004876
 >> iter 77000, loss: 0.004892
 >> iter 78000, loss: 0.004824
 >> iter 79000, loss: 0.004837
 >> iter 80000, loss: 0.004769
   Number of active neurons: 6
 >> iter 81000, loss: 0.004786
 >> iter 82000, loss: 0.004720
 >> iter 83000, loss: 0.004738
 >> iter 84000, loss: 0.004675
 >> iter 85000, loss: 0.004685
 >> iter 86000, loss: 0.004623
 >> iter 87000, loss: 0.004635
 >> iter 88000, loss: 0.004583
 >> iter 89000, loss: 0.004595
 >> iter 90000, loss: 0.004544
   Number of active neurons: 6
 >> iter 91000, loss: 0.004557
 >> iter 92000, loss: 0.004515
 >> iter 93000, loss: 0.004529
 >> iter 94000, loss: 0.004488
 >> iter 95000, loss: 0.004506
 >> iter 96000, loss: 0.004465
 >> iter 97000, loss: 0.004482
 >> iter 98000, loss: 0.004439
 >> iter 99000, loss: 0.004458
 >> iter 100000, loss: 0.004422
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.763640
 >> iter 2000, loss: 3.976465
 >> iter 3000, loss: 1.472777
 >> iter 4000, loss: 0.549100
 >> iter 5000, loss: 0.208387
 >> iter 6000, loss: 0.082072
 >> iter 7000, loss: 0.035275
 >> iter 8000, loss: 0.017500
 >> iter 9000, loss: 0.010834
 >> iter 10000, loss: 0.008005
   Number of active neurons: 5
 >> iter 11000, loss: 0.006927
 >> iter 12000, loss: 0.006236
 >> iter 13000, loss: 0.005984
 >> iter 14000, loss: 0.005646
 >> iter 15000, loss: 0.005576
 >> iter 16000, loss: 0.005316
 >> iter 17000, loss: 0.005292
 >> iter 18000, loss: 0.005073
 >> iter 19000, loss: 0.005072
 >> iter 20000, loss: 0.004889
   Number of active neurons: 5
 >> iter 21000, loss: 0.004904
 >> iter 22000, loss: 0.004744
 >> iter 23000, loss: 0.004774
 >> iter 24000, loss: 0.004634
 >> iter 25000, loss: 0.004676
 >> iter 26000, loss: 0.004548
 >> iter 27000, loss: 0.004598
 >> iter 28000, loss: 0.004476
 >> iter 29000, loss: 0.004513
 >> iter 30000, loss: 0.004390
   Number of active neurons: 5
 >> iter 31000, loss: 0.004430
 >> iter 32000, loss: 0.004322
 >> iter 33000, loss: 0.004372
 >> iter 34000, loss: 0.004281
 >> iter 35000, loss: 0.004327
 >> iter 36000, loss: 0.004256
 >> iter 37000, loss: 0.004316
 >> iter 38000, loss: 0.004259
 >> iter 39000, loss: 0.004319
 >> iter 40000, loss: 0.004273
   Number of active neurons: 4
 >> iter 41000, loss: 0.004323
 >> iter 42000, loss: 0.004270
 >> iter 43000, loss: 0.004322
 >> iter 44000, loss: 0.004275
 >> iter 45000, loss: 0.004323
 >> iter 46000, loss: 0.004273
 >> iter 47000, loss: 0.004321
 >> iter 48000, loss: 0.004268
 >> iter 49000, loss: 0.004317
 >> iter 50000, loss: 0.004260
   Number of active neurons: 4
 >> iter 51000, loss: 0.004306
 >> iter 52000, loss: 0.004254
 >> iter 53000, loss: 0.004290
 >> iter 54000, loss: 0.004244
 >> iter 55000, loss: 0.004276
 >> iter 56000, loss: 0.004228
 >> iter 57000, loss: 0.004256
 >> iter 58000, loss: 0.004206
 >> iter 59000, loss: 0.004229
 >> iter 60000, loss: 0.004179
   Number of active neurons: 4
 >> iter 61000, loss: 0.004204
 >> iter 62000, loss: 0.004146
 >> iter 63000, loss: 0.004167
 >> iter 64000, loss: 0.004115
 >> iter 65000, loss: 0.004134
 >> iter 66000, loss: 0.004086
 >> iter 67000, loss: 0.004105
 >> iter 68000, loss: 0.004061
 >> iter 69000, loss: 0.004075
 >> iter 70000, loss: 0.004035
   Number of active neurons: 4
 >> iter 71000, loss: 0.004046
 >> iter 72000, loss: 0.004008
 >> iter 73000, loss: 0.004024
 >> iter 74000, loss: 0.003984
 >> iter 75000, loss: 0.003998
 >> iter 76000, loss: 0.003959
 >> iter 77000, loss: 0.003972
 >> iter 78000, loss: 0.003932
 >> iter 79000, loss: 0.003945
 >> iter 80000, loss: 0.003904
   Number of active neurons: 4
 >> iter 81000, loss: 0.003918
 >> iter 82000, loss: 0.003878
 >> iter 83000, loss: 0.003895
 >> iter 84000, loss: 0.003857
 >> iter 85000, loss: 0.003873
 >> iter 86000, loss: 0.003838
 >> iter 87000, loss: 0.003854
 >> iter 88000, loss: 0.003827
 >> iter 89000, loss: 0.003840
 >> iter 90000, loss: 0.003813
   Number of active neurons: 4
 >> iter 91000, loss: 0.003826
 >> iter 92000, loss: 0.003804
 >> iter 93000, loss: 0.003817
 >> iter 94000, loss: 0.003793
 >> iter 95000, loss: 0.003809
 >> iter 96000, loss: 0.003784
 >> iter 97000, loss: 0.003800
 >> iter 98000, loss: 0.003775
 >> iter 99000, loss: 0.003792
 >> iter 100000, loss: 0.003769
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.819967
 >> iter 2000, loss: 3.996576
 >> iter 3000, loss: 1.479522
 >> iter 4000, loss: 0.551224
 >> iter 5000, loss: 0.208937
 >> iter 6000, loss: 0.082193
 >> iter 7000, loss: 0.035334
 >> iter 8000, loss: 0.017621
 >> iter 9000, loss: 0.011054
 >> iter 10000, loss: 0.008309
   Number of active neurons: 7
 >> iter 11000, loss: 0.007331
 >> iter 12000, loss: 0.006704
 >> iter 13000, loss: 0.006552
 >> iter 14000, loss: 0.006269
 >> iter 15000, loss: 0.006304
 >> iter 16000, loss: 0.006055
 >> iter 17000, loss: 0.006124
 >> iter 18000, loss: 0.005915
 >> iter 19000, loss: 0.006004
 >> iter 20000, loss: 0.005822
   Number of active neurons: 6
 >> iter 21000, loss: 0.005923
 >> iter 22000, loss: 0.005755
 >> iter 23000, loss: 0.005852
 >> iter 24000, loss: 0.005681
 >> iter 25000, loss: 0.005763
 >> iter 26000, loss: 0.005598
 >> iter 27000, loss: 0.005685
 >> iter 28000, loss: 0.005528
 >> iter 29000, loss: 0.005614
 >> iter 30000, loss: 0.005472
   Number of active neurons: 6
 >> iter 31000, loss: 0.005561
 >> iter 32000, loss: 0.005423
 >> iter 33000, loss: 0.005513
 >> iter 34000, loss: 0.005386
 >> iter 35000, loss: 0.005458
 >> iter 36000, loss: 0.005331
 >> iter 37000, loss: 0.005400
 >> iter 38000, loss: 0.005278
 >> iter 39000, loss: 0.005344
 >> iter 40000, loss: 0.005239
   Number of active neurons: 5
 >> iter 41000, loss: 0.005294
 >> iter 42000, loss: 0.005190
 >> iter 43000, loss: 0.005249
 >> iter 44000, loss: 0.005157
 >> iter 45000, loss: 0.005211
 >> iter 46000, loss: 0.005116
 >> iter 47000, loss: 0.005170
 >> iter 48000, loss: 0.005076
 >> iter 49000, loss: 0.005132
 >> iter 50000, loss: 0.005039
   Number of active neurons: 5
 >> iter 51000, loss: 0.005093
 >> iter 52000, loss: 0.005008
 >> iter 53000, loss: 0.005052
 >> iter 54000, loss: 0.004976
 >> iter 55000, loss: 0.005015
 >> iter 56000, loss: 0.004941
 >> iter 57000, loss: 0.004980
 >> iter 58000, loss: 0.004910
 >> iter 59000, loss: 0.004951
 >> iter 60000, loss: 0.004883
   Number of active neurons: 5
 >> iter 61000, loss: 0.004927
 >> iter 62000, loss: 0.004850
 >> iter 63000, loss: 0.004889
 >> iter 64000, loss: 0.004818
 >> iter 65000, loss: 0.004856
 >> iter 66000, loss: 0.004791
 >> iter 67000, loss: 0.004827
 >> iter 68000, loss: 0.004769
 >> iter 69000, loss: 0.004798
 >> iter 70000, loss: 0.004743
   Number of active neurons: 5
 >> iter 71000, loss: 0.004770
 >> iter 72000, loss: 0.004717
 >> iter 73000, loss: 0.004750
 >> iter 74000, loss: 0.004694
 >> iter 75000, loss: 0.004724
 >> iter 76000, loss: 0.004669
 >> iter 77000, loss: 0.004697
 >> iter 78000, loss: 0.004641
 >> iter 79000, loss: 0.004667
 >> iter 80000, loss: 0.004604
   Number of active neurons: 5
 >> iter 81000, loss: 0.004627
 >> iter 82000, loss: 0.004563
 >> iter 83000, loss: 0.004589
 >> iter 84000, loss: 0.004531
 >> iter 85000, loss: 0.004552
 >> iter 86000, loss: 0.004495
 >> iter 87000, loss: 0.004518
 >> iter 88000, loss: 0.004472
 >> iter 89000, loss: 0.004493
 >> iter 90000, loss: 0.004449
   Number of active neurons: 5
 >> iter 91000, loss: 0.004471
 >> iter 92000, loss: 0.004436
 >> iter 93000, loss: 0.004457
 >> iter 94000, loss: 0.004417
 >> iter 95000, loss: 0.004437
 >> iter 96000, loss: 0.004399
 >> iter 97000, loss: 0.004422
 >> iter 98000, loss: 0.004385
 >> iter 99000, loss: 0.004409
 >> iter 100000, loss: 0.004376
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.843039
 >> iter 2000, loss: 4.005746
 >> iter 3000, loss: 1.483034
 >> iter 4000, loss: 0.552486
 >> iter 5000, loss: 0.209313
 >> iter 6000, loss: 0.082180
 >> iter 7000, loss: 0.035156
 >> iter 8000, loss: 0.017363
 >> iter 9000, loss: 0.010743
 >> iter 10000, loss: 0.007968
   Number of active neurons: 6
 >> iter 11000, loss: 0.006968
 >> iter 12000, loss: 0.006348
 >> iter 13000, loss: 0.006192
 >> iter 14000, loss: 0.005925
 >> iter 15000, loss: 0.005938
 >> iter 16000, loss: 0.005705
 >> iter 17000, loss: 0.005741
 >> iter 18000, loss: 0.005543
 >> iter 19000, loss: 0.005591
 >> iter 20000, loss: 0.005429
   Number of active neurons: 6
 >> iter 21000, loss: 0.005486
 >> iter 22000, loss: 0.005348
 >> iter 23000, loss: 0.005415
 >> iter 24000, loss: 0.005288
 >> iter 25000, loss: 0.005359
 >> iter 26000, loss: 0.005234
 >> iter 27000, loss: 0.005303
 >> iter 28000, loss: 0.005179
 >> iter 29000, loss: 0.005238
 >> iter 30000, loss: 0.005111
   Number of active neurons: 6
 >> iter 31000, loss: 0.005164
 >> iter 32000, loss: 0.005044
 >> iter 33000, loss: 0.005099
 >> iter 34000, loss: 0.004994
 >> iter 35000, loss: 0.005045
 >> iter 36000, loss: 0.004951
 >> iter 37000, loss: 0.005005
 >> iter 38000, loss: 0.004915
 >> iter 39000, loss: 0.004965
 >> iter 40000, loss: 0.004891
   Number of active neurons: 6
 >> iter 41000, loss: 0.004937
 >> iter 42000, loss: 0.004863
 >> iter 43000, loss: 0.004915
 >> iter 44000, loss: 0.004852
 >> iter 45000, loss: 0.004905
 >> iter 46000, loss: 0.004843
 >> iter 47000, loss: 0.004899
 >> iter 48000, loss: 0.004835
 >> iter 49000, loss: 0.004895
 >> iter 50000, loss: 0.004827
   Number of active neurons: 6
 >> iter 51000, loss: 0.004886
 >> iter 52000, loss: 0.004828
 >> iter 53000, loss: 0.004882
 >> iter 54000, loss: 0.004832
 >> iter 55000, loss: 0.004884
 >> iter 56000, loss: 0.004835
 >> iter 57000, loss: 0.004883
 >> iter 58000, loss: 0.004837
 >> iter 59000, loss: 0.004885
 >> iter 60000, loss: 0.004840
   Number of active neurons: 6
 >> iter 61000, loss: 0.004894
 >> iter 62000, loss: 0.004843
 >> iter 63000, loss: 0.004893
 >> iter 64000, loss: 0.004848
 >> iter 65000, loss: 0.004894
 >> iter 66000, loss: 0.004851
 >> iter 67000, loss: 0.004896
 >> iter 68000, loss: 0.004858
 >> iter 69000, loss: 0.004896
 >> iter 70000, loss: 0.004861
   Number of active neurons: 6
 >> iter 71000, loss: 0.004896
 >> iter 72000, loss: 0.004862
 >> iter 73000, loss: 0.004903
 >> iter 74000, loss: 0.004867
 >> iter 75000, loss: 0.004906
 >> iter 76000, loss: 0.004871
 >> iter 77000, loss: 0.004908
 >> iter 78000, loss: 0.004873
 >> iter 79000, loss: 0.004910
 >> iter 80000, loss: 0.004873
   Number of active neurons: 6
 >> iter 81000, loss: 0.004912
 >> iter 82000, loss: 0.004876
 >> iter 83000, loss: 0.004916
 >> iter 84000, loss: 0.004880
 >> iter 85000, loss: 0.004916
 >> iter 86000, loss: 0.004882
 >> iter 87000, loss: 0.004918
 >> iter 88000, loss: 0.004890
 >> iter 89000, loss: 0.004923
 >> iter 90000, loss: 0.004893
   Number of active neurons: 6
 >> iter 91000, loss: 0.004924
 >> iter 92000, loss: 0.004901
 >> iter 93000, loss: 0.004931
 >> iter 94000, loss: 0.004905
 >> iter 95000, loss: 0.004937
 >> iter 96000, loss: 0.004909
 >> iter 97000, loss: 0.004941
 >> iter 98000, loss: 0.004913
 >> iter 99000, loss: 0.004946
 >> iter 100000, loss: 0.004920
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 10.825691
 >> iter 2000, loss: 3.997644
 >> iter 3000, loss: 1.479278
 >> iter 4000, loss: 0.550619
 >> iter 5000, loss: 0.208229
 >> iter 6000, loss: 0.081459
 >> iter 7000, loss: 0.034561
 >> iter 8000, loss: 0.016861
 >> iter 9000, loss: 0.010248
 >> iter 10000, loss: 0.007504
   Number of active neurons: 6
 >> iter 11000, loss: 0.006482
 >> iter 12000, loss: 0.005867
 >> iter 13000, loss: 0.005674
 >> iter 14000, loss: 0.005412
 >> iter 15000, loss: 0.005398
 >> iter 16000, loss: 0.005203
 >> iter 17000, loss: 0.005237
 >> iter 18000, loss: 0.005084
 >> iter 19000, loss: 0.005142
 >> iter 20000, loss: 0.005004
   Number of active neurons: 5
 >> iter 21000, loss: 0.005062
 >> iter 22000, loss: 0.004932
 >> iter 23000, loss: 0.004999
 >> iter 24000, loss: 0.004882
 >> iter 25000, loss: 0.004958
 >> iter 26000, loss: 0.004848
 >> iter 27000, loss: 0.004931
 >> iter 28000, loss: 0.004816
 >> iter 29000, loss: 0.004880
 >> iter 30000, loss: 0.004768
   Number of active neurons: 4
 >> iter 31000, loss: 0.004834
 >> iter 32000, loss: 0.004730
 >> iter 33000, loss: 0.004799
 >> iter 34000, loss: 0.004710
 >> iter 35000, loss: 0.004772
 >> iter 36000, loss: 0.004690
 >> iter 37000, loss: 0.004752
 >> iter 38000, loss: 0.004673
 >> iter 39000, loss: 0.004732
 >> iter 40000, loss: 0.004664
   Number of active neurons: 4
 >> iter 41000, loss: 0.004714
 >> iter 42000, loss: 0.004645
 >> iter 43000, loss: 0.004696
 >> iter 44000, loss: 0.004633
 >> iter 45000, loss: 0.004679
 >> iter 46000, loss: 0.004611
 >> iter 47000, loss: 0.004655
 >> iter 48000, loss: 0.004586
 >> iter 49000, loss: 0.004633
 >> iter 50000, loss: 0.004563
   Number of active neurons: 4
 >> iter 51000, loss: 0.004608
 >> iter 52000, loss: 0.004546
 >> iter 53000, loss: 0.004583
 >> iter 54000, loss: 0.004528
 >> iter 55000, loss: 0.004562
 >> iter 56000, loss: 0.004504
 >> iter 57000, loss: 0.004533
 >> iter 58000, loss: 0.004477
 >> iter 59000, loss: 0.004506
 >> iter 60000, loss: 0.004453
   Number of active neurons: 4
 >> iter 61000, loss: 0.004488
 >> iter 62000, loss: 0.004430
 >> iter 63000, loss: 0.004462
 >> iter 64000, loss: 0.004409
 >> iter 65000, loss: 0.004439
 >> iter 66000, loss: 0.004389
 >> iter 67000, loss: 0.004417
 >> iter 68000, loss: 0.004372
 >> iter 69000, loss: 0.004392
 >> iter 70000, loss: 0.004351
   Number of active neurons: 4
 >> iter 71000, loss: 0.004371
 >> iter 72000, loss: 0.004333
 >> iter 73000, loss: 0.004359
 >> iter 74000, loss: 0.004321
 >> iter 75000, loss: 0.004347
 >> iter 76000, loss: 0.004312
 >> iter 77000, loss: 0.004337
 >> iter 78000, loss: 0.004302
 >> iter 79000, loss: 0.004329
 >> iter 80000, loss: 0.004293
   Number of active neurons: 4
 >> iter 81000, loss: 0.004322
 >> iter 82000, loss: 0.004287
 >> iter 83000, loss: 0.004318
 >> iter 84000, loss: 0.004284
 >> iter 85000, loss: 0.004312
 >> iter 86000, loss: 0.004279
 >> iter 87000, loss: 0.004306
 >> iter 88000, loss: 0.004278
 >> iter 89000, loss: 0.004302
 >> iter 90000, loss: 0.004273
   Number of active neurons: 4
 >> iter 91000, loss: 0.004297
 >> iter 92000, loss: 0.004274
 >> iter 93000, loss: 0.004298
 >> iter 94000, loss: 0.004273
 >> iter 95000, loss: 0.004298
 >> iter 96000, loss: 0.004272
 >> iter 97000, loss: 0.004297
 >> iter 98000, loss: 0.004270
 >> iter 99000, loss: 0.004297
 >> iter 100000, loss: 0.004272
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.839413
 >> iter 2000, loss: 4.005478
 >> iter 3000, loss: 1.482192
 >> iter 4000, loss: 0.552091
 >> iter 5000, loss: 0.209171
 >> iter 6000, loss: 0.082327
 >> iter 7000, loss: 0.035414
 >> iter 8000, loss: 0.017739
 >> iter 9000, loss: 0.011147
 >> iter 10000, loss: 0.008408
   Number of active neurons: 8
 >> iter 11000, loss: 0.007410
 >> iter 12000, loss: 0.006794
 >> iter 13000, loss: 0.006630
 >> iter 14000, loss: 0.006341
 >> iter 15000, loss: 0.006352
 >> iter 16000, loss: 0.006073
 >> iter 17000, loss: 0.006132
 >> iter 18000, loss: 0.005884
 >> iter 19000, loss: 0.005974
 >> iter 20000, loss: 0.005746
   Number of active neurons: 8
 >> iter 21000, loss: 0.005834
 >> iter 22000, loss: 0.005608
 >> iter 23000, loss: 0.005680
 >> iter 24000, loss: 0.005479
 >> iter 25000, loss: 0.005554
 >> iter 26000, loss: 0.005373
 >> iter 27000, loss: 0.005452
 >> iter 28000, loss: 0.005296
 >> iter 29000, loss: 0.005386
 >> iter 30000, loss: 0.005251
   Number of active neurons: 8
 >> iter 31000, loss: 0.005343
 >> iter 32000, loss: 0.005209
 >> iter 33000, loss: 0.005300
 >> iter 34000, loss: 0.005185
 >> iter 35000, loss: 0.005263
 >> iter 36000, loss: 0.005148
 >> iter 37000, loss: 0.005225
 >> iter 38000, loss: 0.005118
 >> iter 39000, loss: 0.005190
 >> iter 40000, loss: 0.005098
   Number of active neurons: 7
 >> iter 41000, loss: 0.005155
 >> iter 42000, loss: 0.005063
 >> iter 43000, loss: 0.005121
 >> iter 44000, loss: 0.005041
 >> iter 45000, loss: 0.005095
 >> iter 46000, loss: 0.005016
 >> iter 47000, loss: 0.005073
 >> iter 48000, loss: 0.004997
 >> iter 49000, loss: 0.005057
 >> iter 50000, loss: 0.004985
   Number of active neurons: 6
 >> iter 51000, loss: 0.005047
 >> iter 52000, loss: 0.004985
 >> iter 53000, loss: 0.005034
 >> iter 54000, loss: 0.004978
 >> iter 55000, loss: 0.005024
 >> iter 56000, loss: 0.004967
 >> iter 57000, loss: 0.005011
 >> iter 58000, loss: 0.004955
 >> iter 59000, loss: 0.004998
 >> iter 60000, loss: 0.004941
   Number of active neurons: 6
 >> iter 61000, loss: 0.004987
 >> iter 62000, loss: 0.004922
 >> iter 63000, loss: 0.004963
 >> iter 64000, loss: 0.004901
 >> iter 65000, loss: 0.004935
 >> iter 66000, loss: 0.004869
 >> iter 67000, loss: 0.004896
 >> iter 68000, loss: 0.004834
 >> iter 69000, loss: 0.004849
 >> iter 70000, loss: 0.004782
   Number of active neurons: 6
 >> iter 71000, loss: 0.004788
 >> iter 72000, loss: 0.004726
 >> iter 73000, loss: 0.004741
 >> iter 74000, loss: 0.004681
 >> iter 75000, loss: 0.004697
 >> iter 76000, loss: 0.004643
 >> iter 77000, loss: 0.004659
 >> iter 78000, loss: 0.004605
 >> iter 79000, loss: 0.004623
 >> iter 80000, loss: 0.004569
   Number of active neurons: 6
 >> iter 81000, loss: 0.004589
 >> iter 82000, loss: 0.004536
 >> iter 83000, loss: 0.004557
 >> iter 84000, loss: 0.004504
 >> iter 85000, loss: 0.004521
 >> iter 86000, loss: 0.004469
 >> iter 87000, loss: 0.004485
 >> iter 88000, loss: 0.004438
 >> iter 89000, loss: 0.004448
 >> iter 90000, loss: 0.004399
   Number of active neurons: 6
 >> iter 91000, loss: 0.004409
 >> iter 92000, loss: 0.004369
 >> iter 93000, loss: 0.004382
 >> iter 94000, loss: 0.004342
 >> iter 95000, loss: 0.004361
 >> iter 96000, loss: 0.004323
 >> iter 97000, loss: 0.004344
 >> iter 98000, loss: 0.004307
 >> iter 99000, loss: 0.004330
 >> iter 100000, loss: 0.004298
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.791590
 >> iter 2000, loss: 3.986112
 >> iter 3000, loss: 1.475498
 >> iter 4000, loss: 0.549467
 >> iter 5000, loss: 0.208096
 >> iter 6000, loss: 0.081640
 >> iter 7000, loss: 0.034919
 >> iter 8000, loss: 0.017238
 >> iter 9000, loss: 0.010718
 >> iter 10000, loss: 0.007963
   Number of active neurons: 6
 >> iter 11000, loss: 0.006987
 >> iter 12000, loss: 0.006343
 >> iter 13000, loss: 0.006183
 >> iter 14000, loss: 0.005886
 >> iter 15000, loss: 0.005928
 >> iter 16000, loss: 0.005668
 >> iter 17000, loss: 0.005750
 >> iter 18000, loss: 0.005528
 >> iter 19000, loss: 0.005621
 >> iter 20000, loss: 0.005425
   Number of active neurons: 6
 >> iter 21000, loss: 0.005513
 >> iter 22000, loss: 0.005324
 >> iter 23000, loss: 0.005403
 >> iter 24000, loss: 0.005222
 >> iter 25000, loss: 0.005307
 >> iter 26000, loss: 0.005143
 >> iter 27000, loss: 0.005232
 >> iter 28000, loss: 0.005081
 >> iter 29000, loss: 0.005171
 >> iter 30000, loss: 0.005031
   Number of active neurons: 6
 >> iter 31000, loss: 0.005106
 >> iter 32000, loss: 0.004967
 >> iter 33000, loss: 0.005040
 >> iter 34000, loss: 0.004922
 >> iter 35000, loss: 0.004986
 >> iter 36000, loss: 0.004879
 >> iter 37000, loss: 0.004944
 >> iter 38000, loss: 0.004846
 >> iter 39000, loss: 0.004906
 >> iter 40000, loss: 0.004822
   Number of active neurons: 6
 >> iter 41000, loss: 0.004872
 >> iter 42000, loss: 0.004793
 >> iter 43000, loss: 0.004844
 >> iter 44000, loss: 0.004775
 >> iter 45000, loss: 0.004825
 >> iter 46000, loss: 0.004754
 >> iter 47000, loss: 0.004806
 >> iter 48000, loss: 0.004737
 >> iter 49000, loss: 0.004794
 >> iter 50000, loss: 0.004727
   Number of active neurons: 6
 >> iter 51000, loss: 0.004783
 >> iter 52000, loss: 0.004724
 >> iter 53000, loss: 0.004772
 >> iter 54000, loss: 0.004722
 >> iter 55000, loss: 0.004768
 >> iter 56000, loss: 0.004717
 >> iter 57000, loss: 0.004760
 >> iter 58000, loss: 0.004711
 >> iter 59000, loss: 0.004754
 >> iter 60000, loss: 0.004706
   Number of active neurons: 6
 >> iter 61000, loss: 0.004754
 >> iter 62000, loss: 0.004700
 >> iter 63000, loss: 0.004744
 >> iter 64000, loss: 0.004695
 >> iter 65000, loss: 0.004736
 >> iter 66000, loss: 0.004690
 >> iter 67000, loss: 0.004729
 >> iter 68000, loss: 0.004687
 >> iter 69000, loss: 0.004718
 >> iter 70000, loss: 0.004679
   Number of active neurons: 5
 >> iter 71000, loss: 0.004708
 >> iter 72000, loss: 0.004670
 >> iter 73000, loss: 0.004704
 >> iter 74000, loss: 0.004663
 >> iter 75000, loss: 0.004694
 >> iter 76000, loss: 0.004655
 >> iter 77000, loss: 0.004684
 >> iter 78000, loss: 0.004644
 >> iter 79000, loss: 0.004673
 >> iter 80000, loss: 0.004631
   Number of active neurons: 5
 >> iter 81000, loss: 0.004661
 >> iter 82000, loss: 0.004618
 >> iter 83000, loss: 0.004650
 >> iter 84000, loss: 0.004606
 >> iter 85000, loss: 0.004634
 >> iter 86000, loss: 0.004591
 >> iter 87000, loss: 0.004612
 >> iter 88000, loss: 0.004569
 >> iter 89000, loss: 0.004584
 >> iter 90000, loss: 0.004538
   Number of active neurons: 5
 >> iter 91000, loss: 0.004550
 >> iter 92000, loss: 0.004513
 >> iter 93000, loss: 0.004528
 >> iter 94000, loss: 0.004490
 >> iter 95000, loss: 0.004508
 >> iter 96000, loss: 0.004471
 >> iter 97000, loss: 0.004489
 >> iter 98000, loss: 0.004453
 >> iter 99000, loss: 0.004473
 >> iter 100000, loss: 0.004439
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.813134
 >> iter 2000, loss: 3.995657
 >> iter 3000, loss: 1.479896
 >> iter 4000, loss: 0.551699
 >> iter 5000, loss: 0.209417
 >> iter 6000, loss: 0.082482
 >> iter 7000, loss: 0.035548
 >> iter 8000, loss: 0.017666
 >> iter 9000, loss: 0.011013
 >> iter 10000, loss: 0.008138
   Number of active neurons: 9
 >> iter 11000, loss: 0.007114
 >> iter 12000, loss: 0.006426
 >> iter 13000, loss: 0.006253
 >> iter 14000, loss: 0.005934
 >> iter 15000, loss: 0.005956
 >> iter 16000, loss: 0.005701
 >> iter 17000, loss: 0.005772
 >> iter 18000, loss: 0.005583
 >> iter 19000, loss: 0.005684
 >> iter 20000, loss: 0.005531
   Number of active neurons: 5
 >> iter 21000, loss: 0.005631
 >> iter 22000, loss: 0.005496
 >> iter 23000, loss: 0.005593
 >> iter 24000, loss: 0.005468
 >> iter 25000, loss: 0.005560
 >> iter 26000, loss: 0.005437
 >> iter 27000, loss: 0.005521
 >> iter 28000, loss: 0.005397
 >> iter 29000, loss: 0.005481
 >> iter 30000, loss: 0.005359
   Number of active neurons: 6
 >> iter 31000, loss: 0.005428
 >> iter 32000, loss: 0.005306
 >> iter 33000, loss: 0.005372
 >> iter 34000, loss: 0.005262
 >> iter 35000, loss: 0.005316
 >> iter 36000, loss: 0.005208
 >> iter 37000, loss: 0.005261
 >> iter 38000, loss: 0.005158
 >> iter 39000, loss: 0.005208
 >> iter 40000, loss: 0.005118
   Number of active neurons: 6
 >> iter 41000, loss: 0.005161
 >> iter 42000, loss: 0.005070
 >> iter 43000, loss: 0.005113
 >> iter 44000, loss: 0.005029
 >> iter 45000, loss: 0.005067
 >> iter 46000, loss: 0.004980
 >> iter 47000, loss: 0.005021
 >> iter 48000, loss: 0.004937
 >> iter 49000, loss: 0.004984
 >> iter 50000, loss: 0.004902
   Number of active neurons: 6
 >> iter 51000, loss: 0.004949
 >> iter 52000, loss: 0.004878
 >> iter 53000, loss: 0.004921
 >> iter 54000, loss: 0.004862
 >> iter 55000, loss: 0.004904
 >> iter 56000, loss: 0.004847
 >> iter 57000, loss: 0.004888
 >> iter 58000, loss: 0.004837
 >> iter 59000, loss: 0.004879
 >> iter 60000, loss: 0.004830
   Number of active neurons: 6
 >> iter 61000, loss: 0.004879
 >> iter 62000, loss: 0.004825
 >> iter 63000, loss: 0.004871
 >> iter 64000, loss: 0.004823
 >> iter 65000, loss: 0.004865
 >> iter 66000, loss: 0.004821
 >> iter 67000, loss: 0.004862
 >> iter 68000, loss: 0.004822
 >> iter 69000, loss: 0.004856
 >> iter 70000, loss: 0.004820
   Number of active neurons: 6
 >> iter 71000, loss: 0.004851
 >> iter 72000, loss: 0.004816
 >> iter 73000, loss: 0.004854
 >> iter 74000, loss: 0.004816
 >> iter 75000, loss: 0.004851
 >> iter 76000, loss: 0.004816
 >> iter 77000, loss: 0.004849
 >> iter 78000, loss: 0.004812
 >> iter 79000, loss: 0.004846
 >> iter 80000, loss: 0.004808
   Number of active neurons: 6
 >> iter 81000, loss: 0.004843
 >> iter 82000, loss: 0.004805
 >> iter 83000, loss: 0.004841
 >> iter 84000, loss: 0.004804
 >> iter 85000, loss: 0.004837
 >> iter 86000, loss: 0.004800
 >> iter 87000, loss: 0.004832
 >> iter 88000, loss: 0.004803
 >> iter 89000, loss: 0.004831
 >> iter 90000, loss: 0.004799
   Number of active neurons: 5
 >> iter 91000, loss: 0.004825
 >> iter 92000, loss: 0.004800
 >> iter 93000, loss: 0.004824
 >> iter 94000, loss: 0.004796
 >> iter 95000, loss: 0.004823
 >> iter 96000, loss: 0.004792
 >> iter 97000, loss: 0.004818
 >> iter 98000, loss: 0.004787
 >> iter 99000, loss: 0.004813
 >> iter 100000, loss: 0.004784
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 10.814118
 >> iter 2000, loss: 3.993660
 >> iter 3000, loss: 1.477840
 >> iter 4000, loss: 0.550217
 >> iter 5000, loss: 0.208204
 >> iter 6000, loss: 0.081632
 >> iter 7000, loss: 0.034822
 >> iter 8000, loss: 0.017166
 >> iter 9000, loss: 0.010595
 >> iter 10000, loss: 0.007877
   Number of active neurons: 8
 >> iter 11000, loss: 0.006888
 >> iter 12000, loss: 0.006293
 >> iter 13000, loss: 0.006122
 >> iter 14000, loss: 0.005876
 >> iter 15000, loss: 0.005893
 >> iter 16000, loss: 0.005706
 >> iter 17000, loss: 0.005772
 >> iter 18000, loss: 0.005621
 >> iter 19000, loss: 0.005702
 >> iter 20000, loss: 0.005570
   Number of active neurons: 7
 >> iter 21000, loss: 0.005665
 >> iter 22000, loss: 0.005549
 >> iter 23000, loss: 0.005654
 >> iter 24000, loss: 0.005543
 >> iter 25000, loss: 0.005654
 >> iter 26000, loss: 0.005543
 >> iter 27000, loss: 0.005655
 >> iter 28000, loss: 0.005538
 >> iter 29000, loss: 0.005641
 >> iter 30000, loss: 0.005526
   Number of active neurons: 8
 >> iter 31000, loss: 0.005623
 >> iter 32000, loss: 0.005504
 >> iter 33000, loss: 0.005590
 >> iter 34000, loss: 0.005485
 >> iter 35000, loss: 0.005562
 >> iter 36000, loss: 0.005467
 >> iter 37000, loss: 0.005545
 >> iter 38000, loss: 0.005454
 >> iter 39000, loss: 0.005532
 >> iter 40000, loss: 0.005455
   Number of active neurons: 7
 >> iter 41000, loss: 0.005526
 >> iter 42000, loss: 0.005448
 >> iter 43000, loss: 0.005520
 >> iter 44000, loss: 0.005449
 >> iter 45000, loss: 0.005517
 >> iter 46000, loss: 0.005443
 >> iter 47000, loss: 0.005513
 >> iter 48000, loss: 0.005437
 >> iter 49000, loss: 0.005509
 >> iter 50000, loss: 0.005430
   Number of active neurons: 7
 >> iter 51000, loss: 0.005499
 >> iter 52000, loss: 0.005429
 >> iter 53000, loss: 0.005487
 >> iter 54000, loss: 0.005425
 >> iter 55000, loss: 0.005479
 >> iter 56000, loss: 0.005416
 >> iter 57000, loss: 0.005466
 >> iter 58000, loss: 0.005404
 >> iter 59000, loss: 0.005453
 >> iter 60000, loss: 0.005392
   Number of active neurons: 7
 >> iter 61000, loss: 0.005445
 >> iter 62000, loss: 0.005376
 >> iter 63000, loss: 0.005422
 >> iter 64000, loss: 0.005354
 >> iter 65000, loss: 0.005393
 >> iter 66000, loss: 0.005326
 >> iter 67000, loss: 0.005360
 >> iter 68000, loss: 0.005299
 >> iter 69000, loss: 0.005326
 >> iter 70000, loss: 0.005270
   Number of active neurons: 6
 >> iter 71000, loss: 0.005296
 >> iter 72000, loss: 0.005243
 >> iter 73000, loss: 0.005276
 >> iter 74000, loss: 0.005220
 >> iter 75000, loss: 0.005250
 >> iter 76000, loss: 0.005197
 >> iter 77000, loss: 0.005224
 >> iter 78000, loss: 0.005169
 >> iter 79000, loss: 0.005196
 >> iter 80000, loss: 0.005139
   Number of active neurons: 5
 >> iter 81000, loss: 0.005166
 >> iter 82000, loss: 0.005108
 >> iter 83000, loss: 0.005136
 >> iter 84000, loss: 0.005080
 >> iter 85000, loss: 0.005105
 >> iter 86000, loss: 0.005051
 >> iter 87000, loss: 0.005075
 >> iter 88000, loss: 0.005028
 >> iter 89000, loss: 0.005045
 >> iter 90000, loss: 0.004990
   Number of active neurons: 5
 >> iter 91000, loss: 0.004999
 >> iter 92000, loss: 0.004950
 >> iter 93000, loss: 0.004962
 >> iter 94000, loss: 0.004913
 >> iter 95000, loss: 0.004928
 >> iter 96000, loss: 0.004880
 >> iter 97000, loss: 0.004895
 >> iter 98000, loss: 0.004848
 >> iter 99000, loss: 0.004862
 >> iter 100000, loss: 0.004811
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.823095
 >> iter 2000, loss: 3.998623
 >> iter 3000, loss: 1.480526
 >> iter 4000, loss: 0.551697
 >> iter 5000, loss: 0.209221
 >> iter 6000, loss: 0.082346
 >> iter 7000, loss: 0.035468
 >> iter 8000, loss: 0.017713
 >> iter 9000, loss: 0.011148
 >> iter 10000, loss: 0.008381
   Number of active neurons: 8
 >> iter 11000, loss: 0.007400
 >> iter 12000, loss: 0.006765
 >> iter 13000, loss: 0.006598
 >> iter 14000, loss: 0.006307
 >> iter 15000, loss: 0.006361
 >> iter 16000, loss: 0.006092
 >> iter 17000, loss: 0.006176
 >> iter 18000, loss: 0.005949
 >> iter 19000, loss: 0.006051
 >> iter 20000, loss: 0.005863
   Number of active neurons: 8
 >> iter 21000, loss: 0.005986
 >> iter 22000, loss: 0.005816
 >> iter 23000, loss: 0.005944
 >> iter 24000, loss: 0.005790
 >> iter 25000, loss: 0.005924
 >> iter 26000, loss: 0.005779
 >> iter 27000, loss: 0.005911
 >> iter 28000, loss: 0.005772
 >> iter 29000, loss: 0.005903
 >> iter 30000, loss: 0.005775
   Number of active neurons: 8
 >> iter 31000, loss: 0.005902
 >> iter 32000, loss: 0.005767
 >> iter 33000, loss: 0.005880
 >> iter 34000, loss: 0.005759
 >> iter 35000, loss: 0.005860
 >> iter 36000, loss: 0.005747
 >> iter 37000, loss: 0.005839
 >> iter 38000, loss: 0.005723
 >> iter 39000, loss: 0.005802
 >> iter 40000, loss: 0.005700
   Number of active neurons: 8
 >> iter 41000, loss: 0.005755
 >> iter 42000, loss: 0.005654
 >> iter 43000, loss: 0.005713
 >> iter 44000, loss: 0.005629
 >> iter 45000, loss: 0.005686
 >> iter 46000, loss: 0.005603
 >> iter 47000, loss: 0.005662
 >> iter 48000, loss: 0.005578
 >> iter 49000, loss: 0.005639
 >> iter 50000, loss: 0.005552
   Number of active neurons: 7
 >> iter 51000, loss: 0.005611
 >> iter 52000, loss: 0.005540
 >> iter 53000, loss: 0.005592
 >> iter 54000, loss: 0.005531
 >> iter 55000, loss: 0.005580
 >> iter 56000, loss: 0.005515
 >> iter 57000, loss: 0.005560
 >> iter 58000, loss: 0.005500
 >> iter 59000, loss: 0.005548
 >> iter 60000, loss: 0.005491
   Number of active neurons: 7
 >> iter 61000, loss: 0.005544
 >> iter 62000, loss: 0.005479
 >> iter 63000, loss: 0.005524
 >> iter 64000, loss: 0.005467
 >> iter 65000, loss: 0.005511
 >> iter 66000, loss: 0.005458
 >> iter 67000, loss: 0.005500
 >> iter 68000, loss: 0.005453
 >> iter 69000, loss: 0.005487
 >> iter 70000, loss: 0.005443
   Number of active neurons: 7
 >> iter 71000, loss: 0.005473
 >> iter 72000, loss: 0.005429
 >> iter 73000, loss: 0.005462
 >> iter 74000, loss: 0.005413
 >> iter 75000, loss: 0.005445
 >> iter 76000, loss: 0.005399
 >> iter 77000, loss: 0.005423
 >> iter 78000, loss: 0.005368
 >> iter 79000, loss: 0.005391
 >> iter 80000, loss: 0.005335
   Number of active neurons: 6
 >> iter 81000, loss: 0.005361
 >> iter 82000, loss: 0.005308
 >> iter 83000, loss: 0.005337
 >> iter 84000, loss: 0.005285
 >> iter 85000, loss: 0.005310
 >> iter 86000, loss: 0.005261
 >> iter 87000, loss: 0.005285
 >> iter 88000, loss: 0.005242
 >> iter 89000, loss: 0.005262
 >> iter 90000, loss: 0.005217
   Number of active neurons: 5
 >> iter 91000, loss: 0.005233
 >> iter 92000, loss: 0.005194
 >> iter 93000, loss: 0.005208
 >> iter 94000, loss: 0.005164
 >> iter 95000, loss: 0.005179
 >> iter 96000, loss: 0.005133
 >> iter 97000, loss: 0.005148
 >> iter 98000, loss: 0.005099
 >> iter 99000, loss: 0.005110
 >> iter 100000, loss: 0.005062
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 10.812338
 >> iter 2000, loss: 3.995026
 >> iter 3000, loss: 1.478265
 >> iter 4000, loss: 0.550544
 >> iter 5000, loss: 0.208605
 >> iter 6000, loss: 0.082070
 >> iter 7000, loss: 0.035357
 >> iter 8000, loss: 0.017728
 >> iter 9000, loss: 0.011225
 >> iter 10000, loss: 0.008503
   Number of active neurons: 8
 >> iter 11000, loss: 0.007540
 >> iter 12000, loss: 0.006891
 >> iter 13000, loss: 0.006710
 >> iter 14000, loss: 0.006384
 >> iter 15000, loss: 0.006423
 >> iter 16000, loss: 0.006104
 >> iter 17000, loss: 0.006188
 >> iter 18000, loss: 0.005912
 >> iter 19000, loss: 0.006005
 >> iter 20000, loss: 0.005757
   Number of active neurons: 7
 >> iter 21000, loss: 0.005852
 >> iter 22000, loss: 0.005630
 >> iter 23000, loss: 0.005730
 >> iter 24000, loss: 0.005532
 >> iter 25000, loss: 0.005638
 >> iter 26000, loss: 0.005459
 >> iter 27000, loss: 0.005571
 >> iter 28000, loss: 0.005406
 >> iter 29000, loss: 0.005514
 >> iter 30000, loss: 0.005356
   Number of active neurons: 7
 >> iter 31000, loss: 0.005445
 >> iter 32000, loss: 0.005282
 >> iter 33000, loss: 0.005357
 >> iter 34000, loss: 0.005209
 >> iter 35000, loss: 0.005274
 >> iter 36000, loss: 0.005141
 >> iter 37000, loss: 0.005206
 >> iter 38000, loss: 0.005083
 >> iter 39000, loss: 0.005141
 >> iter 40000, loss: 0.005030
   Number of active neurons: 7
 >> iter 41000, loss: 0.005077
 >> iter 42000, loss: 0.004975
 >> iter 43000, loss: 0.005025
 >> iter 44000, loss: 0.004935
 >> iter 45000, loss: 0.004982
 >> iter 46000, loss: 0.004891
 >> iter 47000, loss: 0.004938
 >> iter 48000, loss: 0.004846
 >> iter 49000, loss: 0.004893
 >> iter 50000, loss: 0.004803
   Number of active neurons: 7
 >> iter 51000, loss: 0.004849
 >> iter 52000, loss: 0.004774
 >> iter 53000, loss: 0.004816
 >> iter 54000, loss: 0.004754
 >> iter 55000, loss: 0.004796
 >> iter 56000, loss: 0.004736
 >> iter 57000, loss: 0.004774
 >> iter 58000, loss: 0.004720
 >> iter 59000, loss: 0.004762
 >> iter 60000, loss: 0.004712
   Number of active neurons: 7
 >> iter 61000, loss: 0.004762
 >> iter 62000, loss: 0.004711
 >> iter 63000, loss: 0.004761
 >> iter 64000, loss: 0.004715
 >> iter 65000, loss: 0.004758
 >> iter 66000, loss: 0.004713
 >> iter 67000, loss: 0.004757
 >> iter 68000, loss: 0.004719
 >> iter 69000, loss: 0.004755
 >> iter 70000, loss: 0.004720
   Number of active neurons: 7
 >> iter 71000, loss: 0.004754
 >> iter 72000, loss: 0.004720
 >> iter 73000, loss: 0.004759
 >> iter 74000, loss: 0.004722
 >> iter 75000, loss: 0.004758
 >> iter 76000, loss: 0.004722
 >> iter 77000, loss: 0.004757
 >> iter 78000, loss: 0.004721
 >> iter 79000, loss: 0.004756
 >> iter 80000, loss: 0.004717
   Number of active neurons: 7
 >> iter 81000, loss: 0.004754
 >> iter 82000, loss: 0.004713
 >> iter 83000, loss: 0.004752
 >> iter 84000, loss: 0.004711
 >> iter 85000, loss: 0.004747
 >> iter 86000, loss: 0.004708
 >> iter 87000, loss: 0.004745
 >> iter 88000, loss: 0.004714
 >> iter 89000, loss: 0.004745
 >> iter 90000, loss: 0.004713
   Number of active neurons: 7
 >> iter 91000, loss: 0.004742
 >> iter 92000, loss: 0.004716
 >> iter 93000, loss: 0.004745
 >> iter 94000, loss: 0.004715
 >> iter 95000, loss: 0.004746
 >> iter 96000, loss: 0.004714
 >> iter 97000, loss: 0.004745
 >> iter 98000, loss: 0.004712
 >> iter 99000, loss: 0.004744
 >> iter 100000, loss: 0.004714
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.804441
 >> iter 2000, loss: 3.991071
 >> iter 3000, loss: 1.477437
 >> iter 4000, loss: 0.550393
 >> iter 5000, loss: 0.208569
 >> iter 6000, loss: 0.081997
 >> iter 7000, loss: 0.035228
 >> iter 8000, loss: 0.017524
 >> iter 9000, loss: 0.010996
 >> iter 10000, loss: 0.008234
   Number of active neurons: 9
 >> iter 11000, loss: 0.007287
 >> iter 12000, loss: 0.006653
 >> iter 13000, loss: 0.006518
 >> iter 14000, loss: 0.006231
 >> iter 15000, loss: 0.006318
 >> iter 16000, loss: 0.006041
 >> iter 17000, loss: 0.006138
 >> iter 18000, loss: 0.005923
 >> iter 19000, loss: 0.006034
 >> iter 20000, loss: 0.005850
   Number of active neurons: 8
 >> iter 21000, loss: 0.005970
 >> iter 22000, loss: 0.005809
 >> iter 23000, loss: 0.005925
 >> iter 24000, loss: 0.005771
 >> iter 25000, loss: 0.005879
 >> iter 26000, loss: 0.005736
 >> iter 27000, loss: 0.005851
 >> iter 28000, loss: 0.005716
 >> iter 29000, loss: 0.005832
 >> iter 30000, loss: 0.005710
   Number of active neurons: 8
 >> iter 31000, loss: 0.005824
 >> iter 32000, loss: 0.005706
 >> iter 33000, loss: 0.005818
 >> iter 34000, loss: 0.005711
 >> iter 35000, loss: 0.005796
 >> iter 36000, loss: 0.005688
 >> iter 37000, loss: 0.005768
 >> iter 38000, loss: 0.005665
 >> iter 39000, loss: 0.005740
 >> iter 40000, loss: 0.005652
   Number of active neurons: 7
 >> iter 41000, loss: 0.005714
 >> iter 42000, loss: 0.005622
 >> iter 43000, loss: 0.005683
 >> iter 44000, loss: 0.005601
 >> iter 45000, loss: 0.005658
 >> iter 46000, loss: 0.005573
 >> iter 47000, loss: 0.005632
 >> iter 48000, loss: 0.005544
 >> iter 49000, loss: 0.005602
 >> iter 50000, loss: 0.005511
   Number of active neurons: 7
 >> iter 51000, loss: 0.005567
 >> iter 52000, loss: 0.005486
 >> iter 53000, loss: 0.005532
 >> iter 54000, loss: 0.005461
 >> iter 55000, loss: 0.005504
 >> iter 56000, loss: 0.005431
 >> iter 57000, loss: 0.005470
 >> iter 58000, loss: 0.005399
 >> iter 59000, loss: 0.005439
 >> iter 60000, loss: 0.005370
   Number of active neurons: 6
 >> iter 61000, loss: 0.005416
 >> iter 62000, loss: 0.005341
 >> iter 63000, loss: 0.005379
 >> iter 64000, loss: 0.005309
 >> iter 65000, loss: 0.005344
 >> iter 66000, loss: 0.005276
 >> iter 67000, loss: 0.005306
 >> iter 68000, loss: 0.005243
 >> iter 69000, loss: 0.005267
 >> iter 70000, loss: 0.005210
   Number of active neurons: 6
 >> iter 71000, loss: 0.005232
 >> iter 72000, loss: 0.005177
 >> iter 73000, loss: 0.005206
 >> iter 74000, loss: 0.005150
 >> iter 75000, loss: 0.005176
 >> iter 76000, loss: 0.005122
 >> iter 77000, loss: 0.005146
 >> iter 78000, loss: 0.005090
 >> iter 79000, loss: 0.005114
 >> iter 80000, loss: 0.005055
   Number of active neurons: 5
 >> iter 81000, loss: 0.005079
 >> iter 82000, loss: 0.005021
 >> iter 83000, loss: 0.005047
 >> iter 84000, loss: 0.004989
 >> iter 85000, loss: 0.005012
 >> iter 86000, loss: 0.004954
 >> iter 87000, loss: 0.004968
 >> iter 88000, loss: 0.004911
 >> iter 89000, loss: 0.004924
 >> iter 90000, loss: 0.004870
   Number of active neurons: 5
 >> iter 91000, loss: 0.004884
 >> iter 92000, loss: 0.004839
 >> iter 93000, loss: 0.004855
 >> iter 94000, loss: 0.004808
 >> iter 95000, loss: 0.004826
 >> iter 96000, loss: 0.004778
 >> iter 97000, loss: 0.004796
 >> iter 98000, loss: 0.004748
 >> iter 99000, loss: 0.004767
 >> iter 100000, loss: 0.004721
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455157
   Number of active neurons: 0
 >> iter 1000, loss: 10.792101
 >> iter 2000, loss: 3.988241
 >> iter 3000, loss: 1.476186
 >> iter 4000, loss: 0.550006
 >> iter 5000, loss: 0.208505
 >> iter 6000, loss: 0.082066
 >> iter 7000, loss: 0.035295
 >> iter 8000, loss: 0.017594
 >> iter 9000, loss: 0.010993
 >> iter 10000, loss: 0.008191
   Number of active neurons: 7
 >> iter 11000, loss: 0.007166
 >> iter 12000, loss: 0.006491
 >> iter 13000, loss: 0.006295
 >> iter 14000, loss: 0.005960
 >> iter 15000, loss: 0.005955
 >> iter 16000, loss: 0.005660
 >> iter 17000, loss: 0.005713
 >> iter 18000, loss: 0.005485
 >> iter 19000, loss: 0.005575
 >> iter 20000, loss: 0.005384
   Number of active neurons: 7
 >> iter 21000, loss: 0.005484
 >> iter 22000, loss: 0.005310
 >> iter 23000, loss: 0.005399
 >> iter 24000, loss: 0.005221
 >> iter 25000, loss: 0.005307
 >> iter 26000, loss: 0.005146
 >> iter 27000, loss: 0.005242
 >> iter 28000, loss: 0.005090
 >> iter 29000, loss: 0.005180
 >> iter 30000, loss: 0.005027
   Number of active neurons: 7
 >> iter 31000, loss: 0.005102
 >> iter 32000, loss: 0.004948
 >> iter 33000, loss: 0.005022
 >> iter 34000, loss: 0.004887
 >> iter 35000, loss: 0.004952
 >> iter 36000, loss: 0.004831
 >> iter 37000, loss: 0.004895
 >> iter 38000, loss: 0.004783
 >> iter 39000, loss: 0.004842
 >> iter 40000, loss: 0.004749
   Number of active neurons: 6
 >> iter 41000, loss: 0.004801
 >> iter 42000, loss: 0.004712
 >> iter 43000, loss: 0.004765
 >> iter 44000, loss: 0.004692
 >> iter 45000, loss: 0.004743
 >> iter 46000, loss: 0.004670
 >> iter 47000, loss: 0.004725
 >> iter 48000, loss: 0.004655
 >> iter 49000, loss: 0.004714
 >> iter 50000, loss: 0.004644
   Number of active neurons: 6
 >> iter 51000, loss: 0.004700
 >> iter 52000, loss: 0.004638
 >> iter 53000, loss: 0.004686
 >> iter 54000, loss: 0.004631
 >> iter 55000, loss: 0.004675
 >> iter 56000, loss: 0.004619
 >> iter 57000, loss: 0.004659
 >> iter 58000, loss: 0.004605
 >> iter 59000, loss: 0.004645
 >> iter 60000, loss: 0.004590
   Number of active neurons: 6
 >> iter 61000, loss: 0.004635
 >> iter 62000, loss: 0.004573
 >> iter 63000, loss: 0.004611
 >> iter 64000, loss: 0.004550
 >> iter 65000, loss: 0.004579
 >> iter 66000, loss: 0.004519
 >> iter 67000, loss: 0.004547
 >> iter 68000, loss: 0.004494
 >> iter 69000, loss: 0.004517
 >> iter 70000, loss: 0.004469
   Number of active neurons: 6
 >> iter 71000, loss: 0.004490
 >> iter 72000, loss: 0.004445
 >> iter 73000, loss: 0.004472
 >> iter 74000, loss: 0.004426
 >> iter 75000, loss: 0.004452
 >> iter 76000, loss: 0.004407
 >> iter 77000, loss: 0.004432
 >> iter 78000, loss: 0.004387
 >> iter 79000, loss: 0.004412
 >> iter 80000, loss: 0.004365
   Number of active neurons: 6
 >> iter 81000, loss: 0.004392
 >> iter 82000, loss: 0.004345
 >> iter 83000, loss: 0.004373
 >> iter 84000, loss: 0.004326
 >> iter 85000, loss: 0.004351
 >> iter 86000, loss: 0.004305
 >> iter 87000, loss: 0.004329
 >> iter 88000, loss: 0.004292
 >> iter 89000, loss: 0.004312
 >> iter 90000, loss: 0.004276
   Number of active neurons: 6
 >> iter 91000, loss: 0.004297
 >> iter 92000, loss: 0.004267
 >> iter 93000, loss: 0.004289
 >> iter 94000, loss: 0.004257
 >> iter 95000, loss: 0.004282
 >> iter 96000, loss: 0.004250
 >> iter 97000, loss: 0.004274
 >> iter 98000, loss: 0.004243
 >> iter 99000, loss: 0.004269
 >> iter 100000, loss: 0.004240
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.908083
 >> iter 2000, loss: 4.029614
 >> iter 3000, loss: 1.491877
 >> iter 4000, loss: 0.555784
 >> iter 5000, loss: 0.210673
 >> iter 6000, loss: 0.082799
 >> iter 7000, loss: 0.035573
 >> iter 8000, loss: 0.017686
 >> iter 9000, loss: 0.011081
 >> iter 10000, loss: 0.008291
   Number of active neurons: 7
 >> iter 11000, loss: 0.007317
 >> iter 12000, loss: 0.006665
 >> iter 13000, loss: 0.006531
 >> iter 14000, loss: 0.006225
 >> iter 15000, loss: 0.006279
 >> iter 16000, loss: 0.006012
 >> iter 17000, loss: 0.006107
 >> iter 18000, loss: 0.005878
 >> iter 19000, loss: 0.005985
 >> iter 20000, loss: 0.005780
   Number of active neurons: 7
 >> iter 21000, loss: 0.005871
 >> iter 22000, loss: 0.005678
 >> iter 23000, loss: 0.005765
 >> iter 24000, loss: 0.005591
 >> iter 25000, loss: 0.005691
 >> iter 26000, loss: 0.005535
 >> iter 27000, loss: 0.005642
 >> iter 28000, loss: 0.005492
 >> iter 29000, loss: 0.005587
 >> iter 30000, loss: 0.005439
   Number of active neurons: 7
 >> iter 31000, loss: 0.005530
 >> iter 32000, loss: 0.005392
 >> iter 33000, loss: 0.005489
 >> iter 34000, loss: 0.005371
 >> iter 35000, loss: 0.005460
 >> iter 36000, loss: 0.005349
 >> iter 37000, loss: 0.005436
 >> iter 38000, loss: 0.005327
 >> iter 39000, loss: 0.005406
 >> iter 40000, loss: 0.005311
   Number of active neurons: 6
 >> iter 41000, loss: 0.005375
 >> iter 42000, loss: 0.005278
 >> iter 43000, loss: 0.005344
 >> iter 44000, loss: 0.005257
 >> iter 45000, loss: 0.005319
 >> iter 46000, loss: 0.005229
 >> iter 47000, loss: 0.005291
 >> iter 48000, loss: 0.005200
 >> iter 49000, loss: 0.005263
 >> iter 50000, loss: 0.005170
   Number of active neurons: 5
 >> iter 51000, loss: 0.005224
 >> iter 52000, loss: 0.005139
 >> iter 53000, loss: 0.005181
 >> iter 54000, loss: 0.005106
 >> iter 55000, loss: 0.005145
 >> iter 56000, loss: 0.005074
 >> iter 57000, loss: 0.005114
 >> iter 58000, loss: 0.005049
 >> iter 59000, loss: 0.005091
 >> iter 60000, loss: 0.005030
   Number of active neurons: 5
 >> iter 61000, loss: 0.005076
 >> iter 62000, loss: 0.005010
 >> iter 63000, loss: 0.005051
 >> iter 64000, loss: 0.004991
 >> iter 65000, loss: 0.005026
 >> iter 66000, loss: 0.004967
 >> iter 67000, loss: 0.004997
 >> iter 68000, loss: 0.004940
 >> iter 69000, loss: 0.004960
 >> iter 70000, loss: 0.004904
   Number of active neurons: 5
 >> iter 71000, loss: 0.004916
 >> iter 72000, loss: 0.004856
 >> iter 73000, loss: 0.004870
 >> iter 74000, loss: 0.004808
 >> iter 75000, loss: 0.004819
 >> iter 76000, loss: 0.004761
 >> iter 77000, loss: 0.004773
 >> iter 78000, loss: 0.004718
 >> iter 79000, loss: 0.004733
 >> iter 80000, loss: 0.004679
   Number of active neurons: 5
 >> iter 81000, loss: 0.004697
 >> iter 82000, loss: 0.004644
 >> iter 83000, loss: 0.004663
 >> iter 84000, loss: 0.004611
 >> iter 85000, loss: 0.004626
 >> iter 86000, loss: 0.004576
 >> iter 87000, loss: 0.004589
 >> iter 88000, loss: 0.004545
 >> iter 89000, loss: 0.004554
 >> iter 90000, loss: 0.004509
   Number of active neurons: 5
 >> iter 91000, loss: 0.004518
 >> iter 92000, loss: 0.004480
 >> iter 93000, loss: 0.004489
 >> iter 94000, loss: 0.004449
 >> iter 95000, loss: 0.004462
 >> iter 96000, loss: 0.004423
 >> iter 97000, loss: 0.004438
 >> iter 98000, loss: 0.004401
 >> iter 99000, loss: 0.004419
 >> iter 100000, loss: 0.004387
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.818899
 >> iter 2000, loss: 3.996344
 >> iter 3000, loss: 1.479349
 >> iter 4000, loss: 0.551000
 >> iter 5000, loss: 0.208695
 >> iter 6000, loss: 0.081908
 >> iter 7000, loss: 0.035034
 >> iter 8000, loss: 0.017304
 >> iter 9000, loss: 0.010736
 >> iter 10000, loss: 0.008001
   Number of active neurons: 9
 >> iter 11000, loss: 0.007038
 >> iter 12000, loss: 0.006450
 >> iter 13000, loss: 0.006321
 >> iter 14000, loss: 0.006076
 >> iter 15000, loss: 0.006111
 >> iter 16000, loss: 0.005915
 >> iter 17000, loss: 0.005986
 >> iter 18000, loss: 0.005828
 >> iter 19000, loss: 0.005913
 >> iter 20000, loss: 0.005764
   Number of active neurons: 6
 >> iter 21000, loss: 0.005840
 >> iter 22000, loss: 0.005715
 >> iter 23000, loss: 0.005807
 >> iter 24000, loss: 0.005696
 >> iter 25000, loss: 0.005795
 >> iter 26000, loss: 0.005686
 >> iter 27000, loss: 0.005786
 >> iter 28000, loss: 0.005675
 >> iter 29000, loss: 0.005773
 >> iter 30000, loss: 0.005664
   Number of active neurons: 5
 >> iter 31000, loss: 0.005754
 >> iter 32000, loss: 0.005634
 >> iter 33000, loss: 0.005707
 >> iter 34000, loss: 0.005593
 >> iter 35000, loss: 0.005651
 >> iter 36000, loss: 0.005542
 >> iter 37000, loss: 0.005599
 >> iter 38000, loss: 0.005496
 >> iter 39000, loss: 0.005545
 >> iter 40000, loss: 0.005446
   Number of active neurons: 5
 >> iter 41000, loss: 0.005482
 >> iter 42000, loss: 0.005381
 >> iter 43000, loss: 0.005420
 >> iter 44000, loss: 0.005327
 >> iter 45000, loss: 0.005360
 >> iter 46000, loss: 0.005263
 >> iter 47000, loss: 0.005295
 >> iter 48000, loss: 0.005196
 >> iter 49000, loss: 0.005229
 >> iter 50000, loss: 0.005129
   Number of active neurons: 5
 >> iter 51000, loss: 0.005162
 >> iter 52000, loss: 0.005075
 >> iter 53000, loss: 0.005103
 >> iter 54000, loss: 0.005028
 >> iter 55000, loss: 0.005055
 >> iter 56000, loss: 0.004983
 >> iter 57000, loss: 0.005007
 >> iter 58000, loss: 0.004939
 >> iter 59000, loss: 0.004966
 >> iter 60000, loss: 0.004901
   Number of active neurons: 4
 >> iter 61000, loss: 0.004935
 >> iter 62000, loss: 0.004866
 >> iter 63000, loss: 0.004898
 >> iter 64000, loss: 0.004839
 >> iter 65000, loss: 0.004871
 >> iter 66000, loss: 0.004818
 >> iter 67000, loss: 0.004850
 >> iter 68000, loss: 0.004803
 >> iter 69000, loss: 0.004830
 >> iter 70000, loss: 0.004788
   Number of active neurons: 4
 >> iter 71000, loss: 0.004812
 >> iter 72000, loss: 0.004772
 >> iter 73000, loss: 0.004803
 >> iter 74000, loss: 0.004760
 >> iter 75000, loss: 0.004789
 >> iter 76000, loss: 0.004749
 >> iter 77000, loss: 0.004776
 >> iter 78000, loss: 0.004734
 >> iter 79000, loss: 0.004761
 >> iter 80000, loss: 0.004717
   Number of active neurons: 4
 >> iter 81000, loss: 0.004746
 >> iter 82000, loss: 0.004701
 >> iter 83000, loss: 0.004725
 >> iter 84000, loss: 0.004676
 >> iter 85000, loss: 0.004696
 >> iter 86000, loss: 0.004649
 >> iter 87000, loss: 0.004669
 >> iter 88000, loss: 0.004626
 >> iter 89000, loss: 0.004640
 >> iter 90000, loss: 0.004599
   Number of active neurons: 4
 >> iter 91000, loss: 0.004613
 >> iter 92000, loss: 0.004580
 >> iter 93000, loss: 0.004594
 >> iter 94000, loss: 0.004560
 >> iter 95000, loss: 0.004577
 >> iter 96000, loss: 0.004542
 >> iter 97000, loss: 0.004559
 >> iter 98000, loss: 0.004524
 >> iter 99000, loss: 0.004543
 >> iter 100000, loss: 0.004510
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.855040
 >> iter 2000, loss: 4.011311
 >> iter 3000, loss: 1.485795
 >> iter 4000, loss: 0.554208
 >> iter 5000, loss: 0.210515
 >> iter 6000, loss: 0.083197
 >> iter 7000, loss: 0.036028
 >> iter 8000, loss: 0.018185
 >> iter 9000, loss: 0.011501
 >> iter 10000, loss: 0.008703
   Number of active neurons: 7
 >> iter 11000, loss: 0.007648
 >> iter 12000, loss: 0.006992
 >> iter 13000, loss: 0.006772
 >> iter 14000, loss: 0.006454
 >> iter 15000, loss: 0.006404
 >> iter 16000, loss: 0.006147
 >> iter 17000, loss: 0.006141
 >> iter 18000, loss: 0.005918
 >> iter 19000, loss: 0.005942
 >> iter 20000, loss: 0.005741
   Number of active neurons: 7
 >> iter 21000, loss: 0.005773
 >> iter 22000, loss: 0.005583
 >> iter 23000, loss: 0.005621
 >> iter 24000, loss: 0.005440
 >> iter 25000, loss: 0.005478
 >> iter 26000, loss: 0.005308
 >> iter 27000, loss: 0.005365
 >> iter 28000, loss: 0.005212
 >> iter 29000, loss: 0.005275
 >> iter 30000, loss: 0.005139
   Number of active neurons: 7
 >> iter 31000, loss: 0.005214
 >> iter 32000, loss: 0.005087
 >> iter 33000, loss: 0.005166
 >> iter 34000, loss: 0.005058
 >> iter 35000, loss: 0.005133
 >> iter 36000, loss: 0.005038
 >> iter 37000, loss: 0.005119
 >> iter 38000, loss: 0.005027
 >> iter 39000, loss: 0.005104
 >> iter 40000, loss: 0.005025
   Number of active neurons: 6
 >> iter 41000, loss: 0.005090
 >> iter 42000, loss: 0.005006
 >> iter 43000, loss: 0.005075
 >> iter 44000, loss: 0.005002
 >> iter 45000, loss: 0.005069
 >> iter 46000, loss: 0.004993
 >> iter 47000, loss: 0.005060
 >> iter 48000, loss: 0.004980
 >> iter 49000, loss: 0.005041
 >> iter 50000, loss: 0.004950
   Number of active neurons: 6
 >> iter 51000, loss: 0.005002
 >> iter 52000, loss: 0.004920
 >> iter 53000, loss: 0.004963
 >> iter 54000, loss: 0.004893
 >> iter 55000, loss: 0.004931
 >> iter 56000, loss: 0.004865
 >> iter 57000, loss: 0.004900
 >> iter 58000, loss: 0.004837
 >> iter 59000, loss: 0.004869
 >> iter 60000, loss: 0.004808
   Number of active neurons: 6
 >> iter 61000, loss: 0.004848
 >> iter 62000, loss: 0.004783
 >> iter 63000, loss: 0.004819
 >> iter 64000, loss: 0.004762
 >> iter 65000, loss: 0.004795
 >> iter 66000, loss: 0.004738
 >> iter 67000, loss: 0.004765
 >> iter 68000, loss: 0.004713
 >> iter 69000, loss: 0.004733
 >> iter 70000, loss: 0.004683
   Number of active neurons: 5
 >> iter 71000, loss: 0.004701
 >> iter 72000, loss: 0.004657
 >> iter 73000, loss: 0.004682
 >> iter 74000, loss: 0.004637
 >> iter 75000, loss: 0.004657
 >> iter 76000, loss: 0.004608
 >> iter 77000, loss: 0.004626
 >> iter 78000, loss: 0.004580
 >> iter 79000, loss: 0.004601
 >> iter 80000, loss: 0.004555
   Number of active neurons: 5
 >> iter 81000, loss: 0.004577
 >> iter 82000, loss: 0.004532
 >> iter 83000, loss: 0.004554
 >> iter 84000, loss: 0.004509
 >> iter 85000, loss: 0.004526
 >> iter 86000, loss: 0.004478
 >> iter 87000, loss: 0.004488
 >> iter 88000, loss: 0.004441
 >> iter 89000, loss: 0.004447
 >> iter 90000, loss: 0.004400
   Number of active neurons: 5
 >> iter 91000, loss: 0.004406
 >> iter 92000, loss: 0.004366
 >> iter 93000, loss: 0.004373
 >> iter 94000, loss: 0.004334
 >> iter 95000, loss: 0.004345
 >> iter 96000, loss: 0.004306
 >> iter 97000, loss: 0.004318
 >> iter 98000, loss: 0.004280
 >> iter 99000, loss: 0.004292
 >> iter 100000, loss: 0.004254
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.802625
 >> iter 2000, loss: 3.991131
 >> iter 3000, loss: 1.477010
 >> iter 4000, loss: 0.550139
 >> iter 5000, loss: 0.208392
 >> iter 6000, loss: 0.081894
 >> iter 7000, loss: 0.035094
 >> iter 8000, loss: 0.017415
 >> iter 9000, loss: 0.010822
 >> iter 10000, loss: 0.008073
   Number of active neurons: 7
 >> iter 11000, loss: 0.007061
 >> iter 12000, loss: 0.006433
 >> iter 13000, loss: 0.006252
 >> iter 14000, loss: 0.005964
 >> iter 15000, loss: 0.005968
 >> iter 16000, loss: 0.005704
 >> iter 17000, loss: 0.005737
 >> iter 18000, loss: 0.005484
 >> iter 19000, loss: 0.005526
 >> iter 20000, loss: 0.005303
   Number of active neurons: 7
 >> iter 21000, loss: 0.005359
 >> iter 22000, loss: 0.005169
 >> iter 23000, loss: 0.005252
 >> iter 24000, loss: 0.005089
 >> iter 25000, loss: 0.005184
 >> iter 26000, loss: 0.005040
 >> iter 27000, loss: 0.005149
 >> iter 28000, loss: 0.005020
 >> iter 29000, loss: 0.005134
 >> iter 30000, loss: 0.005010
   Number of active neurons: 7
 >> iter 31000, loss: 0.005117
 >> iter 32000, loss: 0.004995
 >> iter 33000, loss: 0.005102
 >> iter 34000, loss: 0.004995
 >> iter 35000, loss: 0.005092
 >> iter 36000, loss: 0.004991
 >> iter 37000, loss: 0.005085
 >> iter 38000, loss: 0.004988
 >> iter 39000, loss: 0.005077
 >> iter 40000, loss: 0.004993
   Number of active neurons: 7
 >> iter 41000, loss: 0.005070
 >> iter 42000, loss: 0.004984
 >> iter 43000, loss: 0.005062
 >> iter 44000, loss: 0.004985
 >> iter 45000, loss: 0.005056
 >> iter 46000, loss: 0.004977
 >> iter 47000, loss: 0.005049
 >> iter 48000, loss: 0.004969
 >> iter 49000, loss: 0.005042
 >> iter 50000, loss: 0.004961
   Number of active neurons: 6
 >> iter 51000, loss: 0.005031
 >> iter 52000, loss: 0.004958
 >> iter 53000, loss: 0.005018
 >> iter 54000, loss: 0.004954
 >> iter 55000, loss: 0.005011
 >> iter 56000, loss: 0.004944
 >> iter 57000, loss: 0.004999
 >> iter 58000, loss: 0.004932
 >> iter 59000, loss: 0.004982
 >> iter 60000, loss: 0.004915
   Number of active neurons: 6
 >> iter 61000, loss: 0.004972
 >> iter 62000, loss: 0.004898
 >> iter 63000, loss: 0.004951
 >> iter 64000, loss: 0.004882
 >> iter 65000, loss: 0.004932
 >> iter 66000, loss: 0.004866
 >> iter 67000, loss: 0.004913
 >> iter 68000, loss: 0.004854
 >> iter 69000, loss: 0.004892
 >> iter 70000, loss: 0.004833
   Number of active neurons: 6
 >> iter 71000, loss: 0.004863
 >> iter 72000, loss: 0.004802
 >> iter 73000, loss: 0.004839
 >> iter 74000, loss: 0.004777
 >> iter 75000, loss: 0.004813
 >> iter 76000, loss: 0.004755
 >> iter 77000, loss: 0.004786
 >> iter 78000, loss: 0.004722
 >> iter 79000, loss: 0.004752
 >> iter 80000, loss: 0.004686
   Number of active neurons: 6
 >> iter 81000, loss: 0.004716
 >> iter 82000, loss: 0.004648
 >> iter 83000, loss: 0.004675
 >> iter 84000, loss: 0.004610
 >> iter 85000, loss: 0.004634
 >> iter 86000, loss: 0.004574
 >> iter 87000, loss: 0.004599
 >> iter 88000, loss: 0.004550
 >> iter 89000, loss: 0.004569
 >> iter 90000, loss: 0.004514
   Number of active neurons: 6
 >> iter 91000, loss: 0.004530
 >> iter 92000, loss: 0.004484
 >> iter 93000, loss: 0.004502
 >> iter 94000, loss: 0.004455
 >> iter 95000, loss: 0.004476
 >> iter 96000, loss: 0.004428
 >> iter 97000, loss: 0.004449
 >> iter 98000, loss: 0.004401
 >> iter 99000, loss: 0.004420
 >> iter 100000, loss: 0.004371
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.805043
 >> iter 2000, loss: 3.991593
 >> iter 3000, loss: 1.477806
 >> iter 4000, loss: 0.550607
 >> iter 5000, loss: 0.208742
 >> iter 6000, loss: 0.082102
 >> iter 7000, loss: 0.035298
 >> iter 8000, loss: 0.017577
 >> iter 9000, loss: 0.011017
 >> iter 10000, loss: 0.008253
   Number of active neurons: 7
 >> iter 11000, loss: 0.007265
 >> iter 12000, loss: 0.006621
 >> iter 13000, loss: 0.006451
 >> iter 14000, loss: 0.006155
 >> iter 15000, loss: 0.006172
 >> iter 16000, loss: 0.005917
 >> iter 17000, loss: 0.005974
 >> iter 18000, loss: 0.005751
 >> iter 19000, loss: 0.005824
 >> iter 20000, loss: 0.005625
   Number of active neurons: 7
 >> iter 21000, loss: 0.005697
 >> iter 22000, loss: 0.005511
 >> iter 23000, loss: 0.005578
 >> iter 24000, loss: 0.005414
 >> iter 25000, loss: 0.005498
 >> iter 26000, loss: 0.005355
 >> iter 27000, loss: 0.005443
 >> iter 28000, loss: 0.005309
 >> iter 29000, loss: 0.005405
 >> iter 30000, loss: 0.005285
   Number of active neurons: 6
 >> iter 31000, loss: 0.005373
 >> iter 32000, loss: 0.005249
 >> iter 33000, loss: 0.005333
 >> iter 34000, loss: 0.005223
 >> iter 35000, loss: 0.005297
 >> iter 36000, loss: 0.005195
 >> iter 37000, loss: 0.005269
 >> iter 38000, loss: 0.005169
 >> iter 39000, loss: 0.005232
 >> iter 40000, loss: 0.005145
   Number of active neurons: 6
 >> iter 41000, loss: 0.005201
 >> iter 42000, loss: 0.005117
 >> iter 43000, loss: 0.005173
 >> iter 44000, loss: 0.005099
 >> iter 45000, loss: 0.005154
 >> iter 46000, loss: 0.005080
 >> iter 47000, loss: 0.005138
 >> iter 48000, loss: 0.005064
 >> iter 49000, loss: 0.005124
 >> iter 50000, loss: 0.005044
   Number of active neurons: 6
 >> iter 51000, loss: 0.005099
 >> iter 52000, loss: 0.005030
 >> iter 53000, loss: 0.005074
 >> iter 54000, loss: 0.005010
 >> iter 55000, loss: 0.005050
 >> iter 56000, loss: 0.004987
 >> iter 57000, loss: 0.005024
 >> iter 58000, loss: 0.004966
 >> iter 59000, loss: 0.005005
 >> iter 60000, loss: 0.004949
   Number of active neurons: 6
 >> iter 61000, loss: 0.004993
 >> iter 62000, loss: 0.004932
 >> iter 63000, loss: 0.004972
 >> iter 64000, loss: 0.004917
 >> iter 65000, loss: 0.004954
 >> iter 66000, loss: 0.004902
 >> iter 67000, loss: 0.004937
 >> iter 68000, loss: 0.004889
 >> iter 69000, loss: 0.004916
 >> iter 70000, loss: 0.004871
   Number of active neurons: 6
 >> iter 71000, loss: 0.004896
 >> iter 72000, loss: 0.004856
 >> iter 73000, loss: 0.004889
 >> iter 74000, loss: 0.004847
 >> iter 75000, loss: 0.004879
 >> iter 76000, loss: 0.004840
 >> iter 77000, loss: 0.004872
 >> iter 78000, loss: 0.004833
 >> iter 79000, loss: 0.004865
 >> iter 80000, loss: 0.004826
   Number of active neurons: 6
 >> iter 81000, loss: 0.004860
 >> iter 82000, loss: 0.004821
 >> iter 83000, loss: 0.004856
 >> iter 84000, loss: 0.004818
 >> iter 85000, loss: 0.004850
 >> iter 86000, loss: 0.004814
 >> iter 87000, loss: 0.004845
 >> iter 88000, loss: 0.004815
 >> iter 89000, loss: 0.004843
 >> iter 90000, loss: 0.004811
   Number of active neurons: 6
 >> iter 91000, loss: 0.004838
 >> iter 92000, loss: 0.004812
 >> iter 93000, loss: 0.004837
 >> iter 94000, loss: 0.004808
 >> iter 95000, loss: 0.004835
 >> iter 96000, loss: 0.004804
 >> iter 97000, loss: 0.004831
 >> iter 98000, loss: 0.004800
 >> iter 99000, loss: 0.004826
 >> iter 100000, loss: 0.004797
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 10.762311
 >> iter 2000, loss: 3.977195
 >> iter 3000, loss: 1.473298
 >> iter 4000, loss: 0.549574
 >> iter 5000, loss: 0.208772
 >> iter 6000, loss: 0.082452
 >> iter 7000, loss: 0.035636
 >> iter 8000, loss: 0.017884
 >> iter 9000, loss: 0.011210
 >> iter 10000, loss: 0.008387
   Number of active neurons: 8
 >> iter 11000, loss: 0.007303
 >> iter 12000, loss: 0.006618
 >> iter 13000, loss: 0.006373
 >> iter 14000, loss: 0.006042
 >> iter 15000, loss: 0.005975
 >> iter 16000, loss: 0.005716
 >> iter 17000, loss: 0.005698
 >> iter 18000, loss: 0.005480
 >> iter 19000, loss: 0.005485
 >> iter 20000, loss: 0.005308
   Number of active neurons: 8
 >> iter 21000, loss: 0.005343
 >> iter 22000, loss: 0.005189
 >> iter 23000, loss: 0.005234
 >> iter 24000, loss: 0.005098
 >> iter 25000, loss: 0.005160
 >> iter 26000, loss: 0.005035
 >> iter 27000, loss: 0.005096
 >> iter 28000, loss: 0.004974
 >> iter 29000, loss: 0.005044
 >> iter 30000, loss: 0.004938
   Number of active neurons: 6
 >> iter 31000, loss: 0.005016
 >> iter 32000, loss: 0.004917
 >> iter 33000, loss: 0.004997
 >> iter 34000, loss: 0.004910
 >> iter 35000, loss: 0.004978
 >> iter 36000, loss: 0.004887
 >> iter 37000, loss: 0.004941
 >> iter 38000, loss: 0.004851
 >> iter 39000, loss: 0.004903
 >> iter 40000, loss: 0.004826
   Number of active neurons: 6
 >> iter 41000, loss: 0.004871
 >> iter 42000, loss: 0.004794
 >> iter 43000, loss: 0.004842
 >> iter 44000, loss: 0.004771
 >> iter 45000, loss: 0.004815
 >> iter 46000, loss: 0.004741
 >> iter 47000, loss: 0.004786
 >> iter 48000, loss: 0.004710
 >> iter 49000, loss: 0.004758
 >> iter 50000, loss: 0.004681
   Number of active neurons: 6
 >> iter 51000, loss: 0.004727
 >> iter 52000, loss: 0.004660
 >> iter 53000, loss: 0.004701
 >> iter 54000, loss: 0.004642
 >> iter 55000, loss: 0.004679
 >> iter 56000, loss: 0.004624
 >> iter 57000, loss: 0.004659
 >> iter 58000, loss: 0.004608
 >> iter 59000, loss: 0.004644
 >> iter 60000, loss: 0.004595
   Number of active neurons: 6
 >> iter 61000, loss: 0.004636
 >> iter 62000, loss: 0.004581
 >> iter 63000, loss: 0.004618
 >> iter 64000, loss: 0.004568
 >> iter 65000, loss: 0.004601
 >> iter 66000, loss: 0.004553
 >> iter 67000, loss: 0.004584
 >> iter 68000, loss: 0.004540
 >> iter 69000, loss: 0.004564
 >> iter 70000, loss: 0.004525
   Number of active neurons: 6
 >> iter 71000, loss: 0.004549
 >> iter 72000, loss: 0.004513
 >> iter 73000, loss: 0.004544
 >> iter 74000, loss: 0.004506
 >> iter 75000, loss: 0.004536
 >> iter 76000, loss: 0.004501
 >> iter 77000, loss: 0.004531
 >> iter 78000, loss: 0.004495
 >> iter 79000, loss: 0.004526
 >> iter 80000, loss: 0.004490
   Number of active neurons: 6
 >> iter 81000, loss: 0.004522
 >> iter 82000, loss: 0.004487
 >> iter 83000, loss: 0.004519
 >> iter 84000, loss: 0.004486
 >> iter 85000, loss: 0.004515
 >> iter 86000, loss: 0.004483
 >> iter 87000, loss: 0.004513
 >> iter 88000, loss: 0.004486
 >> iter 89000, loss: 0.004513
 >> iter 90000, loss: 0.004485
   Number of active neurons: 6
 >> iter 91000, loss: 0.004511
 >> iter 92000, loss: 0.004489
 >> iter 93000, loss: 0.004513
 >> iter 94000, loss: 0.004489
 >> iter 95000, loss: 0.004516
 >> iter 96000, loss: 0.004490
 >> iter 97000, loss: 0.004516
 >> iter 98000, loss: 0.004490
 >> iter 99000, loss: 0.004517
 >> iter 100000, loss: 0.004494
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.832291
 >> iter 2000, loss: 4.003089
 >> iter 3000, loss: 1.482436
 >> iter 4000, loss: 0.552815
 >> iter 5000, loss: 0.209961
 >> iter 6000, loss: 0.082954
 >> iter 7000, loss: 0.035975
 >> iter 8000, loss: 0.018157
 >> iter 9000, loss: 0.011530
 >> iter 10000, loss: 0.008712
   Number of active neurons: 9
 >> iter 11000, loss: 0.007694
 >> iter 12000, loss: 0.007014
 >> iter 13000, loss: 0.006827
 >> iter 14000, loss: 0.006486
 >> iter 15000, loss: 0.006494
 >> iter 16000, loss: 0.006185
 >> iter 17000, loss: 0.006246
 >> iter 18000, loss: 0.005988
 >> iter 19000, loss: 0.006090
 >> iter 20000, loss: 0.005861
   Number of active neurons: 8
 >> iter 21000, loss: 0.005971
 >> iter 22000, loss: 0.005752
 >> iter 23000, loss: 0.005856
 >> iter 24000, loss: 0.005643
 >> iter 25000, loss: 0.005737
 >> iter 26000, loss: 0.005532
 >> iter 27000, loss: 0.005611
 >> iter 28000, loss: 0.005412
 >> iter 29000, loss: 0.005486
 >> iter 30000, loss: 0.005312
   Number of active neurons: 7
 >> iter 31000, loss: 0.005384
 >> iter 32000, loss: 0.005231
 >> iter 33000, loss: 0.005314
 >> iter 34000, loss: 0.005193
 >> iter 35000, loss: 0.005281
 >> iter 36000, loss: 0.005180
 >> iter 37000, loss: 0.005279
 >> iter 38000, loss: 0.005182
 >> iter 39000, loss: 0.005275
 >> iter 40000, loss: 0.005189
   Number of active neurons: 6
 >> iter 41000, loss: 0.005265
 >> iter 42000, loss: 0.005170
 >> iter 43000, loss: 0.005242
 >> iter 44000, loss: 0.005152
 >> iter 45000, loss: 0.005216
 >> iter 46000, loss: 0.005122
 >> iter 47000, loss: 0.005187
 >> iter 48000, loss: 0.005092
 >> iter 49000, loss: 0.005156
 >> iter 50000, loss: 0.005057
   Number of active neurons: 6
 >> iter 51000, loss: 0.005112
 >> iter 52000, loss: 0.005018
 >> iter 53000, loss: 0.005062
 >> iter 54000, loss: 0.004977
 >> iter 55000, loss: 0.005013
 >> iter 56000, loss: 0.004922
 >> iter 57000, loss: 0.004948
 >> iter 58000, loss: 0.004861
 >> iter 59000, loss: 0.004889
 >> iter 60000, loss: 0.004807
   Number of active neurons: 6
 >> iter 61000, loss: 0.004842
 >> iter 62000, loss: 0.004759
 >> iter 63000, loss: 0.004792
 >> iter 64000, loss: 0.004720
 >> iter 65000, loss: 0.004749
 >> iter 66000, loss: 0.004684
 >> iter 67000, loss: 0.004711
 >> iter 68000, loss: 0.004652
 >> iter 69000, loss: 0.004669
 >> iter 70000, loss: 0.004610
   Number of active neurons: 6
 >> iter 71000, loss: 0.004622
 >> iter 72000, loss: 0.004566
 >> iter 73000, loss: 0.004583
 >> iter 74000, loss: 0.004529
 >> iter 75000, loss: 0.004545
 >> iter 76000, loss: 0.004496
 >> iter 77000, loss: 0.004514
 >> iter 78000, loss: 0.004466
 >> iter 79000, loss: 0.004489
 >> iter 80000, loss: 0.004442
   Number of active neurons: 6
 >> iter 81000, loss: 0.004468
 >> iter 82000, loss: 0.004422
 >> iter 83000, loss: 0.004450
 >> iter 84000, loss: 0.004404
 >> iter 85000, loss: 0.004428
 >> iter 86000, loss: 0.004383
 >> iter 87000, loss: 0.004407
 >> iter 88000, loss: 0.004369
 >> iter 89000, loss: 0.004388
 >> iter 90000, loss: 0.004348
   Number of active neurons: 6
 >> iter 91000, loss: 0.004365
 >> iter 92000, loss: 0.004332
 >> iter 93000, loss: 0.004351
 >> iter 94000, loss: 0.004316
 >> iter 95000, loss: 0.004338
 >> iter 96000, loss: 0.004304
 >> iter 97000, loss: 0.004326
 >> iter 98000, loss: 0.004293
 >> iter 99000, loss: 0.004318
 >> iter 100000, loss: 0.004287
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

