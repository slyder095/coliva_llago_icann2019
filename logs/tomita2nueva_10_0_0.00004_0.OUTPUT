 > Problema: tomita2nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 4e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.847355
 >> iter 2000, loss: 4.011305
 >> iter 3000, loss: 1.488369
 >> iter 4000, loss: 0.557803
 >> iter 5000, loss: 0.214678
 >> iter 6000, loss: 0.087564
 >> iter 7000, loss: 0.040587
 >> iter 8000, loss: 0.022667
 >> iter 9000, loss: 0.016044
 >> iter 10000, loss: 0.013119
   Number of active neurons: 7
 >> iter 11000, loss: 0.012101
 >> iter 12000, loss: 0.011315
 >> iter 13000, loss: 0.011148
 >> iter 14000, loss: 0.010746
 >> iter 15000, loss: 0.010770
 >> iter 16000, loss: 0.010420
 >> iter 17000, loss: 0.010470
 >> iter 18000, loss: 0.010185
 >> iter 19000, loss: 0.010282
 >> iter 20000, loss: 0.010048
   Number of active neurons: 6
 >> iter 21000, loss: 0.010160
 >> iter 22000, loss: 0.009933
 >> iter 23000, loss: 0.010050
 >> iter 24000, loss: 0.009845
 >> iter 25000, loss: 0.009982
 >> iter 26000, loss: 0.009787
 >> iter 27000, loss: 0.009935
 >> iter 28000, loss: 0.009742
 >> iter 29000, loss: 0.009891
 >> iter 30000, loss: 0.009708
   Number of active neurons: 5
 >> iter 31000, loss: 0.009854
 >> iter 32000, loss: 0.009666
 >> iter 33000, loss: 0.009803
 >> iter 34000, loss: 0.009628
 >> iter 35000, loss: 0.009741
 >> iter 36000, loss: 0.009567
 >> iter 37000, loss: 0.009665
 >> iter 38000, loss: 0.009472
 >> iter 39000, loss: 0.009538
 >> iter 40000, loss: 0.009352
   Number of active neurons: 4
 >> iter 41000, loss: 0.009394
 >> iter 42000, loss: 0.009213
 >> iter 43000, loss: 0.009252
 >> iter 44000, loss: 0.009068
 >> iter 45000, loss: 0.009092
 >> iter 46000, loss: 0.008910
 >> iter 47000, loss: 0.008940
 >> iter 48000, loss: 0.008759
 >> iter 49000, loss: 0.008783
 >> iter 50000, loss: 0.008592
   Number of active neurons: 4
 >> iter 51000, loss: 0.008614
 >> iter 52000, loss: 0.008450
 >> iter 53000, loss: 0.008471
 >> iter 54000, loss: 0.008336
 >> iter 55000, loss: 0.008361
 >> iter 56000, loss: 0.008234
 >> iter 57000, loss: 0.008257
 >> iter 58000, loss: 0.008137
 >> iter 59000, loss: 0.008160
 >> iter 60000, loss: 0.008040
   Number of active neurons: 4
 >> iter 61000, loss: 0.008062
 >> iter 62000, loss: 0.007926
 >> iter 63000, loss: 0.007938
 >> iter 64000, loss: 0.007828
 >> iter 65000, loss: 0.007850
 >> iter 66000, loss: 0.007761
 >> iter 67000, loss: 0.007791
 >> iter 68000, loss: 0.007719
 >> iter 69000, loss: 0.007744
 >> iter 70000, loss: 0.007684
   Number of active neurons: 4
 >> iter 71000, loss: 0.007705
 >> iter 72000, loss: 0.007644
 >> iter 73000, loss: 0.007680
 >> iter 74000, loss: 0.007622
 >> iter 75000, loss: 0.007658
 >> iter 76000, loss: 0.007607
 >> iter 77000, loss: 0.007643
 >> iter 78000, loss: 0.007593
 >> iter 79000, loss: 0.007631
 >> iter 80000, loss: 0.007581
   Number of active neurons: 4
 >> iter 81000, loss: 0.007623
 >> iter 82000, loss: 0.007574
 >> iter 83000, loss: 0.007617
 >> iter 84000, loss: 0.007571
 >> iter 85000, loss: 0.007609
 >> iter 86000, loss: 0.007566
 >> iter 87000, loss: 0.007603
 >> iter 88000, loss: 0.007571
 >> iter 89000, loss: 0.007602
 >> iter 90000, loss: 0.007568
   Number of active neurons: 4
 >> iter 91000, loss: 0.007597
 >> iter 92000, loss: 0.007571
 >> iter 93000, loss: 0.007600
 >> iter 94000, loss: 0.007570
 >> iter 95000, loss: 0.007603
 >> iter 96000, loss: 0.007571
 >> iter 97000, loss: 0.007604
 >> iter 98000, loss: 0.007567
 >> iter 99000, loss: 0.007597
 >> iter 100000, loss: 0.007562
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.882879
 >> iter 2000, loss: 4.022743
 >> iter 3000, loss: 1.491868
 >> iter 4000, loss: 0.558485
 >> iter 5000, loss: 0.214498
 >> iter 6000, loss: 0.087100
 >> iter 7000, loss: 0.040107
 >> iter 8000, loss: 0.022251
 >> iter 9000, loss: 0.015714
 >> iter 10000, loss: 0.012898
   Number of active neurons: 7
 >> iter 11000, loss: 0.012005
 >> iter 12000, loss: 0.011341
 >> iter 13000, loss: 0.011248
 >> iter 14000, loss: 0.010924
 >> iter 15000, loss: 0.011052
 >> iter 16000, loss: 0.010782
 >> iter 17000, loss: 0.010954
 >> iter 18000, loss: 0.010695
 >> iter 19000, loss: 0.010825
 >> iter 20000, loss: 0.010564
   Number of active neurons: 6
 >> iter 21000, loss: 0.010668
 >> iter 22000, loss: 0.010392
 >> iter 23000, loss: 0.010481
 >> iter 24000, loss: 0.010226
 >> iter 25000, loss: 0.010327
 >> iter 26000, loss: 0.010103
 >> iter 27000, loss: 0.010227
 >> iter 28000, loss: 0.010007
 >> iter 29000, loss: 0.010141
 >> iter 30000, loss: 0.009936
   Number of active neurons: 6
 >> iter 31000, loss: 0.010075
 >> iter 32000, loss: 0.009866
 >> iter 33000, loss: 0.009999
 >> iter 34000, loss: 0.009805
 >> iter 35000, loss: 0.009921
 >> iter 36000, loss: 0.009742
 >> iter 37000, loss: 0.009865
 >> iter 38000, loss: 0.009699
 >> iter 39000, loss: 0.009818
 >> iter 40000, loss: 0.009676
   Number of active neurons: 5
 >> iter 41000, loss: 0.009780
 >> iter 42000, loss: 0.009634
 >> iter 43000, loss: 0.009739
 >> iter 44000, loss: 0.009606
 >> iter 45000, loss: 0.009702
 >> iter 46000, loss: 0.009560
 >> iter 47000, loss: 0.009656
 >> iter 48000, loss: 0.009507
 >> iter 49000, loss: 0.009595
 >> iter 50000, loss: 0.009420
   Number of active neurons: 5
 >> iter 51000, loss: 0.009484
 >> iter 52000, loss: 0.009315
 >> iter 53000, loss: 0.009358
 >> iter 54000, loss: 0.009214
 >> iter 55000, loss: 0.009260
 >> iter 56000, loss: 0.009122
 >> iter 57000, loss: 0.009164
 >> iter 58000, loss: 0.009032
 >> iter 59000, loss: 0.009071
 >> iter 60000, loss: 0.008938
   Number of active neurons: 4
 >> iter 61000, loss: 0.008980
 >> iter 62000, loss: 0.008823
 >> iter 63000, loss: 0.008831
 >> iter 64000, loss: 0.008666
 >> iter 65000, loss: 0.008651
 >> iter 66000, loss: 0.008501
 >> iter 67000, loss: 0.008495
 >> iter 68000, loss: 0.008370
 >> iter 69000, loss: 0.008351
 >> iter 70000, loss: 0.008243
   Number of active neurons: 4
 >> iter 71000, loss: 0.008229
 >> iter 72000, loss: 0.008138
 >> iter 73000, loss: 0.008139
 >> iter 74000, loss: 0.008051
 >> iter 75000, loss: 0.008050
 >> iter 76000, loss: 0.007968
 >> iter 77000, loss: 0.007962
 >> iter 78000, loss: 0.007879
 >> iter 79000, loss: 0.007871
 >> iter 80000, loss: 0.007782
   Number of active neurons: 4
 >> iter 81000, loss: 0.007774
 >> iter 82000, loss: 0.007691
 >> iter 83000, loss: 0.007695
 >> iter 84000, loss: 0.007626
 >> iter 85000, loss: 0.007632
 >> iter 86000, loss: 0.007575
 >> iter 87000, loss: 0.007586
 >> iter 88000, loss: 0.007546
 >> iter 89000, loss: 0.007555
 >> iter 90000, loss: 0.007517
   Number of active neurons: 4
 >> iter 91000, loss: 0.007524
 >> iter 92000, loss: 0.007497
 >> iter 93000, loss: 0.007509
 >> iter 94000, loss: 0.007477
 >> iter 95000, loss: 0.007493
 >> iter 96000, loss: 0.007462
 >> iter 97000, loss: 0.007478
 >> iter 98000, loss: 0.007444
 >> iter 99000, loss: 0.007458
 >> iter 100000, loss: 0.007426
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455157
   Number of active neurons: 0
 >> iter 1000, loss: 10.776463
 >> iter 2000, loss: 3.983932
 >> iter 3000, loss: 1.477972
 >> iter 4000, loss: 0.553429
 >> iter 5000, loss: 0.212691
 >> iter 6000, loss: 0.086371
 >> iter 7000, loss: 0.039844
 >> iter 8000, loss: 0.022168
 >> iter 9000, loss: 0.015754
 >> iter 10000, loss: 0.012992
   Number of active neurons: 7
 >> iter 11000, loss: 0.012125
 >> iter 12000, loss: 0.011473
 >> iter 13000, loss: 0.011406
 >> iter 14000, loss: 0.011128
 >> iter 15000, loss: 0.011238
 >> iter 16000, loss: 0.010998
 >> iter 17000, loss: 0.011135
 >> iter 18000, loss: 0.010931
 >> iter 19000, loss: 0.011077
 >> iter 20000, loss: 0.010881
   Number of active neurons: 6
 >> iter 21000, loss: 0.011008
 >> iter 22000, loss: 0.010797
 >> iter 23000, loss: 0.010907
 >> iter 24000, loss: 0.010686
 >> iter 25000, loss: 0.010804
 >> iter 26000, loss: 0.010585
 >> iter 27000, loss: 0.010703
 >> iter 28000, loss: 0.010468
 >> iter 29000, loss: 0.010575
 >> iter 30000, loss: 0.010353
   Number of active neurons: 6
 >> iter 31000, loss: 0.010474
 >> iter 32000, loss: 0.010264
 >> iter 33000, loss: 0.010389
 >> iter 34000, loss: 0.010201
 >> iter 35000, loss: 0.010308
 >> iter 36000, loss: 0.010127
 >> iter 37000, loss: 0.010235
 >> iter 38000, loss: 0.010069
 >> iter 39000, loss: 0.010179
 >> iter 40000, loss: 0.010043
   Number of active neurons: 5
 >> iter 41000, loss: 0.010144
 >> iter 42000, loss: 0.010008
 >> iter 43000, loss: 0.010114
 >> iter 44000, loss: 0.009990
 >> iter 45000, loss: 0.010089
 >> iter 46000, loss: 0.009958
 >> iter 47000, loss: 0.010044
 >> iter 48000, loss: 0.009886
 >> iter 49000, loss: 0.009969
 >> iter 50000, loss: 0.009811
   Number of active neurons: 5
 >> iter 51000, loss: 0.009890
 >> iter 52000, loss: 0.009739
 >> iter 53000, loss: 0.009797
 >> iter 54000, loss: 0.009671
 >> iter 55000, loss: 0.009728
 >> iter 56000, loss: 0.009608
 >> iter 57000, loss: 0.009660
 >> iter 58000, loss: 0.009546
 >> iter 59000, loss: 0.009595
 >> iter 60000, loss: 0.009479
   Number of active neurons: 5
 >> iter 61000, loss: 0.009515
 >> iter 62000, loss: 0.009372
 >> iter 63000, loss: 0.009404
 >> iter 64000, loss: 0.009288
 >> iter 65000, loss: 0.009328
 >> iter 66000, loss: 0.009231
 >> iter 67000, loss: 0.009278
 >> iter 68000, loss: 0.009194
 >> iter 69000, loss: 0.009233
 >> iter 70000, loss: 0.009154
   Number of active neurons: 4
 >> iter 71000, loss: 0.009169
 >> iter 72000, loss: 0.009072
 >> iter 73000, loss: 0.009094
 >> iter 74000, loss: 0.008998
 >> iter 75000, loss: 0.009021
 >> iter 76000, loss: 0.008935
 >> iter 77000, loss: 0.008957
 >> iter 78000, loss: 0.008870
 >> iter 79000, loss: 0.008879
 >> iter 80000, loss: 0.008777
   Number of active neurons: 4
 >> iter 81000, loss: 0.008789
 >> iter 82000, loss: 0.008694
 >> iter 83000, loss: 0.008708
 >> iter 84000, loss: 0.008618
 >> iter 85000, loss: 0.008624
 >> iter 86000, loss: 0.008533
 >> iter 87000, loss: 0.008525
 >> iter 88000, loss: 0.008430
 >> iter 89000, loss: 0.008410
 >> iter 90000, loss: 0.008313
   Number of active neurons: 3
 >> iter 91000, loss: 0.008297
 >> iter 92000, loss: 0.008212
 >> iter 93000, loss: 0.008182
 >> iter 94000, loss: 0.008085
 >> iter 95000, loss: 0.008064
 >> iter 96000, loss: 0.007975
 >> iter 97000, loss: 0.007964
 >> iter 98000, loss: 0.007884
 >> iter 99000, loss: 0.007881
 >> iter 100000, loss: 0.007810
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.895886
 >> iter 2000, loss: 4.028513
 >> iter 3000, loss: 1.494565
 >> iter 4000, loss: 0.559835
 >> iter 5000, loss: 0.215155
 >> iter 6000, loss: 0.087372
 >> iter 7000, loss: 0.040215
 >> iter 8000, loss: 0.022308
 >> iter 9000, loss: 0.015831
 >> iter 10000, loss: 0.013075
   Number of active neurons: 7
 >> iter 11000, loss: 0.012272
 >> iter 12000, loss: 0.011678
 >> iter 13000, loss: 0.011670
 >> iter 14000, loss: 0.011400
 >> iter 15000, loss: 0.011529
 >> iter 16000, loss: 0.011246
 >> iter 17000, loss: 0.011365
 >> iter 18000, loss: 0.011100
 >> iter 19000, loss: 0.011219
 >> iter 20000, loss: 0.010951
   Number of active neurons: 6
 >> iter 21000, loss: 0.011043
 >> iter 22000, loss: 0.010777
 >> iter 23000, loss: 0.010874
 >> iter 24000, loss: 0.010631
 >> iter 25000, loss: 0.010751
 >> iter 26000, loss: 0.010523
 >> iter 27000, loss: 0.010657
 >> iter 28000, loss: 0.010433
 >> iter 29000, loss: 0.010551
 >> iter 30000, loss: 0.010313
   Number of active neurons: 5
 >> iter 31000, loss: 0.010421
 >> iter 32000, loss: 0.010193
 >> iter 33000, loss: 0.010306
 >> iter 34000, loss: 0.010104
 >> iter 35000, loss: 0.010201
 >> iter 36000, loss: 0.010008
 >> iter 37000, loss: 0.010098
 >> iter 38000, loss: 0.009905
 >> iter 39000, loss: 0.009977
 >> iter 40000, loss: 0.009799
   Number of active neurons: 5
 >> iter 41000, loss: 0.009843
 >> iter 42000, loss: 0.009654
 >> iter 43000, loss: 0.009698
 >> iter 44000, loss: 0.009530
 >> iter 45000, loss: 0.009582
 >> iter 46000, loss: 0.009421
 >> iter 47000, loss: 0.009480
 >> iter 48000, loss: 0.009320
 >> iter 49000, loss: 0.009392
 >> iter 50000, loss: 0.009233
   Number of active neurons: 4
 >> iter 51000, loss: 0.009301
 >> iter 52000, loss: 0.009154
 >> iter 53000, loss: 0.009203
 >> iter 54000, loss: 0.009073
 >> iter 55000, loss: 0.009123
 >> iter 56000, loss: 0.009003
 >> iter 57000, loss: 0.009054
 >> iter 58000, loss: 0.008944
 >> iter 59000, loss: 0.008982
 >> iter 60000, loss: 0.008855
   Number of active neurons: 4
 >> iter 61000, loss: 0.008896
 >> iter 62000, loss: 0.008760
 >> iter 63000, loss: 0.008780
 >> iter 64000, loss: 0.008652
 >> iter 65000, loss: 0.008672
 >> iter 66000, loss: 0.008552
 >> iter 67000, loss: 0.008561
 >> iter 68000, loss: 0.008452
 >> iter 69000, loss: 0.008456
 >> iter 70000, loss: 0.008361
   Number of active neurons: 4
 >> iter 71000, loss: 0.008366
 >> iter 72000, loss: 0.008279
 >> iter 73000, loss: 0.008295
 >> iter 74000, loss: 0.008204
 >> iter 75000, loss: 0.008213
 >> iter 76000, loss: 0.008125
 >> iter 77000, loss: 0.008128
 >> iter 78000, loss: 0.008036
 >> iter 79000, loss: 0.008044
 >> iter 80000, loss: 0.007960
   Number of active neurons: 4
 >> iter 81000, loss: 0.007981
 >> iter 82000, loss: 0.007909
 >> iter 83000, loss: 0.007938
 >> iter 84000, loss: 0.007876
 >> iter 85000, loss: 0.007904
 >> iter 86000, loss: 0.007849
 >> iter 87000, loss: 0.007881
 >> iter 88000, loss: 0.007839
 >> iter 89000, loss: 0.007868
 >> iter 90000, loss: 0.007826
   Number of active neurons: 4
 >> iter 91000, loss: 0.007854
 >> iter 92000, loss: 0.007818
 >> iter 93000, loss: 0.007842
 >> iter 94000, loss: 0.007800
 >> iter 95000, loss: 0.007829
 >> iter 96000, loss: 0.007787
 >> iter 97000, loss: 0.007819
 >> iter 98000, loss: 0.007779
 >> iter 99000, loss: 0.007815
 >> iter 100000, loss: 0.007780
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 10.813654
 >> iter 2000, loss: 3.996136
 >> iter 3000, loss: 1.481456
 >> iter 4000, loss: 0.554206
 >> iter 5000, loss: 0.212522
 >> iter 6000, loss: 0.085967
 >> iter 7000, loss: 0.039323
 >> iter 8000, loss: 0.021607
 >> iter 9000, loss: 0.015140
 >> iter 10000, loss: 0.012371
   Number of active neurons: 6
 >> iter 11000, loss: 0.011470
 >> iter 12000, loss: 0.010839
 >> iter 13000, loss: 0.010776
 >> iter 14000, loss: 0.010450
 >> iter 15000, loss: 0.010504
 >> iter 16000, loss: 0.010174
 >> iter 17000, loss: 0.010250
 >> iter 18000, loss: 0.009975
 >> iter 19000, loss: 0.010089
 >> iter 20000, loss: 0.009849
   Number of active neurons: 6
 >> iter 21000, loss: 0.009972
 >> iter 22000, loss: 0.009760
 >> iter 23000, loss: 0.009901
 >> iter 24000, loss: 0.009708
 >> iter 25000, loss: 0.009863
 >> iter 26000, loss: 0.009676
 >> iter 27000, loss: 0.009839
 >> iter 28000, loss: 0.009655
 >> iter 29000, loss: 0.009821
 >> iter 30000, loss: 0.009647
   Number of active neurons: 6
 >> iter 31000, loss: 0.009812
 >> iter 32000, loss: 0.009635
 >> iter 33000, loss: 0.009807
 >> iter 34000, loss: 0.009650
 >> iter 35000, loss: 0.009802
 >> iter 36000, loss: 0.009652
 >> iter 37000, loss: 0.009800
 >> iter 38000, loss: 0.009654
 >> iter 39000, loss: 0.009793
 >> iter 40000, loss: 0.009668
   Number of active neurons: 6
 >> iter 41000, loss: 0.009788
 >> iter 42000, loss: 0.009659
 >> iter 43000, loss: 0.009782
 >> iter 44000, loss: 0.009666
 >> iter 45000, loss: 0.009782
 >> iter 46000, loss: 0.009660
 >> iter 47000, loss: 0.009778
 >> iter 48000, loss: 0.009654
 >> iter 49000, loss: 0.009775
 >> iter 50000, loss: 0.009646
   Number of active neurons: 5
 >> iter 51000, loss: 0.009762
 >> iter 52000, loss: 0.009648
 >> iter 53000, loss: 0.009745
 >> iter 54000, loss: 0.009644
 >> iter 55000, loss: 0.009734
 >> iter 56000, loss: 0.009630
 >> iter 57000, loss: 0.009709
 >> iter 58000, loss: 0.009608
 >> iter 59000, loss: 0.009683
 >> iter 60000, loss: 0.009581
   Number of active neurons: 5
 >> iter 61000, loss: 0.009649
 >> iter 62000, loss: 0.009510
 >> iter 63000, loss: 0.009559
 >> iter 64000, loss: 0.009434
 >> iter 65000, loss: 0.009459
 >> iter 66000, loss: 0.009319
 >> iter 67000, loss: 0.009330
 >> iter 68000, loss: 0.009217
 >> iter 69000, loss: 0.009225
 >> iter 70000, loss: 0.009129
   Number of active neurons: 5
 >> iter 71000, loss: 0.009136
 >> iter 72000, loss: 0.009049
 >> iter 73000, loss: 0.009066
 >> iter 74000, loss: 0.008973
 >> iter 75000, loss: 0.008983
 >> iter 76000, loss: 0.008891
 >> iter 77000, loss: 0.008897
 >> iter 78000, loss: 0.008811
 >> iter 79000, loss: 0.008824
 >> iter 80000, loss: 0.008736
   Number of active neurons: 4
 >> iter 81000, loss: 0.008757
 >> iter 82000, loss: 0.008677
 >> iter 83000, loss: 0.008705
 >> iter 84000, loss: 0.008626
 >> iter 85000, loss: 0.008627
 >> iter 86000, loss: 0.008532
 >> iter 87000, loss: 0.008531
 >> iter 88000, loss: 0.008455
 >> iter 89000, loss: 0.008455
 >> iter 90000, loss: 0.008380
   Number of active neurons: 4
 >> iter 91000, loss: 0.008366
 >> iter 92000, loss: 0.008292
 >> iter 93000, loss: 0.008282
 >> iter 94000, loss: 0.008212
 >> iter 95000, loss: 0.008209
 >> iter 96000, loss: 0.008135
 >> iter 97000, loss: 0.008125
 >> iter 98000, loss: 0.008048
 >> iter 99000, loss: 0.008040
 >> iter 100000, loss: 0.007967
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.862191
 >> iter 2000, loss: 4.015537
 >> iter 3000, loss: 1.489610
 >> iter 4000, loss: 0.557730
 >> iter 5000, loss: 0.214283
 >> iter 6000, loss: 0.086973
 >> iter 7000, loss: 0.040074
 >> iter 8000, loss: 0.022243
 >> iter 9000, loss: 0.015774
 >> iter 10000, loss: 0.012942
   Number of active neurons: 5
 >> iter 11000, loss: 0.012035
 >> iter 12000, loss: 0.011351
 >> iter 13000, loss: 0.011268
 >> iter 14000, loss: 0.010955
 >> iter 15000, loss: 0.011061
 >> iter 16000, loss: 0.010794
 >> iter 17000, loss: 0.010886
 >> iter 18000, loss: 0.010600
 >> iter 19000, loss: 0.010653
 >> iter 20000, loss: 0.010357
   Number of active neurons: 3
 >> iter 21000, loss: 0.010386
 >> iter 22000, loss: 0.010079
 >> iter 23000, loss: 0.010088
 >> iter 24000, loss: 0.009775
 >> iter 25000, loss: 0.009771
 >> iter 26000, loss: 0.009461
 >> iter 27000, loss: 0.009460
 >> iter 28000, loss: 0.009141
 >> iter 29000, loss: 0.009141
 >> iter 30000, loss: 0.008863
   Number of active neurons: 3
 >> iter 31000, loss: 0.008886
 >> iter 32000, loss: 0.008631
 >> iter 33000, loss: 0.008663
 >> iter 34000, loss: 0.008439
 >> iter 35000, loss: 0.008472
 >> iter 36000, loss: 0.008273
 >> iter 37000, loss: 0.008314
 >> iter 38000, loss: 0.008126
 >> iter 39000, loss: 0.008169
 >> iter 40000, loss: 0.008018
   Number of active neurons: 3
 >> iter 41000, loss: 0.008066
 >> iter 42000, loss: 0.007928
 >> iter 43000, loss: 0.007991
 >> iter 44000, loss: 0.007876
 >> iter 45000, loss: 0.007941
 >> iter 46000, loss: 0.007829
 >> iter 47000, loss: 0.007902
 >> iter 48000, loss: 0.007793
 >> iter 49000, loss: 0.007873
 >> iter 50000, loss: 0.007765
   Number of active neurons: 3
 >> iter 51000, loss: 0.007843
 >> iter 52000, loss: 0.007749
 >> iter 53000, loss: 0.007817
 >> iter 54000, loss: 0.007737
 >> iter 55000, loss: 0.007802
 >> iter 56000, loss: 0.007723
 >> iter 57000, loss: 0.007784
 >> iter 58000, loss: 0.007705
 >> iter 59000, loss: 0.007745
 >> iter 60000, loss: 0.007659
   Number of active neurons: 3
 >> iter 61000, loss: 0.007708
 >> iter 62000, loss: 0.007622
 >> iter 63000, loss: 0.007670
 >> iter 64000, loss: 0.007599
 >> iter 65000, loss: 0.007645
 >> iter 66000, loss: 0.007583
 >> iter 67000, loss: 0.007629
 >> iter 68000, loss: 0.007575
 >> iter 69000, loss: 0.007606
 >> iter 70000, loss: 0.007554
   Number of active neurons: 3
 >> iter 71000, loss: 0.007586
 >> iter 72000, loss: 0.007541
 >> iter 73000, loss: 0.007586
 >> iter 74000, loss: 0.007539
 >> iter 75000, loss: 0.007581
 >> iter 76000, loss: 0.007538
 >> iter 77000, loss: 0.007578
 >> iter 78000, loss: 0.007536
 >> iter 79000, loss: 0.007577
 >> iter 80000, loss: 0.007532
   Number of active neurons: 3
 >> iter 81000, loss: 0.007577
 >> iter 82000, loss: 0.007533
 >> iter 83000, loss: 0.007578
 >> iter 84000, loss: 0.007536
 >> iter 85000, loss: 0.007575
 >> iter 86000, loss: 0.007536
 >> iter 87000, loss: 0.007573
 >> iter 88000, loss: 0.007545
 >> iter 89000, loss: 0.007577
 >> iter 90000, loss: 0.007545
   Number of active neurons: 3
 >> iter 91000, loss: 0.007575
 >> iter 92000, loss: 0.007551
 >> iter 93000, loss: 0.007581
 >> iter 94000, loss: 0.007554
 >> iter 95000, loss: 0.007587
 >> iter 96000, loss: 0.007556
 >> iter 97000, loss: 0.007590
 >> iter 98000, loss: 0.007556
 >> iter 99000, loss: 0.007586
 >> iter 100000, loss: 0.007553
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.861220
 >> iter 2000, loss: 4.016163
 >> iter 3000, loss: 1.489488
 >> iter 4000, loss: 0.557638
 >> iter 5000, loss: 0.214233
 >> iter 6000, loss: 0.086943
 >> iter 7000, loss: 0.040096
 >> iter 8000, loss: 0.022294
 >> iter 9000, loss: 0.015874
 >> iter 10000, loss: 0.013070
   Number of active neurons: 7
 >> iter 11000, loss: 0.012244
 >> iter 12000, loss: 0.011591
 >> iter 13000, loss: 0.011506
 >> iter 14000, loss: 0.011191
 >> iter 15000, loss: 0.011391
 >> iter 16000, loss: 0.011092
 >> iter 17000, loss: 0.011335
 >> iter 18000, loss: 0.011070
 >> iter 19000, loss: 0.011316
 >> iter 20000, loss: 0.011060
   Number of active neurons: 6
 >> iter 21000, loss: 0.011286
 >> iter 22000, loss: 0.011029
 >> iter 23000, loss: 0.011243
 >> iter 24000, loss: 0.010974
 >> iter 25000, loss: 0.011171
 >> iter 26000, loss: 0.010894
 >> iter 27000, loss: 0.011091
 >> iter 28000, loss: 0.010817
 >> iter 29000, loss: 0.011009
 >> iter 30000, loss: 0.010741
   Number of active neurons: 6
 >> iter 31000, loss: 0.010909
 >> iter 32000, loss: 0.010621
 >> iter 33000, loss: 0.010772
 >> iter 34000, loss: 0.010483
 >> iter 35000, loss: 0.010581
 >> iter 36000, loss: 0.010299
 >> iter 37000, loss: 0.010387
 >> iter 38000, loss: 0.010109
 >> iter 39000, loss: 0.010176
 >> iter 40000, loss: 0.009940
   Number of active neurons: 5
 >> iter 41000, loss: 0.010001
 >> iter 42000, loss: 0.009777
 >> iter 43000, loss: 0.009835
 >> iter 44000, loss: 0.009646
 >> iter 45000, loss: 0.009721
 >> iter 46000, loss: 0.009554
 >> iter 47000, loss: 0.009639
 >> iter 48000, loss: 0.009467
 >> iter 49000, loss: 0.009538
 >> iter 50000, loss: 0.009361
   Number of active neurons: 5
 >> iter 51000, loss: 0.009429
 >> iter 52000, loss: 0.009273
 >> iter 53000, loss: 0.009329
 >> iter 54000, loss: 0.009200
 >> iter 55000, loss: 0.009259
 >> iter 56000, loss: 0.009134
 >> iter 57000, loss: 0.009188
 >> iter 58000, loss: 0.009068
 >> iter 59000, loss: 0.009121
 >> iter 60000, loss: 0.009001
   Number of active neurons: 5
 >> iter 61000, loss: 0.009061
 >> iter 62000, loss: 0.008928
 >> iter 63000, loss: 0.008982
 >> iter 64000, loss: 0.008868
 >> iter 65000, loss: 0.008927
 >> iter 66000, loss: 0.008822
 >> iter 67000, loss: 0.008859
 >> iter 68000, loss: 0.008765
 >> iter 69000, loss: 0.008793
 >> iter 70000, loss: 0.008718
   Number of active neurons: 5
 >> iter 71000, loss: 0.008747
 >> iter 72000, loss: 0.008684
 >> iter 73000, loss: 0.008727
 >> iter 74000, loss: 0.008665
 >> iter 75000, loss: 0.008705
 >> iter 76000, loss: 0.008651
 >> iter 77000, loss: 0.008688
 >> iter 78000, loss: 0.008635
 >> iter 79000, loss: 0.008674
 >> iter 80000, loss: 0.008619
   Number of active neurons: 5
 >> iter 81000, loss: 0.008661
 >> iter 82000, loss: 0.008608
 >> iter 83000, loss: 0.008651
 >> iter 84000, loss: 0.008599
 >> iter 85000, loss: 0.008635
 >> iter 86000, loss: 0.008586
 >> iter 87000, loss: 0.008619
 >> iter 88000, loss: 0.008583
 >> iter 89000, loss: 0.008607
 >> iter 90000, loss: 0.008566
   Number of active neurons: 4
 >> iter 91000, loss: 0.008586
 >> iter 92000, loss: 0.008552
 >> iter 93000, loss: 0.008571
 >> iter 94000, loss: 0.008530
 >> iter 95000, loss: 0.008549
 >> iter 96000, loss: 0.008499
 >> iter 97000, loss: 0.008496
 >> iter 98000, loss: 0.008421
 >> iter 99000, loss: 0.008415
 >> iter 100000, loss: 0.008342
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 10.904389
 >> iter 2000, loss: 4.033315
 >> iter 3000, loss: 1.496398
 >> iter 4000, loss: 0.560325
 >> iter 5000, loss: 0.215069
 >> iter 6000, loss: 0.087073
 >> iter 7000, loss: 0.039806
 >> iter 8000, loss: 0.021862
 >> iter 9000, loss: 0.015290
 >> iter 10000, loss: 0.012469
   Number of active neurons: 5
 >> iter 11000, loss: 0.011532
 >> iter 12000, loss: 0.010823
 >> iter 13000, loss: 0.010696
 >> iter 14000, loss: 0.010335
 >> iter 15000, loss: 0.010409
 >> iter 16000, loss: 0.010096
 >> iter 17000, loss: 0.010210
 >> iter 18000, loss: 0.009948
 >> iter 19000, loss: 0.010083
 >> iter 20000, loss: 0.009842
   Number of active neurons: 6
 >> iter 21000, loss: 0.009978
 >> iter 22000, loss: 0.009738
 >> iter 23000, loss: 0.009859
 >> iter 24000, loss: 0.009614
 >> iter 25000, loss: 0.009741
 >> iter 26000, loss: 0.009508
 >> iter 27000, loss: 0.009646
 >> iter 28000, loss: 0.009419
 >> iter 29000, loss: 0.009554
 >> iter 30000, loss: 0.009320
   Number of active neurons: 6
 >> iter 31000, loss: 0.009437
 >> iter 32000, loss: 0.009218
 >> iter 33000, loss: 0.009331
 >> iter 34000, loss: 0.009130
 >> iter 35000, loss: 0.009227
 >> iter 36000, loss: 0.009045
 >> iter 37000, loss: 0.009150
 >> iter 38000, loss: 0.008985
 >> iter 39000, loss: 0.009082
 >> iter 40000, loss: 0.008936
   Number of active neurons: 5
 >> iter 41000, loss: 0.009020
 >> iter 42000, loss: 0.008884
 >> iter 43000, loss: 0.008977
 >> iter 44000, loss: 0.008859
 >> iter 45000, loss: 0.008951
 >> iter 46000, loss: 0.008838
 >> iter 47000, loss: 0.008941
 >> iter 48000, loss: 0.008822
 >> iter 49000, loss: 0.008903
 >> iter 50000, loss: 0.008751
   Number of active neurons: 5
 >> iter 51000, loss: 0.008819
 >> iter 52000, loss: 0.008692
 >> iter 53000, loss: 0.008753
 >> iter 54000, loss: 0.008645
 >> iter 55000, loss: 0.008701
 >> iter 56000, loss: 0.008584
 >> iter 57000, loss: 0.008619
 >> iter 58000, loss: 0.008502
 >> iter 59000, loss: 0.008523
 >> iter 60000, loss: 0.008401
   Number of active neurons: 5
 >> iter 61000, loss: 0.008430
 >> iter 62000, loss: 0.008307
 >> iter 63000, loss: 0.008333
 >> iter 64000, loss: 0.008222
 >> iter 65000, loss: 0.008242
 >> iter 66000, loss: 0.008136
 >> iter 67000, loss: 0.008151
 >> iter 68000, loss: 0.008055
 >> iter 69000, loss: 0.008066
 >> iter 70000, loss: 0.007986
   Number of active neurons: 5
 >> iter 71000, loss: 0.008004
 >> iter 72000, loss: 0.007936
 >> iter 73000, loss: 0.007972
 >> iter 74000, loss: 0.007907
 >> iter 75000, loss: 0.007943
 >> iter 76000, loss: 0.007887
 >> iter 77000, loss: 0.007924
 >> iter 78000, loss: 0.007869
 >> iter 79000, loss: 0.007910
 >> iter 80000, loss: 0.007854
   Number of active neurons: 5
 >> iter 81000, loss: 0.007900
 >> iter 82000, loss: 0.007847
 >> iter 83000, loss: 0.007893
 >> iter 84000, loss: 0.007844
 >> iter 85000, loss: 0.007886
 >> iter 86000, loss: 0.007840
 >> iter 87000, loss: 0.007882
 >> iter 88000, loss: 0.007846
 >> iter 89000, loss: 0.007881
 >> iter 90000, loss: 0.007838
   Number of active neurons: 5
 >> iter 91000, loss: 0.007866
 >> iter 92000, loss: 0.007831
 >> iter 93000, loss: 0.007862
 >> iter 94000, loss: 0.007827
 >> iter 95000, loss: 0.007863
 >> iter 96000, loss: 0.007826
 >> iter 97000, loss: 0.007865
 >> iter 98000, loss: 0.007827
 >> iter 99000, loss: 0.007868
 >> iter 100000, loss: 0.007835
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.867496
 >> iter 2000, loss: 4.017667
 >> iter 3000, loss: 1.490704
 >> iter 4000, loss: 0.558550
 >> iter 5000, loss: 0.215044
 >> iter 6000, loss: 0.087632
 >> iter 7000, loss: 0.040706
 >> iter 8000, loss: 0.022810
 >> iter 9000, loss: 0.016302
 >> iter 10000, loss: 0.013411
   Number of active neurons: 6
 >> iter 11000, loss: 0.012460
 >> iter 12000, loss: 0.011664
 >> iter 13000, loss: 0.011516
 >> iter 14000, loss: 0.011089
 >> iter 15000, loss: 0.011150
 >> iter 16000, loss: 0.010712
 >> iter 17000, loss: 0.010747
 >> iter 18000, loss: 0.010336
 >> iter 19000, loss: 0.010376
 >> iter 20000, loss: 0.010037
   Number of active neurons: 5
 >> iter 21000, loss: 0.010119
 >> iter 22000, loss: 0.009837
 >> iter 23000, loss: 0.009954
 >> iter 24000, loss: 0.009718
 >> iter 25000, loss: 0.009853
 >> iter 26000, loss: 0.009634
 >> iter 27000, loss: 0.009770
 >> iter 28000, loss: 0.009571
 >> iter 29000, loss: 0.009723
 >> iter 30000, loss: 0.009535
   Number of active neurons: 5
 >> iter 31000, loss: 0.009676
 >> iter 32000, loss: 0.009480
 >> iter 33000, loss: 0.009595
 >> iter 34000, loss: 0.009393
 >> iter 35000, loss: 0.009481
 >> iter 36000, loss: 0.009297
 >> iter 37000, loss: 0.009392
 >> iter 38000, loss: 0.009220
 >> iter 39000, loss: 0.009309
 >> iter 40000, loss: 0.009160
   Number of active neurons: 5
 >> iter 41000, loss: 0.009233
 >> iter 42000, loss: 0.009080
 >> iter 43000, loss: 0.009152
 >> iter 44000, loss: 0.009009
 >> iter 45000, loss: 0.009076
 >> iter 46000, loss: 0.008938
 >> iter 47000, loss: 0.009019
 >> iter 48000, loss: 0.008890
 >> iter 49000, loss: 0.008983
 >> iter 50000, loss: 0.008857
   Number of active neurons: 5
 >> iter 51000, loss: 0.008950
 >> iter 52000, loss: 0.008841
 >> iter 53000, loss: 0.008920
 >> iter 54000, loss: 0.008827
 >> iter 55000, loss: 0.008901
 >> iter 56000, loss: 0.008807
 >> iter 57000, loss: 0.008875
 >> iter 58000, loss: 0.008785
 >> iter 59000, loss: 0.008851
 >> iter 60000, loss: 0.008761
   Number of active neurons: 4
 >> iter 61000, loss: 0.008819
 >> iter 62000, loss: 0.008701
 >> iter 63000, loss: 0.008728
 >> iter 64000, loss: 0.008601
 >> iter 65000, loss: 0.008614
 >> iter 66000, loss: 0.008501
 >> iter 67000, loss: 0.008519
 >> iter 68000, loss: 0.008419
 >> iter 69000, loss: 0.008422
 >> iter 70000, loss: 0.008320
   Number of active neurons: 4
 >> iter 71000, loss: 0.008315
 >> iter 72000, loss: 0.008226
 >> iter 73000, loss: 0.008239
 >> iter 74000, loss: 0.008154
 >> iter 75000, loss: 0.008165
 >> iter 76000, loss: 0.008086
 >> iter 77000, loss: 0.008094
 >> iter 78000, loss: 0.008013
 >> iter 79000, loss: 0.008020
 >> iter 80000, loss: 0.007933
   Number of active neurons: 4
 >> iter 81000, loss: 0.007939
 >> iter 82000, loss: 0.007851
 >> iter 83000, loss: 0.007861
 >> iter 84000, loss: 0.007787
 >> iter 85000, loss: 0.007800
 >> iter 86000, loss: 0.007738
 >> iter 87000, loss: 0.007758
 >> iter 88000, loss: 0.007712
 >> iter 89000, loss: 0.007732
 >> iter 90000, loss: 0.007687
   Number of active neurons: 4
 >> iter 91000, loss: 0.007707
 >> iter 92000, loss: 0.007673
 >> iter 93000, loss: 0.007696
 >> iter 94000, loss: 0.007656
 >> iter 95000, loss: 0.007677
 >> iter 96000, loss: 0.007634
 >> iter 97000, loss: 0.007658
 >> iter 98000, loss: 0.007617
 >> iter 99000, loss: 0.007645
 >> iter 100000, loss: 0.007611
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.792436
 >> iter 2000, loss: 3.991408
 >> iter 3000, loss: 1.481737
 >> iter 4000, loss: 0.555664
 >> iter 5000, loss: 0.214158
 >> iter 6000, loss: 0.087459
 >> iter 7000, loss: 0.040657
 >> iter 8000, loss: 0.022815
 >> iter 9000, loss: 0.016254
 >> iter 10000, loss: 0.013381
   Number of active neurons: 6
 >> iter 11000, loss: 0.012397
 >> iter 12000, loss: 0.011635
 >> iter 13000, loss: 0.011493
 >> iter 14000, loss: 0.011106
 >> iter 15000, loss: 0.011157
 >> iter 16000, loss: 0.010791
 >> iter 17000, loss: 0.010875
 >> iter 18000, loss: 0.010584
 >> iter 19000, loss: 0.010697
 >> iter 20000, loss: 0.010433
   Number of active neurons: 6
 >> iter 21000, loss: 0.010554
 >> iter 22000, loss: 0.010324
 >> iter 23000, loss: 0.010463
 >> iter 24000, loss: 0.010236
 >> iter 25000, loss: 0.010371
 >> iter 26000, loss: 0.010162
 >> iter 27000, loss: 0.010314
 >> iter 28000, loss: 0.010114
 >> iter 29000, loss: 0.010266
 >> iter 30000, loss: 0.010077
   Number of active neurons: 5
 >> iter 31000, loss: 0.010227
 >> iter 32000, loss: 0.010048
 >> iter 33000, loss: 0.010204
 >> iter 34000, loss: 0.010057
 >> iter 35000, loss: 0.010206
 >> iter 36000, loss: 0.010069
 >> iter 37000, loss: 0.010206
 >> iter 38000, loss: 0.010061
 >> iter 39000, loss: 0.010180
 >> iter 40000, loss: 0.010034
   Number of active neurons: 5
 >> iter 41000, loss: 0.010116
 >> iter 42000, loss: 0.009962
 >> iter 43000, loss: 0.010042
 >> iter 44000, loss: 0.009890
 >> iter 45000, loss: 0.009959
 >> iter 46000, loss: 0.009812
 >> iter 47000, loss: 0.009890
 >> iter 48000, loss: 0.009744
 >> iter 49000, loss: 0.009829
 >> iter 50000, loss: 0.009678
   Number of active neurons: 5
 >> iter 51000, loss: 0.009756
 >> iter 52000, loss: 0.009615
 >> iter 53000, loss: 0.009673
 >> iter 54000, loss: 0.009547
 >> iter 55000, loss: 0.009605
 >> iter 56000, loss: 0.009491
 >> iter 57000, loss: 0.009550
 >> iter 58000, loss: 0.009432
 >> iter 59000, loss: 0.009477
 >> iter 60000, loss: 0.009366
   Number of active neurons: 3
 >> iter 61000, loss: 0.009426
 >> iter 62000, loss: 0.009297
 >> iter 63000, loss: 0.009328
 >> iter 64000, loss: 0.009197
 >> iter 65000, loss: 0.009203
 >> iter 66000, loss: 0.009059
 >> iter 67000, loss: 0.009060
 >> iter 68000, loss: 0.008931
 >> iter 69000, loss: 0.008926
 >> iter 70000, loss: 0.008810
   Number of active neurons: 3
 >> iter 71000, loss: 0.008800
 >> iter 72000, loss: 0.008675
 >> iter 73000, loss: 0.008654
 >> iter 74000, loss: 0.008522
 >> iter 75000, loss: 0.008484
 >> iter 76000, loss: 0.008343
 >> iter 77000, loss: 0.008296
 >> iter 78000, loss: 0.008158
 >> iter 79000, loss: 0.008109
 >> iter 80000, loss: 0.007966
   Number of active neurons: 3
 >> iter 81000, loss: 0.007902
 >> iter 82000, loss: 0.007742
 >> iter 83000, loss: 0.007667
 >> iter 84000, loss: 0.007516
 >> iter 85000, loss: 0.007441
 >> iter 86000, loss: 0.007303
 >> iter 87000, loss: 0.007242
 >> iter 88000, loss: 0.007133
 >> iter 89000, loss: 0.007088
 >> iter 90000, loss: 0.006996
   Number of active neurons: 3
 >> iter 91000, loss: 0.006964
 >> iter 92000, loss: 0.006892
 >> iter 93000, loss: 0.006871
 >> iter 94000, loss: 0.006807
 >> iter 95000, loss: 0.006798
 >> iter 96000, loss: 0.006738
 >> iter 97000, loss: 0.006735
 >> iter 98000, loss: 0.006680
 >> iter 99000, loss: 0.006682
 >> iter 100000, loss: 0.006634
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 10.806575
 >> iter 2000, loss: 3.993838
 >> iter 3000, loss: 1.480980
 >> iter 4000, loss: 0.554134
 >> iter 5000, loss: 0.212455
 >> iter 6000, loss: 0.085827
 >> iter 7000, loss: 0.039133
 >> iter 8000, loss: 0.021416
 >> iter 9000, loss: 0.014973
 >> iter 10000, loss: 0.012253
   Number of active neurons: 5
 >> iter 11000, loss: 0.011423
 >> iter 12000, loss: 0.010817
 >> iter 13000, loss: 0.010753
 >> iter 14000, loss: 0.010496
 >> iter 15000, loss: 0.010622
 >> iter 16000, loss: 0.010387
 >> iter 17000, loss: 0.010520
 >> iter 18000, loss: 0.010299
 >> iter 19000, loss: 0.010425
 >> iter 20000, loss: 0.010208
   Number of active neurons: 4
 >> iter 21000, loss: 0.010322
 >> iter 22000, loss: 0.010104
 >> iter 23000, loss: 0.010204
 >> iter 24000, loss: 0.009972
 >> iter 25000, loss: 0.010067
 >> iter 26000, loss: 0.009831
 >> iter 27000, loss: 0.009926
 >> iter 28000, loss: 0.009682
 >> iter 29000, loss: 0.009759
 >> iter 30000, loss: 0.009506
   Number of active neurons: 4
 >> iter 31000, loss: 0.009578
 >> iter 32000, loss: 0.009343
 >> iter 33000, loss: 0.009429
 >> iter 34000, loss: 0.009228
 >> iter 35000, loss: 0.009306
 >> iter 36000, loss: 0.009120
 >> iter 37000, loss: 0.009198
 >> iter 38000, loss: 0.009016
 >> iter 39000, loss: 0.009084
 >> iter 40000, loss: 0.008925
   Number of active neurons: 3
 >> iter 41000, loss: 0.008985
 >> iter 42000, loss: 0.008834
 >> iter 43000, loss: 0.008906
 >> iter 44000, loss: 0.008774
 >> iter 45000, loss: 0.008843
 >> iter 46000, loss: 0.008709
 >> iter 47000, loss: 0.008769
 >> iter 48000, loss: 0.008613
 >> iter 49000, loss: 0.008666
 >> iter 50000, loss: 0.008512
   Number of active neurons: 3
 >> iter 51000, loss: 0.008567
 >> iter 52000, loss: 0.008424
 >> iter 53000, loss: 0.008458
 >> iter 54000, loss: 0.008333
 >> iter 55000, loss: 0.008368
 >> iter 56000, loss: 0.008250
 >> iter 57000, loss: 0.008284
 >> iter 58000, loss: 0.008173
 >> iter 59000, loss: 0.008207
 >> iter 60000, loss: 0.008097
   Number of active neurons: 3
 >> iter 61000, loss: 0.008134
 >> iter 62000, loss: 0.007999
 >> iter 63000, loss: 0.008002
 >> iter 64000, loss: 0.007877
 >> iter 65000, loss: 0.007878
 >> iter 66000, loss: 0.007774
 >> iter 67000, loss: 0.007787
 >> iter 68000, loss: 0.007707
 >> iter 69000, loss: 0.007719
 >> iter 70000, loss: 0.007654
   Number of active neurons: 3
 >> iter 71000, loss: 0.007669
 >> iter 72000, loss: 0.007614
 >> iter 73000, loss: 0.007643
 >> iter 74000, loss: 0.007589
 >> iter 75000, loss: 0.007617
 >> iter 76000, loss: 0.007570
 >> iter 77000, loss: 0.007597
 >> iter 78000, loss: 0.007551
 >> iter 79000, loss: 0.007581
 >> iter 80000, loss: 0.007534
   Number of active neurons: 3
 >> iter 81000, loss: 0.007568
 >> iter 82000, loss: 0.007523
 >> iter 83000, loss: 0.007560
 >> iter 84000, loss: 0.007517
 >> iter 85000, loss: 0.007549
 >> iter 86000, loss: 0.007510
 >> iter 87000, loss: 0.007540
 >> iter 88000, loss: 0.007513
 >> iter 89000, loss: 0.007538
 >> iter 90000, loss: 0.007508
   Number of active neurons: 3
 >> iter 91000, loss: 0.007532
 >> iter 92000, loss: 0.007507
 >> iter 93000, loss: 0.007527
 >> iter 94000, loss: 0.007493
 >> iter 95000, loss: 0.007518
 >> iter 96000, loss: 0.007482
 >> iter 97000, loss: 0.007507
 >> iter 98000, loss: 0.007472
 >> iter 99000, loss: 0.007501
 >> iter 100000, loss: 0.007471
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.843144
 >> iter 2000, loss: 4.009320
 >> iter 3000, loss: 1.487178
 >> iter 4000, loss: 0.556873
 >> iter 5000, loss: 0.213914
 >> iter 6000, loss: 0.086854
 >> iter 7000, loss: 0.039966
 >> iter 8000, loss: 0.022166
 >> iter 9000, loss: 0.015625
 >> iter 10000, loss: 0.012791
   Number of active neurons: 5
 >> iter 11000, loss: 0.011842
 >> iter 12000, loss: 0.011138
 >> iter 13000, loss: 0.010992
 >> iter 14000, loss: 0.010576
 >> iter 15000, loss: 0.010578
 >> iter 16000, loss: 0.010223
 >> iter 17000, loss: 0.010288
 >> iter 18000, loss: 0.010001
 >> iter 19000, loss: 0.010106
 >> iter 20000, loss: 0.009852
   Number of active neurons: 5
 >> iter 21000, loss: 0.009965
 >> iter 22000, loss: 0.009730
 >> iter 23000, loss: 0.009858
 >> iter 24000, loss: 0.009641
 >> iter 25000, loss: 0.009790
 >> iter 26000, loss: 0.009582
 >> iter 27000, loss: 0.009739
 >> iter 28000, loss: 0.009532
 >> iter 29000, loss: 0.009688
 >> iter 30000, loss: 0.009491
   Number of active neurons: 4
 >> iter 31000, loss: 0.009640
 >> iter 32000, loss: 0.009427
 >> iter 33000, loss: 0.009534
 >> iter 34000, loss: 0.009319
 >> iter 35000, loss: 0.009413
 >> iter 36000, loss: 0.009209
 >> iter 37000, loss: 0.009302
 >> iter 38000, loss: 0.009121
 >> iter 39000, loss: 0.009216
 >> iter 40000, loss: 0.009064
   Number of active neurons: 4
 >> iter 41000, loss: 0.009144
 >> iter 42000, loss: 0.008991
 >> iter 43000, loss: 0.009070
 >> iter 44000, loss: 0.008924
 >> iter 45000, loss: 0.008969
 >> iter 46000, loss: 0.008793
 >> iter 47000, loss: 0.008837
 >> iter 48000, loss: 0.008677
 >> iter 49000, loss: 0.008739
 >> iter 50000, loss: 0.008587
   Number of active neurons: 4
 >> iter 51000, loss: 0.008645
 >> iter 52000, loss: 0.008506
 >> iter 53000, loss: 0.008557
 >> iter 54000, loss: 0.008447
 >> iter 55000, loss: 0.008498
 >> iter 56000, loss: 0.008384
 >> iter 57000, loss: 0.008419
 >> iter 58000, loss: 0.008312
 >> iter 59000, loss: 0.008336
 >> iter 60000, loss: 0.008216
   Number of active neurons: 4
 >> iter 61000, loss: 0.008240
 >> iter 62000, loss: 0.008112
 >> iter 63000, loss: 0.008133
 >> iter 64000, loss: 0.008026
 >> iter 65000, loss: 0.008054
 >> iter 66000, loss: 0.007964
 >> iter 67000, loss: 0.007999
 >> iter 68000, loss: 0.007926
 >> iter 69000, loss: 0.007956
 >> iter 70000, loss: 0.007894
   Number of active neurons: 4
 >> iter 71000, loss: 0.007925
 >> iter 72000, loss: 0.007870
 >> iter 73000, loss: 0.007914
 >> iter 74000, loss: 0.007857
 >> iter 75000, loss: 0.007899
 >> iter 76000, loss: 0.007848
 >> iter 77000, loss: 0.007889
 >> iter 78000, loss: 0.007838
 >> iter 79000, loss: 0.007882
 >> iter 80000, loss: 0.007829
   Number of active neurons: 4
 >> iter 81000, loss: 0.007877
 >> iter 82000, loss: 0.007826
 >> iter 83000, loss: 0.007875
 >> iter 84000, loss: 0.007827
 >> iter 85000, loss: 0.007870
 >> iter 86000, loss: 0.007826
 >> iter 87000, loss: 0.007869
 >> iter 88000, loss: 0.007834
 >> iter 89000, loss: 0.007873
 >> iter 90000, loss: 0.007834
   Number of active neurons: 4
 >> iter 91000, loss: 0.007864
 >> iter 92000, loss: 0.007829
 >> iter 93000, loss: 0.007859
 >> iter 94000, loss: 0.007824
 >> iter 95000, loss: 0.007860
 >> iter 96000, loss: 0.007823
 >> iter 97000, loss: 0.007861
 >> iter 98000, loss: 0.007824
 >> iter 99000, loss: 0.007865
 >> iter 100000, loss: 0.007832
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.855617
 >> iter 2000, loss: 4.012474
 >> iter 3000, loss: 1.488026
 >> iter 4000, loss: 0.557050
 >> iter 5000, loss: 0.213872
 >> iter 6000, loss: 0.086767
 >> iter 7000, loss: 0.039916
 >> iter 8000, loss: 0.022133
 >> iter 9000, loss: 0.015620
 >> iter 10000, loss: 0.012782
   Number of active neurons: 5
 >> iter 11000, loss: 0.011842
 >> iter 12000, loss: 0.011133
 >> iter 13000, loss: 0.010995
 >> iter 14000, loss: 0.010614
 >> iter 15000, loss: 0.010674
 >> iter 16000, loss: 0.010345
 >> iter 17000, loss: 0.010480
 >> iter 18000, loss: 0.010198
 >> iter 19000, loss: 0.010317
 >> iter 20000, loss: 0.010012
   Number of active neurons: 5
 >> iter 21000, loss: 0.010105
 >> iter 22000, loss: 0.009816
 >> iter 23000, loss: 0.009903
 >> iter 24000, loss: 0.009615
 >> iter 25000, loss: 0.009699
 >> iter 26000, loss: 0.009416
 >> iter 27000, loss: 0.009496
 >> iter 28000, loss: 0.009222
 >> iter 29000, loss: 0.009301
 >> iter 30000, loss: 0.009042
   Number of active neurons: 5
 >> iter 31000, loss: 0.009116
 >> iter 32000, loss: 0.008875
 >> iter 33000, loss: 0.008974
 >> iter 34000, loss: 0.008796
 >> iter 35000, loss: 0.008914
 >> iter 36000, loss: 0.008770
 >> iter 37000, loss: 0.008888
 >> iter 38000, loss: 0.008747
 >> iter 39000, loss: 0.008868
 >> iter 40000, loss: 0.008754
   Number of active neurons: 5
 >> iter 41000, loss: 0.008863
 >> iter 42000, loss: 0.008745
 >> iter 43000, loss: 0.008854
 >> iter 44000, loss: 0.008747
 >> iter 45000, loss: 0.008849
 >> iter 46000, loss: 0.008735
 >> iter 47000, loss: 0.008841
 >> iter 48000, loss: 0.008725
 >> iter 49000, loss: 0.008833
 >> iter 50000, loss: 0.008714
   Number of active neurons: 5
 >> iter 51000, loss: 0.008818
 >> iter 52000, loss: 0.008712
 >> iter 53000, loss: 0.008802
 >> iter 54000, loss: 0.008709
 >> iter 55000, loss: 0.008793
 >> iter 56000, loss: 0.008699
 >> iter 57000, loss: 0.008777
 >> iter 58000, loss: 0.008687
 >> iter 59000, loss: 0.008764
 >> iter 60000, loss: 0.008674
   Number of active neurons: 4
 >> iter 61000, loss: 0.008760
 >> iter 62000, loss: 0.008659
 >> iter 63000, loss: 0.008731
 >> iter 64000, loss: 0.008625
 >> iter 65000, loss: 0.008665
 >> iter 66000, loss: 0.008567
 >> iter 67000, loss: 0.008604
 >> iter 68000, loss: 0.008522
 >> iter 69000, loss: 0.008543
 >> iter 70000, loss: 0.008450
   Number of active neurons: 4
 >> iter 71000, loss: 0.008445
 >> iter 72000, loss: 0.008354
 >> iter 73000, loss: 0.008363
 >> iter 74000, loss: 0.008278
 >> iter 75000, loss: 0.008282
 >> iter 76000, loss: 0.008193
 >> iter 77000, loss: 0.008190
 >> iter 78000, loss: 0.008109
 >> iter 79000, loss: 0.008111
 >> iter 80000, loss: 0.008034
   Number of active neurons: 4
 >> iter 81000, loss: 0.008040
 >> iter 82000, loss: 0.007965
 >> iter 83000, loss: 0.007973
 >> iter 84000, loss: 0.007899
 >> iter 85000, loss: 0.007896
 >> iter 86000, loss: 0.007824
 >> iter 87000, loss: 0.007815
 >> iter 88000, loss: 0.007750
 >> iter 89000, loss: 0.007732
 >> iter 90000, loss: 0.007668
   Number of active neurons: 4
 >> iter 91000, loss: 0.007656
 >> iter 92000, loss: 0.007611
 >> iter 93000, loss: 0.007610
 >> iter 94000, loss: 0.007568
 >> iter 95000, loss: 0.007576
 >> iter 96000, loss: 0.007536
 >> iter 97000, loss: 0.007542
 >> iter 98000, loss: 0.007499
 >> iter 99000, loss: 0.007509
 >> iter 100000, loss: 0.007473
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.894298
 >> iter 2000, loss: 4.026939
 >> iter 3000, loss: 1.493594
 >> iter 4000, loss: 0.559384
 >> iter 5000, loss: 0.214903
 >> iter 6000, loss: 0.087198
 >> iter 7000, loss: 0.040043
 >> iter 8000, loss: 0.022122
 >> iter 9000, loss: 0.015598
 >> iter 10000, loss: 0.012777
   Number of active neurons: 7
 >> iter 11000, loss: 0.011853
 >> iter 12000, loss: 0.011169
 >> iter 13000, loss: 0.011054
 >> iter 14000, loss: 0.010714
 >> iter 15000, loss: 0.010783
 >> iter 16000, loss: 0.010522
 >> iter 17000, loss: 0.010662
 >> iter 18000, loss: 0.010444
 >> iter 19000, loss: 0.010578
 >> iter 20000, loss: 0.010369
   Number of active neurons: 5
 >> iter 21000, loss: 0.010507
 >> iter 22000, loss: 0.010304
 >> iter 23000, loss: 0.010451
 >> iter 24000, loss: 0.010247
 >> iter 25000, loss: 0.010391
 >> iter 26000, loss: 0.010172
 >> iter 27000, loss: 0.010306
 >> iter 28000, loss: 0.010067
 >> iter 29000, loss: 0.010171
 >> iter 30000, loss: 0.009915
   Number of active neurons: 5
 >> iter 31000, loss: 0.009986
 >> iter 32000, loss: 0.009710
 >> iter 33000, loss: 0.009779
 >> iter 34000, loss: 0.009541
 >> iter 35000, loss: 0.009606
 >> iter 36000, loss: 0.009388
 >> iter 37000, loss: 0.009453
 >> iter 38000, loss: 0.009240
 >> iter 39000, loss: 0.009297
 >> iter 40000, loss: 0.009112
   Number of active neurons: 5
 >> iter 41000, loss: 0.009161
 >> iter 42000, loss: 0.008986
 >> iter 43000, loss: 0.009053
 >> iter 44000, loss: 0.008911
 >> iter 45000, loss: 0.008988
 >> iter 46000, loss: 0.008854
 >> iter 47000, loss: 0.008943
 >> iter 48000, loss: 0.008815
 >> iter 49000, loss: 0.008913
 >> iter 50000, loss: 0.008785
   Number of active neurons: 5
 >> iter 51000, loss: 0.008882
 >> iter 52000, loss: 0.008769
 >> iter 53000, loss: 0.008853
 >> iter 54000, loss: 0.008755
 >> iter 55000, loss: 0.008833
 >> iter 56000, loss: 0.008735
 >> iter 57000, loss: 0.008807
 >> iter 58000, loss: 0.008712
 >> iter 59000, loss: 0.008783
 >> iter 60000, loss: 0.008689
   Number of active neurons: 4
 >> iter 61000, loss: 0.008768
 >> iter 62000, loss: 0.008662
 >> iter 63000, loss: 0.008725
 >> iter 64000, loss: 0.008613
 >> iter 65000, loss: 0.008645
 >> iter 66000, loss: 0.008526
 >> iter 67000, loss: 0.008532
 >> iter 68000, loss: 0.008422
 >> iter 69000, loss: 0.008423
 >> iter 70000, loss: 0.008330
   Number of active neurons: 4
 >> iter 71000, loss: 0.008332
 >> iter 72000, loss: 0.008240
 >> iter 73000, loss: 0.008241
 >> iter 74000, loss: 0.008152
 >> iter 75000, loss: 0.008154
 >> iter 76000, loss: 0.008077
 >> iter 77000, loss: 0.008079
 >> iter 78000, loss: 0.008003
 >> iter 79000, loss: 0.008006
 >> iter 80000, loss: 0.007928
   Number of active neurons: 4
 >> iter 81000, loss: 0.007931
 >> iter 82000, loss: 0.007852
 >> iter 83000, loss: 0.007853
 >> iter 84000, loss: 0.007772
 >> iter 85000, loss: 0.007763
 >> iter 86000, loss: 0.007688
 >> iter 87000, loss: 0.007685
 >> iter 88000, loss: 0.007633
 >> iter 89000, loss: 0.007633
 >> iter 90000, loss: 0.007587
   Number of active neurons: 4
 >> iter 91000, loss: 0.007591
 >> iter 92000, loss: 0.007558
 >> iter 93000, loss: 0.007568
 >> iter 94000, loss: 0.007534
 >> iter 95000, loss: 0.007548
 >> iter 96000, loss: 0.007511
 >> iter 97000, loss: 0.007520
 >> iter 98000, loss: 0.007481
 >> iter 99000, loss: 0.007496
 >> iter 100000, loss: 0.007464
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.933611
 >> iter 2000, loss: 4.046521
 >> iter 3000, loss: 1.502818
 >> iter 4000, loss: 0.563958
 >> iter 5000, loss: 0.217703
 >> iter 6000, loss: 0.089170
 >> iter 7000, loss: 0.041756
 >> iter 8000, loss: 0.023726
 >> iter 9000, loss: 0.017189
 >> iter 10000, loss: 0.014345
   Number of active neurons: 9
 >> iter 11000, loss: 0.013430
 >> iter 12000, loss: 0.012716
 >> iter 13000, loss: 0.012655
 >> iter 14000, loss: 0.012342
 >> iter 15000, loss: 0.012497
 >> iter 16000, loss: 0.012262
 >> iter 17000, loss: 0.012458
 >> iter 18000, loss: 0.012233
 >> iter 19000, loss: 0.012418
 >> iter 20000, loss: 0.012217
   Number of active neurons: 8
 >> iter 21000, loss: 0.012411
 >> iter 22000, loss: 0.012223
 >> iter 23000, loss: 0.012408
 >> iter 24000, loss: 0.012201
 >> iter 25000, loss: 0.012375
 >> iter 26000, loss: 0.012161
 >> iter 27000, loss: 0.012337
 >> iter 28000, loss: 0.012114
 >> iter 29000, loss: 0.012276
 >> iter 30000, loss: 0.012053
   Number of active neurons: 3
 >> iter 31000, loss: 0.012213
 >> iter 32000, loss: 0.011994
 >> iter 33000, loss: 0.012151
 >> iter 34000, loss: 0.011941
 >> iter 35000, loss: 0.012054
 >> iter 36000, loss: 0.011839
 >> iter 37000, loss: 0.011944
 >> iter 38000, loss: 0.011705
 >> iter 39000, loss: 0.011755
 >> iter 40000, loss: 0.011517
   Number of active neurons: 2
 >> iter 41000, loss: 0.011512
 >> iter 42000, loss: 0.011236
 >> iter 43000, loss: 0.011216
 >> iter 44000, loss: 0.010942
 >> iter 45000, loss: 0.010877
 >> iter 46000, loss: 0.010560
 >> iter 47000, loss: 0.010460
 >> iter 48000, loss: 0.010142
 >> iter 49000, loss: 0.010062
 >> iter 50000, loss: 0.009766
   Number of active neurons: 2
 >> iter 51000, loss: 0.009686
 >> iter 52000, loss: 0.009402
 >> iter 53000, loss: 0.009299
 >> iter 54000, loss: 0.009020
 >> iter 55000, loss: 0.008895
 >> iter 56000, loss: 0.008632
 >> iter 57000, loss: 0.008522
 >> iter 58000, loss: 0.008285
 >> iter 59000, loss: 0.008194
 >> iter 60000, loss: 0.007993
   Number of active neurons: 2
 >> iter 61000, loss: 0.007934
 >> iter 62000, loss: 0.007747
 >> iter 63000, loss: 0.007695
 >> iter 64000, loss: 0.007525
 >> iter 65000, loss: 0.007475
 >> iter 66000, loss: 0.007330
 >> iter 67000, loss: 0.007298
 >> iter 68000, loss: 0.007179
 >> iter 69000, loss: 0.007154
 >> iter 70000, loss: 0.007055
   Number of active neurons: 2
 >> iter 71000, loss: 0.007039
 >> iter 72000, loss: 0.006953
 >> iter 73000, loss: 0.006952
 >> iter 74000, loss: 0.006872
 >> iter 75000, loss: 0.006873
 >> iter 76000, loss: 0.006802
 >> iter 77000, loss: 0.006803
 >> iter 78000, loss: 0.006728
 >> iter 79000, loss: 0.006728
 >> iter 80000, loss: 0.006658
   Number of active neurons: 2
 >> iter 81000, loss: 0.006666
 >> iter 82000, loss: 0.006601
 >> iter 83000, loss: 0.006614
 >> iter 84000, loss: 0.006557
 >> iter 85000, loss: 0.006568
 >> iter 86000, loss: 0.006517
 >> iter 87000, loss: 0.006530
 >> iter 88000, loss: 0.006489
 >> iter 89000, loss: 0.006500
 >> iter 90000, loss: 0.006459
   Number of active neurons: 2
 >> iter 91000, loss: 0.006470
 >> iter 92000, loss: 0.006437
 >> iter 93000, loss: 0.006448
 >> iter 94000, loss: 0.006414
 >> iter 95000, loss: 0.006429
 >> iter 96000, loss: 0.006394
 >> iter 97000, loss: 0.006410
 >> iter 98000, loss: 0.006375
 >> iter 99000, loss: 0.006392
 >> iter 100000, loss: 0.006360
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.852271
 >> iter 2000, loss: 4.010973
 >> iter 3000, loss: 1.487303
 >> iter 4000, loss: 0.556569
 >> iter 5000, loss: 0.213626
 >> iter 6000, loss: 0.086508
 >> iter 7000, loss: 0.039645
 >> iter 8000, loss: 0.021796
 >> iter 9000, loss: 0.015233
 >> iter 10000, loss: 0.012335
   Number of active neurons: 5
 >> iter 11000, loss: 0.011310
 >> iter 12000, loss: 0.010516
 >> iter 13000, loss: 0.010303
 >> iter 14000, loss: 0.009894
 >> iter 15000, loss: 0.009879
 >> iter 16000, loss: 0.009543
 >> iter 17000, loss: 0.009581
 >> iter 18000, loss: 0.009304
 >> iter 19000, loss: 0.009387
 >> iter 20000, loss: 0.009171
   Number of active neurons: 5
 >> iter 21000, loss: 0.009272
 >> iter 22000, loss: 0.009070
 >> iter 23000, loss: 0.009177
 >> iter 24000, loss: 0.008976
 >> iter 25000, loss: 0.009091
 >> iter 26000, loss: 0.008904
 >> iter 27000, loss: 0.009037
 >> iter 28000, loss: 0.008859
 >> iter 29000, loss: 0.009000
 >> iter 30000, loss: 0.008836
   Number of active neurons: 5
 >> iter 31000, loss: 0.008979
 >> iter 32000, loss: 0.008816
 >> iter 33000, loss: 0.008959
 >> iter 34000, loss: 0.008813
 >> iter 35000, loss: 0.008940
 >> iter 36000, loss: 0.008801
 >> iter 37000, loss: 0.008927
 >> iter 38000, loss: 0.008792
 >> iter 39000, loss: 0.008910
 >> iter 40000, loss: 0.008796
   Number of active neurons: 5
 >> iter 41000, loss: 0.008898
 >> iter 42000, loss: 0.008781
 >> iter 43000, loss: 0.008886
 >> iter 44000, loss: 0.008781
 >> iter 45000, loss: 0.008881
 >> iter 46000, loss: 0.008772
 >> iter 47000, loss: 0.008874
 >> iter 48000, loss: 0.008763
 >> iter 49000, loss: 0.008869
 >> iter 50000, loss: 0.008755
   Number of active neurons: 5
 >> iter 51000, loss: 0.008857
 >> iter 52000, loss: 0.008756
 >> iter 53000, loss: 0.008843
 >> iter 54000, loss: 0.008756
 >> iter 55000, loss: 0.008836
 >> iter 56000, loss: 0.008747
 >> iter 57000, loss: 0.008821
 >> iter 58000, loss: 0.008735
 >> iter 59000, loss: 0.008807
 >> iter 60000, loss: 0.008722
   Number of active neurons: 4
 >> iter 61000, loss: 0.008797
 >> iter 62000, loss: 0.008685
 >> iter 63000, loss: 0.008728
 >> iter 64000, loss: 0.008628
 >> iter 65000, loss: 0.008657
 >> iter 66000, loss: 0.008544
 >> iter 67000, loss: 0.008557
 >> iter 68000, loss: 0.008458
 >> iter 69000, loss: 0.008466
 >> iter 70000, loss: 0.008382
   Number of active neurons: 4
 >> iter 71000, loss: 0.008390
 >> iter 72000, loss: 0.008303
 >> iter 73000, loss: 0.008310
 >> iter 74000, loss: 0.008223
 >> iter 75000, loss: 0.008231
 >> iter 76000, loss: 0.008154
 >> iter 77000, loss: 0.008158
 >> iter 78000, loss: 0.008074
 >> iter 79000, loss: 0.008079
 >> iter 80000, loss: 0.007995
   Number of active neurons: 4
 >> iter 81000, loss: 0.008003
 >> iter 82000, loss: 0.007920
 >> iter 83000, loss: 0.007927
 >> iter 84000, loss: 0.007843
 >> iter 85000, loss: 0.007842
 >> iter 86000, loss: 0.007768
 >> iter 87000, loss: 0.007776
 >> iter 88000, loss: 0.007723
 >> iter 89000, loss: 0.007734
 >> iter 90000, loss: 0.007685
   Number of active neurons: 4
 >> iter 91000, loss: 0.007700
 >> iter 92000, loss: 0.007664
 >> iter 93000, loss: 0.007683
 >> iter 94000, loss: 0.007643
 >> iter 95000, loss: 0.007661
 >> iter 96000, loss: 0.007618
 >> iter 97000, loss: 0.007638
 >> iter 98000, loss: 0.007597
 >> iter 99000, loss: 0.007623
 >> iter 100000, loss: 0.007588
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.801669
 >> iter 2000, loss: 3.992654
 >> iter 3000, loss: 1.480554
 >> iter 4000, loss: 0.553845
 >> iter 5000, loss: 0.212202
 >> iter 6000, loss: 0.085572
 >> iter 7000, loss: 0.038873
 >> iter 8000, loss: 0.021131
 >> iter 9000, loss: 0.014691
 >> iter 10000, loss: 0.011962
   Number of active neurons: 5
 >> iter 11000, loss: 0.011129
 >> iter 12000, loss: 0.010533
 >> iter 13000, loss: 0.010510
 >> iter 14000, loss: 0.010275
 >> iter 15000, loss: 0.010409
 >> iter 16000, loss: 0.010181
 >> iter 17000, loss: 0.010321
 >> iter 18000, loss: 0.010111
 >> iter 19000, loss: 0.010263
 >> iter 20000, loss: 0.010064
   Number of active neurons: 5
 >> iter 21000, loss: 0.010203
 >> iter 22000, loss: 0.009994
 >> iter 23000, loss: 0.010120
 >> iter 24000, loss: 0.009905
 >> iter 25000, loss: 0.010029
 >> iter 26000, loss: 0.009814
 >> iter 27000, loss: 0.009951
 >> iter 28000, loss: 0.009748
 >> iter 29000, loss: 0.009894
 >> iter 30000, loss: 0.009708
   Number of active neurons: 4
 >> iter 31000, loss: 0.009857
 >> iter 32000, loss: 0.009672
 >> iter 33000, loss: 0.009817
 >> iter 34000, loss: 0.009649
 >> iter 35000, loss: 0.009772
 >> iter 36000, loss: 0.009609
 >> iter 37000, loss: 0.009726
 >> iter 38000, loss: 0.009561
 >> iter 39000, loss: 0.009651
 >> iter 40000, loss: 0.009484
   Number of active neurons: 4
 >> iter 41000, loss: 0.009540
 >> iter 42000, loss: 0.009367
 >> iter 43000, loss: 0.009432
 >> iter 44000, loss: 0.009284
 >> iter 45000, loss: 0.009351
 >> iter 46000, loss: 0.009205
 >> iter 47000, loss: 0.009276
 >> iter 48000, loss: 0.009130
 >> iter 49000, loss: 0.009204
 >> iter 50000, loss: 0.009052
   Number of active neurons: 4
 >> iter 51000, loss: 0.009117
 >> iter 52000, loss: 0.008977
 >> iter 53000, loss: 0.009030
 >> iter 54000, loss: 0.008914
 >> iter 55000, loss: 0.008970
 >> iter 56000, loss: 0.008862
 >> iter 57000, loss: 0.008917
 >> iter 58000, loss: 0.008817
 >> iter 59000, loss: 0.008874
 >> iter 60000, loss: 0.008777
   Number of active neurons: 3
 >> iter 61000, loss: 0.008834
 >> iter 62000, loss: 0.008689
 >> iter 63000, loss: 0.008697
 >> iter 64000, loss: 0.008566
 >> iter 65000, loss: 0.008578
 >> iter 66000, loss: 0.008466
 >> iter 67000, loss: 0.008479
 >> iter 68000, loss: 0.008364
 >> iter 69000, loss: 0.008357
 >> iter 70000, loss: 0.008259
   Number of active neurons: 3
 >> iter 71000, loss: 0.008259
 >> iter 72000, loss: 0.008173
 >> iter 73000, loss: 0.008187
 >> iter 74000, loss: 0.008102
 >> iter 75000, loss: 0.008111
 >> iter 76000, loss: 0.008029
 >> iter 77000, loss: 0.008033
 >> iter 78000, loss: 0.007949
 >> iter 79000, loss: 0.007950
 >> iter 80000, loss: 0.007861
   Number of active neurons: 3
 >> iter 81000, loss: 0.007870
 >> iter 82000, loss: 0.007793
 >> iter 83000, loss: 0.007813
 >> iter 84000, loss: 0.007747
 >> iter 85000, loss: 0.007768
 >> iter 86000, loss: 0.007712
 >> iter 87000, loss: 0.007737
 >> iter 88000, loss: 0.007695
 >> iter 89000, loss: 0.007718
 >> iter 90000, loss: 0.007676
   Number of active neurons: 3
 >> iter 91000, loss: 0.007698
 >> iter 92000, loss: 0.007666
 >> iter 93000, loss: 0.007690
 >> iter 94000, loss: 0.007654
 >> iter 95000, loss: 0.007677
 >> iter 96000, loss: 0.007635
 >> iter 97000, loss: 0.007659
 >> iter 98000, loss: 0.007618
 >> iter 99000, loss: 0.007647
 >> iter 100000, loss: 0.007612
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 10.925265
 >> iter 2000, loss: 4.039489
 >> iter 3000, loss: 1.498973
 >> iter 4000, loss: 0.561835
 >> iter 5000, loss: 0.216346
 >> iter 6000, loss: 0.088212
 >> iter 7000, loss: 0.040926
 >> iter 8000, loss: 0.022842
 >> iter 9000, loss: 0.016172
 >> iter 10000, loss: 0.013163
   Number of active neurons: 6
 >> iter 11000, loss: 0.012142
 >> iter 12000, loss: 0.011350
 >> iter 13000, loss: 0.011178
 >> iter 14000, loss: 0.010736
 >> iter 15000, loss: 0.010734
 >> iter 16000, loss: 0.010333
 >> iter 17000, loss: 0.010323
 >> iter 18000, loss: 0.009983
 >> iter 19000, loss: 0.010018
 >> iter 20000, loss: 0.009737
   Number of active neurons: 4
 >> iter 21000, loss: 0.009788
 >> iter 22000, loss: 0.009535
 >> iter 23000, loss: 0.009606
 >> iter 24000, loss: 0.009375
 >> iter 25000, loss: 0.009443
 >> iter 26000, loss: 0.009213
 >> iter 27000, loss: 0.009293
 >> iter 28000, loss: 0.009067
 >> iter 29000, loss: 0.009138
 >> iter 30000, loss: 0.008901
   Number of active neurons: 4
 >> iter 31000, loss: 0.008950
 >> iter 32000, loss: 0.008701
 >> iter 33000, loss: 0.008745
 >> iter 34000, loss: 0.008535
 >> iter 35000, loss: 0.008584
 >> iter 36000, loss: 0.008399
 >> iter 37000, loss: 0.008458
 >> iter 38000, loss: 0.008287
 >> iter 39000, loss: 0.008342
 >> iter 40000, loss: 0.008192
   Number of active neurons: 4
 >> iter 41000, loss: 0.008236
 >> iter 42000, loss: 0.008080
 >> iter 43000, loss: 0.008124
 >> iter 44000, loss: 0.007989
 >> iter 45000, loss: 0.008040
 >> iter 46000, loss: 0.007915
 >> iter 47000, loss: 0.007979
 >> iter 48000, loss: 0.007863
 >> iter 49000, loss: 0.007938
 >> iter 50000, loss: 0.007826
   Number of active neurons: 4
 >> iter 51000, loss: 0.007902
 >> iter 52000, loss: 0.007806
 >> iter 53000, loss: 0.007873
 >> iter 54000, loss: 0.007792
 >> iter 55000, loss: 0.007856
 >> iter 56000, loss: 0.007777
 >> iter 57000, loss: 0.007838
 >> iter 58000, loss: 0.007752
 >> iter 59000, loss: 0.007788
 >> iter 60000, loss: 0.007696
   Number of active neurons: 4
 >> iter 61000, loss: 0.007747
 >> iter 62000, loss: 0.007657
 >> iter 63000, loss: 0.007708
 >> iter 64000, loss: 0.007634
 >> iter 65000, loss: 0.007683
 >> iter 66000, loss: 0.007618
 >> iter 67000, loss: 0.007667
 >> iter 68000, loss: 0.007612
 >> iter 69000, loss: 0.007652
 >> iter 70000, loss: 0.007603
   Number of active neurons: 4
 >> iter 71000, loss: 0.007640
 >> iter 72000, loss: 0.007595
 >> iter 73000, loss: 0.007642
 >> iter 74000, loss: 0.007594
 >> iter 75000, loss: 0.007638
 >> iter 76000, loss: 0.007594
 >> iter 77000, loss: 0.007635
 >> iter 78000, loss: 0.007591
 >> iter 79000, loss: 0.007633
 >> iter 80000, loss: 0.007586
   Number of active neurons: 4
 >> iter 81000, loss: 0.007631
 >> iter 82000, loss: 0.007586
 >> iter 83000, loss: 0.007632
 >> iter 84000, loss: 0.007589
 >> iter 85000, loss: 0.007629
 >> iter 86000, loss: 0.007588
 >> iter 87000, loss: 0.007627
 >> iter 88000, loss: 0.007597
 >> iter 89000, loss: 0.007631
 >> iter 90000, loss: 0.007598
   Number of active neurons: 4
 >> iter 91000, loss: 0.007630
 >> iter 92000, loss: 0.007605
 >> iter 93000, loss: 0.007637
 >> iter 94000, loss: 0.007608
 >> iter 95000, loss: 0.007643
 >> iter 96000, loss: 0.007612
 >> iter 97000, loss: 0.007645
 >> iter 98000, loss: 0.007607
 >> iter 99000, loss: 0.007639
 >> iter 100000, loss: 0.007606
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.821426
 >> iter 2000, loss: 4.002146
 >> iter 3000, loss: 1.485016
 >> iter 4000, loss: 0.556698
 >> iter 5000, loss: 0.214480
 >> iter 6000, loss: 0.087661
 >> iter 7000, loss: 0.040885
 >> iter 8000, loss: 0.023116
 >> iter 9000, loss: 0.016668
 >> iter 10000, loss: 0.013851
   Number of active neurons: 8
 >> iter 11000, loss: 0.012954
 >> iter 12000, loss: 0.012223
 >> iter 13000, loss: 0.012163
 >> iter 14000, loss: 0.011761
 >> iter 15000, loss: 0.011834
 >> iter 16000, loss: 0.011420
 >> iter 17000, loss: 0.011507
 >> iter 18000, loss: 0.011178
 >> iter 19000, loss: 0.011321
 >> iter 20000, loss: 0.011055
   Number of active neurons: 7
 >> iter 21000, loss: 0.011209
 >> iter 22000, loss: 0.010970
 >> iter 23000, loss: 0.011129
 >> iter 24000, loss: 0.010899
 >> iter 25000, loss: 0.011050
 >> iter 26000, loss: 0.010804
 >> iter 27000, loss: 0.010939
 >> iter 28000, loss: 0.010690
 >> iter 29000, loss: 0.010807
 >> iter 30000, loss: 0.010550
   Number of active neurons: 6
 >> iter 31000, loss: 0.010635
 >> iter 32000, loss: 0.010368
 >> iter 33000, loss: 0.010454
 >> iter 34000, loss: 0.010223
 >> iter 35000, loss: 0.010281
 >> iter 36000, loss: 0.010057
 >> iter 37000, loss: 0.010120
 >> iter 38000, loss: 0.009913
 >> iter 39000, loss: 0.009965
 >> iter 40000, loss: 0.009768
   Number of active neurons: 6
 >> iter 41000, loss: 0.009800
 >> iter 42000, loss: 0.009614
 >> iter 43000, loss: 0.009667
 >> iter 44000, loss: 0.009510
 >> iter 45000, loss: 0.009565
 >> iter 46000, loss: 0.009409
 >> iter 47000, loss: 0.009467
 >> iter 48000, loss: 0.009308
 >> iter 49000, loss: 0.009377
 >> iter 50000, loss: 0.009225
   Number of active neurons: 5
 >> iter 51000, loss: 0.009301
 >> iter 52000, loss: 0.009172
 >> iter 53000, loss: 0.009239
 >> iter 54000, loss: 0.009115
 >> iter 55000, loss: 0.009153
 >> iter 56000, loss: 0.009023
 >> iter 57000, loss: 0.009058
 >> iter 58000, loss: 0.008940
 >> iter 59000, loss: 0.008979
 >> iter 60000, loss: 0.008852
   Number of active neurons: 5
 >> iter 61000, loss: 0.008884
 >> iter 62000, loss: 0.008744
 >> iter 63000, loss: 0.008760
 >> iter 64000, loss: 0.008635
 >> iter 65000, loss: 0.008654
 >> iter 66000, loss: 0.008545
 >> iter 67000, loss: 0.008566
 >> iter 68000, loss: 0.008468
 >> iter 69000, loss: 0.008478
 >> iter 70000, loss: 0.008386
   Number of active neurons: 5
 >> iter 71000, loss: 0.008389
 >> iter 72000, loss: 0.008296
 >> iter 73000, loss: 0.008307
 >> iter 74000, loss: 0.008212
 >> iter 75000, loss: 0.008226
 >> iter 76000, loss: 0.008147
 >> iter 77000, loss: 0.008168
 >> iter 78000, loss: 0.008097
 >> iter 79000, loss: 0.008127
 >> iter 80000, loss: 0.008060
   Number of active neurons: 5
 >> iter 81000, loss: 0.008098
 >> iter 82000, loss: 0.008035
 >> iter 83000, loss: 0.008077
 >> iter 84000, loss: 0.008020
 >> iter 85000, loss: 0.008058
 >> iter 86000, loss: 0.008005
 >> iter 87000, loss: 0.008037
 >> iter 88000, loss: 0.007988
 >> iter 89000, loss: 0.008016
 >> iter 90000, loss: 0.007966
   Number of active neurons: 5
 >> iter 91000, loss: 0.007995
 >> iter 92000, loss: 0.007955
 >> iter 93000, loss: 0.007985
 >> iter 94000, loss: 0.007945
 >> iter 95000, loss: 0.007980
 >> iter 96000, loss: 0.007937
 >> iter 97000, loss: 0.007972
 >> iter 98000, loss: 0.007928
 >> iter 99000, loss: 0.007963
 >> iter 100000, loss: 0.007904
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 10.828075
 >> iter 2000, loss: 4.002742
 >> iter 3000, loss: 1.484482
 >> iter 4000, loss: 0.555378
 >> iter 5000, loss: 0.213039
 >> iter 6000, loss: 0.086142
 >> iter 7000, loss: 0.039482
 >> iter 8000, loss: 0.021772
 >> iter 9000, loss: 0.015394
 >> iter 10000, loss: 0.012684
   Number of active neurons: 5
 >> iter 11000, loss: 0.011842
 >> iter 12000, loss: 0.011214
 >> iter 13000, loss: 0.011143
 >> iter 14000, loss: 0.010855
 >> iter 15000, loss: 0.010965
 >> iter 16000, loss: 0.010682
 >> iter 17000, loss: 0.010761
 >> iter 18000, loss: 0.010479
 >> iter 19000, loss: 0.010558
 >> iter 20000, loss: 0.010288
   Number of active neurons: 5
 >> iter 21000, loss: 0.010357
 >> iter 22000, loss: 0.010090
 >> iter 23000, loss: 0.010166
 >> iter 24000, loss: 0.009918
 >> iter 25000, loss: 0.010023
 >> iter 26000, loss: 0.009802
 >> iter 27000, loss: 0.009935
 >> iter 28000, loss: 0.009731
 >> iter 29000, loss: 0.009876
 >> iter 30000, loss: 0.009690
   Number of active neurons: 4
 >> iter 31000, loss: 0.009839
 >> iter 32000, loss: 0.009653
 >> iter 33000, loss: 0.009799
 >> iter 34000, loss: 0.009631
 >> iter 35000, loss: 0.009756
 >> iter 36000, loss: 0.009592
 >> iter 37000, loss: 0.009710
 >> iter 38000, loss: 0.009547
 >> iter 39000, loss: 0.009650
 >> iter 40000, loss: 0.009489
   Number of active neurons: 4
 >> iter 41000, loss: 0.009550
 >> iter 42000, loss: 0.009372
 >> iter 43000, loss: 0.009435
 >> iter 44000, loss: 0.009285
 >> iter 45000, loss: 0.009352
 >> iter 46000, loss: 0.009206
 >> iter 47000, loss: 0.009280
 >> iter 48000, loss: 0.009135
 >> iter 49000, loss: 0.009213
 >> iter 50000, loss: 0.009065
   Number of active neurons: 4
 >> iter 51000, loss: 0.009136
 >> iter 52000, loss: 0.009000
 >> iter 53000, loss: 0.009058
 >> iter 54000, loss: 0.008945
 >> iter 55000, loss: 0.009008
 >> iter 56000, loss: 0.008906
 >> iter 57000, loss: 0.008970
 >> iter 58000, loss: 0.008878
 >> iter 59000, loss: 0.008947
 >> iter 60000, loss: 0.008860
   Number of active neurons: 4
 >> iter 61000, loss: 0.008940
 >> iter 62000, loss: 0.008838
 >> iter 63000, loss: 0.008888
 >> iter 64000, loss: 0.008788
 >> iter 65000, loss: 0.008832
 >> iter 66000, loss: 0.008745
 >> iter 67000, loss: 0.008789
 >> iter 68000, loss: 0.008715
 >> iter 69000, loss: 0.008748
 >> iter 70000, loss: 0.008680
   Number of active neurons: 3
 >> iter 71000, loss: 0.008704
 >> iter 72000, loss: 0.008630
 >> iter 73000, loss: 0.008649
 >> iter 74000, loss: 0.008550
 >> iter 75000, loss: 0.008558
 >> iter 76000, loss: 0.008470
 >> iter 77000, loss: 0.008481
 >> iter 78000, loss: 0.008399
 >> iter 79000, loss: 0.008410
 >> iter 80000, loss: 0.008315
   Number of active neurons: 3
 >> iter 81000, loss: 0.008321
 >> iter 82000, loss: 0.008233
 >> iter 83000, loss: 0.008245
 >> iter 84000, loss: 0.008165
 >> iter 85000, loss: 0.008172
 >> iter 86000, loss: 0.008096
 >> iter 87000, loss: 0.008101
 >> iter 88000, loss: 0.008035
 >> iter 89000, loss: 0.008030
 >> iter 90000, loss: 0.007958
   Number of active neurons: 3
 >> iter 91000, loss: 0.007947
 >> iter 92000, loss: 0.007881
 >> iter 93000, loss: 0.007875
 >> iter 94000, loss: 0.007815
 >> iter 95000, loss: 0.007817
 >> iter 96000, loss: 0.007757
 >> iter 97000, loss: 0.007765
 >> iter 98000, loss: 0.007712
 >> iter 99000, loss: 0.007729
 >> iter 100000, loss: 0.007686
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

