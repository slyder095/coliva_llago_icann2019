 > Problema: tomita5nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.1
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.552371
 >> iter 2000, loss: 10.501798
 >> iter 3000, loss: 8.637038
 >> iter 4000, loss: 7.923813
 >> iter 5000, loss: 7.660536
 >> iter 6000, loss: 7.318343
 >> iter 7000, loss: 6.619294
 >> iter 8000, loss: 4.577954
 >> iter 9000, loss: 1.737995
 >> iter 10000, loss: 0.662175
   Number of active neurons: 10
 >> iter 11000, loss: 0.258935
 >> iter 12000, loss: 0.106913
 >> iter 13000, loss: 0.048672
 >> iter 14000, loss: 0.026132
 >> iter 15000, loss: 0.016368
 >> iter 16000, loss: 0.011927
 >> iter 17000, loss: 0.009634
 >> iter 18000, loss: 0.008264
 >> iter 19000, loss: 0.007310
 >> iter 20000, loss: 0.006609
   Number of active neurons: 10
 >> iter 21000, loss: 0.006051
 >> iter 22000, loss: 0.005582
 >> iter 23000, loss: 0.005170
 >> iter 24000, loss: 0.004835
 >> iter 25000, loss: 0.004535
 >> iter 26000, loss: 0.004259
 >> iter 27000, loss: 0.004021
 >> iter 28000, loss: 0.003820
 >> iter 29000, loss: 0.003631
 >> iter 30000, loss: 0.003445
   Number of active neurons: 10
 >> iter 31000, loss: 0.003281
 >> iter 32000, loss: 0.003140
 >> iter 33000, loss: 0.003013
 >> iter 34000, loss: 0.002895
 >> iter 35000, loss: 0.002771
 >> iter 36000, loss: 0.002668
 >> iter 37000, loss: 0.002571
 >> iter 38000, loss: 0.002491
 >> iter 39000, loss: 0.002405
 >> iter 40000, loss: 0.002323
   Number of active neurons: 10
 >> iter 41000, loss: 0.002248
 >> iter 42000, loss: 0.002180
 >> iter 43000, loss: 0.002114
 >> iter 44000, loss: 0.002055
 >> iter 45000, loss: 0.001995
 >> iter 46000, loss: 0.001938
 >> iter 47000, loss: 0.001879
 >> iter 48000, loss: 0.001829
 >> iter 49000, loss: 0.001782
 >> iter 50000, loss: 0.001740
   Number of active neurons: 10
 >> iter 51000, loss: 0.001693
 >> iter 52000, loss: 0.001652
 >> iter 53000, loss: 0.001614
 >> iter 54000, loss: 0.001580
 >> iter 55000, loss: 0.001543
 >> iter 56000, loss: 0.001508
 >> iter 57000, loss: 0.001483
 >> iter 58000, loss: 0.001446
 >> iter 59000, loss: 0.001418
 >> iter 60000, loss: 0.001389
   Number of active neurons: 10
 >> iter 61000, loss: 0.001359
 >> iter 62000, loss: 0.001333
 >> iter 63000, loss: 0.001307
 >> iter 64000, loss: 0.001285
 >> iter 65000, loss: 0.001260
 >> iter 66000, loss: 0.001239
 >> iter 67000, loss: 0.001219
 >> iter 68000, loss: 0.001194
 >> iter 69000, loss: 0.001171
 >> iter 70000, loss: 0.001151
   Number of active neurons: 10
 >> iter 71000, loss: 0.001133
 >> iter 72000, loss: 0.001115
 >> iter 73000, loss: 0.001095
 >> iter 74000, loss: 0.001080
 >> iter 75000, loss: 0.001063
 >> iter 76000, loss: 0.001043
 >> iter 77000, loss: 0.001030
 >> iter 78000, loss: 0.001014
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.560675
 >> iter 2000, loss: 10.510551
 >> iter 3000, loss: 8.642356
 >> iter 4000, loss: 7.927099
 >> iter 5000, loss: 7.519664
 >> iter 6000, loss: 6.848273
 >> iter 7000, loss: 5.903721
 >> iter 8000, loss: 2.977448
 >> iter 9000, loss: 1.152224
 >> iter 10000, loss: 0.447735
   Number of active neurons: 10
 >> iter 11000, loss: 0.181666
 >> iter 12000, loss: 0.079243
 >> iter 13000, loss: 0.039346
 >> iter 14000, loss: 0.023456
 >> iter 15000, loss: 0.015747
 >> iter 16000, loss: 0.011986
 >> iter 17000, loss: 0.009958
 >> iter 18000, loss: 0.008755
 >> iter 19000, loss: 0.007799
 >> iter 20000, loss: 0.007013
   Number of active neurons: 10
 >> iter 21000, loss: 0.006449
 >> iter 22000, loss: 0.006017
 >> iter 23000, loss: 0.005689
 >> iter 24000, loss: 0.005261
 >> iter 25000, loss: 0.004890
 >> iter 26000, loss: 0.004611
 >> iter 27000, loss: 0.004339
 >> iter 28000, loss: 0.004174
 >> iter 29000, loss: 0.003926
 >> iter 30000, loss: 0.003776
   Number of active neurons: 10
 >> iter 31000, loss: 0.003632
 >> iter 32000, loss: 0.003438
 >> iter 33000, loss: 0.003426
 >> iter 34000, loss: 0.003220
 >> iter 35000, loss: 0.003064
 >> iter 36000, loss: 0.002899
 >> iter 37000, loss: 0.002802
 >> iter 38000, loss: 0.002700
 >> iter 39000, loss: 0.002620
 >> iter 40000, loss: 0.002534
   Number of active neurons: 10
 >> iter 41000, loss: 0.002442
 >> iter 42000, loss: 0.002374
 >> iter 43000, loss: 0.002282
 >> iter 44000, loss: 0.002217
 >> iter 45000, loss: 0.002150
 >> iter 46000, loss: 0.002101
 >> iter 47000, loss: 0.002056
 >> iter 48000, loss: 0.002000
 >> iter 49000, loss: 0.001962
 >> iter 50000, loss: 0.001901
   Number of active neurons: 10
 >> iter 51000, loss: 0.001851
 >> iter 52000, loss: 0.001815
 >> iter 53000, loss: 0.001765
 >> iter 54000, loss: 0.001724
 >> iter 55000, loss: 0.001708
 >> iter 56000, loss: 0.001655
 >> iter 57000, loss: 0.001672
 >> iter 58000, loss: 0.001594
 >> iter 59000, loss: 0.001555
 >> iter 60000, loss: 0.001518
   Number of active neurons: 10
 >> iter 61000, loss: 0.001482
 >> iter 62000, loss: 0.001450
 >> iter 63000, loss: 0.001419
 >> iter 64000, loss: 0.001415
 >> iter 65000, loss: 0.001376
 >> iter 66000, loss: 0.001351
 >> iter 67000, loss: 0.001321
 >> iter 68000, loss: 0.001298
 >> iter 69000, loss: 0.001322
 >> iter 70000, loss: 0.001288
   Number of active neurons: 10
 >> iter 71000, loss: 0.001254
 >> iter 72000, loss: 0.001224
 >> iter 73000, loss: 0.001197
 >> iter 74000, loss: 0.001176
 >> iter 75000, loss: 0.001179
 >> iter 76000, loss: 0.001141
 >> iter 77000, loss: 0.001121
 >> iter 78000, loss: 0.001092
 >> iter 79000, loss: 0.001076
 >> iter 80000, loss: 0.001071
   Number of active neurons: 10
 >> iter 81000, loss: 0.001047
 >> iter 82000, loss: 0.001039
 >> iter 83000, loss: 0.001020
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.546201
 >> iter 2000, loss: 10.507118
 >> iter 3000, loss: 8.649594
 >> iter 4000, loss: 7.943367
 >> iter 5000, loss: 7.690798
 >> iter 6000, loss: 7.570403
 >> iter 7000, loss: 7.443613
 >> iter 8000, loss: 6.191309
 >> iter 9000, loss: 2.355825
 >> iter 10000, loss: 0.894715
   Number of active neurons: 10
 >> iter 11000, loss: 0.347057
 >> iter 12000, loss: 0.140705
 >> iter 13000, loss: 0.062120
 >> iter 14000, loss: 0.031329
 >> iter 15000, loss: 0.018792
 >> iter 16000, loss: 0.013123
 >> iter 17000, loss: 0.010377
 >> iter 18000, loss: 0.008732
 >> iter 19000, loss: 0.007689
 >> iter 20000, loss: 0.006869
   Number of active neurons: 10
 >> iter 21000, loss: 0.006244
 >> iter 22000, loss: 0.005720
 >> iter 23000, loss: 0.005306
 >> iter 24000, loss: 0.004930
 >> iter 25000, loss: 0.004636
 >> iter 26000, loss: 0.004339
 >> iter 27000, loss: 0.004072
 >> iter 28000, loss: 0.003830
 >> iter 29000, loss: 0.003645
 >> iter 30000, loss: 0.003437
   Number of active neurons: 10
 >> iter 31000, loss: 0.003284
 >> iter 32000, loss: 0.003108
 >> iter 33000, loss: 0.002981
 >> iter 34000, loss: 0.002845
 >> iter 35000, loss: 0.002736
 >> iter 36000, loss: 0.002609
 >> iter 37000, loss: 0.002513
 >> iter 38000, loss: 0.002412
 >> iter 39000, loss: 0.002325
 >> iter 40000, loss: 0.002233
   Number of active neurons: 10
 >> iter 41000, loss: 0.002167
 >> iter 42000, loss: 0.002085
 >> iter 43000, loss: 0.002019
 >> iter 44000, loss: 0.001946
 >> iter 45000, loss: 0.001889
 >> iter 46000, loss: 0.001828
 >> iter 47000, loss: 0.001775
 >> iter 48000, loss: 0.001726
 >> iter 49000, loss: 0.001672
 >> iter 50000, loss: 0.001622
   Number of active neurons: 10
 >> iter 51000, loss: 0.001579
 >> iter 52000, loss: 0.001533
 >> iter 53000, loss: 0.001499
 >> iter 54000, loss: 0.001459
 >> iter 55000, loss: 0.001416
 >> iter 56000, loss: 0.001375
 >> iter 57000, loss: 0.001346
 >> iter 58000, loss: 0.001316
 >> iter 59000, loss: 0.001282
 >> iter 60000, loss: 0.001253
   Number of active neurons: 10
 >> iter 61000, loss: 0.001223
 >> iter 62000, loss: 0.001198
 >> iter 63000, loss: 0.001169
 >> iter 64000, loss: 0.001150
 >> iter 65000, loss: 0.001125
 >> iter 66000, loss: 0.001101
 >> iter 67000, loss: 0.001080
 >> iter 68000, loss: 0.001058
 >> iter 69000, loss: 0.001036
 >> iter 70000, loss: 0.001014
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.579812
 >> iter 2000, loss: 10.531688
 >> iter 3000, loss: 8.665495
 >> iter 4000, loss: 7.947328
 >> iter 5000, loss: 7.476469
 >> iter 6000, loss: 3.808032
 >> iter 7000, loss: 1.450323
 >> iter 8000, loss: 0.558335
 >> iter 9000, loss: 0.221424
 >> iter 10000, loss: 0.092758
   Number of active neurons: 9
 >> iter 11000, loss: 0.042825
 >> iter 12000, loss: 0.022800
 >> iter 13000, loss: 0.014324
 >> iter 14000, loss: 0.010322
 >> iter 15000, loss: 0.008262
 >> iter 16000, loss: 0.007031
 >> iter 17000, loss: 0.006187
 >> iter 18000, loss: 0.005518
 >> iter 19000, loss: 0.004999
 >> iter 20000, loss: 0.004566
   Number of active neurons: 9
 >> iter 21000, loss: 0.004210
 >> iter 22000, loss: 0.003895
 >> iter 23000, loss: 0.003626
 >> iter 24000, loss: 0.003393
 >> iter 25000, loss: 0.003166
 >> iter 26000, loss: 0.002990
 >> iter 27000, loss: 0.002825
 >> iter 28000, loss: 0.002671
 >> iter 29000, loss: 0.002527
 >> iter 30000, loss: 0.002410
   Number of active neurons: 9
 >> iter 31000, loss: 0.002303
 >> iter 32000, loss: 0.002203
 >> iter 33000, loss: 0.002102
 >> iter 34000, loss: 0.002019
 >> iter 35000, loss: 0.001939
 >> iter 36000, loss: 0.001863
 >> iter 37000, loss: 0.001792
 >> iter 38000, loss: 0.001734
 >> iter 39000, loss: 0.001668
 >> iter 40000, loss: 0.001622
   Number of active neurons: 9
 >> iter 41000, loss: 0.001569
 >> iter 42000, loss: 0.001524
 >> iter 43000, loss: 0.001473
 >> iter 44000, loss: 0.001436
 >> iter 45000, loss: 0.001388
 >> iter 46000, loss: 0.001351
 >> iter 47000, loss: 0.001313
 >> iter 48000, loss: 0.001285
 >> iter 49000, loss: 0.001248
 >> iter 50000, loss: 0.001219
   Number of active neurons: 9
 >> iter 51000, loss: 0.001188
 >> iter 52000, loss: 0.001160
 >> iter 53000, loss: 0.001133
 >> iter 54000, loss: 0.001108
 >> iter 55000, loss: 0.001080
 >> iter 56000, loss: 0.001067
 >> iter 57000, loss: 0.001038
 >> iter 58000, loss: 0.001018
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.562313
 >> iter 2000, loss: 10.502848
 >> iter 3000, loss: 8.640803
 >> iter 4000, loss: 7.941593
 >> iter 5000, loss: 7.260416
 >> iter 6000, loss: 6.163326
 >> iter 7000, loss: 5.276785
 >> iter 8000, loss: 2.446848
 >> iter 9000, loss: 0.930604
 >> iter 10000, loss: 0.360421
   Number of active neurons: 10
 >> iter 11000, loss: 0.145745
 >> iter 12000, loss: 0.063899
 >> iter 13000, loss: 0.031892
 >> iter 14000, loss: 0.018792
 >> iter 15000, loss: 0.012964
 >> iter 16000, loss: 0.010079
 >> iter 17000, loss: 0.008397
 >> iter 18000, loss: 0.007375
 >> iter 19000, loss: 0.006612
 >> iter 20000, loss: 0.005991
   Number of active neurons: 10
 >> iter 21000, loss: 0.005490
 >> iter 22000, loss: 0.005076
 >> iter 23000, loss: 0.004727
 >> iter 24000, loss: 0.004423
 >> iter 25000, loss: 0.004104
 >> iter 26000, loss: 0.003888
 >> iter 27000, loss: 0.003656
 >> iter 28000, loss: 0.003464
 >> iter 29000, loss: 0.003302
 >> iter 30000, loss: 0.003136
   Number of active neurons: 10
 >> iter 31000, loss: 0.002997
 >> iter 32000, loss: 0.002864
 >> iter 33000, loss: 0.002723
 >> iter 34000, loss: 0.002635
 >> iter 35000, loss: 0.002522
 >> iter 36000, loss: 0.002445
 >> iter 37000, loss: 0.002334
 >> iter 38000, loss: 0.002249
 >> iter 39000, loss: 0.002176
 >> iter 40000, loss: 0.002112
   Number of active neurons: 10
 >> iter 41000, loss: 0.002019
 >> iter 42000, loss: 0.001989
 >> iter 43000, loss: 0.001919
 >> iter 44000, loss: 0.001899
 >> iter 45000, loss: 0.001808
 >> iter 46000, loss: 0.001757
 >> iter 47000, loss: 0.001694
 >> iter 48000, loss: 0.001657
 >> iter 49000, loss: 0.001606
 >> iter 50000, loss: 0.001586
   Number of active neurons: 10
 >> iter 51000, loss: 0.001534
 >> iter 52000, loss: 0.001512
 >> iter 53000, loss: 0.001461
 >> iter 54000, loss: 0.001431
 >> iter 55000, loss: 0.001396
 >> iter 56000, loss: 0.001372
 >> iter 57000, loss: 0.001329
 >> iter 58000, loss: 0.001312
 >> iter 59000, loss: 0.001279
 >> iter 60000, loss: 0.001261
   Number of active neurons: 10
 >> iter 61000, loss: 0.001232
 >> iter 62000, loss: 0.001219
 >> iter 63000, loss: 0.001174
 >> iter 64000, loss: 0.001170
 >> iter 65000, loss: 0.001134
 >> iter 66000, loss: 0.001126
 >> iter 67000, loss: 0.001094
 >> iter 68000, loss: 0.001084
 >> iter 69000, loss: 0.001051
 >> iter 70000, loss: 0.001041
   Number of active neurons: 10
 >> iter 71000, loss: 0.001021
 >> iter 72000, loss: 0.001017
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.506274
 >> iter 2000, loss: 10.475010
 >> iter 3000, loss: 8.622398
 >> iter 4000, loss: 7.898820
 >> iter 5000, loss: 7.306989
 >> iter 6000, loss: 6.204730
 >> iter 7000, loss: 2.511494
 >> iter 8000, loss: 0.949531
 >> iter 9000, loss: 0.364726
 >> iter 10000, loss: 0.145405
   Number of active neurons: 10
 >> iter 11000, loss: 0.062184
 >> iter 12000, loss: 0.030038
 >> iter 13000, loss: 0.017091
 >> iter 14000, loss: 0.011471
 >> iter 15000, loss: 0.008830
 >> iter 16000, loss: 0.007314
 >> iter 17000, loss: 0.006437
 >> iter 18000, loss: 0.005689
 >> iter 19000, loss: 0.005202
 >> iter 20000, loss: 0.004755
   Number of active neurons: 10
 >> iter 21000, loss: 0.004394
 >> iter 22000, loss: 0.004163
 >> iter 23000, loss: 0.003848
 >> iter 24000, loss: 0.003602
 >> iter 25000, loss: 0.003394
 >> iter 26000, loss: 0.003205
 >> iter 27000, loss: 0.003030
 >> iter 28000, loss: 0.002867
 >> iter 29000, loss: 0.002727
 >> iter 30000, loss: 0.002608
   Number of active neurons: 10
 >> iter 31000, loss: 0.002503
 >> iter 32000, loss: 0.002383
 >> iter 33000, loss: 0.002293
 >> iter 34000, loss: 0.002201
 >> iter 35000, loss: 0.002119
 >> iter 36000, loss: 0.002036
 >> iter 37000, loss: 0.001963
 >> iter 38000, loss: 0.001905
 >> iter 39000, loss: 0.001847
 >> iter 40000, loss: 0.001792
   Number of active neurons: 10
 >> iter 41000, loss: 0.001737
 >> iter 42000, loss: 0.001684
 >> iter 43000, loss: 0.001636
 >> iter 44000, loss: 0.001601
 >> iter 45000, loss: 0.001543
 >> iter 46000, loss: 0.001509
 >> iter 47000, loss: 0.001459
 >> iter 48000, loss: 0.001415
 >> iter 49000, loss: 0.001376
 >> iter 50000, loss: 0.001350
   Number of active neurons: 10
 >> iter 51000, loss: 0.001317
 >> iter 52000, loss: 0.001278
 >> iter 53000, loss: 0.001249
 >> iter 54000, loss: 0.001221
 >> iter 55000, loss: 0.001206
 >> iter 56000, loss: 0.001173
 >> iter 57000, loss: 0.001149
 >> iter 58000, loss: 0.001129
 >> iter 59000, loss: 0.001107
 >> iter 60000, loss: 0.001087
   Number of active neurons: 10
 >> iter 61000, loss: 0.001057
 >> iter 62000, loss: 0.001037
 >> iter 63000, loss: 0.001021
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.580558
 >> iter 2000, loss: 10.511888
 >> iter 3000, loss: 8.637153
 >> iter 4000, loss: 7.926417
 >> iter 5000, loss: 7.422972
 >> iter 6000, loss: 5.340675
 >> iter 7000, loss: 2.025943
 >> iter 8000, loss: 0.770400
 >> iter 9000, loss: 0.299796
 >> iter 10000, loss: 0.122386
   Number of active neurons: 9
 >> iter 11000, loss: 0.054587
 >> iter 12000, loss: 0.027991
 >> iter 13000, loss: 0.016991
 >> iter 14000, loss: 0.012077
 >> iter 15000, loss: 0.009568
 >> iter 16000, loss: 0.008109
 >> iter 17000, loss: 0.007110
 >> iter 18000, loss: 0.006381
 >> iter 19000, loss: 0.005805
 >> iter 20000, loss: 0.005338
   Number of active neurons: 9
 >> iter 21000, loss: 0.004910
 >> iter 22000, loss: 0.004578
 >> iter 23000, loss: 0.004272
 >> iter 24000, loss: 0.004014
 >> iter 25000, loss: 0.003764
 >> iter 26000, loss: 0.003565
 >> iter 27000, loss: 0.003359
 >> iter 28000, loss: 0.003200
 >> iter 29000, loss: 0.003039
 >> iter 30000, loss: 0.002893
   Number of active neurons: 9
 >> iter 31000, loss: 0.002768
 >> iter 32000, loss: 0.002660
 >> iter 33000, loss: 0.002537
 >> iter 34000, loss: 0.002449
 >> iter 35000, loss: 0.002349
 >> iter 36000, loss: 0.002271
 >> iter 37000, loss: 0.002184
 >> iter 38000, loss: 0.002122
 >> iter 39000, loss: 0.002046
 >> iter 40000, loss: 0.001989
   Number of active neurons: 9
 >> iter 41000, loss: 0.001916
 >> iter 42000, loss: 0.001869
 >> iter 43000, loss: 0.001806
 >> iter 44000, loss: 0.001756
 >> iter 45000, loss: 0.001708
 >> iter 46000, loss: 0.001668
 >> iter 47000, loss: 0.001618
 >> iter 48000, loss: 0.001574
 >> iter 49000, loss: 0.001529
 >> iter 50000, loss: 0.001492
   Number of active neurons: 9
 >> iter 51000, loss: 0.001454
 >> iter 52000, loss: 0.001429
 >> iter 53000, loss: 0.001391
 >> iter 54000, loss: 0.001365
 >> iter 55000, loss: 0.001330
 >> iter 56000, loss: 0.001306
 >> iter 57000, loss: 0.001275
 >> iter 58000, loss: 0.001252
 >> iter 59000, loss: 0.001221
 >> iter 60000, loss: 0.001206
   Number of active neurons: 9
 >> iter 61000, loss: 0.001177
 >> iter 62000, loss: 0.001156
 >> iter 63000, loss: 0.001130
 >> iter 64000, loss: 0.001114
 >> iter 65000, loss: 0.001083
 >> iter 66000, loss: 0.001072
 >> iter 67000, loss: 0.001052
 >> iter 68000, loss: 0.001039
 >> iter 69000, loss: 0.001015
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.592941
 >> iter 2000, loss: 10.529155
 >> iter 3000, loss: 8.650254
 >> iter 4000, loss: 7.933878
 >> iter 5000, loss: 7.675864
 >> iter 6000, loss: 7.561483
 >> iter 7000, loss: 7.524918
 >> iter 8000, loss: 7.404001
 >> iter 9000, loss: 6.825421
 >> iter 10000, loss: 5.958681
   Number of active neurons: 9
 >> iter 11000, loss: 2.458078
 >> iter 12000, loss: 0.942220
 >> iter 13000, loss: 0.369925
 >> iter 14000, loss: 0.152876
 >> iter 15000, loss: 0.069281
 >> iter 16000, loss: 0.036190
 >> iter 17000, loss: 0.022283
 >> iter 18000, loss: 0.015915
 >> iter 19000, loss: 0.012619
 >> iter 20000, loss: 0.010676
   Number of active neurons: 10
 >> iter 21000, loss: 0.009342
 >> iter 22000, loss: 0.008368
 >> iter 23000, loss: 0.007562
 >> iter 24000, loss: 0.006968
 >> iter 25000, loss: 0.006376
 >> iter 26000, loss: 0.005878
 >> iter 27000, loss: 0.005532
 >> iter 28000, loss: 0.005193
 >> iter 29000, loss: 0.004881
 >> iter 30000, loss: 0.004584
   Number of active neurons: 10
 >> iter 31000, loss: 0.004340
 >> iter 32000, loss: 0.004109
 >> iter 33000, loss: 0.003916
 >> iter 34000, loss: 0.003742
 >> iter 35000, loss: 0.003571
 >> iter 36000, loss: 0.003419
 >> iter 37000, loss: 0.003258
 >> iter 38000, loss: 0.003133
 >> iter 39000, loss: 0.003009
 >> iter 40000, loss: 0.002899
   Number of active neurons: 10
 >> iter 41000, loss: 0.002793
 >> iter 42000, loss: 0.002693
 >> iter 43000, loss: 0.002636
 >> iter 44000, loss: 0.002542
 >> iter 45000, loss: 0.002431
 >> iter 46000, loss: 0.002360
 >> iter 47000, loss: 0.002276
 >> iter 48000, loss: 0.002218
 >> iter 49000, loss: 0.002129
 >> iter 50000, loss: 0.002107
   Number of active neurons: 10
 >> iter 51000, loss: 0.002044
 >> iter 52000, loss: 0.001987
 >> iter 53000, loss: 0.001935
 >> iter 54000, loss: 0.001878
 >> iter 55000, loss: 0.001829
 >> iter 56000, loss: 0.001776
 >> iter 57000, loss: 0.001733
 >> iter 58000, loss: 0.001706
 >> iter 59000, loss: 0.001653
 >> iter 60000, loss: 0.001631
   Number of active neurons: 10
 >> iter 61000, loss: 0.001587
 >> iter 62000, loss: 0.001557
 >> iter 63000, loss: 0.001521
 >> iter 64000, loss: 0.001482
 >> iter 65000, loss: 0.001450
 >> iter 66000, loss: 0.001446
 >> iter 67000, loss: 0.001478
 >> iter 68000, loss: 0.001438
 >> iter 69000, loss: 0.001379
 >> iter 70000, loss: 0.001347
   Number of active neurons: 10
 >> iter 71000, loss: 0.001300
 >> iter 72000, loss: 0.001277
 >> iter 73000, loss: 0.001244
 >> iter 74000, loss: 0.001232
 >> iter 75000, loss: 0.001208
 >> iter 76000, loss: 0.001197
 >> iter 77000, loss: 0.001161
 >> iter 78000, loss: 0.001144
 >> iter 79000, loss: 0.001118
 >> iter 80000, loss: 0.001109
   Number of active neurons: 10
 >> iter 81000, loss: 0.001097
 >> iter 82000, loss: 0.001079
 >> iter 83000, loss: 0.001065
 >> iter 84000, loss: 0.001048
 >> iter 85000, loss: 0.001026
 >> iter 86000, loss: 0.001020
 >> iter 87000, loss: 0.001004
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 8.68608759416
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.549775
 >> iter 2000, loss: 10.509597
 >> iter 3000, loss: 8.643942
 >> iter 4000, loss: 7.893667
 >> iter 5000, loss: 7.312249
 >> iter 6000, loss: 6.530196
 >> iter 7000, loss: 2.579770
 >> iter 8000, loss: 0.987100
 >> iter 9000, loss: 0.385837
 >> iter 10000, loss: 0.157585
   Number of active neurons: 10
 >> iter 11000, loss: 0.070290
 >> iter 12000, loss: 0.035558
 >> iter 13000, loss: 0.021531
 >> iter 14000, loss: 0.015006
 >> iter 15000, loss: 0.011869
 >> iter 16000, loss: 0.009920
 >> iter 17000, loss: 0.008760
 >> iter 18000, loss: 0.007786
 >> iter 19000, loss: 0.007124
 >> iter 20000, loss: 0.006501
   Number of active neurons: 10
 >> iter 21000, loss: 0.006058
 >> iter 22000, loss: 0.005578
 >> iter 23000, loss: 0.005256
 >> iter 24000, loss: 0.004893
 >> iter 25000, loss: 0.004655
 >> iter 26000, loss: 0.004370
 >> iter 27000, loss: 0.004172
 >> iter 28000, loss: 0.003940
 >> iter 29000, loss: 0.003818
 >> iter 30000, loss: 0.003602
   Number of active neurons: 10
 >> iter 31000, loss: 0.003467
 >> iter 32000, loss: 0.003284
 >> iter 33000, loss: 0.003175
 >> iter 34000, loss: 0.003029
 >> iter 35000, loss: 0.002930
 >> iter 36000, loss: 0.002816
 >> iter 37000, loss: 0.002741
 >> iter 38000, loss: 0.002634
 >> iter 39000, loss: 0.002567
 >> iter 40000, loss: 0.002455
   Number of active neurons: 10
 >> iter 41000, loss: 0.002396
 >> iter 42000, loss: 0.002307
 >> iter 43000, loss: 0.002254
 >> iter 44000, loss: 0.002177
 >> iter 45000, loss: 0.002134
 >> iter 46000, loss: 0.002064
 >> iter 47000, loss: 0.002019
 >> iter 48000, loss: 0.001954
 >> iter 49000, loss: 0.001910
 >> iter 50000, loss: 0.001855
   Number of active neurons: 10
 >> iter 51000, loss: 0.001816
 >> iter 52000, loss: 0.001768
 >> iter 53000, loss: 0.001736
 >> iter 54000, loss: 0.001683
 >> iter 55000, loss: 0.001663
 >> iter 56000, loss: 0.001610
 >> iter 57000, loss: 0.001587
 >> iter 58000, loss: 0.001543
 >> iter 59000, loss: 0.001517
 >> iter 60000, loss: 0.001478
   Number of active neurons: 10
 >> iter 61000, loss: 0.001459
 >> iter 62000, loss: 0.001420
 >> iter 63000, loss: 0.001404
 >> iter 64000, loss: 0.001365
 >> iter 65000, loss: 0.001346
 >> iter 66000, loss: 0.001317
 >> iter 67000, loss: 0.001299
 >> iter 68000, loss: 0.001266
 >> iter 69000, loss: 0.001252
 >> iter 70000, loss: 0.001223
   Number of active neurons: 10
 >> iter 71000, loss: 0.001207
 >> iter 72000, loss: 0.001180
 >> iter 73000, loss: 0.001167
 >> iter 74000, loss: 0.001144
 >> iter 75000, loss: 0.001130
 >> iter 76000, loss: 0.001104
 >> iter 77000, loss: 0.001094
 >> iter 78000, loss: 0.001071
 >> iter 79000, loss: 0.001062
 >> iter 80000, loss: 0.001039
   Number of active neurons: 10
 >> iter 81000, loss: 0.001023
 >> iter 82000, loss: 0.001006
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.634062
 >> iter 2000, loss: 10.528932
 >> iter 3000, loss: 8.644924
 >> iter 4000, loss: 7.935075
 >> iter 5000, loss: 7.683514
 >> iter 6000, loss: 7.574135
 >> iter 7000, loss: 7.504638
 >> iter 8000, loss: 7.020575
 >> iter 9000, loss: 6.391503
 >> iter 10000, loss: 2.717583
   Number of active neurons: 10
 >> iter 11000, loss: 1.051295
 >> iter 12000, loss: 0.414387
 >> iter 13000, loss: 0.171576
 >> iter 14000, loss: 0.077235
 >> iter 15000, loss: 0.039747
 >> iter 16000, loss: 0.023761
 >> iter 17000, loss: 0.016702
 >> iter 18000, loss: 0.012853
 >> iter 19000, loss: 0.010733
 >> iter 20000, loss: 0.009188
   Number of active neurons: 10
 >> iter 21000, loss: 0.008153
 >> iter 22000, loss: 0.007284
 >> iter 23000, loss: 0.006653
 >> iter 24000, loss: 0.006080
 >> iter 25000, loss: 0.005613
 >> iter 26000, loss: 0.005179
 >> iter 27000, loss: 0.004837
 >> iter 28000, loss: 0.004468
 >> iter 29000, loss: 0.004210
 >> iter 30000, loss: 0.003950
   Number of active neurons: 10
 >> iter 31000, loss: 0.003771
 >> iter 32000, loss: 0.003538
 >> iter 33000, loss: 0.003368
 >> iter 34000, loss: 0.003197
 >> iter 35000, loss: 0.003042
 >> iter 36000, loss: 0.002881
 >> iter 37000, loss: 0.002774
 >> iter 38000, loss: 0.002643
 >> iter 39000, loss: 0.002527
 >> iter 40000, loss: 0.002416
   Number of active neurons: 10
 >> iter 41000, loss: 0.002325
 >> iter 42000, loss: 0.002228
 >> iter 43000, loss: 0.002146
 >> iter 44000, loss: 0.002050
 >> iter 45000, loss: 0.001987
 >> iter 46000, loss: 0.001904
 >> iter 47000, loss: 0.001845
 >> iter 48000, loss: 0.001793
 >> iter 49000, loss: 0.001727
 >> iter 50000, loss: 0.001651
   Number of active neurons: 10
 >> iter 51000, loss: 0.001598
 >> iter 52000, loss: 0.001534
 >> iter 53000, loss: 0.001496
 >> iter 54000, loss: 0.001446
 >> iter 55000, loss: 0.001409
 >> iter 56000, loss: 0.001366
 >> iter 57000, loss: 0.001321
 >> iter 58000, loss: 0.001289
 >> iter 59000, loss: 0.001261
 >> iter 60000, loss: 0.001225
   Number of active neurons: 10
 >> iter 61000, loss: 0.001195
 >> iter 62000, loss: 0.001163
 >> iter 63000, loss: 0.001144
 >> iter 64000, loss: 0.001111
 >> iter 65000, loss: 0.001085
 >> iter 66000, loss: 0.001066
 >> iter 67000, loss: 0.001050
 >> iter 68000, loss: 0.001029
 >> iter 69000, loss: 0.001008
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.561786
 >> iter 2000, loss: 10.510159
 >> iter 3000, loss: 8.645320
 >> iter 4000, loss: 7.934530
 >> iter 5000, loss: 7.686284
 >> iter 6000, loss: 7.483877
 >> iter 7000, loss: 6.971685
 >> iter 8000, loss: 3.970174
 >> iter 9000, loss: 1.537365
 >> iter 10000, loss: 0.600836
   Number of active neurons: 10
 >> iter 11000, loss: 0.244442
 >> iter 12000, loss: 0.106487
 >> iter 13000, loss: 0.052375
 >> iter 14000, loss: 0.029705
 >> iter 15000, loss: 0.019842
 >> iter 16000, loss: 0.014729
 >> iter 17000, loss: 0.012053
 >> iter 18000, loss: 0.010176
 >> iter 19000, loss: 0.009000
 >> iter 20000, loss: 0.007969
   Number of active neurons: 10
 >> iter 21000, loss: 0.007269
 >> iter 22000, loss: 0.006585
 >> iter 23000, loss: 0.006121
 >> iter 24000, loss: 0.005636
 >> iter 25000, loss: 0.005290
 >> iter 26000, loss: 0.004896
 >> iter 27000, loss: 0.004632
 >> iter 28000, loss: 0.004324
 >> iter 29000, loss: 0.004127
 >> iter 30000, loss: 0.003877
   Number of active neurons: 10
 >> iter 31000, loss: 0.003730
 >> iter 32000, loss: 0.003507
 >> iter 33000, loss: 0.003370
 >> iter 34000, loss: 0.003199
 >> iter 35000, loss: 0.003097
 >> iter 36000, loss: 0.002947
 >> iter 37000, loss: 0.002851
 >> iter 38000, loss: 0.002718
 >> iter 39000, loss: 0.002670
 >> iter 40000, loss: 0.002568
   Number of active neurons: 10
 >> iter 41000, loss: 0.002487
 >> iter 42000, loss: 0.002377
 >> iter 43000, loss: 0.002311
 >> iter 44000, loss: 0.002206
 >> iter 45000, loss: 0.002155
 >> iter 46000, loss: 0.002073
 >> iter 47000, loss: 0.002026
 >> iter 48000, loss: 0.001954
 >> iter 49000, loss: 0.001919
 >> iter 50000, loss: 0.001851
   Number of active neurons: 10
 >> iter 51000, loss: 0.001817
 >> iter 52000, loss: 0.001756
 >> iter 53000, loss: 0.001722
 >> iter 54000, loss: 0.001661
 >> iter 55000, loss: 0.001637
 >> iter 56000, loss: 0.001587
 >> iter 57000, loss: 0.001561
 >> iter 58000, loss: 0.001510
 >> iter 59000, loss: 0.001490
 >> iter 60000, loss: 0.001448
   Number of active neurons: 10
 >> iter 61000, loss: 0.001426
 >> iter 62000, loss: 0.001384
 >> iter 63000, loss: 0.001365
 >> iter 64000, loss: 0.001330
 >> iter 65000, loss: 0.001308
 >> iter 66000, loss: 0.001272
 >> iter 67000, loss: 0.001258
 >> iter 68000, loss: 0.001221
 >> iter 69000, loss: 0.001203
 >> iter 70000, loss: 0.001176
   Number of active neurons: 10
 >> iter 71000, loss: 0.001167
 >> iter 72000, loss: 0.001132
 >> iter 73000, loss: 0.001117
 >> iter 74000, loss: 0.001092
 >> iter 75000, loss: 0.001080
 >> iter 76000, loss: 0.001056
 >> iter 77000, loss: 0.001046
 >> iter 78000, loss: 0.001021
 >> iter 79000, loss: 0.001010
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.524964
 >> iter 2000, loss: 10.474395
 >> iter 3000, loss: 8.615031
 >> iter 4000, loss: 7.913608
 >> iter 5000, loss: 7.657297
 >> iter 6000, loss: 7.228660
 >> iter 7000, loss: 5.459345
 >> iter 8000, loss: 2.077011
 >> iter 9000, loss: 0.791748
 >> iter 10000, loss: 0.308138
   Number of active neurons: 9
 >> iter 11000, loss: 0.125562
 >> iter 12000, loss: 0.055709
 >> iter 13000, loss: 0.028234
 >> iter 14000, loss: 0.016817
 >> iter 15000, loss: 0.011702
 >> iter 16000, loss: 0.009172
 >> iter 17000, loss: 0.007692
 >> iter 18000, loss: 0.006730
 >> iter 19000, loss: 0.005994
 >> iter 20000, loss: 0.005451
   Number of active neurons: 10
 >> iter 21000, loss: 0.004973
 >> iter 22000, loss: 0.004541
 >> iter 23000, loss: 0.004223
 >> iter 24000, loss: 0.003945
 >> iter 25000, loss: 0.003711
 >> iter 26000, loss: 0.003532
 >> iter 27000, loss: 0.003306
 >> iter 28000, loss: 0.003115
 >> iter 29000, loss: 0.002945
 >> iter 30000, loss: 0.002825
   Number of active neurons: 10
 >> iter 31000, loss: 0.002679
 >> iter 32000, loss: 0.002579
 >> iter 33000, loss: 0.002447
 >> iter 34000, loss: 0.002354
 >> iter 35000, loss: 0.002245
 >> iter 36000, loss: 0.002165
 >> iter 37000, loss: 0.002085
 >> iter 38000, loss: 0.002015
 >> iter 39000, loss: 0.001948
 >> iter 40000, loss: 0.001879
   Number of active neurons: 10
 >> iter 41000, loss: 0.001804
 >> iter 42000, loss: 0.001765
 >> iter 43000, loss: 0.001701
 >> iter 44000, loss: 0.001663
 >> iter 45000, loss: 0.001602
 >> iter 46000, loss: 0.001563
 >> iter 47000, loss: 0.001523
 >> iter 48000, loss: 0.001484
 >> iter 49000, loss: 0.001437
 >> iter 50000, loss: 0.001415
   Number of active neurons: 10
 >> iter 51000, loss: 0.001368
 >> iter 52000, loss: 0.001336
 >> iter 53000, loss: 0.001299
 >> iter 54000, loss: 0.001272
 >> iter 55000, loss: 0.001243
 >> iter 56000, loss: 0.001227
 >> iter 57000, loss: 0.001192
 >> iter 58000, loss: 0.001166
 >> iter 59000, loss: 0.001139
 >> iter 60000, loss: 0.001120
   Number of active neurons: 10
 >> iter 61000, loss: 0.001098
 >> iter 62000, loss: 0.001077
 >> iter 63000, loss: 0.001045
 >> iter 64000, loss: 0.001032
 >> iter 65000, loss: 0.001014
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.576089
 >> iter 2000, loss: 10.506256
 >> iter 3000, loss: 8.631346
 >> iter 4000, loss: 7.912227
 >> iter 5000, loss: 7.388258
 >> iter 6000, loss: 6.644773
 >> iter 7000, loss: 4.021767
 >> iter 8000, loss: 1.540582
 >> iter 9000, loss: 0.595992
 >> iter 10000, loss: 0.237577
   Number of active neurons: 10
 >> iter 11000, loss: 0.100970
 >> iter 12000, loss: 0.047297
 >> iter 13000, loss: 0.025505
 >> iter 14000, loss: 0.015925
 >> iter 15000, loss: 0.011594
 >> iter 16000, loss: 0.009049
 >> iter 17000, loss: 0.007675
 >> iter 18000, loss: 0.006653
 >> iter 19000, loss: 0.005992
 >> iter 20000, loss: 0.005387
   Number of active neurons: 10
 >> iter 21000, loss: 0.005166
 >> iter 22000, loss: 0.004583
 >> iter 23000, loss: 0.004251
 >> iter 24000, loss: 0.003866
 >> iter 25000, loss: 0.003886
 >> iter 26000, loss: 0.003677
 >> iter 27000, loss: 0.003338
 >> iter 28000, loss: 0.003085
 >> iter 29000, loss: 0.002916
 >> iter 30000, loss: 0.002730
   Number of active neurons: 10
 >> iter 31000, loss: 0.002599
 >> iter 32000, loss: 0.002484
 >> iter 33000, loss: 0.002402
 >> iter 34000, loss: 0.002697
 >> iter 35000, loss: 0.002586
 >> iter 36000, loss: 0.002285
 >> iter 37000, loss: 0.002094
 >> iter 38000, loss: 0.001968
 >> iter 39000, loss: 0.001894
 >> iter 40000, loss: 0.001816
   Number of active neurons: 10
 >> iter 41000, loss: 0.001758
 >> iter 42000, loss: 0.001695
 >> iter 43000, loss: 0.001675
 >> iter 44000, loss: 0.001603
 >> iter 45000, loss: 0.001551
 >> iter 46000, loss: 0.001500
 >> iter 47000, loss: 0.001468
 >> iter 48000, loss: 0.001431
 >> iter 49000, loss: 0.001400
 >> iter 50000, loss: 0.001354
   Number of active neurons: 10
 >> iter 51000, loss: 0.001333
 >> iter 52000, loss: 0.001306
 >> iter 53000, loss: 0.001276
 >> iter 54000, loss: 0.001239
 >> iter 55000, loss: 0.001212
 >> iter 56000, loss: 0.001187
 >> iter 57000, loss: 0.001164
 >> iter 58000, loss: 0.001135
 >> iter 59000, loss: 0.001118
 >> iter 60000, loss: 0.001091
   Number of active neurons: 10
 >> iter 61000, loss: 0.001077
 >> iter 62000, loss: 0.001051
 >> iter 63000, loss: 0.001049
 >> iter 64000, loss: 0.001022
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.558712
 >> iter 2000, loss: 10.505665
 >> iter 3000, loss: 8.639671
 >> iter 4000, loss: 7.927475
 >> iter 5000, loss: 7.674422
 >> iter 6000, loss: 7.483092
 >> iter 7000, loss: 6.923697
 >> iter 8000, loss: 4.809833
 >> iter 9000, loss: 1.833550
 >> iter 10000, loss: 0.699486
   Number of active neurons: 10
 >> iter 11000, loss: 0.273579
 >> iter 12000, loss: 0.112576
 >> iter 13000, loss: 0.050701
 >> iter 14000, loss: 0.026306
 >> iter 15000, loss: 0.016290
 >> iter 16000, loss: 0.011700
 >> iter 17000, loss: 0.009410
 >> iter 18000, loss: 0.007998
 >> iter 19000, loss: 0.007145
 >> iter 20000, loss: 0.006410
   Number of active neurons: 10
 >> iter 21000, loss: 0.005863
 >> iter 22000, loss: 0.005368
 >> iter 23000, loss: 0.005017
 >> iter 24000, loss: 0.004652
 >> iter 25000, loss: 0.004360
 >> iter 26000, loss: 0.004102
 >> iter 27000, loss: 0.003872
 >> iter 28000, loss: 0.003645
 >> iter 29000, loss: 0.003484
 >> iter 30000, loss: 0.003306
   Number of active neurons: 10
 >> iter 31000, loss: 0.003160
 >> iter 32000, loss: 0.003015
 >> iter 33000, loss: 0.002880
 >> iter 34000, loss: 0.002758
 >> iter 35000, loss: 0.002671
 >> iter 36000, loss: 0.002549
 >> iter 37000, loss: 0.002457
 >> iter 38000, loss: 0.002357
 >> iter 39000, loss: 0.002287
 >> iter 40000, loss: 0.002227
   Number of active neurons: 10
 >> iter 41000, loss: 0.002146
 >> iter 42000, loss: 0.002083
 >> iter 43000, loss: 0.002006
 >> iter 44000, loss: 0.001945
 >> iter 45000, loss: 0.001903
 >> iter 46000, loss: 0.001862
 >> iter 47000, loss: 0.001793
 >> iter 48000, loss: 0.001746
 >> iter 49000, loss: 0.001785
 >> iter 50000, loss: 0.001703
   Number of active neurons: 10
 >> iter 51000, loss: 0.001632
 >> iter 52000, loss: 0.001585
 >> iter 53000, loss: 0.001538
 >> iter 54000, loss: 0.001499
 >> iter 55000, loss: 0.001466
 >> iter 56000, loss: 0.001445
 >> iter 57000, loss: 0.001408
 >> iter 58000, loss: 0.001375
 >> iter 59000, loss: 0.001345
 >> iter 60000, loss: 0.001324
   Number of active neurons: 10
 >> iter 61000, loss: 0.001299
 >> iter 62000, loss: 0.001270
 >> iter 63000, loss: 0.001238
 >> iter 64000, loss: 0.001217
 >> iter 65000, loss: 0.001192
 >> iter 66000, loss: 0.001185
 >> iter 67000, loss: 0.001157
 >> iter 68000, loss: 0.001132
 >> iter 69000, loss: 0.001111
 >> iter 70000, loss: 0.001107
   Number of active neurons: 10
 >> iter 71000, loss: 0.001077
 >> iter 72000, loss: 0.001062
 >> iter 73000, loss: 0.001043
 >> iter 74000, loss: 0.001021
 >> iter 75000, loss: 0.001005
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.543292
 >> iter 2000, loss: 10.486172
 >> iter 3000, loss: 8.619799
 >> iter 4000, loss: 7.908671
 >> iter 5000, loss: 7.676248
 >> iter 6000, loss: 7.076620
 >> iter 7000, loss: 6.181083
 >> iter 8000, loss: 5.635657
 >> iter 9000, loss: 2.450013
 >> iter 10000, loss: 0.930836
   Number of active neurons: 10
 >> iter 11000, loss: 0.359211
 >> iter 12000, loss: 0.180203
 >> iter 13000, loss: 0.076176
 >> iter 14000, loss: 0.036205
 >> iter 15000, loss: 0.020638
 >> iter 16000, loss: 0.013550
 >> iter 17000, loss: 0.009972
 >> iter 18000, loss: 0.008195
 >> iter 19000, loss: 0.006958
 >> iter 20000, loss: 0.006235
   Number of active neurons: 10
 >> iter 21000, loss: 0.005638
 >> iter 22000, loss: 0.005194
 >> iter 23000, loss: 0.004764
 >> iter 24000, loss: 0.004467
 >> iter 25000, loss: 0.012285
 >> iter 26000, loss: 0.007524
 >> iter 27000, loss: 0.005210
 >> iter 28000, loss: 0.004187
 >> iter 29000, loss: 0.003601
 >> iter 30000, loss: 0.003321
   Number of active neurons: 10
 >> iter 31000, loss: 0.003076
 >> iter 32000, loss: 0.002919
 >> iter 33000, loss: 0.002735
 >> iter 34000, loss: 0.002629
 >> iter 35000, loss: 0.002481
 >> iter 36000, loss: 0.002392
 >> iter 37000, loss: 0.002261
 >> iter 38000, loss: 0.002211
 >> iter 39000, loss: 0.002114
 >> iter 40000, loss: 0.002065
   Number of active neurons: 10
 >> iter 41000, loss: 0.001981
 >> iter 42000, loss: 0.001933
 >> iter 43000, loss: 0.001851
 >> iter 44000, loss: 0.002213
 >> iter 45000, loss: 0.002073
 >> iter 46000, loss: 0.001913
 >> iter 47000, loss: 0.001757
 >> iter 48000, loss: 0.001680
 >> iter 49000, loss: 0.001586
 >> iter 50000, loss: 0.001539
   Number of active neurons: 10
 >> iter 51000, loss: 0.001466
 >> iter 52000, loss: 0.001447
 >> iter 53000, loss: 0.001400
 >> iter 54000, loss: 0.001377
 >> iter 55000, loss: 0.001326
 >> iter 56000, loss: 0.001314
 >> iter 57000, loss: 0.001266
 >> iter 58000, loss: 0.001251
 >> iter 59000, loss: 0.001206
 >> iter 60000, loss: 0.001194
   Number of active neurons: 10
 >> iter 61000, loss: 0.001158
 >> iter 62000, loss: 0.001160
 >> iter 63000, loss: 0.001127
 >> iter 64000, loss: 0.001111
 >> iter 65000, loss: 0.001125
 >> iter 66000, loss: 0.001131
 >> iter 67000, loss: 0.001075
 >> iter 68000, loss: 0.001050
 >> iter 69000, loss: 0.001015
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.561080
 >> iter 2000, loss: 10.506725
 >> iter 3000, loss: 8.642642
 >> iter 4000, loss: 7.918137
 >> iter 5000, loss: 7.404965
 >> iter 6000, loss: 6.528888
 >> iter 7000, loss: 5.786059
 >> iter 8000, loss: 3.054470
 >> iter 9000, loss: 1.221779
 >> iter 10000, loss: 0.481532
   Number of active neurons: 10
 >> iter 11000, loss: 0.199176
 >> iter 12000, loss: 0.089662
 >> iter 13000, loss: 0.046235
 >> iter 14000, loss: 0.027893
 >> iter 15000, loss: 0.019637
 >> iter 16000, loss: 0.015265
 >> iter 17000, loss: 0.012827
 >> iter 18000, loss: 0.011138
 >> iter 19000, loss: 0.011190
 >> iter 20000, loss: 0.009473
   Number of active neurons: 10
 >> iter 21000, loss: 0.008161
 >> iter 22000, loss: 0.007182
 >> iter 23000, loss: 0.006527
 >> iter 24000, loss: 0.005909
 >> iter 25000, loss: 0.005468
 >> iter 26000, loss: 0.005049
 >> iter 27000, loss: 0.004733
 >> iter 28000, loss: 0.004389
 >> iter 29000, loss: 0.004183
 >> iter 30000, loss: 0.003866
   Number of active neurons: 10
 >> iter 31000, loss: 0.003689
 >> iter 32000, loss: 0.003443
 >> iter 33000, loss: 0.003290
 >> iter 34000, loss: 0.003105
 >> iter 35000, loss: 0.002985
 >> iter 36000, loss: 0.002822
 >> iter 37000, loss: 0.002710
 >> iter 38000, loss: 0.002548
 >> iter 39000, loss: 0.002455
 >> iter 40000, loss: 0.002328
   Number of active neurons: 10
 >> iter 41000, loss: 0.002245
 >> iter 42000, loss: 0.002131
 >> iter 43000, loss: 0.002063
 >> iter 44000, loss: 0.001975
 >> iter 45000, loss: 0.001900
 >> iter 46000, loss: 0.001837
 >> iter 47000, loss: 0.001773
 >> iter 48000, loss: 0.001691
 >> iter 49000, loss: 0.001640
 >> iter 50000, loss: 0.001567
   Number of active neurons: 10
 >> iter 51000, loss: 0.001533
 >> iter 52000, loss: 0.001475
 >> iter 53000, loss: 0.001438
 >> iter 54000, loss: 0.001390
 >> iter 55000, loss: 0.001354
 >> iter 56000, loss: 0.001310
 >> iter 57000, loss: 0.001279
 >> iter 58000, loss: 0.001229
 >> iter 59000, loss: 0.001204
 >> iter 60000, loss: 0.001163
   Number of active neurons: 10
 >> iter 61000, loss: 0.001138
 >> iter 62000, loss: 0.001099
 >> iter 63000, loss: 0.001078
 >> iter 64000, loss: 0.001042
 >> iter 65000, loss: 0.001022
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.571253
 >> iter 2000, loss: 10.514116
 >> iter 3000, loss: 8.647205
 >> iter 4000, loss: 7.937046
 >> iter 5000, loss: 7.681605
 >> iter 6000, loss: 7.568928
 >> iter 7000, loss: 7.536242
 >> iter 8000, loss: 7.373454
 >> iter 9000, loss: 5.696698
 >> iter 10000, loss: 2.153311
   Number of active neurons: 10
 >> iter 11000, loss: 0.815353
 >> iter 12000, loss: 0.314879
 >> iter 13000, loss: 0.126771
 >> iter 14000, loss: 0.055249
 >> iter 15000, loss: 0.027378
 >> iter 16000, loss: 0.016045
 >> iter 17000, loss: 0.011037
 >> iter 18000, loss: 0.008599
 >> iter 19000, loss: 0.007171
 >> iter 20000, loss: 0.006281
   Number of active neurons: 10
 >> iter 21000, loss: 0.005585
 >> iter 22000, loss: 0.005090
 >> iter 23000, loss: 0.004643
 >> iter 24000, loss: 0.004281
 >> iter 25000, loss: 0.003964
 >> iter 26000, loss: 0.003698
 >> iter 27000, loss: 0.003466
 >> iter 28000, loss: 0.003274
 >> iter 29000, loss: 0.003065
 >> iter 30000, loss: 0.002911
   Number of active neurons: 10
 >> iter 31000, loss: 0.002740
 >> iter 32000, loss: 0.002621
 >> iter 33000, loss: 0.002486
 >> iter 34000, loss: 0.002385
 >> iter 35000, loss: 0.002274
 >> iter 36000, loss: 0.002189
 >> iter 37000, loss: 0.002098
 >> iter 38000, loss: 0.002026
 >> iter 39000, loss: 0.001936
 >> iter 40000, loss: 0.001878
   Number of active neurons: 10
 >> iter 41000, loss: 0.001808
 >> iter 42000, loss: 0.001751
 >> iter 43000, loss: 0.001688
 >> iter 44000, loss: 0.001638
 >> iter 45000, loss: 0.001582
 >> iter 46000, loss: 0.001543
 >> iter 47000, loss: 0.001488
 >> iter 48000, loss: 0.001452
 >> iter 49000, loss: 0.001406
 >> iter 50000, loss: 0.001374
   Number of active neurons: 10
 >> iter 51000, loss: 0.001331
 >> iter 52000, loss: 0.001306
 >> iter 53000, loss: 0.001269
 >> iter 54000, loss: 0.001237
 >> iter 55000, loss: 0.001201
 >> iter 56000, loss: 0.001179
 >> iter 57000, loss: 0.001145
 >> iter 58000, loss: 0.001127
 >> iter 59000, loss: 0.001096
 >> iter 60000, loss: 0.001081
   Number of active neurons: 10
 >> iter 61000, loss: 0.001051
 >> iter 62000, loss: 0.001034
 >> iter 63000, loss: 0.001004
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.545517
 >> iter 2000, loss: 10.505227
 >> iter 3000, loss: 8.654174
 >> iter 4000, loss: 7.947802
 >> iter 5000, loss: 7.724290
 >> iter 6000, loss: 7.478124
 >> iter 7000, loss: 6.742185
 >> iter 8000, loss: 5.880254
 >> iter 9000, loss: 3.820344
 >> iter 10000, loss: 1.601822
   Number of active neurons: 10
 >> iter 11000, loss: 0.652486
 >> iter 12000, loss: 0.286827
 >> iter 13000, loss: 0.129126
 >> iter 14000, loss: 0.065238
 >> iter 15000, loss: 0.038328
 >> iter 16000, loss: 0.025852
 >> iter 17000, loss: 0.019646
 >> iter 18000, loss: 0.015741
 >> iter 19000, loss: 0.013208
 >> iter 20000, loss: 0.011248
   Number of active neurons: 10
 >> iter 21000, loss: 0.009973
 >> iter 22000, loss: 0.009303
 >> iter 23000, loss: 0.008409
 >> iter 24000, loss: 0.007567
 >> iter 25000, loss: 0.006901
 >> iter 26000, loss: 0.006378
 >> iter 27000, loss: 0.005907
 >> iter 28000, loss: 0.005544
 >> iter 29000, loss: 0.005298
 >> iter 30000, loss: 0.004984
   Number of active neurons: 10
 >> iter 31000, loss: 0.004739
 >> iter 32000, loss: 0.004484
 >> iter 33000, loss: 0.004302
 >> iter 34000, loss: 0.004079
 >> iter 35000, loss: 0.003958
 >> iter 36000, loss: 0.003775
 >> iter 37000, loss: 0.003693
 >> iter 38000, loss: 0.003542
 >> iter 39000, loss: 0.003467
 >> iter 40000, loss: 0.003321
   Number of active neurons: 10
 >> iter 41000, loss: 0.003200
 >> iter 42000, loss: 0.003106
 >> iter 43000, loss: 0.003012
 >> iter 44000, loss: 0.002917
 >> iter 45000, loss: 0.002864
 >> iter 46000, loss: 0.002783
 >> iter 47000, loss: 0.002738
 >> iter 48000, loss: 0.002651
 >> iter 49000, loss: 0.002549
 >> iter 50000, loss: 0.002489
   Number of active neurons: 10
 >> iter 51000, loss: 0.002400
 >> iter 52000, loss: 0.002352
 >> iter 53000, loss: 0.002282
 >> iter 54000, loss: 0.002242
 >> iter 55000, loss: 0.002191
 >> iter 56000, loss: 0.002149
 >> iter 57000, loss: 0.002118
 >> iter 58000, loss: 0.002098
 >> iter 59000, loss: 0.002047
 >> iter 60000, loss: 0.001987
   Number of active neurons: 10
 >> iter 61000, loss: 0.001955
 >> iter 62000, loss: 0.001898
 >> iter 63000, loss: 0.001879
 >> iter 64000, loss: 0.001863
 >> iter 65000, loss: 0.001794
 >> iter 66000, loss: 0.001773
 >> iter 67000, loss: 0.001716
 >> iter 68000, loss: 0.001707
 >> iter 69000, loss: 0.001631
 >> iter 70000, loss: 0.001624
   Number of active neurons: 10
 >> iter 71000, loss: 0.001586
 >> iter 72000, loss: 0.001567
 >> iter 73000, loss: 0.001545
 >> iter 74000, loss: 0.001509
 >> iter 75000, loss: 0.001493
 >> iter 76000, loss: 0.001490
 >> iter 77000, loss: 0.001443
 >> iter 78000, loss: 0.001459
 >> iter 79000, loss: 0.001421
 >> iter 80000, loss: 0.001387
   Number of active neurons: 10
 >> iter 81000, loss: 0.001338
 >> iter 82000, loss: 0.001329
 >> iter 83000, loss: 0.001315
 >> iter 84000, loss: 0.001306
 >> iter 85000, loss: 0.001299
 >> iter 86000, loss: 0.001275
 >> iter 87000, loss: 0.001236
 >> iter 88000, loss: 0.001213
 >> iter 89000, loss: 0.001182
 >> iter 90000, loss: 0.001177
   Number of active neurons: 10
 >> iter 91000, loss: 0.001167
 >> iter 92000, loss: 0.001205
 >> iter 93000, loss: 0.001144
 >> iter 94000, loss: 0.001123
 >> iter 95000, loss: 0.001131
 >> iter 96000, loss: 0.001102
 >> iter 97000, loss: 0.001101
 >> iter 98000, loss: 0.001064
 >> iter 99000, loss: 0.001060
 >> iter 100000, loss: 0.001054
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 5.51296580228
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.542596
 >> iter 2000, loss: 10.502538
 >> iter 3000, loss: 8.641447
 >> iter 4000, loss: 7.935329
 >> iter 5000, loss: 7.596312
 >> iter 6000, loss: 6.527717
 >> iter 7000, loss: 2.527959
 >> iter 8000, loss: 0.970296
 >> iter 9000, loss: 0.381735
 >> iter 10000, loss: 0.157594
   Number of active neurons: 10
 >> iter 11000, loss: 0.071360
 >> iter 12000, loss: 0.036730
 >> iter 13000, loss: 0.022325
 >> iter 14000, loss: 0.015590
 >> iter 15000, loss: 0.012236
 >> iter 16000, loss: 0.010185
 >> iter 17000, loss: 0.008863
 >> iter 18000, loss: 0.007889
 >> iter 19000, loss: 0.007133
 >> iter 20000, loss: 0.006472
   Number of active neurons: 10
 >> iter 21000, loss: 0.006024
 >> iter 22000, loss: 0.005557
 >> iter 23000, loss: 0.005185
 >> iter 24000, loss: 0.004832
 >> iter 25000, loss: 0.004579
 >> iter 26000, loss: 0.004313
 >> iter 27000, loss: 0.004093
 >> iter 28000, loss: 0.003867
 >> iter 29000, loss: 0.003703
 >> iter 30000, loss: 0.003499
   Number of active neurons: 10
 >> iter 31000, loss: 0.003352
 >> iter 32000, loss: 0.003203
 >> iter 33000, loss: 0.003093
 >> iter 34000, loss: 0.002966
 >> iter 35000, loss: 0.002867
 >> iter 36000, loss: 0.002755
 >> iter 37000, loss: 0.003429
 >> iter 38000, loss: 0.003129
 >> iter 39000, loss: 0.002909
 >> iter 40000, loss: 0.002705
   Number of active neurons: 10
 >> iter 41000, loss: 0.002560
 >> iter 42000, loss: 0.002425
 >> iter 43000, loss: 0.002333
 >> iter 44000, loss: 0.002243
 >> iter 45000, loss: 0.002161
 >> iter 46000, loss: 0.002080
 >> iter 47000, loss: 0.002015
 >> iter 48000, loss: 0.001945
 >> iter 49000, loss: 0.001889
 >> iter 50000, loss: 0.001847
   Number of active neurons: 10
 >> iter 51000, loss: 0.001789
 >> iter 52000, loss: 0.001740
 >> iter 53000, loss: 0.001700
 >> iter 54000, loss: 0.001642
 >> iter 55000, loss: 0.001604
 >> iter 56000, loss: 0.001563
 >> iter 57000, loss: 0.001539
 >> iter 58000, loss: 0.001497
 >> iter 59000, loss: 0.001463
 >> iter 60000, loss: 0.001439
   Number of active neurons: 10
 >> iter 61000, loss: 0.001405
 >> iter 62000, loss: 0.001387
 >> iter 63000, loss: 0.001352
 >> iter 64000, loss: 0.001441
 >> iter 65000, loss: 0.001364
 >> iter 66000, loss: 0.001297
 >> iter 67000, loss: 0.001247
 >> iter 68000, loss: 0.001213
 >> iter 69000, loss: 0.001217
 >> iter 70000, loss: 0.001176
   Number of active neurons: 10
 >> iter 71000, loss: 0.001144
 >> iter 72000, loss: 0.001126
 >> iter 73000, loss: 0.001105
 >> iter 74000, loss: 0.001078
 >> iter 75000, loss: 0.001056
 >> iter 76000, loss: 0.001038
 >> iter 77000, loss: 0.001024
 >> iter 78000, loss: 0.001005
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 15.547355
 >> iter 2000, loss: 10.495579
 >> iter 3000, loss: 8.626527
 >> iter 4000, loss: 7.884187
 >> iter 5000, loss: 7.190411
 >> iter 6000, loss: 6.216564
 >> iter 7000, loss: 2.939014
 >> iter 8000, loss: 1.113901
 >> iter 9000, loss: 0.428254
 >> iter 10000, loss: 0.170423
   Number of active neurons: 9
 >> iter 11000, loss: 0.072568
 >> iter 12000, loss: 0.034596
 >> iter 13000, loss: 0.019335
 >> iter 14000, loss: 0.012795
 >> iter 15000, loss: 0.009688
 >> iter 16000, loss: 0.007948
 >> iter 17000, loss: 0.007093
 >> iter 18000, loss: 0.006220
 >> iter 19000, loss: 0.005552
 >> iter 20000, loss: 0.005058
   Number of active neurons: 10
 >> iter 21000, loss: 0.004666
 >> iter 22000, loss: 0.004333
 >> iter 23000, loss: 0.004034
 >> iter 24000, loss: 0.003759
 >> iter 25000, loss: 0.003534
 >> iter 26000, loss: 0.003331
 >> iter 27000, loss: 0.003169
 >> iter 28000, loss: 0.003003
 >> iter 29000, loss: 0.002872
 >> iter 30000, loss: 0.002728
   Number of active neurons: 10
 >> iter 31000, loss: 0.002693
 >> iter 32000, loss: 0.002570
 >> iter 33000, loss: 0.002442
 >> iter 34000, loss: 0.002294
 >> iter 35000, loss: 0.002218
 >> iter 36000, loss: 0.002135
 >> iter 37000, loss: 0.002063
 >> iter 38000, loss: 0.001978
 >> iter 39000, loss: 0.001969
 >> iter 40000, loss: 0.001931
   Number of active neurons: 10
 >> iter 41000, loss: 0.001860
 >> iter 42000, loss: 0.001775
 >> iter 43000, loss: 0.001713
 >> iter 44000, loss: 0.001652
 >> iter 45000, loss: 0.001623
 >> iter 46000, loss: 0.001565
 >> iter 47000, loss: 0.001521
 >> iter 48000, loss: 0.001475
 >> iter 49000, loss: 0.001463
 >> iter 50000, loss: 0.001411
   Number of active neurons: 10
 >> iter 51000, loss: 0.001380
 >> iter 52000, loss: 0.001347
 >> iter 53000, loss: 0.001317
 >> iter 54000, loss: 0.001287
 >> iter 55000, loss: 0.001255
 >> iter 56000, loss: 0.001246
 >> iter 57000, loss: 0.001240
 >> iter 58000, loss: 0.001198
 >> iter 59000, loss: 0.001172
 >> iter 60000, loss: 0.001135
   Number of active neurons: 10
 >> iter 61000, loss: 0.001114
 >> iter 62000, loss: 0.001083
 >> iter 63000, loss: 0.001133
 >> iter 64000, loss: 0.001178
 >> iter 65000, loss: 0.001157
 >> iter 66000, loss: 0.001112
 >> iter 67000, loss: 0.001074
 >> iter 68000, loss: 0.001033
 >> iter 69000, loss: 0.001006
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

