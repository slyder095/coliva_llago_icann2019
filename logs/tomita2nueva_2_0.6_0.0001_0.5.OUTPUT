 > Problema: tomita2nueva
 > Args:
   - Hidden size: 2
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 12.010587
 >> iter 2000, loss: 5.706620
 >> iter 3000, loss: 3.451336
 >> iter 4000, loss: 2.527852
 >> iter 5000, loss: 2.241495
 >> iter 6000, loss: 2.079304
 >> iter 7000, loss: 2.083791
 >> iter 8000, loss: 1.995707
 >> iter 9000, loss: 2.058488
 >> iter 10000, loss: 1.988398
   Number of active neurons: 2
 >> iter 11000, loss: 2.025436
 >> iter 12000, loss: 1.971869
 >> iter 13000, loss: 2.039189
 >> iter 14000, loss: 1.965664
 >> iter 15000, loss: 2.003723
 >> iter 16000, loss: 1.954980
 >> iter 17000, loss: 2.025638
 >> iter 18000, loss: 1.954876
 >> iter 19000, loss: 2.008496
 >> iter 20000, loss: 1.949356
   Number of active neurons: 2
 >> iter 21000, loss: 2.018956
 >> iter 22000, loss: 1.941571
 >> iter 23000, loss: 2.014387
 >> iter 24000, loss: 1.945041
 >> iter 25000, loss: 1.991708
 >> iter 26000, loss: 1.923918
 >> iter 27000, loss: 1.998105
 >> iter 28000, loss: 1.936530
 >> iter 29000, loss: 1.987969
 >> iter 30000, loss: 1.940984
   Number of active neurons: 2
 >> iter 31000, loss: 2.001005
 >> iter 32000, loss: 1.920304
 >> iter 33000, loss: 1.970602
 >> iter 34000, loss: 1.924147
 >> iter 35000, loss: 1.994714
 >> iter 36000, loss: 1.931584
 >> iter 37000, loss: 1.985807
 >> iter 38000, loss: 1.925937
 >> iter 39000, loss: 2.003873
 >> iter 40000, loss: 1.949409
   Number of active neurons: 2
 >> iter 41000, loss: 2.006885
 >> iter 42000, loss: 1.938956
 >> iter 43000, loss: 1.995728
 >> iter 44000, loss: 1.921167
 >> iter 45000, loss: 1.954984
 >> iter 46000, loss: 1.899162
 >> iter 47000, loss: 1.954534
 >> iter 48000, loss: 1.912069
 >> iter 49000, loss: 1.978644
 >> iter 50000, loss: 1.925364
   Number of active neurons: 2
 >> iter 51000, loss: 1.967706
 >> iter 52000, loss: 1.919013
 >> iter 53000, loss: 1.976571
 >> iter 54000, loss: 1.933953
 >> iter 55000, loss: 1.995282
 >> iter 56000, loss: 1.932749
 >> iter 57000, loss: 1.971961
 >> iter 58000, loss: 1.937654
 >> iter 59000, loss: 1.968730
 >> iter 60000, loss: 1.922878
   Number of active neurons: 2
 >> iter 61000, loss: 1.992015
 >> iter 62000, loss: 1.936193
 >> iter 63000, loss: 1.971913
 >> iter 64000, loss: 1.927756
 >> iter 65000, loss: 1.963437
 >> iter 66000, loss: 1.916888
 >> iter 67000, loss: 1.974072
 >> iter 68000, loss: 1.917785
 >> iter 69000, loss: 1.974547
 >> iter 70000, loss: 1.915669
   Number of active neurons: 2
 >> iter 71000, loss: 1.966237
 >> iter 72000, loss: 1.931409
 >> iter 73000, loss: 1.972462
 >> iter 74000, loss: 1.938578
 >> iter 75000, loss: 1.961407
 >> iter 76000, loss: 1.921380
 >> iter 77000, loss: 1.953686
 >> iter 78000, loss: 1.924262
 >> iter 79000, loss: 1.975555
 >> iter 80000, loss: 1.913235
   Number of active neurons: 2
 >> iter 81000, loss: 1.963442
 >> iter 82000, loss: 1.913090
 >> iter 83000, loss: 1.955151
 >> iter 84000, loss: 1.926471
 >> iter 85000, loss: 1.977834
 >> iter 86000, loss: 1.934265
 >> iter 87000, loss: 1.980991
 >> iter 88000, loss: 1.926719
 >> iter 89000, loss: 1.966301
 >> iter 90000, loss: 1.918261
   Number of active neurons: 2
 >> iter 91000, loss: 1.929380
 >> iter 92000, loss: 1.892336
 >> iter 93000, loss: 1.940816
 >> iter 94000, loss: 1.899658
 >> iter 95000, loss: 1.950613
 >> iter 96000, loss: 1.917815
 >> iter 97000, loss: 1.978641
 >> iter 98000, loss: 1.907751
 >> iter 99000, loss: 1.950467
 >> iter 100000, loss: 1.908980
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 2.69794604108
   - Test - Long: 0.304984750762
   - Test - Big: 2.50297497025
   - Test - A: 0.00666622225185
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 12.299237
 >> iter 2000, loss: 5.803360
 >> iter 3000, loss: 3.485354
 >> iter 4000, loss: 2.530003
 >> iter 5000, loss: 2.264397
 >> iter 6000, loss: 2.080336
 >> iter 7000, loss: 2.094928
 >> iter 8000, loss: 2.008476
 >> iter 9000, loss: 2.044209
 >> iter 10000, loss: 1.990791
   Number of active neurons: 2
 >> iter 11000, loss: 2.029314
 >> iter 12000, loss: 1.960800
 >> iter 13000, loss: 2.018054
 >> iter 14000, loss: 1.961504
 >> iter 15000, loss: 2.023882
 >> iter 16000, loss: 1.952308
 >> iter 17000, loss: 2.032407
 >> iter 18000, loss: 1.962517
 >> iter 19000, loss: 2.016543
 >> iter 20000, loss: 1.966109
   Number of active neurons: 2
 >> iter 21000, loss: 2.014447
 >> iter 22000, loss: 1.945220
 >> iter 23000, loss: 2.002930
 >> iter 24000, loss: 1.937137
 >> iter 25000, loss: 1.983383
 >> iter 26000, loss: 1.941212
 >> iter 27000, loss: 2.004098
 >> iter 28000, loss: 1.920816
 >> iter 29000, loss: 1.998361
 >> iter 30000, loss: 1.930900
   Number of active neurons: 2
 >> iter 31000, loss: 1.993356
 >> iter 32000, loss: 1.936467
 >> iter 33000, loss: 2.000400
 >> iter 34000, loss: 1.942165
 >> iter 35000, loss: 1.997551
 >> iter 36000, loss: 1.934574
 >> iter 37000, loss: 1.982925
 >> iter 38000, loss: 1.921080
 >> iter 39000, loss: 1.976897
 >> iter 40000, loss: 1.916945
   Number of active neurons: 2
 >> iter 41000, loss: 1.959303
 >> iter 42000, loss: 1.925195
 >> iter 43000, loss: 1.976192
 >> iter 44000, loss: 1.925526
 >> iter 45000, loss: 1.993604
 >> iter 46000, loss: 1.926312
 >> iter 47000, loss: 1.983169
 >> iter 48000, loss: 1.925904
 >> iter 49000, loss: 1.998698
 >> iter 50000, loss: 1.931160
   Number of active neurons: 2
 >> iter 51000, loss: 1.984205
 >> iter 52000, loss: 1.928954
 >> iter 53000, loss: 1.978304
 >> iter 54000, loss: 1.919056
 >> iter 55000, loss: 1.970208
 >> iter 56000, loss: 1.925258
 >> iter 57000, loss: 1.971807
 >> iter 58000, loss: 1.927744
 >> iter 59000, loss: 1.960339
 >> iter 60000, loss: 1.916381
   Number of active neurons: 2
 >> iter 61000, loss: 1.957450
 >> iter 62000, loss: 1.916318
 >> iter 63000, loss: 1.974852
 >> iter 64000, loss: 1.913079
 >> iter 65000, loss: 1.966289
 >> iter 66000, loss: 1.927602
 >> iter 67000, loss: 1.952126
 >> iter 68000, loss: 1.922807
 >> iter 69000, loss: 1.978826
 >> iter 70000, loss: 1.928370
   Number of active neurons: 2
 >> iter 71000, loss: 1.965308
 >> iter 72000, loss: 1.917803
 >> iter 73000, loss: 1.971111
 >> iter 74000, loss: 1.917456
 >> iter 75000, loss: 1.971283
 >> iter 76000, loss: 1.932839
 >> iter 77000, loss: 1.974507
 >> iter 78000, loss: 1.934728
 >> iter 79000, loss: 1.980893
 >> iter 80000, loss: 1.944708
   Number of active neurons: 2
 >> iter 81000, loss: 1.987463
 >> iter 82000, loss: 1.914252
 >> iter 83000, loss: 1.959776
 >> iter 84000, loss: 1.906090
 >> iter 85000, loss: 1.945448
 >> iter 86000, loss: 1.917879
 >> iter 87000, loss: 1.962667
 >> iter 88000, loss: 1.907877
 >> iter 89000, loss: 1.960995
 >> iter 90000, loss: 1.900952
   Number of active neurons: 2
 >> iter 91000, loss: 1.952055
 >> iter 92000, loss: 1.911930
 >> iter 93000, loss: 1.971141
 >> iter 94000, loss: 1.910408
 >> iter 95000, loss: 1.964885
 >> iter 96000, loss: 1.913184
 >> iter 97000, loss: 1.955196
 >> iter 98000, loss: 1.924978
 >> iter 99000, loss: 1.953175
 >> iter 100000, loss: 1.917985
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 2.69794604108
   - Test - Long: 0.304984750762
   - Test - Big: 2.50297497025
   - Test - A: 0.00666622225185
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 12.084766
 >> iter 2000, loss: 5.494588
 >> iter 3000, loss: 2.184101
 >> iter 4000, loss: 0.864525
 >> iter 5000, loss: 0.377672
 >> iter 6000, loss: 0.179500
 >> iter 7000, loss: 0.106037
 >> iter 8000, loss: 0.080362
 >> iter 9000, loss: 0.058961
 >> iter 10000, loss: 0.055912
   Number of active neurons: 2
 >> iter 11000, loss: 0.050689
 >> iter 12000, loss: 0.050054
 >> iter 13000, loss: 0.040430
 >> iter 14000, loss: 0.040772
 >> iter 15000, loss: 0.046833
 >> iter 16000, loss: 0.040601
 >> iter 17000, loss: 0.055002
 >> iter 18000, loss: 0.062913
 >> iter 19000, loss: 0.051569
 >> iter 20000, loss: 0.051247
   Number of active neurons: 2
 >> iter 21000, loss: 0.042335
 >> iter 22000, loss: 0.039819
 >> iter 23000, loss: 0.039620
 >> iter 24000, loss: 0.037182
 >> iter 25000, loss: 0.063118
 >> iter 26000, loss: 0.071909
 >> iter 27000, loss: 0.079718
 >> iter 28000, loss: 0.043837
 >> iter 29000, loss: 0.063057
 >> iter 30000, loss: 0.049815
   Number of active neurons: 2
 >> iter 31000, loss: 0.050063
 >> iter 32000, loss: 0.053461
 >> iter 33000, loss: 0.048645
 >> iter 34000, loss: 0.048421
 >> iter 35000, loss: 0.046226
 >> iter 36000, loss: 0.048371
 >> iter 37000, loss: 0.059241
 >> iter 38000, loss: 0.053421
 >> iter 39000, loss: 0.046096
 >> iter 40000, loss: 0.050319
   Number of active neurons: 2
 >> iter 41000, loss: 0.045676
 >> iter 42000, loss: 0.050304
 >> iter 43000, loss: 0.035936
 >> iter 44000, loss: 0.041746
 >> iter 45000, loss: 0.044732
 >> iter 46000, loss: 0.053006
 >> iter 47000, loss: 0.035554
 >> iter 48000, loss: 0.042276
 >> iter 49000, loss: 0.038548
 >> iter 50000, loss: 0.035525
   Number of active neurons: 2
 >> iter 51000, loss: 0.047010
 >> iter 52000, loss: 0.039904
 >> iter 53000, loss: 0.056779
 >> iter 54000, loss: 0.044589
 >> iter 55000, loss: 0.041331
 >> iter 56000, loss: 0.045476
 >> iter 57000, loss: 0.049428
 >> iter 58000, loss: 0.056605
 >> iter 59000, loss: 0.044862
 >> iter 60000, loss: 0.031131
   Number of active neurons: 2
 >> iter 61000, loss: 0.037193
 >> iter 62000, loss: 0.055308
 >> iter 63000, loss: 0.038419
 >> iter 64000, loss: 0.047899
 >> iter 65000, loss: 0.036211
 >> iter 66000, loss: 0.047164
 >> iter 67000, loss: 0.060413
 >> iter 68000, loss: 0.074050
 >> iter 69000, loss: 0.051786
 >> iter 70000, loss: 0.047816
   Number of active neurons: 2
 >> iter 71000, loss: 0.046402
 >> iter 72000, loss: 0.055584
 >> iter 73000, loss: 0.041523
 >> iter 74000, loss: 0.041453
 >> iter 75000, loss: 0.042236
 >> iter 76000, loss: 0.044088
 >> iter 77000, loss: 0.037828
 >> iter 78000, loss: 0.033581
 >> iter 79000, loss: 0.040003
 >> iter 80000, loss: 0.040833
   Number of active neurons: 2
 >> iter 81000, loss: 0.064229
 >> iter 82000, loss: 0.044208
 >> iter 83000, loss: 0.047312
 >> iter 84000, loss: 0.054183
 >> iter 85000, loss: 0.050233
 >> iter 86000, loss: 0.069651
 >> iter 87000, loss: 0.066088
 >> iter 88000, loss: 0.067719
 >> iter 89000, loss: 0.052613
 >> iter 90000, loss: 0.050649
   Number of active neurons: 2
 >> iter 91000, loss: 0.047155
 >> iter 92000, loss: 0.048253
 >> iter 93000, loss: 0.042193
 >> iter 94000, loss: 0.052084
 >> iter 95000, loss: 0.043540
 >> iter 96000, loss: 0.052369
 >> iter 97000, loss: 0.046414
 >> iter 98000, loss: 0.036904
 >> iter 99000, loss: 0.035133
 >> iter 100000, loss: 0.034751
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 12.514496
 >> iter 2000, loss: 6.406503
 >> iter 3000, loss: 4.326132
 >> iter 4000, loss: 3.382320
 >> iter 5000, loss: 3.203325
 >> iter 6000, loss: 2.968370
 >> iter 7000, loss: 3.045843
 >> iter 8000, loss: 2.899112
 >> iter 9000, loss: 3.027039
 >> iter 10000, loss: 2.898669
   Number of active neurons: 1
 >> iter 11000, loss: 3.023589
 >> iter 12000, loss: 2.899011
 >> iter 13000, loss: 3.029039
 >> iter 14000, loss: 2.897176
 >> iter 15000, loss: 3.027578
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 2.358507
 >> iter 17000, loss: 1.070468
 >> iter 18000, loss: 0.453298
 >> iter 19000, loss: 0.214286
 >> iter 20000, loss: 0.113666
   Number of active neurons: 2
 >> iter 21000, loss: 0.107067
 >> iter 22000, loss: 0.083959
 >> iter 23000, loss: 0.083299
 >> iter 24000, loss: 0.082601
 >> iter 25000, loss: 0.054826
 >> iter 26000, loss: 0.044446
 >> iter 27000, loss: 0.052404
 >> iter 28000, loss: 0.038012
 >> iter 29000, loss: 0.056194
 >> iter 30000, loss: 0.048203
   Number of active neurons: 2
 >> iter 31000, loss: 0.068703
 >> iter 32000, loss: 0.062927
 >> iter 33000, loss: 0.081825
 >> iter 34000, loss: 0.051411
 >> iter 35000, loss: 0.040400
 >> iter 36000, loss: 0.057443
 >> iter 37000, loss: 0.045299
 >> iter 38000, loss: 0.038372
 >> iter 39000, loss: 0.037862
 >> iter 40000, loss: 0.030744
   Number of active neurons: 2
 >> iter 41000, loss: 0.039504
 >> iter 42000, loss: 0.051214
 >> iter 43000, loss: 0.038259
 >> iter 44000, loss: 0.047373
 >> iter 45000, loss: 0.055497
 >> iter 46000, loss: 0.035783
 >> iter 47000, loss: 0.046421
 >> iter 48000, loss: 0.070991
 >> iter 49000, loss: 0.063208
 >> iter 50000, loss: 0.050197
   Number of active neurons: 2
 >> iter 51000, loss: 0.042835
 >> iter 52000, loss: 0.043955
 >> iter 53000, loss: 0.042241
 >> iter 54000, loss: 0.045442
 >> iter 55000, loss: 0.049979
 >> iter 56000, loss: 0.048064
 >> iter 57000, loss: 0.039474
 >> iter 58000, loss: 0.043695
 >> iter 59000, loss: 0.061360
 >> iter 60000, loss: 0.046514
   Number of active neurons: 2
 >> iter 61000, loss: 0.034185
 >> iter 62000, loss: 0.029147
 >> iter 63000, loss: 0.032902
 >> iter 64000, loss: 0.045167
 >> iter 65000, loss: 0.044858
 >> iter 66000, loss: 0.045722
 >> iter 67000, loss: 0.035015
 >> iter 68000, loss: 0.065205
 >> iter 69000, loss: 0.045534
 >> iter 70000, loss: 0.041666
   Number of active neurons: 2
 >> iter 71000, loss: 0.044033
 >> iter 72000, loss: 0.032149
 >> iter 73000, loss: 0.037216
 >> iter 74000, loss: 0.035119
 >> iter 75000, loss: 0.037939
 >> iter 76000, loss: 0.042935
 >> iter 77000, loss: 0.042526
 >> iter 78000, loss: 0.056283
 >> iter 79000, loss: 0.078764
 >> iter 80000, loss: 0.049538
   Number of active neurons: 2
 >> iter 81000, loss: 0.044670
 >> iter 82000, loss: 0.059263
 >> iter 83000, loss: 0.064018
 >> iter 84000, loss: 0.047750
 >> iter 85000, loss: 0.035049
 >> iter 86000, loss: 0.027365
 >> iter 87000, loss: 0.034262
 >> iter 88000, loss: 0.037393
 >> iter 89000, loss: 0.042599
 >> iter 90000, loss: 0.057748
   Number of active neurons: 2
 >> iter 91000, loss: 0.043386
 >> iter 92000, loss: 0.032923
 >> iter 93000, loss: 0.039596
 >> iter 94000, loss: 0.031817
 >> iter 95000, loss: 0.034698
 >> iter 96000, loss: 0.062185
 >> iter 97000, loss: 0.062085
 >> iter 98000, loss: 0.048850
 >> iter 99000, loss: 0.044906
 >> iter 100000, loss: 0.038826
   Number of active neurons: 2
 >> iter 101000, loss: 0.041900
 >> iter 102000, loss: 0.041561
 >> iter 103000, loss: 0.035190
 >> iter 104000, loss: 0.032835
 >> iter 105000, loss: 0.074466
 >> iter 106000, loss: 0.052000
 >> iter 107000, loss: 0.035896
 >> iter 108000, loss: 0.033486
 >> iter 109000, loss: 0.041250
 >> iter 110000, loss: 0.049828
   Number of active neurons: 2
 >> iter 111000, loss: 0.040531
 >> iter 112000, loss: 0.049133
 >> iter 113000, loss: 0.049602
 >> iter 114000, loss: 0.040564
 >> iter 115000, loss: 0.032023
 >> iter 116000, loss: 0.027446
 >> iter 117000, loss: 0.042658
 >> iter 118000, loss: 0.027721
 >> iter 119000, loss: 0.050096
 >> iter 120000, loss: 0.038452
   Number of active neurons: 2
 >> iter 121000, loss: 0.034320
 >> iter 122000, loss: 0.033955
 >> iter 123000, loss: 0.034928
 >> iter 124000, loss: 0.038156
 >> iter 125000, loss: 0.033307
 >> iter 126000, loss: 0.024631
 >> iter 127000, loss: 0.037461
 >> iter 128000, loss: 0.040286
 >> iter 129000, loss: 0.036103
 >> iter 130000, loss: 0.039747
   Number of active neurons: 2
 >> iter 131000, loss: 0.046023
 >> iter 132000, loss: 0.049894
 >> iter 133000, loss: 0.043173
 >> iter 134000, loss: 0.044958
 >> iter 135000, loss: 0.034931
 >> iter 136000, loss: 0.039101
 >> iter 137000, loss: 0.032678
 >> iter 138000, loss: 0.054391
 >> iter 139000, loss: 0.054868
 >> iter 140000, loss: 0.040163
   Number of active neurons: 2
 >> iter 141000, loss: 0.030549
 >> iter 142000, loss: 0.032434
 >> iter 143000, loss: 0.034177
 >> iter 144000, loss: 0.029511
 >> iter 145000, loss: 0.038987
 >> iter 146000, loss: 0.049640
 >> iter 147000, loss: 0.036318
 >> iter 148000, loss: 0.048362
 >> iter 149000, loss: 0.043958
 >> iter 150000, loss: 0.069881
   Number of active neurons: 2
 >> iter 151000, loss: 0.041994
 >> iter 152000, loss: 0.048104
 >> iter 153000, loss: 0.035135
 >> iter 154000, loss: 0.034031
 >> iter 155000, loss: 0.049171
 >> iter 156000, loss: 0.036189
 >> iter 157000, loss: 0.048621
 >> iter 158000, loss: 0.049051
 >> iter 159000, loss: 0.054357
 >> iter 160000, loss: 0.051868
   Number of active neurons: 2
 >> iter 161000, loss: 0.056422
 >> iter 162000, loss: 0.055514
 >> iter 163000, loss: 0.046660
 >> iter 164000, loss: 0.032668
 >> iter 165000, loss: 0.046941
 >> iter 166000, loss: 0.041273
 >> iter 167000, loss: 0.037369
 >> iter 168000, loss: 0.036885
 >> iter 169000, loss: 0.054593
 >> iter 170000, loss: 0.051471
   Number of active neurons: 2
 >> iter 171000, loss: 0.052898
 >> iter 172000, loss: 0.050276
 >> iter 173000, loss: 0.034874
 >> iter 174000, loss: 0.025603
 >> iter 175000, loss: 0.044001
 >> iter 176000, loss: 0.039123
 >> iter 177000, loss: 0.034452
 >> iter 178000, loss: 0.037029
 >> iter 179000, loss: 0.036170
 >> iter 180000, loss: 0.055359
   Number of active neurons: 2
 >> iter 181000, loss: 0.041748
 >> iter 182000, loss: 0.031150
 >> iter 183000, loss: 0.038095
 >> iter 184000, loss: 0.048602
 >> iter 185000, loss: 0.037178
 >> iter 186000, loss: 0.035494
 >> iter 187000, loss: 0.054187
 >> iter 188000, loss: 0.050845
 >> iter 189000, loss: 0.032657
 >> iter 190000, loss: 0.050059
   Number of active neurons: 2
 >> iter 191000, loss: 0.040436
 >> iter 192000, loss: 0.039032
 >> iter 193000, loss: 0.045345
 >> iter 194000, loss: 0.035548
 >> iter 195000, loss: 0.061657
 >> iter 196000, loss: 0.048740
 >> iter 197000, loss: 0.041490
 >> iter 198000, loss: 0.055334
 >> iter 199000, loss: 0.036620
 >> iter 200000, loss: 0.035802
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.896720
 >> iter 2000, loss: 4.752562
 >> iter 3000, loss: 1.850279
 >> iter 4000, loss: 0.733501
 >> iter 5000, loss: 0.325774
 >> iter 6000, loss: 0.153300
 >> iter 7000, loss: 0.081062
 >> iter 8000, loss: 0.070303
 >> iter 9000, loss: 0.082283
 >> iter 10000, loss: 0.070573
   Number of active neurons: 2
 >> iter 11000, loss: 0.074826
 >> iter 12000, loss: 0.052193
 >> iter 13000, loss: 0.045478
 >> iter 14000, loss: 0.061223
 >> iter 15000, loss: 0.042456
 >> iter 16000, loss: 0.047607
 >> iter 17000, loss: 0.051666
 >> iter 18000, loss: 0.042413
 >> iter 19000, loss: 0.041260
 >> iter 20000, loss: 0.047159
   Number of active neurons: 2
 >> iter 21000, loss: 0.042597
 >> iter 22000, loss: 0.050984
 >> iter 23000, loss: 0.052348
 >> iter 24000, loss: 0.054577
 >> iter 25000, loss: 0.055950
 >> iter 26000, loss: 0.050757
 >> iter 27000, loss: 0.047198
 >> iter 28000, loss: 0.055416
 >> iter 29000, loss: 0.051896
 >> iter 30000, loss: 0.050157
   Number of active neurons: 2
 >> iter 31000, loss: 0.045133
 >> iter 32000, loss: 0.047714
 >> iter 33000, loss: 0.039172
 >> iter 34000, loss: 0.052204
 >> iter 35000, loss: 0.039690
 >> iter 36000, loss: 0.033712
 >> iter 37000, loss: 0.054471
 >> iter 38000, loss: 0.034234
 >> iter 39000, loss: 0.042004
 >> iter 40000, loss: 0.050670
   Number of active neurons: 2
 >> iter 41000, loss: 0.045320
 >> iter 42000, loss: 0.043115
 >> iter 43000, loss: 0.040324
 >> iter 44000, loss: 0.038686
 >> iter 45000, loss: 0.045233
 >> iter 46000, loss: 0.043247
 >> iter 47000, loss: 0.047140
 >> iter 48000, loss: 0.040879
 >> iter 49000, loss: 0.034377
 >> iter 50000, loss: 0.029307
   Number of active neurons: 2
 >> iter 51000, loss: 0.053755
 >> iter 52000, loss: 0.041026
 >> iter 53000, loss: 0.047452
 >> iter 54000, loss: 0.029510
 >> iter 55000, loss: 0.035386
 >> iter 56000, loss: 0.038676
 >> iter 57000, loss: 0.052215
 >> iter 58000, loss: 0.066935
 >> iter 59000, loss: 0.053657
 >> iter 60000, loss: 0.033058
   Number of active neurons: 2
 >> iter 61000, loss: 0.030533
 >> iter 62000, loss: 0.046477
 >> iter 63000, loss: 0.040282
 >> iter 64000, loss: 0.044460
 >> iter 65000, loss: 0.048220
 >> iter 66000, loss: 0.061569
 >> iter 67000, loss: 0.045109
 >> iter 68000, loss: 0.044319
 >> iter 69000, loss: 0.057756
 >> iter 70000, loss: 0.070816
   Number of active neurons: 2
 >> iter 71000, loss: 0.058142
 >> iter 72000, loss: 0.054335
 >> iter 73000, loss: 0.035008
 >> iter 74000, loss: 0.030323
 >> iter 75000, loss: 0.051657
 >> iter 76000, loss: 0.041355
 >> iter 77000, loss: 0.040285
 >> iter 78000, loss: 0.035176
 >> iter 79000, loss: 0.035222
 >> iter 80000, loss: 0.036311
   Number of active neurons: 2
 >> iter 81000, loss: 0.048418
 >> iter 82000, loss: 0.053276
 >> iter 83000, loss: 0.049285
 >> iter 84000, loss: 0.045998
 >> iter 85000, loss: 0.042176
 >> iter 86000, loss: 0.042303
 >> iter 87000, loss: 0.046428
 >> iter 88000, loss: 0.042067
 >> iter 89000, loss: 0.036790
 >> iter 90000, loss: 0.032720
   Number of active neurons: 2
 >> iter 91000, loss: 0.034821
 >> iter 92000, loss: 0.032285
 >> iter 93000, loss: 0.044251
 >> iter 94000, loss: 0.030837
 >> iter 95000, loss: 0.046332
 >> iter 96000, loss: 0.056820
 >> iter 97000, loss: 0.047405
 >> iter 98000, loss: 0.042348
 >> iter 99000, loss: 0.055284
 >> iter 100000, loss: 0.041713
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 12.280574
 >> iter 2000, loss: 5.804062
 >> iter 3000, loss: 3.480130
 >> iter 4000, loss: 2.531929
 >> iter 5000, loss: 2.275202
 >> iter 6000, loss: 2.065759
 >> iter 7000, loss: 2.096362
 >> iter 8000, loss: 1.995459
 >> iter 9000, loss: 2.052079
 >> iter 10000, loss: 1.988049
   Number of active neurons: 2
 >> iter 11000, loss: 2.037539
 >> iter 12000, loss: 1.972598
 >> iter 13000, loss: 2.027602
 >> iter 14000, loss: 1.953081
 >> iter 15000, loss: 2.023537
 >> iter 16000, loss: 1.963920
 >> iter 17000, loss: 2.007711
 >> iter 18000, loss: 1.952752
 >> iter 19000, loss: 1.996856
 >> iter 20000, loss: 1.952267
   Number of active neurons: 2
 >> iter 21000, loss: 1.990074
 >> iter 22000, loss: 1.924018
 >> iter 23000, loss: 1.988118
 >> iter 24000, loss: 1.928539
 >> iter 25000, loss: 1.995776
 >> iter 26000, loss: 1.946650
 >> iter 27000, loss: 1.991448
 >> iter 28000, loss: 1.945574
 >> iter 29000, loss: 1.995798
 >> iter 30000, loss: 1.921656
   Number of active neurons: 2
 >> iter 31000, loss: 1.979209
 >> iter 32000, loss: 1.932793
 >> iter 33000, loss: 1.978973
 >> iter 34000, loss: 1.927373
 >> iter 35000, loss: 1.983557
 >> iter 36000, loss: 1.921704
 >> iter 37000, loss: 1.980146
 >> iter 38000, loss: 1.911063
 >> iter 39000, loss: 1.964660
 >> iter 40000, loss: 1.921778
   Number of active neurons: 2
 >> iter 41000, loss: 1.978235
 >> iter 42000, loss: 1.915361
 >> iter 43000, loss: 1.978214
 >> iter 44000, loss: 1.921560
 >> iter 45000, loss: 1.984434
 >> iter 46000, loss: 1.915225
 >> iter 47000, loss: 1.970218
 >> iter 48000, loss: 1.932608
 >> iter 49000, loss: 1.969175
 >> iter 50000, loss: 1.908446
   Number of active neurons: 2
 >> iter 51000, loss: 1.956342
 >> iter 52000, loss: 1.922159
 >> iter 53000, loss: 1.976621
 >> iter 54000, loss: 1.940414
 >> iter 55000, loss: 1.975148
 >> iter 56000, loss: 1.927486
 >> iter 57000, loss: 1.971814
 >> iter 58000, loss: 1.920925
 >> iter 59000, loss: 1.971768
 >> iter 60000, loss: 1.907644
   Number of active neurons: 2
 >> iter 61000, loss: 1.959702
 >> iter 62000, loss: 1.894555
 >> iter 63000, loss: 1.958125
 >> iter 64000, loss: 1.910565
 >> iter 65000, loss: 1.977359
 >> iter 66000, loss: 1.920131
 >> iter 67000, loss: 1.986638
 >> iter 68000, loss: 1.930310
 >> iter 69000, loss: 1.986462
 >> iter 70000, loss: 1.925921
   Number of active neurons: 2
 >> iter 71000, loss: 1.958891
 >> iter 72000, loss: 1.935267
 >> iter 73000, loss: 1.974349
 >> iter 74000, loss: 1.908170
 >> iter 75000, loss: 1.959304
 >> iter 76000, loss: 1.916110
 >> iter 77000, loss: 1.964565
 >> iter 78000, loss: 1.904643
 >> iter 79000, loss: 1.960076
 >> iter 80000, loss: 1.914545
   Number of active neurons: 2
 >> iter 81000, loss: 1.959336
 >> iter 82000, loss: 1.912204
 >> iter 83000, loss: 1.963913
 >> iter 84000, loss: 1.916437
 >> iter 85000, loss: 1.953140
 >> iter 86000, loss: 1.926879
 >> iter 87000, loss: 1.948231
 >> iter 88000, loss: 1.910313
 >> iter 89000, loss: 1.947751
 >> iter 90000, loss: 1.918208
   Number of active neurons: 2
 >> iter 91000, loss: 1.974753
 >> iter 92000, loss: 1.912378
 >> iter 93000, loss: 1.946719
 >> iter 94000, loss: 1.923893
 >> iter 95000, loss: 1.942813
 >> iter 96000, loss: 1.908444
 >> iter 97000, loss: 1.956829
 >> iter 98000, loss: 1.914513
 >> iter 99000, loss: 1.957103
 >> iter 100000, loss: 1.919060
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 2.69794604108
   - Test - Long: 0.304984750762
   - Test - Big: 2.50297497025
   - Test - A: 0.00666622225185
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.477181
 >> iter 2000, loss: 4.374300
 >> iter 3000, loss: 1.698341
 >> iter 4000, loss: 0.678153
 >> iter 5000, loss: 0.299221
 >> iter 6000, loss: 0.139998
 >> iter 7000, loss: 0.094081
 >> iter 8000, loss: 0.075027
 >> iter 9000, loss: 0.062869
 >> iter 10000, loss: 0.047985
   Number of active neurons: 2
 >> iter 11000, loss: 0.071626
 >> iter 12000, loss: 0.059321
 >> iter 13000, loss: 0.046689
 >> iter 14000, loss: 0.045430
 >> iter 15000, loss: 0.047727
 >> iter 16000, loss: 0.036611
 >> iter 17000, loss: 0.048361
 >> iter 18000, loss: 0.037153
 >> iter 19000, loss: 0.033999
 >> iter 20000, loss: 0.041868
   Number of active neurons: 2
 >> iter 21000, loss: 0.052743
 >> iter 22000, loss: 0.059702
 >> iter 23000, loss: 0.042886
 >> iter 24000, loss: 0.050749
 >> iter 25000, loss: 0.045260
 >> iter 26000, loss: 0.047116
 >> iter 27000, loss: 0.065245
 >> iter 28000, loss: 0.050426
 >> iter 29000, loss: 0.042081
 >> iter 30000, loss: 0.057128
   Number of active neurons: 2
 >> iter 31000, loss: 0.039636
 >> iter 32000, loss: 0.052064
 >> iter 33000, loss: 0.067356
 >> iter 34000, loss: 0.060301
 >> iter 35000, loss: 0.049232
 >> iter 36000, loss: 0.038420
 >> iter 37000, loss: 0.042535
 >> iter 38000, loss: 0.045218
 >> iter 39000, loss: 0.054101
 >> iter 40000, loss: 0.046857
   Number of active neurons: 2
 >> iter 41000, loss: 0.065891
 >> iter 42000, loss: 0.048463
 >> iter 43000, loss: 0.064773
 >> iter 44000, loss: 0.060569
 >> iter 45000, loss: 0.041682
 >> iter 46000, loss: 0.054793
 >> iter 47000, loss: 0.061705
 >> iter 48000, loss: 0.070332
 >> iter 49000, loss: 0.052736
 >> iter 50000, loss: 0.037628
   Number of active neurons: 2
 >> iter 51000, loss: 0.042317
 >> iter 52000, loss: 0.039405
 >> iter 53000, loss: 0.029599
 >> iter 54000, loss: 0.049355
 >> iter 55000, loss: 0.044322
 >> iter 56000, loss: 0.043204
 >> iter 57000, loss: 0.043011
 >> iter 58000, loss: 0.038157
 >> iter 59000, loss: 0.049887
 >> iter 60000, loss: 0.067524
   Number of active neurons: 2
 >> iter 61000, loss: 0.052544
 >> iter 62000, loss: 0.037552
 >> iter 63000, loss: 0.047431
 >> iter 64000, loss: 0.054015
 >> iter 65000, loss: 0.043241
 >> iter 66000, loss: 0.053084
 >> iter 67000, loss: 0.074406
 >> iter 68000, loss: 0.058622
 >> iter 69000, loss: 0.048132
 >> iter 70000, loss: 0.034514
   Number of active neurons: 2
 >> iter 71000, loss: 0.051310
 >> iter 72000, loss: 0.044220
 >> iter 73000, loss: 0.033392
 >> iter 74000, loss: 0.055256
 >> iter 75000, loss: 0.045544
 >> iter 76000, loss: 0.032383
 >> iter 77000, loss: 0.038913
 >> iter 78000, loss: 0.047473
 >> iter 79000, loss: 0.066933
 >> iter 80000, loss: 0.063974
   Number of active neurons: 2
 >> iter 81000, loss: 0.048375
 >> iter 82000, loss: 0.043544
 >> iter 83000, loss: 0.063940
 >> iter 84000, loss: 0.054079
 >> iter 85000, loss: 0.033669
 >> iter 86000, loss: 0.032493
 >> iter 87000, loss: 0.046802
 >> iter 88000, loss: 0.056504
 >> iter 89000, loss: 0.038949
 >> iter 90000, loss: 0.071930
   Number of active neurons: 2
 >> iter 91000, loss: 0.064018
 >> iter 92000, loss: 0.052068
 >> iter 93000, loss: 0.043838
 >> iter 94000, loss: 0.029704
 >> iter 95000, loss: 0.030336
 >> iter 96000, loss: 0.027044
 >> iter 97000, loss: 0.034048
 >> iter 98000, loss: 0.030465
 >> iter 99000, loss: 0.027735
 >> iter 100000, loss: 0.030156
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.980781
 >> iter 2000, loss: 4.773145
 >> iter 3000, loss: 1.827652
 >> iter 4000, loss: 0.727799
 >> iter 5000, loss: 0.307666
 >> iter 6000, loss: 0.148384
 >> iter 7000, loss: 0.087361
 >> iter 8000, loss: 0.062171
 >> iter 9000, loss: 0.053156
 >> iter 10000, loss: 0.050418
   Number of active neurons: 2
 >> iter 11000, loss: 0.043080
 >> iter 12000, loss: 0.045364
 >> iter 13000, loss: 0.055512
 >> iter 14000, loss: 0.057075
 >> iter 15000, loss: 0.040820
 >> iter 16000, loss: 0.043056
 >> iter 17000, loss: 0.032064
 >> iter 18000, loss: 0.028059
 >> iter 19000, loss: 0.034359
 >> iter 20000, loss: 0.039359
   Number of active neurons: 2
 >> iter 21000, loss: 0.045409
 >> iter 22000, loss: 0.065526
 >> iter 23000, loss: 0.056611
 >> iter 24000, loss: 0.048580
 >> iter 25000, loss: 0.057501
 >> iter 26000, loss: 0.050436
 >> iter 27000, loss: 0.056211
 >> iter 28000, loss: 0.048770
 >> iter 29000, loss: 0.057345
 >> iter 30000, loss: 0.058214
   Number of active neurons: 2
 >> iter 31000, loss: 0.049702
 >> iter 32000, loss: 0.047070
 >> iter 33000, loss: 0.049978
 >> iter 34000, loss: 0.037820
 >> iter 35000, loss: 0.042139
 >> iter 36000, loss: 0.037641
 >> iter 37000, loss: 0.045884
 >> iter 38000, loss: 0.034484
 >> iter 39000, loss: 0.057952
 >> iter 40000, loss: 0.045338
   Number of active neurons: 2
 >> iter 41000, loss: 0.063649
 >> iter 42000, loss: 0.045284
 >> iter 43000, loss: 0.069276
 >> iter 44000, loss: 0.050597
 >> iter 45000, loss: 0.039934
 >> iter 46000, loss: 0.049550
 >> iter 47000, loss: 0.042924
 >> iter 48000, loss: 0.054341
 >> iter 49000, loss: 0.061690
 >> iter 50000, loss: 0.041903
   Number of active neurons: 2
 >> iter 51000, loss: 0.058777
 >> iter 52000, loss: 0.046077
 >> iter 53000, loss: 0.055633
 >> iter 54000, loss: 0.053504
 >> iter 55000, loss: 0.058081
 >> iter 56000, loss: 0.057015
 >> iter 57000, loss: 0.063448
 >> iter 58000, loss: 0.046534
 >> iter 59000, loss: 0.060494
 >> iter 60000, loss: 0.042839
   Number of active neurons: 2
 >> iter 61000, loss: 0.056140
 >> iter 62000, loss: 0.057684
 >> iter 63000, loss: 0.056047
 >> iter 64000, loss: 0.051386
 >> iter 65000, loss: 0.050257
 >> iter 66000, loss: 0.030567
 >> iter 67000, loss: 0.035263
 >> iter 68000, loss: 0.041342
 >> iter 69000, loss: 0.044639
 >> iter 70000, loss: 0.052732
   Number of active neurons: 2
 >> iter 71000, loss: 0.050696
 >> iter 72000, loss: 0.063441
 >> iter 73000, loss: 0.050802
 >> iter 74000, loss: 0.050986
 >> iter 75000, loss: 0.050658
 >> iter 76000, loss: 0.038428
 >> iter 77000, loss: 0.028929
 >> iter 78000, loss: 0.040684
 >> iter 79000, loss: 0.043489
 >> iter 80000, loss: 0.055864
   Number of active neurons: 2
 >> iter 81000, loss: 0.072407
 >> iter 82000, loss: 0.067388
 >> iter 83000, loss: 0.096783
 >> iter 84000, loss: 0.054758
 >> iter 85000, loss: 0.054841
 >> iter 86000, loss: 0.044249
 >> iter 87000, loss: 0.038448
 >> iter 88000, loss: 0.036186
 >> iter 89000, loss: 0.032597
 >> iter 90000, loss: 0.032725
   Number of active neurons: 2
 >> iter 91000, loss: 0.048433
 >> iter 92000, loss: 0.034735
 >> iter 93000, loss: 0.059687
 >> iter 94000, loss: 0.052403
 >> iter 95000, loss: 0.033466
 >> iter 96000, loss: 0.050458
 >> iter 97000, loss: 0.039424
 >> iter 98000, loss: 0.056837
 >> iter 99000, loss: 0.038460
 >> iter 100000, loss: 0.035112
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 12.532026
 >> iter 2000, loss: 6.401848
 >> iter 3000, loss: 4.320286
 >> iter 4000, loss: 3.380167
 >> iter 5000, loss: 3.206397
 >> iter 6000, loss: 2.973178
 >> iter 7000, loss: 3.051821
 >> iter 8000, loss: 2.910314
 >> iter 9000, loss: 3.028476
 >> iter 10000, loss: 2.905926
   Number of active neurons: 1
 >> iter 11000, loss: 3.024551
 >> iter 12000, loss: 2.900547
 >> iter 13000, loss: 3.023052
 >> iter 14000, loss: 2.899537
 >> iter 15000, loss: 3.010232
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 2.917030
 >> iter 17000, loss: 2.911372
 >> iter 18000, loss: 1.420663
 >> iter 19000, loss: 0.612743
 >> iter 20000, loss: 0.292686
   Number of active neurons: 2
 >> iter 21000, loss: 0.142678
 >> iter 22000, loss: 0.096813
 >> iter 23000, loss: 0.085868
 >> iter 24000, loss: 0.068388
 >> iter 25000, loss: 0.070390
 >> iter 26000, loss: 0.056775
 >> iter 27000, loss: 0.055656
 >> iter 28000, loss: 0.058704
 >> iter 29000, loss: 0.048372
 >> iter 30000, loss: 0.051255
   Number of active neurons: 2
 >> iter 31000, loss: 0.052620
 >> iter 32000, loss: 0.048678
 >> iter 33000, loss: 0.043516
 >> iter 34000, loss: 0.033807
 >> iter 35000, loss: 0.044085
 >> iter 36000, loss: 0.046710
 >> iter 37000, loss: 0.040824
 >> iter 38000, loss: 0.035706
 >> iter 39000, loss: 0.065804
 >> iter 40000, loss: 0.053013
   Number of active neurons: 2
 >> iter 41000, loss: 0.056621
 >> iter 42000, loss: 0.078149
 >> iter 43000, loss: 0.046660
 >> iter 44000, loss: 0.047041
 >> iter 45000, loss: 0.047678
 >> iter 46000, loss: 0.061745
 >> iter 47000, loss: 0.072381
 >> iter 48000, loss: 0.059857
 >> iter 49000, loss: 0.048858
 >> iter 50000, loss: 0.046516
   Number of active neurons: 2
 >> iter 51000, loss: 0.046912
 >> iter 52000, loss: 0.048420
 >> iter 53000, loss: 0.054984
 >> iter 54000, loss: 0.055461
 >> iter 55000, loss: 0.049387
 >> iter 56000, loss: 0.044139
 >> iter 57000, loss: 0.048702
 >> iter 58000, loss: 0.036042
 >> iter 59000, loss: 0.036671
 >> iter 60000, loss: 0.038140
   Number of active neurons: 2
 >> iter 61000, loss: 0.040042
 >> iter 62000, loss: 0.034596
 >> iter 63000, loss: 0.028540
 >> iter 64000, loss: 0.046640
 >> iter 65000, loss: 0.065965
 >> iter 66000, loss: 0.042006
 >> iter 67000, loss: 0.036863
 >> iter 68000, loss: 0.047280
 >> iter 69000, loss: 0.061403
 >> iter 70000, loss: 0.038197
   Number of active neurons: 2
 >> iter 71000, loss: 0.075548
 >> iter 72000, loss: 0.047635
 >> iter 73000, loss: 0.047554
 >> iter 74000, loss: 0.041110
 >> iter 75000, loss: 0.043410
 >> iter 76000, loss: 0.038263
 >> iter 77000, loss: 0.050357
 >> iter 78000, loss: 0.060657
 >> iter 79000, loss: 0.049947
 >> iter 80000, loss: 0.038669
   Number of active neurons: 2
 >> iter 81000, loss: 0.038032
 >> iter 82000, loss: 0.035630
 >> iter 83000, loss: 0.044786
 >> iter 84000, loss: 0.052489
 >> iter 85000, loss: 0.043065
 >> iter 86000, loss: 0.051820
 >> iter 87000, loss: 0.042726
 >> iter 88000, loss: 0.046033
 >> iter 89000, loss: 0.037267
 >> iter 90000, loss: 0.063390
   Number of active neurons: 2
 >> iter 91000, loss: 0.057390
 >> iter 92000, loss: 0.070455
 >> iter 93000, loss: 0.052210
 >> iter 94000, loss: 0.038385
 >> iter 95000, loss: 0.036751
 >> iter 96000, loss: 0.036622
 >> iter 97000, loss: 0.031725
 >> iter 98000, loss: 0.031092
 >> iter 99000, loss: 0.032967
 >> iter 100000, loss: 0.032355
   Number of active neurons: 2
 >> iter 101000, loss: 0.041205
 >> iter 102000, loss: 0.052635
 >> iter 103000, loss: 0.071791
 >> iter 104000, loss: 0.043375
 >> iter 105000, loss: 0.058825
 >> iter 106000, loss: 0.041538
 >> iter 107000, loss: 0.048804
 >> iter 108000, loss: 0.055614
 >> iter 109000, loss: 0.064225
 >> iter 110000, loss: 0.047549
   Number of active neurons: 2
 >> iter 111000, loss: 0.043351
 >> iter 112000, loss: 0.062134
 >> iter 113000, loss: 0.060528
 >> iter 114000, loss: 0.062884
 >> iter 115000, loss: 0.041693
 >> iter 116000, loss: 0.058534
 >> iter 117000, loss: 0.046751
 >> iter 118000, loss: 0.055014
 >> iter 119000, loss: 0.040476
 >> iter 120000, loss: 0.046201
   Number of active neurons: 2
 >> iter 121000, loss: 0.046416
 >> iter 122000, loss: 0.036799
 >> iter 123000, loss: 0.035135
 >> iter 124000, loss: 0.031300
 >> iter 125000, loss: 0.032047
 >> iter 126000, loss: 0.036113
 >> iter 127000, loss: 0.028558
 >> iter 128000, loss: 0.036840
 >> iter 129000, loss: 0.034576
 >> iter 130000, loss: 0.033771
   Number of active neurons: 2
 >> iter 131000, loss: 0.033843
 >> iter 132000, loss: 0.036229
 >> iter 133000, loss: 0.037147
 >> iter 134000, loss: 0.031864
 >> iter 135000, loss: 0.041971
 >> iter 136000, loss: 0.040370
 >> iter 137000, loss: 0.034232
 >> iter 138000, loss: 0.051683
 >> iter 139000, loss: 0.068152
 >> iter 140000, loss: 0.053935
   Number of active neurons: 2
 >> iter 141000, loss: 0.052859
 >> iter 142000, loss: 0.047057
 >> iter 143000, loss: 0.052280
 >> iter 144000, loss: 0.037021
 >> iter 145000, loss: 0.050125
 >> iter 146000, loss: 0.035311
 >> iter 147000, loss: 0.048598
 >> iter 148000, loss: 0.049860
 >> iter 149000, loss: 0.066880
 >> iter 150000, loss: 0.059934
   Number of active neurons: 2
 >> iter 151000, loss: 0.045581
 >> iter 152000, loss: 0.041734
 >> iter 153000, loss: 0.034617
 >> iter 154000, loss: 0.044712
 >> iter 155000, loss: 0.056611
 >> iter 156000, loss: 0.048515
 >> iter 157000, loss: 0.040423
 >> iter 158000, loss: 0.043703
 >> iter 159000, loss: 0.043904
 >> iter 160000, loss: 0.040047
   Number of active neurons: 2
 >> iter 161000, loss: 0.041252
 >> iter 162000, loss: 0.036209
 >> iter 163000, loss: 0.040283
 >> iter 164000, loss: 0.037428
 >> iter 165000, loss: 0.037283
 >> iter 166000, loss: 0.028784
 >> iter 167000, loss: 0.050264
 >> iter 168000, loss: 0.044975
 >> iter 169000, loss: 0.030376
 >> iter 170000, loss: 0.036963
   Number of active neurons: 2
 >> iter 171000, loss: 0.025925
 >> iter 172000, loss: 0.038590
 >> iter 173000, loss: 0.044379
 >> iter 174000, loss: 0.046760
 >> iter 175000, loss: 0.045782
 >> iter 176000, loss: 0.034321
 >> iter 177000, loss: 0.032640
 >> iter 178000, loss: 0.023815
 >> iter 179000, loss: 0.037059
 >> iter 180000, loss: 0.031324
   Number of active neurons: 2
 >> iter 181000, loss: 0.043694
 >> iter 182000, loss: 0.038719
 >> iter 183000, loss: 0.050032
 >> iter 184000, loss: 0.049196
 >> iter 185000, loss: 0.035895
 >> iter 186000, loss: 0.045901
 >> iter 187000, loss: 0.053274
 >> iter 188000, loss: 0.057383
 >> iter 189000, loss: 0.070568
 >> iter 190000, loss: 0.057486
   Number of active neurons: 2
 >> iter 191000, loss: 0.038828
 >> iter 192000, loss: 0.041431
 >> iter 193000, loss: 0.047036
 >> iter 194000, loss: 0.039432
 >> iter 195000, loss: 0.047635
 >> iter 196000, loss: 0.031283
 >> iter 197000, loss: 0.054580
 >> iter 198000, loss: 0.052020
 >> iter 199000, loss: 0.047971
 >> iter 200000, loss: 0.038106
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.958396
 >> iter 2000, loss: 5.669566
 >> iter 3000, loss: 3.438090
 >> iter 4000, loss: 2.509786
 >> iter 5000, loss: 2.258107
 >> iter 6000, loss: 2.067421
 >> iter 7000, loss: 2.080602
 >> iter 8000, loss: 2.004634
 >> iter 9000, loss: 2.036807
 >> iter 10000, loss: 1.956984
   Number of active neurons: 2
 >> iter 11000, loss: 2.028699
 >> iter 12000, loss: 1.950552
 >> iter 13000, loss: 2.036021
 >> iter 14000, loss: 1.967755
 >> iter 15000, loss: 2.036501
 >> iter 16000, loss: 1.962539
 >> iter 17000, loss: 2.006936
 >> iter 18000, loss: 1.954656
 >> iter 19000, loss: 2.018554
 >> iter 20000, loss: 1.953198
   Number of active neurons: 2
 >> iter 21000, loss: 2.005870
 >> iter 22000, loss: 1.952607
 >> iter 23000, loss: 1.997930
 >> iter 24000, loss: 1.936401
 >> iter 25000, loss: 1.980097
 >> iter 26000, loss: 1.926230
 >> iter 27000, loss: 1.974396
 >> iter 28000, loss: 1.926485
 >> iter 29000, loss: 1.980848
 >> iter 30000, loss: 1.921069
   Number of active neurons: 2
 >> iter 31000, loss: 2.009010
 >> iter 32000, loss: 1.924672
 >> iter 33000, loss: 1.967783
 >> iter 34000, loss: 1.919522
 >> iter 35000, loss: 1.993044
 >> iter 36000, loss: 1.918329
 >> iter 37000, loss: 1.989297
 >> iter 38000, loss: 1.942760
 >> iter 39000, loss: 2.003218
 >> iter 40000, loss: 1.936705
   Number of active neurons: 2
 >> iter 41000, loss: 1.964225
 >> iter 42000, loss: 1.937422
 >> iter 43000, loss: 1.987636
 >> iter 44000, loss: 1.938242
 >> iter 45000, loss: 1.995849
 >> iter 46000, loss: 1.936258
 >> iter 47000, loss: 1.981863
 >> iter 48000, loss: 1.926282
 >> iter 49000, loss: 1.972343
 >> iter 50000, loss: 1.918800
   Number of active neurons: 2
 >> iter 51000, loss: 1.971234
 >> iter 52000, loss: 1.913827
 >> iter 53000, loss: 1.976827
 >> iter 54000, loss: 1.929831
 >> iter 55000, loss: 1.972349
 >> iter 56000, loss: 1.899248
 >> iter 57000, loss: 1.944800
 >> iter 58000, loss: 1.908071
 >> iter 59000, loss: 1.965790
 >> iter 60000, loss: 1.905410
   Number of active neurons: 2
 >> iter 61000, loss: 1.974743
 >> iter 62000, loss: 1.931915
 >> iter 63000, loss: 1.996094
 >> iter 64000, loss: 1.890549
 >> iter 65000, loss: 1.960148
 >> iter 66000, loss: 1.909219
 >> iter 67000, loss: 1.949743
 >> iter 68000, loss: 1.926808
 >> iter 69000, loss: 1.959745
 >> iter 70000, loss: 1.914258
   Number of active neurons: 2
 >> iter 71000, loss: 1.975344
 >> iter 72000, loss: 1.932874
 >> iter 73000, loss: 1.978204
 >> iter 74000, loss: 1.929482
 >> iter 75000, loss: 1.988649
 >> iter 76000, loss: 1.934980
 >> iter 77000, loss: 1.969081
 >> iter 78000, loss: 1.918024
 >> iter 79000, loss: 1.964552
 >> iter 80000, loss: 1.926165
   Number of active neurons: 2
 >> iter 81000, loss: 1.947479
 >> iter 82000, loss: 1.917834
 >> iter 83000, loss: 1.975329
 >> iter 84000, loss: 1.907376
 >> iter 85000, loss: 1.964269
 >> iter 86000, loss: 1.914646
 >> iter 87000, loss: 1.961609
 >> iter 88000, loss: 1.919298
 >> iter 89000, loss: 1.939630
 >> iter 90000, loss: 1.922158
   Number of active neurons: 2
 >> iter 91000, loss: 1.969083
 >> iter 92000, loss: 1.929409
 >> iter 93000, loss: 1.961186
 >> iter 94000, loss: 1.914679
 >> iter 95000, loss: 1.955309
 >> iter 96000, loss: 1.905805
 >> iter 97000, loss: 1.944399
 >> iter 98000, loss: 1.907797
 >> iter 99000, loss: 1.951636
 >> iter 100000, loss: 1.904348
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 2.69794604108
   - Test - Long: 0.304984750762
   - Test - Big: 2.50297497025
   - Test - A: 0.00666622225185
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.568989
 >> iter 2000, loss: 4.450147
 >> iter 3000, loss: 1.713037
 >> iter 4000, loss: 0.695193
 >> iter 5000, loss: 0.302698
 >> iter 6000, loss: 0.135571
 >> iter 7000, loss: 0.077282
 >> iter 8000, loss: 0.052031
 >> iter 9000, loss: 0.056593
 >> iter 10000, loss: 0.044038
   Number of active neurons: 2
 >> iter 11000, loss: 0.055753
 >> iter 12000, loss: 0.044297
 >> iter 13000, loss: 0.063768
 >> iter 14000, loss: 0.061819
 >> iter 15000, loss: 0.060534
 >> iter 16000, loss: 0.040681
 >> iter 17000, loss: 0.038697
 >> iter 18000, loss: 0.044842
 >> iter 19000, loss: 0.048234
 >> iter 20000, loss: 0.045868
   Number of active neurons: 2
 >> iter 21000, loss: 0.069666
 >> iter 22000, loss: 0.049290
 >> iter 23000, loss: 0.075499
 >> iter 24000, loss: 0.055860
 >> iter 25000, loss: 0.056234
 >> iter 26000, loss: 0.036940
 >> iter 27000, loss: 0.042648
 >> iter 28000, loss: 0.096152
 >> iter 29000, loss: 0.060986
 >> iter 30000, loss: 0.060707
   Number of active neurons: 2
 >> iter 31000, loss: 0.101561
 >> iter 32000, loss: 0.055155
 >> iter 33000, loss: 0.049957
 >> iter 34000, loss: 0.044386
 >> iter 35000, loss: 0.038926
 >> iter 36000, loss: 0.056265
 >> iter 37000, loss: 0.042337
 >> iter 38000, loss: 0.036554
 >> iter 39000, loss: 0.032703
 >> iter 40000, loss: 0.039581
   Number of active neurons: 2
 >> iter 41000, loss: 0.047795
 >> iter 42000, loss: 0.042881
 >> iter 43000, loss: 0.035275
 >> iter 44000, loss: 0.039841
 >> iter 45000, loss: 0.043277
 >> iter 46000, loss: 0.053602
 >> iter 47000, loss: 0.034647
 >> iter 48000, loss: 0.042246
 >> iter 49000, loss: 0.037326
 >> iter 50000, loss: 0.031935
   Number of active neurons: 2
 >> iter 51000, loss: 0.034119
 >> iter 52000, loss: 0.032686
 >> iter 53000, loss: 0.034746
 >> iter 54000, loss: 0.045065
 >> iter 55000, loss: 0.045630
 >> iter 56000, loss: 0.040477
 >> iter 57000, loss: 0.060459
 >> iter 58000, loss: 0.044609
 >> iter 59000, loss: 0.049682
 >> iter 60000, loss: 0.064389
   Number of active neurons: 2
 >> iter 61000, loss: 0.072110
 >> iter 62000, loss: 0.054330
 >> iter 63000, loss: 0.059759
 >> iter 64000, loss: 0.044492
 >> iter 65000, loss: 0.052440
 >> iter 66000, loss: 0.044845
 >> iter 67000, loss: 0.056243
 >> iter 68000, loss: 0.045935
 >> iter 69000, loss: 0.040632
 >> iter 70000, loss: 0.035611
   Number of active neurons: 2
 >> iter 71000, loss: 0.046932
 >> iter 72000, loss: 0.047406
 >> iter 73000, loss: 0.044542
 >> iter 74000, loss: 0.044622
 >> iter 75000, loss: 0.041578
 >> iter 76000, loss: 0.038021
 >> iter 77000, loss: 0.039740
 >> iter 78000, loss: 0.050920
 >> iter 79000, loss: 0.049470
 >> iter 80000, loss: 0.031204
   Number of active neurons: 2
 >> iter 81000, loss: 0.051420
 >> iter 82000, loss: 0.049456
 >> iter 83000, loss: 0.044310
 >> iter 84000, loss: 0.044771
 >> iter 85000, loss: 0.060464
 >> iter 86000, loss: 0.053502
 >> iter 87000, loss: 0.050394
 >> iter 88000, loss: 0.044840
 >> iter 89000, loss: 0.042340
 >> iter 90000, loss: 0.049012
   Number of active neurons: 2
 >> iter 91000, loss: 0.041690
 >> iter 92000, loss: 0.035854
 >> iter 93000, loss: 0.040565
 >> iter 94000, loss: 0.039608
 >> iter 95000, loss: 0.045689
 >> iter 96000, loss: 0.049306
 >> iter 97000, loss: 0.050256
 >> iter 98000, loss: 0.046184
 >> iter 99000, loss: 0.053777
 >> iter 100000, loss: 0.048692
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.689445
 >> iter 2000, loss: 4.469449
 >> iter 3000, loss: 1.720115
 >> iter 4000, loss: 0.709529
 >> iter 5000, loss: 0.303997
 >> iter 6000, loss: 0.178776
 >> iter 7000, loss: 0.113910
 >> iter 8000, loss: 0.084461
 >> iter 9000, loss: 0.087446
 >> iter 10000, loss: 0.056042
   Number of active neurons: 2
 >> iter 11000, loss: 0.057253
 >> iter 12000, loss: 0.037413
 >> iter 13000, loss: 0.046904
 >> iter 14000, loss: 0.051882
 >> iter 15000, loss: 0.036491
 >> iter 16000, loss: 0.037253
 >> iter 17000, loss: 0.042632
 >> iter 18000, loss: 0.047781
 >> iter 19000, loss: 0.057467
 >> iter 20000, loss: 0.054329
   Number of active neurons: 2
 >> iter 21000, loss: 0.039600
 >> iter 22000, loss: 0.050372
 >> iter 23000, loss: 0.066463
 >> iter 24000, loss: 0.056810
 >> iter 25000, loss: 0.041241
 >> iter 26000, loss: 0.047128
 >> iter 27000, loss: 0.036723
 >> iter 28000, loss: 0.033763
 >> iter 29000, loss: 0.037706
 >> iter 30000, loss: 0.032954
   Number of active neurons: 2
 >> iter 31000, loss: 0.043123
 >> iter 32000, loss: 0.029905
 >> iter 33000, loss: 0.042659
 >> iter 34000, loss: 0.062330
 >> iter 35000, loss: 0.040198
 >> iter 36000, loss: 0.037740
 >> iter 37000, loss: 0.039534
 >> iter 38000, loss: 0.051622
 >> iter 39000, loss: 0.066874
 >> iter 40000, loss: 0.062792
   Number of active neurons: 2
 >> iter 41000, loss: 0.049092
 >> iter 42000, loss: 0.039296
 >> iter 43000, loss: 0.037946
 >> iter 44000, loss: 0.034167
 >> iter 45000, loss: 0.040229
 >> iter 46000, loss: 0.030585
 >> iter 47000, loss: 0.046593
 >> iter 48000, loss: 0.044624
 >> iter 49000, loss: 0.043470
 >> iter 50000, loss: 0.035316
   Number of active neurons: 2
 >> iter 51000, loss: 0.039435
 >> iter 52000, loss: 0.050964
 >> iter 53000, loss: 0.043783
 >> iter 54000, loss: 0.046589
 >> iter 55000, loss: 0.035293
 >> iter 56000, loss: 0.032570
 >> iter 57000, loss: 0.049945
 >> iter 58000, loss: 0.041217
 >> iter 59000, loss: 0.039037
 >> iter 60000, loss: 0.036925
   Number of active neurons: 2
 >> iter 61000, loss: 0.047214
 >> iter 62000, loss: 0.041768
 >> iter 63000, loss: 0.053284
 >> iter 64000, loss: 0.054966
 >> iter 65000, loss: 0.047865
 >> iter 66000, loss: 0.040076
 >> iter 67000, loss: 0.050904
 >> iter 68000, loss: 0.035234
 >> iter 69000, loss: 0.040787
 >> iter 70000, loss: 0.056843
   Number of active neurons: 2
 >> iter 71000, loss: 0.082967
 >> iter 72000, loss: 0.053068
 >> iter 73000, loss: 0.075427
 >> iter 74000, loss: 0.042156
 >> iter 75000, loss: 0.069244
 >> iter 76000, loss: 0.054541
 >> iter 77000, loss: 0.040267
 >> iter 78000, loss: 0.047210
 >> iter 79000, loss: 0.053754
 >> iter 80000, loss: 0.042147
   Number of active neurons: 2
 >> iter 81000, loss: 0.042975
 >> iter 82000, loss: 0.042774
 >> iter 83000, loss: 0.046369
 >> iter 84000, loss: 0.048852
 >> iter 85000, loss: 0.052342
 >> iter 86000, loss: 0.044354
 >> iter 87000, loss: 0.056380
 >> iter 88000, loss: 0.055873
 >> iter 89000, loss: 0.042157
 >> iter 90000, loss: 0.039267
   Number of active neurons: 2
 >> iter 91000, loss: 0.047495
 >> iter 92000, loss: 0.040907
 >> iter 93000, loss: 0.055659
 >> iter 94000, loss: 0.051431
 >> iter 95000, loss: 0.033458
 >> iter 96000, loss: 0.043456
 >> iter 97000, loss: 0.035385
 >> iter 98000, loss: 0.036883
 >> iter 99000, loss: 0.069332
 >> iter 100000, loss: 0.049119
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.969118
 >> iter 2000, loss: 5.690338
 >> iter 3000, loss: 3.448940
 >> iter 4000, loss: 2.518678
 >> iter 5000, loss: 2.243542
 >> iter 6000, loss: 2.075549
 >> iter 7000, loss: 2.077032
 >> iter 8000, loss: 1.998208
 >> iter 9000, loss: 2.055162
 >> iter 10000, loss: 1.975232
   Number of active neurons: 2
 >> iter 11000, loss: 2.025083
 >> iter 12000, loss: 1.953065
 >> iter 13000, loss: 2.021974
 >> iter 14000, loss: 1.961344
 >> iter 15000, loss: 2.028870
 >> iter 16000, loss: 1.968783
 >> iter 17000, loss: 2.012020
 >> iter 18000, loss: 1.947781
 >> iter 19000, loss: 2.011656
 >> iter 20000, loss: 1.955287
   Number of active neurons: 2
 >> iter 21000, loss: 2.009556
 >> iter 22000, loss: 1.939569
 >> iter 23000, loss: 2.000002
 >> iter 24000, loss: 1.938007
 >> iter 25000, loss: 1.997934
 >> iter 26000, loss: 1.947829
 >> iter 27000, loss: 1.985619
 >> iter 28000, loss: 1.919521
 >> iter 29000, loss: 1.991643
 >> iter 30000, loss: 1.935864
   Number of active neurons: 2
 >> iter 31000, loss: 1.990647
 >> iter 32000, loss: 1.919983
 >> iter 33000, loss: 1.999649
 >> iter 34000, loss: 1.938047
 >> iter 35000, loss: 1.990632
 >> iter 36000, loss: 1.927150
 >> iter 37000, loss: 1.993566
 >> iter 38000, loss: 1.916983
 >> iter 39000, loss: 1.989920
 >> iter 40000, loss: 1.939489
   Number of active neurons: 2
 >> iter 41000, loss: 1.978973
 >> iter 42000, loss: 1.942847
 >> iter 43000, loss: 1.982418
 >> iter 44000, loss: 1.924242
 >> iter 45000, loss: 1.966155
 >> iter 46000, loss: 1.915971
 >> iter 47000, loss: 1.987462
 >> iter 48000, loss: 1.930728
 >> iter 49000, loss: 1.981284
 >> iter 50000, loss: 1.927677
   Number of active neurons: 2
 >> iter 51000, loss: 1.967315
 >> iter 52000, loss: 1.925174
 >> iter 53000, loss: 1.965004
 >> iter 54000, loss: 1.945817
 >> iter 55000, loss: 1.981292
 >> iter 56000, loss: 1.938835
 >> iter 57000, loss: 1.985019
 >> iter 58000, loss: 1.931083
 >> iter 59000, loss: 1.977699
 >> iter 60000, loss: 1.910381
   Number of active neurons: 2
 >> iter 61000, loss: 1.972540
 >> iter 62000, loss: 1.916042
 >> iter 63000, loss: 1.992372
 >> iter 64000, loss: 1.929404
 >> iter 65000, loss: 1.992184
 >> iter 66000, loss: 1.930605
 >> iter 67000, loss: 1.961958
 >> iter 68000, loss: 1.928731
 >> iter 69000, loss: 1.939896
 >> iter 70000, loss: 1.918126
   Number of active neurons: 2
 >> iter 71000, loss: 1.955016
 >> iter 72000, loss: 1.927617
 >> iter 73000, loss: 1.974782
 >> iter 74000, loss: 1.922621
 >> iter 75000, loss: 1.964057
 >> iter 76000, loss: 1.925217
 >> iter 77000, loss: 1.973886
 >> iter 78000, loss: 1.919405
 >> iter 79000, loss: 1.957298
 >> iter 80000, loss: 1.924023
   Number of active neurons: 2
 >> iter 81000, loss: 1.966449
 >> iter 82000, loss: 1.911530
 >> iter 83000, loss: 1.962034
 >> iter 84000, loss: 1.913193
 >> iter 85000, loss: 1.954851
 >> iter 86000, loss: 1.913629
 >> iter 87000, loss: 1.959844
 >> iter 88000, loss: 1.937842
 >> iter 89000, loss: 1.956568
 >> iter 90000, loss: 1.917322
   Number of active neurons: 2
 >> iter 91000, loss: 1.974375
 >> iter 92000, loss: 1.911870
 >> iter 93000, loss: 1.947693
 >> iter 94000, loss: 1.919013
 >> iter 95000, loss: 1.957368
 >> iter 96000, loss: 1.910587
 >> iter 97000, loss: 1.949519
 >> iter 98000, loss: 1.906326
 >> iter 99000, loss: 1.954129
 >> iter 100000, loss: 1.917395
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 2.69794604108
   - Test - Long: 0.304984750762
   - Test - Big: 2.50297497025
   - Test - A: 0.00666622225185
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.424620
 >> iter 2000, loss: 4.384578
 >> iter 3000, loss: 1.698473
 >> iter 4000, loss: 0.679746
 >> iter 5000, loss: 0.301263
 >> iter 6000, loss: 0.145763
 >> iter 7000, loss: 0.091694
 >> iter 8000, loss: 0.076291
 >> iter 9000, loss: 0.054645
 >> iter 10000, loss: 0.055002
   Number of active neurons: 2
 >> iter 11000, loss: 0.061009
 >> iter 12000, loss: 0.056732
 >> iter 13000, loss: 0.051674
 >> iter 14000, loss: 0.050436
 >> iter 15000, loss: 0.062572
 >> iter 16000, loss: 0.054042
 >> iter 17000, loss: 0.049770
 >> iter 18000, loss: 0.049662
 >> iter 19000, loss: 0.056450
 >> iter 20000, loss: 0.036191
   Number of active neurons: 2
 >> iter 21000, loss: 0.044433
 >> iter 22000, loss: 0.053822
 >> iter 23000, loss: 0.043903
 >> iter 24000, loss: 0.048985
 >> iter 25000, loss: 0.038961
 >> iter 26000, loss: 0.038269
 >> iter 27000, loss: 0.036098
 >> iter 28000, loss: 0.036131
 >> iter 29000, loss: 0.041094
 >> iter 30000, loss: 0.042456
   Number of active neurons: 2
 >> iter 31000, loss: 0.036421
 >> iter 32000, loss: 0.043074
 >> iter 33000, loss: 0.039943
 >> iter 34000, loss: 0.044695
 >> iter 35000, loss: 0.032256
 >> iter 36000, loss: 0.037706
 >> iter 37000, loss: 0.037815
 >> iter 38000, loss: 0.037386
 >> iter 39000, loss: 0.052283
 >> iter 40000, loss: 0.043844
   Number of active neurons: 2
 >> iter 41000, loss: 0.056504
 >> iter 42000, loss: 0.061876
 >> iter 43000, loss: 0.051285
 >> iter 44000, loss: 0.046552
 >> iter 45000, loss: 0.038880
 >> iter 46000, loss: 0.051984
 >> iter 47000, loss: 0.064755
 >> iter 48000, loss: 0.046776
 >> iter 49000, loss: 0.044496
 >> iter 50000, loss: 0.037113
   Number of active neurons: 2
 >> iter 51000, loss: 0.034887
 >> iter 52000, loss: 0.042457
 >> iter 53000, loss: 0.059193
 >> iter 54000, loss: 0.046199
 >> iter 55000, loss: 0.062120
 >> iter 56000, loss: 0.049945
 >> iter 57000, loss: 0.059234
 >> iter 58000, loss: 0.052533
 >> iter 59000, loss: 0.053068
 >> iter 60000, loss: 0.053708
   Number of active neurons: 2
 >> iter 61000, loss: 0.043462
 >> iter 62000, loss: 0.041141
 >> iter 63000, loss: 0.042545
 >> iter 64000, loss: 0.038584
 >> iter 65000, loss: 0.053820
 >> iter 66000, loss: 0.048219
 >> iter 67000, loss: 0.071192
 >> iter 68000, loss: 0.060403
 >> iter 69000, loss: 0.054241
 >> iter 70000, loss: 0.049984
   Number of active neurons: 2
 >> iter 71000, loss: 0.044872
 >> iter 72000, loss: 0.043498
 >> iter 73000, loss: 0.029864
 >> iter 74000, loss: 0.034966
 >> iter 75000, loss: 0.047573
 >> iter 76000, loss: 0.048216
 >> iter 77000, loss: 0.042130
 >> iter 78000, loss: 0.029966
 >> iter 79000, loss: 0.048383
 >> iter 80000, loss: 0.043170
   Number of active neurons: 2
 >> iter 81000, loss: 0.047310
 >> iter 82000, loss: 0.039691
 >> iter 83000, loss: 0.043630
 >> iter 84000, loss: 0.044032
 >> iter 85000, loss: 0.043898
 >> iter 86000, loss: 0.064477
 >> iter 87000, loss: 0.038908
 >> iter 88000, loss: 0.036000
 >> iter 89000, loss: 0.052428
 >> iter 90000, loss: 0.043101
   Number of active neurons: 2
 >> iter 91000, loss: 0.047198
 >> iter 92000, loss: 0.050924
 >> iter 93000, loss: 0.041951
 >> iter 94000, loss: 0.042765
 >> iter 95000, loss: 0.038235
 >> iter 96000, loss: 0.052668
 >> iter 97000, loss: 0.051140
 >> iter 98000, loss: 0.051626
 >> iter 99000, loss: 0.046763
 >> iter 100000, loss: 0.044695
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.729319
 >> iter 2000, loss: 4.470082
 >> iter 3000, loss: 1.739571
 >> iter 4000, loss: 0.702546
 >> iter 5000, loss: 0.294083
 >> iter 6000, loss: 0.150750
 >> iter 7000, loss: 0.113059
 >> iter 8000, loss: 0.085125
 >> iter 9000, loss: 0.055998
 >> iter 10000, loss: 0.053744
   Number of active neurons: 2
 >> iter 11000, loss: 0.065995
 >> iter 12000, loss: 0.063927
 >> iter 13000, loss: 0.069388
 >> iter 14000, loss: 0.057617
 >> iter 15000, loss: 0.040368
 >> iter 16000, loss: 0.045689
 >> iter 17000, loss: 0.046180
 >> iter 18000, loss: 0.058262
 >> iter 19000, loss: 0.053259
 >> iter 20000, loss: 0.049448
   Number of active neurons: 2
 >> iter 21000, loss: 0.041551
 >> iter 22000, loss: 0.047645
 >> iter 23000, loss: 0.042700
 >> iter 24000, loss: 0.044542
 >> iter 25000, loss: 0.044911
 >> iter 26000, loss: 0.048169
 >> iter 27000, loss: 0.048865
 >> iter 28000, loss: 0.038806
 >> iter 29000, loss: 0.043685
 >> iter 30000, loss: 0.044810
   Number of active neurons: 2
 >> iter 31000, loss: 0.035530
 >> iter 32000, loss: 0.043587
 >> iter 33000, loss: 0.050208
 >> iter 34000, loss: 0.037129
 >> iter 35000, loss: 0.036270
 >> iter 36000, loss: 0.034199
 >> iter 37000, loss: 0.040727
 >> iter 38000, loss: 0.029758
 >> iter 39000, loss: 0.029085
 >> iter 40000, loss: 0.055576
   Number of active neurons: 2
 >> iter 41000, loss: 0.055849
 >> iter 42000, loss: 0.042863
 >> iter 43000, loss: 0.058294
 >> iter 44000, loss: 0.047899
 >> iter 45000, loss: 0.060458
 >> iter 46000, loss: 0.051343
 >> iter 47000, loss: 0.046922
 >> iter 48000, loss: 0.044938
 >> iter 49000, loss: 0.033773
 >> iter 50000, loss: 0.049720
   Number of active neurons: 2
 >> iter 51000, loss: 0.041835
 >> iter 52000, loss: 0.034346
 >> iter 53000, loss: 0.028072
 >> iter 54000, loss: 0.031754
 >> iter 55000, loss: 0.039778
 >> iter 56000, loss: 0.052358
 >> iter 57000, loss: 0.068928
 >> iter 58000, loss: 0.040904
 >> iter 59000, loss: 0.032534
 >> iter 60000, loss: 0.036010
   Number of active neurons: 2
 >> iter 61000, loss: 0.034818
 >> iter 62000, loss: 0.041864
 >> iter 63000, loss: 0.044539
 >> iter 64000, loss: 0.042609
 >> iter 65000, loss: 0.053715
 >> iter 66000, loss: 0.038731
 >> iter 67000, loss: 0.033897
 >> iter 68000, loss: 0.061447
 >> iter 69000, loss: 0.056854
 >> iter 70000, loss: 0.058668
   Number of active neurons: 2
 >> iter 71000, loss: 0.052909
 >> iter 72000, loss: 0.040601
 >> iter 73000, loss: 0.058218
 >> iter 74000, loss: 0.043196
 >> iter 75000, loss: 0.034869
 >> iter 76000, loss: 0.045860
 >> iter 77000, loss: 0.039947
 >> iter 78000, loss: 0.046287
 >> iter 79000, loss: 0.053103
 >> iter 80000, loss: 0.054857
   Number of active neurons: 2
 >> iter 81000, loss: 0.051725
 >> iter 82000, loss: 0.059216
 >> iter 83000, loss: 0.051912
 >> iter 84000, loss: 0.042148
 >> iter 85000, loss: 0.046328
 >> iter 86000, loss: 0.044964
 >> iter 87000, loss: 0.038741
 >> iter 88000, loss: 0.046679
 >> iter 89000, loss: 0.033894
 >> iter 90000, loss: 0.029396
   Number of active neurons: 2
 >> iter 91000, loss: 0.050718
 >> iter 92000, loss: 0.039032
 >> iter 93000, loss: 0.031960
 >> iter 94000, loss: 0.043621
 >> iter 95000, loss: 0.044088
 >> iter 96000, loss: 0.054418
 >> iter 97000, loss: 0.048415
 >> iter 98000, loss: 0.042109
 >> iter 99000, loss: 0.058373
 >> iter 100000, loss: 0.059008
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 12.111118
 >> iter 2000, loss: 5.736978
 >> iter 3000, loss: 3.467102
 >> iter 4000, loss: 2.525853
 >> iter 5000, loss: 2.256644
 >> iter 6000, loss: 2.075777
 >> iter 7000, loss: 2.069231
 >> iter 8000, loss: 1.987994
 >> iter 9000, loss: 2.038936
 >> iter 10000, loss: 1.963339
   Number of active neurons: 2
 >> iter 11000, loss: 2.034759
 >> iter 12000, loss: 1.979017
 >> iter 13000, loss: 2.028662
 >> iter 14000, loss: 1.965445
 >> iter 15000, loss: 2.016771
 >> iter 16000, loss: 1.954090
 >> iter 17000, loss: 2.014364
 >> iter 18000, loss: 1.936116
 >> iter 19000, loss: 2.000482
 >> iter 20000, loss: 1.946691
   Number of active neurons: 2
 >> iter 21000, loss: 2.012312
 >> iter 22000, loss: 1.952890
 >> iter 23000, loss: 2.007924
 >> iter 24000, loss: 1.938998
 >> iter 25000, loss: 1.979636
 >> iter 26000, loss: 1.920647
 >> iter 27000, loss: 1.999963
 >> iter 28000, loss: 1.928620
 >> iter 29000, loss: 2.008583
 >> iter 30000, loss: 1.942143
   Number of active neurons: 2
 >> iter 31000, loss: 2.002880
 >> iter 32000, loss: 1.941508
 >> iter 33000, loss: 1.992504
 >> iter 34000, loss: 1.938368
 >> iter 35000, loss: 1.991795
 >> iter 36000, loss: 1.906244
 >> iter 37000, loss: 1.965985
 >> iter 38000, loss: 1.923199
 >> iter 39000, loss: 1.980074
 >> iter 40000, loss: 1.930654
   Number of active neurons: 2
 >> iter 41000, loss: 1.986992
 >> iter 42000, loss: 1.926771
 >> iter 43000, loss: 1.975426
 >> iter 44000, loss: 1.920263
 >> iter 45000, loss: 1.981306
 >> iter 46000, loss: 1.942559
 >> iter 47000, loss: 1.974185
 >> iter 48000, loss: 1.916886
 >> iter 49000, loss: 1.977900
 >> iter 50000, loss: 1.904663
   Number of active neurons: 2
 >> iter 51000, loss: 1.966798
 >> iter 52000, loss: 1.915017
 >> iter 53000, loss: 1.964030
 >> iter 54000, loss: 1.925139
 >> iter 55000, loss: 1.955727
 >> iter 56000, loss: 1.931750
 >> iter 57000, loss: 1.970427
 >> iter 58000, loss: 1.951017
 >> iter 59000, loss: 1.983689
 >> iter 60000, loss: 1.937931
   Number of active neurons: 2
 >> iter 61000, loss: 1.989174
 >> iter 62000, loss: 1.913348
 >> iter 63000, loss: 1.962600
 >> iter 64000, loss: 1.920201
 >> iter 65000, loss: 2.000025
 >> iter 66000, loss: 1.945123
 >> iter 67000, loss: 1.980894
 >> iter 68000, loss: 1.920729
 >> iter 69000, loss: 1.952384
 >> iter 70000, loss: 1.920519
   Number of active neurons: 2
 >> iter 71000, loss: 1.962743
 >> iter 72000, loss: 1.913772
 >> iter 73000, loss: 1.971227
 >> iter 74000, loss: 1.934990
 >> iter 75000, loss: 1.969684
 >> iter 76000, loss: 1.916485
 >> iter 77000, loss: 1.959047
 >> iter 78000, loss: 1.929129
 >> iter 79000, loss: 1.974047
 >> iter 80000, loss: 1.921867
   Number of active neurons: 2
 >> iter 81000, loss: 1.962816
 >> iter 82000, loss: 1.909519
 >> iter 83000, loss: 1.961257
 >> iter 84000, loss: 1.907201
 >> iter 85000, loss: 1.956525
 >> iter 86000, loss: 1.902895
 >> iter 87000, loss: 1.954461
 >> iter 88000, loss: 1.916620
 >> iter 89000, loss: 1.969131
 >> iter 90000, loss: 1.930917
   Number of active neurons: 2
 >> iter 91000, loss: 1.971778
 >> iter 92000, loss: 1.906949
 >> iter 93000, loss: 1.954039
 >> iter 94000, loss: 1.918213
 >> iter 95000, loss: 1.961808
 >> iter 96000, loss: 1.919036
 >> iter 97000, loss: 1.946860
 >> iter 98000, loss: 1.914259
 >> iter 99000, loss: 1.947429
 >> iter 100000, loss: 1.913722
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 2.69794604108
   - Test - Long: 0.304984750762
   - Test - Big: 2.50297497025
   - Test - A: 0.00666622225185
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 12.516794
 >> iter 2000, loss: 6.410245
 >> iter 3000, loss: 4.320327
 >> iter 4000, loss: 3.381550
 >> iter 5000, loss: 3.208424
 >> iter 6000, loss: 2.973740
 >> iter 7000, loss: 3.056789
 >> iter 8000, loss: 2.895530
 >> iter 9000, loss: 3.009875
 >> iter 10000, loss: 2.894868
   Number of active neurons: 1
 >> iter 11000, loss: 3.017695
 >> iter 12000, loss: 2.891202
 >> iter 13000, loss: 3.020909
 >> iter 14000, loss: 2.898052
 >> iter 15000, loss: 3.019990
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 2.176818
 >> iter 17000, loss: 0.975026
 >> iter 18000, loss: 0.444953
 >> iter 19000, loss: 0.238904
 >> iter 20000, loss: 0.136315
   Number of active neurons: 2
 >> iter 21000, loss: 0.091726
 >> iter 22000, loss: 0.081307
 >> iter 23000, loss: 0.068243
 >> iter 24000, loss: 0.045398
 >> iter 25000, loss: 0.043414
 >> iter 26000, loss: 0.071721
 >> iter 27000, loss: 0.053773
 >> iter 28000, loss: 0.045249
 >> iter 29000, loss: 0.052589
 >> iter 30000, loss: 0.067460
   Number of active neurons: 2
 >> iter 31000, loss: 0.059822
 >> iter 32000, loss: 0.040582
 >> iter 33000, loss: 0.067331
 >> iter 34000, loss: 0.055229
 >> iter 35000, loss: 0.054809
 >> iter 36000, loss: 0.050779
 >> iter 37000, loss: 0.036831
 >> iter 38000, loss: 0.035172
 >> iter 39000, loss: 0.033398
 >> iter 40000, loss: 0.030090
   Number of active neurons: 2
 >> iter 41000, loss: 0.045661
 >> iter 42000, loss: 0.057636
 >> iter 43000, loss: 0.044096
 >> iter 44000, loss: 0.037711
 >> iter 45000, loss: 0.038585
 >> iter 46000, loss: 0.031725
 >> iter 47000, loss: 0.040483
 >> iter 48000, loss: 0.030936
 >> iter 49000, loss: 0.044765
 >> iter 50000, loss: 0.052582
   Number of active neurons: 2
 >> iter 51000, loss: 0.033700
 >> iter 52000, loss: 0.042753
 >> iter 53000, loss: 0.048632
 >> iter 54000, loss: 0.055241
 >> iter 55000, loss: 0.040588
 >> iter 56000, loss: 0.055693
 >> iter 57000, loss: 0.041321
 >> iter 58000, loss: 0.046945
 >> iter 59000, loss: 0.036580
 >> iter 60000, loss: 0.055734
   Number of active neurons: 2
 >> iter 61000, loss: 0.064781
 >> iter 62000, loss: 0.042030
 >> iter 63000, loss: 0.037507
 >> iter 64000, loss: 0.033675
 >> iter 65000, loss: 0.042273
 >> iter 66000, loss: 0.047697
 >> iter 67000, loss: 0.047640
 >> iter 68000, loss: 0.062685
 >> iter 69000, loss: 0.041125
 >> iter 70000, loss: 0.032335
   Number of active neurons: 2
 >> iter 71000, loss: 0.037861
 >> iter 72000, loss: 0.039778
 >> iter 73000, loss: 0.053446
 >> iter 74000, loss: 0.039722
 >> iter 75000, loss: 0.043033
 >> iter 76000, loss: 0.058619
 >> iter 77000, loss: 0.043481
 >> iter 78000, loss: 0.034290
 >> iter 79000, loss: 0.053160
 >> iter 80000, loss: 0.059878
   Number of active neurons: 2
 >> iter 81000, loss: 0.067924
 >> iter 82000, loss: 0.071497
 >> iter 83000, loss: 0.049758
 >> iter 84000, loss: 0.041427
 >> iter 85000, loss: 0.050811
 >> iter 86000, loss: 0.062917
 >> iter 87000, loss: 0.047259
 >> iter 88000, loss: 0.053347
 >> iter 89000, loss: 0.035516
 >> iter 90000, loss: 0.039794
   Number of active neurons: 2
 >> iter 91000, loss: 0.037905
 >> iter 92000, loss: 0.035699
 >> iter 93000, loss: 0.044156
 >> iter 94000, loss: 0.038998
 >> iter 95000, loss: 0.026747
 >> iter 96000, loss: 0.051806
 >> iter 97000, loss: 0.054878
 >> iter 98000, loss: 0.039412
 >> iter 99000, loss: 0.036126
 >> iter 100000, loss: 0.052081
   Number of active neurons: 2
 >> iter 101000, loss: 0.044233
 >> iter 102000, loss: 0.048712
 >> iter 103000, loss: 0.056810
 >> iter 104000, loss: 0.059165
 >> iter 105000, loss: 0.034827
 >> iter 106000, loss: 0.049576
 >> iter 107000, loss: 0.053856
 >> iter 108000, loss: 0.050633
 >> iter 109000, loss: 0.045459
 >> iter 110000, loss: 0.052640
   Number of active neurons: 2
 >> iter 111000, loss: 0.053126
 >> iter 112000, loss: 0.034513
 >> iter 113000, loss: 0.031435
 >> iter 114000, loss: 0.043112
 >> iter 115000, loss: 0.039512
 >> iter 116000, loss: 0.043213
 >> iter 117000, loss: 0.043591
 >> iter 118000, loss: 0.031845
 >> iter 119000, loss: 0.026451
 >> iter 120000, loss: 0.043880
   Number of active neurons: 2
 >> iter 121000, loss: 0.042296
 >> iter 122000, loss: 0.041714
 >> iter 123000, loss: 0.046031
 >> iter 124000, loss: 0.038332
 >> iter 125000, loss: 0.039307
 >> iter 126000, loss: 0.035448
 >> iter 127000, loss: 0.041231
 >> iter 128000, loss: 0.056948
 >> iter 129000, loss: 0.048105
 >> iter 130000, loss: 0.059729
   Number of active neurons: 2
 >> iter 131000, loss: 0.047019
 >> iter 132000, loss: 0.030308
 >> iter 133000, loss: 0.032392
 >> iter 134000, loss: 0.031678
 >> iter 135000, loss: 0.043694
 >> iter 136000, loss: 0.041447
 >> iter 137000, loss: 0.036413
 >> iter 138000, loss: 0.037328
 >> iter 139000, loss: 0.026824
 >> iter 140000, loss: 0.044516
   Number of active neurons: 2
 >> iter 141000, loss: 0.044923
 >> iter 142000, loss: 0.035315
 >> iter 143000, loss: 0.037745
 >> iter 144000, loss: 0.042437
 >> iter 145000, loss: 0.036316
 >> iter 146000, loss: 0.026028
 >> iter 147000, loss: 0.021679
 >> iter 148000, loss: 0.050653
 >> iter 149000, loss: 0.046703
 >> iter 150000, loss: 0.039463
   Number of active neurons: 2
 >> iter 151000, loss: 0.036608
 >> iter 152000, loss: 0.032217
 >> iter 153000, loss: 0.042230
 >> iter 154000, loss: 0.040198
 >> iter 155000, loss: 0.052230
 >> iter 156000, loss: 0.036350
 >> iter 157000, loss: 0.030872
 >> iter 158000, loss: 0.028530
 >> iter 159000, loss: 0.037367
 >> iter 160000, loss: 0.027994
   Number of active neurons: 2
 >> iter 161000, loss: 0.031477
 >> iter 162000, loss: 0.042038
 >> iter 163000, loss: 0.027461
 >> iter 164000, loss: 0.053708
 >> iter 165000, loss: 0.046621
 >> iter 166000, loss: 0.058351
 >> iter 167000, loss: 0.045327
 >> iter 168000, loss: 0.040621
 >> iter 169000, loss: 0.036955
 >> iter 170000, loss: 0.041600
   Number of active neurons: 2
 >> iter 171000, loss: 0.064970
 >> iter 172000, loss: 0.041469
 >> iter 173000, loss: 0.035843
 >> iter 174000, loss: 0.031153
 >> iter 175000, loss: 0.055500
 >> iter 176000, loss: 0.045069
 >> iter 177000, loss: 0.036623
 >> iter 178000, loss: 0.039341
 >> iter 179000, loss: 0.034176
 >> iter 180000, loss: 0.027465
   Number of active neurons: 2
 >> iter 181000, loss: 0.027434
 >> iter 182000, loss: 0.026867
 >> iter 183000, loss: 0.036115
 >> iter 184000, loss: 0.040576
 >> iter 185000, loss: 0.034201
 >> iter 186000, loss: 0.038967
 >> iter 187000, loss: 0.038276
 >> iter 188000, loss: 0.037405
 >> iter 189000, loss: 0.026154
 >> iter 190000, loss: 0.053495
   Number of active neurons: 2
 >> iter 191000, loss: 0.044217
 >> iter 192000, loss: 0.035571
 >> iter 193000, loss: 0.028329
 >> iter 194000, loss: 0.037454
 >> iter 195000, loss: 0.046143
 >> iter 196000, loss: 0.056460
 >> iter 197000, loss: 0.059835
 >> iter 198000, loss: 0.063316
 >> iter 199000, loss: 0.040310
 >> iter 200000, loss: 0.048778
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 12.104831
 >> iter 2000, loss: 5.730032
 >> iter 3000, loss: 3.452902
 >> iter 4000, loss: 2.488525
 >> iter 5000, loss: 2.241946
 >> iter 6000, loss: 2.052973
 >> iter 7000, loss: 2.061564
 >> iter 8000, loss: 1.983131
 >> iter 9000, loss: 2.025118
 >> iter 10000, loss: 1.960227
   Number of active neurons: 2
 >> iter 11000, loss: 2.019213
 >> iter 12000, loss: 1.911809
 >> iter 13000, loss: 1.192693
 >> iter 14000, loss: 0.497108
 >> iter 15000, loss: 0.239637
 >> iter 16000, loss: 0.113634
 >> iter 17000, loss: 0.070195
 >> iter 18000, loss: 0.052604
 >> iter 19000, loss: 0.069229
 >> iter 20000, loss: 0.068587
   Number of active neurons: 2
 >> iter 21000, loss: 0.051448
 >> iter 22000, loss: 0.033378
 >> iter 23000, loss: 0.047005
 >> iter 24000, loss: 0.034146
 >> iter 25000, loss: 0.049444
 >> iter 26000, loss: 0.041966
 >> iter 27000, loss: 0.068511
 >> iter 28000, loss: 0.048317
 >> iter 29000, loss: 0.045399
 >> iter 30000, loss: 0.041155
   Number of active neurons: 2
 >> iter 31000, loss: 0.041521
 >> iter 32000, loss: 0.042980
 >> iter 33000, loss: 0.040961
 >> iter 34000, loss: 0.039315
 >> iter 35000, loss: 0.037690
 >> iter 36000, loss: 0.052005
 >> iter 37000, loss: 0.046691
 >> iter 38000, loss: 0.053137
 >> iter 39000, loss: 0.037722
 >> iter 40000, loss: 0.055983
   Number of active neurons: 2
 >> iter 41000, loss: 0.043140
 >> iter 42000, loss: 0.045814
 >> iter 43000, loss: 0.053127
 >> iter 44000, loss: 0.050703
 >> iter 45000, loss: 0.067824
 >> iter 46000, loss: 0.083186
 >> iter 47000, loss: 0.046445
 >> iter 48000, loss: 0.061667
 >> iter 49000, loss: 0.049730
 >> iter 50000, loss: 0.044710
   Number of active neurons: 2
 >> iter 51000, loss: 0.044022
 >> iter 52000, loss: 0.070920
 >> iter 53000, loss: 0.050990
 >> iter 54000, loss: 0.034357
 >> iter 55000, loss: 0.040247
 >> iter 56000, loss: 0.046809
 >> iter 57000, loss: 0.045305
 >> iter 58000, loss: 0.039586
 >> iter 59000, loss: 0.044740
 >> iter 60000, loss: 0.062286
   Number of active neurons: 2
 >> iter 61000, loss: 0.053072
 >> iter 62000, loss: 0.045868
 >> iter 63000, loss: 0.053583
 >> iter 64000, loss: 0.059376
 >> iter 65000, loss: 0.039922
 >> iter 66000, loss: 0.045045
 >> iter 67000, loss: 0.051262
 >> iter 68000, loss: 0.036220
 >> iter 69000, loss: 0.035705
 >> iter 70000, loss: 0.044828
   Number of active neurons: 2
 >> iter 71000, loss: 0.054781
 >> iter 72000, loss: 0.054674
 >> iter 73000, loss: 0.061694
 >> iter 74000, loss: 0.045009
 >> iter 75000, loss: 0.041052
 >> iter 76000, loss: 0.041964
 >> iter 77000, loss: 0.059978
 >> iter 78000, loss: 0.043768
 >> iter 79000, loss: 0.041536
 >> iter 80000, loss: 0.043303
   Number of active neurons: 2
 >> iter 81000, loss: 0.038533
 >> iter 82000, loss: 0.046242
 >> iter 83000, loss: 0.057182
 >> iter 84000, loss: 0.052853
 >> iter 85000, loss: 0.040751
 >> iter 86000, loss: 0.044693
 >> iter 87000, loss: 0.049482
 >> iter 88000, loss: 0.052483
 >> iter 89000, loss: 0.065724
 >> iter 90000, loss: 0.047809
   Number of active neurons: 2
 >> iter 91000, loss: 0.046802
 >> iter 92000, loss: 0.049829
 >> iter 93000, loss: 0.057612
 >> iter 94000, loss: 0.060452
 >> iter 95000, loss: 0.055641
 >> iter 96000, loss: 0.054382
 >> iter 97000, loss: 0.047595
 >> iter 98000, loss: 0.040897
 >> iter 99000, loss: 0.037714
 >> iter 100000, loss: 0.035006
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 12.590283
 >> iter 2000, loss: 6.438115
 >> iter 3000, loss: 4.339843
 >> iter 4000, loss: 3.379492
 >> iter 5000, loss: 3.202120
 >> iter 6000, loss: 2.978049
 >> iter 7000, loss: 3.055881
 >> iter 8000, loss: 2.909657
 >> iter 9000, loss: 3.021707
 >> iter 10000, loss: 2.893082
   Number of active neurons: 1
 >> iter 11000, loss: 3.029238
 >> iter 12000, loss: 2.903926
 >> iter 13000, loss: 3.010110
 >> iter 14000, loss: 2.890123
 >> iter 15000, loss: 3.018869
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 2.562437
 >> iter 17000, loss: 2.360826
 >> iter 18000, loss: 2.159461
 >> iter 19000, loss: 2.175260
 >> iter 20000, loss: 2.066378
   Number of active neurons: 2
 >> iter 21000, loss: 2.114991
 >> iter 22000, loss: 2.034734
 >> iter 23000, loss: 2.072615
 >> iter 24000, loss: 2.007453
 >> iter 25000, loss: 2.075168
 >> iter 26000, loss: 1.999780
 >> iter 27000, loss: 2.068731
 >> iter 28000, loss: 1.966773
 >> iter 29000, loss: 2.032450
 >> iter 30000, loss: 1.972714
   Number of active neurons: 2
 >> iter 31000, loss: 2.023237
 >> iter 32000, loss: 1.952427
 >> iter 33000, loss: 1.991966
 >> iter 34000, loss: 1.944048
 >> iter 35000, loss: 2.010631
 >> iter 36000, loss: 1.948504
 >> iter 37000, loss: 1.998271
 >> iter 38000, loss: 1.948872
 >> iter 39000, loss: 1.990108
 >> iter 40000, loss: 1.935662
   Number of active neurons: 2
 >> iter 41000, loss: 1.991238
 >> iter 42000, loss: 1.958865
 >> iter 43000, loss: 2.008129
 >> iter 44000, loss: 1.940202
 >> iter 45000, loss: 1.995684
 >> iter 46000, loss: 1.938976
 >> iter 47000, loss: 1.997616
 >> iter 48000, loss: 1.948778
 >> iter 49000, loss: 2.009811
 >> iter 50000, loss: 1.946747
   Number of active neurons: 2
 >> iter 51000, loss: 2.003397
 >> iter 52000, loss: 1.949622
 >> iter 53000, loss: 1.978017
 >> iter 54000, loss: 1.936329
 >> iter 55000, loss: 2.004255
 >> iter 56000, loss: 1.949127
 >> iter 57000, loss: 2.002830
 >> iter 58000, loss: 1.940224
 >> iter 59000, loss: 1.994864
 >> iter 60000, loss: 1.951387
   Number of active neurons: 2
 >> iter 61000, loss: 1.998016
 >> iter 62000, loss: 1.926816
 >> iter 63000, loss: 1.996279
 >> iter 64000, loss: 1.938038
 >> iter 65000, loss: 1.996875
 >> iter 66000, loss: 1.962695
 >> iter 67000, loss: 2.010532
 >> iter 68000, loss: 1.950667
 >> iter 69000, loss: 1.978334
 >> iter 70000, loss: 1.950570
   Number of active neurons: 2
 >> iter 71000, loss: 1.986592
 >> iter 72000, loss: 1.952695
 >> iter 73000, loss: 2.002231
 >> iter 74000, loss: 1.940805
 >> iter 75000, loss: 1.992204
 >> iter 76000, loss: 1.937413
 >> iter 77000, loss: 1.991634
 >> iter 78000, loss: 1.948917
 >> iter 79000, loss: 1.985770
 >> iter 80000, loss: 1.939889
   Number of active neurons: 2
 >> iter 81000, loss: 1.981390
 >> iter 82000, loss: 1.926144
 >> iter 83000, loss: 1.977454
 >> iter 84000, loss: 1.929934
 >> iter 85000, loss: 1.964375
 >> iter 86000, loss: 1.933399
 >> iter 87000, loss: 1.976280
 >> iter 88000, loss: 1.930499
 >> iter 89000, loss: 1.963368
 >> iter 90000, loss: 1.920700
   Number of active neurons: 2
 >> iter 91000, loss: 1.962617
 >> iter 92000, loss: 1.919375
 >> iter 93000, loss: 1.956697
 >> iter 94000, loss: 1.916334
 >> iter 95000, loss: 1.956968
 >> iter 96000, loss: 1.911016
 >> iter 97000, loss: 1.956269
 >> iter 98000, loss: 1.929800
 >> iter 99000, loss: 1.972610
 >> iter 100000, loss: 1.930865
   Number of active neurons: 2
 >> iter 101000, loss: 1.979208
 >> iter 102000, loss: 1.935870
 >> iter 103000, loss: 1.970611
 >> iter 104000, loss: 1.926573
 >> iter 105000, loss: 1.966997
 >> iter 106000, loss: 1.900977
 >> iter 107000, loss: 1.955984
 >> iter 108000, loss: 1.900547
 >> iter 109000, loss: 1.968206
 >> iter 110000, loss: 1.928068
   Number of active neurons: 2
 >> iter 111000, loss: 1.958450
 >> iter 112000, loss: 1.911835
 >> iter 113000, loss: 1.964109
 >> iter 114000, loss: 1.911841
 >> iter 115000, loss: 1.976644
 >> iter 116000, loss: 1.917280
 >> iter 117000, loss: 1.961918
 >> iter 118000, loss: 1.914796
 >> iter 119000, loss: 1.961978
 >> iter 120000, loss: 1.904092
   Number of active neurons: 2
 >> iter 121000, loss: 1.952802
 >> iter 122000, loss: 1.916433
 >> iter 123000, loss: 1.961610
 >> iter 124000, loss: 1.889917
 >> iter 125000, loss: 1.953150
 >> iter 126000, loss: 1.905032
 >> iter 127000, loss: 1.963534
 >> iter 128000, loss: 1.910542
 >> iter 129000, loss: 1.959485
 >> iter 130000, loss: 1.903446
   Number of active neurons: 2
 >> iter 131000, loss: 1.937495
 >> iter 132000, loss: 1.876927
 >> iter 133000, loss: 1.950227
 >> iter 134000, loss: 1.910376
 >> iter 135000, loss: 1.945355
 >> iter 136000, loss: 1.907435
 >> iter 137000, loss: 1.952199
 >> iter 138000, loss: 1.926295
 >> iter 139000, loss: 1.960654
 >> iter 140000, loss: 1.917200
   Number of active neurons: 2
 >> iter 141000, loss: 1.945494
 >> iter 142000, loss: 1.895630
 >> iter 143000, loss: 1.966192
 >> iter 144000, loss: 1.908704
 >> iter 145000, loss: 1.954416
 >> iter 146000, loss: 1.912321
 >> iter 147000, loss: 1.950869
 >> iter 148000, loss: 1.918115
 >> iter 149000, loss: 1.962099
 >> iter 150000, loss: 1.925742
   Number of active neurons: 2
 >> iter 151000, loss: 1.973739
 >> iter 152000, loss: 1.901697
 >> iter 153000, loss: 1.958789
 >> iter 154000, loss: 1.903849
 >> iter 155000, loss: 1.966366
 >> iter 156000, loss: 1.907994
 >> iter 157000, loss: 1.959152
 >> iter 158000, loss: 1.906332
 >> iter 159000, loss: 1.944167
 >> iter 160000, loss: 1.892953
   Number of active neurons: 2
 >> iter 161000, loss: 1.959618
 >> iter 162000, loss: 1.911966
 >> iter 163000, loss: 1.975612
 >> iter 164000, loss: 1.914780
 >> iter 165000, loss: 1.978123
 >> iter 166000, loss: 1.898036
 >> iter 167000, loss: 1.967658
 >> iter 168000, loss: 1.888333
 >> iter 169000, loss: 1.945789
 >> iter 170000, loss: 1.903727
   Number of active neurons: 2
 >> iter 171000, loss: 1.958109
 >> iter 172000, loss: 1.901865
 >> iter 173000, loss: 1.977642
 >> iter 174000, loss: 1.898972
 >> iter 175000, loss: 1.947446
 >> iter 176000, loss: 1.892845
 >> iter 177000, loss: 1.966283
 >> iter 178000, loss: 1.920057
 >> iter 179000, loss: 1.954483
 >> iter 180000, loss: 1.900867
   Number of active neurons: 2
 >> iter 181000, loss: 1.959341
 >> iter 182000, loss: 1.923103
 >> iter 183000, loss: 1.962764
 >> iter 184000, loss: 1.912693
 >> iter 185000, loss: 1.953295
 >> iter 186000, loss: 1.907180
 >> iter 187000, loss: 1.952590
 >> iter 188000, loss: 1.904899
 >> iter 189000, loss: 1.967250
 >> iter 190000, loss: 1.905564
   Number of active neurons: 2
 >> iter 191000, loss: 1.945444
 >> iter 192000, loss: 1.917440
 >> iter 193000, loss: 1.970715
 >> iter 194000, loss: 1.927558
 >> iter 195000, loss: 1.961522
 >> iter 196000, loss: 1.911473
 >> iter 197000, loss: 1.962846
 >> iter 198000, loss: 1.922802
 >> iter 199000, loss: 1.961299
 >> iter 200000, loss: 1.905536
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 2.69794604108
   - Test - Long: 0.304984750762
   - Test - Big: 2.50297497025
   - Test - A: 0.00666622225185
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.590952
 >> iter 2000, loss: 4.434125
 >> iter 3000, loss: 1.697317
 >> iter 4000, loss: 0.680977
 >> iter 5000, loss: 0.277067
 >> iter 6000, loss: 0.140529
 >> iter 7000, loss: 0.090138
 >> iter 8000, loss: 0.081084
 >> iter 9000, loss: 0.066094
 >> iter 10000, loss: 0.046081
   Number of active neurons: 2
 >> iter 11000, loss: 0.041464
 >> iter 12000, loss: 0.041617
 >> iter 13000, loss: 0.055033
 >> iter 14000, loss: 0.045003
 >> iter 15000, loss: 0.047997
 >> iter 16000, loss: 0.038228
 >> iter 17000, loss: 0.039086
 >> iter 18000, loss: 0.051427
 >> iter 19000, loss: 0.058896
 >> iter 20000, loss: 0.041557
   Number of active neurons: 2
 >> iter 21000, loss: 0.041810
 >> iter 22000, loss: 0.038917
 >> iter 23000, loss: 0.047616
 >> iter 24000, loss: 0.085646
 >> iter 25000, loss: 0.048060
 >> iter 26000, loss: 0.054050
 >> iter 27000, loss: 0.042203
 >> iter 28000, loss: 0.040322
 >> iter 29000, loss: 0.045229
 >> iter 30000, loss: 0.055089
   Number of active neurons: 2
 >> iter 31000, loss: 0.045256
 >> iter 32000, loss: 0.043598
 >> iter 33000, loss: 0.046389
 >> iter 34000, loss: 0.043447
 >> iter 35000, loss: 0.036312
 >> iter 36000, loss: 0.059319
 >> iter 37000, loss: 0.043522
 >> iter 38000, loss: 0.047712
 >> iter 39000, loss: 0.058834
 >> iter 40000, loss: 0.040270
   Number of active neurons: 2
 >> iter 41000, loss: 0.059184
 >> iter 42000, loss: 0.043473
 >> iter 43000, loss: 0.042668
 >> iter 44000, loss: 0.030126
 >> iter 45000, loss: 0.041808
 >> iter 46000, loss: 0.047860
 >> iter 47000, loss: 0.035929
 >> iter 48000, loss: 0.046211
 >> iter 49000, loss: 0.056084
 >> iter 50000, loss: 0.042348
   Number of active neurons: 2
 >> iter 51000, loss: 0.056274
 >> iter 52000, loss: 0.042891
 >> iter 53000, loss: 0.035221
 >> iter 54000, loss: 0.055046
 >> iter 55000, loss: 0.043095
 >> iter 56000, loss: 0.056767
 >> iter 57000, loss: 0.058806
 >> iter 58000, loss: 0.060138
 >> iter 59000, loss: 0.059453
 >> iter 60000, loss: 0.052287
   Number of active neurons: 2
 >> iter 61000, loss: 0.045832
 >> iter 62000, loss: 0.047145
 >> iter 63000, loss: 0.069827
 >> iter 64000, loss: 0.086716
 >> iter 65000, loss: 0.057058
 >> iter 66000, loss: 0.045695
 >> iter 67000, loss: 0.041209
 >> iter 68000, loss: 0.036283
 >> iter 69000, loss: 0.058300
 >> iter 70000, loss: 0.054044
   Number of active neurons: 2
 >> iter 71000, loss: 0.046039
 >> iter 72000, loss: 0.048923
 >> iter 73000, loss: 0.038032
 >> iter 74000, loss: 0.059276
 >> iter 75000, loss: 0.051187
 >> iter 76000, loss: 0.043345
 >> iter 77000, loss: 0.051025
 >> iter 78000, loss: 0.061434
 >> iter 79000, loss: 0.061648
 >> iter 80000, loss: 0.046460
   Number of active neurons: 2
 >> iter 81000, loss: 0.046476
 >> iter 82000, loss: 0.036668
 >> iter 83000, loss: 0.048896
 >> iter 84000, loss: 0.038316
 >> iter 85000, loss: 0.053060
 >> iter 86000, loss: 0.040050
 >> iter 87000, loss: 0.039812
 >> iter 88000, loss: 0.056217
 >> iter 89000, loss: 0.049191
 >> iter 90000, loss: 0.040499
   Number of active neurons: 2
 >> iter 91000, loss: 0.038406
 >> iter 92000, loss: 0.044101
 >> iter 93000, loss: 0.040304
 >> iter 94000, loss: 0.035636
 >> iter 95000, loss: 0.060489
 >> iter 96000, loss: 0.047555
 >> iter 97000, loss: 0.038217
 >> iter 98000, loss: 0.033304
 >> iter 99000, loss: 0.025672
 >> iter 100000, loss: 0.038312
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

