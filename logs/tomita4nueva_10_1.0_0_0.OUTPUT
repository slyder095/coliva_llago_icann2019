 > Problema: tomita4nueva
 > Args:
   - Hidden size: 10
   - Noise level: 1.0
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.064934
 >> iter 2000, loss: 10.878485
 >> iter 3000, loss: 5.264958
 >> iter 4000, loss: 2.625012
 >> iter 5000, loss: 1.269878
 >> iter 6000, loss: 0.696434
 >> iter 7000, loss: 0.524588
 >> iter 8000, loss: 0.466308
 >> iter 9000, loss: 0.397280
 >> iter 10000, loss: 0.201478
   Number of active neurons: 10
 >> iter 11000, loss: 0.214518
 >> iter 12000, loss: 0.096664
 >> iter 13000, loss: 0.050992
 >> iter 14000, loss: 0.068993
 >> iter 15000, loss: 0.058717
 >> iter 16000, loss: 0.137217
 >> iter 17000, loss: 0.141075
 >> iter 18000, loss: 0.268816
 >> iter 19000, loss: 0.109407
 >> iter 20000, loss: 0.265044
   Number of active neurons: 10
 >> iter 21000, loss: 0.151870
 >> iter 22000, loss: 0.084891
 >> iter 23000, loss: 0.165669
 >> iter 24000, loss: 0.128847
 >> iter 25000, loss: 0.105820
 >> iter 26000, loss: 0.048221
 >> iter 27000, loss: 0.028119
 >> iter 28000, loss: 0.016750
 >> iter 29000, loss: 0.070630
 >> iter 30000, loss: 0.030899
   Number of active neurons: 10
 >> iter 31000, loss: 0.016642
 >> iter 32000, loss: 0.010659
 >> iter 33000, loss: 0.012000
 >> iter 34000, loss: 0.019348
 >> iter 35000, loss: 0.055171
 >> iter 36000, loss: 0.031405
 >> iter 37000, loss: 0.016942
 >> iter 38000, loss: 0.009339
 >> iter 39000, loss: 0.052524
 >> iter 40000, loss: 0.022828
   Number of active neurons: 10
 >> iter 41000, loss: 0.035971
 >> iter 42000, loss: 0.031233
 >> iter 43000, loss: 0.014719
 >> iter 44000, loss: 0.066604
 >> iter 45000, loss: 0.028171
 >> iter 46000, loss: 0.042645
 >> iter 47000, loss: 0.018990
 >> iter 48000, loss: 0.010153
 >> iter 49000, loss: 0.006008
 >> iter 50000, loss: 0.004991
   Number of active neurons: 10
 >> iter 51000, loss: 0.011079
 >> iter 52000, loss: 0.009871
 >> iter 53000, loss: 0.005666
 >> iter 54000, loss: 0.004164
 >> iter 55000, loss: 0.003503
 >> iter 56000, loss: 0.003268
 >> iter 57000, loss: 0.003610
 >> iter 58000, loss: 0.002904
 >> iter 59000, loss: 0.002662
 >> iter 60000, loss: 0.002527
   Number of active neurons: 10
 >> iter 61000, loss: 0.002798
 >> iter 62000, loss: 0.002380
 >> iter 63000, loss: 0.002487
 >> iter 64000, loss: 0.002126
 >> iter 65000, loss: 0.002003
 >> iter 66000, loss: 0.002569
 >> iter 67000, loss: 0.002138
 >> iter 68000, loss: 0.001936
 >> iter 69000, loss: 0.001745
 >> iter 70000, loss: 0.001688
   Number of active neurons: 10
 >> iter 71000, loss: 0.002644
 >> iter 72000, loss: 0.001978
 >> iter 73000, loss: 0.001665
 >> iter 74000, loss: 0.003520
 >> iter 75000, loss: 0.002407
 >> iter 76000, loss: 0.028444
 >> iter 77000, loss: 0.056143
 >> iter 78000, loss: 0.021790
 >> iter 79000, loss: 0.011994
 >> iter 80000, loss: 0.005456
   Number of active neurons: 10
 >> iter 81000, loss: 0.003239
 >> iter 82000, loss: 0.002823
 >> iter 83000, loss: 0.017699
 >> iter 84000, loss: 0.007781
 >> iter 85000, loss: 0.004236
 >> iter 86000, loss: 0.002848
 >> iter 87000, loss: 0.006062
 >> iter 88000, loss: 0.003090
 >> iter 89000, loss: 0.102017
 >> iter 90000, loss: 0.045639
   Number of active neurons: 10
 >> iter 91000, loss: 0.017950
 >> iter 92000, loss: 0.007862
 >> iter 93000, loss: 0.004031
 >> iter 94000, loss: 0.002422
 >> iter 95000, loss: 0.001817
 >> iter 96000, loss: 0.014213
 >> iter 97000, loss: 0.006414
 >> iter 98000, loss: 0.003558
 >> iter 99000, loss: 0.002229
 >> iter 100000, loss: 0.010312
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 18.442729
 >> iter 2000, loss: 11.957597
 >> iter 3000, loss: 6.237067
 >> iter 4000, loss: 3.040649
 >> iter 5000, loss: 1.296478
 >> iter 6000, loss: 0.817714
 >> iter 7000, loss: 0.610625
 >> iter 8000, loss: 0.326878
 >> iter 9000, loss: 0.175182
 >> iter 10000, loss: 0.116484
   Number of active neurons: 10
 >> iter 11000, loss: 0.232063
 >> iter 12000, loss: 0.103093
 >> iter 13000, loss: 0.228466
 >> iter 14000, loss: 0.111832
 >> iter 15000, loss: 0.132233
 >> iter 16000, loss: 0.392411
 >> iter 17000, loss: 0.161015
 >> iter 18000, loss: 0.135683
 >> iter 19000, loss: 0.367435
 >> iter 20000, loss: 0.153668
   Number of active neurons: 10
 >> iter 21000, loss: 0.064627
 >> iter 22000, loss: 0.031426
 >> iter 23000, loss: 0.042993
 >> iter 24000, loss: 0.044225
 >> iter 25000, loss: 0.203338
 >> iter 26000, loss: 0.101834
 >> iter 27000, loss: 0.072002
 >> iter 28000, loss: 0.033252
 >> iter 29000, loss: 0.045097
 >> iter 30000, loss: 0.035099
   Number of active neurons: 10
 >> iter 31000, loss: 0.157543
 >> iter 32000, loss: 0.062283
 >> iter 33000, loss: 0.028036
 >> iter 34000, loss: 0.036606
 >> iter 35000, loss: 0.017080
 >> iter 36000, loss: 0.054398
 >> iter 37000, loss: 0.028968
 >> iter 38000, loss: 0.013967
 >> iter 39000, loss: 0.010931
 >> iter 40000, loss: 0.006195
   Number of active neurons: 10
 >> iter 41000, loss: 0.004399
 >> iter 42000, loss: 0.003927
 >> iter 43000, loss: 0.035887
 >> iter 44000, loss: 0.103516
 >> iter 45000, loss: 0.041159
 >> iter 46000, loss: 0.058557
 >> iter 47000, loss: 0.026112
 >> iter 48000, loss: 0.011780
 >> iter 49000, loss: 0.055914
 >> iter 50000, loss: 0.023564
   Number of active neurons: 10
 >> iter 51000, loss: 0.010638
 >> iter 52000, loss: 0.006071
 >> iter 53000, loss: 0.029538
 >> iter 54000, loss: 0.039578
 >> iter 55000, loss: 0.017930
 >> iter 56000, loss: 0.009164
 >> iter 57000, loss: 0.049539
 >> iter 58000, loss: 0.020653
 >> iter 59000, loss: 0.099286
 >> iter 60000, loss: 0.039523
   Number of active neurons: 10
 >> iter 61000, loss: 0.171977
 >> iter 62000, loss: 0.099971
 >> iter 63000, loss: 0.090561
 >> iter 64000, loss: 0.162446
 >> iter 65000, loss: 0.064532
 >> iter 66000, loss: 0.027046
 >> iter 67000, loss: 0.023144
 >> iter 68000, loss: 0.011319
 >> iter 69000, loss: 0.013236
 >> iter 70000, loss: 0.007039
   Number of active neurons: 10
 >> iter 71000, loss: 0.004593
 >> iter 72000, loss: 0.003456
 >> iter 73000, loss: 0.003161
 >> iter 74000, loss: 0.011755
 >> iter 75000, loss: 0.076303
 >> iter 76000, loss: 0.029993
 >> iter 77000, loss: 0.012718
 >> iter 78000, loss: 0.006224
 >> iter 79000, loss: 0.004269
 >> iter 80000, loss: 0.005145
   Number of active neurons: 10
 >> iter 81000, loss: 0.003450
 >> iter 82000, loss: 0.002423
 >> iter 83000, loss: 0.002026
 >> iter 84000, loss: 0.001802
 >> iter 85000, loss: 0.001629
 >> iter 86000, loss: 0.006038
 >> iter 87000, loss: 0.003737
 >> iter 88000, loss: 0.002336
 >> iter 89000, loss: 0.001797
 >> iter 90000, loss: 0.001694
   Number of active neurons: 10
 >> iter 91000, loss: 0.001977
 >> iter 92000, loss: 0.046713
 >> iter 93000, loss: 0.018657
 >> iter 94000, loss: 0.007898
 >> iter 95000, loss: 0.003678
 >> iter 96000, loss: 0.002268
 >> iter 97000, loss: 0.001572
 >> iter 98000, loss: 0.002354
 >> iter 99000, loss: 0.002146
 >> iter 100000, loss: 0.083352
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.431811
 >> iter 2000, loss: 10.966386
 >> iter 3000, loss: 5.610246
 >> iter 4000, loss: 3.228084
 >> iter 5000, loss: 2.005491
 >> iter 6000, loss: 1.221300
 >> iter 7000, loss: 0.753375
 >> iter 8000, loss: 0.593972
 >> iter 9000, loss: 0.393441
 >> iter 10000, loss: 0.387197
   Number of active neurons: 10
 >> iter 11000, loss: 0.355882
 >> iter 12000, loss: 0.328947
 >> iter 13000, loss: 0.211796
 >> iter 14000, loss: 0.166384
 >> iter 15000, loss: 0.218627
 >> iter 16000, loss: 0.335065
 >> iter 17000, loss: 0.198844
 >> iter 18000, loss: 0.155607
 >> iter 19000, loss: 0.094964
 >> iter 20000, loss: 0.079027
   Number of active neurons: 10
 >> iter 21000, loss: 0.080230
 >> iter 22000, loss: 0.131399
 >> iter 23000, loss: 0.093520
 >> iter 24000, loss: 0.083019
 >> iter 25000, loss: 0.039949
 >> iter 26000, loss: 0.060612
 >> iter 27000, loss: 0.229458
 >> iter 28000, loss: 0.151630
 >> iter 29000, loss: 0.241530
 >> iter 30000, loss: 0.103189
   Number of active neurons: 10
 >> iter 31000, loss: 0.047018
 >> iter 32000, loss: 0.065658
 >> iter 33000, loss: 0.028694
 >> iter 34000, loss: 0.118676
 >> iter 35000, loss: 0.048194
 >> iter 36000, loss: 0.045932
 >> iter 37000, loss: 0.023934
 >> iter 38000, loss: 0.079165
 >> iter 39000, loss: 0.116896
 >> iter 40000, loss: 0.078999
   Number of active neurons: 10
 >> iter 41000, loss: 0.032779
 >> iter 42000, loss: 0.129451
 >> iter 43000, loss: 0.108371
 >> iter 44000, loss: 0.062231
 >> iter 45000, loss: 0.080298
 >> iter 46000, loss: 0.044211
 >> iter 47000, loss: 0.019401
 >> iter 48000, loss: 0.010008
 >> iter 49000, loss: 0.018551
 >> iter 50000, loss: 0.010015
   Number of active neurons: 10
 >> iter 51000, loss: 0.109265
 >> iter 52000, loss: 0.046014
 >> iter 53000, loss: 0.043207
 >> iter 54000, loss: 0.019446
 >> iter 55000, loss: 0.009545
 >> iter 56000, loss: 0.011812
 >> iter 57000, loss: 0.030968
 >> iter 58000, loss: 0.051296
 >> iter 59000, loss: 0.022329
 >> iter 60000, loss: 0.020480
   Number of active neurons: 10
 >> iter 61000, loss: 0.009421
 >> iter 62000, loss: 0.004983
 >> iter 63000, loss: 0.003368
 >> iter 64000, loss: 0.002543
 >> iter 65000, loss: 0.002272
 >> iter 66000, loss: 0.002705
 >> iter 67000, loss: 0.002512
 >> iter 68000, loss: 0.184742
 >> iter 69000, loss: 0.069516
 >> iter 70000, loss: 0.070957
   Number of active neurons: 10
 >> iter 71000, loss: 0.054027
 >> iter 72000, loss: 0.169937
 >> iter 73000, loss: 0.068538
 >> iter 74000, loss: 0.028242
 >> iter 75000, loss: 0.012439
 >> iter 76000, loss: 0.006601
 >> iter 77000, loss: 0.003981
 >> iter 78000, loss: 0.004821
 >> iter 79000, loss: 0.003706
 >> iter 80000, loss: 0.027993
   Number of active neurons: 10
 >> iter 81000, loss: 0.020211
 >> iter 82000, loss: 0.008853
 >> iter 83000, loss: 0.047251
 >> iter 84000, loss: 0.070587
 >> iter 85000, loss: 0.028270
 >> iter 86000, loss: 0.012455
 >> iter 87000, loss: 0.006123
 >> iter 88000, loss: 0.003620
 >> iter 89000, loss: 0.002653
 >> iter 90000, loss: 0.002297
   Number of active neurons: 10
 >> iter 91000, loss: 0.002094
 >> iter 92000, loss: 0.001831
 >> iter 93000, loss: 0.003683
 >> iter 94000, loss: 0.002271
 >> iter 95000, loss: 0.023526
 >> iter 96000, loss: 0.025628
 >> iter 97000, loss: 0.010620
 >> iter 98000, loss: 0.022040
 >> iter 99000, loss: 0.009223
 >> iter 100000, loss: 0.004475
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455163
   Number of active neurons: 0
 >> iter 1000, loss: 18.251222
 >> iter 2000, loss: 11.564162
 >> iter 3000, loss: 6.196041
 >> iter 4000, loss: 3.045864
 >> iter 5000, loss: 1.695414
 >> iter 6000, loss: 0.842986
 >> iter 7000, loss: 0.679276
 >> iter 8000, loss: 0.490163
 >> iter 9000, loss: 0.319907
 >> iter 10000, loss: 0.322582
   Number of active neurons: 10
 >> iter 11000, loss: 0.290066
 >> iter 12000, loss: 0.164077
 >> iter 13000, loss: 0.100506
 >> iter 14000, loss: 0.098091
 >> iter 15000, loss: 0.262256
 >> iter 16000, loss: 0.113425
 >> iter 17000, loss: 0.075825
 >> iter 18000, loss: 0.136669
 >> iter 19000, loss: 0.095002
 >> iter 20000, loss: 0.045595
   Number of active neurons: 10
 >> iter 21000, loss: 0.022149
 >> iter 22000, loss: 0.204448
 >> iter 23000, loss: 0.155879
 >> iter 24000, loss: 0.103930
 >> iter 25000, loss: 0.074921
 >> iter 26000, loss: 0.040297
 >> iter 27000, loss: 0.023594
 >> iter 28000, loss: 0.016114
 >> iter 29000, loss: 0.018731
 >> iter 30000, loss: 0.010705
   Number of active neurons: 10
 >> iter 31000, loss: 0.044274
 >> iter 32000, loss: 0.141517
 >> iter 33000, loss: 0.226179
 >> iter 34000, loss: 0.148609
 >> iter 35000, loss: 0.108514
 >> iter 36000, loss: 0.147864
 >> iter 37000, loss: 0.059977
 >> iter 38000, loss: 0.026901
 >> iter 39000, loss: 0.015031
 >> iter 40000, loss: 0.009884
   Number of active neurons: 10
 >> iter 41000, loss: 0.007720
 >> iter 42000, loss: 0.014109
 >> iter 43000, loss: 0.007919
 >> iter 44000, loss: 0.004971
 >> iter 45000, loss: 0.022001
 >> iter 46000, loss: 0.024192
 >> iter 47000, loss: 0.011022
 >> iter 48000, loss: 0.010372
 >> iter 49000, loss: 0.110128
 >> iter 50000, loss: 0.100336
   Number of active neurons: 10
 >> iter 51000, loss: 0.040694
 >> iter 52000, loss: 0.021988
 >> iter 53000, loss: 0.010428
 >> iter 54000, loss: 0.143444
 >> iter 55000, loss: 0.056547
 >> iter 56000, loss: 0.024322
 >> iter 57000, loss: 0.125215
 >> iter 58000, loss: 0.049501
 >> iter 59000, loss: 0.021145
 >> iter 60000, loss: 0.010396
   Number of active neurons: 10
 >> iter 61000, loss: 0.005935
 >> iter 62000, loss: 0.018161
 >> iter 63000, loss: 0.012335
 >> iter 64000, loss: 0.006421
 >> iter 65000, loss: 0.018155
 >> iter 66000, loss: 0.008998
 >> iter 67000, loss: 0.012172
 >> iter 68000, loss: 0.006568
 >> iter 69000, loss: 0.032618
 >> iter 70000, loss: 0.140329
   Number of active neurons: 10
 >> iter 71000, loss: 0.053832
 >> iter 72000, loss: 0.022073
 >> iter 73000, loss: 0.013555
 >> iter 74000, loss: 0.006976
 >> iter 75000, loss: 0.004272
 >> iter 76000, loss: 0.216091
 >> iter 77000, loss: 0.084317
 >> iter 78000, loss: 0.033355
 >> iter 79000, loss: 0.014226
 >> iter 80000, loss: 0.006958
   Number of active neurons: 10
 >> iter 81000, loss: 0.004610
 >> iter 82000, loss: 0.003081
 >> iter 83000, loss: 0.002704
 >> iter 84000, loss: 0.019962
 >> iter 85000, loss: 0.008712
 >> iter 86000, loss: 0.004555
 >> iter 87000, loss: 0.003016
 >> iter 88000, loss: 0.002227
 >> iter 89000, loss: 0.002097
 >> iter 90000, loss: 0.001844
   Number of active neurons: 10
 >> iter 91000, loss: 0.007389
 >> iter 92000, loss: 0.003850
 >> iter 93000, loss: 0.002375
 >> iter 94000, loss: 0.001735
 >> iter 95000, loss: 0.001877
 >> iter 96000, loss: 0.004185
 >> iter 97000, loss: 0.002480
 >> iter 98000, loss: 0.001662
 >> iter 99000, loss: 0.190136
 >> iter 100000, loss: 0.071354
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 18.486497
 >> iter 2000, loss: 11.228790
 >> iter 3000, loss: 5.591593
 >> iter 4000, loss: 2.407803
 >> iter 5000, loss: 1.316469
 >> iter 6000, loss: 0.773629
 >> iter 7000, loss: 0.467953
 >> iter 8000, loss: 0.193908
 >> iter 9000, loss: 0.167768
 >> iter 10000, loss: 0.111801
   Number of active neurons: 10
 >> iter 11000, loss: 0.124920
 >> iter 12000, loss: 0.146963
 >> iter 13000, loss: 0.228136
 >> iter 14000, loss: 0.099980
 >> iter 15000, loss: 0.050713
 >> iter 16000, loss: 0.074807
 >> iter 17000, loss: 0.047203
 >> iter 18000, loss: 0.082300
 >> iter 19000, loss: 0.108498
 >> iter 20000, loss: 0.048662
   Number of active neurons: 10
 >> iter 21000, loss: 0.042696
 >> iter 22000, loss: 0.095290
 >> iter 23000, loss: 0.040600
 >> iter 24000, loss: 0.018676
 >> iter 25000, loss: 0.301688
 >> iter 26000, loss: 0.130267
 >> iter 27000, loss: 0.073526
 >> iter 28000, loss: 0.031075
 >> iter 29000, loss: 0.079394
 >> iter 30000, loss: 0.033494
   Number of active neurons: 10
 >> iter 31000, loss: 0.043617
 >> iter 32000, loss: 0.050277
 >> iter 33000, loss: 0.022092
 >> iter 34000, loss: 0.011556
 >> iter 35000, loss: 0.007949
 >> iter 36000, loss: 0.005891
 >> iter 37000, loss: 0.004319
 >> iter 38000, loss: 0.066507
 >> iter 39000, loss: 0.031275
 >> iter 40000, loss: 0.150635
   Number of active neurons: 10
 >> iter 41000, loss: 0.058337
 >> iter 42000, loss: 0.023779
 >> iter 43000, loss: 0.015177
 >> iter 44000, loss: 0.160922
 >> iter 45000, loss: 0.098982
 >> iter 46000, loss: 0.039309
 >> iter 47000, loss: 0.016876
 >> iter 48000, loss: 0.008236
 >> iter 49000, loss: 0.005397
 >> iter 50000, loss: 0.003701
   Number of active neurons: 10
 >> iter 51000, loss: 0.031917
 >> iter 52000, loss: 0.015373
 >> iter 53000, loss: 0.007712
 >> iter 54000, loss: 0.071067
 >> iter 55000, loss: 0.062589
 >> iter 56000, loss: 0.028063
 >> iter 57000, loss: 0.012052
 >> iter 58000, loss: 0.013943
 >> iter 59000, loss: 0.007009
 >> iter 60000, loss: 0.050244
   Number of active neurons: 10
 >> iter 61000, loss: 0.020350
 >> iter 62000, loss: 0.009200
 >> iter 63000, loss: 0.162440
 >> iter 64000, loss: 0.063154
 >> iter 65000, loss: 0.026408
 >> iter 66000, loss: 0.022756
 >> iter 67000, loss: 0.010192
 >> iter 68000, loss: 0.069178
 >> iter 69000, loss: 0.027861
 >> iter 70000, loss: 0.014839
   Number of active neurons: 10
 >> iter 71000, loss: 0.082329
 >> iter 72000, loss: 0.032897
 >> iter 73000, loss: 0.014985
 >> iter 74000, loss: 0.008432
 >> iter 75000, loss: 0.004463
 >> iter 76000, loss: 0.080455
 >> iter 77000, loss: 0.032333
 >> iter 78000, loss: 0.013608
 >> iter 79000, loss: 0.006721
 >> iter 80000, loss: 0.005972
   Number of active neurons: 10
 >> iter 81000, loss: 0.003357
 >> iter 82000, loss: 0.002980
 >> iter 83000, loss: 0.002410
 >> iter 84000, loss: 0.004833
 >> iter 85000, loss: 0.003815
 >> iter 86000, loss: 0.002619
 >> iter 87000, loss: 0.001939
 >> iter 88000, loss: 0.001706
 >> iter 89000, loss: 0.001455
 >> iter 90000, loss: 0.001572
   Number of active neurons: 10
 >> iter 91000, loss: 0.001478
 >> iter 92000, loss: 0.012148
 >> iter 93000, loss: 0.005607
 >> iter 94000, loss: 0.005129
 >> iter 95000, loss: 0.002590
 >> iter 96000, loss: 0.001875
 >> iter 97000, loss: 0.001296
 >> iter 98000, loss: 0.001205
 >> iter 99000, loss: 0.001149
 >> iter 100000, loss: 0.001055
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.381952
 >> iter 2000, loss: 10.584303
 >> iter 3000, loss: 5.317432
 >> iter 4000, loss: 2.187899
 >> iter 5000, loss: 1.152064
 >> iter 6000, loss: 0.799617
 >> iter 7000, loss: 0.453125
 >> iter 8000, loss: 0.383980
 >> iter 9000, loss: 0.306250
 >> iter 10000, loss: 0.155799
   Number of active neurons: 10
 >> iter 11000, loss: 0.139132
 >> iter 12000, loss: 0.082393
 >> iter 13000, loss: 0.129854
 >> iter 14000, loss: 0.167456
 >> iter 15000, loss: 0.084571
 >> iter 16000, loss: 0.216877
 >> iter 17000, loss: 0.214694
 >> iter 18000, loss: 0.101962
 >> iter 19000, loss: 0.133440
 >> iter 20000, loss: 0.163206
   Number of active neurons: 10
 >> iter 21000, loss: 0.069586
 >> iter 22000, loss: 0.035709
 >> iter 23000, loss: 0.080398
 >> iter 24000, loss: 0.046715
 >> iter 25000, loss: 0.027647
 >> iter 26000, loss: 0.016401
 >> iter 27000, loss: 0.042492
 >> iter 28000, loss: 0.020241
 >> iter 29000, loss: 0.211077
 >> iter 30000, loss: 0.216818
   Number of active neurons: 10
 >> iter 31000, loss: 0.090134
 >> iter 32000, loss: 0.038507
 >> iter 33000, loss: 0.020652
 >> iter 34000, loss: 0.036625
 >> iter 35000, loss: 0.017817
 >> iter 36000, loss: 0.030325
 >> iter 37000, loss: 0.049292
 >> iter 38000, loss: 0.022173
 >> iter 39000, loss: 0.011187
 >> iter 40000, loss: 0.013077
   Number of active neurons: 10
 >> iter 41000, loss: 0.008418
 >> iter 42000, loss: 0.012846
 >> iter 43000, loss: 0.077733
 >> iter 44000, loss: 0.032181
 >> iter 45000, loss: 0.014436
 >> iter 46000, loss: 0.011600
 >> iter 47000, loss: 0.026297
 >> iter 48000, loss: 0.026855
 >> iter 49000, loss: 0.014359
 >> iter 50000, loss: 0.009995
   Number of active neurons: 10
 >> iter 51000, loss: 0.032623
 >> iter 52000, loss: 0.014141
 >> iter 53000, loss: 0.031858
 >> iter 54000, loss: 0.013857
 >> iter 55000, loss: 0.012691
 >> iter 56000, loss: 0.023723
 >> iter 57000, loss: 0.011456
 >> iter 58000, loss: 0.034956
 >> iter 59000, loss: 0.016080
 >> iter 60000, loss: 0.007561
   Number of active neurons: 10
 >> iter 61000, loss: 0.077822
 >> iter 62000, loss: 0.030407
 >> iter 63000, loss: 0.013360
 >> iter 64000, loss: 0.030144
 >> iter 65000, loss: 0.013210
 >> iter 66000, loss: 0.031792
 >> iter 67000, loss: 0.013399
 >> iter 68000, loss: 0.006730
 >> iter 69000, loss: 0.004384
 >> iter 70000, loss: 0.003201
   Number of active neurons: 10
 >> iter 71000, loss: 0.002703
 >> iter 72000, loss: 0.002238
 >> iter 73000, loss: 0.009710
 >> iter 74000, loss: 0.006318
 >> iter 75000, loss: 0.003658
 >> iter 76000, loss: 0.012420
 >> iter 77000, loss: 0.011429
 >> iter 78000, loss: 0.165628
 >> iter 79000, loss: 0.062931
 >> iter 80000, loss: 0.024757
   Number of active neurons: 10
 >> iter 81000, loss: 0.010993
 >> iter 82000, loss: 0.006383
 >> iter 83000, loss: 0.003684
 >> iter 84000, loss: 0.002620
 >> iter 85000, loss: 0.045649
 >> iter 86000, loss: 0.023757
 >> iter 87000, loss: 0.090255
 >> iter 88000, loss: 0.050319
 >> iter 89000, loss: 0.020718
 >> iter 90000, loss: 0.012478
   Number of active neurons: 10
 >> iter 91000, loss: 0.007934
 >> iter 92000, loss: 0.021726
 >> iter 93000, loss: 0.043381
 >> iter 94000, loss: 0.020490
 >> iter 95000, loss: 0.103962
 >> iter 96000, loss: 0.041138
 >> iter 97000, loss: 0.019138
 >> iter 98000, loss: 0.011011
 >> iter 99000, loss: 0.014538
 >> iter 100000, loss: 0.012455
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.351236
 >> iter 2000, loss: 11.896472
 >> iter 3000, loss: 5.545136
 >> iter 4000, loss: 2.676861
 >> iter 5000, loss: 1.431882
 >> iter 6000, loss: 0.705933
 >> iter 7000, loss: 0.438039
 >> iter 8000, loss: 0.361912
 >> iter 9000, loss: 0.184547
 >> iter 10000, loss: 0.199169
   Number of active neurons: 10
 >> iter 11000, loss: 0.193007
 >> iter 12000, loss: 0.197182
 >> iter 13000, loss: 0.094954
 >> iter 14000, loss: 0.048633
 >> iter 15000, loss: 0.048375
 >> iter 16000, loss: 0.050009
 >> iter 17000, loss: 0.099226
 >> iter 18000, loss: 0.044352
 >> iter 19000, loss: 0.022344
 >> iter 20000, loss: 0.015181
   Number of active neurons: 10
 >> iter 21000, loss: 0.059285
 >> iter 22000, loss: 0.027843
 >> iter 23000, loss: 0.043979
 >> iter 24000, loss: 0.035315
 >> iter 25000, loss: 0.025484
 >> iter 26000, loss: 0.029744
 >> iter 27000, loss: 0.015481
 >> iter 28000, loss: 0.008934
 >> iter 29000, loss: 0.005942
 >> iter 30000, loss: 0.006265
   Number of active neurons: 10
 >> iter 31000, loss: 0.005304
 >> iter 32000, loss: 0.005025
 >> iter 33000, loss: 0.004068
 >> iter 34000, loss: 0.003858
 >> iter 35000, loss: 0.003413
 >> iter 36000, loss: 0.009701
 >> iter 37000, loss: 0.005399
 >> iter 38000, loss: 0.003791
 >> iter 39000, loss: 0.007126
 >> iter 40000, loss: 0.004369
   Number of active neurons: 10
 >> iter 41000, loss: 0.005676
 >> iter 42000, loss: 0.005522
 >> iter 43000, loss: 0.120041
 >> iter 44000, loss: 0.047452
 >> iter 45000, loss: 0.072011
 >> iter 46000, loss: 0.089351
 >> iter 47000, loss: 0.093956
 >> iter 48000, loss: 0.038365
 >> iter 49000, loss: 0.040724
 >> iter 50000, loss: 0.017433
   Number of active neurons: 10
 >> iter 51000, loss: 0.027907
 >> iter 52000, loss: 0.012847
 >> iter 53000, loss: 0.200060
 >> iter 54000, loss: 0.077791
 >> iter 55000, loss: 0.031953
 >> iter 56000, loss: 0.016619
 >> iter 57000, loss: 0.097412
 >> iter 58000, loss: 0.050033
 >> iter 59000, loss: 0.022064
 >> iter 60000, loss: 0.010425
   Number of active neurons: 10
 >> iter 61000, loss: 0.024647
 >> iter 62000, loss: 0.011074
 >> iter 63000, loss: 0.006077
 >> iter 64000, loss: 0.040533
 >> iter 65000, loss: 0.017564
 >> iter 66000, loss: 0.009196
 >> iter 67000, loss: 0.007300
 >> iter 68000, loss: 0.005254
 >> iter 69000, loss: 0.003595
 >> iter 70000, loss: 0.104268
   Number of active neurons: 10
 >> iter 71000, loss: 0.041022
 >> iter 72000, loss: 0.084916
 >> iter 73000, loss: 0.045685
 >> iter 74000, loss: 0.023024
 >> iter 75000, loss: 0.011289
 >> iter 76000, loss: 0.005851
 >> iter 77000, loss: 0.003776
 >> iter 78000, loss: 0.002833
 >> iter 79000, loss: 0.002445
 >> iter 80000, loss: 0.002273
   Number of active neurons: 10
 >> iter 81000, loss: 0.002625
 >> iter 82000, loss: 0.016171
 >> iter 83000, loss: 0.007581
 >> iter 84000, loss: 0.003979
 >> iter 85000, loss: 0.003358
 >> iter 86000, loss: 0.057635
 >> iter 87000, loss: 0.026038
 >> iter 88000, loss: 0.013592
 >> iter 89000, loss: 0.018607
 >> iter 90000, loss: 0.035057
   Number of active neurons: 10
 >> iter 91000, loss: 0.016165
 >> iter 92000, loss: 0.007088
 >> iter 93000, loss: 0.004982
 >> iter 94000, loss: 0.003112
 >> iter 95000, loss: 0.002702
 >> iter 96000, loss: 0.003443
 >> iter 97000, loss: 0.002227
 >> iter 98000, loss: 0.001827
 >> iter 99000, loss: 0.001968
 >> iter 100000, loss: 0.001545
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 18.113725
 >> iter 2000, loss: 10.651928
 >> iter 3000, loss: 5.076934
 >> iter 4000, loss: 2.458251
 >> iter 5000, loss: 1.172553
 >> iter 6000, loss: 0.912594
 >> iter 7000, loss: 0.436382
 >> iter 8000, loss: 0.354080
 >> iter 9000, loss: 0.260705
 >> iter 10000, loss: 0.474952
   Number of active neurons: 10
 >> iter 11000, loss: 0.336938
 >> iter 12000, loss: 0.278368
 >> iter 13000, loss: 0.225885
 >> iter 14000, loss: 0.128086
 >> iter 15000, loss: 0.142740
 >> iter 16000, loss: 0.169666
 >> iter 17000, loss: 0.130247
 >> iter 18000, loss: 0.160281
 >> iter 19000, loss: 0.224871
 >> iter 20000, loss: 0.164765
   Number of active neurons: 10
 >> iter 21000, loss: 0.158098
 >> iter 22000, loss: 0.099977
 >> iter 23000, loss: 0.202697
 >> iter 24000, loss: 0.107359
 >> iter 25000, loss: 0.063028
 >> iter 26000, loss: 0.057177
 >> iter 27000, loss: 0.026647
 >> iter 28000, loss: 0.014207
 >> iter 29000, loss: 0.023865
 >> iter 30000, loss: 0.018862
   Number of active neurons: 10
 >> iter 31000, loss: 0.010361
 >> iter 32000, loss: 0.035097
 >> iter 33000, loss: 0.023608
 >> iter 34000, loss: 0.022643
 >> iter 35000, loss: 0.017670
 >> iter 36000, loss: 0.248379
 >> iter 37000, loss: 0.097730
 >> iter 38000, loss: 0.038672
 >> iter 39000, loss: 0.018734
 >> iter 40000, loss: 0.009327
   Number of active neurons: 10
 >> iter 41000, loss: 0.006634
 >> iter 42000, loss: 0.119276
 >> iter 43000, loss: 0.047291
 >> iter 44000, loss: 0.021638
 >> iter 45000, loss: 0.011053
 >> iter 46000, loss: 0.006440
 >> iter 47000, loss: 0.238549
 >> iter 48000, loss: 0.121649
 >> iter 49000, loss: 0.049311
 >> iter 50000, loss: 0.075029
   Number of active neurons: 10
 >> iter 51000, loss: 0.030749
 >> iter 52000, loss: 0.013841
 >> iter 53000, loss: 0.007540
 >> iter 54000, loss: 0.004912
 >> iter 55000, loss: 0.004326
 >> iter 56000, loss: 0.058295
 >> iter 57000, loss: 0.085438
 >> iter 58000, loss: 0.037802
 >> iter 59000, loss: 0.015832
 >> iter 60000, loss: 0.007502
   Number of active neurons: 10
 >> iter 61000, loss: 0.004441
 >> iter 62000, loss: 0.003213
 >> iter 63000, loss: 0.002544
 >> iter 64000, loss: 0.063974
 >> iter 65000, loss: 0.024998
 >> iter 66000, loss: 0.010633
 >> iter 67000, loss: 0.005189
 >> iter 68000, loss: 0.029393
 >> iter 69000, loss: 0.012562
 >> iter 70000, loss: 0.008202
   Number of active neurons: 10
 >> iter 71000, loss: 0.005226
 >> iter 72000, loss: 0.003042
 >> iter 73000, loss: 0.004313
 >> iter 74000, loss: 0.002890
 >> iter 75000, loss: 0.002450
 >> iter 76000, loss: 0.002013
 >> iter 77000, loss: 0.002213
 >> iter 78000, loss: 0.020671
 >> iter 79000, loss: 0.071082
 >> iter 80000, loss: 0.027824
   Number of active neurons: 10
 >> iter 81000, loss: 0.023600
 >> iter 82000, loss: 0.015058
 >> iter 83000, loss: 0.153957
 >> iter 84000, loss: 0.074853
 >> iter 85000, loss: 0.029641
 >> iter 86000, loss: 0.012667
 >> iter 87000, loss: 0.006215
 >> iter 88000, loss: 0.060276
 >> iter 89000, loss: 0.024247
 >> iter 90000, loss: 0.011933
   Number of active neurons: 10
 >> iter 91000, loss: 0.068447
 >> iter 92000, loss: 0.027513
 >> iter 93000, loss: 0.011794
 >> iter 94000, loss: 0.005943
 >> iter 95000, loss: 0.003578
 >> iter 96000, loss: 0.002880
 >> iter 97000, loss: 0.041555
 >> iter 98000, loss: 0.016889
 >> iter 99000, loss: 0.015389
 >> iter 100000, loss: 0.034891
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.333189
 >> iter 2000, loss: 11.067602
 >> iter 3000, loss: 5.258363
 >> iter 4000, loss: 2.463246
 >> iter 5000, loss: 1.156014
 >> iter 6000, loss: 0.589014
 >> iter 7000, loss: 0.406710
 >> iter 8000, loss: 0.357002
 >> iter 9000, loss: 0.433773
 >> iter 10000, loss: 0.283538
   Number of active neurons: 10
 >> iter 11000, loss: 0.157830
 >> iter 12000, loss: 0.198093
 >> iter 13000, loss: 0.304713
 >> iter 14000, loss: 0.162971
 >> iter 15000, loss: 0.168501
 >> iter 16000, loss: 0.076704
 >> iter 17000, loss: 0.038830
 >> iter 18000, loss: 0.031971
 >> iter 19000, loss: 0.141013
 >> iter 20000, loss: 0.124933
   Number of active neurons: 10
 >> iter 21000, loss: 0.074992
 >> iter 22000, loss: 0.176514
 >> iter 23000, loss: 0.111123
 >> iter 24000, loss: 0.054054
 >> iter 25000, loss: 0.053276
 >> iter 26000, loss: 0.024250
 >> iter 27000, loss: 0.016598
 >> iter 28000, loss: 0.020309
 >> iter 29000, loss: 0.035733
 >> iter 30000, loss: 0.019864
   Number of active neurons: 10
 >> iter 31000, loss: 0.260703
 >> iter 32000, loss: 0.131417
 >> iter 33000, loss: 0.079074
 >> iter 34000, loss: 0.044153
 >> iter 35000, loss: 0.019817
 >> iter 36000, loss: 0.022399
 >> iter 37000, loss: 0.285557
 >> iter 38000, loss: 0.111032
 >> iter 39000, loss: 0.047600
 >> iter 40000, loss: 0.048174
   Number of active neurons: 10
 >> iter 41000, loss: 0.023765
 >> iter 42000, loss: 0.011995
 >> iter 43000, loss: 0.009046
 >> iter 44000, loss: 0.082819
 >> iter 45000, loss: 0.053787
 >> iter 46000, loss: 0.024410
 >> iter 47000, loss: 0.012852
 >> iter 48000, loss: 0.007208
 >> iter 49000, loss: 0.008936
 >> iter 50000, loss: 0.005227
   Number of active neurons: 10
 >> iter 51000, loss: 0.042579
 >> iter 52000, loss: 0.117642
 >> iter 53000, loss: 0.051403
 >> iter 54000, loss: 0.022094
 >> iter 55000, loss: 0.023332
 >> iter 56000, loss: 0.010437
 >> iter 57000, loss: 0.009495
 >> iter 58000, loss: 0.025278
 >> iter 59000, loss: 0.011771
 >> iter 60000, loss: 0.009334
   Number of active neurons: 10
 >> iter 61000, loss: 0.005270
 >> iter 62000, loss: 0.003283
 >> iter 63000, loss: 0.002714
 >> iter 64000, loss: 0.003647
 >> iter 65000, loss: 0.003682
 >> iter 66000, loss: 0.004022
 >> iter 67000, loss: 0.002518
 >> iter 68000, loss: 0.002276
 >> iter 69000, loss: 0.003901
 >> iter 70000, loss: 0.039377
   Number of active neurons: 10
 >> iter 71000, loss: 0.015854
 >> iter 72000, loss: 0.006947
 >> iter 73000, loss: 0.003642
 >> iter 74000, loss: 0.002246
 >> iter 75000, loss: 0.001593
 >> iter 76000, loss: 0.001325
 >> iter 77000, loss: 0.001226
 >> iter 78000, loss: 0.051270
 >> iter 79000, loss: 0.022359
 >> iter 80000, loss: 0.009108
   Number of active neurons: 10
 >> iter 81000, loss: 0.004357
 >> iter 82000, loss: 0.002598
 >> iter 83000, loss: 0.001773
 >> iter 84000, loss: 0.001589
 >> iter 85000, loss: 0.008344
 >> iter 86000, loss: 0.005338
 >> iter 87000, loss: 0.002839
 >> iter 88000, loss: 0.001698
 >> iter 89000, loss: 0.001525
 >> iter 90000, loss: 0.001155
   Number of active neurons: 10
 >> iter 91000, loss: 0.001069
 >> iter 92000, loss: 0.039395
 >> iter 93000, loss: 0.015338
 >> iter 94000, loss: 0.010789
 >> iter 95000, loss: 0.004729
 >> iter 96000, loss: 0.002399
 >> iter 97000, loss: 0.001622
 >> iter 98000, loss: 0.015764
 >> iter 99000, loss: 0.009465
 >> iter 100000, loss: 0.004631
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.072209
 >> iter 2000, loss: 10.777129
 >> iter 3000, loss: 5.440312
 >> iter 4000, loss: 2.911172
 >> iter 5000, loss: 1.420168
 >> iter 6000, loss: 0.752556
 >> iter 7000, loss: 0.373703
 >> iter 8000, loss: 0.160340
 >> iter 9000, loss: 0.311060
 >> iter 10000, loss: 0.209664
   Number of active neurons: 10
 >> iter 11000, loss: 0.232257
 >> iter 12000, loss: 0.106226
 >> iter 13000, loss: 0.058591
 >> iter 14000, loss: 0.095429
 >> iter 15000, loss: 0.090530
 >> iter 16000, loss: 0.053129
 >> iter 17000, loss: 0.129620
 >> iter 18000, loss: 0.057438
 >> iter 19000, loss: 0.043220
 >> iter 20000, loss: 0.036726
   Number of active neurons: 10
 >> iter 21000, loss: 0.240324
 >> iter 22000, loss: 0.094653
 >> iter 23000, loss: 0.039917
 >> iter 24000, loss: 0.027733
 >> iter 25000, loss: 0.159769
 >> iter 26000, loss: 0.065719
 >> iter 27000, loss: 0.029635
 >> iter 28000, loss: 0.057464
 >> iter 29000, loss: 0.027195
 >> iter 30000, loss: 0.021992
   Number of active neurons: 10
 >> iter 31000, loss: 0.014815
 >> iter 32000, loss: 0.029970
 >> iter 33000, loss: 0.014467
 >> iter 34000, loss: 0.013556
 >> iter 35000, loss: 0.008628
 >> iter 36000, loss: 0.005874
 >> iter 37000, loss: 0.004365
 >> iter 38000, loss: 0.136563
 >> iter 39000, loss: 0.054610
 >> iter 40000, loss: 0.029162
   Number of active neurons: 10
 >> iter 41000, loss: 0.016570
 >> iter 42000, loss: 0.008407
 >> iter 43000, loss: 0.005394
 >> iter 44000, loss: 0.086699
 >> iter 45000, loss: 0.034435
 >> iter 46000, loss: 0.063736
 >> iter 47000, loss: 0.026482
 >> iter 48000, loss: 0.011870
 >> iter 49000, loss: 0.008639
 >> iter 50000, loss: 0.004986
   Number of active neurons: 10
 >> iter 51000, loss: 0.003510
 >> iter 52000, loss: 0.004571
 >> iter 53000, loss: 0.003981
 >> iter 54000, loss: 0.002870
 >> iter 55000, loss: 0.002403
 >> iter 56000, loss: 0.002221
 >> iter 57000, loss: 0.002042
 >> iter 58000, loss: 0.080939
 >> iter 59000, loss: 0.052432
 >> iter 60000, loss: 0.112104
   Number of active neurons: 10
 >> iter 61000, loss: 0.047326
 >> iter 62000, loss: 0.019196
 >> iter 63000, loss: 0.009135
 >> iter 64000, loss: 0.005184
 >> iter 65000, loss: 0.003338
 >> iter 66000, loss: 0.002634
 >> iter 67000, loss: 0.002308
 >> iter 68000, loss: 0.002242
 >> iter 69000, loss: 0.001985
 >> iter 70000, loss: 0.002214
   Number of active neurons: 10
 >> iter 71000, loss: 0.002536
 >> iter 72000, loss: 0.002013
 >> iter 73000, loss: 0.001962
 >> iter 74000, loss: 0.001685
 >> iter 75000, loss: 0.001578
 >> iter 76000, loss: 0.001498
 >> iter 77000, loss: 0.001554
 >> iter 78000, loss: 0.001418
 >> iter 79000, loss: 0.001560
 >> iter 80000, loss: 0.001573
   Number of active neurons: 10
 >> iter 81000, loss: 0.002929
 >> iter 82000, loss: 0.001879
 >> iter 83000, loss: 0.001736
 >> iter 84000, loss: 0.001570
 >> iter 85000, loss: 0.001458
 >> iter 86000, loss: 0.001233
 >> iter 87000, loss: 0.001135
 >> iter 88000, loss: 0.001240
 >> iter 89000, loss: 0.001908
 >> iter 90000, loss: 0.001396
   Number of active neurons: 10
 >> iter 91000, loss: 0.002109
 >> iter 92000, loss: 0.001447
 >> iter 93000, loss: 0.001783
 >> iter 94000, loss: 0.001266
 >> iter 95000, loss: 0.001124
 >> iter 96000, loss: 0.001141
 >> iter 97000, loss: 0.001019
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 18.145764
 >> iter 2000, loss: 9.961648
 >> iter 3000, loss: 5.046666
 >> iter 4000, loss: 2.446841
 >> iter 5000, loss: 1.445927
 >> iter 6000, loss: 0.947410
 >> iter 7000, loss: 0.686248
 >> iter 8000, loss: 0.481985
 >> iter 9000, loss: 0.260430
 >> iter 10000, loss: 0.249989
   Number of active neurons: 10
 >> iter 11000, loss: 0.159602
 >> iter 12000, loss: 0.118499
 >> iter 13000, loss: 0.295539
 >> iter 14000, loss: 0.230246
 >> iter 15000, loss: 0.139098
 >> iter 16000, loss: 0.066268
 >> iter 17000, loss: 0.162519
 >> iter 18000, loss: 0.096561
 >> iter 19000, loss: 0.313125
 >> iter 20000, loss: 0.191085
   Number of active neurons: 10
 >> iter 21000, loss: 0.084055
 >> iter 22000, loss: 0.112566
 >> iter 23000, loss: 0.128796
 >> iter 24000, loss: 0.058243
 >> iter 25000, loss: 0.047519
 >> iter 26000, loss: 0.031833
 >> iter 27000, loss: 0.018570
 >> iter 28000, loss: 0.021572
 >> iter 29000, loss: 0.077784
 >> iter 30000, loss: 0.071154
   Number of active neurons: 10
 >> iter 31000, loss: 0.035762
 >> iter 32000, loss: 0.090197
 >> iter 33000, loss: 0.045142
 >> iter 34000, loss: 0.181670
 >> iter 35000, loss: 0.087533
 >> iter 36000, loss: 0.037882
 >> iter 37000, loss: 0.019884
 >> iter 38000, loss: 0.019534
 >> iter 39000, loss: 0.075849
 >> iter 40000, loss: 0.033534
   Number of active neurons: 10
 >> iter 41000, loss: 0.018588
 >> iter 42000, loss: 0.058802
 >> iter 43000, loss: 0.029682
 >> iter 44000, loss: 0.020095
 >> iter 45000, loss: 0.009719
 >> iter 46000, loss: 0.061893
 >> iter 47000, loss: 0.024948
 >> iter 48000, loss: 0.011409
 >> iter 49000, loss: 0.009086
 >> iter 50000, loss: 0.038057
   Number of active neurons: 10
 >> iter 51000, loss: 0.016745
 >> iter 52000, loss: 0.008462
 >> iter 53000, loss: 0.004833
 >> iter 54000, loss: 0.004672
 >> iter 55000, loss: 0.004436
 >> iter 56000, loss: 0.074623
 >> iter 57000, loss: 0.029529
 >> iter 58000, loss: 0.014297
 >> iter 59000, loss: 0.007474
 >> iter 60000, loss: 0.035589
   Number of active neurons: 10
 >> iter 61000, loss: 0.014642
 >> iter 62000, loss: 0.014305
 >> iter 63000, loss: 0.020354
 >> iter 64000, loss: 0.170121
 >> iter 65000, loss: 0.066061
 >> iter 66000, loss: 0.030542
 >> iter 67000, loss: 0.013633
 >> iter 68000, loss: 0.006604
 >> iter 69000, loss: 0.003724
 >> iter 70000, loss: 0.021919
   Number of active neurons: 10
 >> iter 71000, loss: 0.051642
 >> iter 72000, loss: 0.020536
 >> iter 73000, loss: 0.057806
 >> iter 74000, loss: 0.045792
 >> iter 75000, loss: 0.018328
 >> iter 76000, loss: 0.151092
 >> iter 77000, loss: 0.058494
 >> iter 78000, loss: 0.093199
 >> iter 79000, loss: 0.037206
 >> iter 80000, loss: 0.031212
   Number of active neurons: 10
 >> iter 81000, loss: 0.013846
 >> iter 82000, loss: 0.032868
 >> iter 83000, loss: 0.015079
 >> iter 84000, loss: 0.020000
 >> iter 85000, loss: 0.009247
 >> iter 86000, loss: 0.004994
 >> iter 87000, loss: 0.004503
 >> iter 88000, loss: 0.003033
 >> iter 89000, loss: 0.002227
 >> iter 90000, loss: 0.001915
   Number of active neurons: 10
 >> iter 91000, loss: 0.001816
 >> iter 92000, loss: 0.005964
 >> iter 93000, loss: 0.008470
 >> iter 94000, loss: 0.004004
 >> iter 95000, loss: 0.002468
 >> iter 96000, loss: 0.032162
 >> iter 97000, loss: 0.040153
 >> iter 98000, loss: 0.017921
 >> iter 99000, loss: 0.008019
 >> iter 100000, loss: 0.003877
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.081194
 >> iter 2000, loss: 11.029214
 >> iter 3000, loss: 5.913032
 >> iter 4000, loss: 2.854446
 >> iter 5000, loss: 1.616300
 >> iter 6000, loss: 0.773928
 >> iter 7000, loss: 0.464653
 >> iter 8000, loss: 0.425330
 >> iter 9000, loss: 0.302046
 >> iter 10000, loss: 0.362805
   Number of active neurons: 10
 >> iter 11000, loss: 0.190256
 >> iter 12000, loss: 0.221333
 >> iter 13000, loss: 0.136422
 >> iter 14000, loss: 0.060626
 >> iter 15000, loss: 0.029975
 >> iter 16000, loss: 0.060963
 >> iter 17000, loss: 0.036420
 >> iter 18000, loss: 0.150348
 >> iter 19000, loss: 0.211143
 >> iter 20000, loss: 0.127017
   Number of active neurons: 10
 >> iter 21000, loss: 0.088501
 >> iter 22000, loss: 0.039865
 >> iter 23000, loss: 0.073847
 >> iter 24000, loss: 0.033496
 >> iter 25000, loss: 0.017546
 >> iter 26000, loss: 0.170549
 >> iter 27000, loss: 0.092398
 >> iter 28000, loss: 0.067885
 >> iter 29000, loss: 0.162621
 >> iter 30000, loss: 0.168364
   Number of active neurons: 10
 >> iter 31000, loss: 0.082525
 >> iter 32000, loss: 0.095879
 >> iter 33000, loss: 0.046677
 >> iter 34000, loss: 0.023002
 >> iter 35000, loss: 0.012444
 >> iter 36000, loss: 0.012160
 >> iter 37000, loss: 0.009322
 >> iter 38000, loss: 0.006887
 >> iter 39000, loss: 0.007909
 >> iter 40000, loss: 0.006586
   Number of active neurons: 10
 >> iter 41000, loss: 0.071034
 >> iter 42000, loss: 0.034209
 >> iter 43000, loss: 0.016281
 >> iter 44000, loss: 0.008328
 >> iter 45000, loss: 0.005334
 >> iter 46000, loss: 0.003919
 >> iter 47000, loss: 0.055478
 >> iter 48000, loss: 0.035741
 >> iter 49000, loss: 0.048128
 >> iter 50000, loss: 0.021380
   Number of active neurons: 10
 >> iter 51000, loss: 0.014624
 >> iter 52000, loss: 0.009582
 >> iter 53000, loss: 0.028906
 >> iter 54000, loss: 0.015044
 >> iter 55000, loss: 0.012073
 >> iter 56000, loss: 0.006469
 >> iter 57000, loss: 0.028721
 >> iter 58000, loss: 0.012302
 >> iter 59000, loss: 0.116468
 >> iter 60000, loss: 0.046336
   Number of active neurons: 10
 >> iter 61000, loss: 0.039942
 >> iter 62000, loss: 0.032559
 >> iter 63000, loss: 0.016895
 >> iter 64000, loss: 0.011999
 >> iter 65000, loss: 0.006489
 >> iter 66000, loss: 0.005194
 >> iter 67000, loss: 0.003639
 >> iter 68000, loss: 0.002781
 >> iter 69000, loss: 0.077611
 >> iter 70000, loss: 0.051704
   Number of active neurons: 10
 >> iter 71000, loss: 0.030012
 >> iter 72000, loss: 0.013018
 >> iter 73000, loss: 0.006260
 >> iter 74000, loss: 0.003523
 >> iter 75000, loss: 0.002763
 >> iter 76000, loss: 0.002307
 >> iter 77000, loss: 0.001943
 >> iter 78000, loss: 0.001879
 >> iter 79000, loss: 0.002390
 >> iter 80000, loss: 0.001774
   Number of active neurons: 10
 >> iter 81000, loss: 0.001559
 >> iter 82000, loss: 0.001478
 >> iter 83000, loss: 0.002419
 >> iter 84000, loss: 0.002078
 >> iter 85000, loss: 0.001516
 >> iter 86000, loss: 0.001782
 >> iter 87000, loss: 0.002544
 >> iter 88000, loss: 0.043570
 >> iter 89000, loss: 0.025795
 >> iter 90000, loss: 0.013293
   Number of active neurons: 10
 >> iter 91000, loss: 0.005956
 >> iter 92000, loss: 0.155118
 >> iter 93000, loss: 0.116974
 >> iter 94000, loss: 0.045101
 >> iter 95000, loss: 0.018270
 >> iter 96000, loss: 0.009992
 >> iter 97000, loss: 0.005032
 >> iter 98000, loss: 0.021926
 >> iter 99000, loss: 0.009536
 >> iter 100000, loss: 0.004682
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 18.330783
 >> iter 2000, loss: 11.481421
 >> iter 3000, loss: 6.867090
 >> iter 4000, loss: 3.450903
 >> iter 5000, loss: 2.061356
 >> iter 6000, loss: 1.215374
 >> iter 7000, loss: 1.035051
 >> iter 8000, loss: 0.555852
 >> iter 9000, loss: 0.330858
 >> iter 10000, loss: 0.249775
   Number of active neurons: 10
 >> iter 11000, loss: 0.400562
 >> iter 12000, loss: 0.259405
 >> iter 13000, loss: 0.135219
 >> iter 14000, loss: 0.188839
 >> iter 15000, loss: 0.166699
 >> iter 16000, loss: 0.121405
 >> iter 17000, loss: 0.096956
 >> iter 18000, loss: 0.241416
 >> iter 19000, loss: 0.179149
 >> iter 20000, loss: 0.280915
   Number of active neurons: 10
 >> iter 21000, loss: 0.142692
 >> iter 22000, loss: 0.108649
 >> iter 23000, loss: 0.046369
 >> iter 24000, loss: 0.027458
 >> iter 25000, loss: 0.018357
 >> iter 26000, loss: 0.009802
 >> iter 27000, loss: 0.023032
 >> iter 28000, loss: 0.058320
 >> iter 29000, loss: 0.058197
 >> iter 30000, loss: 0.030206
   Number of active neurons: 10
 >> iter 31000, loss: 0.060060
 >> iter 32000, loss: 0.025165
 >> iter 33000, loss: 0.012494
 >> iter 34000, loss: 0.009335
 >> iter 35000, loss: 0.078245
 >> iter 36000, loss: 0.048167
 >> iter 37000, loss: 0.020850
 >> iter 38000, loss: 0.067788
 >> iter 39000, loss: 0.027939
 >> iter 40000, loss: 0.064452
   Number of active neurons: 10
 >> iter 41000, loss: 0.178632
 >> iter 42000, loss: 0.179924
 >> iter 43000, loss: 0.088586
 >> iter 44000, loss: 0.036909
 >> iter 45000, loss: 0.026442
 >> iter 46000, loss: 0.040118
 >> iter 47000, loss: 0.149669
 >> iter 48000, loss: 0.058449
 >> iter 49000, loss: 0.024721
 >> iter 50000, loss: 0.011611
   Number of active neurons: 10
 >> iter 51000, loss: 0.027075
 >> iter 52000, loss: 0.012021
 >> iter 53000, loss: 0.075737
 >> iter 54000, loss: 0.049614
 >> iter 55000, loss: 0.020956
 >> iter 56000, loss: 0.009970
 >> iter 57000, loss: 0.005606
 >> iter 58000, loss: 0.003882
 >> iter 59000, loss: 0.081363
 >> iter 60000, loss: 0.031559
   Number of active neurons: 10
 >> iter 61000, loss: 0.025986
 >> iter 62000, loss: 0.011407
 >> iter 63000, loss: 0.006568
 >> iter 64000, loss: 0.107743
 >> iter 65000, loss: 0.042805
 >> iter 66000, loss: 0.017293
 >> iter 67000, loss: 0.007625
 >> iter 68000, loss: 0.005201
 >> iter 69000, loss: 0.078695
 >> iter 70000, loss: 0.104593
   Number of active neurons: 10
 >> iter 71000, loss: 0.046675
 >> iter 72000, loss: 0.093400
 >> iter 73000, loss: 0.039179
 >> iter 74000, loss: 0.019986
 >> iter 75000, loss: 0.010182
 >> iter 76000, loss: 0.017927
 >> iter 77000, loss: 0.008568
 >> iter 78000, loss: 0.005290
 >> iter 79000, loss: 0.003543
 >> iter 80000, loss: 0.003057
   Number of active neurons: 10
 >> iter 81000, loss: 0.002530
 >> iter 82000, loss: 0.001943
 >> iter 83000, loss: 0.002311
 >> iter 84000, loss: 0.001984
 >> iter 85000, loss: 0.001778
 >> iter 86000, loss: 0.001693
 >> iter 87000, loss: 0.001697
 >> iter 88000, loss: 0.002239
 >> iter 89000, loss: 0.001639
 >> iter 90000, loss: 0.014243
   Number of active neurons: 10
 >> iter 91000, loss: 0.006029
 >> iter 92000, loss: 0.061904
 >> iter 93000, loss: 0.025252
 >> iter 94000, loss: 0.010074
 >> iter 95000, loss: 0.010607
 >> iter 96000, loss: 0.004986
 >> iter 97000, loss: 0.002768
 >> iter 98000, loss: 0.001818
 >> iter 99000, loss: 0.001401
 >> iter 100000, loss: 0.095815
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.567339
 >> iter 2000, loss: 11.284048
 >> iter 3000, loss: 5.753922
 >> iter 4000, loss: 2.818819
 >> iter 5000, loss: 1.275085
 >> iter 6000, loss: 0.840100
 >> iter 7000, loss: 0.560640
 >> iter 8000, loss: 0.240062
 >> iter 9000, loss: 0.105976
 >> iter 10000, loss: 0.168402
   Number of active neurons: 10
 >> iter 11000, loss: 0.076133
 >> iter 12000, loss: 0.109548
 >> iter 13000, loss: 0.083550
 >> iter 14000, loss: 0.048138
 >> iter 15000, loss: 0.071122
 >> iter 16000, loss: 0.109941
 >> iter 17000, loss: 0.317016
 >> iter 18000, loss: 0.136105
 >> iter 19000, loss: 0.206457
 >> iter 20000, loss: 0.101781
   Number of active neurons: 10
 >> iter 21000, loss: 0.076368
 >> iter 22000, loss: 0.033864
 >> iter 23000, loss: 0.017249
 >> iter 24000, loss: 0.048353
 >> iter 25000, loss: 0.022245
 >> iter 26000, loss: 0.011449
 >> iter 27000, loss: 0.050580
 >> iter 28000, loss: 0.083399
 >> iter 29000, loss: 0.106887
 >> iter 30000, loss: 0.053633
   Number of active neurons: 10
 >> iter 31000, loss: 0.028649
 >> iter 32000, loss: 0.013414
 >> iter 33000, loss: 0.136276
 >> iter 34000, loss: 0.146747
 >> iter 35000, loss: 0.086517
 >> iter 36000, loss: 0.036249
 >> iter 37000, loss: 0.016879
 >> iter 38000, loss: 0.009825
 >> iter 39000, loss: 0.006228
 >> iter 40000, loss: 0.008049
   Number of active neurons: 10
 >> iter 41000, loss: 0.044547
 >> iter 42000, loss: 0.069631
 >> iter 43000, loss: 0.028627
 >> iter 44000, loss: 0.016948
 >> iter 45000, loss: 0.008762
 >> iter 46000, loss: 0.085406
 >> iter 47000, loss: 0.198233
 >> iter 48000, loss: 0.076214
 >> iter 49000, loss: 0.094417
 >> iter 50000, loss: 0.038295
   Number of active neurons: 10
 >> iter 51000, loss: 0.022704
 >> iter 52000, loss: 0.010973
 >> iter 53000, loss: 0.006770
 >> iter 54000, loss: 0.004879
 >> iter 55000, loss: 0.003825
 >> iter 56000, loss: 0.008571
 >> iter 57000, loss: 0.005160
 >> iter 58000, loss: 0.003718
 >> iter 59000, loss: 0.012945
 >> iter 60000, loss: 0.008097
   Number of active neurons: 10
 >> iter 61000, loss: 0.022117
 >> iter 62000, loss: 0.009875
 >> iter 63000, loss: 0.004988
 >> iter 64000, loss: 0.040536
 >> iter 65000, loss: 0.016671
 >> iter 66000, loss: 0.007586
 >> iter 67000, loss: 0.004493
 >> iter 68000, loss: 0.002900
 >> iter 69000, loss: 0.128363
 >> iter 70000, loss: 0.049872
   Number of active neurons: 10
 >> iter 71000, loss: 0.020809
 >> iter 72000, loss: 0.009364
 >> iter 73000, loss: 0.005313
 >> iter 74000, loss: 0.004308
 >> iter 75000, loss: 0.020394
 >> iter 76000, loss: 0.008916
 >> iter 77000, loss: 0.004644
 >> iter 78000, loss: 0.003179
 >> iter 79000, loss: 0.002766
 >> iter 80000, loss: 0.002219
   Number of active neurons: 10
 >> iter 81000, loss: 0.002611
 >> iter 82000, loss: 0.003677
 >> iter 83000, loss: 0.002470
 >> iter 84000, loss: 0.029290
 >> iter 85000, loss: 0.012934
 >> iter 86000, loss: 0.005690
 >> iter 87000, loss: 0.002955
 >> iter 88000, loss: 0.001929
 >> iter 89000, loss: 0.001539
 >> iter 90000, loss: 0.001448
   Number of active neurons: 10
 >> iter 91000, loss: 0.002448
 >> iter 92000, loss: 0.001809
 >> iter 93000, loss: 0.062323
 >> iter 94000, loss: 0.072069
 >> iter 95000, loss: 0.047746
 >> iter 96000, loss: 0.018956
 >> iter 97000, loss: 0.008193
 >> iter 98000, loss: 0.037594
 >> iter 99000, loss: 0.015016
 >> iter 100000, loss: 0.020084
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.396410
 >> iter 2000, loss: 11.585067
 >> iter 3000, loss: 6.265652
 >> iter 4000, loss: 3.199168
 >> iter 5000, loss: 1.766161
 >> iter 6000, loss: 1.026998
 >> iter 7000, loss: 0.636841
 >> iter 8000, loss: 0.784428
 >> iter 9000, loss: 0.613121
 >> iter 10000, loss: 0.420211
   Number of active neurons: 10
 >> iter 11000, loss: 0.472397
 >> iter 12000, loss: 0.453882
 >> iter 13000, loss: 0.200836
 >> iter 14000, loss: 0.239389
 >> iter 15000, loss: 0.411635
 >> iter 16000, loss: 0.275816
 >> iter 17000, loss: 0.276507
 >> iter 18000, loss: 0.132212
 >> iter 19000, loss: 0.118978
 >> iter 20000, loss: 0.071197
   Number of active neurons: 10
 >> iter 21000, loss: 0.072642
 >> iter 22000, loss: 0.031647
 >> iter 23000, loss: 0.018886
 >> iter 24000, loss: 0.013856
 >> iter 25000, loss: 0.066553
 >> iter 26000, loss: 0.064746
 >> iter 27000, loss: 0.099263
 >> iter 28000, loss: 0.065448
 >> iter 29000, loss: 0.093845
 >> iter 30000, loss: 0.079425
   Number of active neurons: 10
 >> iter 31000, loss: 0.042640
 >> iter 32000, loss: 0.103833
 >> iter 33000, loss: 0.050946
 >> iter 34000, loss: 0.022216
 >> iter 35000, loss: 0.014240
 >> iter 36000, loss: 0.009357
 >> iter 37000, loss: 0.006156
 >> iter 38000, loss: 0.014223
 >> iter 39000, loss: 0.009399
 >> iter 40000, loss: 0.095882
   Number of active neurons: 10
 >> iter 41000, loss: 0.060091
 >> iter 42000, loss: 0.025375
 >> iter 43000, loss: 0.011578
 >> iter 44000, loss: 0.007964
 >> iter 45000, loss: 0.016437
 >> iter 46000, loss: 0.007897
 >> iter 47000, loss: 0.004842
 >> iter 48000, loss: 0.003507
 >> iter 49000, loss: 0.003137
 >> iter 50000, loss: 0.163840
   Number of active neurons: 10
 >> iter 51000, loss: 0.063715
 >> iter 52000, loss: 0.160456
 >> iter 53000, loss: 0.102116
 >> iter 54000, loss: 0.040597
 >> iter 55000, loss: 0.018145
 >> iter 56000, loss: 0.008993
 >> iter 57000, loss: 0.013702
 >> iter 58000, loss: 0.007213
 >> iter 59000, loss: 0.004920
 >> iter 60000, loss: 0.106136
   Number of active neurons: 10
 >> iter 61000, loss: 0.052004
 >> iter 62000, loss: 0.036360
 >> iter 63000, loss: 0.124131
 >> iter 64000, loss: 0.047833
 >> iter 65000, loss: 0.019758
 >> iter 66000, loss: 0.033185
 >> iter 67000, loss: 0.015309
 >> iter 68000, loss: 0.007173
 >> iter 69000, loss: 0.047314
 >> iter 70000, loss: 0.018558
   Number of active neurons: 10
 >> iter 71000, loss: 0.008352
 >> iter 72000, loss: 0.007334
 >> iter 73000, loss: 0.003886
 >> iter 74000, loss: 0.002426
 >> iter 75000, loss: 0.001661
 >> iter 76000, loss: 0.001532
 >> iter 77000, loss: 0.002462
 >> iter 78000, loss: 0.001737
 >> iter 79000, loss: 0.001301
 >> iter 80000, loss: 0.012215
   Number of active neurons: 10
 >> iter 81000, loss: 0.005471
 >> iter 82000, loss: 0.002842
 >> iter 83000, loss: 0.001903
 >> iter 84000, loss: 0.048097
 >> iter 85000, loss: 0.019077
 >> iter 86000, loss: 0.009595
 >> iter 87000, loss: 0.004513
 >> iter 88000, loss: 0.003409
 >> iter 89000, loss: 0.052001
 >> iter 90000, loss: 0.021956
   Number of active neurons: 10
 >> iter 91000, loss: 0.008981
 >> iter 92000, loss: 0.004077
 >> iter 93000, loss: 0.002214
 >> iter 94000, loss: 0.001553
 >> iter 95000, loss: 0.086933
 >> iter 96000, loss: 0.038357
 >> iter 97000, loss: 0.029459
 >> iter 98000, loss: 0.011916
 >> iter 99000, loss: 0.005472
 >> iter 100000, loss: 0.003455
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.063866
 >> iter 2000, loss: 11.168296
 >> iter 3000, loss: 5.980014
 >> iter 4000, loss: 3.277121
 >> iter 5000, loss: 1.926825
 >> iter 6000, loss: 1.253261
 >> iter 7000, loss: 1.200590
 >> iter 8000, loss: 0.765230
 >> iter 9000, loss: 0.757966
 >> iter 10000, loss: 0.508471
   Number of active neurons: 10
 >> iter 11000, loss: 0.375730
 >> iter 12000, loss: 0.416572
 >> iter 13000, loss: 0.246069
 >> iter 14000, loss: 0.191311
 >> iter 15000, loss: 0.213455
 >> iter 16000, loss: 0.176172
 >> iter 17000, loss: 0.123624
 >> iter 18000, loss: 0.179077
 >> iter 19000, loss: 0.189409
 >> iter 20000, loss: 0.078761
   Number of active neurons: 10
 >> iter 21000, loss: 0.113801
 >> iter 22000, loss: 0.052151
 >> iter 23000, loss: 0.043286
 >> iter 24000, loss: 0.106217
 >> iter 25000, loss: 0.043624
 >> iter 26000, loss: 0.109950
 >> iter 27000, loss: 0.053595
 >> iter 28000, loss: 0.043535
 >> iter 29000, loss: 0.051078
 >> iter 30000, loss: 0.023365
   Number of active neurons: 10
 >> iter 31000, loss: 0.087964
 >> iter 32000, loss: 0.037093
 >> iter 33000, loss: 0.097735
 >> iter 34000, loss: 0.097579
 >> iter 35000, loss: 0.042919
 >> iter 36000, loss: 0.056399
 >> iter 37000, loss: 0.150999
 >> iter 38000, loss: 0.115329
 >> iter 39000, loss: 0.099431
 >> iter 40000, loss: 0.043352
   Number of active neurons: 10
 >> iter 41000, loss: 0.019499
 >> iter 42000, loss: 0.055279
 >> iter 43000, loss: 0.023589
 >> iter 44000, loss: 0.137180
 >> iter 45000, loss: 0.165898
 >> iter 46000, loss: 0.090950
 >> iter 47000, loss: 0.072829
 >> iter 48000, loss: 0.083018
 >> iter 49000, loss: 0.035575
 >> iter 50000, loss: 0.028641
   Number of active neurons: 10
 >> iter 51000, loss: 0.013409
 >> iter 52000, loss: 0.012646
 >> iter 53000, loss: 0.077100
 >> iter 54000, loss: 0.031260
 >> iter 55000, loss: 0.014011
 >> iter 56000, loss: 0.054798
 >> iter 57000, loss: 0.092142
 >> iter 58000, loss: 0.036304
 >> iter 59000, loss: 0.015579
 >> iter 60000, loss: 0.007207
   Number of active neurons: 10
 >> iter 61000, loss: 0.004152
 >> iter 62000, loss: 0.002806
 >> iter 63000, loss: 0.063252
 >> iter 64000, loss: 0.070974
 >> iter 65000, loss: 0.058328
 >> iter 66000, loss: 0.030160
 >> iter 67000, loss: 0.023827
 >> iter 68000, loss: 0.014643
 >> iter 69000, loss: 0.039313
 >> iter 70000, loss: 0.033513
   Number of active neurons: 10
 >> iter 71000, loss: 0.014605
 >> iter 72000, loss: 0.009149
 >> iter 73000, loss: 0.037338
 >> iter 74000, loss: 0.093101
 >> iter 75000, loss: 0.172246
 >> iter 76000, loss: 0.067405
 >> iter 77000, loss: 0.027053
 >> iter 78000, loss: 0.016478
 >> iter 79000, loss: 0.020875
 >> iter 80000, loss: 0.032472
   Number of active neurons: 10
 >> iter 81000, loss: 0.059034
 >> iter 82000, loss: 0.029672
 >> iter 83000, loss: 0.032818
 >> iter 84000, loss: 0.018073
 >> iter 85000, loss: 0.009011
 >> iter 86000, loss: 0.005018
 >> iter 87000, loss: 0.005846
 >> iter 88000, loss: 0.003622
 >> iter 89000, loss: 0.002840
 >> iter 90000, loss: 0.002351
   Number of active neurons: 10
 >> iter 91000, loss: 0.023062
 >> iter 92000, loss: 0.015202
 >> iter 93000, loss: 0.006753
 >> iter 94000, loss: 0.020973
 >> iter 95000, loss: 0.008777
 >> iter 96000, loss: 0.004286
 >> iter 97000, loss: 0.002677
 >> iter 98000, loss: 0.032940
 >> iter 99000, loss: 0.013770
 >> iter 100000, loss: 0.006293
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.157199
 >> iter 2000, loss: 10.696389
 >> iter 3000, loss: 5.316496
 >> iter 4000, loss: 2.590589
 >> iter 5000, loss: 1.401024
 >> iter 6000, loss: 0.797007
 >> iter 7000, loss: 0.397901
 >> iter 8000, loss: 0.195925
 >> iter 9000, loss: 0.423426
 >> iter 10000, loss: 0.241953
   Number of active neurons: 10
 >> iter 11000, loss: 0.392855
 >> iter 12000, loss: 0.217414
 >> iter 13000, loss: 0.146745
 >> iter 14000, loss: 0.065967
 >> iter 15000, loss: 0.123467
 >> iter 16000, loss: 0.087944
 >> iter 17000, loss: 0.060561
 >> iter 18000, loss: 0.148356
 >> iter 19000, loss: 0.122758
 >> iter 20000, loss: 0.056004
   Number of active neurons: 10
 >> iter 21000, loss: 0.095306
 >> iter 22000, loss: 0.041236
 >> iter 23000, loss: 0.134134
 >> iter 24000, loss: 0.056357
 >> iter 25000, loss: 0.073651
 >> iter 26000, loss: 0.087539
 >> iter 27000, loss: 0.044669
 >> iter 28000, loss: 0.038277
 >> iter 29000, loss: 0.018685
 >> iter 30000, loss: 0.010571
   Number of active neurons: 10
 >> iter 31000, loss: 0.203333
 >> iter 32000, loss: 0.126341
 >> iter 33000, loss: 0.057030
 >> iter 34000, loss: 0.026803
 >> iter 35000, loss: 0.030833
 >> iter 36000, loss: 0.018276
 >> iter 37000, loss: 0.013632
 >> iter 38000, loss: 0.009344
 >> iter 39000, loss: 0.005947
 >> iter 40000, loss: 0.005168
   Number of active neurons: 10
 >> iter 41000, loss: 0.187001
 >> iter 42000, loss: 0.080225
 >> iter 43000, loss: 0.032454
 >> iter 44000, loss: 0.053632
 >> iter 45000, loss: 0.023874
 >> iter 46000, loss: 0.011335
 >> iter 47000, loss: 0.006357
 >> iter 48000, loss: 0.005204
 >> iter 49000, loss: 0.004014
 >> iter 50000, loss: 0.003379
   Number of active neurons: 10
 >> iter 51000, loss: 0.002946
 >> iter 52000, loss: 0.002758
 >> iter 53000, loss: 0.025833
 >> iter 54000, loss: 0.013097
 >> iter 55000, loss: 0.007374
 >> iter 56000, loss: 0.004945
 >> iter 57000, loss: 0.006276
 >> iter 58000, loss: 0.004415
 >> iter 59000, loss: 0.006500
 >> iter 60000, loss: 0.003968
   Number of active neurons: 10
 >> iter 61000, loss: 0.003340
 >> iter 62000, loss: 0.009382
 >> iter 63000, loss: 0.004980
 >> iter 64000, loss: 0.054462
 >> iter 65000, loss: 0.021894
 >> iter 66000, loss: 0.009393
 >> iter 67000, loss: 0.004674
 >> iter 68000, loss: 0.003773
 >> iter 69000, loss: 0.002563
 >> iter 70000, loss: 0.002422
   Number of active neurons: 10
 >> iter 71000, loss: 0.077017
 >> iter 72000, loss: 0.182594
 >> iter 73000, loss: 0.069105
 >> iter 74000, loss: 0.027389
 >> iter 75000, loss: 0.012271
 >> iter 76000, loss: 0.008706
 >> iter 77000, loss: 0.011892
 >> iter 78000, loss: 0.005857
 >> iter 79000, loss: 0.003318
 >> iter 80000, loss: 0.002371
   Number of active neurons: 10
 >> iter 81000, loss: 0.002204
 >> iter 82000, loss: 0.001894
 >> iter 83000, loss: 0.001721
 >> iter 84000, loss: 0.002532
 >> iter 85000, loss: 0.001840
 >> iter 86000, loss: 0.001824
 >> iter 87000, loss: 0.055767
 >> iter 88000, loss: 0.021780
 >> iter 89000, loss: 0.021269
 >> iter 90000, loss: 0.026301
   Number of active neurons: 10
 >> iter 91000, loss: 0.011002
 >> iter 92000, loss: 0.005259
 >> iter 93000, loss: 0.003410
 >> iter 94000, loss: 0.014190
 >> iter 95000, loss: 0.006709
 >> iter 96000, loss: 0.003603
 >> iter 97000, loss: 0.002271
 >> iter 98000, loss: 0.039524
 >> iter 99000, loss: 0.015826
 >> iter 100000, loss: 0.007780
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 18.205894
 >> iter 2000, loss: 11.458658
 >> iter 3000, loss: 5.546361
 >> iter 4000, loss: 2.731891
 >> iter 5000, loss: 1.233677
 >> iter 6000, loss: 0.686736
 >> iter 7000, loss: 0.366492
 >> iter 8000, loss: 0.157132
 >> iter 9000, loss: 0.278598
 >> iter 10000, loss: 0.158462
   Number of active neurons: 10
 >> iter 11000, loss: 0.100461
 >> iter 12000, loss: 0.179852
 >> iter 13000, loss: 0.076518
 >> iter 14000, loss: 0.192653
 >> iter 15000, loss: 0.315808
 >> iter 16000, loss: 0.184332
 >> iter 17000, loss: 0.308519
 >> iter 18000, loss: 0.146697
 >> iter 19000, loss: 0.194423
 >> iter 20000, loss: 0.081820
   Number of active neurons: 10
 >> iter 21000, loss: 0.037559
 >> iter 22000, loss: 0.021266
 >> iter 23000, loss: 0.013502
 >> iter 24000, loss: 0.030525
 >> iter 25000, loss: 0.043229
 >> iter 26000, loss: 0.019418
 >> iter 27000, loss: 0.010436
 >> iter 28000, loss: 0.007144
 >> iter 29000, loss: 0.029233
 >> iter 30000, loss: 0.013338
   Number of active neurons: 10
 >> iter 31000, loss: 0.007099
 >> iter 32000, loss: 0.080973
 >> iter 33000, loss: 0.033760
 >> iter 34000, loss: 0.111217
 >> iter 35000, loss: 0.044762
 >> iter 36000, loss: 0.022152
 >> iter 37000, loss: 0.011257
 >> iter 38000, loss: 0.009275
 >> iter 39000, loss: 0.006147
 >> iter 40000, loss: 0.076110
   Number of active neurons: 10
 >> iter 41000, loss: 0.032548
 >> iter 42000, loss: 0.014235
 >> iter 43000, loss: 0.009821
 >> iter 44000, loss: 0.005909
 >> iter 45000, loss: 0.003850
 >> iter 46000, loss: 0.003188
 >> iter 47000, loss: 0.002645
 >> iter 48000, loss: 0.002770
 >> iter 49000, loss: 0.002814
 >> iter 50000, loss: 0.040124
   Number of active neurons: 10
 >> iter 51000, loss: 0.047708
 >> iter 52000, loss: 0.141040
 >> iter 53000, loss: 0.054910
 >> iter 54000, loss: 0.022887
 >> iter 55000, loss: 0.010719
 >> iter 56000, loss: 0.006282
 >> iter 57000, loss: 0.004169
 >> iter 58000, loss: 0.003018
 >> iter 59000, loss: 0.002651
 >> iter 60000, loss: 0.002232
   Number of active neurons: 10
 >> iter 61000, loss: 0.002156
 >> iter 62000, loss: 0.002198
 >> iter 63000, loss: 0.033837
 >> iter 64000, loss: 0.014558
 >> iter 65000, loss: 0.006815
 >> iter 66000, loss: 0.003851
 >> iter 67000, loss: 0.017126
 >> iter 68000, loss: 0.229827
 >> iter 69000, loss: 0.087408
 >> iter 70000, loss: 0.083929
   Number of active neurons: 10
 >> iter 71000, loss: 0.033586
 >> iter 72000, loss: 0.014460
 >> iter 73000, loss: 0.007128
 >> iter 74000, loss: 0.009320
 >> iter 75000, loss: 0.004795
 >> iter 76000, loss: 0.006885
 >> iter 77000, loss: 0.006092
 >> iter 78000, loss: 0.024848
 >> iter 79000, loss: 0.010409
 >> iter 80000, loss: 0.005020
   Number of active neurons: 10
 >> iter 81000, loss: 0.065053
 >> iter 82000, loss: 0.151523
 >> iter 83000, loss: 0.058894
 >> iter 84000, loss: 0.024287
 >> iter 85000, loss: 0.031507
 >> iter 86000, loss: 0.014015
 >> iter 87000, loss: 0.006956
 >> iter 88000, loss: 0.006876
 >> iter 89000, loss: 0.009080
 >> iter 90000, loss: 0.005270
   Number of active neurons: 10
 >> iter 91000, loss: 0.003222
 >> iter 92000, loss: 0.169518
 >> iter 93000, loss: 0.063784
 >> iter 94000, loss: 0.078926
 >> iter 95000, loss: 0.038826
 >> iter 96000, loss: 0.120846
 >> iter 97000, loss: 0.046590
 >> iter 98000, loss: 0.018889
 >> iter 99000, loss: 0.008476
 >> iter 100000, loss: 0.004478
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.325122
 >> iter 2000, loss: 11.263233
 >> iter 3000, loss: 5.776565
 >> iter 4000, loss: 2.825256
 >> iter 5000, loss: 1.398502
 >> iter 6000, loss: 0.832527
 >> iter 7000, loss: 0.528664
 >> iter 8000, loss: 0.397756
 >> iter 9000, loss: 0.210813
 >> iter 10000, loss: 0.207946
   Number of active neurons: 10
 >> iter 11000, loss: 0.121650
 >> iter 12000, loss: 0.149443
 >> iter 13000, loss: 0.064813
 >> iter 14000, loss: 0.076458
 >> iter 15000, loss: 0.212462
 >> iter 16000, loss: 0.105237
 >> iter 17000, loss: 0.084708
 >> iter 18000, loss: 0.101683
 >> iter 19000, loss: 0.067885
 >> iter 20000, loss: 0.132505
   Number of active neurons: 10
 >> iter 21000, loss: 0.097408
 >> iter 22000, loss: 0.043653
 >> iter 23000, loss: 0.060840
 >> iter 24000, loss: 0.053875
 >> iter 25000, loss: 0.049478
 >> iter 26000, loss: 0.044480
 >> iter 27000, loss: 0.040940
 >> iter 28000, loss: 0.020980
 >> iter 29000, loss: 0.011949
 >> iter 30000, loss: 0.046053
   Number of active neurons: 10
 >> iter 31000, loss: 0.021091
 >> iter 32000, loss: 0.040310
 >> iter 33000, loss: 0.019554
 >> iter 34000, loss: 0.010766
 >> iter 35000, loss: 0.090673
 >> iter 36000, loss: 0.037318
 >> iter 37000, loss: 0.018234
 >> iter 38000, loss: 0.009414
 >> iter 39000, loss: 0.005724
 >> iter 40000, loss: 0.004540
   Number of active neurons: 10
 >> iter 41000, loss: 0.003313
 >> iter 42000, loss: 0.002559
 >> iter 43000, loss: 0.092020
 >> iter 44000, loss: 0.036695
 >> iter 45000, loss: 0.017239
 >> iter 46000, loss: 0.008339
 >> iter 47000, loss: 0.051675
 >> iter 48000, loss: 0.056375
 >> iter 49000, loss: 0.041723
 >> iter 50000, loss: 0.033836
   Number of active neurons: 10
 >> iter 51000, loss: 0.015540
 >> iter 52000, loss: 0.007729
 >> iter 53000, loss: 0.043524
 >> iter 54000, loss: 0.026964
 >> iter 55000, loss: 0.012064
 >> iter 56000, loss: 0.005862
 >> iter 57000, loss: 0.007937
 >> iter 58000, loss: 0.068495
 >> iter 59000, loss: 0.221656
 >> iter 60000, loss: 0.101663
   Number of active neurons: 10
 >> iter 61000, loss: 0.039907
 >> iter 62000, loss: 0.016828
 >> iter 63000, loss: 0.008858
 >> iter 64000, loss: 0.005045
 >> iter 65000, loss: 0.004401
 >> iter 66000, loss: 0.003038
 >> iter 67000, loss: 0.004639
 >> iter 68000, loss: 0.003008
 >> iter 69000, loss: 0.002251
 >> iter 70000, loss: 0.024443
   Number of active neurons: 10
 >> iter 71000, loss: 0.010859
 >> iter 72000, loss: 0.069245
 >> iter 73000, loss: 0.035398
 >> iter 74000, loss: 0.014734
 >> iter 75000, loss: 0.007640
 >> iter 76000, loss: 0.004984
 >> iter 77000, loss: 0.005689
 >> iter 78000, loss: 0.003224
 >> iter 79000, loss: 0.002530
 >> iter 80000, loss: 0.010543
   Number of active neurons: 10
 >> iter 81000, loss: 0.004988
 >> iter 82000, loss: 0.002692
 >> iter 83000, loss: 0.002702
 >> iter 84000, loss: 0.002759
 >> iter 85000, loss: 0.001983
 >> iter 86000, loss: 0.001435
 >> iter 87000, loss: 0.020181
 >> iter 88000, loss: 0.008338
 >> iter 89000, loss: 0.003930
 >> iter 90000, loss: 0.069095
   Number of active neurons: 10
 >> iter 91000, loss: 0.028668
 >> iter 92000, loss: 0.011522
 >> iter 93000, loss: 0.005203
 >> iter 94000, loss: 0.002728
 >> iter 95000, loss: 0.001827
 >> iter 96000, loss: 0.001355
 >> iter 97000, loss: 0.001200
 >> iter 98000, loss: 0.001102
 >> iter 99000, loss: 0.001085
 >> iter 100000, loss: 0.002951
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.374166
 >> iter 2000, loss: 10.644984
 >> iter 3000, loss: 5.297610
 >> iter 4000, loss: 2.731684
 >> iter 5000, loss: 1.365695
 >> iter 6000, loss: 0.643471
 >> iter 7000, loss: 0.526977
 >> iter 8000, loss: 0.584946
 >> iter 9000, loss: 0.314480
 >> iter 10000, loss: 0.461956
   Number of active neurons: 10
 >> iter 11000, loss: 0.403611
 >> iter 12000, loss: 0.331967
 >> iter 13000, loss: 0.171288
 >> iter 14000, loss: 0.156350
 >> iter 15000, loss: 0.106156
 >> iter 16000, loss: 0.092690
 >> iter 17000, loss: 0.127523
 >> iter 18000, loss: 0.204212
 >> iter 19000, loss: 0.084453
 >> iter 20000, loss: 0.037459
   Number of active neurons: 10
 >> iter 21000, loss: 0.038044
 >> iter 22000, loss: 0.103560
 >> iter 23000, loss: 0.149806
 >> iter 24000, loss: 0.063005
 >> iter 25000, loss: 0.029402
 >> iter 26000, loss: 0.080308
 >> iter 27000, loss: 0.065506
 >> iter 28000, loss: 0.082376
 >> iter 29000, loss: 0.171746
 >> iter 30000, loss: 0.070886
   Number of active neurons: 10
 >> iter 31000, loss: 0.092420
 >> iter 32000, loss: 0.063206
 >> iter 33000, loss: 0.112302
 >> iter 34000, loss: 0.053334
 >> iter 35000, loss: 0.025201
 >> iter 36000, loss: 0.014737
 >> iter 37000, loss: 0.009848
 >> iter 38000, loss: 0.007053
 >> iter 39000, loss: 0.006038
 >> iter 40000, loss: 0.004679
   Number of active neurons: 10
 >> iter 41000, loss: 0.005120
 >> iter 42000, loss: 0.004051
 >> iter 43000, loss: 0.003304
 >> iter 44000, loss: 0.003635
 >> iter 45000, loss: 0.006196
 >> iter 46000, loss: 0.003875
 >> iter 47000, loss: 0.002899
 >> iter 48000, loss: 0.011868
 >> iter 49000, loss: 0.019688
 >> iter 50000, loss: 0.017399
   Number of active neurons: 10
 >> iter 51000, loss: 0.051057
 >> iter 52000, loss: 0.070060
 >> iter 53000, loss: 0.027926
 >> iter 54000, loss: 0.012002
 >> iter 55000, loss: 0.010735
 >> iter 56000, loss: 0.005342
 >> iter 57000, loss: 0.003471
 >> iter 58000, loss: 0.002689
 >> iter 59000, loss: 0.002411
 >> iter 60000, loss: 0.002185
   Number of active neurons: 10
 >> iter 61000, loss: 0.001802
 >> iter 62000, loss: 0.007253
 >> iter 63000, loss: 0.028931
 >> iter 64000, loss: 0.061631
 >> iter 65000, loss: 0.029865
 >> iter 66000, loss: 0.012491
 >> iter 67000, loss: 0.006240
 >> iter 68000, loss: 0.003477
 >> iter 69000, loss: 0.009534
 >> iter 70000, loss: 0.010582
   Number of active neurons: 10
 >> iter 71000, loss: 0.005830
 >> iter 72000, loss: 0.003069
 >> iter 73000, loss: 0.002134
 >> iter 74000, loss: 0.005180
 >> iter 75000, loss: 0.004177
 >> iter 76000, loss: 0.002479
 >> iter 77000, loss: 0.003417
 >> iter 78000, loss: 0.001972
 >> iter 79000, loss: 0.004169
 >> iter 80000, loss: 0.004039
   Number of active neurons: 10
 >> iter 81000, loss: 0.007713
 >> iter 82000, loss: 0.007342
 >> iter 83000, loss: 0.046728
 >> iter 84000, loss: 0.018550
 >> iter 85000, loss: 0.009232
 >> iter 86000, loss: 0.004281
 >> iter 87000, loss: 0.003126
 >> iter 88000, loss: 0.004303
 >> iter 89000, loss: 0.005838
 >> iter 90000, loss: 0.004121
   Number of active neurons: 10
 >> iter 91000, loss: 0.076409
 >> iter 92000, loss: 0.029309
 >> iter 93000, loss: 0.011590
 >> iter 94000, loss: 0.006261
 >> iter 95000, loss: 0.003114
 >> iter 96000, loss: 0.001943
 >> iter 97000, loss: 0.002956
 >> iter 98000, loss: 0.002037
 >> iter 99000, loss: 0.001538
 >> iter 100000, loss: 0.106901
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

