 > Problema: tomita3nueva
 > Args:
   - Hidden size: 16
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 19.001036
 >> iter 2000, loss: 10.667334
 >> iter 3000, loss: 4.647179
 >> iter 4000, loss: 1.982855
 >> iter 5000, loss: 0.834463
 >> iter 6000, loss: 0.535425
 >> iter 7000, loss: 0.310560
 >> iter 8000, loss: 0.235273
 >> iter 9000, loss: 0.196921
 >> iter 10000, loss: 0.244666
   Number of active neurons: 6
 >> iter 11000, loss: 0.163266
 >> iter 12000, loss: 0.130924
 >> iter 13000, loss: 0.199094
 >> iter 14000, loss: 0.181312
 >> iter 15000, loss: 0.310233
 >> iter 16000, loss: 0.232710
 >> iter 17000, loss: 0.176377
 >> iter 18000, loss: 0.162072
 >> iter 19000, loss: 0.169312
 >> iter 20000, loss: 0.211053
   Number of active neurons: 6
 >> iter 21000, loss: 0.206398
 >> iter 22000, loss: 0.365453
 >> iter 23000, loss: 0.254025
 >> iter 24000, loss: 0.257270
 >> iter 25000, loss: 0.229041
 >> iter 26000, loss: 0.268964
 >> iter 27000, loss: 0.198632
 >> iter 28000, loss: 0.213397
 >> iter 29000, loss: 0.193101
 >> iter 30000, loss: 0.224583
   Number of active neurons: 6
 >> iter 31000, loss: 0.355680
 >> iter 32000, loss: 0.245602
 >> iter 33000, loss: 0.286059
 >> iter 34000, loss: 0.246394
 >> iter 35000, loss: 0.183123
 >> iter 36000, loss: 0.318838
 >> iter 37000, loss: 0.217645
 >> iter 38000, loss: 0.285012
 >> iter 39000, loss: 0.223500
 >> iter 40000, loss: 0.171746
   Number of active neurons: 5
 >> iter 41000, loss: 0.234144
 >> iter 42000, loss: 0.176541
 >> iter 43000, loss: 0.244198
 >> iter 44000, loss: 0.207206
 >> iter 45000, loss: 0.245316
 >> iter 46000, loss: 0.542742
 >> iter 47000, loss: 0.295343
 >> iter 48000, loss: 0.204777
 >> iter 49000, loss: 0.185328
 >> iter 50000, loss: 0.227486
   Number of active neurons: 5
 >> iter 51000, loss: 0.245457
 >> iter 52000, loss: 0.322824
 >> iter 53000, loss: 0.261517
 >> iter 54000, loss: 0.200415
 >> iter 55000, loss: 0.234591
 >> iter 56000, loss: 0.153290
 >> iter 57000, loss: 0.271132
 >> iter 58000, loss: 0.279578
 >> iter 59000, loss: 0.320745
 >> iter 60000, loss: 0.256379
   Number of active neurons: 5
 >> iter 61000, loss: 0.256350
 >> iter 62000, loss: 0.219833
 >> iter 63000, loss: 0.368744
 >> iter 64000, loss: 0.269594
 >> iter 65000, loss: 0.252691
 >> iter 66000, loss: 0.301853
 >> iter 67000, loss: 0.194268
 >> iter 68000, loss: 0.192551
 >> iter 69000, loss: 0.178489
 >> iter 70000, loss: 0.219368
   Number of active neurons: 5
 >> iter 71000, loss: 0.365487
 >> iter 72000, loss: 0.238093
 >> iter 73000, loss: 0.255462
 >> iter 74000, loss: 0.140458
 >> iter 75000, loss: 0.188459
 >> iter 76000, loss: 0.273087
 >> iter 77000, loss: 0.345341
 >> iter 78000, loss: 0.190481
 >> iter 79000, loss: 0.198992
 >> iter 80000, loss: 0.223482
   Number of active neurons: 4
 >> iter 81000, loss: 0.283208
 >> iter 82000, loss: 0.186184
 >> iter 83000, loss: 0.255592
 >> iter 84000, loss: 0.187570
 >> iter 85000, loss: 0.236671
 >> iter 86000, loss: 0.270137
 >> iter 87000, loss: 0.270307
 >> iter 88000, loss: 0.206126
 >> iter 89000, loss: 0.198006
 >> iter 90000, loss: 0.254197
   Number of active neurons: 4
 >> iter 91000, loss: 0.194394
 >> iter 92000, loss: 0.237047
 >> iter 93000, loss: 0.241334
 >> iter 94000, loss: 0.136727
 >> iter 95000, loss: 0.230035
 >> iter 96000, loss: 0.151112
 >> iter 97000, loss: 0.133148
 >> iter 98000, loss: 0.140333
 >> iter 99000, loss: 0.213816
 >> iter 100000, loss: 0.276439
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.026625
 >> iter 2000, loss: 10.954286
 >> iter 3000, loss: 5.045637
 >> iter 4000, loss: 2.364767
 >> iter 5000, loss: 1.215735
 >> iter 6000, loss: 0.620622
 >> iter 7000, loss: 0.702368
 >> iter 8000, loss: 0.625624
 >> iter 9000, loss: 0.324238
 >> iter 10000, loss: 0.441180
   Number of active neurons: 7
 >> iter 11000, loss: 0.329249
 >> iter 12000, loss: 0.494092
 >> iter 13000, loss: 0.562127
 >> iter 14000, loss: 0.374691
 >> iter 15000, loss: 0.304399
 >> iter 16000, loss: 0.367270
 >> iter 17000, loss: 0.317634
 >> iter 18000, loss: 0.316210
 >> iter 19000, loss: 0.429169
 >> iter 20000, loss: 0.505302
   Number of active neurons: 7
 >> iter 21000, loss: 0.392197
 >> iter 22000, loss: 0.346365
 >> iter 23000, loss: 0.274972
 >> iter 24000, loss: 0.290847
 >> iter 25000, loss: 0.263253
 >> iter 26000, loss: 0.414150
 >> iter 27000, loss: 0.273669
 >> iter 28000, loss: 0.266388
 >> iter 29000, loss: 0.190514
 >> iter 30000, loss: 0.144781
   Number of active neurons: 7
 >> iter 31000, loss: 0.263379
 >> iter 32000, loss: 0.196972
 >> iter 33000, loss: 0.120391
 >> iter 34000, loss: 0.219965
 >> iter 35000, loss: 0.230613
 >> iter 36000, loss: 0.211931
 >> iter 37000, loss: 0.225938
 >> iter 38000, loss: 0.237846
 >> iter 39000, loss: 0.251583
 >> iter 40000, loss: 0.200972
   Number of active neurons: 7
 >> iter 41000, loss: 0.158155
 >> iter 42000, loss: 0.155645
 >> iter 43000, loss: 0.467216
 >> iter 44000, loss: 0.306201
 >> iter 45000, loss: 0.304475
 >> iter 46000, loss: 0.300507
 >> iter 47000, loss: 0.363430
 >> iter 48000, loss: 0.227827
 >> iter 49000, loss: 0.164758
 >> iter 50000, loss: 0.269022
   Number of active neurons: 7
 >> iter 51000, loss: 0.266111
 >> iter 52000, loss: 0.264030
 >> iter 53000, loss: 0.234493
 >> iter 54000, loss: 0.277236
 >> iter 55000, loss: 0.425662
 >> iter 56000, loss: 0.322602
 >> iter 57000, loss: 0.220690
 >> iter 58000, loss: 0.145495
 >> iter 59000, loss: 0.299841
 >> iter 60000, loss: 0.337609
   Number of active neurons: 7
 >> iter 61000, loss: 0.492724
 >> iter 62000, loss: 0.333672
 >> iter 63000, loss: 0.214054
 >> iter 64000, loss: 0.245584
 >> iter 65000, loss: 0.279263
 >> iter 66000, loss: 0.249561
 >> iter 67000, loss: 0.199049
 >> iter 68000, loss: 0.158204
 >> iter 69000, loss: 0.246229
 >> iter 70000, loss: 0.230110
   Number of active neurons: 6
 >> iter 71000, loss: 0.184962
 >> iter 72000, loss: 0.201093
 >> iter 73000, loss: 0.243704
 >> iter 74000, loss: 0.234887
 >> iter 75000, loss: 0.205426
 >> iter 76000, loss: 0.232235
 >> iter 77000, loss: 0.298367
 >> iter 78000, loss: 0.203097
 >> iter 79000, loss: 0.172427
 >> iter 80000, loss: 0.184283
   Number of active neurons: 6
 >> iter 81000, loss: 0.153336
 >> iter 82000, loss: 0.138029
 >> iter 83000, loss: 0.207201
 >> iter 84000, loss: 0.236669
 >> iter 85000, loss: 0.163563
 >> iter 86000, loss: 0.167818
 >> iter 87000, loss: 0.173965
 >> iter 88000, loss: 0.143544
 >> iter 89000, loss: 0.215537
 >> iter 90000, loss: 0.304196
   Number of active neurons: 6
 >> iter 91000, loss: 0.260058
 >> iter 92000, loss: 0.328334
 >> iter 93000, loss: 0.213404
 >> iter 94000, loss: 0.273178
 >> iter 95000, loss: 0.281653
 >> iter 96000, loss: 0.413779
 >> iter 97000, loss: 0.253650
 >> iter 98000, loss: 0.317109
 >> iter 99000, loss: 0.326891
 >> iter 100000, loss: 0.305701
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.927329
 >> iter 2000, loss: 10.829845
 >> iter 3000, loss: 5.057439
 >> iter 4000, loss: 2.560901
 >> iter 5000, loss: 1.310286
 >> iter 6000, loss: 0.841242
 >> iter 7000, loss: 0.727880
 >> iter 8000, loss: 0.623909
 >> iter 9000, loss: 0.567662
 >> iter 10000, loss: 0.427079
   Number of active neurons: 7
 >> iter 11000, loss: 0.392160
 >> iter 12000, loss: 0.265922
 >> iter 13000, loss: 0.261888
 >> iter 14000, loss: 0.243640
 >> iter 15000, loss: 0.383482
 >> iter 16000, loss: 0.265862
 >> iter 17000, loss: 0.374481
 >> iter 18000, loss: 0.416908
 >> iter 19000, loss: 0.445369
 >> iter 20000, loss: 0.366366
   Number of active neurons: 7
 >> iter 21000, loss: 0.379222
 >> iter 22000, loss: 0.383570
 >> iter 23000, loss: 0.373011
 >> iter 24000, loss: 0.209487
 >> iter 25000, loss: 0.332842
 >> iter 26000, loss: 0.341478
 >> iter 27000, loss: 0.245741
 >> iter 28000, loss: 0.203470
 >> iter 29000, loss: 0.347674
 >> iter 30000, loss: 0.291028
   Number of active neurons: 7
 >> iter 31000, loss: 0.296806
 >> iter 32000, loss: 0.437238
 >> iter 33000, loss: 0.398685
 >> iter 34000, loss: 0.330902
 >> iter 35000, loss: 0.402547
 >> iter 36000, loss: 0.338921
 >> iter 37000, loss: 0.355327
 >> iter 38000, loss: 0.403479
 >> iter 39000, loss: 0.335867
 >> iter 40000, loss: 0.348272
   Number of active neurons: 7
 >> iter 41000, loss: 0.372655
 >> iter 42000, loss: 0.433054
 >> iter 43000, loss: 0.280545
 >> iter 44000, loss: 0.260483
 >> iter 45000, loss: 0.349981
 >> iter 46000, loss: 0.262327
 >> iter 47000, loss: 0.204648
 >> iter 48000, loss: 0.286712
 >> iter 49000, loss: 0.234927
 >> iter 50000, loss: 0.216620
   Number of active neurons: 7
 >> iter 51000, loss: 0.298015
 >> iter 52000, loss: 0.203638
 >> iter 53000, loss: 0.235802
 >> iter 54000, loss: 0.236688
 >> iter 55000, loss: 0.208338
 >> iter 56000, loss: 0.198907
 >> iter 57000, loss: 0.211971
 >> iter 58000, loss: 0.291851
 >> iter 59000, loss: 0.197663
 >> iter 60000, loss: 0.166059
   Number of active neurons: 7
 >> iter 61000, loss: 0.247290
 >> iter 62000, loss: 0.446391
 >> iter 63000, loss: 0.207585
 >> iter 64000, loss: 0.114969
 >> iter 65000, loss: 0.197090
 >> iter 66000, loss: 0.180438
 >> iter 67000, loss: 0.128900
 >> iter 68000, loss: 0.233381
 >> iter 69000, loss: 0.263501
 >> iter 70000, loss: 0.271067
   Number of active neurons: 5
 >> iter 71000, loss: 0.363426
 >> iter 72000, loss: 0.244827
 >> iter 73000, loss: 0.240474
 >> iter 74000, loss: 0.236137
 >> iter 75000, loss: 0.212696
 >> iter 76000, loss: 0.186010
 >> iter 77000, loss: 0.165075
 >> iter 78000, loss: 0.159926
 >> iter 79000, loss: 0.146689
 >> iter 80000, loss: 0.186673
   Number of active neurons: 5
 >> iter 81000, loss: 0.156486
 >> iter 82000, loss: 0.188564
 >> iter 83000, loss: 0.270452
 >> iter 84000, loss: 0.212390
 >> iter 85000, loss: 0.326444
 >> iter 86000, loss: 0.214370
 >> iter 87000, loss: 0.167051
 >> iter 88000, loss: 0.185405
 >> iter 89000, loss: 0.201203
 >> iter 90000, loss: 0.251138
   Number of active neurons: 5
 >> iter 91000, loss: 0.164112
 >> iter 92000, loss: 0.128036
 >> iter 93000, loss: 0.116936
 >> iter 94000, loss: 0.196514
 >> iter 95000, loss: 0.216749
 >> iter 96000, loss: 0.204047
 >> iter 97000, loss: 0.355736
 >> iter 98000, loss: 0.278249
 >> iter 99000, loss: 0.235659
 >> iter 100000, loss: 0.286912
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.819792
 >> iter 2000, loss: 11.207628
 >> iter 3000, loss: 6.247440
 >> iter 4000, loss: 3.142357
 >> iter 5000, loss: 1.751638
 >> iter 6000, loss: 1.197404
 >> iter 7000, loss: 0.775725
 >> iter 8000, loss: 0.507848
 >> iter 9000, loss: 0.666240
 >> iter 10000, loss: 0.430443
   Number of active neurons: 9
 >> iter 11000, loss: 0.371242
 >> iter 12000, loss: 0.512449
 >> iter 13000, loss: 0.524885
 >> iter 14000, loss: 0.341879
 >> iter 15000, loss: 0.518435
 >> iter 16000, loss: 0.596441
 >> iter 17000, loss: 0.405772
 >> iter 18000, loss: 0.346757
 >> iter 19000, loss: 0.333085
 >> iter 20000, loss: 0.340750
   Number of active neurons: 9
 >> iter 21000, loss: 0.522544
 >> iter 22000, loss: 0.470490
 >> iter 23000, loss: 0.741037
 >> iter 24000, loss: 0.542741
 >> iter 25000, loss: 0.510751
 >> iter 26000, loss: 0.436329
 >> iter 27000, loss: 0.370334
 >> iter 28000, loss: 0.490308
 >> iter 29000, loss: 0.461696
 >> iter 30000, loss: 0.377460
   Number of active neurons: 8
 >> iter 31000, loss: 0.681595
 >> iter 32000, loss: 0.472130
 >> iter 33000, loss: 0.356720
 >> iter 34000, loss: 0.270537
 >> iter 35000, loss: 0.273102
 >> iter 36000, loss: 0.216692
 >> iter 37000, loss: 0.266709
 >> iter 38000, loss: 0.340327
 >> iter 39000, loss: 0.440856
 >> iter 40000, loss: 0.409511
   Number of active neurons: 8
 >> iter 41000, loss: 0.395244
 >> iter 42000, loss: 0.324234
 >> iter 43000, loss: 0.455963
 >> iter 44000, loss: 0.487760
 >> iter 45000, loss: 0.393730
 >> iter 46000, loss: 0.299988
 >> iter 47000, loss: 0.267856
 >> iter 48000, loss: 0.280256
 >> iter 49000, loss: 0.459536
 >> iter 50000, loss: 0.538417
   Number of active neurons: 8
 >> iter 51000, loss: 0.283928
 >> iter 52000, loss: 0.287097
 >> iter 53000, loss: 0.246618
 >> iter 54000, loss: 0.314748
 >> iter 55000, loss: 0.362230
 >> iter 56000, loss: 0.391523
 >> iter 57000, loss: 0.281635
 >> iter 58000, loss: 0.194947
 >> iter 59000, loss: 0.323124
 >> iter 60000, loss: 0.293958
   Number of active neurons: 8
 >> iter 61000, loss: 0.277993
 >> iter 62000, loss: 0.297259
 >> iter 63000, loss: 0.502558
 >> iter 64000, loss: 0.304998
 >> iter 65000, loss: 0.356377
 >> iter 66000, loss: 0.296232
 >> iter 67000, loss: 0.288456
 >> iter 68000, loss: 0.334028
 >> iter 69000, loss: 0.545157
 >> iter 70000, loss: 0.444675
   Number of active neurons: 8
 >> iter 71000, loss: 0.385547
 >> iter 72000, loss: 0.358807
 >> iter 73000, loss: 0.356629
 >> iter 74000, loss: 0.352408
 >> iter 75000, loss: 0.376836
 >> iter 76000, loss: 0.231265
 >> iter 77000, loss: 0.427962
 >> iter 78000, loss: 0.238038
 >> iter 79000, loss: 0.310003
 >> iter 80000, loss: 0.313507
   Number of active neurons: 8
 >> iter 81000, loss: 0.297186
 >> iter 82000, loss: 0.252729
 >> iter 83000, loss: 0.316549
 >> iter 84000, loss: 0.378246
 >> iter 85000, loss: 0.240030
 >> iter 86000, loss: 0.256597
 >> iter 87000, loss: 0.256577
 >> iter 88000, loss: 0.225525
 >> iter 89000, loss: 0.469814
 >> iter 90000, loss: 0.410407
   Number of active neurons: 8
 >> iter 91000, loss: 0.272392
 >> iter 92000, loss: 0.267127
 >> iter 93000, loss: 0.191099
 >> iter 94000, loss: 0.189814
 >> iter 95000, loss: 0.264483
 >> iter 96000, loss: 0.344095
 >> iter 97000, loss: 0.286194
 >> iter 98000, loss: 0.282799
 >> iter 99000, loss: 0.255240
 >> iter 100000, loss: 0.209636
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.133656
 >> iter 2000, loss: 10.889443
 >> iter 3000, loss: 5.216076
 >> iter 4000, loss: 2.617775
 >> iter 5000, loss: 1.362626
 >> iter 6000, loss: 0.689184
 >> iter 7000, loss: 0.658091
 >> iter 8000, loss: 0.521959
 >> iter 9000, loss: 0.603437
 >> iter 10000, loss: 0.407085
   Number of active neurons: 8
 >> iter 11000, loss: 0.441786
 >> iter 12000, loss: 0.404738
 >> iter 13000, loss: 0.435548
 >> iter 14000, loss: 0.463373
 >> iter 15000, loss: 0.386998
 >> iter 16000, loss: 0.312032
 >> iter 17000, loss: 0.479640
 >> iter 18000, loss: 0.503453
 >> iter 19000, loss: 0.534752
 >> iter 20000, loss: 0.485258
   Number of active neurons: 8
 >> iter 21000, loss: 0.295007
 >> iter 22000, loss: 0.414187
 >> iter 23000, loss: 0.298860
 >> iter 24000, loss: 0.287046
 >> iter 25000, loss: 0.620228
 >> iter 26000, loss: 0.527095
 >> iter 27000, loss: 0.337477
 >> iter 28000, loss: 0.311085
 >> iter 29000, loss: 0.327393
 >> iter 30000, loss: 0.414933
   Number of active neurons: 8
 >> iter 31000, loss: 0.732309
 >> iter 32000, loss: 0.613431
 >> iter 33000, loss: 0.574324
 >> iter 34000, loss: 0.506539
 >> iter 35000, loss: 0.468966
 >> iter 36000, loss: 0.311968
 >> iter 37000, loss: 0.452436
 >> iter 38000, loss: 0.414947
 >> iter 39000, loss: 0.351693
 >> iter 40000, loss: 0.403925
   Number of active neurons: 8
 >> iter 41000, loss: 0.447826
 >> iter 42000, loss: 0.422919
 >> iter 43000, loss: 0.453282
 >> iter 44000, loss: 0.270824
 >> iter 45000, loss: 0.294922
 >> iter 46000, loss: 0.470720
 >> iter 47000, loss: 0.483002
 >> iter 48000, loss: 0.447417
 >> iter 49000, loss: 0.351521
 >> iter 50000, loss: 0.256597
   Number of active neurons: 8
 >> iter 51000, loss: 0.462948
 >> iter 52000, loss: 0.413910
 >> iter 53000, loss: 0.448307
 >> iter 54000, loss: 0.311995
 >> iter 55000, loss: 0.360879
 >> iter 56000, loss: 0.288014
 >> iter 57000, loss: 0.360565
 >> iter 58000, loss: 0.419356
 >> iter 59000, loss: 0.297212
 >> iter 60000, loss: 0.357672
   Number of active neurons: 8
 >> iter 61000, loss: 0.413535
 >> iter 62000, loss: 0.266222
 >> iter 63000, loss: 0.254753
 >> iter 64000, loss: 0.246487
 >> iter 65000, loss: 0.242490
 >> iter 66000, loss: 0.266075
 >> iter 67000, loss: 0.539490
 >> iter 68000, loss: 0.457714
 >> iter 69000, loss: 0.410545
 >> iter 70000, loss: 0.330401
   Number of active neurons: 7
 >> iter 71000, loss: 0.258001
 >> iter 72000, loss: 0.276301
 >> iter 73000, loss: 0.350914
 >> iter 74000, loss: 0.486091
 >> iter 75000, loss: 0.453645
 >> iter 76000, loss: 0.374289
 >> iter 77000, loss: 0.228813
 >> iter 78000, loss: 0.237346
 >> iter 79000, loss: 0.277560
 >> iter 80000, loss: 0.357326
   Number of active neurons: 7
 >> iter 81000, loss: 0.279151
 >> iter 82000, loss: 0.437887
 >> iter 83000, loss: 0.280486
 >> iter 84000, loss: 0.161089
 >> iter 85000, loss: 0.339954
 >> iter 86000, loss: 0.440759
 >> iter 87000, loss: 0.441815
 >> iter 88000, loss: 0.397336
 >> iter 89000, loss: 0.310548
 >> iter 90000, loss: 0.363508
   Number of active neurons: 7
 >> iter 91000, loss: 0.376498
 >> iter 92000, loss: 0.395334
 >> iter 93000, loss: 0.384906
 >> iter 94000, loss: 0.264067
 >> iter 95000, loss: 0.215759
 >> iter 96000, loss: 0.259680
 >> iter 97000, loss: 0.298176
 >> iter 98000, loss: 0.289616
 >> iter 99000, loss: 0.170345
 >> iter 100000, loss: 0.215830
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.991018
 >> iter 2000, loss: 12.213830
 >> iter 3000, loss: 6.436377
 >> iter 4000, loss: 2.910634
 >> iter 5000, loss: 1.640784
 >> iter 6000, loss: 0.782762
 >> iter 7000, loss: 0.724833
 >> iter 8000, loss: 0.528976
 >> iter 9000, loss: 0.406981
 >> iter 10000, loss: 0.572470
   Number of active neurons: 10
 >> iter 11000, loss: 0.529240
 >> iter 12000, loss: 0.357970
 >> iter 13000, loss: 0.244968
 >> iter 14000, loss: 0.543884
 >> iter 15000, loss: 0.477974
 >> iter 16000, loss: 0.382960
 >> iter 17000, loss: 0.373824
 >> iter 18000, loss: 0.362984
 >> iter 19000, loss: 0.371250
 >> iter 20000, loss: 0.368020
   Number of active neurons: 9
 >> iter 21000, loss: 0.527092
 >> iter 22000, loss: 0.376601
 >> iter 23000, loss: 0.440186
 >> iter 24000, loss: 0.331790
 >> iter 25000, loss: 0.337003
 >> iter 26000, loss: 0.307662
 >> iter 27000, loss: 0.415214
 >> iter 28000, loss: 0.347908
 >> iter 29000, loss: 0.364367
 >> iter 30000, loss: 0.344231
   Number of active neurons: 9
 >> iter 31000, loss: 0.653983
 >> iter 32000, loss: 0.502831
 >> iter 33000, loss: 0.448341
 >> iter 34000, loss: 0.342166
 >> iter 35000, loss: 0.311497
 >> iter 36000, loss: 0.285810
 >> iter 37000, loss: 0.245776
 >> iter 38000, loss: 0.290483
 >> iter 39000, loss: 0.359668
 >> iter 40000, loss: 0.383579
   Number of active neurons: 8
 >> iter 41000, loss: 0.367023
 >> iter 42000, loss: 0.243824
 >> iter 43000, loss: 0.251812
 >> iter 44000, loss: 0.281995
 >> iter 45000, loss: 0.305554
 >> iter 46000, loss: 0.343241
 >> iter 47000, loss: 0.388163
 >> iter 48000, loss: 0.360367
 >> iter 49000, loss: 0.262431
 >> iter 50000, loss: 0.408700
   Number of active neurons: 8
 >> iter 51000, loss: 0.360408
 >> iter 52000, loss: 0.326597
 >> iter 53000, loss: 0.431844
 >> iter 54000, loss: 0.233592
 >> iter 55000, loss: 0.265127
 >> iter 56000, loss: 0.331822
 >> iter 57000, loss: 0.301301
 >> iter 58000, loss: 0.322791
 >> iter 59000, loss: 0.397239
 >> iter 60000, loss: 0.329611
   Number of active neurons: 8
 >> iter 61000, loss: 0.432274
 >> iter 62000, loss: 0.324325
 >> iter 63000, loss: 0.233336
 >> iter 64000, loss: 0.249909
 >> iter 65000, loss: 0.194272
 >> iter 66000, loss: 0.342323
 >> iter 67000, loss: 0.435710
 >> iter 68000, loss: 0.276748
 >> iter 69000, loss: 0.253679
 >> iter 70000, loss: 0.301966
   Number of active neurons: 8
 >> iter 71000, loss: 0.267408
 >> iter 72000, loss: 0.309799
 >> iter 73000, loss: 0.246669
 >> iter 74000, loss: 0.180243
 >> iter 75000, loss: 0.285631
 >> iter 76000, loss: 0.304647
 >> iter 77000, loss: 0.195684
 >> iter 78000, loss: 0.286427
 >> iter 79000, loss: 0.387792
 >> iter 80000, loss: 0.367067
   Number of active neurons: 8
 >> iter 81000, loss: 0.316362
 >> iter 82000, loss: 0.320509
 >> iter 83000, loss: 0.243636
 >> iter 84000, loss: 0.201321
 >> iter 85000, loss: 0.348624
 >> iter 86000, loss: 0.288261
 >> iter 87000, loss: 0.191125
 >> iter 88000, loss: 0.252537
 >> iter 89000, loss: 0.219008
 >> iter 90000, loss: 0.222693
   Number of active neurons: 8
 >> iter 91000, loss: 0.272044
 >> iter 92000, loss: 0.238478
 >> iter 93000, loss: 0.371748
 >> iter 94000, loss: 0.225978
 >> iter 95000, loss: 0.178045
 >> iter 96000, loss: 0.340329
 >> iter 97000, loss: 0.241030
 >> iter 98000, loss: 0.252351
 >> iter 99000, loss: 0.295938
 >> iter 100000, loss: 0.220465
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 18.784919
 >> iter 2000, loss: 9.533001
 >> iter 3000, loss: 4.197511
 >> iter 4000, loss: 1.865590
 >> iter 5000, loss: 0.888292
 >> iter 6000, loss: 0.475150
 >> iter 7000, loss: 0.320409
 >> iter 8000, loss: 0.333394
 >> iter 9000, loss: 0.298589
 >> iter 10000, loss: 0.310639
   Number of active neurons: 7
 >> iter 11000, loss: 0.206750
 >> iter 12000, loss: 0.257136
 >> iter 13000, loss: 0.293617
 >> iter 14000, loss: 0.408142
 >> iter 15000, loss: 0.349995
 >> iter 16000, loss: 0.338535
 >> iter 17000, loss: 0.270212
 >> iter 18000, loss: 0.278301
 >> iter 19000, loss: 0.191329
 >> iter 20000, loss: 0.205784
   Number of active neurons: 7
 >> iter 21000, loss: 0.357193
 >> iter 22000, loss: 0.298279
 >> iter 23000, loss: 0.397335
 >> iter 24000, loss: 0.461356
 >> iter 25000, loss: 0.388084
 >> iter 26000, loss: 0.308878
 >> iter 27000, loss: 0.177858
 >> iter 28000, loss: 0.270231
 >> iter 29000, loss: 0.214159
 >> iter 30000, loss: 0.160080
   Number of active neurons: 7
 >> iter 31000, loss: 0.137155
 >> iter 32000, loss: 0.174647
 >> iter 33000, loss: 0.206002
 >> iter 34000, loss: 0.262012
 >> iter 35000, loss: 0.415562
 >> iter 36000, loss: 0.299305
 >> iter 37000, loss: 0.176561
 >> iter 38000, loss: 0.379881
 >> iter 39000, loss: 0.215834
 >> iter 40000, loss: 0.255254
   Number of active neurons: 7
 >> iter 41000, loss: 0.405792
 >> iter 42000, loss: 0.284196
 >> iter 43000, loss: 0.279098
 >> iter 44000, loss: 0.185862
 >> iter 45000, loss: 0.157768
 >> iter 46000, loss: 0.153308
 >> iter 47000, loss: 0.194311
 >> iter 48000, loss: 0.164680
 >> iter 49000, loss: 0.152797
 >> iter 50000, loss: 0.154896
   Number of active neurons: 7
 >> iter 51000, loss: 0.252064
 >> iter 52000, loss: 0.171075
 >> iter 53000, loss: 0.244405
 >> iter 54000, loss: 0.175222
 >> iter 55000, loss: 0.277332
 >> iter 56000, loss: 0.239917
 >> iter 57000, loss: 0.144240
 >> iter 58000, loss: 0.184662
 >> iter 59000, loss: 0.252950
 >> iter 60000, loss: 0.209261
   Number of active neurons: 5
 >> iter 61000, loss: 0.204492
 >> iter 62000, loss: 0.157772
 >> iter 63000, loss: 0.233661
 >> iter 64000, loss: 0.222899
 >> iter 65000, loss: 0.211872
 >> iter 66000, loss: 0.178432
 >> iter 67000, loss: 0.188961
 >> iter 68000, loss: 0.137007
 >> iter 69000, loss: 0.132311
 >> iter 70000, loss: 0.151637
   Number of active neurons: 4
 >> iter 71000, loss: 0.146156
 >> iter 72000, loss: 0.194902
 >> iter 73000, loss: 0.199394
 >> iter 74000, loss: 0.179333
 >> iter 75000, loss: 0.186620
 >> iter 76000, loss: 0.162176
 >> iter 77000, loss: 0.193878
 >> iter 78000, loss: 0.140756
 >> iter 79000, loss: 0.128738
 >> iter 80000, loss: 0.220316
   Number of active neurons: 4
 >> iter 81000, loss: 0.186041
 >> iter 82000, loss: 0.271366
 >> iter 83000, loss: 0.420887
 >> iter 84000, loss: 0.247298
 >> iter 85000, loss: 0.209137
 >> iter 86000, loss: 0.125931
 >> iter 87000, loss: 0.153022
 >> iter 88000, loss: 0.257538
 >> iter 89000, loss: 0.186755
 >> iter 90000, loss: 0.125931
   Number of active neurons: 4
 >> iter 91000, loss: 0.119484
 >> iter 92000, loss: 0.230377
 >> iter 93000, loss: 0.239224
 >> iter 94000, loss: 0.262958
 >> iter 95000, loss: 0.241136
 >> iter 96000, loss: 0.169211
 >> iter 97000, loss: 0.216908
 >> iter 98000, loss: 0.137352
 >> iter 99000, loss: 0.172523
 >> iter 100000, loss: 0.191007
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 19.250816
 >> iter 2000, loss: 10.950284
 >> iter 3000, loss: 4.631695
 >> iter 4000, loss: 2.009185
 >> iter 5000, loss: 1.090277
 >> iter 6000, loss: 0.725675
 >> iter 7000, loss: 0.421513
 >> iter 8000, loss: 0.317359
 >> iter 9000, loss: 0.336655
 >> iter 10000, loss: 0.296036
   Number of active neurons: 10
 >> iter 11000, loss: 0.355088
 >> iter 12000, loss: 0.224295
 >> iter 13000, loss: 0.219095
 >> iter 14000, loss: 0.171841
 >> iter 15000, loss: 0.356233
 >> iter 16000, loss: 0.284622
 >> iter 17000, loss: 0.382776
 >> iter 18000, loss: 0.387352
 >> iter 19000, loss: 0.323658
 >> iter 20000, loss: 0.335819
   Number of active neurons: 10
 >> iter 21000, loss: 0.225179
 >> iter 22000, loss: 0.218452
 >> iter 23000, loss: 0.147492
 >> iter 24000, loss: 0.228189
 >> iter 25000, loss: 0.304858
 >> iter 26000, loss: 0.271524
 >> iter 27000, loss: 0.521615
 >> iter 28000, loss: 0.276547
 >> iter 29000, loss: 0.255310
 >> iter 30000, loss: 0.214795
   Number of active neurons: 8
 >> iter 31000, loss: 0.254136
 >> iter 32000, loss: 0.392331
 >> iter 33000, loss: 0.255180
 >> iter 34000, loss: 0.269041
 >> iter 35000, loss: 0.193132
 >> iter 36000, loss: 0.215132
 >> iter 37000, loss: 0.247351
 >> iter 38000, loss: 0.203310
 >> iter 39000, loss: 0.205457
 >> iter 40000, loss: 0.335129
   Number of active neurons: 7
 >> iter 41000, loss: 0.330683
 >> iter 42000, loss: 0.221740
 >> iter 43000, loss: 0.266108
 >> iter 44000, loss: 0.205664
 >> iter 45000, loss: 0.280183
 >> iter 46000, loss: 0.202299
 >> iter 47000, loss: 0.218166
 >> iter 48000, loss: 0.287543
 >> iter 49000, loss: 0.208845
 >> iter 50000, loss: 0.181316
   Number of active neurons: 7
 >> iter 51000, loss: 0.159875
 >> iter 52000, loss: 0.242056
 >> iter 53000, loss: 0.422797
 >> iter 54000, loss: 0.293707
 >> iter 55000, loss: 0.232615
 >> iter 56000, loss: 0.332157
 >> iter 57000, loss: 0.208837
 >> iter 58000, loss: 0.239915
 >> iter 59000, loss: 0.299436
 >> iter 60000, loss: 0.413189
   Number of active neurons: 7
 >> iter 61000, loss: 0.218833
 >> iter 62000, loss: 0.220773
 >> iter 63000, loss: 0.221122
 >> iter 64000, loss: 0.207772
 >> iter 65000, loss: 0.316910
 >> iter 66000, loss: 0.291671
 >> iter 67000, loss: 0.270556
 >> iter 68000, loss: 0.257458
 >> iter 69000, loss: 0.252972
 >> iter 70000, loss: 0.244125
   Number of active neurons: 6
 >> iter 71000, loss: 0.233801
 >> iter 72000, loss: 0.226221
 >> iter 73000, loss: 0.204953
 >> iter 74000, loss: 0.238300
 >> iter 75000, loss: 0.293934
 >> iter 76000, loss: 0.166988
 >> iter 77000, loss: 0.216949
 >> iter 78000, loss: 0.308660
 >> iter 79000, loss: 0.371056
 >> iter 80000, loss: 0.229831
   Number of active neurons: 6
 >> iter 81000, loss: 0.282390
 >> iter 82000, loss: 0.264207
 >> iter 83000, loss: 0.275920
 >> iter 84000, loss: 0.244101
 >> iter 85000, loss: 0.149918
 >> iter 86000, loss: 0.237161
 >> iter 87000, loss: 0.406023
 >> iter 88000, loss: 0.256679
 >> iter 89000, loss: 0.354724
 >> iter 90000, loss: 0.229276
   Number of active neurons: 6
 >> iter 91000, loss: 0.223240
 >> iter 92000, loss: 0.192087
 >> iter 93000, loss: 0.171136
 >> iter 94000, loss: 0.281755
 >> iter 95000, loss: 0.256300
 >> iter 96000, loss: 0.247742
 >> iter 97000, loss: 0.259734
 >> iter 98000, loss: 0.198506
 >> iter 99000, loss: 0.163837
 >> iter 100000, loss: 0.153803
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.976009
 >> iter 2000, loss: 10.979927
 >> iter 3000, loss: 5.498280
 >> iter 4000, loss: 2.801397
 >> iter 5000, loss: 1.637304
 >> iter 6000, loss: 1.064428
 >> iter 7000, loss: 0.818124
 >> iter 8000, loss: 0.520376
 >> iter 9000, loss: 0.565819
 >> iter 10000, loss: 0.453327
   Number of active neurons: 7
 >> iter 11000, loss: 0.367829
 >> iter 12000, loss: 0.547474
 >> iter 13000, loss: 0.535190
 >> iter 14000, loss: 0.421666
 >> iter 15000, loss: 0.441942
 >> iter 16000, loss: 0.386755
 >> iter 17000, loss: 0.322550
 >> iter 18000, loss: 0.325407
 >> iter 19000, loss: 0.610052
 >> iter 20000, loss: 0.417187
   Number of active neurons: 7
 >> iter 21000, loss: 0.437731
 >> iter 22000, loss: 0.437954
 >> iter 23000, loss: 0.494606
 >> iter 24000, loss: 0.400909
 >> iter 25000, loss: 0.426903
 >> iter 26000, loss: 0.571425
 >> iter 27000, loss: 0.633999
 >> iter 28000, loss: 0.446796
 >> iter 29000, loss: 0.432737
 >> iter 30000, loss: 0.462647
   Number of active neurons: 7
 >> iter 31000, loss: 0.542679
 >> iter 32000, loss: 0.452275
 >> iter 33000, loss: 0.599383
 >> iter 34000, loss: 0.531882
 >> iter 35000, loss: 0.505727
 >> iter 36000, loss: 0.489441
 >> iter 37000, loss: 0.429419
 >> iter 38000, loss: 0.670430
 >> iter 39000, loss: 0.536024
 >> iter 40000, loss: 0.496577
   Number of active neurons: 7
 >> iter 41000, loss: 0.469053
 >> iter 42000, loss: 0.504884
 >> iter 43000, loss: 0.383332
 >> iter 44000, loss: 0.412849
 >> iter 45000, loss: 0.417863
 >> iter 46000, loss: 0.428950
 >> iter 47000, loss: 0.289086
 >> iter 48000, loss: 0.279102
 >> iter 49000, loss: 0.260574
 >> iter 50000, loss: 0.265206
   Number of active neurons: 6
 >> iter 51000, loss: 0.317435
 >> iter 52000, loss: 0.419116
 >> iter 53000, loss: 0.629112
 >> iter 54000, loss: 0.484903
 >> iter 55000, loss: 0.497371
 >> iter 56000, loss: 0.448785
 >> iter 57000, loss: 0.552713
 >> iter 58000, loss: 0.389363
 >> iter 59000, loss: 0.393843
 >> iter 60000, loss: 0.352158
   Number of active neurons: 6
 >> iter 61000, loss: 0.409783
 >> iter 62000, loss: 0.528920
 >> iter 63000, loss: 0.332564
 >> iter 64000, loss: 0.377551
 >> iter 65000, loss: 0.288629
 >> iter 66000, loss: 0.594826
 >> iter 67000, loss: 0.607553
 >> iter 68000, loss: 0.336735
 >> iter 69000, loss: 0.409430
 >> iter 70000, loss: 0.332708
   Number of active neurons: 6
 >> iter 71000, loss: 0.275796
 >> iter 72000, loss: 0.343585
 >> iter 73000, loss: 0.309875
 >> iter 74000, loss: 0.426707
 >> iter 75000, loss: 0.522845
 >> iter 76000, loss: 0.349664
 >> iter 77000, loss: 0.386968
 >> iter 78000, loss: 0.269586
 >> iter 79000, loss: 0.319115
 >> iter 80000, loss: 0.495196
   Number of active neurons: 6
 >> iter 81000, loss: 0.477786
 >> iter 82000, loss: 0.315225
 >> iter 83000, loss: 0.294843
 >> iter 84000, loss: 0.414963
 >> iter 85000, loss: 0.495219
 >> iter 86000, loss: 0.376367
 >> iter 87000, loss: 0.350956
 >> iter 88000, loss: 0.307459
 >> iter 89000, loss: 0.284947
 >> iter 90000, loss: 0.274972
   Number of active neurons: 6
 >> iter 91000, loss: 0.217777
 >> iter 92000, loss: 0.298746
 >> iter 93000, loss: 0.320241
 >> iter 94000, loss: 0.437119
 >> iter 95000, loss: 0.393142
 >> iter 96000, loss: 0.273922
 >> iter 97000, loss: 0.563982
 >> iter 98000, loss: 0.486500
 >> iter 99000, loss: 0.312406
 >> iter 100000, loss: 0.458484
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.940500
 >> iter 2000, loss: 10.839850
 >> iter 3000, loss: 4.576188
 >> iter 4000, loss: 2.293613
 >> iter 5000, loss: 1.284125
 >> iter 6000, loss: 0.579336
 >> iter 7000, loss: 0.701183
 >> iter 8000, loss: 0.417610
 >> iter 9000, loss: 0.399431
 >> iter 10000, loss: 0.440337
   Number of active neurons: 9
 >> iter 11000, loss: 0.418202
 >> iter 12000, loss: 0.452518
 >> iter 13000, loss: 0.712164
 >> iter 14000, loss: 0.419886
 >> iter 15000, loss: 0.222696
 >> iter 16000, loss: 0.247988
 >> iter 17000, loss: 0.314966
 >> iter 18000, loss: 0.207445
 >> iter 19000, loss: 0.236256
 >> iter 20000, loss: 0.241857
   Number of active neurons: 7
 >> iter 21000, loss: 0.258128
 >> iter 22000, loss: 0.214640
 >> iter 23000, loss: 0.261109
 >> iter 24000, loss: 0.149342
 >> iter 25000, loss: 0.263034
 >> iter 26000, loss: 0.325384
 >> iter 27000, loss: 0.308439
 >> iter 28000, loss: 0.277645
 >> iter 29000, loss: 0.189724
 >> iter 30000, loss: 0.139458
   Number of active neurons: 7
 >> iter 31000, loss: 0.280321
 >> iter 32000, loss: 0.492693
 >> iter 33000, loss: 0.489957
 >> iter 34000, loss: 0.339237
 >> iter 35000, loss: 0.299947
 >> iter 36000, loss: 0.191558
 >> iter 37000, loss: 0.167239
 >> iter 38000, loss: 0.236154
 >> iter 39000, loss: 0.163598
 >> iter 40000, loss: 0.187278
   Number of active neurons: 7
 >> iter 41000, loss: 0.168824
 >> iter 42000, loss: 0.182395
 >> iter 43000, loss: 0.241375
 >> iter 44000, loss: 0.239587
 >> iter 45000, loss: 0.244233
 >> iter 46000, loss: 0.234362
 >> iter 47000, loss: 0.307651
 >> iter 48000, loss: 0.397958
 >> iter 49000, loss: 0.404189
 >> iter 50000, loss: 0.259997
   Number of active neurons: 7
 >> iter 51000, loss: 0.159781
 >> iter 52000, loss: 0.187553
 >> iter 53000, loss: 0.172826
 >> iter 54000, loss: 0.325101
 >> iter 55000, loss: 0.243220
 >> iter 56000, loss: 0.320092
 >> iter 57000, loss: 0.292114
 >> iter 58000, loss: 0.204354
 >> iter 59000, loss: 0.300732
 >> iter 60000, loss: 0.286113
   Number of active neurons: 6
 >> iter 61000, loss: 0.325208
 >> iter 62000, loss: 0.225168
 >> iter 63000, loss: 0.229545
 >> iter 64000, loss: 0.138751
 >> iter 65000, loss: 0.149652
 >> iter 66000, loss: 0.246792
 >> iter 67000, loss: 0.265850
 >> iter 68000, loss: 0.295506
 >> iter 69000, loss: 0.339543
 >> iter 70000, loss: 0.307290
   Number of active neurons: 6
 >> iter 71000, loss: 0.292138
 >> iter 72000, loss: 0.227133
 >> iter 73000, loss: 0.226533
 >> iter 74000, loss: 0.168038
 >> iter 75000, loss: 0.197265
 >> iter 76000, loss: 0.206726
 >> iter 77000, loss: 0.180033
 >> iter 78000, loss: 0.212748
 >> iter 79000, loss: 0.216560
 >> iter 80000, loss: 0.159851
   Number of active neurons: 6
 >> iter 81000, loss: 0.209122
 >> iter 82000, loss: 0.161655
 >> iter 83000, loss: 0.326307
 >> iter 84000, loss: 0.223282
 >> iter 85000, loss: 0.263846
 >> iter 86000, loss: 0.187378
 >> iter 87000, loss: 0.296610
 >> iter 88000, loss: 0.214862
 >> iter 89000, loss: 0.312913
 >> iter 90000, loss: 0.185983
   Number of active neurons: 6
 >> iter 91000, loss: 0.166126
 >> iter 92000, loss: 0.248756
 >> iter 93000, loss: 0.351330
 >> iter 94000, loss: 0.256476
 >> iter 95000, loss: 0.183708
 >> iter 96000, loss: 0.212377
 >> iter 97000, loss: 0.316918
 >> iter 98000, loss: 0.305151
 >> iter 99000, loss: 0.164050
 >> iter 100000, loss: 0.163445
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.089043
 >> iter 2000, loss: 10.940056
 >> iter 3000, loss: 5.253281
 >> iter 4000, loss: 2.670364
 >> iter 5000, loss: 1.378172
 >> iter 6000, loss: 0.652885
 >> iter 7000, loss: 0.841042
 >> iter 8000, loss: 0.849925
 >> iter 9000, loss: 0.478725
 >> iter 10000, loss: 0.563953
   Number of active neurons: 7
 >> iter 11000, loss: 0.434440
 >> iter 12000, loss: 0.619456
 >> iter 13000, loss: 0.682172
 >> iter 14000, loss: 0.449216
 >> iter 15000, loss: 0.493147
 >> iter 16000, loss: 0.401012
 >> iter 17000, loss: 0.458028
 >> iter 18000, loss: 0.451108
 >> iter 19000, loss: 0.346811
 >> iter 20000, loss: 0.272566
   Number of active neurons: 7
 >> iter 21000, loss: 0.345169
 >> iter 22000, loss: 0.457888
 >> iter 23000, loss: 0.403829
 >> iter 24000, loss: 0.313440
 >> iter 25000, loss: 0.294005
 >> iter 26000, loss: 0.411086
 >> iter 27000, loss: 0.475223
 >> iter 28000, loss: 0.418893
 >> iter 29000, loss: 0.336200
 >> iter 30000, loss: 0.328277
   Number of active neurons: 7
 >> iter 31000, loss: 0.530441
 >> iter 32000, loss: 0.455359
 >> iter 33000, loss: 0.466491
 >> iter 34000, loss: 0.406514
 >> iter 35000, loss: 0.382107
 >> iter 36000, loss: 0.376481
 >> iter 37000, loss: 0.547550
 >> iter 38000, loss: 0.520443
 >> iter 39000, loss: 0.340247
 >> iter 40000, loss: 0.486916
   Number of active neurons: 7
 >> iter 41000, loss: 0.633404
 >> iter 42000, loss: 0.613729
 >> iter 43000, loss: 0.575080
 >> iter 44000, loss: 0.470132
 >> iter 45000, loss: 0.351087
 >> iter 46000, loss: 0.343092
 >> iter 47000, loss: 0.492951
 >> iter 48000, loss: 0.498868
 >> iter 49000, loss: 0.434191
 >> iter 50000, loss: 0.353248
   Number of active neurons: 7
 >> iter 51000, loss: 0.310426
 >> iter 52000, loss: 0.280122
 >> iter 53000, loss: 0.449720
 >> iter 54000, loss: 0.373989
 >> iter 55000, loss: 0.409560
 >> iter 56000, loss: 0.418594
 >> iter 57000, loss: 0.391451
 >> iter 58000, loss: 0.478804
 >> iter 59000, loss: 0.370022
 >> iter 60000, loss: 0.397837
   Number of active neurons: 7
 >> iter 61000, loss: 0.334954
 >> iter 62000, loss: 0.440169
 >> iter 63000, loss: 0.448715
 >> iter 64000, loss: 0.339114
 >> iter 65000, loss: 0.321055
 >> iter 66000, loss: 0.346230
 >> iter 67000, loss: 0.283934
 >> iter 68000, loss: 0.386592
 >> iter 69000, loss: 0.412649
 >> iter 70000, loss: 0.457802
   Number of active neurons: 7
 >> iter 71000, loss: 0.598450
 >> iter 72000, loss: 0.691471
 >> iter 73000, loss: 0.458037
 >> iter 74000, loss: 0.422481
 >> iter 75000, loss: 0.411280
 >> iter 76000, loss: 0.412486
 >> iter 77000, loss: 0.503873
 >> iter 78000, loss: 0.402628
 >> iter 79000, loss: 0.416069
 >> iter 80000, loss: 0.435917
   Number of active neurons: 7
 >> iter 81000, loss: 0.474355
 >> iter 82000, loss: 0.478637
 >> iter 83000, loss: 0.561291
 >> iter 84000, loss: 0.478010
 >> iter 85000, loss: 0.369392
 >> iter 86000, loss: 0.328944
 >> iter 87000, loss: 0.383077
 >> iter 88000, loss: 0.452575
 >> iter 89000, loss: 0.421351
 >> iter 90000, loss: 0.340632
   Number of active neurons: 7
 >> iter 91000, loss: 0.550256
 >> iter 92000, loss: 0.429523
 >> iter 93000, loss: 0.280959
 >> iter 94000, loss: 0.291465
 >> iter 95000, loss: 0.300064
 >> iter 96000, loss: 0.421792
 >> iter 97000, loss: 0.424299
 >> iter 98000, loss: 0.303982
 >> iter 99000, loss: 0.329171
 >> iter 100000, loss: 0.341890
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.151242
 >> iter 2000, loss: 13.161398
 >> iter 3000, loss: 6.200661
 >> iter 4000, loss: 2.698841
 >> iter 5000, loss: 1.400790
 >> iter 6000, loss: 0.874250
 >> iter 7000, loss: 0.556133
 >> iter 8000, loss: 0.443696
 >> iter 9000, loss: 0.644956
 >> iter 10000, loss: 0.522428
   Number of active neurons: 6
 >> iter 11000, loss: 0.512021
 >> iter 12000, loss: 0.417192
 >> iter 13000, loss: 0.368611
 >> iter 14000, loss: 0.364144
 >> iter 15000, loss: 0.346067
 >> iter 16000, loss: 0.259901
 >> iter 17000, loss: 0.351444
 >> iter 18000, loss: 0.303052
 >> iter 19000, loss: 0.414586
 >> iter 20000, loss: 0.254324
   Number of active neurons: 6
 >> iter 21000, loss: 0.293052
 >> iter 22000, loss: 0.326366
 >> iter 23000, loss: 0.276843
 >> iter 24000, loss: 0.322876
 >> iter 25000, loss: 0.323616
 >> iter 26000, loss: 0.246885
 >> iter 27000, loss: 0.339779
 >> iter 28000, loss: 0.362305
 >> iter 29000, loss: 0.357600
 >> iter 30000, loss: 0.262688
   Number of active neurons: 6
 >> iter 31000, loss: 0.340560
 >> iter 32000, loss: 0.440627
 >> iter 33000, loss: 0.325935
 >> iter 34000, loss: 0.277296
 >> iter 35000, loss: 0.490496
 >> iter 36000, loss: 0.599947
 >> iter 37000, loss: 0.660365
 >> iter 38000, loss: 0.418803
 >> iter 39000, loss: 0.390927
 >> iter 40000, loss: 0.387235
   Number of active neurons: 6
 >> iter 41000, loss: 0.488914
 >> iter 42000, loss: 0.341017
 >> iter 43000, loss: 0.309222
 >> iter 44000, loss: 0.453992
 >> iter 45000, loss: 0.385453
 >> iter 46000, loss: 0.307794
 >> iter 47000, loss: 0.182563
 >> iter 48000, loss: 0.306858
 >> iter 49000, loss: 0.228449
 >> iter 50000, loss: 0.259496
   Number of active neurons: 6
 >> iter 51000, loss: 0.493931
 >> iter 52000, loss: 0.321114
 >> iter 53000, loss: 0.276925
 >> iter 54000, loss: 0.219447
 >> iter 55000, loss: 0.158635
 >> iter 56000, loss: 0.299074
 >> iter 57000, loss: 0.357714
 >> iter 58000, loss: 0.332970
 >> iter 59000, loss: 0.239021
 >> iter 60000, loss: 0.272556
   Number of active neurons: 6
 >> iter 61000, loss: 0.253167
 >> iter 62000, loss: 0.403320
 >> iter 63000, loss: 0.343252
 >> iter 64000, loss: 0.233004
 >> iter 65000, loss: 0.236178
 >> iter 66000, loss: 0.286076
 >> iter 67000, loss: 0.357234
 >> iter 68000, loss: 0.260753
 >> iter 69000, loss: 0.464086
 >> iter 70000, loss: 0.270587
   Number of active neurons: 6
 >> iter 71000, loss: 0.193141
 >> iter 72000, loss: 0.271475
 >> iter 73000, loss: 0.299953
 >> iter 74000, loss: 0.276276
 >> iter 75000, loss: 0.224600
 >> iter 76000, loss: 0.247230
 >> iter 77000, loss: 0.433782
 >> iter 78000, loss: 0.445456
 >> iter 79000, loss: 0.288354
 >> iter 80000, loss: 0.233629
   Number of active neurons: 6
 >> iter 81000, loss: 0.163134
 >> iter 82000, loss: 0.367547
 >> iter 83000, loss: 0.435202
 >> iter 84000, loss: 0.313522
 >> iter 85000, loss: 0.309601
 >> iter 86000, loss: 0.237941
 >> iter 87000, loss: 0.275632
 >> iter 88000, loss: 0.283443
 >> iter 89000, loss: 0.477225
 >> iter 90000, loss: 0.388821
   Number of active neurons: 6
 >> iter 91000, loss: 0.408609
 >> iter 92000, loss: 0.381975
 >> iter 93000, loss: 0.432036
 >> iter 94000, loss: 0.338120
 >> iter 95000, loss: 0.308463
 >> iter 96000, loss: 0.286175
 >> iter 97000, loss: 0.258310
 >> iter 98000, loss: 0.382269
 >> iter 99000, loss: 0.380977
 >> iter 100000, loss: 0.368496
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 19.030781
 >> iter 2000, loss: 12.617277
 >> iter 3000, loss: 5.895983
 >> iter 4000, loss: 2.433073
 >> iter 5000, loss: 1.139733
 >> iter 6000, loss: 0.689416
 >> iter 7000, loss: 0.514298
 >> iter 8000, loss: 0.315689
 >> iter 9000, loss: 0.267877
 >> iter 10000, loss: 0.437133
   Number of active neurons: 9
 >> iter 11000, loss: 0.272091
 >> iter 12000, loss: 0.227150
 >> iter 13000, loss: 0.253322
 >> iter 14000, loss: 0.225091
 >> iter 15000, loss: 0.272752
 >> iter 16000, loss: 0.264422
 >> iter 17000, loss: 0.328817
 >> iter 18000, loss: 0.196359
 >> iter 19000, loss: 0.353704
 >> iter 20000, loss: 0.299882
   Number of active neurons: 9
 >> iter 21000, loss: 0.373551
 >> iter 22000, loss: 0.265341
 >> iter 23000, loss: 0.371667
 >> iter 24000, loss: 0.332938
 >> iter 25000, loss: 0.257438
 >> iter 26000, loss: 0.224118
 >> iter 27000, loss: 0.311823
 >> iter 28000, loss: 0.245195
 >> iter 29000, loss: 0.276528
 >> iter 30000, loss: 0.213075
   Number of active neurons: 9
 >> iter 31000, loss: 0.257640
 >> iter 32000, loss: 0.226201
 >> iter 33000, loss: 0.276599
 >> iter 34000, loss: 0.169017
 >> iter 35000, loss: 0.424352
 >> iter 36000, loss: 0.391951
 >> iter 37000, loss: 0.451539
 >> iter 38000, loss: 0.276196
 >> iter 39000, loss: 0.243404
 >> iter 40000, loss: 0.225932
   Number of active neurons: 7
 >> iter 41000, loss: 0.161147
 >> iter 42000, loss: 0.168047
 >> iter 43000, loss: 0.198864
 >> iter 44000, loss: 0.119179
 >> iter 45000, loss: 0.214885
 >> iter 46000, loss: 0.246659
 >> iter 47000, loss: 0.221920
 >> iter 48000, loss: 0.169925
 >> iter 49000, loss: 0.313401
 >> iter 50000, loss: 0.317944
   Number of active neurons: 7
 >> iter 51000, loss: 0.225606
 >> iter 52000, loss: 0.257144
 >> iter 53000, loss: 0.199332
 >> iter 54000, loss: 0.190324
 >> iter 55000, loss: 0.374279
 >> iter 56000, loss: 0.203929
 >> iter 57000, loss: 0.161971
 >> iter 58000, loss: 0.240749
 >> iter 59000, loss: 0.211436
 >> iter 60000, loss: 0.221435
   Number of active neurons: 5
 >> iter 61000, loss: 0.223521
 >> iter 62000, loss: 0.170742
 >> iter 63000, loss: 0.196810
 >> iter 64000, loss: 0.209908
 >> iter 65000, loss: 0.119834
 >> iter 66000, loss: 0.113087
 >> iter 67000, loss: 0.161936
 >> iter 68000, loss: 0.166644
 >> iter 69000, loss: 0.313858
 >> iter 70000, loss: 0.196221
   Number of active neurons: 5
 >> iter 71000, loss: 0.198832
 >> iter 72000, loss: 0.210854
 >> iter 73000, loss: 0.178545
 >> iter 74000, loss: 0.197253
 >> iter 75000, loss: 0.302480
 >> iter 76000, loss: 0.265833
 >> iter 77000, loss: 0.328142
 >> iter 78000, loss: 0.249093
 >> iter 79000, loss: 0.192456
 >> iter 80000, loss: 0.162846
   Number of active neurons: 5
 >> iter 81000, loss: 0.346412
 >> iter 82000, loss: 0.242262
 >> iter 83000, loss: 0.199960
 >> iter 84000, loss: 0.132838
 >> iter 85000, loss: 0.190429
 >> iter 86000, loss: 0.186693
 >> iter 87000, loss: 0.137008
 >> iter 88000, loss: 0.097282
 >> iter 89000, loss: 0.271939
 >> iter 90000, loss: 0.364992
   Number of active neurons: 5
 >> iter 91000, loss: 0.297062
 >> iter 92000, loss: 0.306316
 >> iter 93000, loss: 0.279687
 >> iter 94000, loss: 0.181405
 >> iter 95000, loss: 0.161217
 >> iter 96000, loss: 0.178835
 >> iter 97000, loss: 0.272136
 >> iter 98000, loss: 0.225556
 >> iter 99000, loss: 0.206441
 >> iter 100000, loss: 0.243070
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.331178
 >> iter 2000, loss: 12.528924
 >> iter 3000, loss: 5.565874
 >> iter 4000, loss: 2.304206
 >> iter 5000, loss: 1.038393
 >> iter 6000, loss: 0.495306
 >> iter 7000, loss: 0.438353
 >> iter 8000, loss: 0.262745
 >> iter 9000, loss: 0.313322
 >> iter 10000, loss: 0.237980
   Number of active neurons: 10
 >> iter 11000, loss: 0.417472
 >> iter 12000, loss: 0.531617
 >> iter 13000, loss: 0.396235
 >> iter 14000, loss: 0.399363
 >> iter 15000, loss: 0.242144
 >> iter 16000, loss: 0.235486
 >> iter 17000, loss: 0.275532
 >> iter 18000, loss: 0.196113
 >> iter 19000, loss: 0.325667
 >> iter 20000, loss: 0.176271
   Number of active neurons: 10
 >> iter 21000, loss: 0.278692
 >> iter 22000, loss: 0.226383
 >> iter 23000, loss: 0.204249
 >> iter 24000, loss: 0.144544
 >> iter 25000, loss: 0.531754
 >> iter 26000, loss: 0.389407
 >> iter 27000, loss: 0.507810
 >> iter 28000, loss: 0.386163
 >> iter 29000, loss: 0.260383
 >> iter 30000, loss: 0.216704
   Number of active neurons: 9
 >> iter 31000, loss: 0.295877
 >> iter 32000, loss: 0.297545
 >> iter 33000, loss: 0.301004
 >> iter 34000, loss: 0.327795
 >> iter 35000, loss: 0.343266
 >> iter 36000, loss: 0.217010
 >> iter 37000, loss: 0.390032
 >> iter 38000, loss: 0.316681
 >> iter 39000, loss: 0.201450
 >> iter 40000, loss: 0.183931
   Number of active neurons: 8
 >> iter 41000, loss: 0.201784
 >> iter 42000, loss: 0.243446
 >> iter 43000, loss: 0.336475
 >> iter 44000, loss: 0.370938
 >> iter 45000, loss: 0.293085
 >> iter 46000, loss: 0.297237
 >> iter 47000, loss: 0.422850
 >> iter 48000, loss: 0.264180
 >> iter 49000, loss: 0.256911
 >> iter 50000, loss: 0.180147
   Number of active neurons: 8
 >> iter 51000, loss: 0.175731
 >> iter 52000, loss: 0.225067
 >> iter 53000, loss: 0.298951
 >> iter 54000, loss: 0.297277
 >> iter 55000, loss: 0.209107
 >> iter 56000, loss: 0.193791
 >> iter 57000, loss: 0.343518
 >> iter 58000, loss: 0.246408
 >> iter 59000, loss: 0.197916
 >> iter 60000, loss: 0.178889
   Number of active neurons: 8
 >> iter 61000, loss: 0.262120
 >> iter 62000, loss: 0.201691
 >> iter 63000, loss: 0.253286
 >> iter 64000, loss: 0.213530
 >> iter 65000, loss: 0.223064
 >> iter 66000, loss: 0.207783
 >> iter 67000, loss: 0.186336
 >> iter 68000, loss: 0.219419
 >> iter 69000, loss: 0.291070
 >> iter 70000, loss: 0.230025
   Number of active neurons: 7
 >> iter 71000, loss: 0.237308
 >> iter 72000, loss: 0.266776
 >> iter 73000, loss: 0.199672
 >> iter 74000, loss: 0.181762
 >> iter 75000, loss: 0.158300
 >> iter 76000, loss: 0.250531
 >> iter 77000, loss: 0.275665
 >> iter 78000, loss: 0.199382
 >> iter 79000, loss: 0.251214
 >> iter 80000, loss: 0.475235
   Number of active neurons: 7
 >> iter 81000, loss: 0.309996
 >> iter 82000, loss: 0.170676
 >> iter 83000, loss: 0.305498
 >> iter 84000, loss: 0.236783
 >> iter 85000, loss: 0.390352
 >> iter 86000, loss: 0.265201
 >> iter 87000, loss: 0.155222
 >> iter 88000, loss: 0.254435
 >> iter 89000, loss: 0.300728
 >> iter 90000, loss: 0.252208
   Number of active neurons: 6
 >> iter 91000, loss: 0.157509
 >> iter 92000, loss: 0.124641
 >> iter 93000, loss: 0.079447
 >> iter 94000, loss: 0.230859
 >> iter 95000, loss: 0.293602
 >> iter 96000, loss: 0.255482
 >> iter 97000, loss: 0.207908
 >> iter 98000, loss: 0.313017
 >> iter 99000, loss: 0.223797
 >> iter 100000, loss: 0.244766
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.140746
 >> iter 2000, loss: 10.741674
 >> iter 3000, loss: 4.851199
 >> iter 4000, loss: 2.253393
 >> iter 5000, loss: 1.051568
 >> iter 6000, loss: 0.824095
 >> iter 7000, loss: 0.698837
 >> iter 8000, loss: 0.413018
 >> iter 9000, loss: 0.306271
 >> iter 10000, loss: 0.268220
   Number of active neurons: 9
 >> iter 11000, loss: 0.492140
 >> iter 12000, loss: 0.351696
 >> iter 13000, loss: 0.310644
 >> iter 14000, loss: 0.368251
 >> iter 15000, loss: 0.399002
 >> iter 16000, loss: 0.525446
 >> iter 17000, loss: 0.451340
 >> iter 18000, loss: 0.247839
 >> iter 19000, loss: 0.357680
 >> iter 20000, loss: 0.417384
   Number of active neurons: 8
 >> iter 21000, loss: 0.367549
 >> iter 22000, loss: 0.247648
 >> iter 23000, loss: 0.259598
 >> iter 24000, loss: 0.330811
 >> iter 25000, loss: 0.250755
 >> iter 26000, loss: 0.401636
 >> iter 27000, loss: 0.423588
 >> iter 28000, loss: 0.500269
 >> iter 29000, loss: 0.411766
 >> iter 30000, loss: 0.483611
   Number of active neurons: 8
 >> iter 31000, loss: 0.433307
 >> iter 32000, loss: 0.441566
 >> iter 33000, loss: 0.281798
 >> iter 34000, loss: 0.264161
 >> iter 35000, loss: 0.303491
 >> iter 36000, loss: 0.430384
 >> iter 37000, loss: 0.459559
 >> iter 38000, loss: 0.340040
 >> iter 39000, loss: 0.368741
 >> iter 40000, loss: 0.517199
   Number of active neurons: 8
 >> iter 41000, loss: 0.349338
 >> iter 42000, loss: 0.303813
 >> iter 43000, loss: 0.338215
 >> iter 44000, loss: 0.559654
 >> iter 45000, loss: 0.501251
 >> iter 46000, loss: 0.371294
 >> iter 47000, loss: 0.327316
 >> iter 48000, loss: 0.392474
 >> iter 49000, loss: 0.416107
 >> iter 50000, loss: 0.423138
   Number of active neurons: 8
 >> iter 51000, loss: 0.409443
 >> iter 52000, loss: 0.411981
 >> iter 53000, loss: 0.390593
 >> iter 54000, loss: 0.463080
 >> iter 55000, loss: 0.359871
 >> iter 56000, loss: 0.397796
 >> iter 57000, loss: 0.399180
 >> iter 58000, loss: 0.246779
 >> iter 59000, loss: 0.263387
 >> iter 60000, loss: 0.381586
   Number of active neurons: 7
 >> iter 61000, loss: 0.391780
 >> iter 62000, loss: 0.339219
 >> iter 63000, loss: 0.476421
 >> iter 64000, loss: 0.357691
 >> iter 65000, loss: 0.308665
 >> iter 66000, loss: 0.312415
 >> iter 67000, loss: 0.385842
 >> iter 68000, loss: 0.394878
 >> iter 69000, loss: 0.371771
 >> iter 70000, loss: 0.309286
   Number of active neurons: 7
 >> iter 71000, loss: 0.400514
 >> iter 72000, loss: 0.319924
 >> iter 73000, loss: 0.420002
 >> iter 74000, loss: 0.349428
 >> iter 75000, loss: 0.338764
 >> iter 76000, loss: 0.231248
 >> iter 77000, loss: 0.236430
 >> iter 78000, loss: 0.387253
 >> iter 79000, loss: 0.320069
 >> iter 80000, loss: 0.233248
   Number of active neurons: 7
 >> iter 81000, loss: 0.278311
 >> iter 82000, loss: 0.280335
 >> iter 83000, loss: 0.204099
 >> iter 84000, loss: 0.305425
 >> iter 85000, loss: 0.225991
 >> iter 86000, loss: 0.200685
 >> iter 87000, loss: 0.220459
 >> iter 88000, loss: 0.262585
 >> iter 89000, loss: 0.281038
 >> iter 90000, loss: 0.193962
   Number of active neurons: 7
 >> iter 91000, loss: 0.406596
 >> iter 92000, loss: 0.372336
 >> iter 93000, loss: 0.285330
 >> iter 94000, loss: 0.228404
 >> iter 95000, loss: 0.241387
 >> iter 96000, loss: 0.233821
 >> iter 97000, loss: 0.198497
 >> iter 98000, loss: 0.176927
 >> iter 99000, loss: 0.137864
 >> iter 100000, loss: 0.149509
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 19.157840
 >> iter 2000, loss: 10.482168
 >> iter 3000, loss: 4.455040
 >> iter 4000, loss: 1.878931
 >> iter 5000, loss: 0.850783
 >> iter 6000, loss: 0.485502
 >> iter 7000, loss: 0.283486
 >> iter 8000, loss: 0.286263
 >> iter 9000, loss: 0.312153
 >> iter 10000, loss: 0.245597
   Number of active neurons: 9
 >> iter 11000, loss: 0.216502
 >> iter 12000, loss: 0.213903
 >> iter 13000, loss: 0.212387
 >> iter 14000, loss: 0.235708
 >> iter 15000, loss: 0.306789
 >> iter 16000, loss: 0.261114
 >> iter 17000, loss: 0.191800
 >> iter 18000, loss: 0.240660
 >> iter 19000, loss: 0.334200
 >> iter 20000, loss: 0.293535
   Number of active neurons: 8
 >> iter 21000, loss: 0.303841
 >> iter 22000, loss: 0.255014
 >> iter 23000, loss: 0.262357
 >> iter 24000, loss: 0.241969
 >> iter 25000, loss: 0.202131
 >> iter 26000, loss: 0.158546
 >> iter 27000, loss: 0.264021
 >> iter 28000, loss: 0.260858
 >> iter 29000, loss: 0.271196
 >> iter 30000, loss: 0.210472
   Number of active neurons: 7
 >> iter 31000, loss: 0.228502
 >> iter 32000, loss: 0.172191
 >> iter 33000, loss: 0.225269
 >> iter 34000, loss: 0.363463
 >> iter 35000, loss: 0.233790
 >> iter 36000, loss: 0.168088
 >> iter 37000, loss: 0.189325
 >> iter 38000, loss: 0.159713
 >> iter 39000, loss: 0.142486
 >> iter 40000, loss: 0.236484
   Number of active neurons: 6
 >> iter 41000, loss: 0.383363
 >> iter 42000, loss: 0.243984
 >> iter 43000, loss: 0.193944
 >> iter 44000, loss: 0.304346
 >> iter 45000, loss: 0.230828
 >> iter 46000, loss: 0.311947
 >> iter 47000, loss: 0.258310
 >> iter 48000, loss: 0.289629
 >> iter 49000, loss: 0.179176
 >> iter 50000, loss: 0.117271
   Number of active neurons: 5
 >> iter 51000, loss: 0.242580
 >> iter 52000, loss: 0.254081
 >> iter 53000, loss: 0.469811
 >> iter 54000, loss: 0.272935
 >> iter 55000, loss: 0.321931
 >> iter 56000, loss: 0.274411
 >> iter 57000, loss: 0.381729
 >> iter 58000, loss: 0.245812
 >> iter 59000, loss: 0.167626
 >> iter 60000, loss: 0.162809
   Number of active neurons: 5
 >> iter 61000, loss: 0.232076
 >> iter 62000, loss: 0.176242
 >> iter 63000, loss: 0.207697
 >> iter 64000, loss: 0.319967
 >> iter 65000, loss: 0.246982
 >> iter 66000, loss: 0.216677
 >> iter 67000, loss: 0.252324
 >> iter 68000, loss: 0.230603
 >> iter 69000, loss: 0.272213
 >> iter 70000, loss: 0.200585
   Number of active neurons: 5
 >> iter 71000, loss: 0.164635
 >> iter 72000, loss: 0.194318
 >> iter 73000, loss: 0.428133
 >> iter 74000, loss: 0.385095
 >> iter 75000, loss: 0.352415
 >> iter 76000, loss: 0.303724
 >> iter 77000, loss: 0.200310
 >> iter 78000, loss: 0.136986
 >> iter 79000, loss: 0.080798
 >> iter 80000, loss: 0.277858
   Number of active neurons: 4
 >> iter 81000, loss: 0.254305
 >> iter 82000, loss: 0.305085
 >> iter 83000, loss: 0.220793
 >> iter 84000, loss: 0.322337
 >> iter 85000, loss: 0.202631
 >> iter 86000, loss: 0.157271
 >> iter 87000, loss: 0.116707
 >> iter 88000, loss: 0.180789
 >> iter 89000, loss: 0.161265
 >> iter 90000, loss: 0.161584
   Number of active neurons: 4
 >> iter 91000, loss: 0.236819
 >> iter 92000, loss: 0.288905
 >> iter 93000, loss: 0.161714
 >> iter 94000, loss: 0.370386
 >> iter 95000, loss: 0.231116
 >> iter 96000, loss: 0.221546
 >> iter 97000, loss: 0.250059
 >> iter 98000, loss: 0.282014
 >> iter 99000, loss: 0.139462
 >> iter 100000, loss: 0.235784
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.995843
 >> iter 2000, loss: 11.165431
 >> iter 3000, loss: 5.037484
 >> iter 4000, loss: 2.343787
 >> iter 5000, loss: 1.107139
 >> iter 6000, loss: 0.590856
 >> iter 7000, loss: 0.356259
 >> iter 8000, loss: 0.354717
 >> iter 9000, loss: 0.471868
 >> iter 10000, loss: 0.448193
   Number of active neurons: 9
 >> iter 11000, loss: 0.314829
 >> iter 12000, loss: 0.273653
 >> iter 13000, loss: 0.247946
 >> iter 14000, loss: 0.341035
 >> iter 15000, loss: 0.188077
 >> iter 16000, loss: 0.140480
 >> iter 17000, loss: 0.214606
 >> iter 18000, loss: 0.336512
 >> iter 19000, loss: 0.261783
 >> iter 20000, loss: 0.332546
   Number of active neurons: 7
 >> iter 21000, loss: 0.203032
 >> iter 22000, loss: 0.229894
 >> iter 23000, loss: 0.258145
 >> iter 24000, loss: 0.257622
 >> iter 25000, loss: 0.254515
 >> iter 26000, loss: 0.263958
 >> iter 27000, loss: 0.246978
 >> iter 28000, loss: 0.222030
 >> iter 29000, loss: 0.193365
 >> iter 30000, loss: 0.201361
   Number of active neurons: 7
 >> iter 31000, loss: 0.160216
 >> iter 32000, loss: 0.181573
 >> iter 33000, loss: 0.144312
 >> iter 34000, loss: 0.214169
 >> iter 35000, loss: 0.168155
 >> iter 36000, loss: 0.225604
 >> iter 37000, loss: 0.211954
 >> iter 38000, loss: 0.189700
 >> iter 39000, loss: 0.216901
 >> iter 40000, loss: 0.181331
   Number of active neurons: 5
 >> iter 41000, loss: 0.200508
 >> iter 42000, loss: 0.272108
 >> iter 43000, loss: 0.241835
 >> iter 44000, loss: 0.174609
 >> iter 45000, loss: 0.309606
 >> iter 46000, loss: 0.329872
 >> iter 47000, loss: 0.210037
 >> iter 48000, loss: 0.264347
 >> iter 49000, loss: 0.227417
 >> iter 50000, loss: 0.199290
   Number of active neurons: 5
 >> iter 51000, loss: 0.179143
 >> iter 52000, loss: 0.202190
 >> iter 53000, loss: 0.170310
 >> iter 54000, loss: 0.148286
 >> iter 55000, loss: 0.177755
 >> iter 56000, loss: 0.210937
 >> iter 57000, loss: 0.154545
 >> iter 58000, loss: 0.307163
 >> iter 59000, loss: 0.225881
 >> iter 60000, loss: 0.234269
   Number of active neurons: 5
 >> iter 61000, loss: 0.238369
 >> iter 62000, loss: 0.235938
 >> iter 63000, loss: 0.286053
 >> iter 64000, loss: 0.178604
 >> iter 65000, loss: 0.212675
 >> iter 66000, loss: 0.145853
 >> iter 67000, loss: 0.098314
 >> iter 68000, loss: 0.148994
 >> iter 69000, loss: 0.231676
 >> iter 70000, loss: 0.194041
   Number of active neurons: 4
 >> iter 71000, loss: 0.249532
 >> iter 72000, loss: 0.219330
 >> iter 73000, loss: 0.272712
 >> iter 74000, loss: 0.376856
 >> iter 75000, loss: 0.327628
 >> iter 76000, loss: 0.373918
 >> iter 77000, loss: 0.335305
 >> iter 78000, loss: 0.189772
 >> iter 79000, loss: 0.221586
 >> iter 80000, loss: 0.205950
   Number of active neurons: 4
 >> iter 81000, loss: 0.210413
 >> iter 82000, loss: 0.250456
 >> iter 83000, loss: 0.183177
 >> iter 84000, loss: 0.153791
 >> iter 85000, loss: 0.260448
 >> iter 86000, loss: 0.281819
 >> iter 87000, loss: 0.185089
 >> iter 88000, loss: 0.159873
 >> iter 89000, loss: 0.255201
 >> iter 90000, loss: 0.190132
   Number of active neurons: 4
 >> iter 91000, loss: 0.131450
 >> iter 92000, loss: 0.150943
 >> iter 93000, loss: 0.174071
 >> iter 94000, loss: 0.180731
 >> iter 95000, loss: 0.151791
 >> iter 96000, loss: 0.252604
 >> iter 97000, loss: 0.168180
 >> iter 98000, loss: 0.213660
 >> iter 99000, loss: 0.252686
 >> iter 100000, loss: 0.291975
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.288899
 >> iter 2000, loss: 11.540252
 >> iter 3000, loss: 5.127709
 >> iter 4000, loss: 2.116161
 >> iter 5000, loss: 1.105035
 >> iter 6000, loss: 0.601831
 >> iter 7000, loss: 0.439424
 >> iter 8000, loss: 0.367787
 >> iter 9000, loss: 0.397513
 >> iter 10000, loss: 0.366957
   Number of active neurons: 10
 >> iter 11000, loss: 0.480263
 >> iter 12000, loss: 0.388108
 >> iter 13000, loss: 0.393085
 >> iter 14000, loss: 0.448542
 >> iter 15000, loss: 0.277842
 >> iter 16000, loss: 0.241509
 >> iter 17000, loss: 0.340787
 >> iter 18000, loss: 0.326409
 >> iter 19000, loss: 0.251974
 >> iter 20000, loss: 0.163311
   Number of active neurons: 10
 >> iter 21000, loss: 0.274907
 >> iter 22000, loss: 0.186920
 >> iter 23000, loss: 0.193483
 >> iter 24000, loss: 0.298027
 >> iter 25000, loss: 0.238279
 >> iter 26000, loss: 0.206156
 >> iter 27000, loss: 0.139238
 >> iter 28000, loss: 0.296207
 >> iter 29000, loss: 0.273922
 >> iter 30000, loss: 0.341787
   Number of active neurons: 10
 >> iter 31000, loss: 0.251683
 >> iter 32000, loss: 0.297142
 >> iter 33000, loss: 0.234228
 >> iter 34000, loss: 0.199010
 >> iter 35000, loss: 0.319179
 >> iter 36000, loss: 0.308326
 >> iter 37000, loss: 0.399025
 >> iter 38000, loss: 0.294278
 >> iter 39000, loss: 0.228390
 >> iter 40000, loss: 0.361607
   Number of active neurons: 10
 >> iter 41000, loss: 0.250827
 >> iter 42000, loss: 0.349356
 >> iter 43000, loss: 0.338575
 >> iter 44000, loss: 0.276830
 >> iter 45000, loss: 0.256602
 >> iter 46000, loss: 0.245142
 >> iter 47000, loss: 0.264200
 >> iter 48000, loss: 0.249635
 >> iter 49000, loss: 0.270899
 >> iter 50000, loss: 0.322922
   Number of active neurons: 10
 >> iter 51000, loss: 0.345398
 >> iter 52000, loss: 0.266781
 >> iter 53000, loss: 0.303984
 >> iter 54000, loss: 0.266808
 >> iter 55000, loss: 0.266968
 >> iter 56000, loss: 0.322177
 >> iter 57000, loss: 0.299784
 >> iter 58000, loss: 0.279229
 >> iter 59000, loss: 0.273337
 >> iter 60000, loss: 0.187035
   Number of active neurons: 10
 >> iter 61000, loss: 0.238015
 >> iter 62000, loss: 0.279097
 >> iter 63000, loss: 0.310654
 >> iter 64000, loss: 0.242581
 >> iter 65000, loss: 0.280875
 >> iter 66000, loss: 0.337276
 >> iter 67000, loss: 0.246170
 >> iter 68000, loss: 0.232743
 >> iter 69000, loss: 0.176982
 >> iter 70000, loss: 0.225569
   Number of active neurons: 10
 >> iter 71000, loss: 0.374015
 >> iter 72000, loss: 0.280639
 >> iter 73000, loss: 0.442906
 >> iter 74000, loss: 0.305416
 >> iter 75000, loss: 0.188967
 >> iter 76000, loss: 0.173819
 >> iter 77000, loss: 0.252657
 >> iter 78000, loss: 0.214992
 >> iter 79000, loss: 0.228556
 >> iter 80000, loss: 0.242933
   Number of active neurons: 8
 >> iter 81000, loss: 0.207393
 >> iter 82000, loss: 0.213908
 >> iter 83000, loss: 0.251031
 >> iter 84000, loss: 0.207922
 >> iter 85000, loss: 0.470242
 >> iter 86000, loss: 0.333915
 >> iter 87000, loss: 0.256704
 >> iter 88000, loss: 0.255428
 >> iter 89000, loss: 0.199300
 >> iter 90000, loss: 0.204673
   Number of active neurons: 8
 >> iter 91000, loss: 0.225901
 >> iter 92000, loss: 0.224524
 >> iter 93000, loss: 0.408475
 >> iter 94000, loss: 0.229986
 >> iter 95000, loss: 0.201507
 >> iter 96000, loss: 0.164102
 >> iter 97000, loss: 0.239814
 >> iter 98000, loss: 0.207135
 >> iter 99000, loss: 0.187423
 >> iter 100000, loss: 0.198026
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.834438
 >> iter 2000, loss: 9.516025
 >> iter 3000, loss: 3.776307
 >> iter 4000, loss: 1.719783
 >> iter 5000, loss: 0.968772
 >> iter 6000, loss: 0.712712
 >> iter 7000, loss: 0.358082
 >> iter 8000, loss: 0.326262
 >> iter 9000, loss: 0.279896
 >> iter 10000, loss: 0.270880
   Number of active neurons: 10
 >> iter 11000, loss: 0.559136
 >> iter 12000, loss: 0.510615
 >> iter 13000, loss: 0.326378
 >> iter 14000, loss: 0.303456
 >> iter 15000, loss: 0.285510
 >> iter 16000, loss: 0.489431
 >> iter 17000, loss: 0.263554
 >> iter 18000, loss: 0.323163
 >> iter 19000, loss: 0.442312
 >> iter 20000, loss: 0.346509
   Number of active neurons: 9
 >> iter 21000, loss: 0.396717
 >> iter 22000, loss: 0.238127
 >> iter 23000, loss: 0.329186
 >> iter 24000, loss: 0.246426
 >> iter 25000, loss: 0.260236
 >> iter 26000, loss: 0.297719
 >> iter 27000, loss: 0.212316
 >> iter 28000, loss: 0.208757
 >> iter 29000, loss: 0.225584
 >> iter 30000, loss: 0.190703
   Number of active neurons: 7
 >> iter 31000, loss: 0.198453
 >> iter 32000, loss: 0.115976
 >> iter 33000, loss: 0.271831
 >> iter 34000, loss: 0.272456
 >> iter 35000, loss: 0.305265
 >> iter 36000, loss: 0.256143
 >> iter 37000, loss: 0.238706
 >> iter 38000, loss: 0.187690
 >> iter 39000, loss: 0.159679
 >> iter 40000, loss: 0.128424
   Number of active neurons: 6
 >> iter 41000, loss: 0.115490
 >> iter 42000, loss: 0.132963
 >> iter 43000, loss: 0.230996
 >> iter 44000, loss: 0.233781
 >> iter 45000, loss: 0.270421
 >> iter 46000, loss: 0.336152
 >> iter 47000, loss: 0.222404
 >> iter 48000, loss: 0.219524
 >> iter 49000, loss: 0.237968
 >> iter 50000, loss: 0.235638
   Number of active neurons: 5
 >> iter 51000, loss: 0.213697
 >> iter 52000, loss: 0.234164
 >> iter 53000, loss: 0.224084
 >> iter 54000, loss: 0.318506
 >> iter 55000, loss: 0.369244
 >> iter 56000, loss: 0.235123
 >> iter 57000, loss: 0.139817
 >> iter 58000, loss: 0.190265
 >> iter 59000, loss: 0.282909
 >> iter 60000, loss: 0.186796
   Number of active neurons: 5
 >> iter 61000, loss: 0.188914
 >> iter 62000, loss: 0.230468
 >> iter 63000, loss: 0.185256
 >> iter 64000, loss: 0.148945
 >> iter 65000, loss: 0.205240
 >> iter 66000, loss: 0.269943
 >> iter 67000, loss: 0.369606
 >> iter 68000, loss: 0.284536
 >> iter 69000, loss: 0.288012
 >> iter 70000, loss: 0.258234
   Number of active neurons: 5
 >> iter 71000, loss: 0.296861
 >> iter 72000, loss: 0.214284
 >> iter 73000, loss: 0.170467
 >> iter 74000, loss: 0.154265
 >> iter 75000, loss: 0.180430
 >> iter 76000, loss: 0.169813
 >> iter 77000, loss: 0.174653
 >> iter 78000, loss: 0.191945
 >> iter 79000, loss: 0.132886
 >> iter 80000, loss: 0.147675
   Number of active neurons: 5
 >> iter 81000, loss: 0.177236
 >> iter 82000, loss: 0.114211
 >> iter 83000, loss: 0.136206
 >> iter 84000, loss: 0.311290
 >> iter 85000, loss: 0.303779
 >> iter 86000, loss: 0.164977
 >> iter 87000, loss: 0.248134
 >> iter 88000, loss: 0.260466
 >> iter 89000, loss: 0.316466
 >> iter 90000, loss: 0.362577
   Number of active neurons: 5
 >> iter 91000, loss: 0.336567
 >> iter 92000, loss: 0.208549
 >> iter 93000, loss: 0.226477
 >> iter 94000, loss: 0.231134
 >> iter 95000, loss: 0.263597
 >> iter 96000, loss: 0.192431
 >> iter 97000, loss: 0.252238
 >> iter 98000, loss: 0.201782
 >> iter 99000, loss: 0.258615
 >> iter 100000, loss: 0.165232
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.204429
 >> iter 2000, loss: 11.633088
 >> iter 3000, loss: 4.807548
 >> iter 4000, loss: 2.176869
 >> iter 5000, loss: 1.002453
 >> iter 6000, loss: 0.570273
 >> iter 7000, loss: 0.505692
 >> iter 8000, loss: 0.411931
 >> iter 9000, loss: 0.388561
 >> iter 10000, loss: 0.261964
   Number of active neurons: 8
 >> iter 11000, loss: 0.194119
 >> iter 12000, loss: 0.234999
 >> iter 13000, loss: 0.389847
 >> iter 14000, loss: 0.403489
 >> iter 15000, loss: 0.389101
 >> iter 16000, loss: 0.380367
 >> iter 17000, loss: 0.367309
 >> iter 18000, loss: 0.264240
 >> iter 19000, loss: 0.361231
 >> iter 20000, loss: 0.215053
   Number of active neurons: 7
 >> iter 21000, loss: 0.448546
 >> iter 22000, loss: 0.400660
 >> iter 23000, loss: 0.314056
 >> iter 24000, loss: 0.241458
 >> iter 25000, loss: 0.261972
 >> iter 26000, loss: 0.227422
 >> iter 27000, loss: 0.415822
 >> iter 28000, loss: 0.377982
 >> iter 29000, loss: 0.310331
 >> iter 30000, loss: 0.281117
   Number of active neurons: 7
 >> iter 31000, loss: 0.205478
 >> iter 32000, loss: 0.286686
 >> iter 33000, loss: 0.355232
 >> iter 34000, loss: 0.250697
 >> iter 35000, loss: 0.272394
 >> iter 36000, loss: 0.225548
 >> iter 37000, loss: 0.226074
 >> iter 38000, loss: 0.447193
 >> iter 39000, loss: 0.251158
 >> iter 40000, loss: 0.186268
   Number of active neurons: 5
 >> iter 41000, loss: 0.198665
 >> iter 42000, loss: 0.277875
 >> iter 43000, loss: 0.303954
 >> iter 44000, loss: 0.232930
 >> iter 45000, loss: 0.161705
 >> iter 46000, loss: 0.295738
 >> iter 47000, loss: 0.297619
 >> iter 48000, loss: 0.210714
 >> iter 49000, loss: 0.198198
 >> iter 50000, loss: 0.180875
   Number of active neurons: 5
 >> iter 51000, loss: 0.228433
 >> iter 52000, loss: 0.219433
 >> iter 53000, loss: 0.164106
 >> iter 54000, loss: 0.149401
 >> iter 55000, loss: 0.153874
 >> iter 56000, loss: 0.177475
 >> iter 57000, loss: 0.244679
 >> iter 58000, loss: 0.274952
 >> iter 59000, loss: 0.237039
 >> iter 60000, loss: 0.237385
   Number of active neurons: 5
 >> iter 61000, loss: 0.225289
 >> iter 62000, loss: 0.296566
 >> iter 63000, loss: 0.210424
 >> iter 64000, loss: 0.260575
 >> iter 65000, loss: 0.320958
 >> iter 66000, loss: 0.200103
 >> iter 67000, loss: 0.212101
 >> iter 68000, loss: 0.150461
 >> iter 69000, loss: 0.175039
 >> iter 70000, loss: 0.137793
   Number of active neurons: 5
 >> iter 71000, loss: 0.121290
 >> iter 72000, loss: 0.277327
 >> iter 73000, loss: 0.192122
 >> iter 74000, loss: 0.185740
 >> iter 75000, loss: 0.149949
 >> iter 76000, loss: 0.128752
 >> iter 77000, loss: 0.175068
 >> iter 78000, loss: 0.265912
 >> iter 79000, loss: 0.335882
 >> iter 80000, loss: 0.268295
   Number of active neurons: 5
 >> iter 81000, loss: 0.276338
 >> iter 82000, loss: 0.248324
 >> iter 83000, loss: 0.169059
 >> iter 84000, loss: 0.175270
 >> iter 85000, loss: 0.215763
 >> iter 86000, loss: 0.217357
 >> iter 87000, loss: 0.392057
 >> iter 88000, loss: 0.324328
 >> iter 89000, loss: 0.342009
 >> iter 90000, loss: 0.275436
   Number of active neurons: 5
 >> iter 91000, loss: 0.166844
 >> iter 92000, loss: 0.124136
 >> iter 93000, loss: 0.246991
 >> iter 94000, loss: 0.200031
 >> iter 95000, loss: 0.239533
 >> iter 96000, loss: 0.278771
 >> iter 97000, loss: 0.199613
 >> iter 98000, loss: 0.149445
 >> iter 99000, loss: 0.099147
 >> iter 100000, loss: 0.125390
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

