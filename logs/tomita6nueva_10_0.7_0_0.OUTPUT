 > Problema: tomita6nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.7
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 18.928412
 >> iter 2000, loss: 15.438905
 >> iter 3000, loss: 13.983538
 >> iter 4000, loss: 13.429289
 >> iter 5000, loss: 13.198349
 >> iter 6000, loss: 13.115956
 >> iter 7000, loss: 13.060079
 >> iter 8000, loss: 13.058992
 >> iter 9000, loss: 13.033162
 >> iter 10000, loss: 13.029979
   Number of active neurons: 10
 >> iter 11000, loss: 13.017843
 >> iter 12000, loss: 13.027113
 >> iter 13000, loss: 13.013301
 >> iter 14000, loss: 13.018792
 >> iter 15000, loss: 13.014327
 >> iter 16000, loss: 13.017451
 >> iter 17000, loss: 13.015033
 >> iter 18000, loss: 13.018993
 >> iter 19000, loss: 13.011863
 >> iter 20000, loss: 13.018663
   Number of active neurons: 10
 >> iter 21000, loss: 13.003988
 >> iter 22000, loss: 13.009666
 >> iter 23000, loss: 12.995930
 >> iter 24000, loss: 13.012217
 >> iter 25000, loss: 13.004522
 >> iter 26000, loss: 13.018730
 >> iter 27000, loss: 13.010496
 >> iter 28000, loss: 13.020246
 >> iter 29000, loss: 13.007479
 >> iter 30000, loss: 13.018174
   Number of active neurons: 10
 >> iter 31000, loss: 13.008431
 >> iter 32000, loss: 13.028022
 >> iter 33000, loss: 13.014612
 >> iter 34000, loss: 13.016831
 >> iter 35000, loss: 13.012278
 >> iter 36000, loss: 13.018612
 >> iter 37000, loss: 13.009370
 >> iter 38000, loss: 13.023638
 >> iter 39000, loss: 13.002041
 >> iter 40000, loss: 13.016733
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 41000, loss: 13.001062
 >> iter 42000, loss: 12.988811
 >> iter 43000, loss: 12.957774
 >> iter 44000, loss: 12.382579
 >> iter 45000, loss: 11.592018
 >> iter 46000, loss: 11.257429
 >> iter 47000, loss: 10.967087
 >> iter 48000, loss: 10.869330
 >> iter 49000, loss: 10.656405
 >> iter 50000, loss: 10.609923
   Number of active neurons: 10
 >> iter 51000, loss: 10.476899
 >> iter 52000, loss: 10.476318
 >> iter 53000, loss: 10.341095
 >> iter 54000, loss: 10.354706
 >> iter 55000, loss: 10.185641
 >> iter 56000, loss: 9.806653
 >> iter 57000, loss: 9.441592
 >> iter 58000, loss: 9.297363
 >> iter 59000, loss: 9.091197
 >> iter 60000, loss: 8.925454
   Number of active neurons: 10
 >> iter 61000, loss: 8.734038
 >> iter 62000, loss: 8.716363
 >> iter 63000, loss: 8.469788
 >> iter 64000, loss: 8.322176
 >> iter 65000, loss: 8.122529
 >> iter 66000, loss: 8.120979
 >> iter 67000, loss: 7.517444
 >> iter 68000, loss: 7.544049
 >> iter 69000, loss: 7.365313
 >> iter 70000, loss: 7.047998
   Number of active neurons: 10
 >> iter 71000, loss: 5.385083
 >> iter 72000, loss: 3.210285
 >> iter 73000, loss: 2.998717
 >> iter 74000, loss: 2.925033
 >> iter 75000, loss: 2.213976
 >> iter 76000, loss: 1.629208
 >> iter 77000, loss: 1.597401
 >> iter 78000, loss: 1.255549
 >> iter 79000, loss: 1.077514
 >> iter 80000, loss: 1.015861
   Number of active neurons: 10
 >> iter 81000, loss: 1.037869
 >> iter 82000, loss: 0.711854
 >> iter 83000, loss: 0.520436
 >> iter 84000, loss: 0.626963
 >> iter 85000, loss: 0.623639
 >> iter 86000, loss: 0.648193
 >> iter 87000, loss: 0.566860
 >> iter 88000, loss: 0.498795
 >> iter 89000, loss: 0.381271
 >> iter 90000, loss: 0.420135
   Number of active neurons: 10
 >> iter 91000, loss: 0.365057
 >> iter 92000, loss: 0.219127
 >> iter 93000, loss: 0.240668
 >> iter 94000, loss: 0.232577
 >> iter 95000, loss: 0.413485
 >> iter 96000, loss: 0.287854
 >> iter 97000, loss: 0.419454
 >> iter 98000, loss: 0.491283
 >> iter 99000, loss: 0.338103
 >> iter 100000, loss: 0.336578
   Number of active neurons: 10
 >> iter 101000, loss: 0.896802
 >> iter 102000, loss: 0.508623
 >> iter 103000, loss: 0.313182
 >> iter 104000, loss: 0.556045
 >> iter 105000, loss: 0.765842
 >> iter 106000, loss: 0.690911
 >> iter 107000, loss: 0.493004
 >> iter 108000, loss: 0.495269
 >> iter 109000, loss: 0.323735
 >> iter 110000, loss: 0.262432
   Number of active neurons: 10
 >> iter 111000, loss: 0.304476
 >> iter 112000, loss: 0.216348
 >> iter 113000, loss: 0.152046
 >> iter 114000, loss: 0.212439
 >> iter 115000, loss: 0.383642
 >> iter 116000, loss: 0.550251
 >> iter 117000, loss: 0.278046
 >> iter 118000, loss: 0.260092
 >> iter 119000, loss: 0.161202
 >> iter 120000, loss: 0.204462
   Number of active neurons: 10
 >> iter 121000, loss: 0.113122
 >> iter 122000, loss: 0.099651
 >> iter 123000, loss: 0.190748
 >> iter 124000, loss: 0.174674
 >> iter 125000, loss: 0.101788
 >> iter 126000, loss: 0.051770
 >> iter 127000, loss: 0.092443
 >> iter 128000, loss: 0.136667
 >> iter 129000, loss: 0.092109
 >> iter 130000, loss: 0.166891
   Number of active neurons: 10
 >> iter 131000, loss: 0.185839
 >> iter 132000, loss: 0.186926
 >> iter 133000, loss: 0.132482
 >> iter 134000, loss: 0.087502
 >> iter 135000, loss: 0.092285
 >> iter 136000, loss: 0.114781
 >> iter 137000, loss: 0.213223
 >> iter 138000, loss: 0.106935
 >> iter 139000, loss: 0.135588
 >> iter 140000, loss: 0.082586
   Number of active neurons: 10
 >> iter 141000, loss: 0.040267
 >> iter 142000, loss: 0.347363
 >> iter 143000, loss: 0.240760
 >> iter 144000, loss: 0.222211
 >> iter 145000, loss: 0.125176
 >> iter 146000, loss: 0.080594
 >> iter 147000, loss: 0.175566
 >> iter 148000, loss: 0.095659
 >> iter 149000, loss: 0.061485
 >> iter 150000, loss: 0.051653
   Number of active neurons: 10
 >> iter 151000, loss: 0.057646
 >> iter 152000, loss: 0.093856
 >> iter 153000, loss: 0.185635
 >> iter 154000, loss: 0.136804
 >> iter 155000, loss: 0.084050
 >> iter 156000, loss: 0.129397
 >> iter 157000, loss: 0.094792
 >> iter 158000, loss: 0.135494
 >> iter 159000, loss: 0.167203
 >> iter 160000, loss: 0.083778
   Number of active neurons: 10
 >> iter 161000, loss: 0.109518
 >> iter 162000, loss: 0.054891
 >> iter 163000, loss: 0.030467
 >> iter 164000, loss: 0.025186
 >> iter 165000, loss: 0.086751
 >> iter 166000, loss: 0.167564
 >> iter 167000, loss: 0.115876
 >> iter 168000, loss: 0.231064
 >> iter 169000, loss: 0.139781
 >> iter 170000, loss: 0.062135
   Number of active neurons: 10
 >> iter 171000, loss: 0.064589
 >> iter 172000, loss: 0.039167
 >> iter 173000, loss: 0.327432
 >> iter 174000, loss: 0.191585
 >> iter 175000, loss: 0.136514
 >> iter 176000, loss: 0.093865
 >> iter 177000, loss: 0.066802
 >> iter 178000, loss: 0.185904
 >> iter 179000, loss: 0.105052
 >> iter 180000, loss: 0.247073
   Number of active neurons: 10
 >> iter 181000, loss: 0.250285
 >> iter 182000, loss: 0.124189
 >> iter 183000, loss: 0.068618
 >> iter 184000, loss: 0.314074
 >> iter 185000, loss: 0.204452
 >> iter 186000, loss: 0.146722
 >> iter 187000, loss: 0.095675
 >> iter 188000, loss: 0.069419
 >> iter 189000, loss: 0.052943
 >> iter 190000, loss: 0.173325
   Number of active neurons: 10
 >> iter 191000, loss: 0.090875
 >> iter 192000, loss: 0.120732
 >> iter 193000, loss: 0.061574
 >> iter 194000, loss: 0.081077
 >> iter 195000, loss: 0.150885
 >> iter 196000, loss: 0.142022
 >> iter 197000, loss: 0.172395
 >> iter 198000, loss: 0.129571
 >> iter 199000, loss: 0.070658
 >> iter 200000, loss: 0.044727
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.862040
 >> iter 2000, loss: 15.339367
 >> iter 3000, loss: 13.961867
 >> iter 4000, loss: 13.427254
 >> iter 5000, loss: 13.200123
 >> iter 6000, loss: 13.130350
 >> iter 7000, loss: 13.079277
 >> iter 8000, loss: 13.062899
 >> iter 9000, loss: 13.050791
 >> iter 10000, loss: 13.061226
   Number of active neurons: 10
 >> iter 11000, loss: 13.048145
 >> iter 12000, loss: 13.051409
 >> iter 13000, loss: 13.035776
 >> iter 14000, loss: 13.041156
 >> iter 15000, loss: 13.026127
 >> iter 16000, loss: 13.041631
 >> iter 17000, loss: 13.021927
 >> iter 18000, loss: 13.029080
 >> iter 19000, loss: 13.020188
 >> iter 20000, loss: 13.032821
   Number of active neurons: 10
 >> iter 21000, loss: 13.015786
 >> iter 22000, loss: 13.028134
 >> iter 23000, loss: 13.013047
 >> iter 24000, loss: 13.020113
 >> iter 25000, loss: 13.012393
 >> iter 26000, loss: 13.008094
 >> iter 27000, loss: 12.998990
 >> iter 28000, loss: 13.009151
 >> iter 29000, loss: 13.001896
 >> iter 30000, loss: 13.014729
   Number of active neurons: 10
 >> iter 31000, loss: 12.994265
 >> iter 32000, loss: 12.924923
 >> iter 33000, loss: 12.150612
 >> iter 34000, loss: 11.532211
 >> iter 35000, loss: 11.115196
 >> iter 36000, loss: 10.962120
 >> iter 37000, loss: 10.737148
 >> iter 38000, loss: 10.662843
 >> iter 39000, loss: 10.448427
 >> iter 40000, loss: 10.425641
   Number of active neurons: 10
 >> iter 41000, loss: 10.161630
 >> iter 42000, loss: 9.998113
 >> iter 43000, loss: 9.738888
 >> iter 44000, loss: 9.187949
 >> iter 45000, loss: 8.907142
 >> iter 46000, loss: 8.617316
 >> iter 47000, loss: 8.256555
 >> iter 48000, loss: 8.311274
 >> iter 49000, loss: 8.202958
 >> iter 50000, loss: 8.137938
   Number of active neurons: 10
 >> iter 51000, loss: 8.044748
 >> iter 52000, loss: 8.059999
 >> iter 53000, loss: 7.851387
 >> iter 54000, loss: 8.007627
 >> iter 55000, loss: 7.897818
 >> iter 56000, loss: 7.872351
 >> iter 57000, loss: 7.791780
 >> iter 58000, loss: 7.931897
 >> iter 59000, loss: 7.831974
 >> iter 60000, loss: 7.864764
   Number of active neurons: 10
 >> iter 61000, loss: 7.809734
 >> iter 62000, loss: 7.911192
 >> iter 63000, loss: 7.773724
 >> iter 64000, loss: 7.896590
 >> iter 65000, loss: 7.853562
 >> iter 66000, loss: 7.784011
 >> iter 67000, loss: 7.672386
 >> iter 68000, loss: 7.372535
 >> iter 69000, loss: 7.049984
 >> iter 70000, loss: 7.326516
   Number of active neurons: 10
 >> iter 71000, loss: 6.199814
 >> iter 72000, loss: 5.671742
 >> iter 73000, loss: 5.497905
 >> iter 74000, loss: 6.089628
 >> iter 75000, loss: 5.624497
 >> iter 76000, loss: 5.274893
 >> iter 77000, loss: 5.305117
 >> iter 78000, loss: 5.529199
 >> iter 79000, loss: 5.743124
 >> iter 80000, loss: 5.691460
   Number of active neurons: 10
 >> iter 81000, loss: 5.825156
 >> iter 82000, loss: 5.215307
 >> iter 83000, loss: 4.021172
 >> iter 84000, loss: 2.389339
 >> iter 85000, loss: 1.428839
 >> iter 86000, loss: 0.765363
 >> iter 87000, loss: 0.983946
 >> iter 88000, loss: 0.617559
 >> iter 89000, loss: 0.430547
 >> iter 90000, loss: 0.270330
   Number of active neurons: 10
 >> iter 91000, loss: 0.411392
 >> iter 92000, loss: 0.448312
 >> iter 93000, loss: 0.272907
 >> iter 94000, loss: 0.157885
 >> iter 95000, loss: 0.269887
 >> iter 96000, loss: 0.133828
 >> iter 97000, loss: 0.073134
 >> iter 98000, loss: 0.063820
 >> iter 99000, loss: 0.309813
 >> iter 100000, loss: 0.157366
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455162
   Number of active neurons: 0
 >> iter 1000, loss: 18.870983
 >> iter 2000, loss: 15.330532
 >> iter 3000, loss: 13.929427
 >> iter 4000, loss: 13.394608
 >> iter 5000, loss: 13.166638
 >> iter 6000, loss: 13.077602
 >> iter 7000, loss: 13.048850
 >> iter 8000, loss: 13.032149
 >> iter 9000, loss: 13.015337
 >> iter 10000, loss: 13.028600
   Number of active neurons: 9
 >> iter 11000, loss: 12.999278
 >> iter 12000, loss: 13.007053
 >> iter 13000, loss: 12.994149
 >> iter 14000, loss: 13.006309
 >> iter 15000, loss: 12.990978
 >> iter 16000, loss: 12.998418
 >> iter 17000, loss: 12.994276
 >> iter 18000, loss: 13.007190
 >> iter 19000, loss: 12.985250
 >> iter 20000, loss: 12.996241
   Number of active neurons: 10
 >> iter 21000, loss: 12.987077
 >> iter 22000, loss: 12.995848
 >> iter 23000, loss: 12.976370
 >> iter 24000, loss: 12.949270
 >> iter 25000, loss: 12.287738
 >> iter 26000, loss: 11.626415
 >> iter 27000, loss: 11.174270
 >> iter 28000, loss: 10.968056
 >> iter 29000, loss: 10.727768
 >> iter 30000, loss: 10.571147
   Number of active neurons: 10
 >> iter 31000, loss: 10.307960
 >> iter 32000, loss: 10.014683
 >> iter 33000, loss: 9.267467
 >> iter 34000, loss: 7.327288
 >> iter 35000, loss: 3.570039
 >> iter 36000, loss: 2.014117
 >> iter 37000, loss: 1.465009
 >> iter 38000, loss: 0.857149
 >> iter 39000, loss: 0.800058
 >> iter 40000, loss: 0.667090
   Number of active neurons: 10
 >> iter 41000, loss: 0.679883
 >> iter 42000, loss: 0.664056
 >> iter 43000, loss: 0.677704
 >> iter 44000, loss: 0.378192
 >> iter 45000, loss: 0.473438
 >> iter 46000, loss: 0.545519
 >> iter 47000, loss: 0.314270
 >> iter 48000, loss: 0.171574
 >> iter 49000, loss: 0.221042
 >> iter 50000, loss: 0.185997
   Number of active neurons: 10
 >> iter 51000, loss: 0.331520
 >> iter 52000, loss: 0.559011
 >> iter 53000, loss: 0.425706
 >> iter 54000, loss: 0.439054
 >> iter 55000, loss: 0.322430
 >> iter 56000, loss: 0.201190
 >> iter 57000, loss: 0.208292
 >> iter 58000, loss: 0.288632
 >> iter 59000, loss: 0.148017
 >> iter 60000, loss: 0.083612
   Number of active neurons: 10
 >> iter 61000, loss: 0.176497
 >> iter 62000, loss: 0.257344
 >> iter 63000, loss: 0.151004
 >> iter 64000, loss: 0.210311
 >> iter 65000, loss: 0.373785
 >> iter 66000, loss: 0.177265
 >> iter 67000, loss: 0.079062
 >> iter 68000, loss: 0.139445
 >> iter 69000, loss: 0.129187
 >> iter 70000, loss: 0.070534
   Number of active neurons: 10
 >> iter 71000, loss: 0.061792
 >> iter 72000, loss: 0.109847
 >> iter 73000, loss: 0.102749
 >> iter 74000, loss: 0.141326
 >> iter 75000, loss: 0.304868
 >> iter 76000, loss: 0.124287
 >> iter 77000, loss: 0.125396
 >> iter 78000, loss: 0.057461
 >> iter 79000, loss: 0.029881
 >> iter 80000, loss: 0.018285
   Number of active neurons: 10
 >> iter 81000, loss: 0.021289
 >> iter 82000, loss: 0.053334
 >> iter 83000, loss: 0.030772
 >> iter 84000, loss: 0.077469
 >> iter 85000, loss: 0.140064
 >> iter 86000, loss: 0.188734
 >> iter 87000, loss: 0.151841
 >> iter 88000, loss: 0.101773
 >> iter 89000, loss: 0.045676
 >> iter 90000, loss: 0.028122
   Number of active neurons: 10
 >> iter 91000, loss: 0.077371
 >> iter 92000, loss: 0.054284
 >> iter 93000, loss: 0.026849
 >> iter 94000, loss: 0.043245
 >> iter 95000, loss: 0.023927
 >> iter 96000, loss: 0.068828
 >> iter 97000, loss: 0.031345
 >> iter 98000, loss: 0.094839
 >> iter 99000, loss: 0.057865
 >> iter 100000, loss: 0.028214
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.888082
 >> iter 2000, loss: 15.336510
 >> iter 3000, loss: 13.930926
 >> iter 4000, loss: 13.377245
 >> iter 5000, loss: 13.162200
 >> iter 6000, loss: 13.084103
 >> iter 7000, loss: 13.035147
 >> iter 8000, loss: 13.020211
 >> iter 9000, loss: 13.009415
 >> iter 10000, loss: 13.008904
   Number of active neurons: 9
 >> iter 11000, loss: 12.991779
 >> iter 12000, loss: 13.003871
 >> iter 13000, loss: 12.995531
 >> iter 14000, loss: 13.005315
 >> iter 15000, loss: 13.000679
 >> iter 16000, loss: 13.001351
 >> iter 17000, loss: 12.988161
 >> iter 18000, loss: 12.995427
 >> iter 19000, loss: 12.983239
 >> iter 20000, loss: 12.982729
   Number of active neurons: 9
 >> iter 21000, loss: 12.971508
 >> iter 22000, loss: 12.868722
 >> iter 23000, loss: 12.094310
 >> iter 24000, loss: 11.534762
 >> iter 25000, loss: 11.136401
 >> iter 26000, loss: 10.994620
 >> iter 27000, loss: 10.823071
 >> iter 28000, loss: 10.824478
 >> iter 29000, loss: 10.707994
 >> iter 30000, loss: 10.637883
   Number of active neurons: 10
 >> iter 31000, loss: 10.283265
 >> iter 32000, loss: 10.006974
 >> iter 33000, loss: 9.696804
 >> iter 34000, loss: 9.610028
 >> iter 35000, loss: 9.464219
 >> iter 36000, loss: 7.971763
 >> iter 37000, loss: 6.579725
 >> iter 38000, loss: 5.532473
 >> iter 39000, loss: 5.392968
 >> iter 40000, loss: 3.175681
   Number of active neurons: 10
 >> iter 41000, loss: 1.779035
 >> iter 42000, loss: 1.154351
 >> iter 43000, loss: 0.829943
 >> iter 44000, loss: 0.506363
 >> iter 45000, loss: 0.515565
 >> iter 46000, loss: 0.570076
 >> iter 47000, loss: 0.412555
 >> iter 48000, loss: 0.540994
 >> iter 49000, loss: 0.489413
 >> iter 50000, loss: 0.274498
   Number of active neurons: 10
 >> iter 51000, loss: 0.413970
 >> iter 52000, loss: 0.393242
 >> iter 53000, loss: 0.539830
 >> iter 54000, loss: 0.381045
 >> iter 55000, loss: 0.308784
 >> iter 56000, loss: 0.156047
 >> iter 57000, loss: 0.325404
 >> iter 58000, loss: 0.235729
 >> iter 59000, loss: 0.163870
 >> iter 60000, loss: 0.152099
   Number of active neurons: 10
 >> iter 61000, loss: 0.286994
 >> iter 62000, loss: 0.286540
 >> iter 63000, loss: 0.566815
 >> iter 64000, loss: 0.317224
 >> iter 65000, loss: 0.341063
 >> iter 66000, loss: 0.262472
 >> iter 67000, loss: 0.259156
 >> iter 68000, loss: 0.117083
 >> iter 69000, loss: 0.143167
 >> iter 70000, loss: 0.084585
   Number of active neurons: 10
 >> iter 71000, loss: 0.136787
 >> iter 72000, loss: 0.151854
 >> iter 73000, loss: 0.179197
 >> iter 74000, loss: 0.134203
 >> iter 75000, loss: 0.183918
 >> iter 76000, loss: 0.147249
 >> iter 77000, loss: 0.271853
 >> iter 78000, loss: 0.274119
 >> iter 79000, loss: 0.278038
 >> iter 80000, loss: 0.299017
   Number of active neurons: 10
 >> iter 81000, loss: 0.229535
 >> iter 82000, loss: 0.105726
 >> iter 83000, loss: 0.183688
 >> iter 84000, loss: 0.084098
 >> iter 85000, loss: 0.058078
 >> iter 86000, loss: 0.071957
 >> iter 87000, loss: 0.103688
 >> iter 88000, loss: 0.058506
 >> iter 89000, loss: 0.031516
 >> iter 90000, loss: 0.020720
   Number of active neurons: 10
 >> iter 91000, loss: 0.016827
 >> iter 92000, loss: 0.085704
 >> iter 93000, loss: 0.100990
 >> iter 94000, loss: 0.046496
 >> iter 95000, loss: 0.024650
 >> iter 96000, loss: 0.032649
 >> iter 97000, loss: 0.144173
 >> iter 98000, loss: 0.145923
 >> iter 99000, loss: 0.239025
 >> iter 100000, loss: 0.221024
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0049999500005
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.875906
 >> iter 2000, loss: 15.391942
 >> iter 3000, loss: 13.974924
 >> iter 4000, loss: 13.434821
 >> iter 5000, loss: 13.219685
 >> iter 6000, loss: 13.135174
 >> iter 7000, loss: 13.082086
 >> iter 8000, loss: 13.067743
 >> iter 9000, loss: 13.044033
 >> iter 10000, loss: 13.054163
   Number of active neurons: 10
 >> iter 11000, loss: 13.036458
 >> iter 12000, loss: 13.037395
 >> iter 13000, loss: 13.014826
 >> iter 14000, loss: 13.025095
 >> iter 15000, loss: 13.013063
 >> iter 16000, loss: 13.021804
 >> iter 17000, loss: 13.015476
 >> iter 18000, loss: 13.019886
 >> iter 19000, loss: 13.011956
 >> iter 20000, loss: 13.022862
   Number of active neurons: 10
 >> iter 21000, loss: 13.008816
 >> iter 22000, loss: 13.017158
 >> iter 23000, loss: 13.004566
 >> iter 24000, loss: 13.020134
 >> iter 25000, loss: 13.002058
 >> iter 26000, loss: 13.019395
 >> iter 27000, loss: 13.006904
 >> iter 28000, loss: 13.017111
 >> iter 29000, loss: 13.005109
 >> iter 30000, loss: 13.013818
   Number of active neurons: 10
 >> iter 31000, loss: 13.009040
 >> iter 32000, loss: 13.015165
 >> iter 33000, loss: 13.011076
 >> iter 34000, loss: 13.011564
 >> iter 35000, loss: 12.998053
 >> iter 36000, loss: 13.011913
 >> iter 37000, loss: 13.007220
 >> iter 38000, loss: 13.006905
 >> iter 39000, loss: 12.982172
 >> iter 40000, loss: 12.585658
   Number of active neurons: 10
 >> iter 41000, loss: 11.747337
 >> iter 42000, loss: 11.257505
 >> iter 43000, loss: 10.950596
 >> iter 44000, loss: 10.827493
 >> iter 45000, loss: 10.645266
 >> iter 46000, loss: 10.531736
 >> iter 47000, loss: 10.371280
 >> iter 48000, loss: 10.280251
 >> iter 49000, loss: 10.054042
 >> iter 50000, loss: 9.955201
   Number of active neurons: 10
 >> iter 51000, loss: 9.692128
 >> iter 52000, loss: 9.500530
 >> iter 53000, loss: 9.280204
 >> iter 54000, loss: 9.205940
 >> iter 55000, loss: 9.106683
 >> iter 56000, loss: 9.044851
 >> iter 57000, loss: 8.828389
 >> iter 58000, loss: 8.776529
 >> iter 59000, loss: 8.640525
 >> iter 60000, loss: 8.612254
   Number of active neurons: 10
 >> iter 61000, loss: 8.403789
 >> iter 62000, loss: 8.379683
 >> iter 63000, loss: 7.357609
 >> iter 64000, loss: 7.307643
 >> iter 65000, loss: 6.605739
 >> iter 66000, loss: 6.645662
 >> iter 67000, loss: 6.343194
 >> iter 68000, loss: 6.470564
 >> iter 69000, loss: 6.232276
 >> iter 70000, loss: 6.122612
   Number of active neurons: 10
 >> iter 71000, loss: 5.769278
 >> iter 72000, loss: 5.803094
 >> iter 73000, loss: 5.519880
 >> iter 74000, loss: 5.588869
 >> iter 75000, loss: 5.246980
 >> iter 76000, loss: 5.682070
 >> iter 77000, loss: 5.253753
 >> iter 78000, loss: 5.477604
 >> iter 79000, loss: 5.117358
 >> iter 80000, loss: 5.094339
   Number of active neurons: 10
 >> iter 81000, loss: 4.967722
 >> iter 82000, loss: 5.532754
 >> iter 83000, loss: 5.524755
 >> iter 84000, loss: 5.816772
 >> iter 85000, loss: 5.744142
 >> iter 86000, loss: 5.561382
 >> iter 87000, loss: 5.189996
 >> iter 88000, loss: 5.462127
 >> iter 89000, loss: 5.174257
 >> iter 90000, loss: 5.440158
   Number of active neurons: 10
 >> iter 91000, loss: 5.189786
 >> iter 92000, loss: 5.902493
 >> iter 93000, loss: 5.352794
 >> iter 94000, loss: 5.932467
 >> iter 95000, loss: 6.094307
 >> iter 96000, loss: 6.051782
 >> iter 97000, loss: 5.973162
 >> iter 98000, loss: 5.879798
 >> iter 99000, loss: 5.969454
 >> iter 100000, loss: 6.146128
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 6.84386312274
   - Test - Long: 27.4586270686
   - Test - Big: 6.9959300407
   - Test - A: 0.533297780148
   - Test - B: 4.93967068862
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.914490
 >> iter 2000, loss: 15.401952
 >> iter 3000, loss: 13.971839
 >> iter 4000, loss: 13.412003
 >> iter 5000, loss: 13.188601
 >> iter 6000, loss: 13.103366
 >> iter 7000, loss: 13.049556
 >> iter 8000, loss: 13.039639
 >> iter 9000, loss: 13.027612
 >> iter 10000, loss: 13.024208
   Number of active neurons: 9
 >> iter 11000, loss: 13.006651
 >> iter 12000, loss: 13.017772
 >> iter 13000, loss: 12.996047
 >> iter 14000, loss: 12.999378
 >> iter 15000, loss: 12.983445
 >> iter 16000, loss: 12.991785
 >> iter 17000, loss: 12.978567
 >> iter 18000, loss: 12.990403
 >> iter 19000, loss: 12.982003
 >> iter 20000, loss: 12.991717
   Number of active neurons: 8
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 8
 >> iter 21000, loss: 12.975954
 >> iter 22000, loss: 12.974999
 >> iter 23000, loss: 12.961966
 >> iter 24000, loss: 12.952887
 >> iter 25000, loss: 12.893062
 >> iter 26000, loss: 12.536358
 >> iter 27000, loss: 11.719422
 >> iter 28000, loss: 10.963423
 >> iter 29000, loss: 10.174590
 >> iter 30000, loss: 9.556474
   Number of active neurons: 10
 >> iter 31000, loss: 9.189733
 >> iter 32000, loss: 8.826737
 >> iter 33000, loss: 8.661431
 >> iter 34000, loss: 8.429225
 >> iter 35000, loss: 8.138878
 >> iter 36000, loss: 7.890365
 >> iter 37000, loss: 7.796086
 >> iter 38000, loss: 7.471152
 >> iter 39000, loss: 7.314526
 >> iter 40000, loss: 7.287999
   Number of active neurons: 10
 >> iter 41000, loss: 7.157626
 >> iter 42000, loss: 7.142808
 >> iter 43000, loss: 7.031228
 >> iter 44000, loss: 7.035954
 >> iter 45000, loss: 6.974266
 >> iter 46000, loss: 6.923188
 >> iter 47000, loss: 6.898544
 >> iter 48000, loss: 6.867791
 >> iter 49000, loss: 6.878718
 >> iter 50000, loss: 6.890749
   Number of active neurons: 10
 >> iter 51000, loss: 6.824301
 >> iter 52000, loss: 6.769166
 >> iter 53000, loss: 6.732501
 >> iter 54000, loss: 6.793728
 >> iter 55000, loss: 6.669479
 >> iter 56000, loss: 6.700783
 >> iter 57000, loss: 6.563527
 >> iter 58000, loss: 6.676680
 >> iter 59000, loss: 6.617229
 >> iter 60000, loss: 6.615463
   Number of active neurons: 10
 >> iter 61000, loss: 6.540186
 >> iter 62000, loss: 6.550984
 >> iter 63000, loss: 6.487046
 >> iter 64000, loss: 6.536482
 >> iter 65000, loss: 6.500807
 >> iter 66000, loss: 6.707622
 >> iter 67000, loss: 6.592423
 >> iter 68000, loss: 6.589705
 >> iter 69000, loss: 6.425233
 >> iter 70000, loss: 6.487236
   Number of active neurons: 10
 >> iter 71000, loss: 6.340660
 >> iter 72000, loss: 6.503962
 >> iter 73000, loss: 6.324597
 >> iter 74000, loss: 6.383989
 >> iter 75000, loss: 6.433960
 >> iter 76000, loss: 6.442541
 >> iter 77000, loss: 6.256214
 >> iter 78000, loss: 6.419180
 >> iter 79000, loss: 6.388288
 >> iter 80000, loss: 6.318231
   Number of active neurons: 10
 >> iter 81000, loss: 6.353038
 >> iter 82000, loss: 6.822131
 >> iter 83000, loss: 6.665945
 >> iter 84000, loss: 6.837589
 >> iter 85000, loss: 6.803921
 >> iter 86000, loss: 6.640969
 >> iter 87000, loss: 6.418789
 >> iter 88000, loss: 6.465660
 >> iter 89000, loss: 6.358428
 >> iter 90000, loss: 6.357943
   Number of active neurons: 10
 >> iter 91000, loss: 6.366334
 >> iter 92000, loss: 6.387892
 >> iter 93000, loss: 6.306435
 >> iter 94000, loss: 6.607514
 >> iter 95000, loss: 6.489290
 >> iter 96000, loss: 6.262315
 >> iter 97000, loss: 6.348221
 >> iter 98000, loss: 6.330459
 >> iter 99000, loss: 6.329950
 >> iter 100000, loss: 6.240212
   Number of active neurons: 10
 >> iter 101000, loss: 6.183794
 >> iter 102000, loss: 6.262261
 >> iter 103000, loss: 6.185665
 >> iter 104000, loss: 5.951675
 >> iter 105000, loss: 6.039961
 >> iter 106000, loss: 6.066997
 >> iter 107000, loss: 5.926686
 >> iter 108000, loss: 5.925800
 >> iter 109000, loss: 5.913225
 >> iter 110000, loss: 6.007748
   Number of active neurons: 10
 >> iter 111000, loss: 5.980314
 >> iter 112000, loss: 6.172722
 >> iter 113000, loss: 6.019053
 >> iter 114000, loss: 6.073522
 >> iter 115000, loss: 6.081601
 >> iter 116000, loss: 6.193216
 >> iter 117000, loss: 6.258443
 >> iter 118000, loss: 6.046264
 >> iter 119000, loss: 6.092981
 >> iter 120000, loss: 6.044007
   Number of active neurons: 10
 >> iter 121000, loss: 6.014126
 >> iter 122000, loss: 6.025497
 >> iter 123000, loss: 5.927465
 >> iter 124000, loss: 6.013255
 >> iter 125000, loss: 5.889045
 >> iter 126000, loss: 6.185505
 >> iter 127000, loss: 6.118737
 >> iter 128000, loss: 6.162390
 >> iter 129000, loss: 6.046865
 >> iter 130000, loss: 5.876646
   Number of active neurons: 10
 >> iter 131000, loss: 5.842063
 >> iter 132000, loss: 5.921561
 >> iter 133000, loss: 5.793200
 >> iter 134000, loss: 5.926369
 >> iter 135000, loss: 5.860218
 >> iter 136000, loss: 6.099383
 >> iter 137000, loss: 5.950504
 >> iter 138000, loss: 6.041039
 >> iter 139000, loss: 5.925135
 >> iter 140000, loss: 6.100642
   Number of active neurons: 10
 >> iter 141000, loss: 6.014388
 >> iter 142000, loss: 6.107577
 >> iter 143000, loss: 6.076581
 >> iter 144000, loss: 6.111988
 >> iter 145000, loss: 5.976686
 >> iter 146000, loss: 6.114363
 >> iter 147000, loss: 6.068464
 >> iter 148000, loss: 6.343966
 >> iter 149000, loss: 6.104002
 >> iter 150000, loss: 6.094223
   Number of active neurons: 10
 >> iter 151000, loss: 6.030982
 >> iter 152000, loss: 6.024680
 >> iter 153000, loss: 6.156673
 >> iter 154000, loss: 6.172422
 >> iter 155000, loss: 6.065071
 >> iter 156000, loss: 5.988325
 >> iter 157000, loss: 6.099256
 >> iter 158000, loss: 6.147620
 >> iter 159000, loss: 6.133636
 >> iter 160000, loss: 6.058594
   Number of active neurons: 10
 >> iter 161000, loss: 5.907622
 >> iter 162000, loss: 6.115322
 >> iter 163000, loss: 6.127748
 >> iter 164000, loss: 6.168155
 >> iter 165000, loss: 6.026235
 >> iter 166000, loss: 5.937220
 >> iter 167000, loss: 5.861417
 >> iter 168000, loss: 5.953419
 >> iter 169000, loss: 6.046072
 >> iter 170000, loss: 6.111713
   Number of active neurons: 10
 >> iter 171000, loss: 6.087358
 >> iter 172000, loss: 6.171532
 >> iter 173000, loss: 6.044390
 >> iter 174000, loss: 6.063033
 >> iter 175000, loss: 6.052611
 >> iter 176000, loss: 5.967476
 >> iter 177000, loss: 6.031311
 >> iter 178000, loss: 5.908718
 >> iter 179000, loss: 6.018745
 >> iter 180000, loss: 5.945129
   Number of active neurons: 10
 >> iter 181000, loss: 5.978288
 >> iter 182000, loss: 5.955960
 >> iter 183000, loss: 5.777935
 >> iter 184000, loss: 6.041214
 >> iter 185000, loss: 5.801166
 >> iter 186000, loss: 5.901071
 >> iter 187000, loss: 5.960279
 >> iter 188000, loss: 5.988072
 >> iter 189000, loss: 5.790139
 >> iter 190000, loss: 5.792035
   Number of active neurons: 10
 >> iter 191000, loss: 5.822182
 >> iter 192000, loss: 5.898406
 >> iter 193000, loss: 5.767159
 >> iter 194000, loss: 5.994108
 >> iter 195000, loss: 5.809271
 >> iter 196000, loss: 5.746177
 >> iter 197000, loss: 5.760960
 >> iter 198000, loss: 5.827066
 >> iter 199000, loss: 5.677120
 >> iter 200000, loss: 5.740438
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 8.79782404352
   - Test - Long: 28.5785710714
   - Test - Big: 8.61691383086
   - Test - A: 0.479968002133
   - Test - B: 30.6579561363
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.931152
 >> iter 2000, loss: 15.358195
 >> iter 3000, loss: 13.933397
 >> iter 4000, loss: 13.398471
 >> iter 5000, loss: 13.201003
 >> iter 6000, loss: 13.129953
 >> iter 7000, loss: 13.081023
 >> iter 8000, loss: 13.066990
 >> iter 9000, loss: 13.054515
 >> iter 10000, loss: 13.062328
   Number of active neurons: 10
 >> iter 11000, loss: 13.047692
 >> iter 12000, loss: 13.046234
 >> iter 13000, loss: 13.038519
 >> iter 14000, loss: 13.051184
 >> iter 15000, loss: 13.044799
 >> iter 16000, loss: 13.048464
 >> iter 17000, loss: 13.040351
 >> iter 18000, loss: 13.041622
 >> iter 19000, loss: 13.030304
 >> iter 20000, loss: 13.036764
   Number of active neurons: 10
 >> iter 21000, loss: 13.019026
 >> iter 22000, loss: 13.026478
 >> iter 23000, loss: 13.019846
 >> iter 24000, loss: 13.031889
 >> iter 25000, loss: 13.013212
 >> iter 26000, loss: 13.021811
 >> iter 27000, loss: 13.011684
 >> iter 28000, loss: 13.025568
 >> iter 29000, loss: 13.016045
 >> iter 30000, loss: 13.025202
   Number of active neurons: 10
 >> iter 31000, loss: 13.009938
 >> iter 32000, loss: 13.022918
 >> iter 33000, loss: 13.014368
 >> iter 34000, loss: 13.010337
 >> iter 35000, loss: 12.998206
 >> iter 36000, loss: 12.830126
 >> iter 37000, loss: 11.952775
 >> iter 38000, loss: 11.459061
 >> iter 39000, loss: 11.049207
 >> iter 40000, loss: 10.954679
   Number of active neurons: 10
 >> iter 41000, loss: 10.743983
 >> iter 42000, loss: 10.698458
 >> iter 43000, loss: 10.545146
 >> iter 44000, loss: 10.481686
 >> iter 45000, loss: 10.263171
 >> iter 46000, loss: 9.959002
 >> iter 47000, loss: 9.337511
 >> iter 48000, loss: 8.966827
 >> iter 49000, loss: 8.520513
 >> iter 50000, loss: 8.442055
   Number of active neurons: 10
 >> iter 51000, loss: 7.331085
 >> iter 52000, loss: 6.524357
 >> iter 53000, loss: 5.991976
 >> iter 54000, loss: 5.604765
 >> iter 55000, loss: 5.321532
 >> iter 56000, loss: 5.712800
 >> iter 57000, loss: 5.326053
 >> iter 58000, loss: 5.053157
 >> iter 59000, loss: 3.689314
 >> iter 60000, loss: 2.640655
   Number of active neurons: 10
 >> iter 61000, loss: 1.804868
 >> iter 62000, loss: 1.299612
 >> iter 63000, loss: 1.186893
 >> iter 64000, loss: 0.925573
 >> iter 65000, loss: 0.966320
 >> iter 66000, loss: 0.864943
 >> iter 67000, loss: 1.221225
 >> iter 68000, loss: 0.823018
 >> iter 69000, loss: 0.573520
 >> iter 70000, loss: 0.331974
   Number of active neurons: 10
 >> iter 71000, loss: 0.403735
 >> iter 72000, loss: 0.239130
 >> iter 73000, loss: 0.284779
 >> iter 74000, loss: 0.499738
 >> iter 75000, loss: 0.501723
 >> iter 76000, loss: 0.449026
 >> iter 77000, loss: 0.341027
 >> iter 78000, loss: 0.635188
 >> iter 79000, loss: 0.994591
 >> iter 80000, loss: 0.882790
   Number of active neurons: 10
 >> iter 81000, loss: 0.621688
 >> iter 82000, loss: 0.294909
 >> iter 83000, loss: 0.232377
 >> iter 84000, loss: 0.138816
 >> iter 85000, loss: 0.224182
 >> iter 86000, loss: 0.229512
 >> iter 87000, loss: 0.395856
 >> iter 88000, loss: 0.227227
 >> iter 89000, loss: 0.203883
 >> iter 90000, loss: 0.154168
   Number of active neurons: 10
 >> iter 91000, loss: 0.162151
 >> iter 92000, loss: 0.077924
 >> iter 93000, loss: 0.142978
 >> iter 94000, loss: 0.091235
 >> iter 95000, loss: 0.046171
 >> iter 96000, loss: 0.038832
 >> iter 97000, loss: 0.040283
 >> iter 98000, loss: 0.114585
 >> iter 99000, loss: 0.135506
 >> iter 100000, loss: 0.098439
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.922830
 >> iter 2000, loss: 15.359881
 >> iter 3000, loss: 13.928313
 >> iter 4000, loss: 13.394874
 >> iter 5000, loss: 13.179472
 >> iter 6000, loss: 13.091084
 >> iter 7000, loss: 13.048955
 >> iter 8000, loss: 13.032215
 >> iter 9000, loss: 13.019954
 >> iter 10000, loss: 13.035307
   Number of active neurons: 10
 >> iter 11000, loss: 13.026198
 >> iter 12000, loss: 13.030073
 >> iter 13000, loss: 13.014757
 >> iter 14000, loss: 13.021161
 >> iter 15000, loss: 13.021353
 >> iter 16000, loss: 13.026144
 >> iter 17000, loss: 13.017848
 >> iter 18000, loss: 13.012703
 >> iter 19000, loss: 13.011365
 >> iter 20000, loss: 13.016857
   Number of active neurons: 10
 >> iter 21000, loss: 12.990716
 >> iter 22000, loss: 12.996920
 >> iter 23000, loss: 12.991422
 >> iter 24000, loss: 13.010239
 >> iter 25000, loss: 12.993671
 >> iter 26000, loss: 13.004129
 >> iter 27000, loss: 12.996013
 >> iter 28000, loss: 12.993952
 >> iter 29000, loss: 12.991390
 >> iter 30000, loss: 13.003131
   Number of active neurons: 10
 >> iter 31000, loss: 12.987161
 >> iter 32000, loss: 12.991129
 >> iter 33000, loss: 12.984875
 >> iter 34000, loss: 12.996306
 >> iter 35000, loss: 12.988916
 >> iter 36000, loss: 12.993275
 >> iter 37000, loss: 12.986526
 >> iter 38000, loss: 12.999653
 >> iter 39000, loss: 12.982368
 >> iter 40000, loss: 12.992650
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 41000, loss: 12.835533
 >> iter 42000, loss: 12.072601
 >> iter 43000, loss: 11.397694
 >> iter 44000, loss: 11.100317
 >> iter 45000, loss: 10.763560
 >> iter 46000, loss: 10.633566
 >> iter 47000, loss: 10.450319
 >> iter 48000, loss: 10.314437
 >> iter 49000, loss: 10.031937
 >> iter 50000, loss: 9.719152
   Number of active neurons: 10
 >> iter 51000, loss: 9.258527
 >> iter 52000, loss: 8.565488
 >> iter 53000, loss: 7.200766
 >> iter 54000, loss: 6.621092
 >> iter 55000, loss: 6.361629
 >> iter 56000, loss: 6.131810
 >> iter 57000, loss: 6.161606
 >> iter 58000, loss: 6.025314
 >> iter 59000, loss: 6.002987
 >> iter 60000, loss: 6.106031
   Number of active neurons: 10
 >> iter 61000, loss: 5.976384
 >> iter 62000, loss: 6.177577
 >> iter 63000, loss: 6.125112
 >> iter 64000, loss: 6.115026
 >> iter 65000, loss: 6.124244
 >> iter 66000, loss: 5.252862
 >> iter 67000, loss: 4.451459
 >> iter 68000, loss: 3.221791
 >> iter 69000, loss: 2.008621
 >> iter 70000, loss: 1.851730
   Number of active neurons: 10
 >> iter 71000, loss: 1.123545
 >> iter 72000, loss: 0.983090
 >> iter 73000, loss: 0.950369
 >> iter 74000, loss: 1.005776
 >> iter 75000, loss: 0.727200
 >> iter 76000, loss: 0.535780
 >> iter 77000, loss: 0.353361
 >> iter 78000, loss: 0.403927
 >> iter 79000, loss: 0.255084
 >> iter 80000, loss: 0.840380
   Number of active neurons: 10
 >> iter 81000, loss: 0.541251
 >> iter 82000, loss: 0.408215
 >> iter 83000, loss: 0.191963
 >> iter 84000, loss: 0.228515
 >> iter 85000, loss: 0.153913
 >> iter 86000, loss: 0.132900
 >> iter 87000, loss: 0.105223
 >> iter 88000, loss: 0.146347
 >> iter 89000, loss: 0.293120
 >> iter 90000, loss: 0.182456
   Number of active neurons: 10
 >> iter 91000, loss: 0.182937
 >> iter 92000, loss: 0.136663
 >> iter 93000, loss: 0.198934
 >> iter 94000, loss: 0.254943
 >> iter 95000, loss: 0.304497
 >> iter 96000, loss: 0.240640
 >> iter 97000, loss: 0.137954
 >> iter 98000, loss: 0.066922
 >> iter 99000, loss: 0.085090
 >> iter 100000, loss: 0.063549
   Number of active neurons: 10
 >> iter 101000, loss: 0.116031
 >> iter 102000, loss: 0.118278
 >> iter 103000, loss: 0.164383
 >> iter 104000, loss: 0.156883
 >> iter 105000, loss: 0.116671
 >> iter 106000, loss: 0.100335
 >> iter 107000, loss: 0.048093
 >> iter 108000, loss: 0.074514
 >> iter 109000, loss: 0.090180
 >> iter 110000, loss: 0.043020
   Number of active neurons: 10
 >> iter 111000, loss: 0.159246
 >> iter 112000, loss: 0.117734
 >> iter 113000, loss: 0.059546
 >> iter 114000, loss: 0.070233
 >> iter 115000, loss: 0.193168
 >> iter 116000, loss: 0.220626
 >> iter 117000, loss: 0.126291
 >> iter 118000, loss: 0.055956
 >> iter 119000, loss: 0.162256
 >> iter 120000, loss: 0.211798
   Number of active neurons: 10
 >> iter 121000, loss: 0.136242
 >> iter 122000, loss: 0.064181
 >> iter 123000, loss: 0.074557
 >> iter 124000, loss: 0.189760
 >> iter 125000, loss: 0.079976
 >> iter 126000, loss: 0.106324
 >> iter 127000, loss: 0.057082
 >> iter 128000, loss: 0.148772
 >> iter 129000, loss: 0.073210
 >> iter 130000, loss: 0.034466
   Number of active neurons: 10
 >> iter 131000, loss: 0.020593
 >> iter 132000, loss: 0.117807
 >> iter 133000, loss: 0.123961
 >> iter 134000, loss: 0.052490
 >> iter 135000, loss: 0.026663
 >> iter 136000, loss: 0.016148
 >> iter 137000, loss: 0.031130
 >> iter 138000, loss: 0.080732
 >> iter 139000, loss: 0.100808
 >> iter 140000, loss: 0.045853
   Number of active neurons: 10
 >> iter 141000, loss: 0.026326
 >> iter 142000, loss: 0.101510
 >> iter 143000, loss: 0.129509
 >> iter 144000, loss: 0.148198
 >> iter 145000, loss: 0.075681
 >> iter 146000, loss: 0.042976
 >> iter 147000, loss: 0.024496
 >> iter 148000, loss: 0.198182
 >> iter 149000, loss: 0.129085
 >> iter 150000, loss: 0.339851
   Number of active neurons: 10
 >> iter 151000, loss: 0.159289
 >> iter 152000, loss: 0.160380
 >> iter 153000, loss: 0.169564
 >> iter 154000, loss: 0.075408
 >> iter 155000, loss: 0.064921
 >> iter 156000, loss: 0.214122
 >> iter 157000, loss: 0.136330
 >> iter 158000, loss: 0.199308
 >> iter 159000, loss: 0.083985
 >> iter 160000, loss: 0.170056
   Number of active neurons: 10
 >> iter 161000, loss: 0.081516
 >> iter 162000, loss: 0.086871
 >> iter 163000, loss: 0.044459
 >> iter 164000, loss: 0.131965
 >> iter 165000, loss: 0.059004
 >> iter 166000, loss: 0.121774
 >> iter 167000, loss: 0.055055
 >> iter 168000, loss: 0.058310
 >> iter 169000, loss: 0.084222
 >> iter 170000, loss: 0.275987
   Number of active neurons: 10
 >> iter 171000, loss: 0.179269
 >> iter 172000, loss: 0.098466
 >> iter 173000, loss: 0.061849
 >> iter 174000, loss: 0.133192
 >> iter 175000, loss: 0.058221
 >> iter 176000, loss: 0.084804
 >> iter 177000, loss: 0.044314
 >> iter 178000, loss: 0.052176
 >> iter 179000, loss: 0.026886
 >> iter 180000, loss: 0.091128
   Number of active neurons: 10
 >> iter 181000, loss: 0.039654
 >> iter 182000, loss: 0.066625
 >> iter 183000, loss: 0.029922
 >> iter 184000, loss: 0.016559
 >> iter 185000, loss: 0.010811
 >> iter 186000, loss: 0.007957
 >> iter 187000, loss: 0.054114
 >> iter 188000, loss: 0.119256
 >> iter 189000, loss: 0.132234
 >> iter 190000, loss: 0.085621
   Number of active neurons: 10
 >> iter 191000, loss: 0.145769
 >> iter 192000, loss: 0.063338
 >> iter 193000, loss: 0.086223
 >> iter 194000, loss: 0.085261
 >> iter 195000, loss: 0.037006
 >> iter 196000, loss: 0.018062
 >> iter 197000, loss: 0.013668
 >> iter 198000, loss: 0.059376
 >> iter 199000, loss: 0.026028
 >> iter 200000, loss: 0.018342
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.867984
 >> iter 2000, loss: 15.343706
 >> iter 3000, loss: 13.920176
 >> iter 4000, loss: 13.389854
 >> iter 5000, loss: 13.176945
 >> iter 6000, loss: 13.093901
 >> iter 7000, loss: 13.055654
 >> iter 8000, loss: 13.050357
 >> iter 9000, loss: 13.018078
 >> iter 10000, loss: 13.026488
   Number of active neurons: 10
 >> iter 11000, loss: 13.006692
 >> iter 12000, loss: 13.014900
 >> iter 13000, loss: 13.000474
 >> iter 14000, loss: 13.006736
 >> iter 15000, loss: 13.000733
 >> iter 16000, loss: 13.005360
 >> iter 17000, loss: 12.996024
 >> iter 18000, loss: 12.989864
 >> iter 19000, loss: 12.963154
 >> iter 20000, loss: 12.745461
   Number of active neurons: 10
 >> iter 21000, loss: 11.907011
 >> iter 22000, loss: 11.424757
 >> iter 23000, loss: 11.051470
 >> iter 24000, loss: 10.872572
 >> iter 25000, loss: 10.601185
 >> iter 26000, loss: 10.345423
 >> iter 27000, loss: 9.919320
 >> iter 28000, loss: 9.625709
 >> iter 29000, loss: 9.254852
 >> iter 30000, loss: 8.991474
   Number of active neurons: 10
 >> iter 31000, loss: 8.709607
 >> iter 32000, loss: 8.605428
 >> iter 33000, loss: 8.415779
 >> iter 34000, loss: 8.391439
 >> iter 35000, loss: 8.283852
 >> iter 36000, loss: 8.273908
 >> iter 37000, loss: 8.233206
 >> iter 38000, loss: 8.066123
 >> iter 39000, loss: 7.738215
 >> iter 40000, loss: 7.616978
   Number of active neurons: 10
 >> iter 41000, loss: 7.419330
 >> iter 42000, loss: 7.481463
 >> iter 43000, loss: 7.388197
 >> iter 44000, loss: 7.454662
 >> iter 45000, loss: 7.411315
 >> iter 46000, loss: 7.427074
 >> iter 47000, loss: 7.398003
 >> iter 48000, loss: 7.534437
 >> iter 49000, loss: 7.396004
 >> iter 50000, loss: 7.398486
   Number of active neurons: 10
 >> iter 51000, loss: 7.320362
 >> iter 52000, loss: 7.364841
 >> iter 53000, loss: 7.306609
 >> iter 54000, loss: 7.331866
 >> iter 55000, loss: 7.282750
 >> iter 56000, loss: 7.382130
 >> iter 57000, loss: 7.308576
 >> iter 58000, loss: 7.424451
 >> iter 59000, loss: 7.207622
 >> iter 60000, loss: 7.318298
   Number of active neurons: 10
 >> iter 61000, loss: 7.336428
 >> iter 62000, loss: 7.314513
 >> iter 63000, loss: 7.170621
 >> iter 64000, loss: 7.193506
 >> iter 65000, loss: 6.996674
 >> iter 66000, loss: 6.994966
 >> iter 67000, loss: 6.880222
 >> iter 68000, loss: 6.992490
 >> iter 69000, loss: 6.770552
 >> iter 70000, loss: 6.808098
   Number of active neurons: 10
 >> iter 71000, loss: 6.820966
 >> iter 72000, loss: 6.878497
 >> iter 73000, loss: 6.792482
 >> iter 74000, loss: 6.809625
 >> iter 75000, loss: 6.694346
 >> iter 76000, loss: 6.819496
 >> iter 77000, loss: 6.727041
 >> iter 78000, loss: 6.821319
 >> iter 79000, loss: 6.679182
 >> iter 80000, loss: 6.786403
   Number of active neurons: 10
 >> iter 81000, loss: 6.676680
 >> iter 82000, loss: 6.711665
 >> iter 83000, loss: 6.653008
 >> iter 84000, loss: 6.765112
 >> iter 85000, loss: 6.839951
 >> iter 86000, loss: 7.248571
 >> iter 87000, loss: 6.796351
 >> iter 88000, loss: 6.544202
 >> iter 89000, loss: 5.932540
 >> iter 90000, loss: 5.491007
   Number of active neurons: 10
 >> iter 91000, loss: 4.856229
 >> iter 92000, loss: 4.752749
 >> iter 93000, loss: 4.514615
 >> iter 94000, loss: 4.447821
 >> iter 95000, loss: 4.477698
 >> iter 96000, loss: 4.649281
 >> iter 97000, loss: 4.534061
 >> iter 98000, loss: 4.400850
 >> iter 99000, loss: 4.274902
 >> iter 100000, loss: 4.398633
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 8.14183716326
   - Test - Long: 27.8686065697
   - Test - Big: 8.0339196608
   - Test - A: 8.43943737084
   - Test - B: 3.85307646157
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.884661
 >> iter 2000, loss: 15.325100
 >> iter 3000, loss: 13.914696
 >> iter 4000, loss: 13.370886
 >> iter 5000, loss: 13.150617
 >> iter 6000, loss: 13.079826
 >> iter 7000, loss: 13.024465
 >> iter 8000, loss: 13.024224
 >> iter 9000, loss: 13.013020
 >> iter 10000, loss: 13.017672
   Number of active neurons: 9
 >> iter 11000, loss: 13.007657
 >> iter 12000, loss: 13.000184
 >> iter 13000, loss: 12.994572
 >> iter 14000, loss: 13.002910
 >> iter 15000, loss: 12.999421
 >> iter 16000, loss: 13.006953
 >> iter 17000, loss: 13.000391
 >> iter 18000, loss: 13.004390
 >> iter 19000, loss: 12.989140
 >> iter 20000, loss: 12.990941
   Number of active neurons: 9
 >> iter 21000, loss: 12.984158
 >> iter 22000, loss: 12.994613
 >> iter 23000, loss: 12.987143
 >> iter 24000, loss: 12.996325
 >> iter 25000, loss: 12.983149
 >> iter 26000, loss: 12.990979
 >> iter 27000, loss: 12.976437
 >> iter 28000, loss: 12.964248
 >> iter 29000, loss: 12.811286
 >> iter 30000, loss: 12.175429
   Number of active neurons: 10
 >> iter 31000, loss: 11.484959
 >> iter 32000, loss: 11.095971
 >> iter 33000, loss: 10.658320
 >> iter 34000, loss: 10.283937
 >> iter 35000, loss: 9.724637
 >> iter 36000, loss: 9.396205
 >> iter 37000, loss: 9.484195
 >> iter 38000, loss: 9.202056
 >> iter 39000, loss: 7.302561
 >> iter 40000, loss: 5.840214
   Number of active neurons: 10
 >> iter 41000, loss: 5.386370
 >> iter 42000, loss: 4.812100
 >> iter 43000, loss: 4.228755
 >> iter 44000, loss: 4.388865
 >> iter 45000, loss: 4.468412
 >> iter 46000, loss: 4.109164
 >> iter 47000, loss: 3.894803
 >> iter 48000, loss: 3.769333
 >> iter 49000, loss: 3.661886
 >> iter 50000, loss: 3.647799
   Number of active neurons: 10
 >> iter 51000, loss: 3.653929
 >> iter 52000, loss: 3.669580
 >> iter 53000, loss: 3.675297
 >> iter 54000, loss: 3.715030
 >> iter 55000, loss: 3.774720
 >> iter 56000, loss: 3.585496
 >> iter 57000, loss: 3.645879
 >> iter 58000, loss: 3.575715
 >> iter 59000, loss: 3.660929
 >> iter 60000, loss: 3.640888
   Number of active neurons: 10
 >> iter 61000, loss: 3.613393
 >> iter 62000, loss: 3.631453
 >> iter 63000, loss: 3.592297
 >> iter 64000, loss: 3.516754
 >> iter 65000, loss: 3.463182
 >> iter 66000, loss: 3.486791
 >> iter 67000, loss: 3.453642
 >> iter 68000, loss: 3.442241
 >> iter 69000, loss: 3.491356
 >> iter 70000, loss: 3.475842
   Number of active neurons: 10
 >> iter 71000, loss: 3.454824
 >> iter 72000, loss: 3.565368
 >> iter 73000, loss: 3.467732
 >> iter 74000, loss: 3.421777
 >> iter 75000, loss: 3.420170
 >> iter 76000, loss: 3.427090
 >> iter 77000, loss: 3.422909
 >> iter 78000, loss: 3.386714
 >> iter 79000, loss: 3.531476
 >> iter 80000, loss: 3.435517
   Number of active neurons: 10
 >> iter 81000, loss: 3.449115
 >> iter 82000, loss: 3.406617
 >> iter 83000, loss: 3.442467
 >> iter 84000, loss: 3.488300
 >> iter 85000, loss: 3.502341
 >> iter 86000, loss: 3.456904
 >> iter 87000, loss: 3.482768
 >> iter 88000, loss: 3.497796
 >> iter 89000, loss: 3.456096
 >> iter 90000, loss: 3.421188
   Number of active neurons: 10
 >> iter 91000, loss: 3.448033
 >> iter 92000, loss: 3.542695
 >> iter 93000, loss: 3.467641
 >> iter 94000, loss: 3.395403
 >> iter 95000, loss: 3.459439
 >> iter 96000, loss: 3.386607
 >> iter 97000, loss: 3.466600
 >> iter 98000, loss: 3.432738
 >> iter 99000, loss: 3.472634
 >> iter 100000, loss: 3.412849
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 7.14785704286
   - Test - Long: 26.3736813159
   - Test - Big: 6.60893391066
   - Test - A: 0.10665955603
   - Test - B: 7.25284981001
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.958346
 >> iter 2000, loss: 15.406090
 >> iter 3000, loss: 13.950169
 >> iter 4000, loss: 13.395365
 >> iter 5000, loss: 13.161328
 >> iter 6000, loss: 13.082167
 >> iter 7000, loss: 13.030238
 >> iter 8000, loss: 13.019991
 >> iter 9000, loss: 13.016374
 >> iter 10000, loss: 13.019097
   Number of active neurons: 8
 >> iter 11000, loss: 12.998671
 >> iter 12000, loss: 13.005519
 >> iter 13000, loss: 12.998840
 >> iter 14000, loss: 13.007144
 >> iter 15000, loss: 12.994854
 >> iter 16000, loss: 13.005896
 >> iter 17000, loss: 12.995994
 >> iter 18000, loss: 12.993978
 >> iter 19000, loss: 12.992226
 >> iter 20000, loss: 12.993978
   Number of active neurons: 7
 >> iter 21000, loss: 12.977055
 >> iter 22000, loss: 12.984710
 >> iter 23000, loss: 12.969413
 >> iter 24000, loss: 12.901449
 >> iter 25000, loss: 12.362202
 >> iter 26000, loss: 11.672828
 >> iter 27000, loss: 11.144897
 >> iter 28000, loss: 10.933330
 >> iter 29000, loss: 10.633640
 >> iter 30000, loss: 10.455437
   Number of active neurons: 10
 >> iter 31000, loss: 10.189250
 >> iter 32000, loss: 10.061619
 >> iter 33000, loss: 9.333132
 >> iter 34000, loss: 8.621693
 >> iter 35000, loss: 7.530469
 >> iter 36000, loss: 7.058985
 >> iter 37000, loss: 5.586729
 >> iter 38000, loss: 4.356415
 >> iter 39000, loss: 3.545408
 >> iter 40000, loss: 2.644545
   Number of active neurons: 10
 >> iter 41000, loss: 2.218358
 >> iter 42000, loss: 1.793871
 >> iter 43000, loss: 1.513525
 >> iter 44000, loss: 0.979220
 >> iter 45000, loss: 0.971971
 >> iter 46000, loss: 0.924647
 >> iter 47000, loss: 0.647160
 >> iter 48000, loss: 0.441850
 >> iter 49000, loss: 0.581740
 >> iter 50000, loss: 0.882253
   Number of active neurons: 10
 >> iter 51000, loss: 0.618744
 >> iter 52000, loss: 1.010985
 >> iter 53000, loss: 0.775652
 >> iter 54000, loss: 0.545629
 >> iter 55000, loss: 0.839475
 >> iter 56000, loss: 0.978900
 >> iter 57000, loss: 0.706494
 >> iter 58000, loss: 0.659385
 >> iter 59000, loss: 0.467434
 >> iter 60000, loss: 0.420238
   Number of active neurons: 10
 >> iter 61000, loss: 0.770890
 >> iter 62000, loss: 0.903972
 >> iter 63000, loss: 1.073478
 >> iter 64000, loss: 0.921296
 >> iter 65000, loss: 0.671342
 >> iter 66000, loss: 0.557239
 >> iter 67000, loss: 0.458618
 >> iter 68000, loss: 0.498437
 >> iter 69000, loss: 0.346181
 >> iter 70000, loss: 0.427722
   Number of active neurons: 10
 >> iter 71000, loss: 0.782119
 >> iter 72000, loss: 0.621292
 >> iter 73000, loss: 0.395484
 >> iter 74000, loss: 0.324941
 >> iter 75000, loss: 0.376029
 >> iter 76000, loss: 0.234293
 >> iter 77000, loss: 0.341457
 >> iter 78000, loss: 0.155479
 >> iter 79000, loss: 0.228208
 >> iter 80000, loss: 0.360320
   Number of active neurons: 10
 >> iter 81000, loss: 0.190593
 >> iter 82000, loss: 0.362327
 >> iter 83000, loss: 0.325069
 >> iter 84000, loss: 0.184948
 >> iter 85000, loss: 0.431640
 >> iter 86000, loss: 0.407271
 >> iter 87000, loss: 0.331039
 >> iter 88000, loss: 0.296397
 >> iter 89000, loss: 0.205955
 >> iter 90000, loss: 0.142658
   Number of active neurons: 10
 >> iter 91000, loss: 0.168332
 >> iter 92000, loss: 0.081438
 >> iter 93000, loss: 0.420913
 >> iter 94000, loss: 0.474834
 >> iter 95000, loss: 0.551038
 >> iter 96000, loss: 0.386067
 >> iter 97000, loss: 0.254642
 >> iter 98000, loss: 0.356949
 >> iter 99000, loss: 0.375324
 >> iter 100000, loss: 0.305529
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0239995200096
   - Test - Long: 0.0
   - Test - Big: 0.00999990000101
   - Test - A: 0.266648890074
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.858147
 >> iter 2000, loss: 15.351602
 >> iter 3000, loss: 13.921436
 >> iter 4000, loss: 13.397664
 >> iter 5000, loss: 13.178852
 >> iter 6000, loss: 13.098950
 >> iter 7000, loss: 13.060016
 >> iter 8000, loss: 13.040967
 >> iter 9000, loss: 13.023704
 >> iter 10000, loss: 13.033675
   Number of active neurons: 10
 >> iter 11000, loss: 13.011135
 >> iter 12000, loss: 13.011223
 >> iter 13000, loss: 12.998966
 >> iter 14000, loss: 13.009374
 >> iter 15000, loss: 12.994980
 >> iter 16000, loss: 13.006340
 >> iter 17000, loss: 12.993252
 >> iter 18000, loss: 12.997667
 >> iter 19000, loss: 12.983680
 >> iter 20000, loss: 12.994792
   Number of active neurons: 8
 >> iter 21000, loss: 12.971735
 >> iter 22000, loss: 12.983235
 >> iter 23000, loss: 12.974689
 >> iter 24000, loss: 12.982171
 >> iter 25000, loss: 12.915668
 >> iter 26000, loss: 12.208465
 >> iter 27000, loss: 11.462240
 >> iter 28000, loss: 11.158962
 >> iter 29000, loss: 10.883810
 >> iter 30000, loss: 10.759939
   Number of active neurons: 10
 >> iter 31000, loss: 10.351354
 >> iter 32000, loss: 9.981929
 >> iter 33000, loss: 9.542327
 >> iter 34000, loss: 9.377800
 >> iter 35000, loss: 9.092198
 >> iter 36000, loss: 9.032327
 >> iter 37000, loss: 8.900763
 >> iter 38000, loss: 8.930112
 >> iter 39000, loss: 8.807169
 >> iter 40000, loss: 8.836301
   Number of active neurons: 10
 >> iter 41000, loss: 8.746680
 >> iter 42000, loss: 8.800792
 >> iter 43000, loss: 8.713610
 >> iter 44000, loss: 8.772405
 >> iter 45000, loss: 8.663673
 >> iter 46000, loss: 8.724679
 >> iter 47000, loss: 8.653303
 >> iter 48000, loss: 8.755025
 >> iter 49000, loss: 8.623380
 >> iter 50000, loss: 8.711110
   Number of active neurons: 10
 >> iter 51000, loss: 8.609726
 >> iter 52000, loss: 8.687915
 >> iter 53000, loss: 8.568398
 >> iter 54000, loss: 8.696299
 >> iter 55000, loss: 8.592830
 >> iter 56000, loss: 8.688174
 >> iter 57000, loss: 8.560275
 >> iter 58000, loss: 8.661214
 >> iter 59000, loss: 8.549286
 >> iter 60000, loss: 8.662236
   Number of active neurons: 10
 >> iter 61000, loss: 8.576276
 >> iter 62000, loss: 8.670413
 >> iter 63000, loss: 8.552771
 >> iter 64000, loss: 8.648542
 >> iter 65000, loss: 8.522148
 >> iter 66000, loss: 8.645560
 >> iter 67000, loss: 8.530781
 >> iter 68000, loss: 8.614529
 >> iter 69000, loss: 8.519994
 >> iter 70000, loss: 8.637290
   Number of active neurons: 10
 >> iter 71000, loss: 8.519249
 >> iter 72000, loss: 8.617754
 >> iter 73000, loss: 8.523166
 >> iter 74000, loss: 8.625471
 >> iter 75000, loss: 8.515880
 >> iter 76000, loss: 8.639569
 >> iter 77000, loss: 8.527002
 >> iter 78000, loss: 8.627739
 >> iter 79000, loss: 8.500881
 >> iter 80000, loss: 8.594534
   Number of active neurons: 10
 >> iter 81000, loss: 8.464364
 >> iter 82000, loss: 8.520459
 >> iter 83000, loss: 8.415315
 >> iter 84000, loss: 8.453726
 >> iter 85000, loss: 8.276967
 >> iter 86000, loss: 8.327394
 >> iter 87000, loss: 8.088607
 >> iter 88000, loss: 8.098193
 >> iter 89000, loss: 7.887906
 >> iter 90000, loss: 8.100601
   Number of active neurons: 10
 >> iter 91000, loss: 7.919254
 >> iter 92000, loss: 7.874159
 >> iter 93000, loss: 7.558067
 >> iter 94000, loss: 7.774468
 >> iter 95000, loss: 7.412826
 >> iter 96000, loss: 7.494634
 >> iter 97000, loss: 7.203295
 >> iter 98000, loss: 7.056959
 >> iter 99000, loss: 6.904847
 >> iter 100000, loss: 6.906832
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 12.3237535249
   - Test - Long: 30.0434978251
   - Test - Big: 12.1548784512
   - Test - A: 8.50609959336
   - Test - B: 30.7179521365
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.874532
 >> iter 2000, loss: 15.312673
 >> iter 3000, loss: 13.921033
 >> iter 4000, loss: 13.389679
 >> iter 5000, loss: 13.175672
 >> iter 6000, loss: 13.087296
 >> iter 7000, loss: 13.032443
 >> iter 8000, loss: 13.022054
 >> iter 9000, loss: 13.006658
 >> iter 10000, loss: 13.010817
   Number of active neurons: 10
 >> iter 11000, loss: 12.995603
 >> iter 12000, loss: 13.007231
 >> iter 13000, loss: 12.996071
 >> iter 14000, loss: 13.001474
 >> iter 15000, loss: 12.990753
 >> iter 16000, loss: 12.999454
 >> iter 17000, loss: 12.993699
 >> iter 18000, loss: 12.995392
 >> iter 19000, loss: 12.985369
 >> iter 20000, loss: 12.996882
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 21000, loss: 12.981595
 >> iter 22000, loss: 12.998893
 >> iter 23000, loss: 12.978261
 >> iter 24000, loss: 12.924269
 >> iter 25000, loss: 12.246318
 >> iter 26000, loss: 11.582318
 >> iter 27000, loss: 11.145405
 >> iter 28000, loss: 10.877143
 >> iter 29000, loss: 10.461622
 >> iter 30000, loss: 10.112425
   Number of active neurons: 10
 >> iter 31000, loss: 9.741363
 >> iter 32000, loss: 9.604067
 >> iter 33000, loss: 9.342066
 >> iter 34000, loss: 9.242686
 >> iter 35000, loss: 9.079182
 >> iter 36000, loss: 9.056619
 >> iter 37000, loss: 8.835697
 >> iter 38000, loss: 8.799957
 >> iter 39000, loss: 8.625795
 >> iter 40000, loss: 8.501301
   Number of active neurons: 10
 >> iter 41000, loss: 8.362231
 >> iter 42000, loss: 8.046377
 >> iter 43000, loss: 7.880489
 >> iter 44000, loss: 7.464029
 >> iter 45000, loss: 7.209142
 >> iter 46000, loss: 6.997720
 >> iter 47000, loss: 6.400818
 >> iter 48000, loss: 6.173432
 >> iter 49000, loss: 5.917935
 >> iter 50000, loss: 5.509714
   Number of active neurons: 10
 >> iter 51000, loss: 5.509958
 >> iter 52000, loss: 5.466571
 >> iter 53000, loss: 5.706608
 >> iter 54000, loss: 5.285598
 >> iter 55000, loss: 5.661739
 >> iter 56000, loss: 5.434137
 >> iter 57000, loss: 5.119016
 >> iter 58000, loss: 4.753471
 >> iter 59000, loss: 4.574585
 >> iter 60000, loss: 4.099727
   Number of active neurons: 10
 >> iter 61000, loss: 4.065684
 >> iter 62000, loss: 3.964473
 >> iter 63000, loss: 4.121391
 >> iter 64000, loss: 3.808097
 >> iter 65000, loss: 3.753700
 >> iter 66000, loss: 3.626277
 >> iter 67000, loss: 3.656487
 >> iter 68000, loss: 3.588632
 >> iter 69000, loss: 3.606389
 >> iter 70000, loss: 3.791784
   Number of active neurons: 10
 >> iter 71000, loss: 3.727707
 >> iter 72000, loss: 3.455243
 >> iter 73000, loss: 3.599412
 >> iter 74000, loss: 3.764123
 >> iter 75000, loss: 3.903913
 >> iter 76000, loss: 3.494289
 >> iter 77000, loss: 3.574249
 >> iter 78000, loss: 3.496831
 >> iter 79000, loss: 3.691874
 >> iter 80000, loss: 3.471493
   Number of active neurons: 10
 >> iter 81000, loss: 3.405552
 >> iter 82000, loss: 3.464376
 >> iter 83000, loss: 3.494192
 >> iter 84000, loss: 3.233575
 >> iter 85000, loss: 3.322966
 >> iter 86000, loss: 3.163338
 >> iter 87000, loss: 3.429780
 >> iter 88000, loss: 3.190462
 >> iter 89000, loss: 3.259649
 >> iter 90000, loss: 3.368541
   Number of active neurons: 10
 >> iter 91000, loss: 3.454180
 >> iter 92000, loss: 3.656083
 >> iter 93000, loss: 3.751739
 >> iter 94000, loss: 3.286191
 >> iter 95000, loss: 3.434106
 >> iter 96000, loss: 3.478255
 >> iter 97000, loss: 3.482453
 >> iter 98000, loss: 3.363063
 >> iter 99000, loss: 3.186260
 >> iter 100000, loss: 3.386051
   Number of active neurons: 10
 >> iter 101000, loss: 3.193769
 >> iter 102000, loss: 3.214692
 >> iter 103000, loss: 3.165179
 >> iter 104000, loss: 3.069858
 >> iter 105000, loss: 3.251718
 >> iter 106000, loss: 3.155713
 >> iter 107000, loss: 3.017321
 >> iter 108000, loss: 3.334530
 >> iter 109000, loss: 3.336493
 >> iter 110000, loss: 3.021649
   Number of active neurons: 10
 >> iter 111000, loss: 3.099947
 >> iter 112000, loss: 2.905899
 >> iter 113000, loss: 3.065424
 >> iter 114000, loss: 3.128241
 >> iter 115000, loss: 2.922493
 >> iter 116000, loss: 2.797663
 >> iter 117000, loss: 3.083158
 >> iter 118000, loss: 2.928593
 >> iter 119000, loss: 2.872593
 >> iter 120000, loss: 2.985779
   Number of active neurons: 10
 >> iter 121000, loss: 2.746706
 >> iter 122000, loss: 2.843954
 >> iter 123000, loss: 2.968372
 >> iter 124000, loss: 2.807687
 >> iter 125000, loss: 2.815561
 >> iter 126000, loss: 2.645821
 >> iter 127000, loss: 2.666689
 >> iter 128000, loss: 2.819748
 >> iter 129000, loss: 2.495590
 >> iter 130000, loss: 2.318996
   Number of active neurons: 10
 >> iter 131000, loss: 2.304869
 >> iter 132000, loss: 2.186661
 >> iter 133000, loss: 2.280336
 >> iter 134000, loss: 2.218051
 >> iter 135000, loss: 2.363664
 >> iter 136000, loss: 2.347125
 >> iter 137000, loss: 2.472902
 >> iter 138000, loss: 2.507243
 >> iter 139000, loss: 2.362513
 >> iter 140000, loss: 2.226349
   Number of active neurons: 10
 >> iter 141000, loss: 2.183035
 >> iter 142000, loss: 2.176571
 >> iter 143000, loss: 2.047479
 >> iter 144000, loss: 2.098016
 >> iter 145000, loss: 2.012254
 >> iter 146000, loss: 2.171495
 >> iter 147000, loss: 2.286571
 >> iter 148000, loss: 2.211066
 >> iter 149000, loss: 2.301952
 >> iter 150000, loss: 2.350741
   Number of active neurons: 10
 >> iter 151000, loss: 2.583920
 >> iter 152000, loss: 2.392856
 >> iter 153000, loss: 2.518981
 >> iter 154000, loss: 2.401918
 >> iter 155000, loss: 2.448971
 >> iter 156000, loss: 2.288845
 >> iter 157000, loss: 2.323257
 >> iter 158000, loss: 2.132500
 >> iter 159000, loss: 2.239219
 >> iter 160000, loss: 2.339968
   Number of active neurons: 10
 >> iter 161000, loss: 2.215787
 >> iter 162000, loss: 2.126504
 >> iter 163000, loss: 2.391098
 >> iter 164000, loss: 2.502100
 >> iter 165000, loss: 2.428709
 >> iter 166000, loss: 2.094796
 >> iter 167000, loss: 2.247904
 >> iter 168000, loss: 2.309514
 >> iter 169000, loss: 2.291084
 >> iter 170000, loss: 2.478025
   Number of active neurons: 10
 >> iter 171000, loss: 2.302476
 >> iter 172000, loss: 2.252560
 >> iter 173000, loss: 2.471318
 >> iter 174000, loss: 2.490089
 >> iter 175000, loss: 2.480897
 >> iter 176000, loss: 2.218436
 >> iter 177000, loss: 2.373749
 >> iter 178000, loss: 2.242365
 >> iter 179000, loss: 2.414853
 >> iter 180000, loss: 2.471455
   Number of active neurons: 10
 >> iter 181000, loss: 2.505850
 >> iter 182000, loss: 2.393280
 >> iter 183000, loss: 2.469201
 >> iter 184000, loss: 2.229574
 >> iter 185000, loss: 2.248695
 >> iter 186000, loss: 2.254578
 >> iter 187000, loss: 2.644661
 >> iter 188000, loss: 2.641425
 >> iter 189000, loss: 2.452246
 >> iter 190000, loss: 2.255219
   Number of active neurons: 10
 >> iter 191000, loss: 2.288605
 >> iter 192000, loss: 2.254651
 >> iter 193000, loss: 2.407537
 >> iter 194000, loss: 2.462453
 >> iter 195000, loss: 2.450437
 >> iter 196000, loss: 2.311536
 >> iter 197000, loss: 2.431358
 >> iter 198000, loss: 2.256252
 >> iter 199000, loss: 2.189710
 >> iter 200000, loss: 2.157364
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 3.52392952141
   - Test - Long: 20.2689865507
   - Test - Big: 3.76496235038
   - Test - A: 0.0
   - Test - B: 30.651289914
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.880935
 >> iter 2000, loss: 15.388668
 >> iter 3000, loss: 13.980421
 >> iter 4000, loss: 13.436247
 >> iter 5000, loss: 13.199993
 >> iter 6000, loss: 13.114885
 >> iter 7000, loss: 13.061638
 >> iter 8000, loss: 13.052727
 >> iter 9000, loss: 13.040161
 >> iter 10000, loss: 13.051875
   Number of active neurons: 10
 >> iter 11000, loss: 13.036604
 >> iter 12000, loss: 13.039496
 >> iter 13000, loss: 13.022721
 >> iter 14000, loss: 13.025357
 >> iter 15000, loss: 13.016850
 >> iter 16000, loss: 13.027462
 >> iter 17000, loss: 13.017952
 >> iter 18000, loss: 13.021614
 >> iter 19000, loss: 13.017103
 >> iter 20000, loss: 13.027050
   Number of active neurons: 10
 >> iter 21000, loss: 13.010180
 >> iter 22000, loss: 13.024686
 >> iter 23000, loss: 13.014909
 >> iter 24000, loss: 13.025477
 >> iter 25000, loss: 13.010643
 >> iter 26000, loss: 13.026503
 >> iter 27000, loss: 13.006216
 >> iter 28000, loss: 13.018021
 >> iter 29000, loss: 13.010167
 >> iter 30000, loss: 13.024094
   Number of active neurons: 10
 >> iter 31000, loss: 13.011185
 >> iter 32000, loss: 13.027575
 >> iter 33000, loss: 13.013105
 >> iter 34000, loss: 13.027379
 >> iter 35000, loss: 13.009304
 >> iter 36000, loss: 13.018866
 >> iter 37000, loss: 13.008716
 >> iter 38000, loss: 13.019297
 >> iter 39000, loss: 13.009324
 >> iter 40000, loss: 13.019274
   Number of active neurons: 10
 >> iter 41000, loss: 13.006137
 >> iter 42000, loss: 13.019427
 >> iter 43000, loss: 13.008788
 >> iter 44000, loss: 13.023844
 >> iter 45000, loss: 13.004438
 >> iter 46000, loss: 13.027946
 >> iter 47000, loss: 13.006029
 >> iter 48000, loss: 13.020905
 >> iter 49000, loss: 13.005524
 >> iter 50000, loss: 13.004416
   Number of active neurons: 10
 >> iter 51000, loss: 12.528695
 >> iter 52000, loss: 11.773812
 >> iter 53000, loss: 11.214886
 >> iter 54000, loss: 10.986957
 >> iter 55000, loss: 10.714731
 >> iter 56000, loss: 10.627611
 >> iter 57000, loss: 10.396466
 >> iter 58000, loss: 10.144674
 >> iter 59000, loss: 9.502207
 >> iter 60000, loss: 9.156163
   Number of active neurons: 10
 >> iter 61000, loss: 8.749921
 >> iter 62000, loss: 8.656990
 >> iter 63000, loss: 8.287925
 >> iter 64000, loss: 8.238806
 >> iter 65000, loss: 7.931732
 >> iter 66000, loss: 7.893874
 >> iter 67000, loss: 7.574131
 >> iter 68000, loss: 7.565782
 >> iter 69000, loss: 7.273164
 >> iter 70000, loss: 7.431546
   Number of active neurons: 10
 >> iter 71000, loss: 7.150544
 >> iter 72000, loss: 7.345000
 >> iter 73000, loss: 7.139784
 >> iter 74000, loss: 7.331409
 >> iter 75000, loss: 7.128035
 >> iter 76000, loss: 7.252528
 >> iter 77000, loss: 7.067126
 >> iter 78000, loss: 7.264456
 >> iter 79000, loss: 6.988965
 >> iter 80000, loss: 7.195663
   Number of active neurons: 10
 >> iter 81000, loss: 6.957354
 >> iter 82000, loss: 7.198412
 >> iter 83000, loss: 7.003131
 >> iter 84000, loss: 7.193995
 >> iter 85000, loss: 6.986807
 >> iter 86000, loss: 7.189323
 >> iter 87000, loss: 6.933757
 >> iter 88000, loss: 7.149134
 >> iter 89000, loss: 6.876661
 >> iter 90000, loss: 7.093584
   Number of active neurons: 10
 >> iter 91000, loss: 6.869175
 >> iter 92000, loss: 7.108457
 >> iter 93000, loss: 6.945041
 >> iter 94000, loss: 7.160825
 >> iter 95000, loss: 6.872335
 >> iter 96000, loss: 7.089802
 >> iter 97000, loss: 6.859099
 >> iter 98000, loss: 7.097485
 >> iter 99000, loss: 7.032066
 >> iter 100000, loss: 7.112001
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 13.6217275654
   - Test - Long: 30.2434878256
   - Test - Big: 13.6418635814
   - Test - A: 31.391240584
   - Test - B: 13.3724418372
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.909326
 >> iter 2000, loss: 15.403373
 >> iter 3000, loss: 13.980937
 >> iter 4000, loss: 13.438812
 >> iter 5000, loss: 13.213783
 >> iter 6000, loss: 13.123840
 >> iter 7000, loss: 13.077423
 >> iter 8000, loss: 13.075182
 >> iter 9000, loss: 13.065219
 >> iter 10000, loss: 13.061212
   Number of active neurons: 10
 >> iter 11000, loss: 13.049817
 >> iter 12000, loss: 13.055710
 >> iter 13000, loss: 13.034030
 >> iter 14000, loss: 13.034817
 >> iter 15000, loss: 13.029281
 >> iter 16000, loss: 13.036966
 >> iter 17000, loss: 13.037642
 >> iter 18000, loss: 13.041447
 >> iter 19000, loss: 13.024704
 >> iter 20000, loss: 13.027437
   Number of active neurons: 10
 >> iter 21000, loss: 13.014360
 >> iter 22000, loss: 13.029846
 >> iter 23000, loss: 13.013896
 >> iter 24000, loss: 13.024124
 >> iter 25000, loss: 13.007511
 >> iter 26000, loss: 13.020079
 >> iter 27000, loss: 13.008558
 >> iter 28000, loss: 13.026052
 >> iter 29000, loss: 13.016201
 >> iter 30000, loss: 13.023197
   Number of active neurons: 10
 >> iter 31000, loss: 13.013225
 >> iter 32000, loss: 13.028524
 >> iter 33000, loss: 13.013226
 >> iter 34000, loss: 13.020039
 >> iter 35000, loss: 13.013077
 >> iter 36000, loss: 13.017426
 >> iter 37000, loss: 13.005377
 >> iter 38000, loss: 13.004305
 >> iter 39000, loss: 12.980706
 >> iter 40000, loss: 12.630872
   Number of active neurons: 10
 >> iter 41000, loss: 11.776821
 >> iter 42000, loss: 11.356850
 >> iter 43000, loss: 11.055188
 >> iter 44000, loss: 11.007952
 >> iter 45000, loss: 10.775870
 >> iter 46000, loss: 10.683135
 >> iter 47000, loss: 10.554775
 >> iter 48000, loss: 10.522342
 >> iter 49000, loss: 10.344943
 >> iter 50000, loss: 10.178841
   Number of active neurons: 10
 >> iter 51000, loss: 9.677488
 >> iter 52000, loss: 8.663974
 >> iter 53000, loss: 5.295506
 >> iter 54000, loss: 3.779312
 >> iter 55000, loss: 2.417863
 >> iter 56000, loss: 1.767854
 >> iter 57000, loss: 1.094694
 >> iter 58000, loss: 1.144003
 >> iter 59000, loss: 1.521248
 >> iter 60000, loss: 1.118420
   Number of active neurons: 10
 >> iter 61000, loss: 0.800172
 >> iter 62000, loss: 0.656673
 >> iter 63000, loss: 0.566663
 >> iter 64000, loss: 0.389215
 >> iter 65000, loss: 0.366459
 >> iter 66000, loss: 0.477283
 >> iter 67000, loss: 0.305986
 >> iter 68000, loss: 0.246910
 >> iter 69000, loss: 0.256862
 >> iter 70000, loss: 0.232334
   Number of active neurons: 10
 >> iter 71000, loss: 0.223319
 >> iter 72000, loss: 0.414040
 >> iter 73000, loss: 0.186627
 >> iter 74000, loss: 0.273229
 >> iter 75000, loss: 0.300917
 >> iter 76000, loss: 0.145001
 >> iter 77000, loss: 0.147908
 >> iter 78000, loss: 0.320374
 >> iter 79000, loss: 0.289678
 >> iter 80000, loss: 0.268806
   Number of active neurons: 10
 >> iter 81000, loss: 0.260956
 >> iter 82000, loss: 0.277285
 >> iter 83000, loss: 0.141614
 >> iter 84000, loss: 0.230378
 >> iter 85000, loss: 0.222531
 >> iter 86000, loss: 0.177642
 >> iter 87000, loss: 0.261672
 >> iter 88000, loss: 0.209610
 >> iter 89000, loss: 0.110952
 >> iter 90000, loss: 0.060627
   Number of active neurons: 10
 >> iter 91000, loss: 0.194782
 >> iter 92000, loss: 0.143995
 >> iter 93000, loss: 0.264675
 >> iter 94000, loss: 0.434388
 >> iter 95000, loss: 0.180364
 >> iter 96000, loss: 0.131805
 >> iter 97000, loss: 0.317268
 >> iter 98000, loss: 0.133585
 >> iter 99000, loss: 0.121198
 >> iter 100000, loss: 0.101557
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.924169
 >> iter 2000, loss: 15.416287
 >> iter 3000, loss: 13.997000
 >> iter 4000, loss: 13.435850
 >> iter 5000, loss: 13.205983
 >> iter 6000, loss: 13.115607
 >> iter 7000, loss: 13.063752
 >> iter 8000, loss: 13.050187
 >> iter 9000, loss: 13.039998
 >> iter 10000, loss: 13.041864
   Number of active neurons: 10
 >> iter 11000, loss: 13.026997
 >> iter 12000, loss: 13.026775
 >> iter 13000, loss: 13.019845
 >> iter 14000, loss: 13.023575
 >> iter 15000, loss: 13.016093
 >> iter 16000, loss: 13.024571
 >> iter 17000, loss: 13.011564
 >> iter 18000, loss: 13.020271
 >> iter 19000, loss: 13.012712
 >> iter 20000, loss: 13.017599
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 21000, loss: 13.008660
 >> iter 22000, loss: 13.018335
 >> iter 23000, loss: 13.005626
 >> iter 24000, loss: 13.008786
 >> iter 25000, loss: 12.997612
 >> iter 26000, loss: 13.018717
 >> iter 27000, loss: 12.999044
 >> iter 28000, loss: 13.011273
 >> iter 29000, loss: 13.003034
 >> iter 30000, loss: 12.994208
   Number of active neurons: 10
 >> iter 31000, loss: 12.894388
 >> iter 32000, loss: 12.093609
 >> iter 33000, loss: 11.419576
 >> iter 34000, loss: 11.175685
 >> iter 35000, loss: 10.944079
 >> iter 36000, loss: 10.876906
 >> iter 37000, loss: 10.722997
 >> iter 38000, loss: 10.700883
 >> iter 39000, loss: 10.571706
 >> iter 40000, loss: 10.526609
   Number of active neurons: 10
 >> iter 41000, loss: 10.192616
 >> iter 42000, loss: 9.974906
 >> iter 43000, loss: 9.588006
 >> iter 44000, loss: 9.450228
 >> iter 45000, loss: 9.231038
 >> iter 46000, loss: 9.189260
 >> iter 47000, loss: 9.098782
 >> iter 48000, loss: 9.079173
 >> iter 49000, loss: 8.805281
 >> iter 50000, loss: 8.677338
   Number of active neurons: 10
 >> iter 51000, loss: 8.422988
 >> iter 52000, loss: 8.366128
 >> iter 53000, loss: 8.246394
 >> iter 54000, loss: 8.237143
 >> iter 55000, loss: 8.179999
 >> iter 56000, loss: 8.332955
 >> iter 57000, loss: 7.993180
 >> iter 58000, loss: 8.092998
 >> iter 59000, loss: 7.688164
 >> iter 60000, loss: 7.329796
   Number of active neurons: 10
 >> iter 61000, loss: 5.756155
 >> iter 62000, loss: 4.184284
 >> iter 63000, loss: 2.737760
 >> iter 64000, loss: 1.861987
 >> iter 65000, loss: 1.961468
 >> iter 66000, loss: 1.561433
 >> iter 67000, loss: 1.569070
 >> iter 68000, loss: 1.546045
 >> iter 69000, loss: 1.195378
 >> iter 70000, loss: 1.150756
   Number of active neurons: 10
 >> iter 71000, loss: 0.934253
 >> iter 72000, loss: 0.713703
 >> iter 73000, loss: 0.715085
 >> iter 74000, loss: 0.741257
 >> iter 75000, loss: 0.923957
 >> iter 76000, loss: 1.107709
 >> iter 77000, loss: 0.899153
 >> iter 78000, loss: 1.010564
 >> iter 79000, loss: 0.550241
 >> iter 80000, loss: 0.629880
   Number of active neurons: 10
 >> iter 81000, loss: 0.639357
 >> iter 82000, loss: 0.586141
 >> iter 83000, loss: 0.364156
 >> iter 84000, loss: 0.266649
 >> iter 85000, loss: 0.475031
 >> iter 86000, loss: 0.552619
 >> iter 87000, loss: 0.633025
 >> iter 88000, loss: 0.415203
 >> iter 89000, loss: 0.326058
 >> iter 90000, loss: 0.558205
   Number of active neurons: 10
 >> iter 91000, loss: 0.382601
 >> iter 92000, loss: 0.396238
 >> iter 93000, loss: 0.593921
 >> iter 94000, loss: 0.287911
 >> iter 95000, loss: 0.658208
 >> iter 96000, loss: 0.417691
 >> iter 97000, loss: 0.207751
 >> iter 98000, loss: 0.321525
 >> iter 99000, loss: 0.223366
 >> iter 100000, loss: 0.309742
   Number of active neurons: 10
 >> iter 101000, loss: 0.202923
 >> iter 102000, loss: 0.492264
 >> iter 103000, loss: 0.235856
 >> iter 104000, loss: 0.447122
 >> iter 105000, loss: 0.274280
 >> iter 106000, loss: 0.367821
 >> iter 107000, loss: 0.552704
 >> iter 108000, loss: 0.414027
 >> iter 109000, loss: 0.320554
 >> iter 110000, loss: 0.390149
   Number of active neurons: 10
 >> iter 111000, loss: 0.301429
 >> iter 112000, loss: 0.378859
 >> iter 113000, loss: 0.522530
 >> iter 114000, loss: 0.604233
 >> iter 115000, loss: 0.404758
 >> iter 116000, loss: 0.349057
 >> iter 117000, loss: 0.302280
 >> iter 118000, loss: 0.238553
 >> iter 119000, loss: 0.389023
 >> iter 120000, loss: 0.267364
   Number of active neurons: 10
 >> iter 121000, loss: 0.235303
 >> iter 122000, loss: 0.152392
 >> iter 123000, loss: 0.363292
 >> iter 124000, loss: 0.360871
 >> iter 125000, loss: 0.170598
 >> iter 126000, loss: 0.324793
 >> iter 127000, loss: 0.602956
 >> iter 128000, loss: 0.275115
 >> iter 129000, loss: 0.306454
 >> iter 130000, loss: 0.494434
   Number of active neurons: 10
 >> iter 131000, loss: 0.349743
 >> iter 132000, loss: 0.276215
 >> iter 133000, loss: 0.359640
 >> iter 134000, loss: 0.442709
 >> iter 135000, loss: 0.310274
 >> iter 136000, loss: 0.146834
 >> iter 137000, loss: 0.158289
 >> iter 138000, loss: 0.113641
 >> iter 139000, loss: 0.143998
 >> iter 140000, loss: 0.136857
   Number of active neurons: 10
 >> iter 141000, loss: 0.113159
 >> iter 142000, loss: 0.097888
 >> iter 143000, loss: 0.059789
 >> iter 144000, loss: 0.291501
 >> iter 145000, loss: 0.217818
 >> iter 146000, loss: 0.249297
 >> iter 147000, loss: 0.179761
 >> iter 148000, loss: 0.259028
 >> iter 149000, loss: 0.234987
 >> iter 150000, loss: 0.136750
   Number of active neurons: 10
 >> iter 151000, loss: 0.071765
 >> iter 152000, loss: 0.044645
 >> iter 153000, loss: 0.181816
 >> iter 154000, loss: 0.273925
 >> iter 155000, loss: 0.300011
 >> iter 156000, loss: 0.220230
 >> iter 157000, loss: 0.159119
 >> iter 158000, loss: 0.077042
 >> iter 159000, loss: 0.106724
 >> iter 160000, loss: 0.055666
   Number of active neurons: 10
 >> iter 161000, loss: 0.094936
 >> iter 162000, loss: 0.092134
 >> iter 163000, loss: 0.158388
 >> iter 164000, loss: 0.236291
 >> iter 165000, loss: 0.158605
 >> iter 166000, loss: 0.111571
 >> iter 167000, loss: 0.100353
 >> iter 168000, loss: 0.148687
 >> iter 169000, loss: 0.070590
 >> iter 170000, loss: 0.145303
   Number of active neurons: 10
 >> iter 171000, loss: 0.183258
 >> iter 172000, loss: 0.211121
 >> iter 173000, loss: 0.145735
 >> iter 174000, loss: 0.069941
 >> iter 175000, loss: 0.048168
 >> iter 176000, loss: 0.032018
 >> iter 177000, loss: 0.104929
 >> iter 178000, loss: 0.279454
 >> iter 179000, loss: 0.165009
 >> iter 180000, loss: 0.099522
   Number of active neurons: 10
 >> iter 181000, loss: 0.119296
 >> iter 182000, loss: 0.187330
 >> iter 183000, loss: 0.082998
 >> iter 184000, loss: 0.042934
 >> iter 185000, loss: 0.027963
 >> iter 186000, loss: 0.308386
 >> iter 187000, loss: 0.445240
 >> iter 188000, loss: 0.179726
 >> iter 189000, loss: 0.099210
 >> iter 190000, loss: 0.089943
   Number of active neurons: 10
 >> iter 191000, loss: 0.202732
 >> iter 192000, loss: 0.126072
 >> iter 193000, loss: 0.059986
 >> iter 194000, loss: 0.102858
 >> iter 195000, loss: 0.122917
 >> iter 196000, loss: 0.120430
 >> iter 197000, loss: 0.139194
 >> iter 198000, loss: 0.101685
 >> iter 199000, loss: 0.165768
 >> iter 200000, loss: 0.102959
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00199998000021
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.946969
 >> iter 2000, loss: 15.416655
 >> iter 3000, loss: 13.996055
 >> iter 4000, loss: 13.444494
 >> iter 5000, loss: 13.210558
 >> iter 6000, loss: 13.120548
 >> iter 7000, loss: 13.062514
 >> iter 8000, loss: 13.052624
 >> iter 9000, loss: 13.034595
 >> iter 10000, loss: 13.034771
   Number of active neurons: 10
 >> iter 11000, loss: 13.024280
 >> iter 12000, loss: 13.026287
 >> iter 13000, loss: 13.012431
 >> iter 14000, loss: 13.025622
 >> iter 15000, loss: 13.012913
 >> iter 16000, loss: 13.012930
 >> iter 17000, loss: 13.000658
 >> iter 18000, loss: 13.005926
 >> iter 19000, loss: 13.004840
 >> iter 20000, loss: 13.023786
   Number of active neurons: 10
 >> iter 21000, loss: 13.003016
 >> iter 22000, loss: 13.014406
 >> iter 23000, loss: 12.999847
 >> iter 24000, loss: 12.999970
 >> iter 25000, loss: 12.969327
 >> iter 26000, loss: 12.493139
 >> iter 27000, loss: 11.650824
 >> iter 28000, loss: 11.210340
 >> iter 29000, loss: 10.816906
 >> iter 30000, loss: 10.509877
   Number of active neurons: 10
 >> iter 31000, loss: 10.052841
 >> iter 32000, loss: 9.870512
 >> iter 33000, loss: 9.494875
 >> iter 34000, loss: 9.397609
 >> iter 35000, loss: 9.223975
 >> iter 36000, loss: 9.242748
 >> iter 37000, loss: 9.075793
 >> iter 38000, loss: 9.102338
 >> iter 39000, loss: 9.035463
 >> iter 40000, loss: 8.978579
   Number of active neurons: 10
 >> iter 41000, loss: 8.956458
 >> iter 42000, loss: 8.970831
 >> iter 43000, loss: 8.904798
 >> iter 44000, loss: 8.913495
 >> iter 45000, loss: 8.820867
 >> iter 46000, loss: 8.893231
 >> iter 47000, loss: 8.858482
 >> iter 48000, loss: 8.889276
 >> iter 49000, loss: 8.807132
 >> iter 50000, loss: 8.801810
   Number of active neurons: 10
 >> iter 51000, loss: 8.773182
 >> iter 52000, loss: 8.771674
 >> iter 53000, loss: 8.693112
 >> iter 54000, loss: 8.749048
 >> iter 55000, loss: 8.681166
 >> iter 56000, loss: 8.854731
 >> iter 57000, loss: 8.722402
 >> iter 58000, loss: 8.708954
 >> iter 59000, loss: 8.641171
 >> iter 60000, loss: 8.744219
   Number of active neurons: 10
 >> iter 61000, loss: 8.633272
 >> iter 62000, loss: 8.735810
 >> iter 63000, loss: 8.655744
 >> iter 64000, loss: 8.705154
 >> iter 65000, loss: 8.699511
 >> iter 66000, loss: 8.788602
 >> iter 67000, loss: 8.679178
 >> iter 68000, loss: 8.713989
 >> iter 69000, loss: 8.600401
 >> iter 70000, loss: 8.668251
   Number of active neurons: 10
 >> iter 71000, loss: 8.636685
 >> iter 72000, loss: 8.693103
 >> iter 73000, loss: 8.701687
 >> iter 74000, loss: 8.641790
 >> iter 75000, loss: 8.598740
 >> iter 76000, loss: 8.643305
 >> iter 77000, loss: 8.529766
 >> iter 78000, loss: 8.603747
 >> iter 79000, loss: 8.445783
 >> iter 80000, loss: 8.553678
   Number of active neurons: 10
 >> iter 81000, loss: 8.465877
 >> iter 82000, loss: 8.574313
 >> iter 83000, loss: 8.501175
 >> iter 84000, loss: 8.566729
 >> iter 85000, loss: 8.491865
 >> iter 86000, loss: 8.593903
 >> iter 87000, loss: 8.474104
 >> iter 88000, loss: 8.552143
 >> iter 89000, loss: 8.462307
 >> iter 90000, loss: 8.590048
   Number of active neurons: 10
 >> iter 91000, loss: 8.454551
 >> iter 92000, loss: 8.554365
 >> iter 93000, loss: 8.439838
 >> iter 94000, loss: 8.505984
 >> iter 95000, loss: 8.406282
 >> iter 96000, loss: 8.478287
 >> iter 97000, loss: 8.389871
 >> iter 98000, loss: 8.452866
 >> iter 99000, loss: 8.384064
 >> iter 100000, loss: 8.486808
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 17.1976560469
   - Test - Long: 31.2834358282
   - Test - Big: 17.2588274117
   - Test - A: 15.6256249583
   - Test - B: 32.4911672555
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.893437
 >> iter 2000, loss: 15.382656
 >> iter 3000, loss: 13.951690
 >> iter 4000, loss: 13.398102
 >> iter 5000, loss: 13.162643
 >> iter 6000, loss: 13.092131
 >> iter 7000, loss: 13.052335
 >> iter 8000, loss: 13.034318
 >> iter 9000, loss: 13.035516
 >> iter 10000, loss: 13.045373
   Number of active neurons: 10
 >> iter 11000, loss: 13.037355
 >> iter 12000, loss: 13.037013
 >> iter 13000, loss: 13.023362
 >> iter 14000, loss: 13.026232
 >> iter 15000, loss: 13.010741
 >> iter 16000, loss: 13.014753
 >> iter 17000, loss: 13.004285
 >> iter 18000, loss: 13.001890
 >> iter 19000, loss: 12.988587
 >> iter 20000, loss: 13.004233
   Number of active neurons: 9
 >> iter 21000, loss: 12.986457
 >> iter 22000, loss: 12.994675
 >> iter 23000, loss: 12.987318
 >> iter 24000, loss: 13.004020
 >> iter 25000, loss: 12.990034
 >> iter 26000, loss: 13.001359
 >> iter 27000, loss: 12.989252
 >> iter 28000, loss: 12.998699
 >> iter 29000, loss: 12.984434
 >> iter 30000, loss: 12.997659
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 31000, loss: 12.982672
 >> iter 32000, loss: 12.991788
 >> iter 33000, loss: 12.985949
 >> iter 34000, loss: 12.978415
 >> iter 35000, loss: 12.820619
 >> iter 36000, loss: 12.017018
 >> iter 37000, loss: 11.336265
 >> iter 38000, loss: 11.077749
 >> iter 39000, loss: 10.860101
 >> iter 40000, loss: 10.814886
   Number of active neurons: 10
 >> iter 41000, loss: 10.629972
 >> iter 42000, loss: 10.561380
 >> iter 43000, loss: 10.387681
 >> iter 44000, loss: 10.394489
 >> iter 45000, loss: 10.272066
 >> iter 46000, loss: 10.166530
 >> iter 47000, loss: 9.838010
 >> iter 48000, loss: 9.498150
 >> iter 49000, loss: 9.180015
 >> iter 50000, loss: 8.534326
   Number of active neurons: 10
 >> iter 51000, loss: 7.653953
 >> iter 52000, loss: 7.385522
 >> iter 53000, loss: 6.821367
 >> iter 54000, loss: 6.701818
 >> iter 55000, loss: 3.884252
 >> iter 56000, loss: 2.213583
 >> iter 57000, loss: 1.717035
 >> iter 58000, loss: 0.975503
 >> iter 59000, loss: 0.801256
 >> iter 60000, loss: 0.598595
   Number of active neurons: 10
 >> iter 61000, loss: 0.677544
 >> iter 62000, loss: 0.340030
 >> iter 63000, loss: 0.349645
 >> iter 64000, loss: 0.224038
 >> iter 65000, loss: 0.464749
 >> iter 66000, loss: 0.450761
 >> iter 67000, loss: 0.415250
 >> iter 68000, loss: 0.259472
 >> iter 69000, loss: 0.138534
 >> iter 70000, loss: 0.129636
   Number of active neurons: 10
 >> iter 71000, loss: 0.125707
 >> iter 72000, loss: 0.191171
 >> iter 73000, loss: 0.234126
 >> iter 74000, loss: 0.149275
 >> iter 75000, loss: 0.086393
 >> iter 76000, loss: 0.129014
 >> iter 77000, loss: 0.117728
 >> iter 78000, loss: 0.080313
 >> iter 79000, loss: 0.083001
 >> iter 80000, loss: 0.062834
   Number of active neurons: 10
 >> iter 81000, loss: 0.043830
 >> iter 82000, loss: 0.052831
 >> iter 83000, loss: 0.030100
 >> iter 84000, loss: 0.092689
 >> iter 85000, loss: 0.093579
 >> iter 86000, loss: 0.371229
 >> iter 87000, loss: 0.255334
 >> iter 88000, loss: 0.387454
 >> iter 89000, loss: 0.170946
 >> iter 90000, loss: 0.329236
   Number of active neurons: 10
 >> iter 91000, loss: 0.218442
 >> iter 92000, loss: 0.116842
 >> iter 93000, loss: 0.093240
 >> iter 94000, loss: 0.056529
 >> iter 95000, loss: 0.031491
 >> iter 96000, loss: 0.136638
 >> iter 97000, loss: 0.070906
 >> iter 98000, loss: 0.119239
 >> iter 99000, loss: 0.200043
 >> iter 100000, loss: 0.109725
   Number of active neurons: 10
 >> iter 101000, loss: 0.096924
 >> iter 102000, loss: 0.101187
 >> iter 103000, loss: 0.066417
 >> iter 104000, loss: 0.033475
 >> iter 105000, loss: 0.066771
 >> iter 106000, loss: 0.031784
 >> iter 107000, loss: 0.032609
 >> iter 108000, loss: 0.018057
 >> iter 109000, loss: 0.018431
 >> iter 110000, loss: 0.018567
   Number of active neurons: 10
 >> iter 111000, loss: 0.093816
 >> iter 112000, loss: 0.097559
 >> iter 113000, loss: 0.100542
 >> iter 114000, loss: 0.105339
 >> iter 115000, loss: 0.046328
 >> iter 116000, loss: 0.102413
 >> iter 117000, loss: 0.144539
 >> iter 118000, loss: 0.209551
 >> iter 119000, loss: 0.165472
 >> iter 120000, loss: 0.102722
   Number of active neurons: 10
 >> iter 121000, loss: 0.098282
 >> iter 122000, loss: 0.046202
 >> iter 123000, loss: 0.106477
 >> iter 124000, loss: 0.116331
 >> iter 125000, loss: 0.049219
 >> iter 126000, loss: 0.045597
 >> iter 127000, loss: 0.071147
 >> iter 128000, loss: 0.118059
 >> iter 129000, loss: 0.057597
 >> iter 130000, loss: 0.032575
   Number of active neurons: 10
 >> iter 131000, loss: 0.170095
 >> iter 132000, loss: 0.072051
 >> iter 133000, loss: 0.039518
 >> iter 134000, loss: 0.042677
 >> iter 135000, loss: 0.020612
 >> iter 136000, loss: 0.012561
 >> iter 137000, loss: 0.009497
 >> iter 138000, loss: 0.180395
 >> iter 139000, loss: 0.168097
 >> iter 140000, loss: 0.095532
   Number of active neurons: 10
 >> iter 141000, loss: 0.076758
 >> iter 142000, loss: 0.043087
 >> iter 143000, loss: 0.027053
 >> iter 144000, loss: 0.101866
 >> iter 145000, loss: 0.378844
 >> iter 146000, loss: 0.364293
 >> iter 147000, loss: 0.178389
 >> iter 148000, loss: 0.095881
 >> iter 149000, loss: 0.075237
 >> iter 150000, loss: 0.034651
   Number of active neurons: 10
 >> iter 151000, loss: 0.035905
 >> iter 152000, loss: 0.177783
 >> iter 153000, loss: 0.266859
 >> iter 154000, loss: 0.107768
 >> iter 155000, loss: 0.058632
 >> iter 156000, loss: 0.028044
 >> iter 157000, loss: 0.015834
 >> iter 158000, loss: 0.011002
 >> iter 159000, loss: 0.008924
 >> iter 160000, loss: 0.022619
   Number of active neurons: 10
 >> iter 161000, loss: 0.079649
 >> iter 162000, loss: 0.074665
 >> iter 163000, loss: 0.032118
 >> iter 164000, loss: 0.016975
 >> iter 165000, loss: 0.010195
 >> iter 166000, loss: 0.007748
 >> iter 167000, loss: 0.007021
 >> iter 168000, loss: 0.082809
 >> iter 169000, loss: 0.034473
 >> iter 170000, loss: 0.041586
   Number of active neurons: 10
 >> iter 171000, loss: 0.027939
 >> iter 172000, loss: 0.013672
 >> iter 173000, loss: 0.008345
 >> iter 174000, loss: 0.006262
 >> iter 175000, loss: 0.048713
 >> iter 176000, loss: 0.021331
 >> iter 177000, loss: 0.022656
 >> iter 178000, loss: 0.012021
 >> iter 179000, loss: 0.116041
 >> iter 180000, loss: 0.046225
   Number of active neurons: 10
 >> iter 181000, loss: 0.020090
 >> iter 182000, loss: 0.040584
 >> iter 183000, loss: 0.030797
 >> iter 184000, loss: 0.133059
 >> iter 185000, loss: 0.095579
 >> iter 186000, loss: 0.085290
 >> iter 187000, loss: 0.039659
 >> iter 188000, loss: 0.165631
 >> iter 189000, loss: 0.065263
 >> iter 190000, loss: 0.027772
   Number of active neurons: 10
 >> iter 191000, loss: 0.015031
 >> iter 192000, loss: 0.025461
 >> iter 193000, loss: 0.013490
 >> iter 194000, loss: 0.122074
 >> iter 195000, loss: 0.073477
 >> iter 196000, loss: 0.068349
 >> iter 197000, loss: 0.030813
 >> iter 198000, loss: 0.028010
 >> iter 199000, loss: 0.015361
 >> iter 200000, loss: 0.008684
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 18.944675
 >> iter 2000, loss: 15.341824
 >> iter 3000, loss: 13.931935
 >> iter 4000, loss: 13.403630
 >> iter 5000, loss: 13.191606
 >> iter 6000, loss: 13.098849
 >> iter 7000, loss: 13.047410
 >> iter 8000, loss: 13.044242
 >> iter 9000, loss: 13.028535
 >> iter 10000, loss: 13.029265
   Number of active neurons: 9
 >> iter 11000, loss: 13.013092
 >> iter 12000, loss: 13.018726
 >> iter 13000, loss: 13.002403
 >> iter 14000, loss: 13.010360
 >> iter 15000, loss: 12.998993
 >> iter 16000, loss: 13.003459
 >> iter 17000, loss: 12.985744
 >> iter 18000, loss: 12.851147
 >> iter 19000, loss: 12.018522
 >> iter 20000, loss: 11.477958
   Number of active neurons: 10
 >> iter 21000, loss: 11.078854
 >> iter 22000, loss: 10.958836
 >> iter 23000, loss: 10.798583
 >> iter 24000, loss: 10.708083
 >> iter 25000, loss: 10.521969
 >> iter 26000, loss: 10.424173
 >> iter 27000, loss: 10.245195
 >> iter 28000, loss: 10.185552
 >> iter 29000, loss: 10.041924
 >> iter 30000, loss: 10.023084
   Number of active neurons: 10
 >> iter 31000, loss: 9.860672
 >> iter 32000, loss: 9.759517
 >> iter 33000, loss: 9.485555
 >> iter 34000, loss: 9.447330
 >> iter 35000, loss: 9.199854
 >> iter 36000, loss: 9.009659
 >> iter 37000, loss: 8.815531
 >> iter 38000, loss: 8.657227
 >> iter 39000, loss: 8.506628
 >> iter 40000, loss: 8.425683
   Number of active neurons: 10
 >> iter 41000, loss: 8.075528
 >> iter 42000, loss: 8.137480
 >> iter 43000, loss: 8.019952
 >> iter 44000, loss: 8.139984
 >> iter 45000, loss: 7.970596
 >> iter 46000, loss: 7.685676
 >> iter 47000, loss: 6.836294
 >> iter 48000, loss: 6.614221
 >> iter 49000, loss: 6.250863
 >> iter 50000, loss: 5.993159
   Number of active neurons: 10
 >> iter 51000, loss: 5.253623
 >> iter 52000, loss: 5.248967
 >> iter 53000, loss: 3.450814
 >> iter 54000, loss: 2.497730
 >> iter 55000, loss: 1.624874
 >> iter 56000, loss: 1.688154
 >> iter 57000, loss: 1.412624
 >> iter 58000, loss: 0.902099
 >> iter 59000, loss: 0.871411
 >> iter 60000, loss: 0.701189
   Number of active neurons: 10
 >> iter 61000, loss: 0.559029
 >> iter 62000, loss: 0.305326
 >> iter 63000, loss: 0.608161
 >> iter 64000, loss: 0.928501
 >> iter 65000, loss: 0.774438
 >> iter 66000, loss: 1.249172
 >> iter 67000, loss: 0.897273
 >> iter 68000, loss: 0.710365
 >> iter 69000, loss: 0.584362
 >> iter 70000, loss: 0.463342
   Number of active neurons: 10
 >> iter 71000, loss: 0.574963
 >> iter 72000, loss: 0.694833
 >> iter 73000, loss: 0.666990
 >> iter 74000, loss: 0.461236
 >> iter 75000, loss: 0.578631
 >> iter 76000, loss: 0.831197
 >> iter 77000, loss: 0.621587
 >> iter 78000, loss: 0.404800
 >> iter 79000, loss: 0.626607
 >> iter 80000, loss: 0.422034
   Number of active neurons: 10
 >> iter 81000, loss: 0.305981
 >> iter 82000, loss: 0.445058
 >> iter 83000, loss: 0.375459
 >> iter 84000, loss: 0.168062
 >> iter 85000, loss: 0.487387
 >> iter 86000, loss: 0.459349
 >> iter 87000, loss: 0.294105
 >> iter 88000, loss: 0.188476
 >> iter 89000, loss: 0.128469
 >> iter 90000, loss: 0.064328
   Number of active neurons: 10
 >> iter 91000, loss: 0.054088
 >> iter 92000, loss: 0.135591
 >> iter 93000, loss: 0.163791
 >> iter 94000, loss: 0.395612
 >> iter 95000, loss: 0.374076
 >> iter 96000, loss: 0.613444
 >> iter 97000, loss: 0.534050
 >> iter 98000, loss: 0.254299
 >> iter 99000, loss: 0.354809
 >> iter 100000, loss: 0.421373
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.14999700006
   - Test - Long: 0.3199840008
   - Test - Big: 0.0559994400056
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.949292
 >> iter 2000, loss: 15.418089
 >> iter 3000, loss: 13.989829
 >> iter 4000, loss: 13.434720
 >> iter 5000, loss: 13.197045
 >> iter 6000, loss: 13.114577
 >> iter 7000, loss: 13.062816
 >> iter 8000, loss: 13.034625
 >> iter 9000, loss: 13.019792
 >> iter 10000, loss: 13.016960
   Number of active neurons: 10
 >> iter 11000, loss: 12.997849
 >> iter 12000, loss: 13.012036
 >> iter 13000, loss: 13.000657
 >> iter 14000, loss: 12.997288
 >> iter 15000, loss: 12.983668
 >> iter 16000, loss: 12.992150
 >> iter 17000, loss: 12.977809
 >> iter 18000, loss: 12.988113
 >> iter 19000, loss: 12.971144
 >> iter 20000, loss: 12.981766
   Number of active neurons: 10
 >> iter 21000, loss: 12.972610
 >> iter 22000, loss: 12.980692
 >> iter 23000, loss: 12.965465
 >> iter 24000, loss: 12.961469
 >> iter 25000, loss: 12.684709
 >> iter 26000, loss: 11.886515
 >> iter 27000, loss: 11.308668
 >> iter 28000, loss: 11.072742
 >> iter 29000, loss: 10.858039
 >> iter 30000, loss: 10.740854
   Number of active neurons: 10
 >> iter 31000, loss: 10.487706
 >> iter 32000, loss: 10.434479
 >> iter 33000, loss: 10.271536
 >> iter 34000, loss: 10.240303
 >> iter 35000, loss: 10.024276
 >> iter 36000, loss: 9.975779
 >> iter 37000, loss: 9.802548
 >> iter 38000, loss: 9.772126
 >> iter 39000, loss: 9.643198
 >> iter 40000, loss: 9.624992
   Number of active neurons: 10
 >> iter 41000, loss: 9.513667
 >> iter 42000, loss: 9.408248
 >> iter 43000, loss: 9.201401
 >> iter 44000, loss: 9.207890
 >> iter 45000, loss: 9.073317
 >> iter 46000, loss: 9.111634
 >> iter 47000, loss: 8.991757
 >> iter 48000, loss: 9.017563
 >> iter 49000, loss: 8.976848
 >> iter 50000, loss: 9.014945
   Number of active neurons: 10
 >> iter 51000, loss: 8.883690
 >> iter 52000, loss: 8.959536
 >> iter 53000, loss: 8.845805
 >> iter 54000, loss: 8.854160
 >> iter 55000, loss: 8.514987
 >> iter 56000, loss: 8.151098
 >> iter 57000, loss: 7.547616
 >> iter 58000, loss: 7.377484
 >> iter 59000, loss: 7.131658
 >> iter 60000, loss: 7.218671
   Number of active neurons: 10
 >> iter 61000, loss: 6.977960
 >> iter 62000, loss: 7.129462
 >> iter 63000, loss: 7.152869
 >> iter 64000, loss: 7.172155
 >> iter 65000, loss: 7.082029
 >> iter 66000, loss: 7.144125
 >> iter 67000, loss: 6.969901
 >> iter 68000, loss: 6.887221
 >> iter 69000, loss: 6.766289
 >> iter 70000, loss: 6.820945
   Number of active neurons: 10
 >> iter 71000, loss: 6.726859
 >> iter 72000, loss: 6.734482
 >> iter 73000, loss: 6.665089
 >> iter 74000, loss: 6.903383
 >> iter 75000, loss: 6.674436
 >> iter 76000, loss: 6.770919
 >> iter 77000, loss: 6.781049
 >> iter 78000, loss: 6.784337
 >> iter 79000, loss: 6.284191
 >> iter 80000, loss: 6.550211
   Number of active neurons: 10
 >> iter 81000, loss: 5.771843
 >> iter 82000, loss: 5.670048
 >> iter 83000, loss: 5.239558
 >> iter 84000, loss: 5.017049
 >> iter 85000, loss: 4.895995
 >> iter 86000, loss: 4.937453
 >> iter 87000, loss: 4.638835
 >> iter 88000, loss: 4.686828
 >> iter 89000, loss: 4.372284
 >> iter 90000, loss: 4.816901
   Number of active neurons: 10
 >> iter 91000, loss: 4.509510
 >> iter 92000, loss: 3.973429
 >> iter 93000, loss: 3.206945
 >> iter 94000, loss: 2.862584
 >> iter 95000, loss: 2.644501
 >> iter 96000, loss: 2.618934
 >> iter 97000, loss: 2.472478
 >> iter 98000, loss: 2.394182
 >> iter 99000, loss: 1.934890
 >> iter 100000, loss: 1.738205
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 1.87196256075
   - Test - Long: 16.3241837908
   - Test - Big: 1.78398216018
   - Test - A: 0.493300446637
   - Test - B: 0.0599960002667

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

