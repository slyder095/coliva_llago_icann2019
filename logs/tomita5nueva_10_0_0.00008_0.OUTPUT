 > Problema: tomita5nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 8e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.684087
 >> iter 2000, loss: 10.543664
 >> iter 3000, loss: 8.652301
 >> iter 4000, loss: 7.928583
 >> iter 5000, loss: 7.682849
 >> iter 6000, loss: 7.571317
 >> iter 7000, loss: 7.548072
 >> iter 8000, loss: 7.509829
 >> iter 9000, loss: 7.528797
 >> iter 10000, loss: 7.233157
   Number of active neurons: 5
 >> iter 11000, loss: 3.308461
 >> iter 12000, loss: 1.284299
 >> iter 13000, loss: 0.518791
 >> iter 14000, loss: 0.228762
 >> iter 15000, loss: 0.118105
 >> iter 16000, loss: 0.074742
 >> iter 17000, loss: 0.057353
 >> iter 18000, loss: 0.049751
 >> iter 19000, loss: 0.046365
 >> iter 20000, loss: 0.044494
   Number of active neurons: 5
 >> iter 21000, loss: 0.043508
 >> iter 22000, loss: 0.042718
 >> iter 23000, loss: 0.042182
 >> iter 24000, loss: 0.041687
 >> iter 25000, loss: 0.041344
 >> iter 26000, loss: 0.041052
 >> iter 27000, loss: 0.040832
 >> iter 28000, loss: 0.040639
 >> iter 29000, loss: 0.040442
 >> iter 30000, loss: 0.040294
   Number of active neurons: 5
 >> iter 31000, loss: 0.040106
 >> iter 32000, loss: 0.039936
 >> iter 33000, loss: 0.039701
 >> iter 34000, loss: 0.039459
 >> iter 35000, loss: 0.039203
 >> iter 36000, loss: 0.038986
 >> iter 37000, loss: 0.038745
 >> iter 38000, loss: 0.038556
 >> iter 39000, loss: 0.038284
 >> iter 40000, loss: 0.038051
   Number of active neurons: 5
 >> iter 41000, loss: 0.037720
 >> iter 42000, loss: 0.037471
 >> iter 43000, loss: 0.037126
 >> iter 44000, loss: 0.036848
 >> iter 45000, loss: 0.036546
 >> iter 46000, loss: 0.036358
 >> iter 47000, loss: 0.036125
 >> iter 48000, loss: 0.035988
 >> iter 49000, loss: 0.035808
 >> iter 50000, loss: 0.035715
   Number of active neurons: 5
 >> iter 51000, loss: 0.035566
 >> iter 52000, loss: 0.035496
 >> iter 53000, loss: 0.035363
 >> iter 54000, loss: 0.035329
 >> iter 55000, loss: 0.035172
 >> iter 56000, loss: 0.035152
 >> iter 57000, loss: 0.035012
 >> iter 58000, loss: 0.035010
 >> iter 59000, loss: 0.034836
 >> iter 60000, loss: 0.034807
   Number of active neurons: 5
 >> iter 61000, loss: 0.034656
 >> iter 62000, loss: 0.034657
 >> iter 63000, loss: 0.034539
 >> iter 64000, loss: 0.034538
 >> iter 65000, loss: 0.034368
 >> iter 66000, loss: 0.034349
 >> iter 67000, loss: 0.034202
 >> iter 68000, loss: 0.034221
 >> iter 69000, loss: 0.034104
 >> iter 70000, loss: 0.034142
   Number of active neurons: 5
 >> iter 71000, loss: 0.034047
 >> iter 72000, loss: 0.034098
 >> iter 73000, loss: 0.033996
 >> iter 74000, loss: 0.034005
 >> iter 75000, loss: 0.033891
 >> iter 76000, loss: 0.033921
 >> iter 77000, loss: 0.033828
 >> iter 78000, loss: 0.033881
 >> iter 79000, loss: 0.033817
 >> iter 80000, loss: 0.033874
   Number of active neurons: 5
 >> iter 81000, loss: 0.033814
 >> iter 82000, loss: 0.033885
 >> iter 83000, loss: 0.033823
 >> iter 84000, loss: 0.033900
 >> iter 85000, loss: 0.033839
 >> iter 86000, loss: 0.033926
 >> iter 87000, loss: 0.033860
 >> iter 88000, loss: 0.033946
 >> iter 89000, loss: 0.033881
 >> iter 90000, loss: 0.033967
   Number of active neurons: 5
 >> iter 91000, loss: 0.033898
 >> iter 92000, loss: 0.033990
 >> iter 93000, loss: 0.033915
 >> iter 94000, loss: 0.034003
 >> iter 95000, loss: 0.033941
 >> iter 96000, loss: 0.034018
 >> iter 97000, loss: 0.033961
 >> iter 98000, loss: 0.034034
 >> iter 99000, loss: 0.033979
 >> iter 100000, loss: 0.034050
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.715723
 >> iter 2000, loss: 10.580561
 >> iter 3000, loss: 8.691000
 >> iter 4000, loss: 7.954638
 >> iter 5000, loss: 7.694968
 >> iter 6000, loss: 7.511114
 >> iter 7000, loss: 7.161718
 >> iter 8000, loss: 5.911064
 >> iter 9000, loss: 2.359543
 >> iter 10000, loss: 0.934890
   Number of active neurons: 7
 >> iter 11000, loss: 0.391368
 >> iter 12000, loss: 0.182859
 >> iter 13000, loss: 0.103354
 >> iter 14000, loss: 0.071740
 >> iter 15000, loss: 0.059826
 >> iter 16000, loss: 0.054524
 >> iter 17000, loss: 0.052558
 >> iter 18000, loss: 0.051020
 >> iter 19000, loss: 0.050247
 >> iter 20000, loss: 0.049094
   Number of active neurons: 7
 >> iter 21000, loss: 0.048122
 >> iter 22000, loss: 0.046842
 >> iter 23000, loss: 0.045955
 >> iter 24000, loss: 0.045130
 >> iter 25000, loss: 0.044509
 >> iter 26000, loss: 0.043932
 >> iter 27000, loss: 0.043383
 >> iter 28000, loss: 0.042885
 >> iter 29000, loss: 0.042402
 >> iter 30000, loss: 0.042035
   Number of active neurons: 7
 >> iter 31000, loss: 0.041644
 >> iter 32000, loss: 0.041407
 >> iter 33000, loss: 0.041066
 >> iter 34000, loss: 0.040910
 >> iter 35000, loss: 0.040546
 >> iter 36000, loss: 0.040278
 >> iter 37000, loss: 0.039757
 >> iter 38000, loss: 0.039530
 >> iter 39000, loss: 0.039070
 >> iter 40000, loss: 0.038956
   Number of active neurons: 7
 >> iter 41000, loss: 0.038592
 >> iter 42000, loss: 0.038538
 >> iter 43000, loss: 0.038205
 >> iter 44000, loss: 0.038180
 >> iter 45000, loss: 0.037875
 >> iter 46000, loss: 0.037894
 >> iter 47000, loss: 0.037597
 >> iter 48000, loss: 0.037621
 >> iter 49000, loss: 0.037350
 >> iter 50000, loss: 0.037396
   Number of active neurons: 7
 >> iter 51000, loss: 0.037135
 >> iter 52000, loss: 0.037183
 >> iter 53000, loss: 0.036894
 >> iter 54000, loss: 0.036879
 >> iter 55000, loss: 0.036595
 >> iter 56000, loss: 0.036631
 >> iter 57000, loss: 0.036391
 >> iter 58000, loss: 0.036457
 >> iter 59000, loss: 0.036241
 >> iter 60000, loss: 0.036341
   Number of active neurons: 7
 >> iter 61000, loss: 0.036134
 >> iter 62000, loss: 0.036245
 >> iter 63000, loss: 0.036035
 >> iter 64000, loss: 0.036145
 >> iter 65000, loss: 0.035949
 >> iter 66000, loss: 0.036056
 >> iter 67000, loss: 0.035876
 >> iter 68000, loss: 0.035984
 >> iter 69000, loss: 0.035823
 >> iter 70000, loss: 0.035914
   Number of active neurons: 7
 >> iter 71000, loss: 0.035760
 >> iter 72000, loss: 0.035809
 >> iter 73000, loss: 0.035647
 >> iter 74000, loss: 0.035661
 >> iter 75000, loss: 0.035505
 >> iter 76000, loss: 0.035476
 >> iter 77000, loss: 0.035313
 >> iter 78000, loss: 0.035252
 >> iter 79000, loss: 0.035056
 >> iter 80000, loss: 0.034879
   Number of active neurons: 6
 >> iter 81000, loss: 0.034672
 >> iter 82000, loss: 0.034598
 >> iter 83000, loss: 0.034465
 >> iter 84000, loss: 0.034443
 >> iter 85000, loss: 0.034350
 >> iter 86000, loss: 0.034374
 >> iter 87000, loss: 0.034302
 >> iter 88000, loss: 0.034339
 >> iter 89000, loss: 0.034263
 >> iter 90000, loss: 0.034315
   Number of active neurons: 6
 >> iter 91000, loss: 0.034238
 >> iter 92000, loss: 0.034295
 >> iter 93000, loss: 0.034221
 >> iter 94000, loss: 0.034271
 >> iter 95000, loss: 0.034203
 >> iter 96000, loss: 0.034261
 >> iter 97000, loss: 0.034188
 >> iter 98000, loss: 0.034254
 >> iter 99000, loss: 0.034167
 >> iter 100000, loss: 0.034249
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.574536
 >> iter 2000, loss: 10.498667
 >> iter 3000, loss: 8.631677
 >> iter 4000, loss: 7.926147
 >> iter 5000, loss: 7.718331
 >> iter 6000, loss: 7.725884
 >> iter 7000, loss: 7.229113
 >> iter 8000, loss: 3.049208
 >> iter 9000, loss: 1.206494
 >> iter 10000, loss: 0.505405
   Number of active neurons: 5
 >> iter 11000, loss: 0.234734
 >> iter 12000, loss: 0.131266
 >> iter 13000, loss: 0.087394
 >> iter 14000, loss: 0.072000
 >> iter 15000, loss: 0.061640
 >> iter 16000, loss: 0.058139
 >> iter 17000, loss: 0.054565
 >> iter 18000, loss: 0.053771
 >> iter 19000, loss: 0.051676
 >> iter 20000, loss: 0.051343
   Number of active neurons: 5
 >> iter 21000, loss: 0.049957
 >> iter 22000, loss: 0.049402
 >> iter 23000, loss: 0.048598
 >> iter 24000, loss: 0.047982
 >> iter 25000, loss: 0.047485
 >> iter 26000, loss: 0.046866
 >> iter 27000, loss: 0.046534
 >> iter 28000, loss: 0.046044
 >> iter 29000, loss: 0.045886
 >> iter 30000, loss: 0.045399
   Number of active neurons: 5
 >> iter 31000, loss: 0.045339
 >> iter 32000, loss: 0.044880
 >> iter 33000, loss: 0.044878
 >> iter 34000, loss: 0.044425
 >> iter 35000, loss: 0.044485
 >> iter 36000, loss: 0.043999
 >> iter 37000, loss: 0.043997
 >> iter 38000, loss: 0.043384
 >> iter 39000, loss: 0.043553
 >> iter 40000, loss: 0.042921
   Number of active neurons: 5
 >> iter 41000, loss: 0.043137
 >> iter 42000, loss: 0.042487
 >> iter 43000, loss: 0.043108
 >> iter 44000, loss: 0.042309
 >> iter 45000, loss: 0.046055
 >> iter 46000, loss: 0.043380
 >> iter 47000, loss: 0.056035
 >> iter 48000, loss: 0.046992
 >> iter 49000, loss: 0.058241
 >> iter 50000, loss: 0.047834
   Number of active neurons: 5
 >> iter 51000, loss: 0.058685
 >> iter 52000, loss: 0.048084
 >> iter 53000, loss: 0.058551
 >> iter 54000, loss: 0.048106
 >> iter 55000, loss: 0.057296
 >> iter 56000, loss: 0.047714
 >> iter 57000, loss: 0.045231
 >> iter 58000, loss: 0.043039
 >> iter 59000, loss: 0.042880
 >> iter 60000, loss: 0.042303
   Number of active neurons: 5
 >> iter 61000, loss: 0.042444
 >> iter 62000, loss: 0.042278
 >> iter 63000, loss: 0.042560
 >> iter 64000, loss: 0.042546
 >> iter 65000, loss: 0.042843
 >> iter 66000, loss: 0.042805
 >> iter 67000, loss: 0.042924
 >> iter 68000, loss: 0.042736
 >> iter 69000, loss: 0.042731
 >> iter 70000, loss: 0.042499
   Number of active neurons: 5
 >> iter 71000, loss: 0.042480
 >> iter 72000, loss: 0.042294
 >> iter 73000, loss: 0.042314
 >> iter 74000, loss: 0.042129
 >> iter 75000, loss: 0.042158
 >> iter 76000, loss: 0.041987
 >> iter 77000, loss: 0.042030
 >> iter 78000, loss: 0.041879
 >> iter 79000, loss: 0.041929
 >> iter 80000, loss: 0.041791
   Number of active neurons: 5
 >> iter 81000, loss: 0.041826
 >> iter 82000, loss: 0.041708
 >> iter 83000, loss: 0.041754
 >> iter 84000, loss: 0.041636
 >> iter 85000, loss: 0.041682
 >> iter 86000, loss: 0.041577
 >> iter 87000, loss: 0.041628
 >> iter 88000, loss: 0.041530
 >> iter 89000, loss: 0.041561
 >> iter 90000, loss: 0.041483
   Number of active neurons: 5
 >> iter 91000, loss: 0.041508
 >> iter 92000, loss: 0.041441
 >> iter 93000, loss: 0.041463
 >> iter 94000, loss: 0.041390
 >> iter 95000, loss: 0.041416
 >> iter 96000, loss: 0.041357
 >> iter 97000, loss: 0.041381
 >> iter 98000, loss: 0.041330
 >> iter 99000, loss: 0.041341
 >> iter 100000, loss: 0.041317
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 12.9391373908
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.629152
 >> iter 2000, loss: 10.525163
 >> iter 3000, loss: 8.641415
 >> iter 4000, loss: 7.915028
 >> iter 5000, loss: 7.660173
 >> iter 6000, loss: 7.221215
 >> iter 7000, loss: 4.071868
 >> iter 8000, loss: 1.582242
 >> iter 9000, loss: 0.635329
 >> iter 10000, loss: 0.276480
   Number of active neurons: 6
 >> iter 11000, loss: 0.139795
 >> iter 12000, loss: 0.086802
 >> iter 13000, loss: 0.065638
 >> iter 14000, loss: 0.056615
 >> iter 15000, loss: 0.052380
 >> iter 16000, loss: 0.050136
 >> iter 17000, loss: 0.048778
 >> iter 18000, loss: 0.047876
 >> iter 19000, loss: 0.047192
 >> iter 20000, loss: 0.046668
   Number of active neurons: 6
 >> iter 21000, loss: 0.046175
 >> iter 22000, loss: 0.045672
 >> iter 23000, loss: 0.045110
 >> iter 24000, loss: 0.044577
 >> iter 25000, loss: 0.044103
 >> iter 26000, loss: 0.043687
 >> iter 27000, loss: 0.043301
 >> iter 28000, loss: 0.042956
 >> iter 29000, loss: 0.042554
 >> iter 30000, loss: 0.042078
   Number of active neurons: 6
 >> iter 31000, loss: 0.041626
 >> iter 32000, loss: 0.041254
 >> iter 33000, loss: 0.040915
 >> iter 34000, loss: 0.040644
 >> iter 35000, loss: 0.040415
 >> iter 36000, loss: 0.040236
 >> iter 37000, loss: 0.040067
 >> iter 38000, loss: 0.039882
 >> iter 39000, loss: 0.039676
 >> iter 40000, loss: 0.039489
   Number of active neurons: 6
 >> iter 41000, loss: 0.039367
 >> iter 42000, loss: 0.039269
 >> iter 43000, loss: 0.039218
 >> iter 44000, loss: 0.039175
 >> iter 45000, loss: 0.039136
 >> iter 46000, loss: 0.039144
 >> iter 47000, loss: 0.039168
 >> iter 48000, loss: 0.039208
 >> iter 49000, loss: 0.039228
 >> iter 50000, loss: 0.039248
   Number of active neurons: 6
 >> iter 51000, loss: 0.039297
 >> iter 52000, loss: 0.039239
 >> iter 53000, loss: 0.039112
 >> iter 54000, loss: 0.038995
 >> iter 55000, loss: 0.038927
 >> iter 56000, loss: 0.038877
 >> iter 57000, loss: 0.038859
 >> iter 58000, loss: 0.038841
 >> iter 59000, loss: 0.038846
 >> iter 60000, loss: 0.038838
   Number of active neurons: 6
 >> iter 61000, loss: 0.038789
 >> iter 62000, loss: 0.038696
 >> iter 63000, loss: 0.038619
 >> iter 64000, loss: 0.038500
 >> iter 65000, loss: 0.038292
 >> iter 66000, loss: 0.037956
 >> iter 67000, loss: 0.037533
 >> iter 68000, loss: 0.037125
 >> iter 69000, loss: 0.036745
 >> iter 70000, loss: 0.036407
   Number of active neurons: 6
 >> iter 71000, loss: 0.036081
 >> iter 72000, loss: 0.035782
 >> iter 73000, loss: 0.035462
 >> iter 74000, loss: 0.035156
 >> iter 75000, loss: 0.034822
 >> iter 76000, loss: 0.034520
 >> iter 77000, loss: 0.034227
 >> iter 78000, loss: 0.033977
 >> iter 79000, loss: 0.033758
 >> iter 80000, loss: 0.033579
   Number of active neurons: 4
 >> iter 81000, loss: 0.033429
 >> iter 82000, loss: 0.033312
 >> iter 83000, loss: 0.033202
 >> iter 84000, loss: 0.033122
 >> iter 85000, loss: 0.033042
 >> iter 86000, loss: 0.032980
 >> iter 87000, loss: 0.032920
 >> iter 88000, loss: 0.032875
 >> iter 89000, loss: 0.032822
 >> iter 90000, loss: 0.032791
   Number of active neurons: 4
 >> iter 91000, loss: 0.032745
 >> iter 92000, loss: 0.032724
 >> iter 93000, loss: 0.032683
 >> iter 94000, loss: 0.032665
 >> iter 95000, loss: 0.032629
 >> iter 96000, loss: 0.032614
 >> iter 97000, loss: 0.032585
 >> iter 98000, loss: 0.032573
 >> iter 99000, loss: 0.032552
 >> iter 100000, loss: 0.032540
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 15.584366
 >> iter 2000, loss: 10.520773
 >> iter 3000, loss: 8.652394
 >> iter 4000, loss: 7.925133
 >> iter 5000, loss: 7.675023
 >> iter 6000, loss: 7.547523
 >> iter 7000, loss: 7.377997
 >> iter 8000, loss: 7.017636
 >> iter 9000, loss: 6.255503
 >> iter 10000, loss: 2.704327
   Number of active neurons: 7
 >> iter 11000, loss: 1.312676
 >> iter 12000, loss: 0.576362
 >> iter 13000, loss: 0.284783
 >> iter 14000, loss: 0.148634
 >> iter 15000, loss: 0.096837
 >> iter 16000, loss: 0.075369
 >> iter 17000, loss: 0.065618
 >> iter 18000, loss: 0.066578
 >> iter 19000, loss: 1.926897
 >> iter 20000, loss: 0.788479
   Number of active neurons: 7
 >> iter 21000, loss: 0.346191
 >> iter 22000, loss: 0.174388
 >> iter 23000, loss: 0.106686
 >> iter 24000, loss: 0.078896
 >> iter 25000, loss: 0.067073
 >> iter 26000, loss: 0.061344
 >> iter 27000, loss: 0.058339
 >> iter 28000, loss: 0.056376
 >> iter 29000, loss: 0.054994
 >> iter 30000, loss: 0.053950
   Number of active neurons: 6
 >> iter 31000, loss: 0.052963
 >> iter 32000, loss: 0.052145
 >> iter 33000, loss: 0.051246
 >> iter 34000, loss: 0.050595
 >> iter 35000, loss: 0.049714
 >> iter 36000, loss: 0.049109
 >> iter 37000, loss: 0.048241
 >> iter 38000, loss: 0.047737
 >> iter 39000, loss: 0.046956
 >> iter 40000, loss: 0.046575
   Number of active neurons: 6
 >> iter 41000, loss: 0.045930
 >> iter 42000, loss: 0.045696
 >> iter 43000, loss: 0.045205
 >> iter 44000, loss: 0.045045
 >> iter 45000, loss: 0.044625
 >> iter 46000, loss: 0.044496
 >> iter 47000, loss: 0.044142
 >> iter 48000, loss: 0.044042
 >> iter 49000, loss: 0.043687
 >> iter 50000, loss: 0.043624
   Number of active neurons: 6
 >> iter 51000, loss: 0.043353
 >> iter 52000, loss: 0.043331
 >> iter 53000, loss: 0.043114
 >> iter 54000, loss: 0.043057
 >> iter 55000, loss: 0.042771
 >> iter 56000, loss: 0.042634
 >> iter 57000, loss: 0.042417
 >> iter 58000, loss: 0.042284
 >> iter 59000, loss: 0.042243
 >> iter 60000, loss: 0.042000
   Number of active neurons: 6
 >> iter 61000, loss: 0.042074
 >> iter 62000, loss: 0.041477
 >> iter 63000, loss: 0.041650
 >> iter 64000, loss: 0.040901
 >> iter 65000, loss: 0.041312
 >> iter 66000, loss: 0.040364
 >> iter 67000, loss: 0.127587
 >> iter 68000, loss: 0.072719
 >> iter 69000, loss: 0.137311
 >> iter 70000, loss: 0.076659
   Number of active neurons: 6
 >> iter 71000, loss: 0.176619
 >> iter 72000, loss: 0.091931
 >> iter 73000, loss: 0.073286
 >> iter 74000, loss: 0.053088
 >> iter 75000, loss: 0.231565
 >> iter 76000, loss: 0.113011
 >> iter 77000, loss: 0.068178
 >> iter 78000, loss: 0.051192
 >> iter 79000, loss: 0.061188
 >> iter 80000, loss: 0.048638
   Number of active neurons: 6
 >> iter 81000, loss: 0.103615
 >> iter 82000, loss: 0.062864
 >> iter 83000, loss: 0.048124
 >> iter 84000, loss: 0.043123
 >> iter 85000, loss: 0.057913
 >> iter 86000, loss: 0.046695
 >> iter 87000, loss: 0.063694
 >> iter 88000, loss: 0.048283
 >> iter 89000, loss: 0.042703
 >> iter 90000, loss: 0.040904
   Number of active neurons: 6
 >> iter 91000, loss: 0.108103
 >> iter 92000, loss: 0.064386
 >> iter 93000, loss: 0.053680
 >> iter 94000, loss: 0.044944
 >> iter 95000, loss: 0.069838
 >> iter 96000, loss: 0.049783
 >> iter 97000, loss: 0.042892
 >> iter 98000, loss: 0.040602
 >> iter 99000, loss: 0.494952
 >> iter 100000, loss: 0.212806
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.547724
 >> iter 2000, loss: 10.491290
 >> iter 3000, loss: 8.628714
 >> iter 4000, loss: 7.926232
 >> iter 5000, loss: 7.704399
 >> iter 6000, loss: 7.618335
 >> iter 7000, loss: 7.385960
 >> iter 8000, loss: 4.951647
 >> iter 9000, loss: 1.906990
 >> iter 10000, loss: 0.748349
   Number of active neurons: 5
 >> iter 11000, loss: 0.311808
 >> iter 12000, loss: 0.146237
 >> iter 13000, loss: 0.083057
 >> iter 14000, loss: 0.058373
 >> iter 15000, loss: 0.048751
 >> iter 16000, loss: 0.044742
 >> iter 17000, loss: 0.043227
 >> iter 18000, loss: 0.042394
 >> iter 19000, loss: 0.042124
 >> iter 20000, loss: 0.041822
   Number of active neurons: 5
 >> iter 21000, loss: 0.041776
 >> iter 22000, loss: 0.041669
 >> iter 23000, loss: 0.041698
 >> iter 24000, loss: 0.041638
 >> iter 25000, loss: 0.041674
 >> iter 26000, loss: 0.041625
 >> iter 27000, loss: 0.041546
 >> iter 28000, loss: 0.041404
 >> iter 29000, loss: 0.041283
 >> iter 30000, loss: 0.041139
   Number of active neurons: 4
 >> iter 31000, loss: 0.040894
 >> iter 32000, loss: 0.040558
 >> iter 33000, loss: 0.040188
 >> iter 34000, loss: 0.039835
 >> iter 35000, loss: 0.039454
 >> iter 36000, loss: 0.039089
 >> iter 37000, loss: 0.038686
 >> iter 38000, loss: 0.038381
 >> iter 39000, loss: 0.038064
 >> iter 40000, loss: 0.037807
   Number of active neurons: 5
 >> iter 41000, loss: 0.037523
 >> iter 42000, loss: 0.037333
 >> iter 43000, loss: 0.037135
 >> iter 44000, loss: 0.037012
 >> iter 45000, loss: 0.036856
 >> iter 46000, loss: 0.036681
 >> iter 47000, loss: 0.036403
 >> iter 48000, loss: 0.036215
 >> iter 49000, loss: 0.036003
 >> iter 50000, loss: 0.035880
   Number of active neurons: 5
 >> iter 51000, loss: 0.035712
 >> iter 52000, loss: 0.035621
 >> iter 53000, loss: 0.035470
 >> iter 54000, loss: 0.035421
 >> iter 55000, loss: 0.035269
 >> iter 56000, loss: 0.035248
 >> iter 57000, loss: 0.035106
 >> iter 58000, loss: 0.035106
 >> iter 59000, loss: 0.034943
 >> iter 60000, loss: 0.034902
   Number of active neurons: 5
 >> iter 61000, loss: 0.034704
 >> iter 62000, loss: 0.034631
 >> iter 63000, loss: 0.034437
 >> iter 64000, loss: 0.034415
 >> iter 65000, loss: 0.034275
 >> iter 66000, loss: 0.034289
 >> iter 67000, loss: 0.034177
 >> iter 68000, loss: 0.034218
 >> iter 69000, loss: 0.034124
 >> iter 70000, loss: 0.034173
   Number of active neurons: 5
 >> iter 71000, loss: 0.034093
 >> iter 72000, loss: 0.034120
 >> iter 73000, loss: 0.034006
 >> iter 74000, loss: 0.034026
 >> iter 75000, loss: 0.033938
 >> iter 76000, loss: 0.033983
 >> iter 77000, loss: 0.033909
 >> iter 78000, loss: 0.033969
 >> iter 79000, loss: 0.033917
 >> iter 80000, loss: 0.033976
   Number of active neurons: 5
 >> iter 81000, loss: 0.033925
 >> iter 82000, loss: 0.033996
 >> iter 83000, loss: 0.033940
 >> iter 84000, loss: 0.034017
 >> iter 85000, loss: 0.033962
 >> iter 86000, loss: 0.034047
 >> iter 87000, loss: 0.033988
 >> iter 88000, loss: 0.034071
 >> iter 89000, loss: 0.034013
 >> iter 90000, loss: 0.034098
   Number of active neurons: 5
 >> iter 91000, loss: 0.034034
 >> iter 92000, loss: 0.034125
 >> iter 93000, loss: 0.034057
 >> iter 94000, loss: 0.034144
 >> iter 95000, loss: 0.034089
 >> iter 96000, loss: 0.034164
 >> iter 97000, loss: 0.034115
 >> iter 98000, loss: 0.034187
 >> iter 99000, loss: 0.034140
 >> iter 100000, loss: 0.034211
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.608388
 >> iter 2000, loss: 10.490881
 >> iter 3000, loss: 8.610121
 >> iter 4000, loss: 7.890062
 >> iter 5000, loss: 7.646792
 >> iter 6000, loss: 7.525695
 >> iter 7000, loss: 7.499371
 >> iter 8000, loss: 7.414770
 >> iter 9000, loss: 7.210606
 >> iter 10000, loss: 6.966652
   Number of active neurons: 4
 >> iter 11000, loss: 5.705671
 >> iter 12000, loss: 2.311875
 >> iter 13000, loss: 0.929855
 >> iter 14000, loss: 0.397762
 >> iter 15000, loss: 0.192596
 >> iter 16000, loss: 0.111285
 >> iter 17000, loss: 0.102509
 >> iter 18000, loss: 0.073282
 >> iter 19000, loss: 0.061289
 >> iter 20000, loss: 0.054829
   Number of active neurons: 4
 >> iter 21000, loss: 0.052395
 >> iter 22000, loss: 0.050918
 >> iter 23000, loss: 0.052104
 >> iter 24000, loss: 0.152818
 >> iter 25000, loss: 0.112521
 >> iter 26000, loss: 0.169765
 >> iter 27000, loss: 0.113734
 >> iter 28000, loss: 0.127983
 >> iter 29000, loss: 0.108439
 >> iter 30000, loss: 0.125644
   Number of active neurons: 4
 >> iter 31000, loss: 0.380317
 >> iter 32000, loss: 0.175125
 >> iter 33000, loss: 0.114492
 >> iter 34000, loss: 0.073357
 >> iter 35000, loss: 0.314881
 >> iter 36000, loss: 0.148123
 >> iter 37000, loss: 0.107997
 >> iter 38000, loss: 0.070786
 >> iter 39000, loss: 0.079804
 >> iter 40000, loss: 0.356766
   Number of active neurons: 4
 >> iter 41000, loss: 0.237727
 >> iter 42000, loss: 0.175731
 >> iter 43000, loss: 0.362956
 >> iter 44000, loss: 0.325852
 >> iter 45000, loss: 0.176169
 >> iter 46000, loss: 0.329366
 >> iter 47000, loss: 0.180507
 >> iter 48000, loss: 0.112427
 >> iter 49000, loss: 0.225042
 >> iter 50000, loss: 0.231842
   Number of active neurons: 4
 >> iter 51000, loss: 0.157660
 >> iter 52000, loss: 0.369467
 >> iter 53000, loss: 0.236523
 >> iter 54000, loss: 0.234374
 >> iter 55000, loss: 0.147121
 >> iter 56000, loss: 0.209524
 >> iter 57000, loss: 0.142186
 >> iter 58000, loss: 0.143427
 >> iter 59000, loss: 0.113314
 >> iter 60000, loss: 0.197871
   Number of active neurons: 4
 >> iter 61000, loss: 0.105335
 >> iter 62000, loss: 0.185710
 >> iter 63000, loss: 0.239722
 >> iter 64000, loss: 0.246701
 >> iter 65000, loss: 0.132687
 >> iter 66000, loss: 0.157450
 >> iter 67000, loss: 0.180750
 >> iter 68000, loss: 0.275287
 >> iter 69000, loss: 0.383659
 >> iter 70000, loss: 0.326739
   Number of active neurons: 4
 >> iter 71000, loss: 0.182423
 >> iter 72000, loss: 0.240156
 >> iter 73000, loss: 0.536258
 >> iter 74000, loss: 0.247200
 >> iter 75000, loss: 0.381331
 >> iter 76000, loss: 0.954612
 >> iter 77000, loss: 0.611323
 >> iter 78000, loss: 0.394394
 >> iter 79000, loss: 0.245722
 >> iter 80000, loss: 0.152909
   Number of active neurons: 4
 >> iter 81000, loss: 0.482719
 >> iter 82000, loss: 0.325349
 >> iter 83000, loss: 0.204599
 >> iter 84000, loss: 0.162871
 >> iter 85000, loss: 0.163160
 >> iter 86000, loss: 0.159283
 >> iter 87000, loss: 0.156825
 >> iter 88000, loss: 0.432507
 >> iter 89000, loss: 0.234594
 >> iter 90000, loss: 0.143632
   Number of active neurons: 4
 >> iter 91000, loss: 0.135969
 >> iter 92000, loss: 0.116728
 >> iter 93000, loss: 0.098554
 >> iter 94000, loss: 0.090577
 >> iter 95000, loss: 0.409837
 >> iter 96000, loss: 0.223777
 >> iter 97000, loss: 0.130241
 >> iter 98000, loss: 0.104706
 >> iter 99000, loss: 0.089088
 >> iter 100000, loss: 0.249676
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0219995600088
   - Test - Long: 0.254987250637
   - Test - Big: 0.0309996900031
   - Test - A: 14.4657022865
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.624684
 >> iter 2000, loss: 10.542489
 >> iter 3000, loss: 8.668877
 >> iter 4000, loss: 7.941171
 >> iter 5000, loss: 7.684659
 >> iter 6000, loss: 7.651092
 >> iter 7000, loss: 7.559797
 >> iter 8000, loss: 7.164307
 >> iter 9000, loss: 4.494317
 >> iter 10000, loss: 1.716760
   Number of active neurons: 6
 >> iter 11000, loss: 0.672263
 >> iter 12000, loss: 0.281103
 >> iter 13000, loss: 0.134101
 >> iter 14000, loss: 0.078106
 >> iter 15000, loss: 0.056533
 >> iter 16000, loss: 0.047728
 >> iter 17000, loss: 0.044028
 >> iter 18000, loss: 0.042096
 >> iter 19000, loss: 0.041106
 >> iter 20000, loss: 0.040342
   Number of active neurons: 6
 >> iter 21000, loss: 0.039913
 >> iter 22000, loss: 0.039450
 >> iter 23000, loss: 0.039159
 >> iter 24000, loss: 0.038819
 >> iter 25000, loss: 0.038570
 >> iter 26000, loss: 0.038256
 >> iter 27000, loss: 0.038007
 >> iter 28000, loss: 0.037799
 >> iter 29000, loss: 0.037573
 >> iter 30000, loss: 0.037315
   Number of active neurons: 6
 >> iter 31000, loss: 0.037028
 >> iter 32000, loss: 0.036834
 >> iter 33000, loss: 0.036589
 >> iter 34000, loss: 0.036449
 >> iter 35000, loss: 0.036252
 >> iter 36000, loss: 0.036134
 >> iter 37000, loss: 0.035873
 >> iter 38000, loss: 0.035752
 >> iter 39000, loss: 0.035538
 >> iter 40000, loss: 0.035484
   Number of active neurons: 6
 >> iter 41000, loss: 0.035314
 >> iter 42000, loss: 0.035281
 >> iter 43000, loss: 0.035084
 >> iter 44000, loss: 0.035010
 >> iter 45000, loss: 0.034750
 >> iter 46000, loss: 0.034635
 >> iter 47000, loss: 0.034397
 >> iter 48000, loss: 0.034267
 >> iter 49000, loss: 0.034032
 >> iter 50000, loss: 0.033859
   Number of active neurons: 6
 >> iter 51000, loss: 0.033525
 >> iter 52000, loss: 0.033220
 >> iter 53000, loss: 0.032838
 >> iter 54000, loss: 0.032535
 >> iter 55000, loss: 0.032126
 >> iter 56000, loss: 0.031906
 >> iter 57000, loss: 0.031570
 >> iter 58000, loss: 0.031434
 >> iter 59000, loss: 0.031119
 >> iter 60000, loss: 0.030996
   Number of active neurons: 6
 >> iter 61000, loss: 0.030682
 >> iter 62000, loss: 0.030648
 >> iter 63000, loss: 0.030447
 >> iter 64000, loss: 0.030519
 >> iter 65000, loss: 0.030363
 >> iter 66000, loss: 0.030460
 >> iter 67000, loss: 0.030297
 >> iter 68000, loss: 0.030395
 >> iter 69000, loss: 0.030210
 >> iter 70000, loss: 0.030295
   Number of active neurons: 6
 >> iter 71000, loss: 0.030097
 >> iter 72000, loss: 0.030186
 >> iter 73000, loss: 0.029977
 >> iter 74000, loss: 0.030049
 >> iter 75000, loss: 0.029792
 >> iter 76000, loss: 0.029862
 >> iter 77000, loss: 0.029619
 >> iter 78000, loss: 0.029681
 >> iter 79000, loss: 0.029348
 >> iter 80000, loss: 0.029345
   Number of active neurons: 6
 >> iter 81000, loss: 0.029058
 >> iter 82000, loss: 0.029131
 >> iter 83000, loss: 0.028883
 >> iter 84000, loss: 0.029002
 >> iter 85000, loss: 0.028773
 >> iter 86000, loss: 0.028914
 >> iter 87000, loss: 0.028688
 >> iter 88000, loss: 0.028837
 >> iter 89000, loss: 0.028616
 >> iter 90000, loss: 0.028773
   Number of active neurons: 6
 >> iter 91000, loss: 0.028552
 >> iter 92000, loss: 0.028720
 >> iter 93000, loss: 0.028498
 >> iter 94000, loss: 0.028664
 >> iter 95000, loss: 0.028460
 >> iter 96000, loss: 0.028628
 >> iter 97000, loss: 0.028421
 >> iter 98000, loss: 0.028591
 >> iter 99000, loss: 0.028389
 >> iter 100000, loss: 0.028559
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.687188
 >> iter 2000, loss: 10.561280
 >> iter 3000, loss: 8.671932
 >> iter 4000, loss: 7.935542
 >> iter 5000, loss: 7.695376
 >> iter 6000, loss: 7.577288
 >> iter 7000, loss: 7.046043
 >> iter 8000, loss: 4.717523
 >> iter 9000, loss: 1.846204
 >> iter 10000, loss: 0.743237
   Number of active neurons: 7
 >> iter 11000, loss: 0.322297
 >> iter 12000, loss: 0.161723
 >> iter 13000, loss: 0.099482
 >> iter 14000, loss: 0.074818
 >> iter 15000, loss: 0.064741
 >> iter 16000, loss: 0.060146
 >> iter 17000, loss: 0.058090
 >> iter 18000, loss: 0.056629
 >> iter 19000, loss: 0.055910
 >> iter 20000, loss: 0.055032
   Number of active neurons: 7
 >> iter 21000, loss: 0.054685
 >> iter 22000, loss: 0.054212
 >> iter 23000, loss: 0.054106
 >> iter 24000, loss: 0.053857
 >> iter 25000, loss: 0.053817
 >> iter 26000, loss: 0.053618
 >> iter 27000, loss: 0.053516
 >> iter 28000, loss: 0.053324
 >> iter 29000, loss: 0.053202
 >> iter 30000, loss: 0.052991
   Number of active neurons: 7
 >> iter 31000, loss: 0.052743
 >> iter 32000, loss: 0.052408
 >> iter 33000, loss: 0.052184
 >> iter 34000, loss: 0.051852
 >> iter 35000, loss: 0.051630
 >> iter 36000, loss: 0.051301
 >> iter 37000, loss: 0.051100
 >> iter 38000, loss: 0.050768
 >> iter 39000, loss: 0.050493
 >> iter 40000, loss: 0.050169
   Number of active neurons: 7
 >> iter 41000, loss: 0.049933
 >> iter 42000, loss: 0.049685
 >> iter 43000, loss: 0.049486
 >> iter 44000, loss: 0.049251
 >> iter 45000, loss: 0.048970
 >> iter 46000, loss: 0.048556
 >> iter 47000, loss: 0.048184
 >> iter 48000, loss: 0.047799
 >> iter 49000, loss: 0.047604
 >> iter 50000, loss: 0.047354
   Number of active neurons: 6
 >> iter 51000, loss: 0.047291
 >> iter 52000, loss: 0.047106
 >> iter 53000, loss: 0.047109
 >> iter 54000, loss: 0.046954
 >> iter 55000, loss: 0.046996
 >> iter 56000, loss: 0.046843
 >> iter 57000, loss: 0.046888
 >> iter 58000, loss: 0.046704
 >> iter 59000, loss: 0.046752
 >> iter 60000, loss: 0.046567
   Number of active neurons: 6
 >> iter 61000, loss: 0.046885
 >> iter 62000, loss: 0.046600
 >> iter 63000, loss: 0.047961
 >> iter 64000, loss: 0.047170
 >> iter 65000, loss: 0.047740
 >> iter 66000, loss: 0.047218
 >> iter 67000, loss: 0.047206
 >> iter 68000, loss: 0.047372
 >> iter 69000, loss: 0.047540
 >> iter 70000, loss: 0.047816
   Number of active neurons: 6
 >> iter 71000, loss: 0.047978
 >> iter 72000, loss: 0.048198
 >> iter 73000, loss: 0.048303
 >> iter 74000, loss: 0.048484
 >> iter 75000, loss: 0.048637
 >> iter 76000, loss: 0.048822
 >> iter 77000, loss: 0.048959
 >> iter 78000, loss: 0.049061
 >> iter 79000, loss: 0.049160
 >> iter 80000, loss: 0.049267
   Number of active neurons: 6
 >> iter 81000, loss: 0.049345
 >> iter 82000, loss: 0.049439
 >> iter 83000, loss: 0.049394
 >> iter 84000, loss: 0.049371
 >> iter 85000, loss: 0.049203
 >> iter 86000, loss: 0.049105
 >> iter 87000, loss: 0.048795
 >> iter 88000, loss: 0.048628
 >> iter 89000, loss: 0.048249
 >> iter 90000, loss: 0.048168
   Number of active neurons: 5
 >> iter 91000, loss: 0.047752
 >> iter 92000, loss: 0.047947
 >> iter 93000, loss: 0.047410
 >> iter 94000, loss: 0.047423
 >> iter 95000, loss: 0.047364
 >> iter 96000, loss: 0.046589
 >> iter 97000, loss: 0.046452
 >> iter 98000, loss: 0.045982
 >> iter 99000, loss: 0.045956
 >> iter 100000, loss: 0.045406
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.00599988000241
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.728135
 >> iter 2000, loss: 10.555673
 >> iter 3000, loss: 8.648189
 >> iter 4000, loss: 7.907585
 >> iter 5000, loss: 7.674282
 >> iter 6000, loss: 7.588864
 >> iter 7000, loss: 7.308977
 >> iter 8000, loss: 3.848970
 >> iter 9000, loss: 1.472881
 >> iter 10000, loss: 0.580912
   Number of active neurons: 5
 >> iter 11000, loss: 0.246784
 >> iter 12000, loss: 0.120640
 >> iter 13000, loss: 0.072505
 >> iter 14000, loss: 0.053490
 >> iter 15000, loss: 0.045822
 >> iter 16000, loss: 0.042324
 >> iter 17000, loss: 0.040757
 >> iter 18000, loss: 0.039776
 >> iter 19000, loss: 0.039308
 >> iter 20000, loss: 0.038794
   Number of active neurons: 5
 >> iter 21000, loss: 0.038418
 >> iter 22000, loss: 0.037957
 >> iter 23000, loss: 0.037703
 >> iter 24000, loss: 0.037451
 >> iter 25000, loss: 0.037306
 >> iter 26000, loss: 0.037133
 >> iter 27000, loss: 0.037014
 >> iter 28000, loss: 0.036812
 >> iter 29000, loss: 0.036630
 >> iter 30000, loss: 0.036460
   Number of active neurons: 5
 >> iter 31000, loss: 0.036252
 >> iter 32000, loss: 0.036039
 >> iter 33000, loss: 0.035860
 >> iter 34000, loss: 0.035678
 >> iter 35000, loss: 0.035524
 >> iter 36000, loss: 0.035365
 >> iter 37000, loss: 0.035226
 >> iter 38000, loss: 0.035098
 >> iter 39000, loss: 0.034961
 >> iter 40000, loss: 0.034841
   Number of active neurons: 5
 >> iter 41000, loss: 0.034713
 >> iter 42000, loss: 0.034587
 >> iter 43000, loss: 0.034464
 >> iter 44000, loss: 0.034337
 >> iter 45000, loss: 0.034219
 >> iter 46000, loss: 0.034063
 >> iter 47000, loss: 0.033908
 >> iter 48000, loss: 0.033771
 >> iter 49000, loss: 0.033674
 >> iter 50000, loss: 0.033587
   Number of active neurons: 5
 >> iter 51000, loss: 0.033524
 >> iter 52000, loss: 0.033462
 >> iter 53000, loss: 0.033403
 >> iter 54000, loss: 0.033380
 >> iter 55000, loss: 0.033307
 >> iter 56000, loss: 0.033304
 >> iter 57000, loss: 0.033227
 >> iter 58000, loss: 0.033217
 >> iter 59000, loss: 0.033076
 >> iter 60000, loss: 0.033045
   Number of active neurons: 5
 >> iter 61000, loss: 0.032918
 >> iter 62000, loss: 0.032871
 >> iter 63000, loss: 0.032704
 >> iter 64000, loss: 0.032708
 >> iter 65000, loss: 0.032597
 >> iter 66000, loss: 0.032650
 >> iter 67000, loss: 0.032566
 >> iter 68000, loss: 0.032644
 >> iter 69000, loss: 0.032555
 >> iter 70000, loss: 0.032632
   Number of active neurons: 5
 >> iter 71000, loss: 0.032536
 >> iter 72000, loss: 0.032611
 >> iter 73000, loss: 0.032507
 >> iter 74000, loss: 0.032576
 >> iter 75000, loss: 0.032465
 >> iter 76000, loss: 0.032532
 >> iter 77000, loss: 0.032411
 >> iter 78000, loss: 0.032479
 >> iter 79000, loss: 0.032365
 >> iter 80000, loss: 0.032425
   Number of active neurons: 5
 >> iter 81000, loss: 0.032301
 >> iter 82000, loss: 0.032369
 >> iter 83000, loss: 0.032231
 >> iter 84000, loss: 0.032305
 >> iter 85000, loss: 0.032161
 >> iter 86000, loss: 0.032244
 >> iter 87000, loss: 0.032091
 >> iter 88000, loss: 0.032173
 >> iter 89000, loss: 0.032018
 >> iter 90000, loss: 0.032102
   Number of active neurons: 5
 >> iter 91000, loss: 0.031938
 >> iter 92000, loss: 0.032030
 >> iter 93000, loss: 0.031857
 >> iter 94000, loss: 0.031945
 >> iter 95000, loss: 0.031785
 >> iter 96000, loss: 0.031867
 >> iter 97000, loss: 0.031703
 >> iter 98000, loss: 0.031785
 >> iter 99000, loss: 0.031618
 >> iter 100000, loss: 0.031699
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.543461
 >> iter 2000, loss: 10.487280
 >> iter 3000, loss: 8.631136
 >> iter 4000, loss: 7.966938
 >> iter 5000, loss: 7.762734
 >> iter 6000, loss: 7.562262
 >> iter 7000, loss: 6.962520
 >> iter 8000, loss: 3.863864
 >> iter 9000, loss: 1.794696
 >> iter 10000, loss: 0.930860
   Number of active neurons: 6
 >> iter 11000, loss: 0.547592
 >> iter 12000, loss: 0.323172
 >> iter 13000, loss: 0.270189
 >> iter 14000, loss: 0.152266
 >> iter 15000, loss: 0.144987
 >> iter 16000, loss: 0.100061
 >> iter 17000, loss: 0.093905
 >> iter 18000, loss: 0.073047
 >> iter 19000, loss: 0.062988
 >> iter 20000, loss: 0.057117
   Number of active neurons: 6
 >> iter 21000, loss: 0.054481
 >> iter 22000, loss: 0.052349
 >> iter 23000, loss: 0.051669
 >> iter 24000, loss: 0.050740
 >> iter 25000, loss: 0.050783
 >> iter 26000, loss: 0.064721
 >> iter 27000, loss: 0.138951
 >> iter 28000, loss: 0.084545
 >> iter 29000, loss: 0.064346
 >> iter 30000, loss: 0.067808
   Number of active neurons: 5
 >> iter 31000, loss: 0.120730
 >> iter 32000, loss: 0.131762
 >> iter 33000, loss: 0.107213
 >> iter 34000, loss: 0.224199
 >> iter 35000, loss: 0.238203
 >> iter 36000, loss: 0.225572
 >> iter 37000, loss: 0.134863
 >> iter 38000, loss: 0.186346
 >> iter 39000, loss: 0.216016
 >> iter 40000, loss: 0.230970
   Number of active neurons: 4
 >> iter 41000, loss: 0.201779
 >> iter 42000, loss: 0.229761
 >> iter 43000, loss: 0.246956
 >> iter 44000, loss: 0.376203
 >> iter 45000, loss: 0.191289
 >> iter 46000, loss: 1.638316
 >> iter 47000, loss: 0.660872
 >> iter 48000, loss: 0.384970
 >> iter 49000, loss: 0.232558
 >> iter 50000, loss: 0.224126
   Number of active neurons: 4
 >> iter 51000, loss: 0.214280
 >> iter 52000, loss: 0.211116
 >> iter 53000, loss: 0.354028
 >> iter 54000, loss: 0.170585
 >> iter 55000, loss: 0.119965
 >> iter 56000, loss: 0.173127
 >> iter 57000, loss: 0.211800
 >> iter 58000, loss: 0.217932
 >> iter 59000, loss: 0.179605
 >> iter 60000, loss: 0.103813
   Number of active neurons: 4
 >> iter 61000, loss: 0.757560
 >> iter 62000, loss: 0.320158
 >> iter 63000, loss: 0.311045
 >> iter 64000, loss: 0.152247
 >> iter 65000, loss: 0.124972
 >> iter 66000, loss: 0.096173
 >> iter 67000, loss: 0.164247
 >> iter 68000, loss: 1.210387
 >> iter 69000, loss: 0.511370
 >> iter 70000, loss: 0.236215
   Number of active neurons: 4
 >> iter 71000, loss: 0.131831
 >> iter 72000, loss: 0.086398
 >> iter 73000, loss: 0.069802
 >> iter 74000, loss: 0.159581
 >> iter 75000, loss: 0.222242
 >> iter 76000, loss: 0.146964
 >> iter 77000, loss: 0.396800
 >> iter 78000, loss: 0.209706
 >> iter 79000, loss: 0.115786
 >> iter 80000, loss: 0.187053
   Number of active neurons: 4
 >> iter 81000, loss: 0.130561
 >> iter 82000, loss: 0.178703
 >> iter 83000, loss: 0.559137
 >> iter 84000, loss: 0.454799
 >> iter 85000, loss: 0.210111
 >> iter 86000, loss: 0.214203
 >> iter 87000, loss: 0.142991
 >> iter 88000, loss: 0.191186
 >> iter 89000, loss: 0.541310
 >> iter 90000, loss: 0.335022
   Number of active neurons: 4
 >> iter 91000, loss: 0.187101
 >> iter 92000, loss: 0.302792
 >> iter 93000, loss: 0.153780
 >> iter 94000, loss: 0.189990
 >> iter 95000, loss: 0.152468
 >> iter 96000, loss: 0.239600
 >> iter 97000, loss: 0.200946
 >> iter 98000, loss: 0.210634
 >> iter 99000, loss: 0.255992
 >> iter 100000, loss: 0.388507
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0039999200016
   - Test - Long: 0.244987750612
   - Test - Big: 0.00199998000021
   - Test - A: 13.0191320579
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.562626
 >> iter 2000, loss: 10.492859
 >> iter 3000, loss: 8.616275
 >> iter 4000, loss: 7.899544
 >> iter 5000, loss: 7.645418
 >> iter 6000, loss: 7.567598
 >> iter 7000, loss: 7.798183
 >> iter 8000, loss: 8.236635
 >> iter 9000, loss: 7.280791
 >> iter 10000, loss: 6.785044
   Number of active neurons: 5
 >> iter 11000, loss: 6.479658
 >> iter 12000, loss: 6.250892
 >> iter 13000, loss: 3.985530
 >> iter 14000, loss: 1.621157
 >> iter 15000, loss: 0.692744
 >> iter 16000, loss: 0.317717
 >> iter 17000, loss: 0.169502
 >> iter 18000, loss: 0.109519
 >> iter 19000, loss: 0.083446
 >> iter 20000, loss: 0.071499
   Number of active neurons: 5
 >> iter 21000, loss: 0.064767
 >> iter 22000, loss: 0.063290
 >> iter 23000, loss: 0.058004
 >> iter 24000, loss: 0.058552
 >> iter 25000, loss: 0.054980
 >> iter 26000, loss: 0.058193
 >> iter 27000, loss: 0.054154
 >> iter 28000, loss: 0.058924
 >> iter 29000, loss: 0.134410
 >> iter 30000, loss: 0.091559
   Number of active neurons: 5
 >> iter 31000, loss: 0.148083
 >> iter 32000, loss: 0.097674
 >> iter 33000, loss: 0.068555
 >> iter 34000, loss: 0.067551
 >> iter 35000, loss: 0.057934
 >> iter 36000, loss: 0.062217
 >> iter 37000, loss: 0.056723
 >> iter 38000, loss: 0.061373
 >> iter 39000, loss: 0.054988
 >> iter 40000, loss: 0.059603
   Number of active neurons: 5
 >> iter 41000, loss: 0.053562
 >> iter 42000, loss: 0.058841
 >> iter 43000, loss: 0.052717
 >> iter 44000, loss: 0.057676
 >> iter 45000, loss: 0.051848
 >> iter 46000, loss: 0.057366
 >> iter 47000, loss: 0.051172
 >> iter 48000, loss: 0.057183
 >> iter 49000, loss: 0.050607
 >> iter 50000, loss: 0.056585
   Number of active neurons: 5
 >> iter 51000, loss: 0.050107
 >> iter 52000, loss: 0.055940
 >> iter 53000, loss: 0.049460
 >> iter 54000, loss: 0.054768
 >> iter 55000, loss: 0.048777
 >> iter 56000, loss: 0.053125
 >> iter 57000, loss: 0.048049
 >> iter 58000, loss: 0.050509
 >> iter 59000, loss: 0.046829
 >> iter 60000, loss: 0.045603
   Number of active neurons: 5
 >> iter 61000, loss: 0.044704
 >> iter 62000, loss: 0.044494
 >> iter 63000, loss: 0.044251
 >> iter 64000, loss: 0.044030
 >> iter 65000, loss: 0.043903
 >> iter 66000, loss: 0.043725
 >> iter 67000, loss: 0.043625
 >> iter 68000, loss: 0.043523
 >> iter 69000, loss: 0.043409
 >> iter 70000, loss: 0.043378
   Number of active neurons: 5
 >> iter 71000, loss: 0.043268
 >> iter 72000, loss: 0.043272
 >> iter 73000, loss: 0.043138
 >> iter 74000, loss: 0.043135
 >> iter 75000, loss: 0.042890
 >> iter 76000, loss: 0.042786
 >> iter 77000, loss: 0.042559
 >> iter 78000, loss: 0.042487
 >> iter 79000, loss: 0.042311
 >> iter 80000, loss: 0.042286
   Number of active neurons: 5
 >> iter 81000, loss: 0.042142
 >> iter 82000, loss: 0.042163
 >> iter 83000, loss: 0.042026
 >> iter 84000, loss: 0.042107
 >> iter 85000, loss: 0.041950
 >> iter 86000, loss: 0.042116
 >> iter 87000, loss: 0.041892
 >> iter 88000, loss: 0.042178
 >> iter 89000, loss: 0.041852
 >> iter 90000, loss: 0.042237
   Number of active neurons: 5
 >> iter 91000, loss: 0.041796
 >> iter 92000, loss: 0.042279
 >> iter 93000, loss: 0.041746
 >> iter 94000, loss: 0.042279
 >> iter 95000, loss: 0.041709
 >> iter 96000, loss: 0.042270
 >> iter 97000, loss: 0.041684
 >> iter 98000, loss: 0.042245
 >> iter 99000, loss: 0.041647
 >> iter 100000, loss: 0.042201
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.532180
 >> iter 2000, loss: 10.469502
 >> iter 3000, loss: 8.610376
 >> iter 4000, loss: 7.891740
 >> iter 5000, loss: 7.666662
 >> iter 6000, loss: 7.601643
 >> iter 7000, loss: 7.528925
 >> iter 8000, loss: 7.222814
 >> iter 9000, loss: 3.122672
 >> iter 10000, loss: 1.213953
   Number of active neurons: 4
 >> iter 11000, loss: 0.492045
 >> iter 12000, loss: 0.218307
 >> iter 13000, loss: 0.113624
 >> iter 14000, loss: 0.072500
 >> iter 15000, loss: 0.055920
 >> iter 16000, loss: 0.048580
 >> iter 17000, loss: 0.045146
 >> iter 18000, loss: 0.043142
 >> iter 19000, loss: 0.042090
 >> iter 20000, loss: 0.041291
   Number of active neurons: 4
 >> iter 21000, loss: 0.040847
 >> iter 22000, loss: 0.040422
 >> iter 23000, loss: 0.040159
 >> iter 24000, loss: 0.039882
 >> iter 25000, loss: 0.039673
 >> iter 26000, loss: 0.039465
 >> iter 27000, loss: 0.039274
 >> iter 28000, loss: 0.039100
 >> iter 29000, loss: 0.038901
 >> iter 30000, loss: 0.038751
   Number of active neurons: 4
 >> iter 31000, loss: 0.038557
 >> iter 32000, loss: 0.038418
 >> iter 33000, loss: 0.038231
 >> iter 34000, loss: 0.038076
 >> iter 35000, loss: 0.037853
 >> iter 36000, loss: 0.037694
 >> iter 37000, loss: 0.037474
 >> iter 38000, loss: 0.037360
 >> iter 39000, loss: 0.037054
 >> iter 40000, loss: 0.036859
   Number of active neurons: 4
 >> iter 41000, loss: 0.036568
 >> iter 42000, loss: 0.036427
 >> iter 43000, loss: 0.036198
 >> iter 44000, loss: 0.036099
 >> iter 45000, loss: 0.035899
 >> iter 46000, loss: 0.035829
 >> iter 47000, loss: 0.035648
 >> iter 48000, loss: 0.035587
 >> iter 49000, loss: 0.035430
 >> iter 50000, loss: 0.035389
   Number of active neurons: 4
 >> iter 51000, loss: 0.035247
 >> iter 52000, loss: 0.035182
 >> iter 53000, loss: 0.034938
 >> iter 54000, loss: 0.034824
 >> iter 55000, loss: 0.034608
 >> iter 56000, loss: 0.034570
 >> iter 57000, loss: 0.034410
 >> iter 58000, loss: 0.034425
 >> iter 59000, loss: 0.034298
 >> iter 60000, loss: 0.034342
   Number of active neurons: 4
 >> iter 61000, loss: 0.034235
 >> iter 62000, loss: 0.034283
 >> iter 63000, loss: 0.034124
 >> iter 64000, loss: 0.034123
 >> iter 65000, loss: 0.033934
 >> iter 66000, loss: 0.033900
 >> iter 67000, loss: 0.033726
 >> iter 68000, loss: 0.033746
 >> iter 69000, loss: 0.033619
 >> iter 70000, loss: 0.033675
   Number of active neurons: 4
 >> iter 71000, loss: 0.033581
 >> iter 72000, loss: 0.033657
 >> iter 73000, loss: 0.033576
 >> iter 74000, loss: 0.033659
 >> iter 75000, loss: 0.033587
 >> iter 76000, loss: 0.033675
 >> iter 77000, loss: 0.033599
 >> iter 78000, loss: 0.033689
 >> iter 79000, loss: 0.033626
 >> iter 80000, loss: 0.033706
   Number of active neurons: 4
 >> iter 81000, loss: 0.033639
 >> iter 82000, loss: 0.033726
 >> iter 83000, loss: 0.033652
 >> iter 84000, loss: 0.033742
 >> iter 85000, loss: 0.033666
 >> iter 86000, loss: 0.033765
 >> iter 87000, loss: 0.033684
 >> iter 88000, loss: 0.033780
 >> iter 89000, loss: 0.033698
 >> iter 90000, loss: 0.033795
   Number of active neurons: 4
 >> iter 91000, loss: 0.033709
 >> iter 92000, loss: 0.033810
 >> iter 93000, loss: 0.033720
 >> iter 94000, loss: 0.033816
 >> iter 95000, loss: 0.033739
 >> iter 96000, loss: 0.033820
 >> iter 97000, loss: 0.033734
 >> iter 98000, loss: 0.033809
 >> iter 99000, loss: 0.033731
 >> iter 100000, loss: 0.033810
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.728545
 >> iter 2000, loss: 10.586873
 >> iter 3000, loss: 8.663771
 >> iter 4000, loss: 7.927609
 >> iter 5000, loss: 7.664622
 >> iter 6000, loss: 7.550451
 >> iter 7000, loss: 7.537661
 >> iter 8000, loss: 7.693796
 >> iter 9000, loss: 7.950026
 >> iter 10000, loss: 4.704852
   Number of active neurons: 5
 >> iter 11000, loss: 1.829778
 >> iter 12000, loss: 0.732096
 >> iter 13000, loss: 0.316040
 >> iter 14000, loss: 0.156812
 >> iter 15000, loss: 0.094919
 >> iter 16000, loss: 0.069682
 >> iter 17000, loss: 0.058870
 >> iter 18000, loss: 0.053579
 >> iter 19000, loss: 0.050781
 >> iter 20000, loss: 0.048987
   Number of active neurons: 5
 >> iter 21000, loss: 0.047787
 >> iter 22000, loss: 0.046781
 >> iter 23000, loss: 0.045848
 >> iter 24000, loss: 0.045079
 >> iter 25000, loss: 0.044382
 >> iter 26000, loss: 0.043806
 >> iter 27000, loss: 0.043283
 >> iter 28000, loss: 0.042902
 >> iter 29000, loss: 0.042523
 >> iter 30000, loss: 0.042245
   Number of active neurons: 5
 >> iter 31000, loss: 0.041873
 >> iter 32000, loss: 0.041583
 >> iter 33000, loss: 0.041288
 >> iter 34000, loss: 0.041054
 >> iter 35000, loss: 0.040678
 >> iter 36000, loss: 0.040315
 >> iter 37000, loss: 0.039948
 >> iter 38000, loss: 0.039628
 >> iter 39000, loss: 0.039384
 >> iter 40000, loss: 0.039172
   Number of active neurons: 5
 >> iter 41000, loss: 0.039031
 >> iter 42000, loss: 0.038859
 >> iter 43000, loss: 0.038684
 >> iter 44000, loss: 0.038467
 >> iter 45000, loss: 0.038292
 >> iter 46000, loss: 0.038086
 >> iter 47000, loss: 0.037929
 >> iter 48000, loss: 0.037771
 >> iter 49000, loss: 0.037715
 >> iter 50000, loss: 0.037578
   Number of active neurons: 5
 >> iter 51000, loss: 0.037447
 >> iter 52000, loss: 0.037293
 >> iter 53000, loss: 0.037179
 >> iter 54000, loss: 0.037054
 >> iter 55000, loss: 0.036904
 >> iter 56000, loss: 0.036707
 >> iter 57000, loss: 0.036427
 >> iter 58000, loss: 0.036183
 >> iter 59000, loss: 0.035904
 >> iter 60000, loss: 0.035664
   Number of active neurons: 5
 >> iter 61000, loss: 0.035369
 >> iter 62000, loss: 0.035114
 >> iter 63000, loss: 0.034857
 >> iter 64000, loss: 0.034667
 >> iter 65000, loss: 0.034445
 >> iter 66000, loss: 0.034148
 >> iter 67000, loss: 0.033779
 >> iter 68000, loss: 0.033505
 >> iter 69000, loss: 0.033244
 >> iter 70000, loss: 0.033084
   Number of active neurons: 5
 >> iter 71000, loss: 0.032923
 >> iter 72000, loss: 0.032844
 >> iter 73000, loss: 0.032737
 >> iter 74000, loss: 0.032699
 >> iter 75000, loss: 0.032625
 >> iter 76000, loss: 0.032611
 >> iter 77000, loss: 0.032547
 >> iter 78000, loss: 0.032548
 >> iter 79000, loss: 0.032501
 >> iter 80000, loss: 0.032505
   Number of active neurons: 5
 >> iter 81000, loss: 0.032459
 >> iter 82000, loss: 0.032475
 >> iter 83000, loss: 0.032428
 >> iter 84000, loss: 0.032450
 >> iter 85000, loss: 0.032404
 >> iter 86000, loss: 0.032435
 >> iter 87000, loss: 0.032386
 >> iter 88000, loss: 0.032418
 >> iter 89000, loss: 0.032369
 >> iter 90000, loss: 0.032405
   Number of active neurons: 5
 >> iter 91000, loss: 0.032352
 >> iter 92000, loss: 0.032394
 >> iter 93000, loss: 0.032336
 >> iter 94000, loss: 0.032377
 >> iter 95000, loss: 0.032329
 >> iter 96000, loss: 0.032362
 >> iter 97000, loss: 0.032320
 >> iter 98000, loss: 0.032350
 >> iter 99000, loss: 0.032310
 >> iter 100000, loss: 0.032340
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.598752
 >> iter 2000, loss: 10.499845
 >> iter 3000, loss: 8.623671
 >> iter 4000, loss: 7.898567
 >> iter 5000, loss: 7.664462
 >> iter 6000, loss: 7.584321
 >> iter 7000, loss: 7.278413
 >> iter 8000, loss: 4.353904
 >> iter 9000, loss: 1.835121
 >> iter 10000, loss: 0.815955
   Number of active neurons: 5
 >> iter 11000, loss: 0.374740
 >> iter 12000, loss: 0.199242
 >> iter 13000, loss: 0.134087
 >> iter 14000, loss: 0.095174
 >> iter 15000, loss: 0.093473
 >> iter 16000, loss: 0.080309
 >> iter 17000, loss: 0.084582
 >> iter 18000, loss: 0.092139
 >> iter 19000, loss: 0.096008
 >> iter 20000, loss: 0.097948
   Number of active neurons: 5
 >> iter 21000, loss: 0.101999
 >> iter 22000, loss: 0.105533
 >> iter 23000, loss: 0.233774
 >> iter 24000, loss: 6.967902
 >> iter 25000, loss: 7.279451
 >> iter 26000, loss: 6.446545
 >> iter 27000, loss: 3.406119
 >> iter 28000, loss: 1.331014
 >> iter 29000, loss: 0.540291
 >> iter 30000, loss: 0.244189
   Number of active neurons: 9
 >> iter 31000, loss: 0.127278
 >> iter 32000, loss: 0.082493
 >> iter 33000, loss: 0.065324
 >> iter 34000, loss: 0.058514
 >> iter 35000, loss: 0.055801
 >> iter 36000, loss: 0.054368
 >> iter 37000, loss: 0.053472
 >> iter 38000, loss: 0.052699
 >> iter 39000, loss: 0.052077
 >> iter 40000, loss: 0.051635
   Number of active neurons: 9
 >> iter 41000, loss: 0.051193
 >> iter 42000, loss: 0.050788
 >> iter 43000, loss: 0.050290
 >> iter 44000, loss: 0.049967
 >> iter 45000, loss: 0.049687
 >> iter 46000, loss: 0.049576
 >> iter 47000, loss: 0.049452
 >> iter 48000, loss: 0.049261
 >> iter 49000, loss: 0.048952
 >> iter 50000, loss: 0.048657
   Number of active neurons: 9
 >> iter 51000, loss: 0.048279
 >> iter 52000, loss: 0.047942
 >> iter 53000, loss: 0.047531
 >> iter 54000, loss: 0.047167
 >> iter 55000, loss: 0.046856
 >> iter 56000, loss: 0.046421
 >> iter 57000, loss: 0.046915
 >> iter 58000, loss: 0.045846
 >> iter 59000, loss: 0.104531
 >> iter 60000, loss: 0.067201
   Number of active neurons: 8
 >> iter 61000, loss: 0.117016
 >> iter 62000, loss: 0.071999
 >> iter 63000, loss: 0.117739
 >> iter 64000, loss: 0.072421
 >> iter 65000, loss: 0.096652
 >> iter 66000, loss: 0.065406
 >> iter 67000, loss: 0.053781
 >> iter 68000, loss: 0.048251
 >> iter 69000, loss: 0.046529
 >> iter 70000, loss: 0.045063
   Number of active neurons: 7
 >> iter 71000, loss: 0.044644
 >> iter 72000, loss: 0.043914
 >> iter 73000, loss: 0.043759
 >> iter 74000, loss: 0.043489
 >> iter 75000, loss: 0.043395
 >> iter 76000, loss: 0.043076
 >> iter 77000, loss: 0.042997
 >> iter 78000, loss: 0.042727
 >> iter 79000, loss: 0.042714
 >> iter 80000, loss: 0.042477
   Number of active neurons: 7
 >> iter 81000, loss: 0.042496
 >> iter 82000, loss: 0.042263
 >> iter 83000, loss: 0.042303
 >> iter 84000, loss: 0.042080
 >> iter 85000, loss: 0.042146
 >> iter 86000, loss: 0.041919
 >> iter 87000, loss: 0.041984
 >> iter 88000, loss: 0.041765
 >> iter 89000, loss: 0.041825
 >> iter 90000, loss: 0.041627
   Number of active neurons: 7
 >> iter 91000, loss: 0.041681
 >> iter 92000, loss: 0.041446
 >> iter 93000, loss: 0.041437
 >> iter 94000, loss: 0.041193
 >> iter 95000, loss: 0.041171
 >> iter 96000, loss: 0.040890
 >> iter 97000, loss: 0.040839
 >> iter 98000, loss: 0.040587
 >> iter 99000, loss: 0.040620
 >> iter 100000, loss: 0.040386
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.616690
 >> iter 2000, loss: 10.523141
 >> iter 3000, loss: 8.639233
 >> iter 4000, loss: 7.914803
 >> iter 5000, loss: 7.718179
 >> iter 6000, loss: 7.759706
 >> iter 7000, loss: 7.905766
 >> iter 8000, loss: 7.532105
 >> iter 9000, loss: 7.277441
 >> iter 10000, loss: 4.200524
   Number of active neurons: 9
 >> iter 11000, loss: 1.618631
 >> iter 12000, loss: 0.644821
 >> iter 13000, loss: 0.279095
 >> iter 14000, loss: 0.140649
 >> iter 15000, loss: 0.087236
 >> iter 16000, loss: 0.065729
 >> iter 17000, loss: 0.056489
 >> iter 18000, loss: 0.052005
 >> iter 19000, loss: 0.049580
 >> iter 20000, loss: 0.047852
   Number of active neurons: 8
 >> iter 21000, loss: 0.046613
 >> iter 22000, loss: 0.045600
 >> iter 23000, loss: 0.044920
 >> iter 24000, loss: 0.044116
 >> iter 25000, loss: 0.043491
 >> iter 26000, loss: 0.042935
 >> iter 27000, loss: 0.042599
 >> iter 28000, loss: 0.042142
 >> iter 29000, loss: 0.041914
 >> iter 30000, loss: 0.041507
   Number of active neurons: 8
 >> iter 31000, loss: 0.041222
 >> iter 32000, loss: 0.040803
 >> iter 33000, loss: 0.040598
 >> iter 34000, loss: 0.040195
 >> iter 35000, loss: 0.039764
 >> iter 36000, loss: 0.039111
 >> iter 37000, loss: 0.038413
 >> iter 38000, loss: 0.037568
 >> iter 39000, loss: 0.036847
 >> iter 40000, loss: 0.036261
   Number of active neurons: 8
 >> iter 41000, loss: 0.035872
 >> iter 42000, loss: 0.035566
 >> iter 43000, loss: 0.035362
 >> iter 44000, loss: 0.035140
 >> iter 45000, loss: 0.035011
 >> iter 46000, loss: 0.034862
 >> iter 47000, loss: 0.034782
 >> iter 48000, loss: 0.034690
 >> iter 49000, loss: 0.034660
 >> iter 50000, loss: 0.034595
   Number of active neurons: 8
 >> iter 51000, loss: 0.034570
 >> iter 52000, loss: 0.034501
 >> iter 53000, loss: 0.034458
 >> iter 54000, loss: 0.034392
 >> iter 55000, loss: 0.034323
 >> iter 56000, loss: 0.034257
 >> iter 57000, loss: 0.034176
 >> iter 58000, loss: 0.034111
 >> iter 59000, loss: 0.034021
 >> iter 60000, loss: 0.033960
   Number of active neurons: 8
 >> iter 61000, loss: 0.033871
 >> iter 62000, loss: 0.033810
 >> iter 63000, loss: 0.033724
 >> iter 64000, loss: 0.033672
 >> iter 65000, loss: 0.033590
 >> iter 66000, loss: 0.033542
 >> iter 67000, loss: 0.033463
 >> iter 68000, loss: 0.033424
 >> iter 69000, loss: 0.033350
 >> iter 70000, loss: 0.033316
   Number of active neurons: 8
 >> iter 71000, loss: 0.033249
 >> iter 72000, loss: 0.033144
 >> iter 73000, loss: 0.032937
 >> iter 74000, loss: 0.032797
 >> iter 75000, loss: 0.032643
 >> iter 76000, loss: 0.032570
 >> iter 77000, loss: 0.032466
 >> iter 78000, loss: 0.032439
 >> iter 79000, loss: 0.032373
 >> iter 80000, loss: 0.032365
   Number of active neurons: 8
 >> iter 81000, loss: 0.032312
 >> iter 82000, loss: 0.032322
 >> iter 83000, loss: 0.032274
 >> iter 84000, loss: 0.032294
 >> iter 85000, loss: 0.032250
 >> iter 86000, loss: 0.032282
 >> iter 87000, loss: 0.032235
 >> iter 88000, loss: 0.032270
 >> iter 89000, loss: 0.032225
 >> iter 90000, loss: 0.032263
   Number of active neurons: 8
 >> iter 91000, loss: 0.032213
 >> iter 92000, loss: 0.032258
 >> iter 93000, loss: 0.032204
 >> iter 94000, loss: 0.032248
 >> iter 95000, loss: 0.032204
 >> iter 96000, loss: 0.032240
 >> iter 97000, loss: 0.032202
 >> iter 98000, loss: 0.032235
 >> iter 99000, loss: 0.032198
 >> iter 100000, loss: 0.032231
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.596635
 >> iter 2000, loss: 10.507882
 >> iter 3000, loss: 8.633219
 >> iter 4000, loss: 7.918608
 >> iter 5000, loss: 7.700644
 >> iter 6000, loss: 7.607478
 >> iter 7000, loss: 6.904069
 >> iter 8000, loss: 3.053927
 >> iter 9000, loss: 1.198550
 >> iter 10000, loss: 0.492910
   Number of active neurons: 6
 >> iter 11000, loss: 0.225717
 >> iter 12000, loss: 0.122385
 >> iter 13000, loss: 0.082372
 >> iter 14000, loss: 0.065028
 >> iter 15000, loss: 0.058407
 >> iter 16000, loss: 0.054123
 >> iter 17000, loss: 0.052635
 >> iter 18000, loss: 0.050858
 >> iter 19000, loss: 0.050348
 >> iter 20000, loss: 0.049161
   Number of active neurons: 5
 >> iter 21000, loss: 0.048782
 >> iter 22000, loss: 0.047823
 >> iter 23000, loss: 0.047417
 >> iter 24000, loss: 0.046592
 >> iter 25000, loss: 0.046285
 >> iter 26000, loss: 0.045634
 >> iter 27000, loss: 0.045437
 >> iter 28000, loss: 0.045026
 >> iter 29000, loss: 0.044890
 >> iter 30000, loss: 0.044677
   Number of active neurons: 5
 >> iter 31000, loss: 0.044460
 >> iter 32000, loss: 0.044323
 >> iter 33000, loss: 0.044091
 >> iter 34000, loss: 0.043932
 >> iter 35000, loss: 0.043624
 >> iter 36000, loss: 0.043406
 >> iter 37000, loss: 0.043123
 >> iter 38000, loss: 0.042996
 >> iter 39000, loss: 0.042714
 >> iter 40000, loss: 0.042642
   Number of active neurons: 5
 >> iter 41000, loss: 0.042399
 >> iter 42000, loss: 0.042364
 >> iter 43000, loss: 0.042074
 >> iter 44000, loss: 0.042005
 >> iter 45000, loss: 0.041697
 >> iter 46000, loss: 0.041677
 >> iter 47000, loss: 0.041415
 >> iter 48000, loss: 0.041380
 >> iter 49000, loss: 0.041215
 >> iter 50000, loss: 0.041154
   Number of active neurons: 5
 >> iter 51000, loss: 0.041077
 >> iter 52000, loss: 0.040953
 >> iter 53000, loss: 0.040954
 >> iter 54000, loss: 0.040744
 >> iter 55000, loss: 0.040848
 >> iter 56000, loss: 0.040586
 >> iter 57000, loss: 0.040841
 >> iter 58000, loss: 0.040531
 >> iter 59000, loss: 0.040978
 >> iter 60000, loss: 0.040598
   Number of active neurons: 5
 >> iter 61000, loss: 0.041189
 >> iter 62000, loss: 0.040698
 >> iter 63000, loss: 0.041396
 >> iter 64000, loss: 0.040772
 >> iter 65000, loss: 0.041640
 >> iter 66000, loss: 0.040856
 >> iter 67000, loss: 0.042556
 >> iter 68000, loss: 0.041275
 >> iter 69000, loss: 0.055464
 >> iter 70000, loss: 0.046102
   Number of active neurons: 5
 >> iter 71000, loss: 0.055968
 >> iter 72000, loss: 0.046440
 >> iter 73000, loss: 0.055082
 >> iter 74000, loss: 0.046176
 >> iter 75000, loss: 0.044370
 >> iter 76000, loss: 0.042387
 >> iter 77000, loss: 0.043207
 >> iter 78000, loss: 0.042203
 >> iter 79000, loss: 0.042912
 >> iter 80000, loss: 0.042256
   Number of active neurons: 5
 >> iter 81000, loss: 0.042500
 >> iter 82000, loss: 0.042267
 >> iter 83000, loss: 0.042569
 >> iter 84000, loss: 0.042378
 >> iter 85000, loss: 0.042482
 >> iter 86000, loss: 0.042261
 >> iter 87000, loss: 0.042411
 >> iter 88000, loss: 0.042273
 >> iter 89000, loss: 0.042336
 >> iter 90000, loss: 0.042216
   Number of active neurons: 5
 >> iter 91000, loss: 0.042315
 >> iter 92000, loss: 0.042232
 >> iter 93000, loss: 0.042301
 >> iter 94000, loss: 0.042183
 >> iter 95000, loss: 0.042222
 >> iter 96000, loss: 0.042104
 >> iter 97000, loss: 0.042127
 >> iter 98000, loss: 0.042019
 >> iter 99000, loss: 0.042022
 >> iter 100000, loss: 0.041948
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 13.3857742817
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.562038
 >> iter 2000, loss: 10.494377
 >> iter 3000, loss: 8.629538
 >> iter 4000, loss: 7.910486
 >> iter 5000, loss: 7.696608
 >> iter 6000, loss: 7.765444
 >> iter 7000, loss: 7.651458
 >> iter 8000, loss: 6.290974
 >> iter 9000, loss: 2.502973
 >> iter 10000, loss: 1.014680
   Number of active neurons: 5
 >> iter 11000, loss: 0.428220
 >> iter 12000, loss: 0.202415
 >> iter 13000, loss: 0.114265
 >> iter 14000, loss: 0.078599
 >> iter 15000, loss: 0.063410
 >> iter 16000, loss: 0.056466
 >> iter 17000, loss: 0.052879
 >> iter 18000, loss: 0.051134
 >> iter 19000, loss: 0.050273
 >> iter 20000, loss: 0.049519
   Number of active neurons: 5
 >> iter 21000, loss: 0.129012
 >> iter 22000, loss: 0.082766
 >> iter 23000, loss: 0.076808
 >> iter 24000, loss: 0.059410
 >> iter 25000, loss: 0.055438
 >> iter 26000, loss: 0.056943
 >> iter 27000, loss: 0.050831
 >> iter 28000, loss: 0.048401
 >> iter 29000, loss: 0.066504
 >> iter 30000, loss: 0.090688
   Number of active neurons: 5
 >> iter 31000, loss: 0.078590
 >> iter 32000, loss: 0.059767
 >> iter 33000, loss: 0.077694
 >> iter 34000, loss: 0.057338
 >> iter 35000, loss: 0.281778
 >> iter 36000, loss: 0.174096
 >> iter 37000, loss: 0.095189
 >> iter 38000, loss: 0.064225
 >> iter 39000, loss: 0.066291
 >> iter 40000, loss: 0.052770
   Number of active neurons: 4
 >> iter 41000, loss: 0.049159
 >> iter 42000, loss: 0.045240
 >> iter 43000, loss: 0.091829
 >> iter 44000, loss: 0.062052
 >> iter 45000, loss: 0.051344
 >> iter 46000, loss: 0.046234
 >> iter 47000, loss: 0.044102
 >> iter 48000, loss: 0.042958
 >> iter 49000, loss: 0.042482
 >> iter 50000, loss: 0.042189
   Number of active neurons: 4
 >> iter 51000, loss: 0.042108
 >> iter 52000, loss: 0.041875
 >> iter 53000, loss: 0.041866
 >> iter 54000, loss: 0.041765
 >> iter 55000, loss: 0.041698
 >> iter 56000, loss: 0.041604
 >> iter 57000, loss: 0.041694
 >> iter 58000, loss: 0.041578
 >> iter 59000, loss: 0.041477
 >> iter 60000, loss: 0.041296
   Number of active neurons: 4
 >> iter 61000, loss: 0.041193
 >> iter 62000, loss: 0.041050
 >> iter 63000, loss: 0.041004
 >> iter 64000, loss: 0.040919
 >> iter 65000, loss: 0.040904
 >> iter 66000, loss: 0.040845
 >> iter 67000, loss: 0.040850
 >> iter 68000, loss: 0.040824
 >> iter 69000, loss: 0.040854
 >> iter 70000, loss: 0.040854
   Number of active neurons: 4
 >> iter 71000, loss: 0.040885
 >> iter 72000, loss: 0.040887
 >> iter 73000, loss: 0.040937
 >> iter 74000, loss: 0.040926
 >> iter 75000, loss: 0.040991
 >> iter 76000, loss: 0.040965
 >> iter 77000, loss: 0.041036
 >> iter 78000, loss: 0.041006
 >> iter 79000, loss: 0.041081
 >> iter 80000, loss: 0.041041
   Number of active neurons: 4
 >> iter 81000, loss: 0.041072
 >> iter 82000, loss: 0.041047
 >> iter 83000, loss: 0.041095
 >> iter 84000, loss: 0.041070
 >> iter 85000, loss: 0.041129
 >> iter 86000, loss: 0.041109
 >> iter 87000, loss: 0.041177
 >> iter 88000, loss: 0.041164
 >> iter 89000, loss: 0.041216
 >> iter 90000, loss: 0.041220
   Number of active neurons: 4
 >> iter 91000, loss: 0.041262
 >> iter 92000, loss: 0.041273
 >> iter 93000, loss: 0.041309
 >> iter 94000, loss: 0.041316
 >> iter 95000, loss: 0.041343
 >> iter 96000, loss: 0.041360
 >> iter 97000, loss: 0.041394
 >> iter 98000, loss: 0.041408
 >> iter 99000, loss: 0.041431
 >> iter 100000, loss: 0.041467
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.640431
 >> iter 2000, loss: 10.514581
 >> iter 3000, loss: 8.628366
 >> iter 4000, loss: 7.897066
 >> iter 5000, loss: 7.652505
 >> iter 6000, loss: 7.381494
 >> iter 7000, loss: 5.402683
 >> iter 8000, loss: 2.168195
 >> iter 9000, loss: 0.875786
 >> iter 10000, loss: 0.378048
   Number of active neurons: 5
 >> iter 11000, loss: 0.186596
 >> iter 12000, loss: 0.110020
 >> iter 13000, loss: 0.079393
 >> iter 14000, loss: 0.069090
 >> iter 15000, loss: 0.060674
 >> iter 16000, loss: 0.058863
 >> iter 17000, loss: 0.054660
 >> iter 18000, loss: 0.053036
 >> iter 19000, loss: 0.067197
 >> iter 20000, loss: 0.381627
   Number of active neurons: 5
 >> iter 21000, loss: 0.179905
 >> iter 22000, loss: 0.104515
 >> iter 23000, loss: 0.072886
 >> iter 24000, loss: 0.164193
 >> iter 25000, loss: 0.095445
 >> iter 26000, loss: 0.071486
 >> iter 27000, loss: 0.079527
 >> iter 28000, loss: 0.236596
 >> iter 29000, loss: 0.124336
 >> iter 30000, loss: 0.191491
   Number of active neurons: 4
 >> iter 31000, loss: 0.253147
 >> iter 32000, loss: 0.136522
 >> iter 33000, loss: 0.087361
 >> iter 34000, loss: 0.063105
 >> iter 35000, loss: 0.377550
 >> iter 36000, loss: 0.281299
 >> iter 37000, loss: 0.148999
 >> iter 38000, loss: 0.087568
 >> iter 39000, loss: 0.095298
 >> iter 40000, loss: 0.069632
   Number of active neurons: 4
 >> iter 41000, loss: 0.083538
 >> iter 42000, loss: 0.064609
 >> iter 43000, loss: 0.434407
 >> iter 44000, loss: 0.444594
 >> iter 45000, loss: 0.209181
 >> iter 46000, loss: 0.113014
 >> iter 47000, loss: 0.225870
 >> iter 48000, loss: 0.323153
 >> iter 49000, loss: 0.347163
 >> iter 50000, loss: 0.264839
   Number of active neurons: 4
 >> iter 51000, loss: 0.136139
 >> iter 52000, loss: 0.454435
 >> iter 53000, loss: 0.224590
 >> iter 54000, loss: 0.233770
 >> iter 55000, loss: 0.514362
 >> iter 56000, loss: 3.254115
 >> iter 57000, loss: 1.287176
 >> iter 58000, loss: 0.538242
 >> iter 59000, loss: 0.248778
 >> iter 60000, loss: 0.148665
   Number of active neurons: 4
 >> iter 61000, loss: 0.102902
 >> iter 62000, loss: 0.237600
 >> iter 63000, loss: 0.161273
 >> iter 64000, loss: 0.254798
 >> iter 65000, loss: 0.174358
 >> iter 66000, loss: 0.276382
 >> iter 67000, loss: 0.205755
 >> iter 68000, loss: 0.306124
 >> iter 69000, loss: 0.219793
 >> iter 70000, loss: 0.842061
   Number of active neurons: 4
 >> iter 71000, loss: 0.395218
 >> iter 72000, loss: 0.254911
 >> iter 73000, loss: 0.170078
 >> iter 74000, loss: 0.111695
 >> iter 75000, loss: 0.098698
 >> iter 76000, loss: 0.091780
 >> iter 77000, loss: 0.118851
 >> iter 78000, loss: 0.142952
 >> iter 79000, loss: 0.396799
 >> iter 80000, loss: 0.382585
   Number of active neurons: 4
 >> iter 81000, loss: 0.595440
 >> iter 82000, loss: 0.595564
 >> iter 83000, loss: 0.314931
 >> iter 84000, loss: 0.196637
 >> iter 85000, loss: 0.127105
 >> iter 86000, loss: 0.104838
 >> iter 87000, loss: 0.095777
 >> iter 88000, loss: 0.098794
 >> iter 89000, loss: 0.187207
 >> iter 90000, loss: 0.124476
   Number of active neurons: 4
 >> iter 91000, loss: 0.098430
 >> iter 92000, loss: 0.270625
 >> iter 93000, loss: 0.341119
 >> iter 94000, loss: 0.338116
 >> iter 95000, loss: 0.250291
 >> iter 96000, loss: 0.556594
 >> iter 97000, loss: 0.309434
 >> iter 98000, loss: 0.208967
 >> iter 99000, loss: 0.130172
 >> iter 100000, loss: 0.096919
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 13.3124458369
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.571124
 >> iter 2000, loss: 10.510416
 >> iter 3000, loss: 8.644732
 >> iter 4000, loss: 7.919459
 >> iter 5000, loss: 7.671057
 >> iter 6000, loss: 7.535207
 >> iter 7000, loss: 6.017323
 >> iter 8000, loss: 2.303099
 >> iter 9000, loss: 0.889971
 >> iter 10000, loss: 0.361212
   Number of active neurons: 6
 >> iter 11000, loss: 0.163367
 >> iter 12000, loss: 0.088756
 >> iter 13000, loss: 0.060241
 >> iter 14000, loss: 0.048920
 >> iter 15000, loss: 0.044255
 >> iter 16000, loss: 0.042056
 >> iter 17000, loss: 0.041046
 >> iter 18000, loss: 0.040436
 >> iter 19000, loss: 0.040147
 >> iter 20000, loss: 0.039869
   Number of active neurons: 6
 >> iter 21000, loss: 0.039676
 >> iter 22000, loss: 0.039405
 >> iter 23000, loss: 0.039092
 >> iter 24000, loss: 0.038741
 >> iter 25000, loss: 0.038358
 >> iter 26000, loss: 0.038048
 >> iter 27000, loss: 0.037660
 >> iter 28000, loss: 0.037434
 >> iter 29000, loss: 0.037139
 >> iter 30000, loss: 0.037006
   Number of active neurons: 6
 >> iter 31000, loss: 0.036740
 >> iter 32000, loss: 0.036628
 >> iter 33000, loss: 0.036417
 >> iter 34000, loss: 0.036357
 >> iter 35000, loss: 0.036196
 >> iter 36000, loss: 0.036181
 >> iter 37000, loss: 0.036029
 >> iter 38000, loss: 0.036099
 >> iter 39000, loss: 0.035900
 >> iter 40000, loss: 0.035982
   Number of active neurons: 6
 >> iter 41000, loss: 0.035791
 >> iter 42000, loss: 0.035884
 >> iter 43000, loss: 0.035694
 >> iter 44000, loss: 0.035791
 >> iter 45000, loss: 0.035603
 >> iter 46000, loss: 0.035706
 >> iter 47000, loss: 0.035516
 >> iter 48000, loss: 0.035617
 >> iter 49000, loss: 0.035439
 >> iter 50000, loss: 0.035545
   Number of active neurons: 6
 >> iter 51000, loss: 0.035383
 >> iter 52000, loss: 0.035484
 >> iter 53000, loss: 0.035314
 >> iter 54000, loss: 0.035443
 >> iter 55000, loss: 0.035252
 >> iter 56000, loss: 0.035411
 >> iter 57000, loss: 0.035199
 >> iter 58000, loss: 0.035374
 >> iter 59000, loss: 0.035154
 >> iter 60000, loss: 0.035335
   Number of active neurons: 6
 >> iter 61000, loss: 0.035110
 >> iter 62000, loss: 0.035296
 >> iter 63000, loss: 0.035067
 >> iter 64000, loss: 0.035260
 >> iter 65000, loss: 0.035026
 >> iter 66000, loss: 0.035224
 >> iter 67000, loss: 0.034981
 >> iter 68000, loss: 0.035186
 >> iter 69000, loss: 0.034938
 >> iter 70000, loss: 0.035132
   Number of active neurons: 6
 >> iter 71000, loss: 0.034874
 >> iter 72000, loss: 0.035070
 >> iter 73000, loss: 0.034815
 >> iter 74000, loss: 0.035004
 >> iter 75000, loss: 0.034745
 >> iter 76000, loss: 0.034925
 >> iter 77000, loss: 0.034660
 >> iter 78000, loss: 0.034812
 >> iter 79000, loss: 0.034531
 >> iter 80000, loss: 0.034566
   Number of active neurons: 6
 >> iter 81000, loss: 0.034312
 >> iter 82000, loss: 0.034387
 >> iter 83000, loss: 0.034173
 >> iter 84000, loss: 0.034267
 >> iter 85000, loss: 0.034095
 >> iter 86000, loss: 0.034195
 >> iter 87000, loss: 0.034049
 >> iter 88000, loss: 0.034145
 >> iter 89000, loss: 0.034019
 >> iter 90000, loss: 0.034110
   Number of active neurons: 6
 >> iter 91000, loss: 0.033959
 >> iter 92000, loss: 0.034028
 >> iter 93000, loss: 0.033873
 >> iter 94000, loss: 0.033964
 >> iter 95000, loss: 0.033850
 >> iter 96000, loss: 0.033945
 >> iter 97000, loss: 0.033844
 >> iter 98000, loss: 0.033945
 >> iter 99000, loss: 0.033846
 >> iter 100000, loss: 0.033943
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

