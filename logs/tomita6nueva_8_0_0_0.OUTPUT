 > Problema: tomita6nueva
 > Args:
   - Hidden size: 8
   - Noise level: 0.0
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.611914
 >> iter 2000, loss: 15.091465
 >> iter 3000, loss: 13.758687
 >> iter 4000, loss: 13.264449
 >> iter 5000, loss: 13.067860
 >> iter 6000, loss: 12.997570
 >> iter 7000, loss: 12.961871
 >> iter 8000, loss: 12.955655
 >> iter 9000, loss: 12.943693
 >> iter 10000, loss: 12.949614
   Number of active neurons: 6
 >> iter 11000, loss: 12.939495
 >> iter 12000, loss: 12.943783
 >> iter 13000, loss: 12.912615
 >> iter 14000, loss: 12.217245
 >> iter 15000, loss: 5.604215
 >> iter 16000, loss: 2.105311
 >> iter 17000, loss: 0.798275
 >> iter 18000, loss: 0.309891
 >> iter 19000, loss: 0.126455
 >> iter 20000, loss: 0.056456
   Number of active neurons: 8
 >> iter 21000, loss: 0.029131
 >> iter 22000, loss: 0.017826
 >> iter 23000, loss: 0.012814
 >> iter 24000, loss: 0.010224
 >> iter 25000, loss: 0.008740
 >> iter 26000, loss: 0.007697
 >> iter 27000, loss: 0.006955
 >> iter 28000, loss: 0.006329
 >> iter 29000, loss: 0.005841
 >> iter 30000, loss: 0.005394
   Number of active neurons: 8
 >> iter 31000, loss: 0.005039
 >> iter 32000, loss: 0.004700
 >> iter 33000, loss: 0.004429
 >> iter 34000, loss: 0.004160
 >> iter 35000, loss: 0.003944
 >> iter 36000, loss: 0.003728
 >> iter 37000, loss: 0.003553
 >> iter 38000, loss: 0.003375
 >> iter 39000, loss: 0.003231
 >> iter 40000, loss: 0.003082
   Number of active neurons: 8
 >> iter 41000, loss: 0.002961
 >> iter 42000, loss: 0.002832
 >> iter 43000, loss: 0.002730
 >> iter 44000, loss: 0.002620
 >> iter 45000, loss: 0.002533
 >> iter 46000, loss: 0.002436
 >> iter 47000, loss: 0.002361
 >> iter 48000, loss: 0.002275
 >> iter 49000, loss: 0.002210
 >> iter 50000, loss: 0.002134
   Number of active neurons: 8
 >> iter 51000, loss: 0.002076
 >> iter 52000, loss: 0.002009
 >> iter 53000, loss: 0.001956
 >> iter 54000, loss: 0.001897
 >> iter 55000, loss: 0.001850
 >> iter 56000, loss: 0.001796
 >> iter 57000, loss: 0.001754
 >> iter 58000, loss: 0.001706
 >> iter 59000, loss: 0.001668
 >> iter 60000, loss: 0.001623
   Number of active neurons: 8
 >> iter 61000, loss: 0.001589
 >> iter 62000, loss: 0.001548
 >> iter 63000, loss: 0.001517
 >> iter 64000, loss: 0.001480
 >> iter 65000, loss: 0.001452
 >> iter 66000, loss: 0.001417
 >> iter 67000, loss: 0.001392
 >> iter 68000, loss: 0.001359
 >> iter 69000, loss: 0.001336
 >> iter 70000, loss: 0.001305
   Number of active neurons: 8
 >> iter 71000, loss: 0.001285
 >> iter 72000, loss: 0.001256
 >> iter 73000, loss: 0.001237
 >> iter 74000, loss: 0.001210
 >> iter 75000, loss: 0.001193
 >> iter 76000, loss: 0.001167
 >> iter 77000, loss: 0.001152
 >> iter 78000, loss: 0.001128
 >> iter 79000, loss: 0.001114
 >> iter 80000, loss: 0.001090
   Number of active neurons: 8
 >> iter 81000, loss: 0.001078
 >> iter 82000, loss: 0.001056
 >> iter 83000, loss: 0.001044
 >> iter 84000, loss: 0.001023
 >> iter 85000, loss: 0.001012
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.615826
 >> iter 2000, loss: 15.064868
 >> iter 3000, loss: 13.726068
 >> iter 4000, loss: 13.236509
 >> iter 5000, loss: 13.041423
 >> iter 6000, loss: 12.976402
 >> iter 7000, loss: 12.941226
 >> iter 8000, loss: 12.937545
 >> iter 9000, loss: 12.923764
 >> iter 10000, loss: 12.692731
   Number of active neurons: 7
 >> iter 11000, loss: 6.799629
 >> iter 12000, loss: 2.567316
 >> iter 13000, loss: 0.976019
 >> iter 14000, loss: 0.380286
 >> iter 15000, loss: 0.155664
 >> iter 16000, loss: 0.069927
 >> iter 17000, loss: 0.036149
 >> iter 18000, loss: 0.022265
 >> iter 19000, loss: 0.015939
 >> iter 20000, loss: 0.012782
   Number of active neurons: 8
 >> iter 21000, loss: 0.010846
 >> iter 22000, loss: 0.009613
 >> iter 23000, loss: 0.008617
 >> iter 24000, loss: 0.007902
 >> iter 25000, loss: 0.007234
 >> iter 26000, loss: 0.006739
 >> iter 27000, loss: 0.006242
 >> iter 28000, loss: 0.005878
 >> iter 29000, loss: 0.005490
 >> iter 30000, loss: 0.005211
   Number of active neurons: 8
 >> iter 31000, loss: 0.004898
 >> iter 32000, loss: 0.004678
 >> iter 33000, loss: 0.004420
 >> iter 34000, loss: 0.004243
 >> iter 35000, loss: 0.004026
 >> iter 36000, loss: 0.003882
 >> iter 37000, loss: 0.003694
 >> iter 38000, loss: 0.003576
 >> iter 39000, loss: 0.003413
 >> iter 40000, loss: 0.003316
   Number of active neurons: 8
 >> iter 41000, loss: 0.003171
 >> iter 42000, loss: 0.003088
 >> iter 43000, loss: 0.002960
 >> iter 44000, loss: 0.002890
 >> iter 45000, loss: 0.002775
 >> iter 46000, loss: 0.002716
 >> iter 47000, loss: 0.002612
 >> iter 48000, loss: 0.002561
 >> iter 49000, loss: 0.002467
 >> iter 50000, loss: 0.002422
   Number of active neurons: 8
 >> iter 51000, loss: 0.002336
 >> iter 52000, loss: 0.002298
 >> iter 53000, loss: 0.002217
 >> iter 54000, loss: 0.002186
 >> iter 55000, loss: 0.002111
 >> iter 56000, loss: 0.002083
 >> iter 57000, loss: 0.002013
 >> iter 58000, loss: 0.001989
 >> iter 59000, loss: 0.001925
 >> iter 60000, loss: 0.001903
   Number of active neurons: 8
 >> iter 61000, loss: 0.001843
 >> iter 62000, loss: 0.001824
 >> iter 63000, loss: 0.001768
 >> iter 64000, loss: 0.001751
 >> iter 65000, loss: 0.001699
 >> iter 66000, loss: 0.001684
 >> iter 67000, loss: 0.001635
 >> iter 68000, loss: 0.001622
 >> iter 69000, loss: 0.001576
 >> iter 70000, loss: 0.001563
   Number of active neurons: 8
 >> iter 71000, loss: 0.001520
 >> iter 72000, loss: 0.001509
 >> iter 73000, loss: 0.001468
 >> iter 74000, loss: 0.001459
 >> iter 75000, loss: 0.001420
 >> iter 76000, loss: 0.001412
 >> iter 77000, loss: 0.001375
 >> iter 78000, loss: 0.001367
 >> iter 79000, loss: 0.001332
 >> iter 80000, loss: 0.001326
   Number of active neurons: 8
 >> iter 81000, loss: 0.001292
 >> iter 82000, loss: 0.001286
 >> iter 83000, loss: 0.001255
 >> iter 84000, loss: 0.001249
 >> iter 85000, loss: 0.001219
 >> iter 86000, loss: 0.001214
 >> iter 87000, loss: 0.001185
 >> iter 88000, loss: 0.001181
 >> iter 89000, loss: 0.001153
 >> iter 90000, loss: 0.001149
   Number of active neurons: 8
 >> iter 91000, loss: 0.001123
 >> iter 92000, loss: 0.001120
 >> iter 93000, loss: 0.001094
 >> iter 94000, loss: 0.001091
 >> iter 95000, loss: 0.001067
 >> iter 96000, loss: 0.001064
 >> iter 97000, loss: 0.001041
 >> iter 98000, loss: 0.001039
 >> iter 99000, loss: 0.001016
 >> iter 100000, loss: 0.001014
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0049999500005
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.635589
 >> iter 2000, loss: 15.097232
 >> iter 3000, loss: 13.761374
 >> iter 4000, loss: 13.267327
 >> iter 5000, loss: 13.072409
 >> iter 6000, loss: 13.005174
 >> iter 7000, loss: 12.971341
 >> iter 8000, loss: 12.967157
 >> iter 9000, loss: 12.956038
 >> iter 10000, loss: 12.962920
   Number of active neurons: 5
 >> iter 11000, loss: 12.953055
 >> iter 12000, loss: 12.957660
 >> iter 13000, loss: 12.925731
 >> iter 14000, loss: 12.108728
 >> iter 15000, loss: 4.874208
 >> iter 16000, loss: 1.917912
 >> iter 17000, loss: 0.744303
 >> iter 18000, loss: 0.298683
 >> iter 19000, loss: 0.130610
 >> iter 20000, loss: 0.063531
   Number of active neurons: 8
 >> iter 21000, loss: 0.038355
 >> iter 22000, loss: 0.025333
 >> iter 23000, loss: 0.018976
 >> iter 24000, loss: 0.015670
 >> iter 25000, loss: 0.013485
 >> iter 26000, loss: 0.012073
 >> iter 27000, loss: 0.010881
 >> iter 28000, loss: 0.010026
 >> iter 29000, loss: 0.009209
 >> iter 30000, loss: 0.008608
   Number of active neurons: 8
 >> iter 31000, loss: 0.007995
 >> iter 32000, loss: 0.007543
 >> iter 33000, loss: 0.007064
 >> iter 34000, loss: 0.006710
 >> iter 35000, loss: 0.006323
 >> iter 36000, loss: 0.006041
 >> iter 37000, loss: 0.005719
 >> iter 38000, loss: 0.005489
 >> iter 39000, loss: 0.005218
 >> iter 40000, loss: 0.005031
   Number of active neurons: 8
 >> iter 41000, loss: 0.004797
 >> iter 42000, loss: 0.004637
 >> iter 43000, loss: 0.004436
 >> iter 44000, loss: 0.004298
 >> iter 45000, loss: 0.004123
 >> iter 46000, loss: 0.004006
 >> iter 47000, loss: 0.003850
 >> iter 48000, loss: 0.003746
 >> iter 49000, loss: 0.003610
 >> iter 50000, loss: 0.003519
   Number of active neurons: 8
 >> iter 51000, loss: 0.003395
 >> iter 52000, loss: 0.003315
 >> iter 53000, loss: 0.003202
 >> iter 54000, loss: 0.003133
 >> iter 55000, loss: 0.003029
 >> iter 56000, loss: 0.002968
 >> iter 57000, loss: 0.002873
 >> iter 58000, loss: 0.002819
 >> iter 59000, loss: 0.002733
 >> iter 60000, loss: 0.002683
   Number of active neurons: 8
 >> iter 61000, loss: 0.002604
 >> iter 62000, loss: 0.002559
 >> iter 63000, loss: 0.002485
 >> iter 64000, loss: 0.002445
 >> iter 65000, loss: 0.002378
 >> iter 66000, loss: 0.002340
 >> iter 67000, loss: 0.002279
 >> iter 68000, loss: 0.002243
 >> iter 69000, loss: 0.002187
 >> iter 70000, loss: 0.002154
   Number of active neurons: 8
 >> iter 71000, loss: 0.002101
 >> iter 72000, loss: 0.002071
 >> iter 73000, loss: 0.002022
 >> iter 74000, loss: 0.001995
 >> iter 75000, loss: 0.001949
 >> iter 76000, loss: 0.001924
 >> iter 77000, loss: 0.001881
 >> iter 78000, loss: 0.001858
 >> iter 79000, loss: 0.001816
 >> iter 80000, loss: 0.001795
   Number of active neurons: 8
 >> iter 81000, loss: 0.001757
 >> iter 82000, loss: 0.001737
 >> iter 83000, loss: 0.001700
 >> iter 84000, loss: 0.001682
 >> iter 85000, loss: 0.001648
 >> iter 86000, loss: 0.001630
 >> iter 87000, loss: 0.001598
 >> iter 88000, loss: 0.001582
 >> iter 89000, loss: 0.001551
 >> iter 90000, loss: 0.001536
   Number of active neurons: 8
 >> iter 91000, loss: 0.001507
 >> iter 92000, loss: 0.001492
 >> iter 93000, loss: 0.001465
 >> iter 94000, loss: 0.001451
 >> iter 95000, loss: 0.001425
 >> iter 96000, loss: 0.001412
 >> iter 97000, loss: 0.001388
 >> iter 98000, loss: 0.001376
 >> iter 99000, loss: 0.001353
 >> iter 100000, loss: 0.001341
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.625399
 >> iter 2000, loss: 15.104509
 >> iter 3000, loss: 13.770654
 >> iter 4000, loss: 13.274679
 >> iter 5000, loss: 13.077197
 >> iter 6000, loss: 13.007049
 >> iter 7000, loss: 12.971896
 >> iter 8000, loss: 12.966075
 >> iter 9000, loss: 12.954358
 >> iter 10000, loss: 12.959610
   Number of active neurons: 6
 >> iter 11000, loss: 12.948610
 >> iter 12000, loss: 12.904302
 >> iter 13000, loss: 9.866857
 >> iter 14000, loss: 3.744063
 >> iter 15000, loss: 1.417099
 >> iter 16000, loss: 0.546139
 >> iter 17000, loss: 0.218615
 >> iter 18000, loss: 0.094224
 >> iter 19000, loss: 0.046372
 >> iter 20000, loss: 0.026706
   Number of active neurons: 8
 >> iter 21000, loss: 0.018114
 >> iter 22000, loss: 0.013954
 >> iter 23000, loss: 0.011630
 >> iter 24000, loss: 0.010158
 >> iter 25000, loss: 0.009086
 >> iter 26000, loss: 0.008263
 >> iter 27000, loss: 0.007583
 >> iter 28000, loss: 0.007024
 >> iter 29000, loss: 0.006533
 >> iter 30000, loss: 0.006115
   Number of active neurons: 8
 >> iter 31000, loss: 0.005738
 >> iter 32000, loss: 0.005412
 >> iter 33000, loss: 0.005116
 >> iter 34000, loss: 0.004855
 >> iter 35000, loss: 0.004614
 >> iter 36000, loss: 0.004400
 >> iter 37000, loss: 0.004199
 >> iter 38000, loss: 0.004023
 >> iter 39000, loss: 0.003854
 >> iter 40000, loss: 0.003707
   Number of active neurons: 8
 >> iter 41000, loss: 0.003562
 >> iter 42000, loss: 0.003433
 >> iter 43000, loss: 0.003309
 >> iter 44000, loss: 0.003197
 >> iter 45000, loss: 0.003089
 >> iter 46000, loss: 0.002993
 >> iter 47000, loss: 0.002896
 >> iter 48000, loss: 0.002811
 >> iter 49000, loss: 0.002726
 >> iter 50000, loss: 0.002651
   Number of active neurons: 8
 >> iter 51000, loss: 0.002574
 >> iter 52000, loss: 0.002507
 >> iter 53000, loss: 0.002437
 >> iter 54000, loss: 0.002378
 >> iter 55000, loss: 0.002314
 >> iter 56000, loss: 0.002261
 >> iter 57000, loss: 0.002204
 >> iter 58000, loss: 0.002156
 >> iter 59000, loss: 0.002103
 >> iter 60000, loss: 0.002059
   Number of active neurons: 8
 >> iter 61000, loss: 0.002011
 >> iter 62000, loss: 0.001971
 >> iter 63000, loss: 0.001926
 >> iter 64000, loss: 0.001889
 >> iter 65000, loss: 0.001849
 >> iter 66000, loss: 0.001814
 >> iter 67000, loss: 0.001778
 >> iter 68000, loss: 0.001745
 >> iter 69000, loss: 0.001711
 >> iter 70000, loss: 0.001680
   Number of active neurons: 8
 >> iter 71000, loss: 0.001650
 >> iter 72000, loss: 0.001620
 >> iter 73000, loss: 0.001591
 >> iter 74000, loss: 0.001565
 >> iter 75000, loss: 0.001537
 >> iter 76000, loss: 0.001513
 >> iter 77000, loss: 0.001488
 >> iter 78000, loss: 0.001464
 >> iter 79000, loss: 0.001440
 >> iter 80000, loss: 0.001419
   Number of active neurons: 8
 >> iter 81000, loss: 0.001396
 >> iter 82000, loss: 0.001376
 >> iter 83000, loss: 0.001354
 >> iter 84000, loss: 0.001335
 >> iter 85000, loss: 0.001315
 >> iter 86000, loss: 0.001297
 >> iter 87000, loss: 0.001277
 >> iter 88000, loss: 0.001261
 >> iter 89000, loss: 0.001242
 >> iter 90000, loss: 0.001226
   Number of active neurons: 8
 >> iter 91000, loss: 0.001209
 >> iter 92000, loss: 0.001194
 >> iter 93000, loss: 0.001177
 >> iter 94000, loss: 0.001163
 >> iter 95000, loss: 0.001147
 >> iter 96000, loss: 0.001134
 >> iter 97000, loss: 0.001119
 >> iter 98000, loss: 0.001106
 >> iter 99000, loss: 0.001092
 >> iter 100000, loss: 0.001079
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.599921
 >> iter 2000, loss: 15.090631
 >> iter 3000, loss: 13.760280
 >> iter 4000, loss: 13.265315
 >> iter 5000, loss: 13.063551
 >> iter 6000, loss: 12.992442
 >> iter 7000, loss: 12.953100
 >> iter 8000, loss: 12.946107
 >> iter 9000, loss: 12.931445
 >> iter 10000, loss: 12.903962
   Number of active neurons: 5
 >> iter 11000, loss: 11.664544
 >> iter 12000, loss: 4.654391
 >> iter 13000, loss: 1.764125
 >> iter 14000, loss: 0.679260
 >> iter 15000, loss: 0.271070
 >> iter 16000, loss: 0.115932
 >> iter 17000, loss: 0.055734
 >> iter 18000, loss: 0.031416
 >> iter 19000, loss: 0.020926
 >> iter 20000, loss: 0.015859
   Number of active neurons: 8
 >> iter 21000, loss: 0.013081
 >> iter 22000, loss: 0.011299
 >> iter 23000, loss: 0.010040
 >> iter 24000, loss: 0.009058
 >> iter 25000, loss: 0.008270
 >> iter 26000, loss: 0.007598
 >> iter 27000, loss: 0.007038
 >> iter 28000, loss: 0.006542
 >> iter 29000, loss: 0.006121
 >> iter 30000, loss: 0.005734
   Number of active neurons: 8
 >> iter 31000, loss: 0.005406
 >> iter 32000, loss: 0.005095
 >> iter 33000, loss: 0.004834
 >> iter 34000, loss: 0.004579
 >> iter 35000, loss: 0.004365
 >> iter 36000, loss: 0.004153
 >> iter 37000, loss: 0.003975
 >> iter 38000, loss: 0.003796
 >> iter 39000, loss: 0.003646
 >> iter 40000, loss: 0.003493
   Number of active neurons: 8
 >> iter 41000, loss: 0.003366
 >> iter 42000, loss: 0.003231
 >> iter 43000, loss: 0.003122
 >> iter 44000, loss: 0.003004
 >> iter 45000, loss: 0.002910
 >> iter 46000, loss: 0.002806
 >> iter 47000, loss: 0.002723
 >> iter 48000, loss: 0.002630
 >> iter 49000, loss: 0.002557
 >> iter 50000, loss: 0.002474
   Number of active neurons: 8
 >> iter 51000, loss: 0.002409
 >> iter 52000, loss: 0.002334
 >> iter 53000, loss: 0.002275
 >> iter 54000, loss: 0.002208
 >> iter 55000, loss: 0.002155
 >> iter 56000, loss: 0.002094
 >> iter 57000, loss: 0.002047
 >> iter 58000, loss: 0.001991
 >> iter 59000, loss: 0.001949
 >> iter 60000, loss: 0.001897
   Number of active neurons: 8
 >> iter 61000, loss: 0.001858
 >> iter 62000, loss: 0.001811
 >> iter 63000, loss: 0.001775
 >> iter 64000, loss: 0.001731
 >> iter 65000, loss: 0.001699
 >> iter 66000, loss: 0.001658
 >> iter 67000, loss: 0.001629
 >> iter 68000, loss: 0.001590
 >> iter 69000, loss: 0.001564
 >> iter 70000, loss: 0.001527
   Number of active neurons: 8
 >> iter 71000, loss: 0.001504
 >> iter 72000, loss: 0.001469
 >> iter 73000, loss: 0.001447
 >> iter 74000, loss: 0.001415
 >> iter 75000, loss: 0.001395
 >> iter 76000, loss: 0.001364
 >> iter 77000, loss: 0.001346
 >> iter 78000, loss: 0.001317
 >> iter 79000, loss: 0.001300
 >> iter 80000, loss: 0.001273
   Number of active neurons: 8
 >> iter 81000, loss: 0.001257
 >> iter 82000, loss: 0.001231
 >> iter 83000, loss: 0.001217
 >> iter 84000, loss: 0.001192
 >> iter 85000, loss: 0.001179
 >> iter 86000, loss: 0.001155
 >> iter 87000, loss: 0.001143
 >> iter 88000, loss: 0.001121
 >> iter 89000, loss: 0.001109
 >> iter 90000, loss: 0.001087
   Number of active neurons: 8
 >> iter 91000, loss: 0.001077
 >> iter 92000, loss: 0.001056
 >> iter 93000, loss: 0.001047
 >> iter 94000, loss: 0.001027
 >> iter 95000, loss: 0.001018
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.627464
 >> iter 2000, loss: 15.092255
 >> iter 3000, loss: 13.751012
 >> iter 4000, loss: 13.253735
 >> iter 5000, loss: 13.051700
 >> iter 6000, loss: 12.981442
 >> iter 7000, loss: 12.942984
 >> iter 8000, loss: 12.936575
 >> iter 9000, loss: 12.922435
 >> iter 10000, loss: 12.908275
   Number of active neurons: 4
 >> iter 11000, loss: 12.329103
 >> iter 12000, loss: 10.756884
 >> iter 13000, loss: 5.227519
 >> iter 14000, loss: 1.951115
 >> iter 15000, loss: 0.734002
 >> iter 16000, loss: 0.281443
 >> iter 17000, loss: 0.112482
 >> iter 18000, loss: 0.048604
 >> iter 19000, loss: 0.024018
 >> iter 20000, loss: 0.014086
   Number of active neurons: 8
 >> iter 21000, loss: 0.009826
 >> iter 22000, loss: 0.007722
 >> iter 23000, loss: 0.006564
 >> iter 24000, loss: 0.005780
 >> iter 25000, loss: 0.005226
 >> iter 26000, loss: 0.004766
 >> iter 27000, loss: 0.004406
 >> iter 28000, loss: 0.004082
 >> iter 29000, loss: 0.003818
 >> iter 30000, loss: 0.003571
   Number of active neurons: 8
 >> iter 31000, loss: 0.003370
 >> iter 32000, loss: 0.003172
 >> iter 33000, loss: 0.003014
 >> iter 34000, loss: 0.002854
 >> iter 35000, loss: 0.002725
 >> iter 36000, loss: 0.002593
 >> iter 37000, loss: 0.002486
 >> iter 38000, loss: 0.002375
 >> iter 39000, loss: 0.002286
 >> iter 40000, loss: 0.002192
   Number of active neurons: 8
 >> iter 41000, loss: 0.002116
 >> iter 42000, loss: 0.002033
 >> iter 43000, loss: 0.001969
 >> iter 44000, loss: 0.001897
 >> iter 45000, loss: 0.001841
 >> iter 46000, loss: 0.001778
 >> iter 47000, loss: 0.001729
 >> iter 48000, loss: 0.001672
 >> iter 49000, loss: 0.001629
 >> iter 50000, loss: 0.001579
   Number of active neurons: 8
 >> iter 51000, loss: 0.001539
 >> iter 52000, loss: 0.001495
 >> iter 53000, loss: 0.001459
 >> iter 54000, loss: 0.001419
 >> iter 55000, loss: 0.001387
 >> iter 56000, loss: 0.001351
 >> iter 57000, loss: 0.001321
 >> iter 58000, loss: 0.001288
 >> iter 59000, loss: 0.001262
 >> iter 60000, loss: 0.001232
   Number of active neurons: 8
 >> iter 61000, loss: 0.001208
 >> iter 62000, loss: 0.001180
 >> iter 63000, loss: 0.001158
 >> iter 64000, loss: 0.001132
 >> iter 65000, loss: 0.001112
 >> iter 66000, loss: 0.001088
 >> iter 67000, loss: 0.001069
 >> iter 68000, loss: 0.001047
 >> iter 69000, loss: 0.001030
 >> iter 70000, loss: 0.001008
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.612370
 >> iter 2000, loss: 15.080151
 >> iter 3000, loss: 13.746870
 >> iter 4000, loss: 13.254171
 >> iter 5000, loss: 13.058938
 >> iter 6000, loss: 12.990691
 >> iter 7000, loss: 12.955912
 >> iter 8000, loss: 12.950278
 >> iter 9000, loss: 12.938298
 >> iter 10000, loss: 12.942047
   Number of active neurons: 4
 >> iter 11000, loss: 12.920240
 >> iter 12000, loss: 12.512286
 >> iter 13000, loss: 8.428861
 >> iter 14000, loss: 3.284844
 >> iter 15000, loss: 1.238792
 >> iter 16000, loss: 0.474055
 >> iter 17000, loss: 0.187448
 >> iter 18000, loss: 0.079142
 >> iter 19000, loss: 0.037412
 >> iter 20000, loss: 0.020788
   Number of active neurons: 8
 >> iter 21000, loss: 0.013698
 >> iter 22000, loss: 0.010386
 >> iter 23000, loss: 0.008570
 >> iter 24000, loss: 0.007464
 >> iter 25000, loss: 0.006649
 >> iter 26000, loss: 0.006050
 >> iter 27000, loss: 0.005535
 >> iter 28000, loss: 0.005135
 >> iter 29000, loss: 0.004761
 >> iter 30000, loss: 0.004466
   Number of active neurons: 8
 >> iter 31000, loss: 0.004178
 >> iter 32000, loss: 0.003949
 >> iter 33000, loss: 0.003722
 >> iter 34000, loss: 0.003540
 >> iter 35000, loss: 0.003356
 >> iter 36000, loss: 0.003208
 >> iter 37000, loss: 0.003054
 >> iter 38000, loss: 0.002932
 >> iter 39000, loss: 0.002802
 >> iter 40000, loss: 0.002702
   Number of active neurons: 8
 >> iter 41000, loss: 0.002591
 >> iter 42000, loss: 0.002503
 >> iter 43000, loss: 0.002407
 >> iter 44000, loss: 0.002331
 >> iter 45000, loss: 0.002248
 >> iter 46000, loss: 0.002183
 >> iter 47000, loss: 0.002108
 >> iter 48000, loss: 0.002050
 >> iter 49000, loss: 0.001985
 >> iter 50000, loss: 0.001934
   Number of active neurons: 8
 >> iter 51000, loss: 0.001874
 >> iter 52000, loss: 0.001830
 >> iter 53000, loss: 0.001775
 >> iter 54000, loss: 0.001736
 >> iter 55000, loss: 0.001686
 >> iter 56000, loss: 0.001651
 >> iter 57000, loss: 0.001607
 >> iter 58000, loss: 0.001575
 >> iter 59000, loss: 0.001534
 >> iter 60000, loss: 0.001505
   Number of active neurons: 8
 >> iter 61000, loss: 0.001467
 >> iter 62000, loss: 0.001441
 >> iter 63000, loss: 0.001406
 >> iter 64000, loss: 0.001381
 >> iter 65000, loss: 0.001350
 >> iter 66000, loss: 0.001327
 >> iter 67000, loss: 0.001299
 >> iter 68000, loss: 0.001276
 >> iter 69000, loss: 0.001251
 >> iter 70000, loss: 0.001229
   Number of active neurons: 8
 >> iter 71000, loss: 0.001206
 >> iter 72000, loss: 0.001187
 >> iter 73000, loss: 0.001164
 >> iter 74000, loss: 0.001147
 >> iter 75000, loss: 0.001125
 >> iter 76000, loss: 0.001109
 >> iter 77000, loss: 0.001089
 >> iter 78000, loss: 0.001074
 >> iter 79000, loss: 0.001054
 >> iter 80000, loss: 0.001041
   Number of active neurons: 8
 >> iter 81000, loss: 0.001023
 >> iter 82000, loss: 0.001010
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.637613
 >> iter 2000, loss: 15.102572
 >> iter 3000, loss: 13.763193
 >> iter 4000, loss: 13.266114
 >> iter 5000, loss: 13.068273
 >> iter 6000, loss: 12.997944
 >> iter 7000, loss: 12.961843
 >> iter 8000, loss: 12.955521
 >> iter 9000, loss: 12.943423
 >> iter 10000, loss: 12.949120
   Number of active neurons: 5
 >> iter 11000, loss: 12.938526
 >> iter 12000, loss: 12.918049
 >> iter 13000, loss: 12.400507
 >> iter 14000, loss: 10.814668
 >> iter 15000, loss: 9.277030
 >> iter 16000, loss: 8.312762
 >> iter 17000, loss: 7.758169
 >> iter 18000, loss: 4.014916
 >> iter 19000, loss: 1.541890
 >> iter 20000, loss: 0.604339
   Number of active neurons: 8
 >> iter 21000, loss: 0.249787
 >> iter 22000, loss: 0.112748
 >> iter 23000, loss: 0.058331
 >> iter 24000, loss: 0.035500
 >> iter 25000, loss: 0.025233
 >> iter 26000, loss: 0.019888
 >> iter 27000, loss: 0.016834
 >> iter 28000, loss: 0.014709
 >> iter 29000, loss: 0.013228
 >> iter 30000, loss: 0.011971
   Number of active neurons: 8
 >> iter 31000, loss: 0.011028
 >> iter 32000, loss: 0.010156
 >> iter 33000, loss: 0.009483
 >> iter 34000, loss: 0.008829
 >> iter 35000, loss: 0.008320
 >> iter 36000, loss: 0.007805
 >> iter 37000, loss: 0.007414
 >> iter 38000, loss: 0.006995
 >> iter 39000, loss: 0.006684
 >> iter 40000, loss: 0.006333
   Number of active neurons: 8
 >> iter 41000, loss: 0.006083
 >> iter 42000, loss: 0.005783
 >> iter 43000, loss: 0.005576
 >> iter 44000, loss: 0.005319
 >> iter 45000, loss: 0.005145
 >> iter 46000, loss: 0.004924
 >> iter 47000, loss: 0.004773
 >> iter 48000, loss: 0.004580
 >> iter 49000, loss: 0.004452
 >> iter 50000, loss: 0.004281
   Number of active neurons: 8
 >> iter 51000, loss: 0.004174
 >> iter 52000, loss: 0.004016
 >> iter 53000, loss: 0.003924
 >> iter 54000, loss: 0.003782
 >> iter 55000, loss: 0.003705
 >> iter 56000, loss: 0.003572
 >> iter 57000, loss: 0.003506
 >> iter 58000, loss: 0.003384
 >> iter 59000, loss: 0.003328
 >> iter 60000, loss: 0.003216
   Number of active neurons: 8
 >> iter 61000, loss: 0.003167
 >> iter 62000, loss: 0.003062
 >> iter 63000, loss: 0.003019
 >> iter 64000, loss: 0.002924
 >> iter 65000, loss: 0.002883
 >> iter 66000, loss: 0.002797
 >> iter 67000, loss: 0.002761
 >> iter 68000, loss: 0.002677
 >> iter 69000, loss: 0.002646
 >> iter 70000, loss: 0.002568
   Number of active neurons: 8
 >> iter 71000, loss: 0.002539
 >> iter 72000, loss: 0.002465
 >> iter 73000, loss: 0.002440
 >> iter 74000, loss: 0.002370
 >> iter 75000, loss: 0.002347
 >> iter 76000, loss: 0.002281
 >> iter 77000, loss: 0.002261
 >> iter 78000, loss: 0.002199
 >> iter 79000, loss: 0.002181
 >> iter 80000, loss: 0.002123
   Number of active neurons: 8
 >> iter 81000, loss: 0.002106
 >> iter 82000, loss: 0.002052
 >> iter 83000, loss: 0.002035
 >> iter 84000, loss: 0.001983
 >> iter 85000, loss: 0.001967
 >> iter 86000, loss: 0.001919
 >> iter 87000, loss: 0.001905
 >> iter 88000, loss: 0.001858
 >> iter 89000, loss: 0.001846
 >> iter 90000, loss: 0.001801
   Number of active neurons: 8
 >> iter 91000, loss: 0.001789
 >> iter 92000, loss: 0.001747
 >> iter 93000, loss: 0.001735
 >> iter 94000, loss: 0.001694
 >> iter 95000, loss: 0.001683
 >> iter 96000, loss: 0.001644
 >> iter 97000, loss: 0.001634
 >> iter 98000, loss: 0.001598
 >> iter 99000, loss: 0.001587
 >> iter 100000, loss: 0.001553
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0249997500025
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.639652
 >> iter 2000, loss: 15.082044
 >> iter 3000, loss: 13.737712
 >> iter 4000, loss: 13.241588
 >> iter 5000, loss: 13.045780
 >> iter 6000, loss: 12.978115
 >> iter 7000, loss: 12.943713
 >> iter 8000, loss: 12.939115
 >> iter 9000, loss: 12.927677
 >> iter 10000, loss: 12.934404
   Number of active neurons: 4
 >> iter 11000, loss: 12.924309
 >> iter 12000, loss: 12.929461
 >> iter 13000, loss: 12.910544
 >> iter 14000, loss: 12.122464
 >> iter 15000, loss: 5.139370
 >> iter 16000, loss: 1.953000
 >> iter 17000, loss: 0.753500
 >> iter 18000, loss: 0.301847
 >> iter 19000, loss: 0.130007
 >> iter 20000, loss: 0.063314
   Number of active neurons: 8
 >> iter 21000, loss: 0.036267
 >> iter 22000, loss: 0.024605
 >> iter 23000, loss: 0.018886
 >> iter 24000, loss: 0.015785
 >> iter 25000, loss: 0.013715
 >> iter 26000, loss: 0.012302
 >> iter 27000, loss: 0.011130
 >> iter 28000, loss: 0.010250
 >> iter 29000, loss: 0.009440
 >> iter 30000, loss: 0.008812
   Number of active neurons: 8
 >> iter 31000, loss: 0.008202
 >> iter 32000, loss: 0.007728
 >> iter 33000, loss: 0.007253
 >> iter 34000, loss: 0.006881
 >> iter 35000, loss: 0.006500
 >> iter 36000, loss: 0.006202
 >> iter 37000, loss: 0.005885
 >> iter 38000, loss: 0.005643
 >> iter 39000, loss: 0.005377
 >> iter 40000, loss: 0.005178
   Number of active neurons: 8
 >> iter 41000, loss: 0.004951
 >> iter 42000, loss: 0.004780
 >> iter 43000, loss: 0.004585
 >> iter 44000, loss: 0.004439
 >> iter 45000, loss: 0.004269
 >> iter 46000, loss: 0.004144
 >> iter 47000, loss: 0.003994
 >> iter 48000, loss: 0.003884
 >> iter 49000, loss: 0.003752
 >> iter 50000, loss: 0.003656
   Number of active neurons: 8
 >> iter 51000, loss: 0.003536
 >> iter 52000, loss: 0.003452
 >> iter 53000, loss: 0.003342
 >> iter 54000, loss: 0.003270
 >> iter 55000, loss: 0.003170
 >> iter 56000, loss: 0.003106
 >> iter 57000, loss: 0.003015
 >> iter 58000, loss: 0.002957
 >> iter 59000, loss: 0.002875
 >> iter 60000, loss: 0.002822
   Number of active neurons: 8
 >> iter 61000, loss: 0.002746
 >> iter 62000, loss: 0.002699
 >> iter 63000, loss: 0.002627
 >> iter 64000, loss: 0.002585
 >> iter 65000, loss: 0.002520
 >> iter 66000, loss: 0.002480
 >> iter 67000, loss: 0.002421
 >> iter 68000, loss: 0.002384
 >> iter 69000, loss: 0.002329
 >> iter 70000, loss: 0.002294
   Number of active neurons: 8
 >> iter 71000, loss: 0.002244
 >> iter 72000, loss: 0.002211
 >> iter 73000, loss: 0.002164
 >> iter 74000, loss: 0.002135
 >> iter 75000, loss: 0.002089
 >> iter 76000, loss: 0.002063
 >> iter 77000, loss: 0.002021
 >> iter 78000, loss: 0.001996
 >> iter 79000, loss: 0.001955
 >> iter 80000, loss: 0.001933
   Number of active neurons: 8
 >> iter 81000, loss: 0.001895
 >> iter 82000, loss: 0.001874
 >> iter 83000, loss: 0.001837
 >> iter 84000, loss: 0.001818
 >> iter 85000, loss: 0.001784
 >> iter 86000, loss: 0.001766
 >> iter 87000, loss: 0.001733
 >> iter 88000, loss: 0.001717
 >> iter 89000, loss: 0.001685
 >> iter 90000, loss: 0.001670
   Number of active neurons: 8
 >> iter 91000, loss: 0.001639
 >> iter 92000, loss: 0.001625
 >> iter 93000, loss: 0.001596
 >> iter 94000, loss: 0.001583
 >> iter 95000, loss: 0.001555
 >> iter 96000, loss: 0.001543
 >> iter 97000, loss: 0.001517
 >> iter 98000, loss: 0.001505
 >> iter 99000, loss: 0.001480
 >> iter 100000, loss: 0.001468
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.622979
 >> iter 2000, loss: 15.097658
 >> iter 3000, loss: 13.766230
 >> iter 4000, loss: 13.272263
 >> iter 5000, loss: 13.077066
 >> iter 6000, loss: 13.006932
 >> iter 7000, loss: 12.972605
 >> iter 8000, loss: 12.966371
 >> iter 9000, loss: 12.954897
 >> iter 10000, loss: 12.960133
   Number of active neurons: 6
 >> iter 11000, loss: 12.948364
 >> iter 12000, loss: 12.952109
 >> iter 13000, loss: 12.938068
 >> iter 14000, loss: 12.936701
 >> iter 15000, loss: 12.818268
 >> iter 16000, loss: 11.371337
 >> iter 17000, loss: 5.390935
 >> iter 18000, loss: 2.042713
 >> iter 19000, loss: 0.783515
 >> iter 20000, loss: 0.310304
   Number of active neurons: 8
 >> iter 21000, loss: 0.130749
 >> iter 22000, loss: 0.061561
 >> iter 23000, loss: 0.033779
 >> iter 24000, loss: 0.022075
 >> iter 25000, loss: 0.016462
 >> iter 26000, loss: 0.013538
 >> iter 27000, loss: 0.011628
 >> iter 28000, loss: 0.010378
 >> iter 29000, loss: 0.009336
 >> iter 30000, loss: 0.008570
   Number of active neurons: 8
 >> iter 31000, loss: 0.007860
 >> iter 32000, loss: 0.007324
 >> iter 33000, loss: 0.006796
 >> iter 34000, loss: 0.006392
 >> iter 35000, loss: 0.005980
 >> iter 36000, loss: 0.005666
 >> iter 37000, loss: 0.005334
 >> iter 38000, loss: 0.005084
 >> iter 39000, loss: 0.004812
 >> iter 40000, loss: 0.004607
   Number of active neurons: 8
 >> iter 41000, loss: 0.004379
 >> iter 42000, loss: 0.004209
 >> iter 43000, loss: 0.004014
 >> iter 44000, loss: 0.003871
 >> iter 45000, loss: 0.003703
 >> iter 46000, loss: 0.003581
 >> iter 47000, loss: 0.003433
 >> iter 48000, loss: 0.003329
 >> iter 49000, loss: 0.003199
 >> iter 50000, loss: 0.003109
   Number of active neurons: 8
 >> iter 51000, loss: 0.002992
 >> iter 52000, loss: 0.002913
 >> iter 53000, loss: 0.002808
 >> iter 54000, loss: 0.002740
 >> iter 55000, loss: 0.002645
 >> iter 56000, loss: 0.002584
 >> iter 57000, loss: 0.002498
 >> iter 58000, loss: 0.002444
 >> iter 59000, loss: 0.002365
 >> iter 60000, loss: 0.002316
   Number of active neurons: 8
 >> iter 61000, loss: 0.002244
 >> iter 62000, loss: 0.002201
 >> iter 63000, loss: 0.002134
 >> iter 64000, loss: 0.002095
 >> iter 65000, loss: 0.002034
 >> iter 66000, loss: 0.001998
 >> iter 67000, loss: 0.001942
 >> iter 68000, loss: 0.001909
 >> iter 69000, loss: 0.001857
 >> iter 70000, loss: 0.001827
   Number of active neurons: 8
 >> iter 71000, loss: 0.001779
 >> iter 72000, loss: 0.001752
 >> iter 73000, loss: 0.001706
 >> iter 74000, loss: 0.001682
 >> iter 75000, loss: 0.001639
 >> iter 76000, loss: 0.001617
 >> iter 77000, loss: 0.001578
 >> iter 78000, loss: 0.001556
 >> iter 79000, loss: 0.001519
 >> iter 80000, loss: 0.001500
   Number of active neurons: 8
 >> iter 81000, loss: 0.001465
 >> iter 82000, loss: 0.001447
 >> iter 83000, loss: 0.001414
 >> iter 84000, loss: 0.001398
 >> iter 85000, loss: 0.001367
 >> iter 86000, loss: 0.001351
 >> iter 87000, loss: 0.001322
 >> iter 88000, loss: 0.001308
 >> iter 89000, loss: 0.001280
 >> iter 90000, loss: 0.001267
   Number of active neurons: 8
 >> iter 91000, loss: 0.001241
 >> iter 92000, loss: 0.001228
 >> iter 93000, loss: 0.001204
 >> iter 94000, loss: 0.001192
 >> iter 95000, loss: 0.001169
 >> iter 96000, loss: 0.001158
 >> iter 97000, loss: 0.001135
 >> iter 98000, loss: 0.001125
 >> iter 99000, loss: 0.001104
 >> iter 100000, loss: 0.001094
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.642410
 >> iter 2000, loss: 15.092573
 >> iter 3000, loss: 13.748293
 >> iter 4000, loss: 13.252332
 >> iter 5000, loss: 13.056926
 >> iter 6000, loss: 12.989785
 >> iter 7000, loss: 12.955857
 >> iter 8000, loss: 12.951696
 >> iter 9000, loss: 12.940453
 >> iter 10000, loss: 12.947529
   Number of active neurons: 5
 >> iter 11000, loss: 12.937467
 >> iter 12000, loss: 12.943993
 >> iter 13000, loss: 12.934431
 >> iter 14000, loss: 12.941911
 >> iter 15000, loss: 12.932187
 >> iter 16000, loss: 12.680695
 >> iter 17000, loss: 6.791184
 >> iter 18000, loss: 2.566053
 >> iter 19000, loss: 0.983257
 >> iter 20000, loss: 0.387611
   Number of active neurons: 8
 >> iter 21000, loss: 0.160626
 >> iter 22000, loss: 0.073553
 >> iter 23000, loss: 0.038889
 >> iter 24000, loss: 0.024559
 >> iter 25000, loss: 0.017848
 >> iter 26000, loss: 0.014497
 >> iter 27000, loss: 0.012349
 >> iter 28000, loss: 0.011012
 >> iter 29000, loss: 0.009877
 >> iter 30000, loss: 0.009087
   Number of active neurons: 8
 >> iter 31000, loss: 0.008320
 >> iter 32000, loss: 0.007772
 >> iter 33000, loss: 0.007202
 >> iter 34000, loss: 0.006794
 >> iter 35000, loss: 0.006350
 >> iter 36000, loss: 0.006034
 >> iter 37000, loss: 0.005676
 >> iter 38000, loss: 0.005426
 >> iter 39000, loss: 0.005131
 >> iter 40000, loss: 0.004929
   Number of active neurons: 8
 >> iter 41000, loss: 0.004682
 >> iter 42000, loss: 0.004513
 >> iter 43000, loss: 0.004302
 >> iter 44000, loss: 0.004161
 >> iter 45000, loss: 0.003979
 >> iter 46000, loss: 0.003864
 >> iter 47000, loss: 0.003700
 >> iter 48000, loss: 0.003602
 >> iter 49000, loss: 0.003459
 >> iter 50000, loss: 0.003374
   Number of active neurons: 8
 >> iter 51000, loss: 0.003245
 >> iter 52000, loss: 0.003170
 >> iter 53000, loss: 0.003054
 >> iter 54000, loss: 0.002990
 >> iter 55000, loss: 0.002886
 >> iter 56000, loss: 0.002829
 >> iter 57000, loss: 0.002734
 >> iter 58000, loss: 0.002684
 >> iter 59000, loss: 0.002598
 >> iter 60000, loss: 0.002553
   Number of active neurons: 8
 >> iter 61000, loss: 0.002474
 >> iter 62000, loss: 0.002434
 >> iter 63000, loss: 0.002360
 >> iter 64000, loss: 0.002324
 >> iter 65000, loss: 0.002257
 >> iter 66000, loss: 0.002224
 >> iter 67000, loss: 0.002163
 >> iter 68000, loss: 0.002132
 >> iter 69000, loss: 0.002076
 >> iter 70000, loss: 0.002047
   Number of active neurons: 8
 >> iter 71000, loss: 0.001995
 >> iter 72000, loss: 0.001969
 >> iter 73000, loss: 0.001919
 >> iter 74000, loss: 0.001897
 >> iter 75000, loss: 0.001850
 >> iter 76000, loss: 0.001830
 >> iter 77000, loss: 0.001786
 >> iter 78000, loss: 0.001766
 >> iter 79000, loss: 0.001724
 >> iter 80000, loss: 0.001707
   Number of active neurons: 8
 >> iter 81000, loss: 0.001668
 >> iter 82000, loss: 0.001652
 >> iter 83000, loss: 0.001615
 >> iter 84000, loss: 0.001600
 >> iter 85000, loss: 0.001565
 >> iter 86000, loss: 0.001551
 >> iter 87000, loss: 0.001517
 >> iter 88000, loss: 0.001505
 >> iter 89000, loss: 0.001473
 >> iter 90000, loss: 0.001462
   Number of active neurons: 8
 >> iter 91000, loss: 0.001431
 >> iter 92000, loss: 0.001421
 >> iter 93000, loss: 0.001392
 >> iter 94000, loss: 0.001382
 >> iter 95000, loss: 0.001354
 >> iter 96000, loss: 0.001345
 >> iter 97000, loss: 0.001319
 >> iter 98000, loss: 0.001310
 >> iter 99000, loss: 0.001285
 >> iter 100000, loss: 0.001277
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.648007
 >> iter 2000, loss: 15.091710
 >> iter 3000, loss: 13.748631
 >> iter 4000, loss: 13.253262
 >> iter 5000, loss: 13.057186
 >> iter 6000, loss: 12.989198
 >> iter 7000, loss: 12.954664
 >> iter 8000, loss: 12.949510
 >> iter 9000, loss: 12.937972
 >> iter 10000, loss: 12.943022
   Number of active neurons: 5
 >> iter 11000, loss: 12.931581
 >> iter 12000, loss: 12.915891
 >> iter 13000, loss: 12.535271
 >> iter 14000, loss: 7.973012
 >> iter 15000, loss: 3.031799
 >> iter 16000, loss: 1.160488
 >> iter 17000, loss: 0.454712
 >> iter 18000, loss: 0.189565
 >> iter 19000, loss: 0.086232
 >> iter 20000, loss: 0.045384
   Number of active neurons: 8
 >> iter 21000, loss: 0.028195
 >> iter 22000, loss: 0.020567
 >> iter 23000, loss: 0.016418
 >> iter 24000, loss: 0.014095
 >> iter 25000, loss: 0.012369
 >> iter 26000, loss: 0.011205
 >> iter 27000, loss: 0.010160
 >> iter 28000, loss: 0.009422
 >> iter 29000, loss: 0.008691
 >> iter 30000, loss: 0.008138
   Number of active neurons: 8
 >> iter 31000, loss: 0.007563
 >> iter 32000, loss: 0.007163
 >> iter 33000, loss: 0.006710
 >> iter 34000, loss: 0.006383
 >> iter 35000, loss: 0.006017
 >> iter 36000, loss: 0.005775
 >> iter 37000, loss: 0.005472
 >> iter 38000, loss: 0.005254
 >> iter 39000, loss: 0.004993
 >> iter 40000, loss: 0.004836
   Number of active neurons: 8
 >> iter 41000, loss: 0.004609
 >> iter 42000, loss: 0.004460
 >> iter 43000, loss: 0.004266
 >> iter 44000, loss: 0.004148
 >> iter 45000, loss: 0.003979
 >> iter 46000, loss: 0.003873
 >> iter 47000, loss: 0.003721
 >> iter 48000, loss: 0.003634
 >> iter 49000, loss: 0.003500
 >> iter 50000, loss: 0.003422
   Number of active neurons: 8
 >> iter 51000, loss: 0.003300
 >> iter 52000, loss: 0.003233
 >> iter 53000, loss: 0.003121
 >> iter 54000, loss: 0.003063
 >> iter 55000, loss: 0.002960
 >> iter 56000, loss: 0.002911
 >> iter 57000, loss: 0.002816
 >> iter 58000, loss: 0.002772
 >> iter 59000, loss: 0.002686
 >> iter 60000, loss: 0.002647
   Number of active neurons: 8
 >> iter 61000, loss: 0.002566
 >> iter 62000, loss: 0.002532
 >> iter 63000, loss: 0.002455
 >> iter 64000, loss: 0.002428
 >> iter 65000, loss: 0.002356
 >> iter 66000, loss: 0.002330
 >> iter 67000, loss: 0.002265
 >> iter 68000, loss: 0.002240
 >> iter 69000, loss: 0.002179
 >> iter 70000, loss: 0.002156
   Number of active neurons: 8
 >> iter 71000, loss: 0.002099
 >> iter 72000, loss: 0.002078
 >> iter 73000, loss: 0.002024
 >> iter 74000, loss: 0.002007
 >> iter 75000, loss: 0.001955
 >> iter 76000, loss: 0.001940
 >> iter 77000, loss: 0.001891
 >> iter 78000, loss: 0.001878
 >> iter 79000, loss: 0.001830
 >> iter 80000, loss: 0.001819
   Number of active neurons: 8
 >> iter 81000, loss: 0.001774
 >> iter 82000, loss: 0.001763
 >> iter 83000, loss: 0.001720
 >> iter 84000, loss: 0.001711
 >> iter 85000, loss: 0.001669
 >> iter 86000, loss: 0.001662
 >> iter 87000, loss: 0.001621
 >> iter 88000, loss: 0.001615
 >> iter 89000, loss: 0.001576
 >> iter 90000, loss: 0.001571
   Number of active neurons: 8
 >> iter 91000, loss: 0.001534
 >> iter 92000, loss: 0.001529
 >> iter 93000, loss: 0.001494
 >> iter 94000, loss: 0.001489
 >> iter 95000, loss: 0.001456
 >> iter 96000, loss: 0.001452
 >> iter 97000, loss: 0.001420
 >> iter 98000, loss: 0.001416
 >> iter 99000, loss: 0.001385
 >> iter 100000, loss: 0.001381
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0129998700013
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.634195
 >> iter 2000, loss: 15.116914
 >> iter 3000, loss: 13.781648
 >> iter 4000, loss: 13.283298
 >> iter 5000, loss: 13.083855
 >> iter 6000, loss: 13.011632
 >> iter 7000, loss: 12.974851
 >> iter 8000, loss: 12.966545
 >> iter 9000, loss: 12.952633
 >> iter 10000, loss: 12.952306
   Number of active neurons: 6
 >> iter 11000, loss: 12.806215
 >> iter 12000, loss: 8.028040
 >> iter 13000, loss: 3.171884
 >> iter 14000, loss: 1.216549
 >> iter 15000, loss: 0.476553
 >> iter 16000, loss: 0.265588
 >> iter 17000, loss: 0.116729
 >> iter 18000, loss: 0.057612
 >> iter 19000, loss: 0.059157
 >> iter 20000, loss: 0.033183
   Number of active neurons: 8
 >> iter 21000, loss: 0.021713
 >> iter 22000, loss: 0.016362
 >> iter 23000, loss: 0.013392
 >> iter 24000, loss: 0.011648
 >> iter 25000, loss: 0.010344
 >> iter 26000, loss: 0.009426
 >> iter 27000, loss: 0.008608
 >> iter 28000, loss: 0.007998
 >> iter 29000, loss: 0.007407
 >> iter 30000, loss: 0.006955
   Number of active neurons: 8
 >> iter 31000, loss: 0.006502
 >> iter 32000, loss: 0.006149
 >> iter 33000, loss: 0.005794
 >> iter 34000, loss: 0.005508
 >> iter 35000, loss: 0.005221
 >> iter 36000, loss: 0.004986
 >> iter 37000, loss: 0.004750
 >> iter 38000, loss: 0.004554
 >> iter 39000, loss: 0.004357
 >> iter 40000, loss: 0.004192
   Number of active neurons: 8
 >> iter 41000, loss: 0.004026
 >> iter 42000, loss: 0.003881
 >> iter 43000, loss: 0.003738
 >> iter 44000, loss: 0.003613
 >> iter 45000, loss: 0.003490
 >> iter 46000, loss: 0.003380
 >> iter 47000, loss: 0.003271
 >> iter 48000, loss: 0.003173
 >> iter 49000, loss: 0.003078
 >> iter 50000, loss: 0.002992
   Number of active neurons: 8
 >> iter 51000, loss: 0.002906
 >> iter 52000, loss: 0.002828
 >> iter 53000, loss: 0.002750
 >> iter 54000, loss: 0.002681
 >> iter 55000, loss: 0.002611
 >> iter 56000, loss: 0.002549
 >> iter 57000, loss: 0.002485
 >> iter 58000, loss: 0.002428
 >> iter 59000, loss: 0.002371
 >> iter 60000, loss: 0.002318
   Number of active neurons: 8
 >> iter 61000, loss: 0.002267
 >> iter 62000, loss: 0.002219
 >> iter 63000, loss: 0.002170
 >> iter 64000, loss: 0.002126
 >> iter 65000, loss: 0.002083
 >> iter 66000, loss: 0.002040
 >> iter 67000, loss: 0.002001
 >> iter 68000, loss: 0.001961
 >> iter 69000, loss: 0.001926
 >> iter 70000, loss: 0.001887
   Number of active neurons: 8
 >> iter 71000, loss: 0.001856
 >> iter 72000, loss: 0.001820
 >> iter 73000, loss: 0.001790
 >> iter 74000, loss: 0.001757
 >> iter 75000, loss: 0.001729
 >> iter 76000, loss: 0.001699
 >> iter 77000, loss: 0.001673
 >> iter 78000, loss: 0.001643
 >> iter 79000, loss: 0.001618
 >> iter 80000, loss: 0.001591
   Number of active neurons: 8
 >> iter 81000, loss: 0.001568
 >> iter 82000, loss: 0.001542
 >> iter 83000, loss: 0.001521
 >> iter 84000, loss: 0.001497
 >> iter 85000, loss: 0.001476
 >> iter 86000, loss: 0.001454
 >> iter 87000, loss: 0.001434
 >> iter 88000, loss: 0.001413
 >> iter 89000, loss: 0.001394
 >> iter 90000, loss: 0.001374
   Number of active neurons: 8
 >> iter 91000, loss: 0.001357
 >> iter 92000, loss: 0.001337
 >> iter 93000, loss: 0.001322
 >> iter 94000, loss: 0.001302
 >> iter 95000, loss: 0.001288
 >> iter 96000, loss: 0.001269
 >> iter 97000, loss: 0.001256
 >> iter 98000, loss: 0.001237
 >> iter 99000, loss: 0.001226
 >> iter 100000, loss: 0.001207
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.623273
 >> iter 2000, loss: 15.108755
 >> iter 3000, loss: 13.772990
 >> iter 4000, loss: 13.272962
 >> iter 5000, loss: 13.067519
 >> iter 6000, loss: 12.993628
 >> iter 7000, loss: 12.953279
 >> iter 8000, loss: 12.945748
 >> iter 9000, loss: 12.930968
 >> iter 10000, loss: 12.908900
   Number of active neurons: 4
 >> iter 11000, loss: 10.452189
 >> iter 12000, loss: 3.978566
 >> iter 13000, loss: 1.509714
 >> iter 14000, loss: 0.584114
 >> iter 15000, loss: 0.235557
 >> iter 16000, loss: 0.102770
 >> iter 17000, loss: 0.051067
 >> iter 18000, loss: 0.029957
 >> iter 19000, loss: 0.020731
 >> iter 20000, loss: 0.016149
   Number of active neurons: 8
 >> iter 21000, loss: 0.013563
 >> iter 22000, loss: 0.011868
 >> iter 23000, loss: 0.010625
 >> iter 24000, loss: 0.009668
 >> iter 25000, loss: 0.008865
 >> iter 26000, loss: 0.008204
 >> iter 27000, loss: 0.007620
 >> iter 28000, loss: 0.007134
 >> iter 29000, loss: 0.006687
 >> iter 30000, loss: 0.006309
   Number of active neurons: 8
 >> iter 31000, loss: 0.005953
 >> iter 32000, loss: 0.005651
 >> iter 33000, loss: 0.005364
 >> iter 34000, loss: 0.005116
 >> iter 35000, loss: 0.004878
 >> iter 36000, loss: 0.004673
 >> iter 37000, loss: 0.004471
 >> iter 38000, loss: 0.004300
 >> iter 39000, loss: 0.004126
 >> iter 40000, loss: 0.003983
   Number of active neurons: 8
 >> iter 41000, loss: 0.003832
 >> iter 42000, loss: 0.003706
 >> iter 43000, loss: 0.003575
 >> iter 44000, loss: 0.003465
 >> iter 45000, loss: 0.003350
 >> iter 46000, loss: 0.003255
 >> iter 47000, loss: 0.003151
 >> iter 48000, loss: 0.003066
 >> iter 49000, loss: 0.002975
 >> iter 50000, loss: 0.002899
   Number of active neurons: 8
 >> iter 51000, loss: 0.002816
 >> iter 52000, loss: 0.002748
 >> iter 53000, loss: 0.002671
 >> iter 54000, loss: 0.002613
 >> iter 55000, loss: 0.002542
 >> iter 56000, loss: 0.002489
 >> iter 57000, loss: 0.002425
 >> iter 58000, loss: 0.002376
 >> iter 59000, loss: 0.002318
 >> iter 60000, loss: 0.002274
   Number of active neurons: 8
 >> iter 61000, loss: 0.002220
 >> iter 62000, loss: 0.002179
 >> iter 63000, loss: 0.002129
 >> iter 64000, loss: 0.002092
 >> iter 65000, loss: 0.002046
 >> iter 66000, loss: 0.002011
 >> iter 67000, loss: 0.001970
 >> iter 68000, loss: 0.001936
 >> iter 69000, loss: 0.001898
 >> iter 70000, loss: 0.001865
   Number of active neurons: 8
 >> iter 71000, loss: 0.001831
 >> iter 72000, loss: 0.001801
 >> iter 73000, loss: 0.001768
 >> iter 74000, loss: 0.001741
 >> iter 75000, loss: 0.001709
 >> iter 76000, loss: 0.001685
 >> iter 77000, loss: 0.001655
 >> iter 78000, loss: 0.001632
 >> iter 79000, loss: 0.001603
 >> iter 80000, loss: 0.001582
   Number of active neurons: 8
 >> iter 81000, loss: 0.001555
 >> iter 82000, loss: 0.001535
 >> iter 83000, loss: 0.001509
 >> iter 84000, loss: 0.001490
 >> iter 85000, loss: 0.001466
 >> iter 86000, loss: 0.001449
 >> iter 87000, loss: 0.001425
 >> iter 88000, loss: 0.001409
 >> iter 89000, loss: 0.001386
 >> iter 90000, loss: 0.001371
   Number of active neurons: 8
 >> iter 91000, loss: 0.001350
 >> iter 92000, loss: 0.001335
 >> iter 93000, loss: 0.001316
 >> iter 94000, loss: 0.001301
 >> iter 95000, loss: 0.001283
 >> iter 96000, loss: 0.001269
 >> iter 97000, loss: 0.001252
 >> iter 98000, loss: 0.001238
 >> iter 99000, loss: 0.001222
 >> iter 100000, loss: 0.001209
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0029999700003
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.608633
 >> iter 2000, loss: 15.079455
 >> iter 3000, loss: 13.745841
 >> iter 4000, loss: 13.253368
 >> iter 5000, loss: 13.058559
 >> iter 6000, loss: 12.991373
 >> iter 7000, loss: 12.957081
 >> iter 8000, loss: 12.952696
 >> iter 9000, loss: 12.941176
 >> iter 10000, loss: 12.947790
   Number of active neurons: 4
 >> iter 11000, loss: 12.937573
 >> iter 12000, loss: 12.939105
 >> iter 13000, loss: 12.754339
 >> iter 14000, loss: 7.827825
 >> iter 15000, loss: 2.958903
 >> iter 16000, loss: 1.123826
 >> iter 17000, loss: 0.436485
 >> iter 18000, loss: 0.177493
 >> iter 19000, loss: 0.078850
 >> iter 20000, loss: 0.040097
   Number of active neurons: 8
 >> iter 21000, loss: 0.024304
 >> iter 22000, loss: 0.017163
 >> iter 23000, loss: 0.013670
 >> iter 24000, loss: 0.011552
 >> iter 25000, loss: 0.010224
 >> iter 26000, loss: 0.009157
 >> iter 27000, loss: 0.008391
 >> iter 28000, loss: 0.007688
 >> iter 29000, loss: 0.007160
 >> iter 30000, loss: 0.006639
   Number of active neurons: 8
 >> iter 31000, loss: 0.006248
 >> iter 32000, loss: 0.005842
 >> iter 33000, loss: 0.005543
 >> iter 34000, loss: 0.005216
 >> iter 35000, loss: 0.004978
 >> iter 36000, loss: 0.004711
 >> iter 37000, loss: 0.004517
 >> iter 38000, loss: 0.004294
 >> iter 39000, loss: 0.004135
 >> iter 40000, loss: 0.003945
   Number of active neurons: 8
 >> iter 41000, loss: 0.003814
 >> iter 42000, loss: 0.003647
 >> iter 43000, loss: 0.003536
 >> iter 44000, loss: 0.003390
 >> iter 45000, loss: 0.003297
 >> iter 46000, loss: 0.003169
 >> iter 47000, loss: 0.003087
 >> iter 48000, loss: 0.002972
 >> iter 49000, loss: 0.002902
 >> iter 50000, loss: 0.002800
   Number of active neurons: 8
 >> iter 51000, loss: 0.002737
 >> iter 52000, loss: 0.002645
 >> iter 53000, loss: 0.002589
 >> iter 54000, loss: 0.002507
 >> iter 55000, loss: 0.002457
 >> iter 56000, loss: 0.002382
 >> iter 57000, loss: 0.002338
 >> iter 58000, loss: 0.002269
 >> iter 59000, loss: 0.002230
 >> iter 60000, loss: 0.002166
   Number of active neurons: 8
 >> iter 61000, loss: 0.002132
 >> iter 62000, loss: 0.002072
 >> iter 63000, loss: 0.002041
 >> iter 64000, loss: 0.001985
 >> iter 65000, loss: 0.001958
 >> iter 66000, loss: 0.001905
 >> iter 67000, loss: 0.001881
 >> iter 68000, loss: 0.001832
 >> iter 69000, loss: 0.001810
 >> iter 70000, loss: 0.001763
   Number of active neurons: 8
 >> iter 71000, loss: 0.001744
 >> iter 72000, loss: 0.001700
 >> iter 73000, loss: 0.001683
 >> iter 74000, loss: 0.001642
 >> iter 75000, loss: 0.001626
 >> iter 76000, loss: 0.001587
 >> iter 77000, loss: 0.001573
 >> iter 78000, loss: 0.001535
 >> iter 79000, loss: 0.001522
 >> iter 80000, loss: 0.001487
   Number of active neurons: 8
 >> iter 81000, loss: 0.001475
 >> iter 82000, loss: 0.001442
 >> iter 83000, loss: 0.001431
 >> iter 84000, loss: 0.001399
 >> iter 85000, loss: 0.001389
 >> iter 86000, loss: 0.001359
 >> iter 87000, loss: 0.001350
 >> iter 88000, loss: 0.001321
 >> iter 89000, loss: 0.001312
 >> iter 90000, loss: 0.001285
   Number of active neurons: 8
 >> iter 91000, loss: 0.001277
 >> iter 92000, loss: 0.001251
 >> iter 93000, loss: 0.001244
 >> iter 94000, loss: 0.001218
 >> iter 95000, loss: 0.001212
 >> iter 96000, loss: 0.001188
 >> iter 97000, loss: 0.001182
 >> iter 98000, loss: 0.001158
 >> iter 99000, loss: 0.001154
 >> iter 100000, loss: 0.001130
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00999990000101
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.603436
 >> iter 2000, loss: 15.092179
 >> iter 3000, loss: 13.761341
 >> iter 4000, loss: 13.265269
 >> iter 5000, loss: 13.063613
 >> iter 6000, loss: 12.991814
 >> iter 7000, loss: 12.952902
 >> iter 8000, loss: 12.945745
 >> iter 9000, loss: 12.931280
 >> iter 10000, loss: 12.854914
   Number of active neurons: 6
 >> iter 11000, loss: 9.179591
 >> iter 12000, loss: 3.555234
 >> iter 13000, loss: 1.354619
 >> iter 14000, loss: 0.596292
 >> iter 15000, loss: 0.240678
 >> iter 16000, loss: 0.105543
 >> iter 17000, loss: 0.051971
 >> iter 18000, loss: 0.029822
 >> iter 19000, loss: 0.020034
 >> iter 20000, loss: 0.015336
   Number of active neurons: 8
 >> iter 21000, loss: 0.012652
 >> iter 22000, loss: 0.010998
 >> iter 23000, loss: 0.009760
 >> iter 24000, loss: 0.008854
 >> iter 25000, loss: 0.008093
 >> iter 26000, loss: 0.007469
 >> iter 27000, loss: 0.006963
 >> iter 28000, loss: 0.006488
 >> iter 29000, loss: 0.006120
 >> iter 30000, loss: 0.005740
   Number of active neurons: 8
 >> iter 31000, loss: 0.005436
 >> iter 32000, loss: 0.005131
 >> iter 33000, loss: 0.004883
 >> iter 34000, loss: 0.004633
 >> iter 35000, loss: 0.004430
 >> iter 36000, loss: 0.004221
 >> iter 37000, loss: 0.004050
 >> iter 38000, loss: 0.003874
 >> iter 39000, loss: 0.003729
 >> iter 40000, loss: 0.003580
   Number of active neurons: 8
 >> iter 41000, loss: 0.003455
 >> iter 42000, loss: 0.003323
 >> iter 43000, loss: 0.003216
 >> iter 44000, loss: 0.003099
 >> iter 45000, loss: 0.003007
 >> iter 46000, loss: 0.002904
 >> iter 47000, loss: 0.002821
 >> iter 48000, loss: 0.002729
 >> iter 49000, loss: 0.002658
 >> iter 50000, loss: 0.002575
   Number of active neurons: 8
 >> iter 51000, loss: 0.002510
 >> iter 52000, loss: 0.002436
 >> iter 53000, loss: 0.002377
 >> iter 54000, loss: 0.002311
 >> iter 55000, loss: 0.002257
 >> iter 56000, loss: 0.002197
 >> iter 57000, loss: 0.002149
 >> iter 58000, loss: 0.002093
 >> iter 59000, loss: 0.002051
 >> iter 60000, loss: 0.001999
   Number of active neurons: 8
 >> iter 61000, loss: 0.001960
 >> iter 62000, loss: 0.001912
 >> iter 63000, loss: 0.001876
 >> iter 64000, loss: 0.001832
 >> iter 65000, loss: 0.001800
 >> iter 66000, loss: 0.001758
 >> iter 67000, loss: 0.001729
 >> iter 68000, loss: 0.001690
 >> iter 69000, loss: 0.001664
 >> iter 70000, loss: 0.001625
   Number of active neurons: 8
 >> iter 71000, loss: 0.001602
 >> iter 72000, loss: 0.001567
 >> iter 73000, loss: 0.001544
 >> iter 74000, loss: 0.001513
 >> iter 75000, loss: 0.001491
 >> iter 76000, loss: 0.001461
 >> iter 77000, loss: 0.001442
 >> iter 78000, loss: 0.001413
 >> iter 79000, loss: 0.001395
 >> iter 80000, loss: 0.001368
   Number of active neurons: 8
 >> iter 81000, loss: 0.001351
 >> iter 82000, loss: 0.001326
 >> iter 83000, loss: 0.001309
 >> iter 84000, loss: 0.001285
 >> iter 85000, loss: 0.001270
 >> iter 86000, loss: 0.001248
 >> iter 87000, loss: 0.001233
 >> iter 88000, loss: 0.001212
 >> iter 89000, loss: 0.001198
 >> iter 90000, loss: 0.001178
   Number of active neurons: 8
 >> iter 91000, loss: 0.001165
 >> iter 92000, loss: 0.001146
 >> iter 93000, loss: 0.001134
 >> iter 94000, loss: 0.001116
 >> iter 95000, loss: 0.001104
 >> iter 96000, loss: 0.001087
 >> iter 97000, loss: 0.001076
 >> iter 98000, loss: 0.001059
 >> iter 99000, loss: 0.001049
 >> iter 100000, loss: 0.001033
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.616701
 >> iter 2000, loss: 15.090803
 >> iter 3000, loss: 13.759355
 >> iter 4000, loss: 13.264099
 >> iter 5000, loss: 13.061349
 >> iter 6000, loss: 12.989023
 >> iter 7000, loss: 12.948188
 >> iter 8000, loss: 12.941010
 >> iter 9000, loss: 12.925423
 >> iter 10000, loss: 12.931154
   Number of active neurons: 3
 >> iter 11000, loss: 12.918331
 >> iter 12000, loss: 12.924487
 >> iter 13000, loss: 12.912816
 >> iter 14000, loss: 12.921245
 >> iter 15000, loss: 12.912465
 >> iter 16000, loss: 12.915325
 >> iter 17000, loss: 12.683159
 >> iter 18000, loss: 6.489595
 >> iter 19000, loss: 2.457167
 >> iter 20000, loss: 0.940029
   Number of active neurons: 8
 >> iter 21000, loss: 0.369928
 >> iter 22000, loss: 0.154247
 >> iter 23000, loss: 0.071252
 >> iter 24000, loss: 0.038287
 >> iter 25000, loss: 0.024379
 >> iter 26000, loss: 0.017941
 >> iter 27000, loss: 0.014528
 >> iter 28000, loss: 0.012453
 >> iter 29000, loss: 0.011008
 >> iter 30000, loss: 0.009911
   Number of active neurons: 8
 >> iter 31000, loss: 0.009028
 >> iter 32000, loss: 0.008293
 >> iter 33000, loss: 0.007670
 >> iter 34000, loss: 0.007130
 >> iter 35000, loss: 0.006660
 >> iter 36000, loss: 0.006247
 >> iter 37000, loss: 0.005876
 >> iter 38000, loss: 0.005551
 >> iter 39000, loss: 0.005252
 >> iter 40000, loss: 0.004990
   Number of active neurons: 8
 >> iter 41000, loss: 0.004744
 >> iter 42000, loss: 0.004527
 >> iter 43000, loss: 0.004321
 >> iter 44000, loss: 0.004138
 >> iter 45000, loss: 0.003966
 >> iter 46000, loss: 0.003812
 >> iter 47000, loss: 0.003661
 >> iter 48000, loss: 0.003529
 >> iter 49000, loss: 0.003399
 >> iter 50000, loss: 0.003285
   Number of active neurons: 8
 >> iter 51000, loss: 0.003169
 >> iter 52000, loss: 0.003070
 >> iter 53000, loss: 0.002967
 >> iter 54000, loss: 0.002881
 >> iter 55000, loss: 0.002788
 >> iter 56000, loss: 0.002713
 >> iter 57000, loss: 0.002630
 >> iter 58000, loss: 0.002563
 >> iter 59000, loss: 0.002489
 >> iter 60000, loss: 0.002428
   Number of active neurons: 8
 >> iter 61000, loss: 0.002360
 >> iter 62000, loss: 0.002306
 >> iter 63000, loss: 0.002244
 >> iter 64000, loss: 0.002195
 >> iter 65000, loss: 0.002139
 >> iter 66000, loss: 0.002094
 >> iter 67000, loss: 0.002043
 >> iter 68000, loss: 0.002002
 >> iter 69000, loss: 0.001954
 >> iter 70000, loss: 0.001916
   Number of active neurons: 8
 >> iter 71000, loss: 0.001873
 >> iter 72000, loss: 0.001837
 >> iter 73000, loss: 0.001797
 >> iter 74000, loss: 0.001765
 >> iter 75000, loss: 0.001727
 >> iter 76000, loss: 0.001698
 >> iter 77000, loss: 0.001663
 >> iter 78000, loss: 0.001636
 >> iter 79000, loss: 0.001603
 >> iter 80000, loss: 0.001578
   Number of active neurons: 8
 >> iter 81000, loss: 0.001550
 >> iter 82000, loss: 0.001525
 >> iter 83000, loss: 0.001497
 >> iter 84000, loss: 0.001473
 >> iter 85000, loss: 0.001448
 >> iter 86000, loss: 0.001426
 >> iter 87000, loss: 0.001404
 >> iter 88000, loss: 0.001381
 >> iter 89000, loss: 0.001360
 >> iter 90000, loss: 0.001339
   Number of active neurons: 8
 >> iter 91000, loss: 0.001319
 >> iter 92000, loss: 0.001299
 >> iter 93000, loss: 0.001281
 >> iter 94000, loss: 0.001261
 >> iter 95000, loss: 0.001244
 >> iter 96000, loss: 0.001226
 >> iter 97000, loss: 0.001210
 >> iter 98000, loss: 0.001193
 >> iter 99000, loss: 0.001177
 >> iter 100000, loss: 0.001161
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.619072
 >> iter 2000, loss: 15.101545
 >> iter 3000, loss: 13.767740
 >> iter 4000, loss: 13.270549
 >> iter 5000, loss: 13.070205
 >> iter 6000, loss: 12.998653
 >> iter 7000, loss: 12.961893
 >> iter 8000, loss: 12.955787
 >> iter 9000, loss: 12.943458
 >> iter 10000, loss: 12.949259
   Number of active neurons: 4
 >> iter 11000, loss: 12.938454
 >> iter 12000, loss: 12.926612
 >> iter 13000, loss: 12.425003
 >> iter 14000, loss: 6.307929
 >> iter 15000, loss: 2.398886
 >> iter 16000, loss: 0.923458
 >> iter 17000, loss: 0.362857
 >> iter 18000, loss: 0.150605
 >> iter 19000, loss: 0.068983
 >> iter 20000, loss: 0.036731
   Number of active neurons: 8
 >> iter 21000, loss: 0.023169
 >> iter 22000, loss: 0.017010
 >> iter 23000, loss: 0.013729
 >> iter 24000, loss: 0.011819
 >> iter 25000, loss: 0.010433
 >> iter 26000, loss: 0.009454
 >> iter 27000, loss: 0.008603
 >> iter 28000, loss: 0.007965
 >> iter 29000, loss: 0.007356
 >> iter 30000, loss: 0.006890
   Number of active neurons: 8
 >> iter 31000, loss: 0.006425
 >> iter 32000, loss: 0.006070
 >> iter 33000, loss: 0.005704
 >> iter 34000, loss: 0.005423
 >> iter 35000, loss: 0.005125
 >> iter 36000, loss: 0.004899
 >> iter 37000, loss: 0.004650
 >> iter 38000, loss: 0.004466
 >> iter 39000, loss: 0.004256
 >> iter 40000, loss: 0.004105
   Number of active neurons: 8
 >> iter 41000, loss: 0.003924
 >> iter 42000, loss: 0.003794
 >> iter 43000, loss: 0.003637
 >> iter 44000, loss: 0.003526
 >> iter 45000, loss: 0.003390
 >> iter 46000, loss: 0.003295
 >> iter 47000, loss: 0.003173
 >> iter 48000, loss: 0.003090
 >> iter 49000, loss: 0.002982
 >> iter 50000, loss: 0.002910
   Number of active neurons: 8
 >> iter 51000, loss: 0.002812
 >> iter 52000, loss: 0.002748
 >> iter 53000, loss: 0.002658
 >> iter 54000, loss: 0.002603
 >> iter 55000, loss: 0.002521
 >> iter 56000, loss: 0.002473
 >> iter 57000, loss: 0.002398
 >> iter 58000, loss: 0.002355
 >> iter 59000, loss: 0.002286
 >> iter 60000, loss: 0.002247
   Number of active neurons: 8
 >> iter 61000, loss: 0.002183
 >> iter 62000, loss: 0.002148
 >> iter 63000, loss: 0.002088
 >> iter 64000, loss: 0.002057
 >> iter 65000, loss: 0.002003
 >> iter 66000, loss: 0.001973
 >> iter 67000, loss: 0.001925
 >> iter 68000, loss: 0.001896
 >> iter 69000, loss: 0.001851
 >> iter 70000, loss: 0.001824
   Number of active neurons: 8
 >> iter 71000, loss: 0.001783
 >> iter 72000, loss: 0.001758
 >> iter 73000, loss: 0.001719
 >> iter 74000, loss: 0.001697
 >> iter 75000, loss: 0.001660
 >> iter 76000, loss: 0.001640
 >> iter 77000, loss: 0.001605
 >> iter 78000, loss: 0.001586
 >> iter 79000, loss: 0.001552
 >> iter 80000, loss: 0.001535
   Number of active neurons: 8
 >> iter 81000, loss: 0.001504
 >> iter 82000, loss: 0.001488
 >> iter 83000, loss: 0.001458
 >> iter 84000, loss: 0.001443
 >> iter 85000, loss: 0.001415
 >> iter 86000, loss: 0.001401
 >> iter 87000, loss: 0.001374
 >> iter 88000, loss: 0.001361
 >> iter 89000, loss: 0.001335
 >> iter 90000, loss: 0.001323
   Number of active neurons: 8
 >> iter 91000, loss: 0.001299
 >> iter 92000, loss: 0.001288
 >> iter 93000, loss: 0.001265
 >> iter 94000, loss: 0.001254
 >> iter 95000, loss: 0.001232
 >> iter 96000, loss: 0.001222
 >> iter 97000, loss: 0.001201
 >> iter 98000, loss: 0.001191
 >> iter 99000, loss: 0.001172
 >> iter 100000, loss: 0.001162
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0049999500005
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.612267
 >> iter 2000, loss: 15.073664
 >> iter 3000, loss: 13.739081
 >> iter 4000, loss: 13.247311
 >> iter 5000, loss: 13.053293
 >> iter 6000, loss: 12.986104
 >> iter 7000, loss: 12.951802
 >> iter 8000, loss: 12.946599
 >> iter 9000, loss: 12.934609
 >> iter 10000, loss: 12.939824
   Number of active neurons: 5
 >> iter 11000, loss: 12.929040
 >> iter 12000, loss: 12.928980
 >> iter 13000, loss: 12.732322
 >> iter 14000, loss: 6.681554
 >> iter 15000, loss: 2.535386
 >> iter 16000, loss: 0.977279
 >> iter 17000, loss: 0.386196
 >> iter 18000, loss: 0.161997
 >> iter 19000, loss: 0.075456
 >> iter 20000, loss: 0.040900
   Number of active neurons: 8
 >> iter 21000, loss: 0.026271
 >> iter 22000, loss: 0.019425
 >> iter 23000, loss: 0.015793
 >> iter 24000, loss: 0.013553
 >> iter 25000, loss: 0.011996
 >> iter 26000, loss: 0.010812
 >> iter 27000, loss: 0.009860
 >> iter 28000, loss: 0.009076
 >> iter 29000, loss: 0.008401
 >> iter 30000, loss: 0.007828
   Number of active neurons: 8
 >> iter 31000, loss: 0.007317
 >> iter 32000, loss: 0.006877
 >> iter 33000, loss: 0.006478
 >> iter 34000, loss: 0.006130
 >> iter 35000, loss: 0.005808
 >> iter 36000, loss: 0.005527
 >> iter 37000, loss: 0.005261
 >> iter 38000, loss: 0.005031
 >> iter 39000, loss: 0.004806
 >> iter 40000, loss: 0.004616
   Number of active neurons: 8
 >> iter 41000, loss: 0.004425
 >> iter 42000, loss: 0.004261
 >> iter 43000, loss: 0.004097
 >> iter 44000, loss: 0.003956
 >> iter 45000, loss: 0.003814
 >> iter 46000, loss: 0.003693
 >> iter 47000, loss: 0.003566
 >> iter 48000, loss: 0.003460
 >> iter 49000, loss: 0.003349
 >> iter 50000, loss: 0.003255
   Number of active neurons: 8
 >> iter 51000, loss: 0.003155
 >> iter 52000, loss: 0.003072
 >> iter 53000, loss: 0.002981
 >> iter 54000, loss: 0.002908
 >> iter 55000, loss: 0.002826
 >> iter 56000, loss: 0.002760
 >> iter 57000, loss: 0.002686
 >> iter 58000, loss: 0.002626
 >> iter 59000, loss: 0.002560
 >> iter 60000, loss: 0.002505
   Number of active neurons: 8
 >> iter 61000, loss: 0.002443
 >> iter 62000, loss: 0.002394
 >> iter 63000, loss: 0.002336
 >> iter 64000, loss: 0.002291
 >> iter 65000, loss: 0.002239
 >> iter 66000, loss: 0.002197
 >> iter 67000, loss: 0.002150
 >> iter 68000, loss: 0.002111
 >> iter 69000, loss: 0.002067
 >> iter 70000, loss: 0.002030
   Number of active neurons: 8
 >> iter 71000, loss: 0.001990
 >> iter 72000, loss: 0.001955
 >> iter 73000, loss: 0.001917
 >> iter 74000, loss: 0.001886
 >> iter 75000, loss: 0.001850
 >> iter 76000, loss: 0.001821
 >> iter 77000, loss: 0.001788
 >> iter 78000, loss: 0.001761
 >> iter 79000, loss: 0.001728
 >> iter 80000, loss: 0.001704
   Number of active neurons: 8
 >> iter 81000, loss: 0.001673
 >> iter 82000, loss: 0.001650
 >> iter 83000, loss: 0.001621
 >> iter 84000, loss: 0.001599
 >> iter 85000, loss: 0.001572
 >> iter 86000, loss: 0.001552
 >> iter 87000, loss: 0.001526
 >> iter 88000, loss: 0.001507
 >> iter 89000, loss: 0.001482
 >> iter 90000, loss: 0.001464
   Number of active neurons: 8
 >> iter 91000, loss: 0.001440
 >> iter 92000, loss: 0.001424
 >> iter 93000, loss: 0.001401
 >> iter 94000, loss: 0.001385
 >> iter 95000, loss: 0.001364
 >> iter 96000, loss: 0.001349
 >> iter 97000, loss: 0.001329
 >> iter 98000, loss: 0.001314
 >> iter 99000, loss: 0.001294
 >> iter 100000, loss: 0.001280
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0029999700003
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.630665
 >> iter 2000, loss: 15.083149
 >> iter 3000, loss: 13.737735
 >> iter 4000, loss: 13.240743
 >> iter 5000, loss: 13.039468
 >> iter 6000, loss: 12.971017
 >> iter 7000, loss: 12.933292
 >> iter 8000, loss: 12.928962
 >> iter 9000, loss: 12.915512
 >> iter 10000, loss: 12.922851
   Number of active neurons: 3
 >> iter 11000, loss: 12.911468
 >> iter 12000, loss: 12.917671
 >> iter 13000, loss: 12.905445
 >> iter 14000, loss: 12.582265
 >> iter 15000, loss: 7.666500
 >> iter 16000, loss: 2.920223
 >> iter 17000, loss: 1.121629
 >> iter 18000, loss: 0.441785
 >> iter 19000, loss: 0.184066
 >> iter 20000, loss: 0.084932
   Number of active neurons: 8
 >> iter 21000, loss: 0.045308
 >> iter 22000, loss: 0.028749
 >> iter 23000, loss: 0.020935
 >> iter 24000, loss: 0.016949
 >> iter 25000, loss: 0.014393
 >> iter 26000, loss: 0.012747
 >> iter 27000, loss: 0.011395
 >> iter 28000, loss: 0.010419
 >> iter 29000, loss: 0.009514
 >> iter 30000, loss: 0.008836
   Number of active neurons: 8
 >> iter 31000, loss: 0.008169
 >> iter 32000, loss: 0.007664
 >> iter 33000, loss: 0.007152
 >> iter 34000, loss: 0.006761
 >> iter 35000, loss: 0.006353
 >> iter 36000, loss: 0.006044
 >> iter 37000, loss: 0.005710
 >> iter 38000, loss: 0.005461
 >> iter 39000, loss: 0.005183
 >> iter 40000, loss: 0.004979
   Number of active neurons: 8
 >> iter 41000, loss: 0.004744
 >> iter 42000, loss: 0.004571
 >> iter 43000, loss: 0.004371
 >> iter 44000, loss: 0.004224
 >> iter 45000, loss: 0.004051
 >> iter 46000, loss: 0.003927
 >> iter 47000, loss: 0.003774
 >> iter 48000, loss: 0.003667
 >> iter 49000, loss: 0.003532
 >> iter 50000, loss: 0.003439
   Number of active neurons: 8
 >> iter 51000, loss: 0.003317
 >> iter 52000, loss: 0.003237
 >> iter 53000, loss: 0.003127
 >> iter 54000, loss: 0.003057
 >> iter 55000, loss: 0.002957
 >> iter 56000, loss: 0.002896
 >> iter 57000, loss: 0.002805
 >> iter 58000, loss: 0.002750
 >> iter 59000, loss: 0.002668
 >> iter 60000, loss: 0.002620
   Number of active neurons: 8
 >> iter 61000, loss: 0.002543
 >> iter 62000, loss: 0.002500
 >> iter 63000, loss: 0.002429
 >> iter 64000, loss: 0.002391
 >> iter 65000, loss: 0.002326
 >> iter 66000, loss: 0.002291
 >> iter 67000, loss: 0.002231
 >> iter 68000, loss: 0.002199
 >> iter 69000, loss: 0.002144
 >> iter 70000, loss: 0.002114
   Number of active neurons: 8
 >> iter 71000, loss: 0.002064
 >> iter 72000, loss: 0.002036
 >> iter 73000, loss: 0.001989
 >> iter 74000, loss: 0.001965
 >> iter 75000, loss: 0.001919
 >> iter 76000, loss: 0.001898
 >> iter 77000, loss: 0.001855
 >> iter 78000, loss: 0.001835
 >> iter 79000, loss: 0.001795
 >> iter 80000, loss: 0.001777
   Number of active neurons: 8
 >> iter 81000, loss: 0.001738
 >> iter 82000, loss: 0.001722
 >> iter 83000, loss: 0.001685
 >> iter 84000, loss: 0.001671
 >> iter 85000, loss: 0.001635
 >> iter 86000, loss: 0.001622
 >> iter 87000, loss: 0.001588
 >> iter 88000, loss: 0.001576
 >> iter 89000, loss: 0.001543
 >> iter 90000, loss: 0.001532
   Number of active neurons: 8
 >> iter 91000, loss: 0.001501
 >> iter 92000, loss: 0.001492
 >> iter 93000, loss: 0.001461
 >> iter 94000, loss: 0.001453
 >> iter 95000, loss: 0.001424
 >> iter 96000, loss: 0.001416
 >> iter 97000, loss: 0.001388
 >> iter 98000, loss: 0.001382
 >> iter 99000, loss: 0.001354
 >> iter 100000, loss: 0.001348
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

