 > Problema: tomita6nueva
 > Args:
   - Hidden size: 2
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.954580
 >> iter 2000, loss: 15.270586
 >> iter 3000, loss: 13.875298
 >> iter 4000, loss: 13.358430
 >> iter 5000, loss: 13.157808
 >> iter 6000, loss: 13.097265
 >> iter 7000, loss: 13.056996
 >> iter 8000, loss: 13.057097
 >> iter 9000, loss: 13.034170
 >> iter 10000, loss: 13.049087
   Number of active neurons: 2
 >> iter 11000, loss: 13.036170
 >> iter 12000, loss: 13.031688
 >> iter 13000, loss: 13.015823
 >> iter 14000, loss: 13.039511
 >> iter 15000, loss: 13.025729
 >> iter 16000, loss: 13.056231
 >> iter 17000, loss: 13.038674
 >> iter 18000, loss: 13.060345
 >> iter 19000, loss: 13.025975
 >> iter 20000, loss: 13.058416
   Number of active neurons: 2
 >> iter 21000, loss: 13.029584
 >> iter 22000, loss: 13.045570
 >> iter 23000, loss: 13.007528
 >> iter 24000, loss: 13.044533
 >> iter 25000, loss: 13.025996
 >> iter 26000, loss: 13.052777
 >> iter 27000, loss: 13.030682
 >> iter 28000, loss: 13.054807
 >> iter 29000, loss: 13.033558
 >> iter 30000, loss: 13.061381
   Number of active neurons: 2
 >> iter 31000, loss: 13.038694
 >> iter 32000, loss: 13.054928
 >> iter 33000, loss: 13.027621
 >> iter 34000, loss: 13.050354
 >> iter 35000, loss: 13.036256
 >> iter 36000, loss: 13.058915
 >> iter 37000, loss: 13.044153
 >> iter 38000, loss: 13.055281
 >> iter 39000, loss: 13.026042
 >> iter 40000, loss: 13.059611
   Number of active neurons: 2
 >> iter 41000, loss: 13.027603
 >> iter 42000, loss: 13.059467
 >> iter 43000, loss: 13.031691
 >> iter 44000, loss: 13.058868
 >> iter 45000, loss: 13.016580
 >> iter 46000, loss: 13.056440
 >> iter 47000, loss: 13.027923
 >> iter 48000, loss: 13.054897
 >> iter 49000, loss: 13.028769
 >> iter 50000, loss: 13.066797
   Number of active neurons: 2
 >> iter 51000, loss: 13.029458
 >> iter 52000, loss: 13.061726
 >> iter 53000, loss: 13.031360
 >> iter 54000, loss: 13.056360
 >> iter 55000, loss: 13.021531
 >> iter 56000, loss: 13.049467
 >> iter 57000, loss: 13.009460
 >> iter 58000, loss: 13.058674
 >> iter 59000, loss: 13.025592
 >> iter 60000, loss: 13.060683
   Number of active neurons: 2
 >> iter 61000, loss: 13.018953
 >> iter 62000, loss: 13.054281
 >> iter 63000, loss: 13.026942
 >> iter 64000, loss: 13.061682
 >> iter 65000, loss: 13.027343
 >> iter 66000, loss: 13.054995
 >> iter 67000, loss: 13.024515
 >> iter 68000, loss: 13.046981
 >> iter 69000, loss: 13.017398
 >> iter 70000, loss: 13.059372
   Number of active neurons: 2
 >> iter 71000, loss: 13.022795
 >> iter 72000, loss: 13.068382
 >> iter 73000, loss: 13.031410
 >> iter 74000, loss: 13.054721
 >> iter 75000, loss: 13.021963
 >> iter 76000, loss: 13.060196
 >> iter 77000, loss: 13.023240
 >> iter 78000, loss: 13.065077
 >> iter 79000, loss: 13.022776
 >> iter 80000, loss: 13.057895
   Number of active neurons: 2
 >> iter 81000, loss: 13.023531
 >> iter 82000, loss: 13.070346
 >> iter 83000, loss: 13.036310
 >> iter 84000, loss: 13.064234
 >> iter 85000, loss: 13.037599
 >> iter 86000, loss: 13.067134
 >> iter 87000, loss: 13.029884
 >> iter 88000, loss: 13.073013
 >> iter 89000, loss: 13.027162
 >> iter 90000, loss: 13.063503
   Number of active neurons: 2
 >> iter 91000, loss: 13.029135
 >> iter 92000, loss: 13.062133
 >> iter 93000, loss: 13.021235
 >> iter 94000, loss: 13.072965
 >> iter 95000, loss: 13.047420
 >> iter 96000, loss: 13.069744
 >> iter 97000, loss: 13.025588
 >> iter 98000, loss: 13.070240
 >> iter 99000, loss: 13.038935
 >> iter 100000, loss: 13.077348
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.853543
 >> iter 2000, loss: 15.239978
 >> iter 3000, loss: 13.846153
 >> iter 4000, loss: 13.358534
 >> iter 5000, loss: 13.159283
 >> iter 6000, loss: 13.093816
 >> iter 7000, loss: 13.045675
 >> iter 8000, loss: 13.052516
 >> iter 9000, loss: 13.035760
 >> iter 10000, loss: 13.059855
   Number of active neurons: 2
 >> iter 11000, loss: 13.047510
 >> iter 12000, loss: 13.051771
 >> iter 13000, loss: 13.035918
 >> iter 14000, loss: 13.040183
 >> iter 15000, loss: 13.035492
 >> iter 16000, loss: 13.061227
 >> iter 17000, loss: 13.045819
 >> iter 18000, loss: 13.024638
 >> iter 19000, loss: 13.028751
 >> iter 20000, loss: 13.055012
   Number of active neurons: 2
 >> iter 21000, loss: 13.040761
 >> iter 22000, loss: 13.064400
 >> iter 23000, loss: 13.039161
 >> iter 24000, loss: 13.049939
 >> iter 25000, loss: 13.024668
 >> iter 26000, loss: 13.056273
 >> iter 27000, loss: 13.028649
 >> iter 28000, loss: 13.059082
 >> iter 29000, loss: 13.030971
 >> iter 30000, loss: 13.055145
   Number of active neurons: 2
 >> iter 31000, loss: 13.027173
 >> iter 32000, loss: 13.050662
 >> iter 33000, loss: 13.029026
 >> iter 34000, loss: 13.054993
 >> iter 35000, loss: 13.047653
 >> iter 36000, loss: 13.042253
 >> iter 37000, loss: 13.027472
 >> iter 38000, loss: 13.059019
 >> iter 39000, loss: 13.034602
 >> iter 40000, loss: 13.056921
   Number of active neurons: 2
 >> iter 41000, loss: 13.034723
 >> iter 42000, loss: 13.065092
 >> iter 43000, loss: 13.041986
 >> iter 44000, loss: 13.075596
 >> iter 45000, loss: 13.041713
 >> iter 46000, loss: 13.077788
 >> iter 47000, loss: 13.034094
 >> iter 48000, loss: 13.072356
 >> iter 49000, loss: 13.038279
 >> iter 50000, loss: 13.062604
   Number of active neurons: 2
 >> iter 51000, loss: 13.037036
 >> iter 52000, loss: 13.065050
 >> iter 53000, loss: 13.022785
 >> iter 54000, loss: 13.059745
 >> iter 55000, loss: 13.029431
 >> iter 56000, loss: 13.059410
 >> iter 57000, loss: 13.024203
 >> iter 58000, loss: 13.057079
 >> iter 59000, loss: 13.033906
 >> iter 60000, loss: 13.063498
   Number of active neurons: 2
 >> iter 61000, loss: 13.034432
 >> iter 62000, loss: 13.082305
 >> iter 63000, loss: 13.029081
 >> iter 64000, loss: 13.059280
 >> iter 65000, loss: 13.025643
 >> iter 66000, loss: 13.051839
 >> iter 67000, loss: 13.025712
 >> iter 68000, loss: 13.046261
 >> iter 69000, loss: 13.024621
 >> iter 70000, loss: 13.051675
   Number of active neurons: 2
 >> iter 71000, loss: 13.024551
 >> iter 72000, loss: 13.064205
 >> iter 73000, loss: 13.025341
 >> iter 74000, loss: 13.065930
 >> iter 75000, loss: 13.032943
 >> iter 76000, loss: 13.067474
 >> iter 77000, loss: 13.031516
 >> iter 78000, loss: 13.062271
 >> iter 79000, loss: 13.023966
 >> iter 80000, loss: 13.059543
   Number of active neurons: 2
 >> iter 81000, loss: 13.023503
 >> iter 82000, loss: 13.075576
 >> iter 83000, loss: 13.034310
 >> iter 84000, loss: 13.063181
 >> iter 85000, loss: 13.020656
 >> iter 86000, loss: 13.067828
 >> iter 87000, loss: 13.039347
 >> iter 88000, loss: 13.077764
 >> iter 89000, loss: 13.028691
 >> iter 90000, loss: 13.072044
   Number of active neurons: 2
 >> iter 91000, loss: 13.045842
 >> iter 92000, loss: 13.069680
 >> iter 93000, loss: 13.014367
 >> iter 94000, loss: 13.066292
 >> iter 95000, loss: 13.042247
 >> iter 96000, loss: 13.064184
 >> iter 97000, loss: 13.028648
 >> iter 98000, loss: 13.068008
 >> iter 99000, loss: 13.039334
 >> iter 100000, loss: 13.065616
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.940025
 >> iter 2000, loss: 15.274802
 >> iter 3000, loss: 13.874492
 >> iter 4000, loss: 13.351677
 >> iter 5000, loss: 13.147181
 >> iter 6000, loss: 13.088321
 >> iter 7000, loss: 13.038122
 >> iter 8000, loss: 13.041132
 >> iter 9000, loss: 13.033433
 >> iter 10000, loss: 13.049488
   Number of active neurons: 2
 >> iter 11000, loss: 13.039975
 >> iter 12000, loss: 13.041439
 >> iter 13000, loss: 13.031075
 >> iter 14000, loss: 13.052811
 >> iter 15000, loss: 13.039422
 >> iter 16000, loss: 13.037977
 >> iter 17000, loss: 13.030158
 >> iter 18000, loss: 13.050692
 >> iter 19000, loss: 13.034609
 >> iter 20000, loss: 13.055878
   Number of active neurons: 2
 >> iter 21000, loss: 13.033129
 >> iter 22000, loss: 13.046315
 >> iter 23000, loss: 13.021443
 >> iter 24000, loss: 13.048771
 >> iter 25000, loss: 13.027483
 >> iter 26000, loss: 13.059575
 >> iter 27000, loss: 13.022333
 >> iter 28000, loss: 13.043540
 >> iter 29000, loss: 13.034477
 >> iter 30000, loss: 13.057292
   Number of active neurons: 2
 >> iter 31000, loss: 13.027449
 >> iter 32000, loss: 13.061239
 >> iter 33000, loss: 13.037723
 >> iter 34000, loss: 13.058235
 >> iter 35000, loss: 13.034362
 >> iter 36000, loss: 13.052605
 >> iter 37000, loss: 13.027718
 >> iter 38000, loss: 13.046289
 >> iter 39000, loss: 13.036541
 >> iter 40000, loss: 13.057800
   Number of active neurons: 2
 >> iter 41000, loss: 13.035258
 >> iter 42000, loss: 13.057958
 >> iter 43000, loss: 13.033180
 >> iter 44000, loss: 13.050005
 >> iter 45000, loss: 13.029701
 >> iter 46000, loss: 13.076977
 >> iter 47000, loss: 13.038653
 >> iter 48000, loss: 13.067540
 >> iter 49000, loss: 13.040164
 >> iter 50000, loss: 13.070977
   Number of active neurons: 2
 >> iter 51000, loss: 13.031313
 >> iter 52000, loss: 13.064459
 >> iter 53000, loss: 13.025339
 >> iter 54000, loss: 13.052918
 >> iter 55000, loss: 13.013925
 >> iter 56000, loss: 13.064625
 >> iter 57000, loss: 13.032192
 >> iter 58000, loss: 13.071298
 >> iter 59000, loss: 13.036280
 >> iter 60000, loss: 13.058658
   Number of active neurons: 2
 >> iter 61000, loss: 13.039522
 >> iter 62000, loss: 13.060282
 >> iter 63000, loss: 13.024721
 >> iter 64000, loss: 13.067337
 >> iter 65000, loss: 13.024031
 >> iter 66000, loss: 13.041691
 >> iter 67000, loss: 13.023359
 >> iter 68000, loss: 13.067224
 >> iter 69000, loss: 13.034749
 >> iter 70000, loss: 13.065085
   Number of active neurons: 2
 >> iter 71000, loss: 13.029557
 >> iter 72000, loss: 13.068184
 >> iter 73000, loss: 13.034966
 >> iter 74000, loss: 13.056363
 >> iter 75000, loss: 13.025818
 >> iter 76000, loss: 13.057406
 >> iter 77000, loss: 13.023767
 >> iter 78000, loss: 13.059853
 >> iter 79000, loss: 13.029287
 >> iter 80000, loss: 13.061186
   Number of active neurons: 2
 >> iter 81000, loss: 13.022969
 >> iter 82000, loss: 13.049797
 >> iter 83000, loss: 13.020518
 >> iter 84000, loss: 13.060580
 >> iter 85000, loss: 13.030639
 >> iter 86000, loss: 13.077098
 >> iter 87000, loss: 13.041289
 >> iter 88000, loss: 13.060778
 >> iter 89000, loss: 13.036006
 >> iter 90000, loss: 13.083322
   Number of active neurons: 2
 >> iter 91000, loss: 13.033559
 >> iter 92000, loss: 13.070205
 >> iter 93000, loss: 13.025428
 >> iter 94000, loss: 13.075114
 >> iter 95000, loss: 13.033705
 >> iter 96000, loss: 13.062706
 >> iter 97000, loss: 13.026554
 >> iter 98000, loss: 13.072142
 >> iter 99000, loss: 13.037906
 >> iter 100000, loss: 13.056653
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.273034
 >> iter 2000, loss: 15.911938
 >> iter 3000, loss: 14.646271
 >> iter 4000, loss: 14.192634
 >> iter 5000, loss: 14.023956
 >> iter 6000, loss: 13.968749
 >> iter 7000, loss: 13.935185
 >> iter 8000, loss: 13.933919
 >> iter 9000, loss: 13.927312
 >> iter 10000, loss: 13.929978
   Number of active neurons: 1
 >> iter 11000, loss: 13.912324
 >> iter 12000, loss: 13.921309
 >> iter 13000, loss: 13.921366
 >> iter 14000, loss: 13.927430
 >> iter 15000, loss: 13.917299
 >> iter 16000, loss: 13.932020
 >> iter 17000, loss: 13.924781
 >> iter 18000, loss: 13.923953
 >> iter 19000, loss: 13.909451
 >> iter 20000, loss: 13.927404
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 1
 >> iter 21000, loss: 13.528020
 >> iter 22000, loss: 13.271742
 >> iter 23000, loss: 13.127190
 >> iter 24000, loss: 13.092069
 >> iter 25000, loss: 13.044439
 >> iter 26000, loss: 13.050587
 >> iter 27000, loss: 13.032416
 >> iter 28000, loss: 13.050231
 >> iter 29000, loss: 13.034002
 >> iter 30000, loss: 13.053622
   Number of active neurons: 2
 >> iter 31000, loss: 13.039465
 >> iter 32000, loss: 13.058605
 >> iter 33000, loss: 13.033270
 >> iter 34000, loss: 13.055603
 >> iter 35000, loss: 13.037664
 >> iter 36000, loss: 13.051285
 >> iter 37000, loss: 13.034281
 >> iter 38000, loss: 13.059564
 >> iter 39000, loss: 13.027820
 >> iter 40000, loss: 13.047343
   Number of active neurons: 2
 >> iter 41000, loss: 13.020004
 >> iter 42000, loss: 13.047313
 >> iter 43000, loss: 13.019798
 >> iter 44000, loss: 13.047926
 >> iter 45000, loss: 13.028111
 >> iter 46000, loss: 13.058284
 >> iter 47000, loss: 13.031094
 >> iter 48000, loss: 13.055387
 >> iter 49000, loss: 13.030283
 >> iter 50000, loss: 13.077871
   Number of active neurons: 2
 >> iter 51000, loss: 13.027511
 >> iter 52000, loss: 13.075650
 >> iter 53000, loss: 13.026605
 >> iter 54000, loss: 13.057596
 >> iter 55000, loss: 13.037904
 >> iter 56000, loss: 13.050033
 >> iter 57000, loss: 13.025953
 >> iter 58000, loss: 13.051361
 >> iter 59000, loss: 13.020356
 >> iter 60000, loss: 13.045943
   Number of active neurons: 2
 >> iter 61000, loss: 13.022952
 >> iter 62000, loss: 13.052114
 >> iter 63000, loss: 13.022059
 >> iter 64000, loss: 13.069117
 >> iter 65000, loss: 13.024995
 >> iter 66000, loss: 13.053365
 >> iter 67000, loss: 13.028818
 >> iter 68000, loss: 13.051582
 >> iter 69000, loss: 13.028498
 >> iter 70000, loss: 13.065984
   Number of active neurons: 2
 >> iter 71000, loss: 13.039880
 >> iter 72000, loss: 13.059416
 >> iter 73000, loss: 13.033614
 >> iter 74000, loss: 13.061904
 >> iter 75000, loss: 13.029040
 >> iter 76000, loss: 13.070785
 >> iter 77000, loss: 13.018399
 >> iter 78000, loss: 13.054120
 >> iter 79000, loss: 13.027864
 >> iter 80000, loss: 13.061992
   Number of active neurons: 2
 >> iter 81000, loss: 13.026530
 >> iter 82000, loss: 13.062256
 >> iter 83000, loss: 13.022061
 >> iter 84000, loss: 13.057742
 >> iter 85000, loss: 13.017952
 >> iter 86000, loss: 13.061171
 >> iter 87000, loss: 13.030829
 >> iter 88000, loss: 13.072746
 >> iter 89000, loss: 13.033765
 >> iter 90000, loss: 13.076549
   Number of active neurons: 2
 >> iter 91000, loss: 13.038337
 >> iter 92000, loss: 13.074665
 >> iter 93000, loss: 13.015253
 >> iter 94000, loss: 13.061325
 >> iter 95000, loss: 13.028035
 >> iter 96000, loss: 13.069567
 >> iter 97000, loss: 13.038860
 >> iter 98000, loss: 13.082669
 >> iter 99000, loss: 13.038825
 >> iter 100000, loss: 13.071245
   Number of active neurons: 2
 >> iter 101000, loss: 13.029703
 >> iter 102000, loss: 13.077405
 >> iter 103000, loss: 13.032343
 >> iter 104000, loss: 13.075459
 >> iter 105000, loss: 13.027199
 >> iter 106000, loss: 13.079507
 >> iter 107000, loss: 13.037926
 >> iter 108000, loss: 13.081565
 >> iter 109000, loss: 13.016972
 >> iter 110000, loss: 13.074750
   Number of active neurons: 2
 >> iter 111000, loss: 13.032004
 >> iter 112000, loss: 13.074805
 >> iter 113000, loss: 13.027037
 >> iter 114000, loss: 13.079167
 >> iter 115000, loss: 13.030681
 >> iter 116000, loss: 13.080353
 >> iter 117000, loss: 13.017991
 >> iter 118000, loss: 13.064813
 >> iter 119000, loss: 13.015683
 >> iter 120000, loss: 13.072992
   Number of active neurons: 2
 >> iter 121000, loss: 13.028551
 >> iter 122000, loss: 13.079244
 >> iter 123000, loss: 13.016046
 >> iter 124000, loss: 13.074470
 >> iter 125000, loss: 13.011590
 >> iter 126000, loss: 13.081817
 >> iter 127000, loss: 13.016585
 >> iter 128000, loss: 13.068925
 >> iter 129000, loss: 13.022466
 >> iter 130000, loss: 13.083944
   Number of active neurons: 2
 >> iter 131000, loss: 13.010861
 >> iter 132000, loss: 13.058399
 >> iter 133000, loss: 13.008473
 >> iter 134000, loss: 13.069672
 >> iter 135000, loss: 13.012825
 >> iter 136000, loss: 13.067301
 >> iter 137000, loss: 13.001721
 >> iter 138000, loss: 13.060481
 >> iter 139000, loss: 13.017907
 >> iter 140000, loss: 13.088521
   Number of active neurons: 2
 >> iter 141000, loss: 13.021952
 >> iter 142000, loss: 13.089673
 >> iter 143000, loss: 13.020041
 >> iter 144000, loss: 13.086101
 >> iter 145000, loss: 13.021881
 >> iter 146000, loss: 13.071155
 >> iter 147000, loss: 13.024371
 >> iter 148000, loss: 13.088310
 >> iter 149000, loss: 13.028626
 >> iter 150000, loss: 13.069129
   Number of active neurons: 2
 >> iter 151000, loss: 13.019017
 >> iter 152000, loss: 13.077642
 >> iter 153000, loss: 13.022254
 >> iter 154000, loss: 13.091170
 >> iter 155000, loss: 13.027089
 >> iter 156000, loss: 13.072151
 >> iter 157000, loss: 13.015976
 >> iter 158000, loss: 13.083085
 >> iter 159000, loss: 13.015126
 >> iter 160000, loss: 13.084363
   Number of active neurons: 2
 >> iter 161000, loss: 13.007388
 >> iter 162000, loss: 13.090424
 >> iter 163000, loss: 13.017257
 >> iter 164000, loss: 13.083687
 >> iter 165000, loss: 13.017603
 >> iter 166000, loss: 13.079675
 >> iter 167000, loss: 13.008377
 >> iter 168000, loss: 13.063531
 >> iter 169000, loss: 13.007050
 >> iter 170000, loss: 13.081998
   Number of active neurons: 2
 >> iter 171000, loss: 13.013365
 >> iter 172000, loss: 13.077017
 >> iter 173000, loss: 13.007448
 >> iter 174000, loss: 13.086116
 >> iter 175000, loss: 13.014671
 >> iter 176000, loss: 13.083293
 >> iter 177000, loss: 13.013774
 >> iter 178000, loss: 13.077557
 >> iter 179000, loss: 13.015368
 >> iter 180000, loss: 13.080956
   Number of active neurons: 2
 >> iter 181000, loss: 13.010576
 >> iter 182000, loss: 13.072325
 >> iter 183000, loss: 12.999700
 >> iter 184000, loss: 13.074435
 >> iter 185000, loss: 13.003649
 >> iter 186000, loss: 13.076755
 >> iter 187000, loss: 13.016719
 >> iter 188000, loss: 13.082436
 >> iter 189000, loss: 12.999972
 >> iter 190000, loss: 13.081397
   Number of active neurons: 2
 >> iter 191000, loss: 13.006749
 >> iter 192000, loss: 13.071890
 >> iter 193000, loss: 13.013102
 >> iter 194000, loss: 13.071015
 >> iter 195000, loss: 13.016680
 >> iter 196000, loss: 13.069916
 >> iter 197000, loss: 13.006318
 >> iter 198000, loss: 13.071665
 >> iter 199000, loss: 13.003730
 >> iter 200000, loss: 13.054758
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.246868
 >> iter 2000, loss: 15.900801
 >> iter 3000, loss: 14.657408
 >> iter 4000, loss: 14.204184
 >> iter 5000, loss: 14.024395
 >> iter 6000, loss: 13.966058
 >> iter 7000, loss: 13.933921
 >> iter 8000, loss: 13.920982
 >> iter 9000, loss: 13.922526
 >> iter 10000, loss: 13.908256
   Number of active neurons: 1
 >> iter 11000, loss: 13.920003
 >> iter 12000, loss: 13.920693
 >> iter 13000, loss: 13.921052
 >> iter 14000, loss: 13.921332
 >> iter 15000, loss: 13.908897
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 13.536908
 >> iter 17000, loss: 13.237614
 >> iter 18000, loss: 13.130486
 >> iter 19000, loss: 13.058169
 >> iter 20000, loss: 13.063674
   Number of active neurons: 2
 >> iter 21000, loss: 13.036806
 >> iter 22000, loss: 13.054996
 >> iter 23000, loss: 13.043118
 >> iter 24000, loss: 13.051997
 >> iter 25000, loss: 13.025103
 >> iter 26000, loss: 13.049959
 >> iter 27000, loss: 13.030568
 >> iter 28000, loss: 13.051071
 >> iter 29000, loss: 13.032683
 >> iter 30000, loss: 13.062827
   Number of active neurons: 2
 >> iter 31000, loss: 13.038577
 >> iter 32000, loss: 13.058467
 >> iter 33000, loss: 13.029717
 >> iter 34000, loss: 13.053264
 >> iter 35000, loss: 13.034319
 >> iter 36000, loss: 13.049448
 >> iter 37000, loss: 13.032153
 >> iter 38000, loss: 13.064067
 >> iter 39000, loss: 13.036791
 >> iter 40000, loss: 13.054825
   Number of active neurons: 2
 >> iter 41000, loss: 13.031318
 >> iter 42000, loss: 13.050244
 >> iter 43000, loss: 13.026681
 >> iter 44000, loss: 13.056794
 >> iter 45000, loss: 13.030396
 >> iter 46000, loss: 13.069409
 >> iter 47000, loss: 13.038342
 >> iter 48000, loss: 13.064188
 >> iter 49000, loss: 13.034924
 >> iter 50000, loss: 13.069849
   Number of active neurons: 2
 >> iter 51000, loss: 13.026403
 >> iter 52000, loss: 13.051585
 >> iter 53000, loss: 13.027066
 >> iter 54000, loss: 13.069970
 >> iter 55000, loss: 13.021615
 >> iter 56000, loss: 13.059176
 >> iter 57000, loss: 13.019594
 >> iter 58000, loss: 13.058248
 >> iter 59000, loss: 13.022449
 >> iter 60000, loss: 13.044006
   Number of active neurons: 2
 >> iter 61000, loss: 13.020664
 >> iter 62000, loss: 13.059285
 >> iter 63000, loss: 13.033689
 >> iter 64000, loss: 13.054056
 >> iter 65000, loss: 13.030289
 >> iter 66000, loss: 13.057850
 >> iter 67000, loss: 13.012043
 >> iter 68000, loss: 13.059972
 >> iter 69000, loss: 13.034903
 >> iter 70000, loss: 13.073032
   Number of active neurons: 2
 >> iter 71000, loss: 13.035498
 >> iter 72000, loss: 13.058891
 >> iter 73000, loss: 13.031892
 >> iter 74000, loss: 13.066778
 >> iter 75000, loss: 13.030522
 >> iter 76000, loss: 13.058540
 >> iter 77000, loss: 13.030539
 >> iter 78000, loss: 13.070245
 >> iter 79000, loss: 13.033360
 >> iter 80000, loss: 13.076897
   Number of active neurons: 2
 >> iter 81000, loss: 13.031264
 >> iter 82000, loss: 13.069508
 >> iter 83000, loss: 13.009518
 >> iter 84000, loss: 13.066439
 >> iter 85000, loss: 13.031044
 >> iter 86000, loss: 13.051098
 >> iter 87000, loss: 13.034537
 >> iter 88000, loss: 13.061014
 >> iter 89000, loss: 13.028654
 >> iter 90000, loss: 13.075041
   Number of active neurons: 2
 >> iter 91000, loss: 13.038717
 >> iter 92000, loss: 13.066326
 >> iter 93000, loss: 13.032504
 >> iter 94000, loss: 13.069957
 >> iter 95000, loss: 13.040032
 >> iter 96000, loss: 13.080946
 >> iter 97000, loss: 13.026733
 >> iter 98000, loss: 13.080733
 >> iter 99000, loss: 13.034036
 >> iter 100000, loss: 13.070549
   Number of active neurons: 2
 >> iter 101000, loss: 13.031759
 >> iter 102000, loss: 13.063913
 >> iter 103000, loss: 13.023660
 >> iter 104000, loss: 13.065552
 >> iter 105000, loss: 13.023393
 >> iter 106000, loss: 13.060022
 >> iter 107000, loss: 13.026866
 >> iter 108000, loss: 13.070843
 >> iter 109000, loss: 13.037583
 >> iter 110000, loss: 13.084712
   Number of active neurons: 2
 >> iter 111000, loss: 13.030242
 >> iter 112000, loss: 13.077754
 >> iter 113000, loss: 13.028620
 >> iter 114000, loss: 13.073869
 >> iter 115000, loss: 13.018461
 >> iter 116000, loss: 13.080179
 >> iter 117000, loss: 13.031767
 >> iter 118000, loss: 13.071525
 >> iter 119000, loss: 13.028038
 >> iter 120000, loss: 13.073249
   Number of active neurons: 2
 >> iter 121000, loss: 13.023086
 >> iter 122000, loss: 13.071443
 >> iter 123000, loss: 13.014779
 >> iter 124000, loss: 13.071617
 >> iter 125000, loss: 13.013463
 >> iter 126000, loss: 13.070474
 >> iter 127000, loss: 13.013607
 >> iter 128000, loss: 13.075994
 >> iter 129000, loss: 13.015390
 >> iter 130000, loss: 13.064932
   Number of active neurons: 2
 >> iter 131000, loss: 13.013705
 >> iter 132000, loss: 13.066805
 >> iter 133000, loss: 13.008935
 >> iter 134000, loss: 13.074139
 >> iter 135000, loss: 13.021401
 >> iter 136000, loss: 13.063535
 >> iter 137000, loss: 13.004482
 >> iter 138000, loss: 13.073177
 >> iter 139000, loss: 13.011163
 >> iter 140000, loss: 13.067971
   Number of active neurons: 2
 >> iter 141000, loss: 13.023140
 >> iter 142000, loss: 13.077727
 >> iter 143000, loss: 13.019509
 >> iter 144000, loss: 13.069405
 >> iter 145000, loss: 13.015916
 >> iter 146000, loss: 13.085949
 >> iter 147000, loss: 13.015300
 >> iter 148000, loss: 13.082860
 >> iter 149000, loss: 13.010186
 >> iter 150000, loss: 13.070601
   Number of active neurons: 2
 >> iter 151000, loss: 13.006269
 >> iter 152000, loss: 13.082027
 >> iter 153000, loss: 13.015938
 >> iter 154000, loss: 13.073228
 >> iter 155000, loss: 13.024609
 >> iter 156000, loss: 13.081738
 >> iter 157000, loss: 13.023720
 >> iter 158000, loss: 13.075396
 >> iter 159000, loss: 13.020471
 >> iter 160000, loss: 13.090917
   Number of active neurons: 2
 >> iter 161000, loss: 13.021979
 >> iter 162000, loss: 13.093451
 >> iter 163000, loss: 13.022148
 >> iter 164000, loss: 13.066335
 >> iter 165000, loss: 13.010851
 >> iter 166000, loss: 13.078587
 >> iter 167000, loss: 13.003061
 >> iter 168000, loss: 13.070982
 >> iter 169000, loss: 13.014578
 >> iter 170000, loss: 13.077847
   Number of active neurons: 2
 >> iter 171000, loss: 12.999846
 >> iter 172000, loss: 13.066590
 >> iter 173000, loss: 13.014181
 >> iter 174000, loss: 13.092932
 >> iter 175000, loss: 13.019174
 >> iter 176000, loss: 13.085233
 >> iter 177000, loss: 13.013790
 >> iter 178000, loss: 13.068694
 >> iter 179000, loss: 13.018065
 >> iter 180000, loss: 13.081518
   Number of active neurons: 2
 >> iter 181000, loss: 13.015231
 >> iter 182000, loss: 13.077664
 >> iter 183000, loss: 13.010791
 >> iter 184000, loss: 13.083940
 >> iter 185000, loss: 13.014690
 >> iter 186000, loss: 13.067169
 >> iter 187000, loss: 13.007109
 >> iter 188000, loss: 13.078500
 >> iter 189000, loss: 13.007392
 >> iter 190000, loss: 13.089251
   Number of active neurons: 2
 >> iter 191000, loss: 13.000452
 >> iter 192000, loss: 13.075299
 >> iter 193000, loss: 13.008319
 >> iter 194000, loss: 13.090153
 >> iter 195000, loss: 13.018028
 >> iter 196000, loss: 13.075888
 >> iter 197000, loss: 13.014809
 >> iter 198000, loss: 13.074973
 >> iter 199000, loss: 13.015817
 >> iter 200000, loss: 13.070115
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.886648
 >> iter 2000, loss: 15.233831
 >> iter 3000, loss: 13.857972
 >> iter 4000, loss: 13.366114
 >> iter 5000, loss: 13.160123
 >> iter 6000, loss: 13.101271
 >> iter 7000, loss: 13.048984
 >> iter 8000, loss: 13.045857
 >> iter 9000, loss: 13.047106
 >> iter 10000, loss: 13.058142
   Number of active neurons: 2
 >> iter 11000, loss: 13.044985
 >> iter 12000, loss: 13.055309
 >> iter 13000, loss: 13.037569
 >> iter 14000, loss: 13.029818
 >> iter 15000, loss: 13.026334
 >> iter 16000, loss: 13.057577
 >> iter 17000, loss: 13.039384
 >> iter 18000, loss: 13.046938
 >> iter 19000, loss: 13.036673
 >> iter 20000, loss: 13.052279
   Number of active neurons: 2
 >> iter 21000, loss: 13.026423
 >> iter 22000, loss: 13.056976
 >> iter 23000, loss: 13.050171
 >> iter 24000, loss: 13.059939
 >> iter 25000, loss: 13.034054
 >> iter 26000, loss: 13.050282
 >> iter 27000, loss: 13.032858
 >> iter 28000, loss: 13.049795
 >> iter 29000, loss: 13.039178
 >> iter 30000, loss: 13.053868
   Number of active neurons: 2
 >> iter 31000, loss: 13.027248
 >> iter 32000, loss: 13.060231
 >> iter 33000, loss: 13.039862
 >> iter 34000, loss: 13.050173
 >> iter 35000, loss: 13.034083
 >> iter 36000, loss: 13.049521
 >> iter 37000, loss: 13.032018
 >> iter 38000, loss: 13.057838
 >> iter 39000, loss: 13.030149
 >> iter 40000, loss: 13.056027
   Number of active neurons: 2
 >> iter 41000, loss: 13.037457
 >> iter 42000, loss: 13.059074
 >> iter 43000, loss: 13.026422
 >> iter 44000, loss: 13.063635
 >> iter 45000, loss: 13.038002
 >> iter 46000, loss: 13.066921
 >> iter 47000, loss: 13.029974
 >> iter 48000, loss: 13.060981
 >> iter 49000, loss: 13.030808
 >> iter 50000, loss: 13.053167
   Number of active neurons: 2
 >> iter 51000, loss: 13.034083
 >> iter 52000, loss: 13.076187
 >> iter 53000, loss: 13.032804
 >> iter 54000, loss: 13.063538
 >> iter 55000, loss: 13.028272
 >> iter 56000, loss: 13.068814
 >> iter 57000, loss: 13.032115
 >> iter 58000, loss: 13.053908
 >> iter 59000, loss: 13.014734
 >> iter 60000, loss: 13.065145
   Number of active neurons: 2
 >> iter 61000, loss: 13.022490
 >> iter 62000, loss: 13.063153
 >> iter 63000, loss: 13.026697
 >> iter 64000, loss: 13.068623
 >> iter 65000, loss: 13.020190
 >> iter 66000, loss: 13.054930
 >> iter 67000, loss: 13.025952
 >> iter 68000, loss: 13.059443
 >> iter 69000, loss: 13.027905
 >> iter 70000, loss: 13.064738
   Number of active neurons: 2
 >> iter 71000, loss: 13.036544
 >> iter 72000, loss: 13.074140
 >> iter 73000, loss: 13.023582
 >> iter 74000, loss: 13.056550
 >> iter 75000, loss: 13.023779
 >> iter 76000, loss: 13.060883
 >> iter 77000, loss: 13.033228
 >> iter 78000, loss: 13.057176
 >> iter 79000, loss: 13.025337
 >> iter 80000, loss: 13.062646
   Number of active neurons: 2
 >> iter 81000, loss: 13.031571
 >> iter 82000, loss: 13.071747
 >> iter 83000, loss: 13.031549
 >> iter 84000, loss: 13.079368
 >> iter 85000, loss: 13.038399
 >> iter 86000, loss: 13.069432
 >> iter 87000, loss: 13.032855
 >> iter 88000, loss: 13.075501
 >> iter 89000, loss: 13.028310
 >> iter 90000, loss: 13.069505
   Number of active neurons: 2
 >> iter 91000, loss: 13.031241
 >> iter 92000, loss: 13.063787
 >> iter 93000, loss: 13.021128
 >> iter 94000, loss: 13.074979
 >> iter 95000, loss: 13.040261
 >> iter 96000, loss: 13.058686
 >> iter 97000, loss: 13.035554
 >> iter 98000, loss: 13.070313
 >> iter 99000, loss: 13.040846
 >> iter 100000, loss: 13.059661
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.367516
 >> iter 2000, loss: 15.943673
 >> iter 3000, loss: 14.672349
 >> iter 4000, loss: 14.203534
 >> iter 5000, loss: 14.024515
 >> iter 6000, loss: 13.959177
 >> iter 7000, loss: 13.935423
 >> iter 8000, loss: 13.932523
 >> iter 9000, loss: 13.927605
 >> iter 10000, loss: 13.933389
   Number of active neurons: 1
 >> iter 11000, loss: 13.929038
 >> iter 12000, loss: 13.928466
 >> iter 13000, loss: 13.923203
 >> iter 14000, loss: 13.925063
 >> iter 15000, loss: 13.911557
 >> iter 16000, loss: 13.922704
 >> iter 17000, loss: 13.919625
 >> iter 18000, loss: 13.924121
 >> iter 19000, loss: 13.922847
 >> iter 20000, loss: 13.929783
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 1
 >> iter 21000, loss: 13.487415
 >> iter 22000, loss: 13.243327
 >> iter 23000, loss: 13.117761
 >> iter 24000, loss: 13.081299
 >> iter 25000, loss: 13.043753
 >> iter 26000, loss: 13.045313
 >> iter 27000, loss: 13.040375
 >> iter 28000, loss: 13.073320
 >> iter 29000, loss: 13.038495
 >> iter 30000, loss: 13.059347
   Number of active neurons: 2
 >> iter 31000, loss: 13.037238
 >> iter 32000, loss: 13.061565
 >> iter 33000, loss: 13.042364
 >> iter 34000, loss: 13.054180
 >> iter 35000, loss: 13.034114
 >> iter 36000, loss: 13.053407
 >> iter 37000, loss: 13.035293
 >> iter 38000, loss: 13.063504
 >> iter 39000, loss: 13.036333
 >> iter 40000, loss: 13.055833
   Number of active neurons: 2
 >> iter 41000, loss: 13.037895
 >> iter 42000, loss: 13.059965
 >> iter 43000, loss: 13.032572
 >> iter 44000, loss: 13.053043
 >> iter 45000, loss: 13.029710
 >> iter 46000, loss: 13.060689
 >> iter 47000, loss: 13.030716
 >> iter 48000, loss: 13.057317
 >> iter 49000, loss: 13.023080
 >> iter 50000, loss: 13.071456
   Number of active neurons: 2
 >> iter 51000, loss: 13.033877
 >> iter 52000, loss: 13.069461
 >> iter 53000, loss: 13.031387
 >> iter 54000, loss: 13.063196
 >> iter 55000, loss: 13.026755
 >> iter 56000, loss: 13.056273
 >> iter 57000, loss: 13.025171
 >> iter 58000, loss: 13.059273
 >> iter 59000, loss: 13.025009
 >> iter 60000, loss: 13.061034
   Number of active neurons: 2
 >> iter 61000, loss: 13.034001
 >> iter 62000, loss: 13.060125
 >> iter 63000, loss: 13.038114
 >> iter 64000, loss: 13.066667
 >> iter 65000, loss: 13.029583
 >> iter 66000, loss: 13.076550
 >> iter 67000, loss: 13.025538
 >> iter 68000, loss: 13.069622
 >> iter 69000, loss: 13.035933
 >> iter 70000, loss: 13.072166
   Number of active neurons: 2
 >> iter 71000, loss: 13.027139
 >> iter 72000, loss: 13.066920
 >> iter 73000, loss: 13.029410
 >> iter 74000, loss: 13.074670
 >> iter 75000, loss: 13.032548
 >> iter 76000, loss: 13.068851
 >> iter 77000, loss: 13.015154
 >> iter 78000, loss: 13.057097
 >> iter 79000, loss: 13.021204
 >> iter 80000, loss: 13.065168
   Number of active neurons: 2
 >> iter 81000, loss: 13.024897
 >> iter 82000, loss: 13.058659
 >> iter 83000, loss: 13.025204
 >> iter 84000, loss: 13.066081
 >> iter 85000, loss: 13.039983
 >> iter 86000, loss: 13.072398
 >> iter 87000, loss: 13.021383
 >> iter 88000, loss: 13.063303
 >> iter 89000, loss: 13.034712
 >> iter 90000, loss: 13.068454
   Number of active neurons: 2
 >> iter 91000, loss: 13.030700
 >> iter 92000, loss: 13.081292
 >> iter 93000, loss: 13.036171
 >> iter 94000, loss: 13.075738
 >> iter 95000, loss: 13.042456
 >> iter 96000, loss: 13.075950
 >> iter 97000, loss: 13.034311
 >> iter 98000, loss: 13.069969
 >> iter 99000, loss: 13.045626
 >> iter 100000, loss: 13.071865
   Number of active neurons: 2
 >> iter 101000, loss: 13.049063
 >> iter 102000, loss: 13.077398
 >> iter 103000, loss: 13.021483
 >> iter 104000, loss: 13.062132
 >> iter 105000, loss: 13.038080
 >> iter 106000, loss: 13.074692
 >> iter 107000, loss: 13.029910
 >> iter 108000, loss: 13.060369
 >> iter 109000, loss: 13.023193
 >> iter 110000, loss: 13.069485
   Number of active neurons: 2
 >> iter 111000, loss: 13.022030
 >> iter 112000, loss: 13.070206
 >> iter 113000, loss: 13.028044
 >> iter 114000, loss: 13.075114
 >> iter 115000, loss: 13.022108
 >> iter 116000, loss: 13.075511
 >> iter 117000, loss: 13.031150
 >> iter 118000, loss: 13.070464
 >> iter 119000, loss: 13.018924
 >> iter 120000, loss: 13.069888
   Number of active neurons: 2
 >> iter 121000, loss: 13.016968
 >> iter 122000, loss: 13.069235
 >> iter 123000, loss: 13.007855
 >> iter 124000, loss: 13.069586
 >> iter 125000, loss: 13.014345
 >> iter 126000, loss: 13.084639
 >> iter 127000, loss: 13.025266
 >> iter 128000, loss: 13.077318
 >> iter 129000, loss: 13.019670
 >> iter 130000, loss: 13.064622
   Number of active neurons: 2
 >> iter 131000, loss: 13.021554
 >> iter 132000, loss: 13.062798
 >> iter 133000, loss: 13.013197
 >> iter 134000, loss: 13.071006
 >> iter 135000, loss: 13.031028
 >> iter 136000, loss: 13.088715
 >> iter 137000, loss: 13.028189
 >> iter 138000, loss: 13.089521
 >> iter 139000, loss: 13.024738
 >> iter 140000, loss: 13.076664
   Number of active neurons: 2
 >> iter 141000, loss: 13.023738
 >> iter 142000, loss: 13.082936
 >> iter 143000, loss: 13.015692
 >> iter 144000, loss: 13.093997
 >> iter 145000, loss: 13.019836
 >> iter 146000, loss: 13.090821
 >> iter 147000, loss: 13.023929
 >> iter 148000, loss: 13.087256
 >> iter 149000, loss: 13.016402
 >> iter 150000, loss: 13.080772
   Number of active neurons: 2
 >> iter 151000, loss: 13.021655
 >> iter 152000, loss: 13.067434
 >> iter 153000, loss: 13.010218
 >> iter 154000, loss: 13.074504
 >> iter 155000, loss: 13.019608
 >> iter 156000, loss: 13.091083
 >> iter 157000, loss: 13.026249
 >> iter 158000, loss: 13.089890
 >> iter 159000, loss: 13.015579
 >> iter 160000, loss: 13.076382
   Number of active neurons: 2
 >> iter 161000, loss: 12.998785
 >> iter 162000, loss: 13.082512
 >> iter 163000, loss: 13.015832
 >> iter 164000, loss: 13.076196
 >> iter 165000, loss: 13.007568
 >> iter 166000, loss: 13.070662
 >> iter 167000, loss: 12.997345
 >> iter 168000, loss: 13.054177
 >> iter 169000, loss: 13.008413
 >> iter 170000, loss: 13.065807
   Number of active neurons: 2
 >> iter 171000, loss: 13.005406
 >> iter 172000, loss: 13.057352
 >> iter 173000, loss: 13.009712
 >> iter 174000, loss: 13.073903
 >> iter 175000, loss: 13.011715
 >> iter 176000, loss: 13.079830
 >> iter 177000, loss: 13.013676
 >> iter 178000, loss: 13.072776
 >> iter 179000, loss: 13.016596
 >> iter 180000, loss: 13.077508
   Number of active neurons: 2
 >> iter 181000, loss: 13.007005
 >> iter 182000, loss: 13.078511
 >> iter 183000, loss: 13.016862
 >> iter 184000, loss: 13.070232
 >> iter 185000, loss: 12.990754
 >> iter 186000, loss: 13.079437
 >> iter 187000, loss: 13.009279
 >> iter 188000, loss: 13.082203
 >> iter 189000, loss: 13.006643
 >> iter 190000, loss: 13.069530
   Number of active neurons: 2
 >> iter 191000, loss: 13.002948
 >> iter 192000, loss: 13.080625
 >> iter 193000, loss: 13.004400
 >> iter 194000, loss: 13.076056
 >> iter 195000, loss: 13.022212
 >> iter 196000, loss: 13.077932
 >> iter 197000, loss: 13.008602
 >> iter 198000, loss: 13.086491
 >> iter 199000, loss: 13.027262
 >> iter 200000, loss: 13.079703
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.932547
 >> iter 2000, loss: 15.247052
 >> iter 3000, loss: 13.871612
 >> iter 4000, loss: 13.368289
 >> iter 5000, loss: 13.150474
 >> iter 6000, loss: 13.086768
 >> iter 7000, loss: 13.049943
 >> iter 8000, loss: 13.053623
 >> iter 9000, loss: 13.034302
 >> iter 10000, loss: 13.033303
   Number of active neurons: 2
 >> iter 11000, loss: 13.028157
 >> iter 12000, loss: 13.052982
 >> iter 13000, loss: 13.042853
 >> iter 14000, loss: 13.056517
 >> iter 15000, loss: 13.033838
 >> iter 16000, loss: 13.050371
 >> iter 17000, loss: 13.028891
 >> iter 18000, loss: 13.051995
 >> iter 19000, loss: 13.032710
 >> iter 20000, loss: 13.061714
   Number of active neurons: 2
 >> iter 21000, loss: 13.027797
 >> iter 22000, loss: 13.059832
 >> iter 23000, loss: 13.034316
 >> iter 24000, loss: 13.067007
 >> iter 25000, loss: 13.046707
 >> iter 26000, loss: 13.056845
 >> iter 27000, loss: 13.037588
 >> iter 28000, loss: 13.041391
 >> iter 29000, loss: 13.029016
 >> iter 30000, loss: 13.063741
   Number of active neurons: 2
 >> iter 31000, loss: 13.038549
 >> iter 32000, loss: 13.064202
 >> iter 33000, loss: 13.043775
 >> iter 34000, loss: 13.068363
 >> iter 35000, loss: 13.039207
 >> iter 36000, loss: 13.039820
 >> iter 37000, loss: 13.024771
 >> iter 38000, loss: 13.052152
 >> iter 39000, loss: 13.036432
 >> iter 40000, loss: 13.052330
   Number of active neurons: 2
 >> iter 41000, loss: 13.029630
 >> iter 42000, loss: 13.055283
 >> iter 43000, loss: 13.033110
 >> iter 44000, loss: 13.055714
 >> iter 45000, loss: 13.031376
 >> iter 46000, loss: 13.072654
 >> iter 47000, loss: 13.020843
 >> iter 48000, loss: 13.071487
 >> iter 49000, loss: 13.021685
 >> iter 50000, loss: 13.047784
   Number of active neurons: 2
 >> iter 51000, loss: 13.026802
 >> iter 52000, loss: 13.052320
 >> iter 53000, loss: 13.032374
 >> iter 54000, loss: 13.061331
 >> iter 55000, loss: 13.019478
 >> iter 56000, loss: 13.065283
 >> iter 57000, loss: 13.017076
 >> iter 58000, loss: 13.060230
 >> iter 59000, loss: 13.026425
 >> iter 60000, loss: 13.069607
   Number of active neurons: 2
 >> iter 61000, loss: 13.034644
 >> iter 62000, loss: 13.065800
 >> iter 63000, loss: 13.022034
 >> iter 64000, loss: 13.065569
 >> iter 65000, loss: 13.028467
 >> iter 66000, loss: 13.069173
 >> iter 67000, loss: 13.036604
 >> iter 68000, loss: 13.052569
 >> iter 69000, loss: 13.026471
 >> iter 70000, loss: 13.068675
   Number of active neurons: 2
 >> iter 71000, loss: 13.026103
 >> iter 72000, loss: 13.061050
 >> iter 73000, loss: 13.028047
 >> iter 74000, loss: 13.064369
 >> iter 75000, loss: 13.029910
 >> iter 76000, loss: 13.059432
 >> iter 77000, loss: 13.028215
 >> iter 78000, loss: 13.062615
 >> iter 79000, loss: 13.036692
 >> iter 80000, loss: 13.071874
   Number of active neurons: 2
 >> iter 81000, loss: 13.035857
 >> iter 82000, loss: 13.070009
 >> iter 83000, loss: 13.039409
 >> iter 84000, loss: 13.067335
 >> iter 85000, loss: 13.039877
 >> iter 86000, loss: 13.071061
 >> iter 87000, loss: 13.040960
 >> iter 88000, loss: 13.067424
 >> iter 89000, loss: 13.031920
 >> iter 90000, loss: 13.072989
   Number of active neurons: 2
 >> iter 91000, loss: 13.036853
 >> iter 92000, loss: 13.071187
 >> iter 93000, loss: 13.030748
 >> iter 94000, loss: 13.066279
 >> iter 95000, loss: 13.022141
 >> iter 96000, loss: 13.069036
 >> iter 97000, loss: 13.031508
 >> iter 98000, loss: 13.075562
 >> iter 99000, loss: 13.038342
 >> iter 100000, loss: 13.063713
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.249007
 >> iter 2000, loss: 15.897783
 >> iter 3000, loss: 14.654911
 >> iter 4000, loss: 14.196543
 >> iter 5000, loss: 14.030761
 >> iter 6000, loss: 13.967570
 >> iter 7000, loss: 13.930323
 >> iter 8000, loss: 13.935116
 >> iter 9000, loss: 13.915378
 >> iter 10000, loss: 13.923450
   Number of active neurons: 1
 >> iter 11000, loss: 13.921709
 >> iter 12000, loss: 13.909572
 >> iter 13000, loss: 13.911676
 >> iter 14000, loss: 13.929432
 >> iter 15000, loss: 13.917536
 >> iter 16000, loss: 13.922243
 >> iter 17000, loss: 13.916340
 >> iter 18000, loss: 13.924336
 >> iter 19000, loss: 13.921491
 >> iter 20000, loss: 13.938555
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 1
 >> iter 21000, loss: 13.512799
 >> iter 22000, loss: 13.257733
 >> iter 23000, loss: 13.111768
 >> iter 24000, loss: 13.094932
 >> iter 25000, loss: 13.049731
 >> iter 26000, loss: 13.053960
 >> iter 27000, loss: 13.032772
 >> iter 28000, loss: 13.059352
 >> iter 29000, loss: 13.028427
 >> iter 30000, loss: 13.058073
   Number of active neurons: 2
 >> iter 31000, loss: 13.037717
 >> iter 32000, loss: 13.055434
 >> iter 33000, loss: 13.028213
 >> iter 34000, loss: 13.056743
 >> iter 35000, loss: 13.053668
 >> iter 36000, loss: 13.063989
 >> iter 37000, loss: 13.044546
 >> iter 38000, loss: 13.069386
 >> iter 39000, loss: 13.026025
 >> iter 40000, loss: 13.047093
   Number of active neurons: 2
 >> iter 41000, loss: 13.019948
 >> iter 42000, loss: 13.045815
 >> iter 43000, loss: 13.030684
 >> iter 44000, loss: 13.059142
 >> iter 45000, loss: 13.011657
 >> iter 46000, loss: 13.062987
 >> iter 47000, loss: 13.032045
 >> iter 48000, loss: 13.066379
 >> iter 49000, loss: 13.030388
 >> iter 50000, loss: 13.066216
   Number of active neurons: 2
 >> iter 51000, loss: 13.027859
 >> iter 52000, loss: 13.057454
 >> iter 53000, loss: 13.026103
 >> iter 54000, loss: 13.057643
 >> iter 55000, loss: 13.016520
 >> iter 56000, loss: 13.048216
 >> iter 57000, loss: 13.028139
 >> iter 58000, loss: 13.048653
 >> iter 59000, loss: 13.019312
 >> iter 60000, loss: 13.064426
   Number of active neurons: 2
 >> iter 61000, loss: 13.027024
 >> iter 62000, loss: 13.053462
 >> iter 63000, loss: 13.028253
 >> iter 64000, loss: 13.072816
 >> iter 65000, loss: 13.035944
 >> iter 66000, loss: 13.064797
 >> iter 67000, loss: 13.011174
 >> iter 68000, loss: 13.055815
 >> iter 69000, loss: 13.025988
 >> iter 70000, loss: 13.073533
   Number of active neurons: 2
 >> iter 71000, loss: 13.029537
 >> iter 72000, loss: 13.070000
 >> iter 73000, loss: 13.025757
 >> iter 74000, loss: 13.055593
 >> iter 75000, loss: 13.032719
 >> iter 76000, loss: 13.071268
 >> iter 77000, loss: 13.040694
 >> iter 78000, loss: 13.077085
 >> iter 79000, loss: 13.023314
 >> iter 80000, loss: 13.063640
   Number of active neurons: 2
 >> iter 81000, loss: 13.029272
 >> iter 82000, loss: 13.077282
 >> iter 83000, loss: 13.038883
 >> iter 84000, loss: 13.057585
 >> iter 85000, loss: 13.017137
 >> iter 86000, loss: 13.073951
 >> iter 87000, loss: 13.039040
 >> iter 88000, loss: 13.065893
 >> iter 89000, loss: 13.029647
 >> iter 90000, loss: 13.070838
   Number of active neurons: 2
 >> iter 91000, loss: 13.037612
 >> iter 92000, loss: 13.077876
 >> iter 93000, loss: 13.022525
 >> iter 94000, loss: 13.068737
 >> iter 95000, loss: 13.037267
 >> iter 96000, loss: 13.066481
 >> iter 97000, loss: 13.031814
 >> iter 98000, loss: 13.068873
 >> iter 99000, loss: 13.031682
 >> iter 100000, loss: 13.059804
   Number of active neurons: 2
 >> iter 101000, loss: 13.032585
 >> iter 102000, loss: 13.072384
 >> iter 103000, loss: 13.033504
 >> iter 104000, loss: 13.067492
 >> iter 105000, loss: 13.028495
 >> iter 106000, loss: 13.075395
 >> iter 107000, loss: 13.020511
 >> iter 108000, loss: 13.073575
 >> iter 109000, loss: 13.017307
 >> iter 110000, loss: 13.070026
   Number of active neurons: 2
 >> iter 111000, loss: 13.035909
 >> iter 112000, loss: 13.080049
 >> iter 113000, loss: 13.031494
 >> iter 114000, loss: 13.069875
 >> iter 115000, loss: 13.010765
 >> iter 116000, loss: 13.058690
 >> iter 117000, loss: 13.028945
 >> iter 118000, loss: 13.069980
 >> iter 119000, loss: 13.015772
 >> iter 120000, loss: 13.064565
   Number of active neurons: 2
 >> iter 121000, loss: 13.017107
 >> iter 122000, loss: 13.068072
 >> iter 123000, loss: 13.018808
 >> iter 124000, loss: 13.057778
 >> iter 125000, loss: 13.009608
 >> iter 126000, loss: 13.071793
 >> iter 127000, loss: 13.018832
 >> iter 128000, loss: 13.081807
 >> iter 129000, loss: 13.023662
 >> iter 130000, loss: 13.070614
   Number of active neurons: 2
 >> iter 131000, loss: 13.017986
 >> iter 132000, loss: 13.075700
 >> iter 133000, loss: 13.024167
 >> iter 134000, loss: 13.087677
 >> iter 135000, loss: 13.020443
 >> iter 136000, loss: 13.078561
 >> iter 137000, loss: 13.022013
 >> iter 138000, loss: 13.083929
 >> iter 139000, loss: 13.026191
 >> iter 140000, loss: 13.074758
   Number of active neurons: 2
 >> iter 141000, loss: 13.013971
 >> iter 142000, loss: 13.064962
 >> iter 143000, loss: 13.008404
 >> iter 144000, loss: 13.080512
 >> iter 145000, loss: 13.005340
 >> iter 146000, loss: 13.086471
 >> iter 147000, loss: 13.025283
 >> iter 148000, loss: 13.083870
 >> iter 149000, loss: 13.014961
 >> iter 150000, loss: 13.072836
   Number of active neurons: 2
 >> iter 151000, loss: 13.015408
 >> iter 152000, loss: 13.074669
 >> iter 153000, loss: 13.016156
 >> iter 154000, loss: 13.097331
 >> iter 155000, loss: 13.024507
 >> iter 156000, loss: 13.081129
 >> iter 157000, loss: 13.015876
 >> iter 158000, loss: 13.085123
 >> iter 159000, loss: 13.023161
 >> iter 160000, loss: 13.090388
   Number of active neurons: 2
 >> iter 161000, loss: 13.019087
 >> iter 162000, loss: 13.077940
 >> iter 163000, loss: 13.028541
 >> iter 164000, loss: 13.092600
 >> iter 165000, loss: 13.011084
 >> iter 166000, loss: 13.053870
 >> iter 167000, loss: 13.011670
 >> iter 168000, loss: 13.062527
 >> iter 169000, loss: 13.004144
 >> iter 170000, loss: 13.065662
   Number of active neurons: 2
 >> iter 171000, loss: 13.008494
 >> iter 172000, loss: 13.069318
 >> iter 173000, loss: 13.007594
 >> iter 174000, loss: 13.058364
 >> iter 175000, loss: 13.007449
 >> iter 176000, loss: 13.081880
 >> iter 177000, loss: 13.014107
 >> iter 178000, loss: 13.068703
 >> iter 179000, loss: 13.010650
 >> iter 180000, loss: 13.075550
   Number of active neurons: 2
 >> iter 181000, loss: 13.013347
 >> iter 182000, loss: 13.069428
 >> iter 183000, loss: 13.009220
 >> iter 184000, loss: 13.079045
 >> iter 185000, loss: 13.012236
 >> iter 186000, loss: 13.083251
 >> iter 187000, loss: 13.011684
 >> iter 188000, loss: 13.085200
 >> iter 189000, loss: 13.006629
 >> iter 190000, loss: 13.078441
   Number of active neurons: 2
 >> iter 191000, loss: 12.995024
 >> iter 192000, loss: 13.059344
 >> iter 193000, loss: 12.988878
 >> iter 194000, loss: 13.074657
 >> iter 195000, loss: 13.011662
 >> iter 196000, loss: 13.066295
 >> iter 197000, loss: 13.012971
 >> iter 198000, loss: 13.072719
 >> iter 199000, loss: 13.004911
 >> iter 200000, loss: 13.069116
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.319612
 >> iter 2000, loss: 15.924673
 >> iter 3000, loss: 14.665896
 >> iter 4000, loss: 14.200676
 >> iter 5000, loss: 14.031079
 >> iter 6000, loss: 13.967456
 >> iter 7000, loss: 13.941839
 >> iter 8000, loss: 13.928215
 >> iter 9000, loss: 13.924082
 >> iter 10000, loss: 13.932731
   Number of active neurons: 1
 >> iter 11000, loss: 13.931861
 >> iter 12000, loss: 13.928807
 >> iter 13000, loss: 13.913887
 >> iter 14000, loss: 13.927329
 >> iter 15000, loss: 13.920658
 >> iter 16000, loss: 13.928620
 >> iter 17000, loss: 13.925038
 >> iter 18000, loss: 13.927968
 >> iter 19000, loss: 13.920830
 >> iter 20000, loss: 13.930015
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 1
 >> iter 21000, loss: 13.424330
 >> iter 22000, loss: 13.201265
 >> iter 23000, loss: 13.082478
 >> iter 24000, loss: 13.063403
 >> iter 25000, loss: 13.036348
 >> iter 26000, loss: 13.043714
 >> iter 27000, loss: 13.024328
 >> iter 28000, loss: 13.061099
 >> iter 29000, loss: 13.041441
 >> iter 30000, loss: 13.063303
   Number of active neurons: 2
 >> iter 31000, loss: 13.037967
 >> iter 32000, loss: 13.040157
 >> iter 33000, loss: 13.037201
 >> iter 34000, loss: 13.064538
 >> iter 35000, loss: 13.047656
 >> iter 36000, loss: 13.044478
 >> iter 37000, loss: 13.034528
 >> iter 38000, loss: 13.061795
 >> iter 39000, loss: 13.034557
 >> iter 40000, loss: 13.058314
   Number of active neurons: 2
 >> iter 41000, loss: 13.034359
 >> iter 42000, loss: 13.064252
 >> iter 43000, loss: 13.026988
 >> iter 44000, loss: 13.069107
 >> iter 45000, loss: 13.035050
 >> iter 46000, loss: 13.063878
 >> iter 47000, loss: 13.037320
 >> iter 48000, loss: 13.062360
 >> iter 49000, loss: 13.036059
 >> iter 50000, loss: 13.078093
   Number of active neurons: 2
 >> iter 51000, loss: 13.044884
 >> iter 52000, loss: 13.059533
 >> iter 53000, loss: 13.022978
 >> iter 54000, loss: 13.059257
 >> iter 55000, loss: 13.026932
 >> iter 56000, loss: 13.049516
 >> iter 57000, loss: 13.024328
 >> iter 58000, loss: 13.049103
 >> iter 59000, loss: 13.032585
 >> iter 60000, loss: 13.051149
   Number of active neurons: 2
 >> iter 61000, loss: 13.021141
 >> iter 62000, loss: 13.051096
 >> iter 63000, loss: 13.031052
 >> iter 64000, loss: 13.069283
 >> iter 65000, loss: 13.037934
 >> iter 66000, loss: 13.062320
 >> iter 67000, loss: 13.028576
 >> iter 68000, loss: 13.077628
 >> iter 69000, loss: 13.036783
 >> iter 70000, loss: 13.064859
   Number of active neurons: 2
 >> iter 71000, loss: 13.028277
 >> iter 72000, loss: 13.063961
 >> iter 73000, loss: 13.041737
 >> iter 74000, loss: 13.083553
 >> iter 75000, loss: 13.031129
 >> iter 76000, loss: 13.064480
 >> iter 77000, loss: 13.035218
 >> iter 78000, loss: 13.066234
 >> iter 79000, loss: 13.030826
 >> iter 80000, loss: 13.057768
   Number of active neurons: 2
 >> iter 81000, loss: 13.026373
 >> iter 82000, loss: 13.059715
 >> iter 83000, loss: 13.025070
 >> iter 84000, loss: 13.066381
 >> iter 85000, loss: 13.021608
 >> iter 86000, loss: 13.072698
 >> iter 87000, loss: 13.026416
 >> iter 88000, loss: 13.070040
 >> iter 89000, loss: 13.033935
 >> iter 90000, loss: 13.075188
   Number of active neurons: 2
 >> iter 91000, loss: 13.033439
 >> iter 92000, loss: 13.075739
 >> iter 93000, loss: 13.019512
 >> iter 94000, loss: 13.052727
 >> iter 95000, loss: 13.029054
 >> iter 96000, loss: 13.059732
 >> iter 97000, loss: 13.029193
 >> iter 98000, loss: 13.077160
 >> iter 99000, loss: 13.041711
 >> iter 100000, loss: 13.069315
   Number of active neurons: 2
 >> iter 101000, loss: 13.036839
 >> iter 102000, loss: 13.070398
 >> iter 103000, loss: 13.024246
 >> iter 104000, loss: 13.065426
 >> iter 105000, loss: 13.033262
 >> iter 106000, loss: 13.073242
 >> iter 107000, loss: 13.026434
 >> iter 108000, loss: 13.077844
 >> iter 109000, loss: 13.032373
 >> iter 110000, loss: 13.083864
   Number of active neurons: 2
 >> iter 111000, loss: 13.032377
 >> iter 112000, loss: 13.065556
 >> iter 113000, loss: 13.025747
 >> iter 114000, loss: 13.073822
 >> iter 115000, loss: 13.035174
 >> iter 116000, loss: 13.073167
 >> iter 117000, loss: 13.031052
 >> iter 118000, loss: 13.068497
 >> iter 119000, loss: 13.020908
 >> iter 120000, loss: 13.065570
   Number of active neurons: 2
 >> iter 121000, loss: 13.021558
 >> iter 122000, loss: 13.073332
 >> iter 123000, loss: 13.011496
 >> iter 124000, loss: 13.063563
 >> iter 125000, loss: 13.019380
 >> iter 126000, loss: 13.065820
 >> iter 127000, loss: 13.007946
 >> iter 128000, loss: 13.072110
 >> iter 129000, loss: 13.022417
 >> iter 130000, loss: 13.077924
   Number of active neurons: 2
 >> iter 131000, loss: 13.023136
 >> iter 132000, loss: 13.062124
 >> iter 133000, loss: 13.014896
 >> iter 134000, loss: 13.067747
 >> iter 135000, loss: 13.003931
 >> iter 136000, loss: 13.063350
 >> iter 137000, loss: 13.013299
 >> iter 138000, loss: 13.076524
 >> iter 139000, loss: 13.018132
 >> iter 140000, loss: 13.066695
   Number of active neurons: 2
 >> iter 141000, loss: 13.019933
 >> iter 142000, loss: 13.090564
 >> iter 143000, loss: 13.011591
 >> iter 144000, loss: 13.067181
 >> iter 145000, loss: 13.017299
 >> iter 146000, loss: 13.088235
 >> iter 147000, loss: 13.012283
 >> iter 148000, loss: 13.081890
 >> iter 149000, loss: 13.018417
 >> iter 150000, loss: 13.066622
   Number of active neurons: 2
 >> iter 151000, loss: 13.021334
 >> iter 152000, loss: 13.083492
 >> iter 153000, loss: 13.022338
 >> iter 154000, loss: 13.068693
 >> iter 155000, loss: 13.034629
 >> iter 156000, loss: 13.095057
 >> iter 157000, loss: 13.000296
 >> iter 158000, loss: 13.073059
 >> iter 159000, loss: 13.002827
 >> iter 160000, loss: 13.078736
   Number of active neurons: 2
 >> iter 161000, loss: 13.002592
 >> iter 162000, loss: 13.082330
 >> iter 163000, loss: 13.013095
 >> iter 164000, loss: 13.081919
 >> iter 165000, loss: 13.024106
 >> iter 166000, loss: 13.079185
 >> iter 167000, loss: 13.021983
 >> iter 168000, loss: 13.074484
 >> iter 169000, loss: 13.012012
 >> iter 170000, loss: 13.062447
   Number of active neurons: 2
 >> iter 171000, loss: 13.003633
 >> iter 172000, loss: 13.076323
 >> iter 173000, loss: 13.016538
 >> iter 174000, loss: 13.076178
 >> iter 175000, loss: 13.016486
 >> iter 176000, loss: 13.068471
 >> iter 177000, loss: 12.997726
 >> iter 178000, loss: 13.068298
 >> iter 179000, loss: 13.011790
 >> iter 180000, loss: 13.059778
   Number of active neurons: 2
 >> iter 181000, loss: 13.015623
 >> iter 182000, loss: 13.087593
 >> iter 183000, loss: 13.021683
 >> iter 184000, loss: 13.085605
 >> iter 185000, loss: 13.011777
 >> iter 186000, loss: 13.088796
 >> iter 187000, loss: 13.019317
 >> iter 188000, loss: 13.092897
 >> iter 189000, loss: 13.007134
 >> iter 190000, loss: 13.070920
   Number of active neurons: 2
 >> iter 191000, loss: 13.003236
 >> iter 192000, loss: 13.076376
 >> iter 193000, loss: 13.005945
 >> iter 194000, loss: 13.070466
 >> iter 195000, loss: 13.014155
 >> iter 196000, loss: 13.060092
 >> iter 197000, loss: 13.006999
 >> iter 198000, loss: 13.083856
 >> iter 199000, loss: 13.018671
 >> iter 200000, loss: 13.082479
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.923528
 >> iter 2000, loss: 15.259820
 >> iter 3000, loss: 13.867411
 >> iter 4000, loss: 13.364269
 >> iter 5000, loss: 13.155569
 >> iter 6000, loss: 13.094122
 >> iter 7000, loss: 13.063364
 >> iter 8000, loss: 13.073447
 >> iter 9000, loss: 13.047004
 >> iter 10000, loss: 13.054393
   Number of active neurons: 2
 >> iter 11000, loss: 13.041350
 >> iter 12000, loss: 13.050058
 >> iter 13000, loss: 13.029775
 >> iter 14000, loss: 13.053104
 >> iter 15000, loss: 13.047326
 >> iter 16000, loss: 13.061889
 >> iter 17000, loss: 13.052390
 >> iter 18000, loss: 13.055193
 >> iter 19000, loss: 13.035520
 >> iter 20000, loss: 13.053931
   Number of active neurons: 2
 >> iter 21000, loss: 13.030916
 >> iter 22000, loss: 13.050626
 >> iter 23000, loss: 13.033337
 >> iter 24000, loss: 13.058923
 >> iter 25000, loss: 13.032024
 >> iter 26000, loss: 13.065221
 >> iter 27000, loss: 13.029386
 >> iter 28000, loss: 13.061431
 >> iter 29000, loss: 13.042989
 >> iter 30000, loss: 13.070426
   Number of active neurons: 2
 >> iter 31000, loss: 13.043473
 >> iter 32000, loss: 13.052970
 >> iter 33000, loss: 13.034740
 >> iter 34000, loss: 13.051777
 >> iter 35000, loss: 13.038260
 >> iter 36000, loss: 13.052361
 >> iter 37000, loss: 13.033383
 >> iter 38000, loss: 13.044708
 >> iter 39000, loss: 13.031297
 >> iter 40000, loss: 13.062260
   Number of active neurons: 2
 >> iter 41000, loss: 13.029901
 >> iter 42000, loss: 13.057293
 >> iter 43000, loss: 13.023359
 >> iter 44000, loss: 13.062132
 >> iter 45000, loss: 13.038350
 >> iter 46000, loss: 13.069616
 >> iter 47000, loss: 13.025082
 >> iter 48000, loss: 13.045658
 >> iter 49000, loss: 13.021704
 >> iter 50000, loss: 13.055090
   Number of active neurons: 2
 >> iter 51000, loss: 13.030793
 >> iter 52000, loss: 13.052637
 >> iter 53000, loss: 13.033018
 >> iter 54000, loss: 13.048357
 >> iter 55000, loss: 12.995057
 >> iter 56000, loss: 13.051194
 >> iter 57000, loss: 13.031641
 >> iter 58000, loss: 13.060578
 >> iter 59000, loss: 13.031853
 >> iter 60000, loss: 13.063300
   Number of active neurons: 2
 >> iter 61000, loss: 13.023886
 >> iter 62000, loss: 13.063127
 >> iter 63000, loss: 13.006290
 >> iter 64000, loss: 13.040149
 >> iter 65000, loss: 13.025694
 >> iter 66000, loss: 13.059112
 >> iter 67000, loss: 13.018813
 >> iter 68000, loss: 13.064834
 >> iter 69000, loss: 13.029756
 >> iter 70000, loss: 13.066857
   Number of active neurons: 2
 >> iter 71000, loss: 13.015221
 >> iter 72000, loss: 13.061960
 >> iter 73000, loss: 13.025793
 >> iter 74000, loss: 13.061253
 >> iter 75000, loss: 13.013127
 >> iter 76000, loss: 13.060946
 >> iter 77000, loss: 13.028391
 >> iter 78000, loss: 13.062708
 >> iter 79000, loss: 13.034185
 >> iter 80000, loss: 13.064604
   Number of active neurons: 2
 >> iter 81000, loss: 13.019718
 >> iter 82000, loss: 13.056969
 >> iter 83000, loss: 13.026479
 >> iter 84000, loss: 13.072442
 >> iter 85000, loss: 13.040820
 >> iter 86000, loss: 13.071261
 >> iter 87000, loss: 13.021819
 >> iter 88000, loss: 13.072482
 >> iter 89000, loss: 13.045403
 >> iter 90000, loss: 13.077515
   Number of active neurons: 2
 >> iter 91000, loss: 13.034446
 >> iter 92000, loss: 13.059115
 >> iter 93000, loss: 13.036989
 >> iter 94000, loss: 13.073215
 >> iter 95000, loss: 13.039380
 >> iter 96000, loss: 13.068501
 >> iter 97000, loss: 13.022997
 >> iter 98000, loss: 13.067696
 >> iter 99000, loss: 13.023526
 >> iter 100000, loss: 13.068351
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.877344
 >> iter 2000, loss: 15.234883
 >> iter 3000, loss: 13.842790
 >> iter 4000, loss: 13.366809
 >> iter 5000, loss: 13.157235
 >> iter 6000, loss: 13.097622
 >> iter 7000, loss: 13.046160
 >> iter 8000, loss: 13.050911
 >> iter 9000, loss: 13.030068
 >> iter 10000, loss: 13.043220
   Number of active neurons: 2
 >> iter 11000, loss: 13.043693
 >> iter 12000, loss: 13.049986
 >> iter 13000, loss: 13.034628
 >> iter 14000, loss: 13.058003
 >> iter 15000, loss: 13.027120
 >> iter 16000, loss: 13.046383
 >> iter 17000, loss: 13.029516
 >> iter 18000, loss: 13.032898
 >> iter 19000, loss: 13.027382
 >> iter 20000, loss: 13.051362
   Number of active neurons: 2
 >> iter 21000, loss: 13.015343
 >> iter 22000, loss: 13.038680
 >> iter 23000, loss: 13.013948
 >> iter 24000, loss: 13.053564
 >> iter 25000, loss: 13.038641
 >> iter 26000, loss: 13.061423
 >> iter 27000, loss: 13.022059
 >> iter 28000, loss: 13.046978
 >> iter 29000, loss: 13.026493
 >> iter 30000, loss: 13.055636
   Number of active neurons: 2
 >> iter 31000, loss: 13.035692
 >> iter 32000, loss: 13.061126
 >> iter 33000, loss: 13.034366
 >> iter 34000, loss: 13.053498
 >> iter 35000, loss: 13.024030
 >> iter 36000, loss: 13.053062
 >> iter 37000, loss: 13.036254
 >> iter 38000, loss: 13.053700
 >> iter 39000, loss: 13.025226
 >> iter 40000, loss: 13.045835
   Number of active neurons: 2
 >> iter 41000, loss: 13.026790
 >> iter 42000, loss: 13.054025
 >> iter 43000, loss: 13.028262
 >> iter 44000, loss: 13.057776
 >> iter 45000, loss: 13.033612
 >> iter 46000, loss: 13.064180
 >> iter 47000, loss: 13.035881
 >> iter 48000, loss: 13.072494
 >> iter 49000, loss: 13.042760
 >> iter 50000, loss: 13.070905
   Number of active neurons: 2
 >> iter 51000, loss: 13.025322
 >> iter 52000, loss: 13.047208
 >> iter 53000, loss: 13.026880
 >> iter 54000, loss: 13.072679
 >> iter 55000, loss: 13.033356
 >> iter 56000, loss: 13.063127
 >> iter 57000, loss: 13.026205
 >> iter 58000, loss: 13.059459
 >> iter 59000, loss: 13.023566
 >> iter 60000, loss: 13.061911
   Number of active neurons: 2
 >> iter 61000, loss: 13.033065
 >> iter 62000, loss: 13.064116
 >> iter 63000, loss: 13.038544
 >> iter 64000, loss: 13.058218
 >> iter 65000, loss: 13.028817
 >> iter 66000, loss: 13.052487
 >> iter 67000, loss: 13.023918
 >> iter 68000, loss: 13.065707
 >> iter 69000, loss: 13.033094
 >> iter 70000, loss: 13.061725
   Number of active neurons: 2
 >> iter 71000, loss: 13.034013
 >> iter 72000, loss: 13.052485
 >> iter 73000, loss: 13.030302
 >> iter 74000, loss: 13.060353
 >> iter 75000, loss: 13.030430
 >> iter 76000, loss: 13.068891
 >> iter 77000, loss: 13.031461
 >> iter 78000, loss: 13.072575
 >> iter 79000, loss: 13.027608
 >> iter 80000, loss: 13.076536
   Number of active neurons: 2
 >> iter 81000, loss: 13.027823
 >> iter 82000, loss: 13.069260
 >> iter 83000, loss: 13.045554
 >> iter 84000, loss: 13.067902
 >> iter 85000, loss: 13.020872
 >> iter 86000, loss: 13.040498
 >> iter 87000, loss: 13.025200
 >> iter 88000, loss: 13.073830
 >> iter 89000, loss: 13.034119
 >> iter 90000, loss: 13.064522
   Number of active neurons: 2
 >> iter 91000, loss: 13.029893
 >> iter 92000, loss: 13.078718
 >> iter 93000, loss: 13.029144
 >> iter 94000, loss: 13.057105
 >> iter 95000, loss: 13.035278
 >> iter 96000, loss: 13.079609
 >> iter 97000, loss: 13.030736
 >> iter 98000, loss: 13.078982
 >> iter 99000, loss: 13.031987
 >> iter 100000, loss: 13.073262
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.944781
 >> iter 2000, loss: 15.263062
 >> iter 3000, loss: 13.866559
 >> iter 4000, loss: 13.367719
 >> iter 5000, loss: 13.156632
 >> iter 6000, loss: 13.087391
 >> iter 7000, loss: 13.051714
 >> iter 8000, loss: 13.044793
 >> iter 9000, loss: 13.037818
 >> iter 10000, loss: 13.059480
   Number of active neurons: 2
 >> iter 11000, loss: 13.034229
 >> iter 12000, loss: 13.052411
 >> iter 13000, loss: 13.037255
 >> iter 14000, loss: 13.050465
 >> iter 15000, loss: 13.035438
 >> iter 16000, loss: 13.048402
 >> iter 17000, loss: 13.024908
 >> iter 18000, loss: 13.048407
 >> iter 19000, loss: 13.037404
 >> iter 20000, loss: 13.055755
   Number of active neurons: 2
 >> iter 21000, loss: 13.023607
 >> iter 22000, loss: 13.044991
 >> iter 23000, loss: 13.027809
 >> iter 24000, loss: 13.055712
 >> iter 25000, loss: 13.036156
 >> iter 26000, loss: 13.056444
 >> iter 27000, loss: 13.038810
 >> iter 28000, loss: 13.049019
 >> iter 29000, loss: 13.038248
 >> iter 30000, loss: 13.067364
   Number of active neurons: 2
 >> iter 31000, loss: 13.039799
 >> iter 32000, loss: 13.060823
 >> iter 33000, loss: 13.041893
 >> iter 34000, loss: 13.047197
 >> iter 35000, loss: 13.028040
 >> iter 36000, loss: 13.040433
 >> iter 37000, loss: 13.025063
 >> iter 38000, loss: 13.056490
 >> iter 39000, loss: 13.031896
 >> iter 40000, loss: 13.056083
   Number of active neurons: 2
 >> iter 41000, loss: 13.023378
 >> iter 42000, loss: 13.049353
 >> iter 43000, loss: 13.040523
 >> iter 44000, loss: 13.067602
 >> iter 45000, loss: 13.030041
 >> iter 46000, loss: 13.060717
 >> iter 47000, loss: 13.024084
 >> iter 48000, loss: 13.056791
 >> iter 49000, loss: 13.030521
 >> iter 50000, loss: 13.064591
   Number of active neurons: 2
 >> iter 51000, loss: 13.030413
 >> iter 52000, loss: 13.063400
 >> iter 53000, loss: 13.036484
 >> iter 54000, loss: 13.052144
 >> iter 55000, loss: 13.012323
 >> iter 56000, loss: 13.054531
 >> iter 57000, loss: 13.026461
 >> iter 58000, loss: 13.046077
 >> iter 59000, loss: 13.018042
 >> iter 60000, loss: 13.063228
   Number of active neurons: 2
 >> iter 61000, loss: 13.026368
 >> iter 62000, loss: 13.045968
 >> iter 63000, loss: 13.023447
 >> iter 64000, loss: 13.055146
 >> iter 65000, loss: 13.029456
 >> iter 66000, loss: 13.059331
 >> iter 67000, loss: 13.033510
 >> iter 68000, loss: 13.071524
 >> iter 69000, loss: 13.032278
 >> iter 70000, loss: 13.055968
   Number of active neurons: 2
 >> iter 71000, loss: 13.031616
 >> iter 72000, loss: 13.068461
 >> iter 73000, loss: 13.027346
 >> iter 74000, loss: 13.066911
 >> iter 75000, loss: 13.028351
 >> iter 76000, loss: 13.070039
 >> iter 77000, loss: 13.034657
 >> iter 78000, loss: 13.067096
 >> iter 79000, loss: 13.032729
 >> iter 80000, loss: 13.059359
   Number of active neurons: 2
 >> iter 81000, loss: 13.016457
 >> iter 82000, loss: 13.064628
 >> iter 83000, loss: 13.038237
 >> iter 84000, loss: 13.068902
 >> iter 85000, loss: 13.022108
 >> iter 86000, loss: 13.055280
 >> iter 87000, loss: 13.027845
 >> iter 88000, loss: 13.062197
 >> iter 89000, loss: 13.040812
 >> iter 90000, loss: 13.076805
   Number of active neurons: 2
 >> iter 91000, loss: 13.020729
 >> iter 92000, loss: 13.050197
 >> iter 93000, loss: 13.023441
 >> iter 94000, loss: 13.062894
 >> iter 95000, loss: 13.034294
 >> iter 96000, loss: 13.071319
 >> iter 97000, loss: 13.032035
 >> iter 98000, loss: 13.074968
 >> iter 99000, loss: 13.015279
 >> iter 100000, loss: 13.072350
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.308790
 >> iter 2000, loss: 15.928484
 >> iter 3000, loss: 14.668806
 >> iter 4000, loss: 14.203884
 >> iter 5000, loss: 14.023576
 >> iter 6000, loss: 13.959595
 >> iter 7000, loss: 13.934028
 >> iter 8000, loss: 13.934516
 >> iter 9000, loss: 13.925490
 >> iter 10000, loss: 13.920664
   Number of active neurons: 1
 >> iter 11000, loss: 13.913609
 >> iter 12000, loss: 13.922818
 >> iter 13000, loss: 13.920457
 >> iter 14000, loss: 13.928091
 >> iter 15000, loss: 13.919415
 >> iter 16000, loss: 13.923277
 >> iter 17000, loss: 13.922184
 >> iter 18000, loss: 13.921834
 >> iter 19000, loss: 13.917175
 >> iter 20000, loss: 13.924533
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 1
 >> iter 21000, loss: 13.475608
 >> iter 22000, loss: 13.226971
 >> iter 23000, loss: 13.102414
 >> iter 24000, loss: 13.072832
 >> iter 25000, loss: 13.035946
 >> iter 26000, loss: 13.060830
 >> iter 27000, loss: 13.028390
 >> iter 28000, loss: 13.057933
 >> iter 29000, loss: 13.031336
 >> iter 30000, loss: 13.050774
   Number of active neurons: 2
 >> iter 31000, loss: 13.033370
 >> iter 32000, loss: 13.056189
 >> iter 33000, loss: 13.035759
 >> iter 34000, loss: 13.047693
 >> iter 35000, loss: 13.032549
 >> iter 36000, loss: 13.064194
 >> iter 37000, loss: 13.031709
 >> iter 38000, loss: 13.049238
 >> iter 39000, loss: 13.029589
 >> iter 40000, loss: 13.043609
   Number of active neurons: 2
 >> iter 41000, loss: 13.032764
 >> iter 42000, loss: 13.059414
 >> iter 43000, loss: 13.025543
 >> iter 44000, loss: 13.055502
 >> iter 45000, loss: 13.028475
 >> iter 46000, loss: 13.047403
 >> iter 47000, loss: 13.035760
 >> iter 48000, loss: 13.068036
 >> iter 49000, loss: 13.043695
 >> iter 50000, loss: 13.065576
   Number of active neurons: 2
 >> iter 51000, loss: 13.032694
 >> iter 52000, loss: 13.068057
 >> iter 53000, loss: 13.017820
 >> iter 54000, loss: 13.045581
 >> iter 55000, loss: 13.023991
 >> iter 56000, loss: 13.072751
 >> iter 57000, loss: 13.030623
 >> iter 58000, loss: 13.056595
 >> iter 59000, loss: 13.026892
 >> iter 60000, loss: 13.071118
   Number of active neurons: 2
 >> iter 61000, loss: 13.034213
 >> iter 62000, loss: 13.052596
 >> iter 63000, loss: 13.026204
 >> iter 64000, loss: 13.065546
 >> iter 65000, loss: 13.034027
 >> iter 66000, loss: 13.060397
 >> iter 67000, loss: 13.018146
 >> iter 68000, loss: 13.062017
 >> iter 69000, loss: 13.023683
 >> iter 70000, loss: 13.057643
   Number of active neurons: 2
 >> iter 71000, loss: 13.035866
 >> iter 72000, loss: 13.069314
 >> iter 73000, loss: 13.025591
 >> iter 74000, loss: 13.070448
 >> iter 75000, loss: 13.028804
 >> iter 76000, loss: 13.052259
 >> iter 77000, loss: 13.020458
 >> iter 78000, loss: 13.056793
 >> iter 79000, loss: 13.009185
 >> iter 80000, loss: 13.060194
   Number of active neurons: 2
 >> iter 81000, loss: 13.003762
 >> iter 82000, loss: 13.066957
 >> iter 83000, loss: 13.024836
 >> iter 84000, loss: 13.063512
 >> iter 85000, loss: 13.022614
 >> iter 86000, loss: 13.043220
 >> iter 87000, loss: 13.012589
 >> iter 88000, loss: 13.040407
 >> iter 89000, loss: 13.019195
 >> iter 90000, loss: 13.066317
   Number of active neurons: 2
 >> iter 91000, loss: 13.030737
 >> iter 92000, loss: 13.072806
 >> iter 93000, loss: 13.035980
 >> iter 94000, loss: 13.071211
 >> iter 95000, loss: 13.030108
 >> iter 96000, loss: 13.075976
 >> iter 97000, loss: 13.035512
 >> iter 98000, loss: 13.086484
 >> iter 99000, loss: 13.031228
 >> iter 100000, loss: 13.072793
   Number of active neurons: 2
 >> iter 101000, loss: 13.038757
 >> iter 102000, loss: 13.081347
 >> iter 103000, loss: 13.037756
 >> iter 104000, loss: 13.060482
 >> iter 105000, loss: 13.027557
 >> iter 106000, loss: 13.068203
 >> iter 107000, loss: 13.032243
 >> iter 108000, loss: 13.078084
 >> iter 109000, loss: 13.029056
 >> iter 110000, loss: 13.079177
   Number of active neurons: 2
 >> iter 111000, loss: 13.030723
 >> iter 112000, loss: 13.065516
 >> iter 113000, loss: 13.030264
 >> iter 114000, loss: 13.065183
 >> iter 115000, loss: 13.017497
 >> iter 116000, loss: 13.061858
 >> iter 117000, loss: 13.018217
 >> iter 118000, loss: 13.063133
 >> iter 119000, loss: 13.008859
 >> iter 120000, loss: 13.061623
   Number of active neurons: 2
 >> iter 121000, loss: 13.020109
 >> iter 122000, loss: 13.073635
 >> iter 123000, loss: 13.026864
 >> iter 124000, loss: 13.073660
 >> iter 125000, loss: 13.013136
 >> iter 126000, loss: 13.073868
 >> iter 127000, loss: 13.013639
 >> iter 128000, loss: 13.069919
 >> iter 129000, loss: 13.027528
 >> iter 130000, loss: 13.064518
   Number of active neurons: 2
 >> iter 131000, loss: 13.025152
 >> iter 132000, loss: 13.069435
 >> iter 133000, loss: 13.012504
 >> iter 134000, loss: 13.068188
 >> iter 135000, loss: 13.013632
 >> iter 136000, loss: 13.063416
 >> iter 137000, loss: 13.014876
 >> iter 138000, loss: 13.076285
 >> iter 139000, loss: 13.031633
 >> iter 140000, loss: 13.076711
   Number of active neurons: 2
 >> iter 141000, loss: 13.010245
 >> iter 142000, loss: 13.075561
 >> iter 143000, loss: 13.024125
 >> iter 144000, loss: 13.091805
 >> iter 145000, loss: 13.005271
 >> iter 146000, loss: 13.075679
 >> iter 147000, loss: 13.020669
 >> iter 148000, loss: 13.074983
 >> iter 149000, loss: 13.028324
 >> iter 150000, loss: 13.081738
   Number of active neurons: 2
 >> iter 151000, loss: 13.015792
 >> iter 152000, loss: 13.076068
 >> iter 153000, loss: 13.012851
 >> iter 154000, loss: 13.068237
 >> iter 155000, loss: 13.020234
 >> iter 156000, loss: 13.082184
 >> iter 157000, loss: 13.019173
 >> iter 158000, loss: 13.077964
 >> iter 159000, loss: 13.014023
 >> iter 160000, loss: 13.087860
   Number of active neurons: 2
 >> iter 161000, loss: 13.007251
 >> iter 162000, loss: 13.081587
 >> iter 163000, loss: 13.004495
 >> iter 164000, loss: 13.077919
 >> iter 165000, loss: 13.013668
 >> iter 166000, loss: 13.060060
 >> iter 167000, loss: 13.003626
 >> iter 168000, loss: 13.063050
 >> iter 169000, loss: 12.995816
 >> iter 170000, loss: 13.071778
   Number of active neurons: 2
 >> iter 171000, loss: 13.013628
 >> iter 172000, loss: 13.072348
 >> iter 173000, loss: 13.010622
 >> iter 174000, loss: 13.061363
 >> iter 175000, loss: 13.008621
 >> iter 176000, loss: 13.072297
 >> iter 177000, loss: 13.008949
 >> iter 178000, loss: 13.082495
 >> iter 179000, loss: 13.022848
 >> iter 180000, loss: 13.072670
   Number of active neurons: 2
 >> iter 181000, loss: 12.994025
 >> iter 182000, loss: 13.073716
 >> iter 183000, loss: 13.010935
 >> iter 184000, loss: 13.083534
 >> iter 185000, loss: 13.015732
 >> iter 186000, loss: 13.094265
 >> iter 187000, loss: 13.012412
 >> iter 188000, loss: 13.084416
 >> iter 189000, loss: 13.015054
 >> iter 190000, loss: 13.085259
   Number of active neurons: 2
 >> iter 191000, loss: 13.009186
 >> iter 192000, loss: 13.072384
 >> iter 193000, loss: 13.019315
 >> iter 194000, loss: 13.087543
 >> iter 195000, loss: 13.012040
 >> iter 196000, loss: 13.072789
 >> iter 197000, loss: 13.013011
 >> iter 198000, loss: 13.084646
 >> iter 199000, loss: 13.015858
 >> iter 200000, loss: 13.062727
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.949358
 >> iter 2000, loss: 15.267808
 >> iter 3000, loss: 13.860719
 >> iter 4000, loss: 13.362911
 >> iter 5000, loss: 13.158322
 >> iter 6000, loss: 13.098097
 >> iter 7000, loss: 13.056708
 >> iter 8000, loss: 13.055438
 >> iter 9000, loss: 13.044780
 >> iter 10000, loss: 13.061974
   Number of active neurons: 2
 >> iter 11000, loss: 13.037355
 >> iter 12000, loss: 13.051549
 >> iter 13000, loss: 13.022621
 >> iter 14000, loss: 13.046029
 >> iter 15000, loss: 13.042006
 >> iter 16000, loss: 13.040777
 >> iter 17000, loss: 13.033367
 >> iter 18000, loss: 13.051148
 >> iter 19000, loss: 13.027518
 >> iter 20000, loss: 13.044762
   Number of active neurons: 2
 >> iter 21000, loss: 13.037991
 >> iter 22000, loss: 13.055158
 >> iter 23000, loss: 13.032642
 >> iter 24000, loss: 13.056157
 >> iter 25000, loss: 13.050819
 >> iter 26000, loss: 13.065308
 >> iter 27000, loss: 13.031042
 >> iter 28000, loss: 13.049683
 >> iter 29000, loss: 13.034940
 >> iter 30000, loss: 13.051232
   Number of active neurons: 2
 >> iter 31000, loss: 13.045754
 >> iter 32000, loss: 13.060519
 >> iter 33000, loss: 13.037785
 >> iter 34000, loss: 13.066121
 >> iter 35000, loss: 13.031661
 >> iter 36000, loss: 13.049271
 >> iter 37000, loss: 13.030903
 >> iter 38000, loss: 13.058044
 >> iter 39000, loss: 13.024538
 >> iter 40000, loss: 13.059234
   Number of active neurons: 2
 >> iter 41000, loss: 13.024590
 >> iter 42000, loss: 13.060470
 >> iter 43000, loss: 13.039676
 >> iter 44000, loss: 13.069879
 >> iter 45000, loss: 13.048307
 >> iter 46000, loss: 13.068643
 >> iter 47000, loss: 13.034014
 >> iter 48000, loss: 13.048755
 >> iter 49000, loss: 13.012312
 >> iter 50000, loss: 13.051008
   Number of active neurons: 2
 >> iter 51000, loss: 13.027058
 >> iter 52000, loss: 13.057957
 >> iter 53000, loss: 13.027576
 >> iter 54000, loss: 13.062459
 >> iter 55000, loss: 13.027987
 >> iter 56000, loss: 13.063317
 >> iter 57000, loss: 13.028633
 >> iter 58000, loss: 13.059908
 >> iter 59000, loss: 13.035095
 >> iter 60000, loss: 13.053592
   Number of active neurons: 2
 >> iter 61000, loss: 13.019442
 >> iter 62000, loss: 13.064414
 >> iter 63000, loss: 13.035836
 >> iter 64000, loss: 13.066724
 >> iter 65000, loss: 13.040773
 >> iter 66000, loss: 13.062958
 >> iter 67000, loss: 13.032776
 >> iter 68000, loss: 13.062723
 >> iter 69000, loss: 13.030584
 >> iter 70000, loss: 13.053061
   Number of active neurons: 2
 >> iter 71000, loss: 13.027541
 >> iter 72000, loss: 13.064062
 >> iter 73000, loss: 13.028190
 >> iter 74000, loss: 13.063594
 >> iter 75000, loss: 13.022620
 >> iter 76000, loss: 13.067034
 >> iter 77000, loss: 13.046119
 >> iter 78000, loss: 13.066632
 >> iter 79000, loss: 13.029626
 >> iter 80000, loss: 13.059103
   Number of active neurons: 2
 >> iter 81000, loss: 13.034287
 >> iter 82000, loss: 13.074742
 >> iter 83000, loss: 13.038031
 >> iter 84000, loss: 13.067046
 >> iter 85000, loss: 13.023577
 >> iter 86000, loss: 13.068609
 >> iter 87000, loss: 13.031813
 >> iter 88000, loss: 13.065429
 >> iter 89000, loss: 13.037667
 >> iter 90000, loss: 13.073752
   Number of active neurons: 2
 >> iter 91000, loss: 13.036829
 >> iter 92000, loss: 13.068542
 >> iter 93000, loss: 13.034456
 >> iter 94000, loss: 13.073230
 >> iter 95000, loss: 13.036828
 >> iter 96000, loss: 13.063594
 >> iter 97000, loss: 13.026152
 >> iter 98000, loss: 13.055808
 >> iter 99000, loss: 13.040844
 >> iter 100000, loss: 13.073215
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.870120
 >> iter 2000, loss: 15.230191
 >> iter 3000, loss: 13.841999
 >> iter 4000, loss: 13.355748
 >> iter 5000, loss: 13.148182
 >> iter 6000, loss: 13.076398
 >> iter 7000, loss: 13.055090
 >> iter 8000, loss: 13.051501
 >> iter 9000, loss: 13.025321
 >> iter 10000, loss: 13.056354
   Number of active neurons: 2
 >> iter 11000, loss: 13.030379
 >> iter 12000, loss: 13.044532
 >> iter 13000, loss: 13.040273
 >> iter 14000, loss: 13.048891
 >> iter 15000, loss: 13.033731
 >> iter 16000, loss: 13.061573
 >> iter 17000, loss: 13.048576
 >> iter 18000, loss: 13.055823
 >> iter 19000, loss: 13.034011
 >> iter 20000, loss: 13.039310
   Number of active neurons: 2
 >> iter 21000, loss: 13.031056
 >> iter 22000, loss: 13.038629
 >> iter 23000, loss: 13.028109
 >> iter 24000, loss: 13.040408
 >> iter 25000, loss: 13.026582
 >> iter 26000, loss: 13.056186
 >> iter 27000, loss: 13.017510
 >> iter 28000, loss: 13.050966
 >> iter 29000, loss: 13.026649
 >> iter 30000, loss: 13.055361
   Number of active neurons: 2
 >> iter 31000, loss: 13.027396
 >> iter 32000, loss: 13.059482
 >> iter 33000, loss: 13.042547
 >> iter 34000, loss: 13.059649
 >> iter 35000, loss: 13.042474
 >> iter 36000, loss: 13.057966
 >> iter 37000, loss: 13.026688
 >> iter 38000, loss: 13.060795
 >> iter 39000, loss: 13.034273
 >> iter 40000, loss: 13.066358
   Number of active neurons: 2
 >> iter 41000, loss: 13.040352
 >> iter 42000, loss: 13.061226
 >> iter 43000, loss: 13.035100
 >> iter 44000, loss: 13.070086
 >> iter 45000, loss: 13.039617
 >> iter 46000, loss: 13.061982
 >> iter 47000, loss: 13.033886
 >> iter 48000, loss: 13.055529
 >> iter 49000, loss: 13.034804
 >> iter 50000, loss: 13.066658
   Number of active neurons: 2
 >> iter 51000, loss: 13.032602
 >> iter 52000, loss: 13.067470
 >> iter 53000, loss: 13.033034
 >> iter 54000, loss: 13.077692
 >> iter 55000, loss: 13.031434
 >> iter 56000, loss: 13.067752
 >> iter 57000, loss: 13.028687
 >> iter 58000, loss: 13.068005
 >> iter 59000, loss: 13.027432
 >> iter 60000, loss: 13.063058
   Number of active neurons: 2
 >> iter 61000, loss: 13.026297
 >> iter 62000, loss: 13.056956
 >> iter 63000, loss: 13.027211
 >> iter 64000, loss: 13.047140
 >> iter 65000, loss: 13.032344
 >> iter 66000, loss: 13.061194
 >> iter 67000, loss: 13.032951
 >> iter 68000, loss: 13.065031
 >> iter 69000, loss: 13.029904
 >> iter 70000, loss: 13.058440
   Number of active neurons: 2
 >> iter 71000, loss: 13.027710
 >> iter 72000, loss: 13.064116
 >> iter 73000, loss: 13.033464
 >> iter 74000, loss: 13.072489
 >> iter 75000, loss: 13.035405
 >> iter 76000, loss: 13.057546
 >> iter 77000, loss: 13.033072
 >> iter 78000, loss: 13.077788
 >> iter 79000, loss: 13.019343
 >> iter 80000, loss: 13.056180
   Number of active neurons: 2
 >> iter 81000, loss: 13.019733
 >> iter 82000, loss: 13.074423
 >> iter 83000, loss: 13.039943
 >> iter 84000, loss: 13.077666
 >> iter 85000, loss: 13.031028
 >> iter 86000, loss: 13.075188
 >> iter 87000, loss: 13.024763
 >> iter 88000, loss: 13.066318
 >> iter 89000, loss: 13.029395
 >> iter 90000, loss: 13.063690
   Number of active neurons: 2
 >> iter 91000, loss: 13.032558
 >> iter 92000, loss: 13.063909
 >> iter 93000, loss: 13.037148
 >> iter 94000, loss: 13.070999
 >> iter 95000, loss: 13.038592
 >> iter 96000, loss: 13.071958
 >> iter 97000, loss: 13.036266
 >> iter 98000, loss: 13.071532
 >> iter 99000, loss: 13.031144
 >> iter 100000, loss: 13.075412
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.592104
 >> iter 2000, loss: 18.053297
 >> iter 3000, loss: 17.133857
 >> iter 4000, loss: 16.782079
 >> iter 5000, loss: 16.665553
 >> iter 6000, loss: 16.611422
 >> iter 7000, loss: 16.602645
 >> iter 8000, loss: 16.587542
 >> iter 9000, loss: 16.594384
 >> iter 10000, loss: 16.584656
   Number of active neurons: 0
 >> iter 11000, loss: 16.594025
 >> iter 12000, loss: 16.584484
 >> iter 13000, loss: 16.594121
 >> iter 14000, loss: 16.584677
 >> iter 15000, loss: 16.592910
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 14.726122
 >> iter 17000, loss: 13.676080
 >> iter 18000, loss: 13.300120
 >> iter 19000, loss: 13.124459
 >> iter 20000, loss: 13.077909
   Number of active neurons: 2
 >> iter 21000, loss: 13.038591
 >> iter 22000, loss: 13.057329
 >> iter 23000, loss: 13.040189
 >> iter 24000, loss: 13.052791
 >> iter 25000, loss: 13.042545
 >> iter 26000, loss: 13.050808
 >> iter 27000, loss: 13.037128
 >> iter 28000, loss: 13.050842
 >> iter 29000, loss: 13.037789
 >> iter 30000, loss: 13.052917
   Number of active neurons: 2
 >> iter 31000, loss: 13.034744
 >> iter 32000, loss: 13.046727
 >> iter 33000, loss: 13.039815
 >> iter 34000, loss: 13.065726
 >> iter 35000, loss: 13.047731
 >> iter 36000, loss: 13.051065
 >> iter 37000, loss: 13.024749
 >> iter 38000, loss: 13.051994
 >> iter 39000, loss: 13.034713
 >> iter 40000, loss: 13.050487
   Number of active neurons: 2
 >> iter 41000, loss: 13.029102
 >> iter 42000, loss: 13.061167
 >> iter 43000, loss: 13.037720
 >> iter 44000, loss: 13.064202
 >> iter 45000, loss: 13.038529
 >> iter 46000, loss: 13.062750
 >> iter 47000, loss: 13.034053
 >> iter 48000, loss: 13.061025
 >> iter 49000, loss: 13.028258
 >> iter 50000, loss: 13.061427
   Number of active neurons: 2
 >> iter 51000, loss: 13.017886
 >> iter 52000, loss: 13.063398
 >> iter 53000, loss: 13.032313
 >> iter 54000, loss: 13.049860
 >> iter 55000, loss: 13.029983
 >> iter 56000, loss: 13.071611
 >> iter 57000, loss: 13.031800
 >> iter 58000, loss: 13.049023
 >> iter 59000, loss: 13.026669
 >> iter 60000, loss: 13.051545
   Number of active neurons: 2
 >> iter 61000, loss: 13.030812
 >> iter 62000, loss: 13.060570
 >> iter 63000, loss: 13.026532
 >> iter 64000, loss: 13.048615
 >> iter 65000, loss: 13.019468
 >> iter 66000, loss: 13.067653
 >> iter 67000, loss: 13.039399
 >> iter 68000, loss: 13.066782
 >> iter 69000, loss: 13.043699
 >> iter 70000, loss: 13.080520
   Number of active neurons: 2
 >> iter 71000, loss: 13.032158
 >> iter 72000, loss: 13.074833
 >> iter 73000, loss: 13.027780
 >> iter 74000, loss: 13.069079
 >> iter 75000, loss: 13.025386
 >> iter 76000, loss: 13.068694
 >> iter 77000, loss: 13.024558
 >> iter 78000, loss: 13.060931
 >> iter 79000, loss: 13.033877
 >> iter 80000, loss: 13.076175
   Number of active neurons: 2
 >> iter 81000, loss: 13.032000
 >> iter 82000, loss: 13.076024
 >> iter 83000, loss: 13.040563
 >> iter 84000, loss: 13.059743
 >> iter 85000, loss: 13.022672
 >> iter 86000, loss: 13.060813
 >> iter 87000, loss: 13.023526
 >> iter 88000, loss: 13.071209
 >> iter 89000, loss: 13.023850
 >> iter 90000, loss: 13.061485
   Number of active neurons: 2
 >> iter 91000, loss: 13.031062
 >> iter 92000, loss: 13.056638
 >> iter 93000, loss: 13.027620
 >> iter 94000, loss: 13.075817
 >> iter 95000, loss: 13.034051
 >> iter 96000, loss: 13.073084
 >> iter 97000, loss: 13.039826
 >> iter 98000, loss: 13.082905
 >> iter 99000, loss: 13.037027
 >> iter 100000, loss: 13.065095
   Number of active neurons: 2
 >> iter 101000, loss: 13.029675
 >> iter 102000, loss: 13.061353
 >> iter 103000, loss: 13.041218
 >> iter 104000, loss: 13.080633
 >> iter 105000, loss: 13.044040
 >> iter 106000, loss: 13.078212
 >> iter 107000, loss: 13.031821
 >> iter 108000, loss: 13.077658
 >> iter 109000, loss: 13.029979
 >> iter 110000, loss: 13.071460
   Number of active neurons: 2
 >> iter 111000, loss: 13.035389
 >> iter 112000, loss: 13.061693
 >> iter 113000, loss: 13.015211
 >> iter 114000, loss: 13.073010
 >> iter 115000, loss: 13.034453
 >> iter 116000, loss: 13.075564
 >> iter 117000, loss: 13.026415
 >> iter 118000, loss: 13.052281
 >> iter 119000, loss: 13.022778
 >> iter 120000, loss: 13.059446
   Number of active neurons: 2
 >> iter 121000, loss: 13.007595
 >> iter 122000, loss: 13.054191
 >> iter 123000, loss: 13.005011
 >> iter 124000, loss: 13.066137
 >> iter 125000, loss: 13.007336
 >> iter 126000, loss: 13.068653
 >> iter 127000, loss: 13.018501
 >> iter 128000, loss: 13.076471
 >> iter 129000, loss: 13.029043
 >> iter 130000, loss: 13.077434
   Number of active neurons: 2
 >> iter 131000, loss: 13.018294
 >> iter 132000, loss: 13.064956
 >> iter 133000, loss: 13.019243
 >> iter 134000, loss: 13.071704
 >> iter 135000, loss: 13.012827
 >> iter 136000, loss: 13.067369
 >> iter 137000, loss: 12.995418
 >> iter 138000, loss: 13.066193
 >> iter 139000, loss: 13.006784
 >> iter 140000, loss: 13.081653
   Number of active neurons: 2
 >> iter 141000, loss: 13.013720
 >> iter 142000, loss: 13.083939
 >> iter 143000, loss: 13.010476
 >> iter 144000, loss: 13.072263
 >> iter 145000, loss: 13.021612
 >> iter 146000, loss: 13.081640
 >> iter 147000, loss: 13.022506
 >> iter 148000, loss: 13.090818
 >> iter 149000, loss: 13.023482
 >> iter 150000, loss: 13.079191
   Number of active neurons: 2
 >> iter 151000, loss: 13.030330
 >> iter 152000, loss: 13.073215
 >> iter 153000, loss: 13.015342
 >> iter 154000, loss: 13.083137
 >> iter 155000, loss: 13.021610
 >> iter 156000, loss: 13.086091
 >> iter 157000, loss: 13.010127
 >> iter 158000, loss: 13.073866
 >> iter 159000, loss: 13.018549
 >> iter 160000, loss: 13.081534
   Number of active neurons: 2
 >> iter 161000, loss: 13.024729
 >> iter 162000, loss: 13.068216
 >> iter 163000, loss: 13.011677
 >> iter 164000, loss: 13.069675
 >> iter 165000, loss: 13.008401
 >> iter 166000, loss: 13.080046
 >> iter 167000, loss: 13.002179
 >> iter 168000, loss: 13.067434
 >> iter 169000, loss: 13.008441
 >> iter 170000, loss: 13.076197
   Number of active neurons: 2
 >> iter 171000, loss: 13.004094
 >> iter 172000, loss: 13.074731
 >> iter 173000, loss: 13.009089
 >> iter 174000, loss: 13.079687
 >> iter 175000, loss: 13.009131
 >> iter 176000, loss: 13.066038
 >> iter 177000, loss: 13.011040
 >> iter 178000, loss: 13.090296
 >> iter 179000, loss: 13.015443
 >> iter 180000, loss: 13.074340
   Number of active neurons: 2
 >> iter 181000, loss: 13.010826
 >> iter 182000, loss: 13.079635
 >> iter 183000, loss: 13.010273
 >> iter 184000, loss: 13.080487
 >> iter 185000, loss: 13.005314
 >> iter 186000, loss: 13.078043
 >> iter 187000, loss: 12.999701
 >> iter 188000, loss: 13.059738
 >> iter 189000, loss: 12.998719
 >> iter 190000, loss: 13.087407
   Number of active neurons: 2
 >> iter 191000, loss: 13.008474
 >> iter 192000, loss: 13.077513
 >> iter 193000, loss: 13.010978
 >> iter 194000, loss: 13.073882
 >> iter 195000, loss: 13.003699
 >> iter 196000, loss: 13.061193
 >> iter 197000, loss: 12.995700
 >> iter 198000, loss: 13.067696
 >> iter 199000, loss: 13.010275
 >> iter 200000, loss: 13.075571
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.848042
 >> iter 2000, loss: 15.215612
 >> iter 3000, loss: 13.852778
 >> iter 4000, loss: 13.365811
 >> iter 5000, loss: 13.159960
 >> iter 6000, loss: 13.093720
 >> iter 7000, loss: 13.056445
 >> iter 8000, loss: 13.063264
 >> iter 9000, loss: 13.038083
 >> iter 10000, loss: 13.047606
   Number of active neurons: 2
 >> iter 11000, loss: 13.038166
 >> iter 12000, loss: 13.044443
 >> iter 13000, loss: 13.039343
 >> iter 14000, loss: 13.054263
 >> iter 15000, loss: 13.041651
 >> iter 16000, loss: 13.052075
 >> iter 17000, loss: 13.035242
 >> iter 18000, loss: 13.051337
 >> iter 19000, loss: 13.035808
 >> iter 20000, loss: 13.055256
   Number of active neurons: 2
 >> iter 21000, loss: 13.035926
 >> iter 22000, loss: 13.060013
 >> iter 23000, loss: 13.043175
 >> iter 24000, loss: 13.054871
 >> iter 25000, loss: 13.034006
 >> iter 26000, loss: 13.050811
 >> iter 27000, loss: 13.023444
 >> iter 28000, loss: 13.051563
 >> iter 29000, loss: 13.045571
 >> iter 30000, loss: 13.051379
   Number of active neurons: 2
 >> iter 31000, loss: 13.035805
 >> iter 32000, loss: 13.054450
 >> iter 33000, loss: 13.036563
 >> iter 34000, loss: 13.060114
 >> iter 35000, loss: 13.036484
 >> iter 36000, loss: 13.053124
 >> iter 37000, loss: 13.035479
 >> iter 38000, loss: 13.046211
 >> iter 39000, loss: 13.029033
 >> iter 40000, loss: 13.058690
   Number of active neurons: 2
 >> iter 41000, loss: 13.044813
 >> iter 42000, loss: 13.049860
 >> iter 43000, loss: 13.037257
 >> iter 44000, loss: 13.058449
 >> iter 45000, loss: 13.025289
 >> iter 46000, loss: 13.048784
 >> iter 47000, loss: 13.024729
 >> iter 48000, loss: 13.062544
 >> iter 49000, loss: 13.034595
 >> iter 50000, loss: 13.064520
   Number of active neurons: 2
 >> iter 51000, loss: 13.039415
 >> iter 52000, loss: 13.069976
 >> iter 53000, loss: 13.037750
 >> iter 54000, loss: 13.064938
 >> iter 55000, loss: 13.027970
 >> iter 56000, loss: 13.074146
 >> iter 57000, loss: 13.024667
 >> iter 58000, loss: 13.064669
 >> iter 59000, loss: 13.034168
 >> iter 60000, loss: 13.059054
   Number of active neurons: 2
 >> iter 61000, loss: 13.026639
 >> iter 62000, loss: 13.062361
 >> iter 63000, loss: 13.044104
 >> iter 64000, loss: 13.069925
 >> iter 65000, loss: 13.019617
 >> iter 66000, loss: 13.066417
 >> iter 67000, loss: 13.023911
 >> iter 68000, loss: 13.046939
 >> iter 69000, loss: 13.034281
 >> iter 70000, loss: 13.059938
   Number of active neurons: 2
 >> iter 71000, loss: 13.020069
 >> iter 72000, loss: 13.066953
 >> iter 73000, loss: 13.031815
 >> iter 74000, loss: 13.069908
 >> iter 75000, loss: 13.029237
 >> iter 76000, loss: 13.063066
 >> iter 77000, loss: 13.013620
 >> iter 78000, loss: 13.045234
 >> iter 79000, loss: 13.020360
 >> iter 80000, loss: 13.055256
   Number of active neurons: 2
 >> iter 81000, loss: 13.031469
 >> iter 82000, loss: 13.071699
 >> iter 83000, loss: 13.035029
 >> iter 84000, loss: 13.052247
 >> iter 85000, loss: 13.024793
 >> iter 86000, loss: 13.071280
 >> iter 87000, loss: 13.033821
 >> iter 88000, loss: 13.065149
 >> iter 89000, loss: 13.040236
 >> iter 90000, loss: 13.080341
   Number of active neurons: 2
 >> iter 91000, loss: 13.038545
 >> iter 92000, loss: 13.072148
 >> iter 93000, loss: 13.021244
 >> iter 94000, loss: 13.065234
 >> iter 95000, loss: 13.033330
 >> iter 96000, loss: 13.057185
 >> iter 97000, loss: 13.031273
 >> iter 98000, loss: 13.052412
 >> iter 99000, loss: 13.021700
 >> iter 100000, loss: 13.046365
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.234731
 >> iter 2000, loss: 15.894840
 >> iter 3000, loss: 14.659915
 >> iter 4000, loss: 14.202018
 >> iter 5000, loss: 14.023053
 >> iter 6000, loss: 13.963388
 >> iter 7000, loss: 13.930921
 >> iter 8000, loss: 13.929770
 >> iter 9000, loss: 13.920660
 >> iter 10000, loss: 13.926143
   Number of active neurons: 1
 >> iter 11000, loss: 13.914495
 >> iter 12000, loss: 13.925659
 >> iter 13000, loss: 13.916848
 >> iter 14000, loss: 13.919153
 >> iter 15000, loss: 13.914260
 >> iter 16000, loss: 13.928209
 >> iter 17000, loss: 13.918171
 >> iter 18000, loss: 13.926367
 >> iter 19000, loss: 13.910578
 >> iter 20000, loss: 13.930800
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 1
 >> iter 21000, loss: 13.931056
 >> iter 22000, loss: 13.681974
 >> iter 23000, loss: 13.298673
 >> iter 24000, loss: 13.159317
 >> iter 25000, loss: 13.067730
 >> iter 26000, loss: 13.066041
 >> iter 27000, loss: 13.054497
 >> iter 28000, loss: 13.066372
 >> iter 29000, loss: 13.039535
 >> iter 30000, loss: 13.066530
   Number of active neurons: 2
 >> iter 31000, loss: 13.044764
 >> iter 32000, loss: 13.069881
 >> iter 33000, loss: 13.048382
 >> iter 34000, loss: 13.070364
 >> iter 35000, loss: 13.039172
 >> iter 36000, loss: 13.054170
 >> iter 37000, loss: 13.038578
 >> iter 38000, loss: 13.060040
 >> iter 39000, loss: 13.037914
 >> iter 40000, loss: 13.056553
   Number of active neurons: 2
 >> iter 41000, loss: 13.026253
 >> iter 42000, loss: 13.051475
 >> iter 43000, loss: 13.023355
 >> iter 44000, loss: 13.057858
 >> iter 45000, loss: 13.023411
 >> iter 46000, loss: 13.058842
 >> iter 47000, loss: 13.033119
 >> iter 48000, loss: 13.070985
 >> iter 49000, loss: 13.038957
 >> iter 50000, loss: 13.074439
   Number of active neurons: 2
 >> iter 51000, loss: 13.049241
 >> iter 52000, loss: 13.063023
 >> iter 53000, loss: 13.032626
 >> iter 54000, loss: 13.052275
 >> iter 55000, loss: 13.017457
 >> iter 56000, loss: 13.049314
 >> iter 57000, loss: 13.024969
 >> iter 58000, loss: 13.066461
 >> iter 59000, loss: 13.024549
 >> iter 60000, loss: 13.057586
   Number of active neurons: 2
 >> iter 61000, loss: 13.023232
 >> iter 62000, loss: 13.064912
 >> iter 63000, loss: 13.020647
 >> iter 64000, loss: 13.054668
 >> iter 65000, loss: 13.017154
 >> iter 66000, loss: 13.067011
 >> iter 67000, loss: 13.025007
 >> iter 68000, loss: 13.051760
 >> iter 69000, loss: 13.021909
 >> iter 70000, loss: 13.054206
   Number of active neurons: 2
 >> iter 71000, loss: 13.030896
 >> iter 72000, loss: 13.069127
 >> iter 73000, loss: 13.029056
 >> iter 74000, loss: 13.060469
 >> iter 75000, loss: 13.027878
 >> iter 76000, loss: 13.053970
 >> iter 77000, loss: 13.020045
 >> iter 78000, loss: 13.068397
 >> iter 79000, loss: 13.019295
 >> iter 80000, loss: 13.058507
   Number of active neurons: 2
 >> iter 81000, loss: 13.020532
 >> iter 82000, loss: 13.058325
 >> iter 83000, loss: 13.018630
 >> iter 84000, loss: 13.064657
 >> iter 85000, loss: 13.029352
 >> iter 86000, loss: 13.061645
 >> iter 87000, loss: 13.022175
 >> iter 88000, loss: 13.049448
 >> iter 89000, loss: 13.027239
 >> iter 90000, loss: 13.066203
   Number of active neurons: 2
 >> iter 91000, loss: 13.022388
 >> iter 92000, loss: 13.059978
 >> iter 93000, loss: 13.025565
 >> iter 94000, loss: 13.072326
 >> iter 95000, loss: 13.036340
 >> iter 96000, loss: 13.060613
 >> iter 97000, loss: 13.028106
 >> iter 98000, loss: 13.060878
 >> iter 99000, loss: 13.031291
 >> iter 100000, loss: 13.076463
   Number of active neurons: 2
 >> iter 101000, loss: 13.030303
 >> iter 102000, loss: 13.073113
 >> iter 103000, loss: 13.018048
 >> iter 104000, loss: 13.074396
 >> iter 105000, loss: 13.035084
 >> iter 106000, loss: 13.064596
 >> iter 107000, loss: 13.009044
 >> iter 108000, loss: 13.053883
 >> iter 109000, loss: 13.019258
 >> iter 110000, loss: 13.078849
   Number of active neurons: 2
 >> iter 111000, loss: 13.026254
 >> iter 112000, loss: 13.081610
 >> iter 113000, loss: 13.028712
 >> iter 114000, loss: 13.066776
 >> iter 115000, loss: 13.032985
 >> iter 116000, loss: 13.083467
 >> iter 117000, loss: 13.025625
 >> iter 118000, loss: 13.055170
 >> iter 119000, loss: 13.010288
 >> iter 120000, loss: 13.064799
   Number of active neurons: 2
 >> iter 121000, loss: 13.016353
 >> iter 122000, loss: 13.073128
 >> iter 123000, loss: 13.005267
 >> iter 124000, loss: 13.043519
 >> iter 125000, loss: 13.009878
 >> iter 126000, loss: 13.073512
 >> iter 127000, loss: 13.023016
 >> iter 128000, loss: 13.070168
 >> iter 129000, loss: 13.011225
 >> iter 130000, loss: 13.064199
   Number of active neurons: 2
 >> iter 131000, loss: 13.024092
 >> iter 132000, loss: 13.091391
 >> iter 133000, loss: 13.020866
 >> iter 134000, loss: 13.090768
 >> iter 135000, loss: 13.026021
 >> iter 136000, loss: 13.073439
 >> iter 137000, loss: 13.015062
 >> iter 138000, loss: 13.081206
 >> iter 139000, loss: 13.029552
 >> iter 140000, loss: 13.079423
   Number of active neurons: 2
 >> iter 141000, loss: 13.017704
 >> iter 142000, loss: 13.091542
 >> iter 143000, loss: 13.017328
 >> iter 144000, loss: 13.087221
 >> iter 145000, loss: 13.012464
 >> iter 146000, loss: 13.060213
 >> iter 147000, loss: 13.009712
 >> iter 148000, loss: 13.080407
 >> iter 149000, loss: 13.017550
 >> iter 150000, loss: 13.088719
   Number of active neurons: 2
 >> iter 151000, loss: 13.022268
 >> iter 152000, loss: 13.083523
 >> iter 153000, loss: 13.007077
 >> iter 154000, loss: 13.067898
 >> iter 155000, loss: 13.026622
 >> iter 156000, loss: 13.078244
 >> iter 157000, loss: 13.023446
 >> iter 158000, loss: 13.092144
 >> iter 159000, loss: 13.015340
 >> iter 160000, loss: 13.087904
   Number of active neurons: 2
 >> iter 161000, loss: 13.015737
 >> iter 162000, loss: 13.080682
 >> iter 163000, loss: 13.015860
 >> iter 164000, loss: 13.078548
 >> iter 165000, loss: 13.009045
 >> iter 166000, loss: 13.070368
 >> iter 167000, loss: 13.016253
 >> iter 168000, loss: 13.068208
 >> iter 169000, loss: 13.010391
 >> iter 170000, loss: 13.075812
   Number of active neurons: 2
 >> iter 171000, loss: 13.010282
 >> iter 172000, loss: 13.074003
 >> iter 173000, loss: 13.011630
 >> iter 174000, loss: 13.076849
 >> iter 175000, loss: 13.019857
 >> iter 176000, loss: 13.089730
 >> iter 177000, loss: 13.024581
 >> iter 178000, loss: 13.074895
 >> iter 179000, loss: 13.018039
 >> iter 180000, loss: 13.078030
   Number of active neurons: 2
 >> iter 181000, loss: 13.014653
 >> iter 182000, loss: 13.079960
 >> iter 183000, loss: 13.012797
 >> iter 184000, loss: 13.082921
 >> iter 185000, loss: 13.009516
 >> iter 186000, loss: 13.075541
 >> iter 187000, loss: 13.008870
 >> iter 188000, loss: 13.067018
 >> iter 189000, loss: 13.006267
 >> iter 190000, loss: 13.080200
   Number of active neurons: 2
 >> iter 191000, loss: 13.002137
 >> iter 192000, loss: 13.080323
 >> iter 193000, loss: 13.010604
 >> iter 194000, loss: 13.076376
 >> iter 195000, loss: 13.013299
 >> iter 196000, loss: 13.070903
 >> iter 197000, loss: 13.009687
 >> iter 198000, loss: 13.076545
 >> iter 199000, loss: 13.011855
 >> iter 200000, loss: 13.055920
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.414491
 >> iter 2000, loss: 15.967076
 >> iter 3000, loss: 14.683670
 >> iter 4000, loss: 14.213394
 >> iter 5000, loss: 14.036201
 >> iter 6000, loss: 13.966538
 >> iter 7000, loss: 13.929722
 >> iter 8000, loss: 13.928608
 >> iter 9000, loss: 13.926223
 >> iter 10000, loss: 13.926969
   Number of active neurons: 1
 >> iter 11000, loss: 13.920065
 >> iter 12000, loss: 13.921199
 >> iter 13000, loss: 13.917949
 >> iter 14000, loss: 13.924163
 >> iter 15000, loss: 13.906967
 >> iter 16000, loss: 13.921599
 >> iter 17000, loss: 13.923758
 >> iter 18000, loss: 13.929407
 >> iter 19000, loss: 13.907822
 >> iter 20000, loss: 13.926062
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 1
 >> iter 21000, loss: 13.457361
 >> iter 22000, loss: 13.218520
 >> iter 23000, loss: 13.101597
 >> iter 24000, loss: 13.082751
 >> iter 25000, loss: 13.036651
 >> iter 26000, loss: 13.060416
 >> iter 27000, loss: 13.037682
 >> iter 28000, loss: 13.063424
 >> iter 29000, loss: 13.035718
 >> iter 30000, loss: 13.052746
   Number of active neurons: 2
 >> iter 31000, loss: 13.036662
 >> iter 32000, loss: 13.058778
 >> iter 33000, loss: 13.034951
 >> iter 34000, loss: 13.044241
 >> iter 35000, loss: 13.024442
 >> iter 36000, loss: 13.041142
 >> iter 37000, loss: 13.035690
 >> iter 38000, loss: 13.034294
 >> iter 39000, loss: 13.029119
 >> iter 40000, loss: 13.049953
   Number of active neurons: 2
 >> iter 41000, loss: 13.023237
 >> iter 42000, loss: 13.052729
 >> iter 43000, loss: 13.028414
 >> iter 44000, loss: 13.055858
 >> iter 45000, loss: 13.028813
 >> iter 46000, loss: 13.049891
 >> iter 47000, loss: 13.024477
 >> iter 48000, loss: 13.056833
 >> iter 49000, loss: 13.035112
 >> iter 50000, loss: 13.053864
   Number of active neurons: 2
 >> iter 51000, loss: 13.021589
 >> iter 52000, loss: 13.063311
 >> iter 53000, loss: 13.024766
 >> iter 54000, loss: 13.058469
 >> iter 55000, loss: 13.021830
 >> iter 56000, loss: 13.069034
 >> iter 57000, loss: 13.034945
 >> iter 58000, loss: 13.060434
 >> iter 59000, loss: 13.025324
 >> iter 60000, loss: 13.063673
   Number of active neurons: 2
 >> iter 61000, loss: 13.028875
 >> iter 62000, loss: 13.056497
 >> iter 63000, loss: 13.024559
 >> iter 64000, loss: 13.084291
 >> iter 65000, loss: 13.035510
 >> iter 66000, loss: 13.072980
 >> iter 67000, loss: 13.040646
 >> iter 68000, loss: 13.070145
 >> iter 69000, loss: 13.036771
 >> iter 70000, loss: 13.073933
   Number of active neurons: 2
 >> iter 71000, loss: 13.025944
 >> iter 72000, loss: 13.068935
 >> iter 73000, loss: 13.020016
 >> iter 74000, loss: 13.064940
 >> iter 75000, loss: 13.030219
 >> iter 76000, loss: 13.069743
 >> iter 77000, loss: 13.036175
 >> iter 78000, loss: 13.077903
 >> iter 79000, loss: 13.036936
 >> iter 80000, loss: 13.073089
   Number of active neurons: 2
 >> iter 81000, loss: 13.041431
 >> iter 82000, loss: 13.073568
 >> iter 83000, loss: 13.032011
 >> iter 84000, loss: 13.073604
 >> iter 85000, loss: 13.034587
 >> iter 86000, loss: 13.071309
 >> iter 87000, loss: 13.033013
 >> iter 88000, loss: 13.070515
 >> iter 89000, loss: 13.028466
 >> iter 90000, loss: 13.067800
   Number of active neurons: 2
 >> iter 91000, loss: 13.041870
 >> iter 92000, loss: 13.060251
 >> iter 93000, loss: 13.022012
 >> iter 94000, loss: 13.060323
 >> iter 95000, loss: 13.019467
 >> iter 96000, loss: 13.075788
 >> iter 97000, loss: 13.021925
 >> iter 98000, loss: 13.066267
 >> iter 99000, loss: 13.028470
 >> iter 100000, loss: 13.054039
   Number of active neurons: 2
 >> iter 101000, loss: 13.026489
 >> iter 102000, loss: 13.058265
 >> iter 103000, loss: 13.032081
 >> iter 104000, loss: 13.076686
 >> iter 105000, loss: 13.029681
 >> iter 106000, loss: 13.080267
 >> iter 107000, loss: 13.037163
 >> iter 108000, loss: 13.081835
 >> iter 109000, loss: 13.031559
 >> iter 110000, loss: 13.066104
   Number of active neurons: 2
 >> iter 111000, loss: 13.021988
 >> iter 112000, loss: 13.077973
 >> iter 113000, loss: 13.021872
 >> iter 114000, loss: 13.062403
 >> iter 115000, loss: 13.016464
 >> iter 116000, loss: 13.058740
 >> iter 117000, loss: 13.019111
 >> iter 118000, loss: 13.057471
 >> iter 119000, loss: 13.020996
 >> iter 120000, loss: 13.079563
   Number of active neurons: 2
 >> iter 121000, loss: 13.021703
 >> iter 122000, loss: 13.066325
 >> iter 123000, loss: 13.027394
 >> iter 124000, loss: 13.078405
 >> iter 125000, loss: 13.014471
 >> iter 126000, loss: 13.072143
 >> iter 127000, loss: 13.005804
 >> iter 128000, loss: 13.079668
 >> iter 129000, loss: 13.019091
 >> iter 130000, loss: 13.081248
   Number of active neurons: 2
 >> iter 131000, loss: 13.010880
 >> iter 132000, loss: 13.081706
 >> iter 133000, loss: 13.014809
 >> iter 134000, loss: 13.057656
 >> iter 135000, loss: 13.011062
 >> iter 136000, loss: 13.075355
 >> iter 137000, loss: 13.009695
 >> iter 138000, loss: 13.067416
 >> iter 139000, loss: 13.016247
 >> iter 140000, loss: 13.060547
   Number of active neurons: 2
 >> iter 141000, loss: 13.006975
 >> iter 142000, loss: 13.072592
 >> iter 143000, loss: 13.014325
 >> iter 144000, loss: 13.076781
 >> iter 145000, loss: 13.017428
 >> iter 146000, loss: 13.093139
 >> iter 147000, loss: 13.025796
 >> iter 148000, loss: 13.094205
 >> iter 149000, loss: 13.028163
 >> iter 150000, loss: 13.088600
   Number of active neurons: 2
 >> iter 151000, loss: 13.020394
 >> iter 152000, loss: 13.086309
 >> iter 153000, loss: 13.028004
 >> iter 154000, loss: 13.072898
 >> iter 155000, loss: 13.028460
 >> iter 156000, loss: 13.086852
 >> iter 157000, loss: 13.022650
 >> iter 158000, loss: 13.091025
 >> iter 159000, loss: 13.026655
 >> iter 160000, loss: 13.080997
   Number of active neurons: 2
 >> iter 161000, loss: 13.016501
 >> iter 162000, loss: 13.080896
 >> iter 163000, loss: 13.002273
 >> iter 164000, loss: 13.070098
 >> iter 165000, loss: 13.018225
 >> iter 166000, loss: 13.078705
 >> iter 167000, loss: 13.015566
 >> iter 168000, loss: 13.075515
 >> iter 169000, loss: 13.011562
 >> iter 170000, loss: 13.089467
   Number of active neurons: 2
 >> iter 171000, loss: 13.009451
 >> iter 172000, loss: 13.074507
 >> iter 173000, loss: 13.016774
 >> iter 174000, loss: 13.068264
 >> iter 175000, loss: 13.007141
 >> iter 176000, loss: 13.067178
 >> iter 177000, loss: 13.008898
 >> iter 178000, loss: 13.059657
 >> iter 179000, loss: 13.025961
 >> iter 180000, loss: 13.087251
   Number of active neurons: 2
 >> iter 181000, loss: 13.023362
 >> iter 182000, loss: 13.075236
 >> iter 183000, loss: 13.020267
 >> iter 184000, loss: 13.083679
 >> iter 185000, loss: 13.008220
 >> iter 186000, loss: 13.084638
 >> iter 187000, loss: 13.009979
 >> iter 188000, loss: 13.090336
 >> iter 189000, loss: 13.009425
 >> iter 190000, loss: 13.093241
   Number of active neurons: 2
 >> iter 191000, loss: 13.016987
 >> iter 192000, loss: 13.079529
 >> iter 193000, loss: 13.004891
 >> iter 194000, loss: 13.073785
 >> iter 195000, loss: 13.020991
 >> iter 196000, loss: 13.065454
 >> iter 197000, loss: 13.005387
 >> iter 198000, loss: 13.083538
 >> iter 199000, loss: 13.013103
 >> iter 200000, loss: 13.071888
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 27.7774444511
   - Test - Long: 32.7233638318
   - Test - Big: 27.8507214928
   - Test - A: 32.557829478
   - Test - B: 32.6044930338

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

