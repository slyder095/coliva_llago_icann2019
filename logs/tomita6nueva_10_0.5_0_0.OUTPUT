 > Problema: tomita6nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.5
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.788187
 >> iter 2000, loss: 15.242571
 >> iter 3000, loss: 13.847565
 >> iter 4000, loss: 13.328289
 >> iter 5000, loss: 13.116395
 >> iter 6000, loss: 13.046952
 >> iter 7000, loss: 13.001022
 >> iter 8000, loss: 13.001021
 >> iter 9000, loss: 12.985998
 >> iter 10000, loss: 12.992271
   Number of active neurons: 9
 >> iter 11000, loss: 12.980548
 >> iter 12000, loss: 12.988138
 >> iter 13000, loss: 12.982252
 >> iter 14000, loss: 12.994332
 >> iter 15000, loss: 12.980687
 >> iter 16000, loss: 12.983196
 >> iter 17000, loss: 12.983870
 >> iter 18000, loss: 12.984013
 >> iter 19000, loss: 12.972695
 >> iter 20000, loss: 12.995153
   Number of active neurons: 10
 >> iter 21000, loss: 12.977527
 >> iter 22000, loss: 12.988186
 >> iter 23000, loss: 12.973140
 >> iter 24000, loss: 12.986362
 >> iter 25000, loss: 12.980585
 >> iter 26000, loss: 12.985677
 >> iter 27000, loss: 12.976740
 >> iter 28000, loss: 12.974220
 >> iter 29000, loss: 12.935968
 >> iter 30000, loss: 12.902790
   Number of active neurons: 10
 >> iter 31000, loss: 12.398729
 >> iter 32000, loss: 11.148060
 >> iter 33000, loss: 9.378082
 >> iter 34000, loss: 7.591049
 >> iter 35000, loss: 6.991258
 >> iter 36000, loss: 5.540854
 >> iter 37000, loss: 3.432552
 >> iter 38000, loss: 2.053864
 >> iter 39000, loss: 1.531482
 >> iter 40000, loss: 0.717302
   Number of active neurons: 10
 >> iter 41000, loss: 0.824389
 >> iter 42000, loss: 0.785957
 >> iter 43000, loss: 0.481590
 >> iter 44000, loss: 0.827922
 >> iter 45000, loss: 0.471030
 >> iter 46000, loss: 0.370863
 >> iter 47000, loss: 0.234864
 >> iter 48000, loss: 0.331225
 >> iter 49000, loss: 0.266070
 >> iter 50000, loss: 0.157260
   Number of active neurons: 10
 >> iter 51000, loss: 0.213217
 >> iter 52000, loss: 0.355821
 >> iter 53000, loss: 0.250741
 >> iter 54000, loss: 0.165697
 >> iter 55000, loss: 0.147116
 >> iter 56000, loss: 0.124052
 >> iter 57000, loss: 0.066506
 >> iter 58000, loss: 0.091542
 >> iter 59000, loss: 0.044158
 >> iter 60000, loss: 0.282962
   Number of active neurons: 10
 >> iter 61000, loss: 0.220580
 >> iter 62000, loss: 0.148307
 >> iter 63000, loss: 0.067212
 >> iter 64000, loss: 0.071797
 >> iter 65000, loss: 0.128896
 >> iter 66000, loss: 0.125484
 >> iter 67000, loss: 0.338607
 >> iter 68000, loss: 0.153156
 >> iter 69000, loss: 0.079155
 >> iter 70000, loss: 0.053967
   Number of active neurons: 10
 >> iter 71000, loss: 0.031390
 >> iter 72000, loss: 0.024471
 >> iter 73000, loss: 0.070546
 >> iter 74000, loss: 0.069555
 >> iter 75000, loss: 0.049529
 >> iter 76000, loss: 0.091990
 >> iter 77000, loss: 0.040041
 >> iter 78000, loss: 0.020153
 >> iter 79000, loss: 0.012824
 >> iter 80000, loss: 0.131291
   Number of active neurons: 10
 >> iter 81000, loss: 0.168710
 >> iter 82000, loss: 0.148916
 >> iter 83000, loss: 0.079438
 >> iter 84000, loss: 0.035530
 >> iter 85000, loss: 0.018695
 >> iter 86000, loss: 0.112547
 >> iter 87000, loss: 0.052799
 >> iter 88000, loss: 0.036695
 >> iter 89000, loss: 0.068363
 >> iter 90000, loss: 0.102058
   Number of active neurons: 10
 >> iter 91000, loss: 0.101455
 >> iter 92000, loss: 0.111934
 >> iter 93000, loss: 0.233665
 >> iter 94000, loss: 0.129917
 >> iter 95000, loss: 0.054955
 >> iter 96000, loss: 0.415581
 >> iter 97000, loss: 0.291464
 >> iter 98000, loss: 0.137873
 >> iter 99000, loss: 0.058820
 >> iter 100000, loss: 0.029375
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.785604
 >> iter 2000, loss: 15.223559
 >> iter 3000, loss: 13.820086
 >> iter 4000, loss: 13.302553
 >> iter 5000, loss: 13.106516
 >> iter 6000, loss: 13.022317
 >> iter 7000, loss: 12.978557
 >> iter 8000, loss: 12.974931
 >> iter 9000, loss: 12.970081
 >> iter 10000, loss: 12.975391
   Number of active neurons: 8
 >> iter 11000, loss: 12.953312
 >> iter 12000, loss: 12.966105
 >> iter 13000, loss: 12.957357
 >> iter 14000, loss: 12.966940
 >> iter 15000, loss: 12.959381
 >> iter 16000, loss: 12.963155
 >> iter 17000, loss: 12.955732
 >> iter 18000, loss: 12.960410
 >> iter 19000, loss: 12.956209
 >> iter 20000, loss: 12.972285
   Number of active neurons: 8
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 8
 >> iter 21000, loss: 12.953431
 >> iter 22000, loss: 12.969286
 >> iter 23000, loss: 12.956264
 >> iter 24000, loss: 12.970885
 >> iter 25000, loss: 12.957401
 >> iter 26000, loss: 12.970655
 >> iter 27000, loss: 12.960009
 >> iter 28000, loss: 12.963931
 >> iter 29000, loss: 12.953947
 >> iter 30000, loss: 12.968335
   Number of active neurons: 8
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 8
 >> iter 31000, loss: 12.947767
 >> iter 32000, loss: 12.958459
 >> iter 33000, loss: 12.940779
 >> iter 34000, loss: 12.746602
 >> iter 35000, loss: 11.689662
 >> iter 36000, loss: 6.633818
 >> iter 37000, loss: 3.644333
 >> iter 38000, loss: 1.670132
 >> iter 39000, loss: 0.858713
 >> iter 40000, loss: 0.530302
   Number of active neurons: 10
 >> iter 41000, loss: 0.493077
 >> iter 42000, loss: 0.447035
 >> iter 43000, loss: 0.375266
 >> iter 44000, loss: 0.209237
 >> iter 45000, loss: 0.265705
 >> iter 46000, loss: 0.269976
 >> iter 47000, loss: 0.273999
 >> iter 48000, loss: 0.177737
 >> iter 49000, loss: 0.387889
 >> iter 50000, loss: 0.498535
   Number of active neurons: 10
 >> iter 51000, loss: 0.227157
 >> iter 52000, loss: 0.103142
 >> iter 53000, loss: 0.119553
 >> iter 54000, loss: 0.267029
 >> iter 55000, loss: 0.265182
 >> iter 56000, loss: 0.266261
 >> iter 57000, loss: 0.245914
 >> iter 58000, loss: 0.109118
 >> iter 59000, loss: 0.166375
 >> iter 60000, loss: 0.075194
   Number of active neurons: 10
 >> iter 61000, loss: 0.040373
 >> iter 62000, loss: 0.025998
 >> iter 63000, loss: 0.019329
 >> iter 64000, loss: 0.016001
 >> iter 65000, loss: 0.013478
 >> iter 66000, loss: 0.305843
 >> iter 67000, loss: 0.123387
 >> iter 68000, loss: 0.128025
 >> iter 69000, loss: 0.068496
 >> iter 70000, loss: 0.042352
   Number of active neurons: 10
 >> iter 71000, loss: 0.084907
 >> iter 72000, loss: 0.045434
 >> iter 73000, loss: 0.024526
 >> iter 74000, loss: 0.015023
 >> iter 75000, loss: 0.010919
 >> iter 76000, loss: 0.009263
 >> iter 77000, loss: 0.069064
 >> iter 78000, loss: 0.031395
 >> iter 79000, loss: 0.016489
 >> iter 80000, loss: 0.092831
   Number of active neurons: 10
 >> iter 81000, loss: 0.039293
 >> iter 82000, loss: 0.019888
 >> iter 83000, loss: 0.079789
 >> iter 84000, loss: 0.076515
 >> iter 85000, loss: 0.032971
 >> iter 86000, loss: 0.016390
 >> iter 87000, loss: 0.146899
 >> iter 88000, loss: 0.061020
 >> iter 89000, loss: 0.149533
 >> iter 90000, loss: 0.181892
   Number of active neurons: 10
 >> iter 91000, loss: 0.178375
 >> iter 92000, loss: 0.087266
 >> iter 93000, loss: 0.038858
 >> iter 94000, loss: 0.284729
 >> iter 95000, loss: 0.112034
 >> iter 96000, loss: 0.047265
 >> iter 97000, loss: 0.022696
 >> iter 98000, loss: 0.014313
 >> iter 99000, loss: 0.011878
 >> iter 100000, loss: 0.011199
   Number of active neurons: 10
 >> iter 101000, loss: 0.012978
 >> iter 102000, loss: 0.013275
 >> iter 103000, loss: 0.099666
 >> iter 104000, loss: 0.041411
 >> iter 105000, loss: 0.019316
 >> iter 106000, loss: 0.010889
 >> iter 107000, loss: 0.007544
 >> iter 108000, loss: 0.006172
 >> iter 109000, loss: 0.005363
 >> iter 110000, loss: 0.004976
   Number of active neurons: 10
 >> iter 111000, loss: 0.075971
 >> iter 112000, loss: 0.031580
 >> iter 113000, loss: 0.014866
 >> iter 114000, loss: 0.082340
 >> iter 115000, loss: 0.033994
 >> iter 116000, loss: 0.015582
 >> iter 117000, loss: 0.008509
 >> iter 118000, loss: 0.006054
 >> iter 119000, loss: 0.038995
 >> iter 120000, loss: 0.017684
   Number of active neurons: 10
 >> iter 121000, loss: 0.009214
 >> iter 122000, loss: 0.008230
 >> iter 123000, loss: 0.005572
 >> iter 124000, loss: 0.057785
 >> iter 125000, loss: 0.025697
 >> iter 126000, loss: 0.013059
 >> iter 127000, loss: 0.008585
 >> iter 128000, loss: 0.005803
 >> iter 129000, loss: 0.005336
 >> iter 130000, loss: 0.004550
   Number of active neurons: 10
 >> iter 131000, loss: 0.004083
 >> iter 132000, loss: 0.003673
 >> iter 133000, loss: 0.003496
 >> iter 134000, loss: 0.003293
 >> iter 135000, loss: 0.044700
 >> iter 136000, loss: 0.018628
 >> iter 137000, loss: 0.008901
 >> iter 138000, loss: 0.044418
 >> iter 139000, loss: 0.018389
 >> iter 140000, loss: 0.016094
   Number of active neurons: 10
 >> iter 141000, loss: 0.008167
 >> iter 142000, loss: 0.004793
 >> iter 143000, loss: 0.003656
 >> iter 144000, loss: 0.003135
 >> iter 145000, loss: 0.002913
 >> iter 146000, loss: 0.002655
 >> iter 147000, loss: 0.002747
 >> iter 148000, loss: 0.002546
 >> iter 149000, loss: 0.002527
 >> iter 150000, loss: 0.002329
   Number of active neurons: 10
 >> iter 151000, loss: 0.002247
 >> iter 152000, loss: 0.002311
 >> iter 153000, loss: 0.002145
 >> iter 154000, loss: 0.002075
 >> iter 155000, loss: 0.002005
 >> iter 156000, loss: 0.002951
 >> iter 157000, loss: 0.002710
 >> iter 158000, loss: 0.002325
 >> iter 159000, loss: 0.002087
 >> iter 160000, loss: 0.002082
   Number of active neurons: 10
 >> iter 161000, loss: 0.001967
 >> iter 162000, loss: 0.002199
 >> iter 163000, loss: 0.001911
 >> iter 164000, loss: 0.001891
 >> iter 165000, loss: 0.095321
 >> iter 166000, loss: 0.038799
 >> iter 167000, loss: 0.081776
 >> iter 168000, loss: 0.033180
 >> iter 169000, loss: 0.014013
 >> iter 170000, loss: 0.006725
   Number of active neurons: 10
 >> iter 171000, loss: 0.005405
 >> iter 172000, loss: 0.003380
 >> iter 173000, loss: 0.002592
 >> iter 174000, loss: 0.002272
 >> iter 175000, loss: 0.002106
 >> iter 176000, loss: 0.001936
 >> iter 177000, loss: 0.001869
 >> iter 178000, loss: 0.001862
 >> iter 179000, loss: 0.001813
 >> iter 180000, loss: 0.035879
   Number of active neurons: 10
 >> iter 181000, loss: 0.014603
 >> iter 182000, loss: 0.006616
 >> iter 183000, loss: 0.003733
 >> iter 184000, loss: 0.002479
 >> iter 185000, loss: 0.002383
 >> iter 186000, loss: 0.002144
 >> iter 187000, loss: 0.001809
 >> iter 188000, loss: 0.003786
 >> iter 189000, loss: 0.002331
 >> iter 190000, loss: 0.001779
   Number of active neurons: 10
 >> iter 191000, loss: 0.051982
 >> iter 192000, loss: 0.020661
 >> iter 193000, loss: 0.008944
 >> iter 194000, loss: 0.004485
 >> iter 195000, loss: 0.002737
 >> iter 196000, loss: 0.002340
 >> iter 197000, loss: 0.001921
 >> iter 198000, loss: 0.002266
 >> iter 199000, loss: 0.001838
 >> iter 200000, loss: 0.001691
   Number of active neurons: 10
 >> iter 201000, loss: 0.001550
 >> iter 202000, loss: 0.001482
 >> iter 203000, loss: 0.001752
 >> iter 204000, loss: 0.001662
 >> iter 205000, loss: 0.001514
 >> iter 206000, loss: 0.087212
 >> iter 207000, loss: 0.083331
 >> iter 208000, loss: 0.032498
 >> iter 209000, loss: 0.013359
 >> iter 210000, loss: 0.010067
   Number of active neurons: 10
 >> iter 211000, loss: 0.004816
 >> iter 212000, loss: 0.002761
 >> iter 213000, loss: 0.001986
 >> iter 214000, loss: 0.001636
 >> iter 215000, loss: 0.001626
 >> iter 216000, loss: 0.001470
 >> iter 217000, loss: 0.001442
 >> iter 218000, loss: 0.031862
 >> iter 219000, loss: 0.012585
 >> iter 220000, loss: 0.032030
   Number of active neurons: 10
 >> iter 221000, loss: 0.012840
 >> iter 222000, loss: 0.005675
 >> iter 223000, loss: 0.056622
 >> iter 224000, loss: 0.021792
 >> iter 225000, loss: 0.009935
 >> iter 226000, loss: 0.004991
 >> iter 227000, loss: 0.032407
 >> iter 228000, loss: 0.014939
 >> iter 229000, loss: 0.006398
 >> iter 230000, loss: 0.003229
   Number of active neurons: 10
 >> iter 231000, loss: 0.002011
 >> iter 232000, loss: 0.001554
 >> iter 233000, loss: 0.001484
 >> iter 234000, loss: 0.001562
 >> iter 235000, loss: 0.001396
 >> iter 236000, loss: 0.001283
 >> iter 237000, loss: 0.001243
 >> iter 238000, loss: 0.001197
 >> iter 239000, loss: 0.001188
 >> iter 240000, loss: 0.001164
   Number of active neurons: 10
 >> iter 241000, loss: 0.001200
 >> iter 242000, loss: 0.001224
 >> iter 243000, loss: 0.001165
 >> iter 244000, loss: 0.001257
 >> iter 245000, loss: 0.001141
 >> iter 246000, loss: 0.001090
 >> iter 247000, loss: 0.001036
 >> iter 248000, loss: 0.001142
 >> iter 249000, loss: 0.029607
 >> iter 250000, loss: 0.019092
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.803452
 >> iter 2000, loss: 15.284151
 >> iter 3000, loss: 13.884481
 >> iter 4000, loss: 13.359793
 >> iter 5000, loss: 13.142968
 >> iter 6000, loss: 13.057382
 >> iter 7000, loss: 13.021354
 >> iter 8000, loss: 13.014950
 >> iter 9000, loss: 13.011994
 >> iter 10000, loss: 13.009241
   Number of active neurons: 10
 >> iter 11000, loss: 12.996472
 >> iter 12000, loss: 13.003406
 >> iter 13000, loss: 12.995623
 >> iter 14000, loss: 13.005362
 >> iter 15000, loss: 12.994008
 >> iter 16000, loss: 12.997686
 >> iter 17000, loss: 12.995904
 >> iter 18000, loss: 12.995481
 >> iter 19000, loss: 12.994147
 >> iter 20000, loss: 13.008561
   Number of active neurons: 10
 >> iter 21000, loss: 12.999306
 >> iter 22000, loss: 13.013583
 >> iter 23000, loss: 12.996011
 >> iter 24000, loss: 13.008140
 >> iter 25000, loss: 12.994594
 >> iter 26000, loss: 12.996180
 >> iter 27000, loss: 12.990372
 >> iter 28000, loss: 12.991857
 >> iter 29000, loss: 12.990415
 >> iter 30000, loss: 12.999814
   Number of active neurons: 10
 >> iter 31000, loss: 12.987253
 >> iter 32000, loss: 12.990858
 >> iter 33000, loss: 12.987702
 >> iter 34000, loss: 12.985340
 >> iter 35000, loss: 12.964931
 >> iter 36000, loss: 12.934235
 >> iter 37000, loss: 12.832477
 >> iter 38000, loss: 12.527736
 >> iter 39000, loss: 11.838053
 >> iter 40000, loss: 10.355365
   Number of active neurons: 10
 >> iter 41000, loss: 6.380201
 >> iter 42000, loss: 2.953590
 >> iter 43000, loss: 1.415351
 >> iter 44000, loss: 0.758595
 >> iter 45000, loss: 0.337121
 >> iter 46000, loss: 0.430672
 >> iter 47000, loss: 0.280049
 >> iter 48000, loss: 0.192103
 >> iter 49000, loss: 0.283053
 >> iter 50000, loss: 0.221984
   Number of active neurons: 10
 >> iter 51000, loss: 0.107855
 >> iter 52000, loss: 0.053382
 >> iter 53000, loss: 0.181105
 >> iter 54000, loss: 0.133221
 >> iter 55000, loss: 0.097738
 >> iter 56000, loss: 0.136861
 >> iter 57000, loss: 0.060501
 >> iter 58000, loss: 0.030828
 >> iter 59000, loss: 0.153729
 >> iter 60000, loss: 0.111947
   Number of active neurons: 10
 >> iter 61000, loss: 0.179271
 >> iter 62000, loss: 0.095575
 >> iter 63000, loss: 0.076146
 >> iter 64000, loss: 0.035333
 >> iter 65000, loss: 0.019434
 >> iter 66000, loss: 0.091673
 >> iter 67000, loss: 0.096337
 >> iter 68000, loss: 0.055923
 >> iter 69000, loss: 0.155824
 >> iter 70000, loss: 0.064232
   Number of active neurons: 10
 >> iter 71000, loss: 0.084456
 >> iter 72000, loss: 0.037135
 >> iter 73000, loss: 0.018928
 >> iter 74000, loss: 0.011686
 >> iter 75000, loss: 0.008588
 >> iter 76000, loss: 0.007247
 >> iter 77000, loss: 0.083829
 >> iter 78000, loss: 0.056770
 >> iter 79000, loss: 0.043081
 >> iter 80000, loss: 0.022373
   Number of active neurons: 10
 >> iter 81000, loss: 0.095545
 >> iter 82000, loss: 0.040061
 >> iter 83000, loss: 0.019640
 >> iter 84000, loss: 0.010698
 >> iter 85000, loss: 0.007103
 >> iter 86000, loss: 0.005528
 >> iter 87000, loss: 0.004772
 >> iter 88000, loss: 0.065196
 >> iter 89000, loss: 0.042748
 >> iter 90000, loss: 0.023077
   Number of active neurons: 10
 >> iter 91000, loss: 0.010936
 >> iter 92000, loss: 0.024064
 >> iter 93000, loss: 0.014784
 >> iter 94000, loss: 0.007478
 >> iter 95000, loss: 0.022512
 >> iter 96000, loss: 0.011179
 >> iter 97000, loss: 0.006139
 >> iter 98000, loss: 0.032941
 >> iter 99000, loss: 0.014239
 >> iter 100000, loss: 0.007030
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 18.774615
 >> iter 2000, loss: 15.295139
 >> iter 3000, loss: 13.893071
 >> iter 4000, loss: 13.366543
 >> iter 5000, loss: 13.144731
 >> iter 6000, loss: 13.057366
 >> iter 7000, loss: 13.021294
 >> iter 8000, loss: 13.015768
 >> iter 9000, loss: 12.998115
 >> iter 10000, loss: 13.005667
   Number of active neurons: 8
 >> iter 11000, loss: 12.981864
 >> iter 12000, loss: 12.988404
 >> iter 13000, loss: 12.971759
 >> iter 14000, loss: 12.665779
 >> iter 15000, loss: 11.743529
 >> iter 16000, loss: 11.223839
 >> iter 17000, loss: 10.778520
 >> iter 18000, loss: 10.309244
 >> iter 19000, loss: 8.297480
 >> iter 20000, loss: 4.305788
   Number of active neurons: 10
 >> iter 21000, loss: 2.224019
 >> iter 22000, loss: 1.429092
 >> iter 23000, loss: 0.913664
 >> iter 24000, loss: 0.535240
 >> iter 25000, loss: 0.535125
 >> iter 26000, loss: 0.296402
 >> iter 27000, loss: 0.238485
 >> iter 28000, loss: 0.279911
 >> iter 29000, loss: 0.252494
 >> iter 30000, loss: 0.322606
   Number of active neurons: 10
 >> iter 31000, loss: 0.312237
 >> iter 32000, loss: 0.234270
 >> iter 33000, loss: 0.205332
 >> iter 34000, loss: 0.094450
 >> iter 35000, loss: 0.050651
 >> iter 36000, loss: 0.339870
 >> iter 37000, loss: 0.381617
 >> iter 38000, loss: 0.390036
 >> iter 39000, loss: 0.444724
 >> iter 40000, loss: 0.215824
   Number of active neurons: 10
 >> iter 41000, loss: 0.173960
 >> iter 42000, loss: 0.079432
 >> iter 43000, loss: 0.087104
 >> iter 44000, loss: 0.044031
 >> iter 45000, loss: 0.094392
 >> iter 46000, loss: 0.044717
 >> iter 47000, loss: 0.114891
 >> iter 48000, loss: 0.135462
 >> iter 49000, loss: 0.061429
 >> iter 50000, loss: 0.053846
   Number of active neurons: 10
 >> iter 51000, loss: 0.151536
 >> iter 52000, loss: 0.066725
 >> iter 53000, loss: 0.114195
 >> iter 54000, loss: 0.248906
 >> iter 55000, loss: 0.161834
 >> iter 56000, loss: 0.278461
 >> iter 57000, loss: 0.232269
 >> iter 58000, loss: 0.102647
 >> iter 59000, loss: 0.102410
 >> iter 60000, loss: 0.070999
   Number of active neurons: 10
 >> iter 61000, loss: 0.064922
 >> iter 62000, loss: 0.031656
 >> iter 63000, loss: 0.026709
 >> iter 64000, loss: 0.044559
 >> iter 65000, loss: 0.126018
 >> iter 66000, loss: 0.055468
 >> iter 67000, loss: 0.082500
 >> iter 68000, loss: 0.097344
 >> iter 69000, loss: 0.268220
 >> iter 70000, loss: 0.108554
   Number of active neurons: 10
 >> iter 71000, loss: 0.046530
 >> iter 72000, loss: 0.031129
 >> iter 73000, loss: 0.082934
 >> iter 74000, loss: 0.042341
 >> iter 75000, loss: 0.053176
 >> iter 76000, loss: 0.024853
 >> iter 77000, loss: 0.014323
 >> iter 78000, loss: 0.009739
 >> iter 79000, loss: 0.008141
 >> iter 80000, loss: 0.006991
   Number of active neurons: 10
 >> iter 81000, loss: 0.006348
 >> iter 82000, loss: 0.010265
 >> iter 83000, loss: 0.007763
 >> iter 84000, loss: 0.006592
 >> iter 85000, loss: 0.005778
 >> iter 86000, loss: 0.005575
 >> iter 87000, loss: 0.007791
 >> iter 88000, loss: 0.006132
 >> iter 89000, loss: 0.064892
 >> iter 90000, loss: 0.027093
   Number of active neurons: 10
 >> iter 91000, loss: 0.013061
 >> iter 92000, loss: 0.007445
 >> iter 93000, loss: 0.005291
 >> iter 94000, loss: 0.004854
 >> iter 95000, loss: 0.004254
 >> iter 96000, loss: 0.145952
 >> iter 97000, loss: 0.056388
 >> iter 98000, loss: 0.023332
 >> iter 99000, loss: 0.019582
 >> iter 100000, loss: 0.011958
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.761305
 >> iter 2000, loss: 15.234256
 >> iter 3000, loss: 13.856021
 >> iter 4000, loss: 13.326456
 >> iter 5000, loss: 13.107900
 >> iter 6000, loss: 13.047138
 >> iter 7000, loss: 13.000934
 >> iter 8000, loss: 12.993001
 >> iter 9000, loss: 12.976279
 >> iter 10000, loss: 12.982861
   Number of active neurons: 9
 >> iter 11000, loss: 12.967490
 >> iter 12000, loss: 12.971372
 >> iter 13000, loss: 12.959562
 >> iter 14000, loss: 12.964095
 >> iter 15000, loss: 12.952285
 >> iter 16000, loss: 12.844678
 >> iter 17000, loss: 11.878828
 >> iter 18000, loss: 11.276120
 >> iter 19000, loss: 10.763749
 >> iter 20000, loss: 10.251642
   Number of active neurons: 10
 >> iter 21000, loss: 9.493183
 >> iter 22000, loss: 9.076667
 >> iter 23000, loss: 8.540389
 >> iter 24000, loss: 7.912871
 >> iter 25000, loss: 9.804347
 >> iter 26000, loss: 10.101191
 >> iter 27000, loss: 9.082499
 >> iter 28000, loss: 7.896115
 >> iter 29000, loss: 6.892795
 >> iter 30000, loss: 5.997323
   Number of active neurons: 10
 >> iter 31000, loss: 5.110689
 >> iter 32000, loss: 4.760977
 >> iter 33000, loss: 4.595793
 >> iter 34000, loss: 4.669455
 >> iter 35000, loss: 4.790296
 >> iter 36000, loss: 4.426143
 >> iter 37000, loss: 3.906204
 >> iter 38000, loss: 3.639508
 >> iter 39000, loss: 3.614982
 >> iter 40000, loss: 3.621877
   Number of active neurons: 10
 >> iter 41000, loss: 3.093717
 >> iter 42000, loss: 3.625646
 >> iter 43000, loss: 3.123359
 >> iter 44000, loss: 3.117654
 >> iter 45000, loss: 3.063815
 >> iter 46000, loss: 3.433289
 >> iter 47000, loss: 3.071128
 >> iter 48000, loss: 3.298397
 >> iter 49000, loss: 2.970858
 >> iter 50000, loss: 3.123058
   Number of active neurons: 10
 >> iter 51000, loss: 2.918987
 >> iter 52000, loss: 3.585272
 >> iter 53000, loss: 3.892146
 >> iter 54000, loss: 3.464296
 >> iter 55000, loss: 3.206093
 >> iter 56000, loss: 3.071450
 >> iter 57000, loss: 2.716867
 >> iter 58000, loss: 2.924926
 >> iter 59000, loss: 2.785106
 >> iter 60000, loss: 3.213461
   Number of active neurons: 10
 >> iter 61000, loss: 2.768083
 >> iter 62000, loss: 3.267515
 >> iter 63000, loss: 2.690017
 >> iter 64000, loss: 3.174341
 >> iter 65000, loss: 2.915500
 >> iter 66000, loss: 2.978207
 >> iter 67000, loss: 2.433533
 >> iter 68000, loss: 2.303941
 >> iter 69000, loss: 2.334555
 >> iter 70000, loss: 2.448781
   Number of active neurons: 10
 >> iter 71000, loss: 2.298116
 >> iter 72000, loss: 3.037886
 >> iter 73000, loss: 3.669470
 >> iter 74000, loss: 3.780214
 >> iter 75000, loss: 3.236658
 >> iter 76000, loss: 3.314022
 >> iter 77000, loss: 3.167702
 >> iter 78000, loss: 2.784333
 >> iter 79000, loss: 2.291756
 >> iter 80000, loss: 2.422319
   Number of active neurons: 10
 >> iter 81000, loss: 2.865810
 >> iter 82000, loss: 2.619345
 >> iter 83000, loss: 2.424045
 >> iter 84000, loss: 2.625351
 >> iter 85000, loss: 2.722366
 >> iter 86000, loss: 2.469191
 >> iter 87000, loss: 2.137384
 >> iter 88000, loss: 2.688936
 >> iter 89000, loss: 3.273533
 >> iter 90000, loss: 3.037560
   Number of active neurons: 10
 >> iter 91000, loss: 2.436177
 >> iter 92000, loss: 3.305367
 >> iter 93000, loss: 3.040828
 >> iter 94000, loss: 2.920997
 >> iter 95000, loss: 2.509882
 >> iter 96000, loss: 2.414132
 >> iter 97000, loss: 2.427819
 >> iter 98000, loss: 2.790392
 >> iter 99000, loss: 2.552999
 >> iter 100000, loss: 2.452509
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 4.12791744165
   - Test - Long: 23.2488375581
   - Test - Big: 4.07795922041
   - Test - A: 0.753283114459
   - Test - B: 0.193320445304
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.694658
 >> iter 2000, loss: 15.206442
 >> iter 3000, loss: 13.855749
 >> iter 4000, loss: 13.329172
 >> iter 5000, loss: 13.112349
 >> iter 6000, loss: 13.035904
 >> iter 7000, loss: 12.998367
 >> iter 8000, loss: 12.984107
 >> iter 9000, loss: 12.964884
 >> iter 10000, loss: 12.963271
   Number of active neurons: 7
 >> iter 11000, loss: 12.435910
 >> iter 12000, loss: 11.664361
 >> iter 13000, loss: 11.062312
 >> iter 14000, loss: 10.707519
 >> iter 15000, loss: 10.340425
 >> iter 16000, loss: 10.120755
 >> iter 17000, loss: 9.832444
 >> iter 18000, loss: 9.708225
 >> iter 19000, loss: 9.459165
 >> iter 20000, loss: 9.248534
   Number of active neurons: 10
 >> iter 21000, loss: 8.893653
 >> iter 22000, loss: 8.721348
 >> iter 23000, loss: 8.531336
 >> iter 24000, loss: 8.394889
 >> iter 25000, loss: 7.641372
 >> iter 26000, loss: 8.369002
 >> iter 27000, loss: 5.796212
 >> iter 28000, loss: 3.534262
 >> iter 29000, loss: 2.786214
 >> iter 30000, loss: 1.377178
   Number of active neurons: 10
 >> iter 31000, loss: 0.935526
 >> iter 32000, loss: 0.477841
 >> iter 33000, loss: 0.574728
 >> iter 34000, loss: 0.455397
 >> iter 35000, loss: 0.323149
 >> iter 36000, loss: 0.210438
 >> iter 37000, loss: 0.169119
 >> iter 38000, loss: 0.149833
 >> iter 39000, loss: 0.210010
 >> iter 40000, loss: 0.098411
   Number of active neurons: 10
 >> iter 41000, loss: 0.374771
 >> iter 42000, loss: 0.373536
 >> iter 43000, loss: 0.195308
 >> iter 44000, loss: 0.220767
 >> iter 45000, loss: 0.300991
 >> iter 46000, loss: 0.163753
 >> iter 47000, loss: 0.108177
 >> iter 48000, loss: 0.111827
 >> iter 49000, loss: 0.556973
 >> iter 50000, loss: 0.307773
   Number of active neurons: 10
 >> iter 51000, loss: 0.215302
 >> iter 52000, loss: 0.118600
 >> iter 53000, loss: 0.059530
 >> iter 54000, loss: 0.036986
 >> iter 55000, loss: 0.047797
 >> iter 56000, loss: 0.054996
 >> iter 57000, loss: 0.031368
 >> iter 58000, loss: 0.022112
 >> iter 59000, loss: 0.017394
 >> iter 60000, loss: 0.017416
   Number of active neurons: 10
 >> iter 61000, loss: 0.014619
 >> iter 62000, loss: 0.012954
 >> iter 63000, loss: 0.012612
 >> iter 64000, loss: 0.013578
 >> iter 65000, loss: 0.011688
 >> iter 66000, loss: 0.069654
 >> iter 67000, loss: 0.042247
 >> iter 68000, loss: 0.025153
 >> iter 69000, loss: 0.019084
 >> iter 70000, loss: 0.098587
   Number of active neurons: 10
 >> iter 71000, loss: 0.047416
 >> iter 72000, loss: 0.024458
 >> iter 73000, loss: 0.052307
 >> iter 74000, loss: 0.089355
 >> iter 75000, loss: 0.039767
 >> iter 76000, loss: 0.020484
 >> iter 77000, loss: 0.013203
 >> iter 78000, loss: 0.038330
 >> iter 79000, loss: 0.019303
 >> iter 80000, loss: 0.012069
   Number of active neurons: 10
 >> iter 81000, loss: 0.074575
 >> iter 82000, loss: 0.032785
 >> iter 83000, loss: 0.021577
 >> iter 84000, loss: 0.012654
 >> iter 85000, loss: 0.008776
 >> iter 86000, loss: 0.008170
 >> iter 87000, loss: 0.007182
 >> iter 88000, loss: 0.011896
 >> iter 89000, loss: 0.008234
 >> iter 90000, loss: 0.007473
   Number of active neurons: 10
 >> iter 91000, loss: 0.006316
 >> iter 92000, loss: 0.009380
 >> iter 93000, loss: 0.061136
 >> iter 94000, loss: 0.026352
 >> iter 95000, loss: 0.129524
 >> iter 96000, loss: 0.051355
 >> iter 97000, loss: 0.160998
 >> iter 98000, loss: 0.063804
 >> iter 99000, loss: 0.054306
 >> iter 100000, loss: 0.024613
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.748974
 >> iter 2000, loss: 15.237497
 >> iter 3000, loss: 13.868397
 >> iter 4000, loss: 13.334254
 >> iter 5000, loss: 13.124525
 >> iter 6000, loss: 13.041363
 >> iter 7000, loss: 12.997464
 >> iter 8000, loss: 12.988726
 >> iter 9000, loss: 12.969981
 >> iter 10000, loss: 12.980441
   Number of active neurons: 10
 >> iter 11000, loss: 12.966678
 >> iter 12000, loss: 12.974488
 >> iter 13000, loss: 12.961947
 >> iter 14000, loss: 12.967729
 >> iter 15000, loss: 12.959413
 >> iter 16000, loss: 12.960656
 >> iter 17000, loss: 12.962410
 >> iter 18000, loss: 12.967567
 >> iter 19000, loss: 12.961592
 >> iter 20000, loss: 12.968236
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 21000, loss: 12.964408
 >> iter 22000, loss: 12.970005
 >> iter 23000, loss: 12.957825
 >> iter 24000, loss: 12.970480
 >> iter 25000, loss: 12.955730
 >> iter 26000, loss: 12.964770
 >> iter 27000, loss: 12.955838
 >> iter 28000, loss: 12.971837
 >> iter 29000, loss: 12.953458
 >> iter 30000, loss: 12.966633
   Number of active neurons: 8
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 8
 >> iter 31000, loss: 12.953340
 >> iter 32000, loss: 12.963686
 >> iter 33000, loss: 12.956948
 >> iter 34000, loss: 12.969844
 >> iter 35000, loss: 12.956889
 >> iter 36000, loss: 12.970031
 >> iter 37000, loss: 12.959715
 >> iter 38000, loss: 12.955420
 >> iter 39000, loss: 12.745348
 >> iter 40000, loss: 11.894970
   Number of active neurons: 10
 >> iter 41000, loss: 9.537711
 >> iter 42000, loss: 6.540661
 >> iter 43000, loss: 3.527926
 >> iter 44000, loss: 1.731425
 >> iter 45000, loss: 1.554462
 >> iter 46000, loss: 1.126395
 >> iter 47000, loss: 0.710507
 >> iter 48000, loss: 0.397621
 >> iter 49000, loss: 0.355584
 >> iter 50000, loss: 0.162410
   Number of active neurons: 10
 >> iter 51000, loss: 0.149007
 >> iter 52000, loss: 0.116520
 >> iter 53000, loss: 0.102990
 >> iter 54000, loss: 0.089109
 >> iter 55000, loss: 0.051252
 >> iter 56000, loss: 0.037882
 >> iter 57000, loss: 0.043080
 >> iter 58000, loss: 0.054627
 >> iter 59000, loss: 0.134941
 >> iter 60000, loss: 0.496471
   Number of active neurons: 10
 >> iter 61000, loss: 0.377889
 >> iter 62000, loss: 0.165713
 >> iter 63000, loss: 0.122312
 >> iter 64000, loss: 0.147812
 >> iter 65000, loss: 0.175980
 >> iter 66000, loss: 0.074340
 >> iter 67000, loss: 0.036555
 >> iter 68000, loss: 0.022951
 >> iter 69000, loss: 0.015989
 >> iter 70000, loss: 0.019790
   Number of active neurons: 10
 >> iter 71000, loss: 0.056006
 >> iter 72000, loss: 0.068730
 >> iter 73000, loss: 0.031283
 >> iter 74000, loss: 0.068833
 >> iter 75000, loss: 0.030553
 >> iter 76000, loss: 0.042766
 >> iter 77000, loss: 0.021160
 >> iter 78000, loss: 0.038783
 >> iter 79000, loss: 0.018654
 >> iter 80000, loss: 0.010527
   Number of active neurons: 10
 >> iter 81000, loss: 0.078355
 >> iter 82000, loss: 0.033136
 >> iter 83000, loss: 0.030606
 >> iter 84000, loss: 0.015880
 >> iter 85000, loss: 0.027374
 >> iter 86000, loss: 0.092904
 >> iter 87000, loss: 0.073522
 >> iter 88000, loss: 0.047659
 >> iter 89000, loss: 0.056287
 >> iter 90000, loss: 0.053087
   Number of active neurons: 10
 >> iter 91000, loss: 0.064604
 >> iter 92000, loss: 0.133483
 >> iter 93000, loss: 0.054989
 >> iter 94000, loss: 0.024223
 >> iter 95000, loss: 0.012444
 >> iter 96000, loss: 0.017369
 >> iter 97000, loss: 0.009690
 >> iter 98000, loss: 0.006462
 >> iter 99000, loss: 0.064203
 >> iter 100000, loss: 0.027266
   Number of active neurons: 10
 >> iter 101000, loss: 0.013335
 >> iter 102000, loss: 0.055512
 >> iter 103000, loss: 0.023790
 >> iter 104000, loss: 0.012154
 >> iter 105000, loss: 0.007232
 >> iter 106000, loss: 0.005875
 >> iter 107000, loss: 0.025688
 >> iter 108000, loss: 0.012169
 >> iter 109000, loss: 0.044464
 >> iter 110000, loss: 0.018873
   Number of active neurons: 10
 >> iter 111000, loss: 0.124261
 >> iter 112000, loss: 0.048651
 >> iter 113000, loss: 0.023075
 >> iter 114000, loss: 0.011046
 >> iter 115000, loss: 0.007177
 >> iter 116000, loss: 0.040199
 >> iter 117000, loss: 0.023090
 >> iter 118000, loss: 0.106145
 >> iter 119000, loss: 0.075863
 >> iter 120000, loss: 0.030590
   Number of active neurons: 10
 >> iter 121000, loss: 0.013801
 >> iter 122000, loss: 0.007699
 >> iter 123000, loss: 0.010509
 >> iter 124000, loss: 0.006031
 >> iter 125000, loss: 0.004326
 >> iter 126000, loss: 0.003968
 >> iter 127000, loss: 0.006809
 >> iter 128000, loss: 0.004607
 >> iter 129000, loss: 0.004032
 >> iter 130000, loss: 0.003357
   Number of active neurons: 10
 >> iter 131000, loss: 0.090146
 >> iter 132000, loss: 0.048576
 >> iter 133000, loss: 0.021905
 >> iter 134000, loss: 0.010293
 >> iter 135000, loss: 0.005983
 >> iter 136000, loss: 0.004096
 >> iter 137000, loss: 0.104040
 >> iter 138000, loss: 0.097593
 >> iter 139000, loss: 0.090290
 >> iter 140000, loss: 0.068586
   Number of active neurons: 10
 >> iter 141000, loss: 0.059997
 >> iter 142000, loss: 0.027939
 >> iter 143000, loss: 0.013202
 >> iter 144000, loss: 0.006912
 >> iter 145000, loss: 0.004505
 >> iter 146000, loss: 0.331788
 >> iter 147000, loss: 0.125403
 >> iter 148000, loss: 0.048833
 >> iter 149000, loss: 0.020417
 >> iter 150000, loss: 0.012769
   Number of active neurons: 10
 >> iter 151000, loss: 0.006899
 >> iter 152000, loss: 0.004567
 >> iter 153000, loss: 0.008189
 >> iter 154000, loss: 0.004896
 >> iter 155000, loss: 0.003861
 >> iter 156000, loss: 0.003228
 >> iter 157000, loss: 0.003354
 >> iter 158000, loss: 0.002864
 >> iter 159000, loss: 0.002620
 >> iter 160000, loss: 0.002474
   Number of active neurons: 10
 >> iter 161000, loss: 0.002457
 >> iter 162000, loss: 0.002385
 >> iter 163000, loss: 0.002273
 >> iter 164000, loss: 0.002186
 >> iter 165000, loss: 0.005391
 >> iter 166000, loss: 0.006618
 >> iter 167000, loss: 0.004372
 >> iter 168000, loss: 0.002951
 >> iter 169000, loss: 0.002469
 >> iter 170000, loss: 0.002183
   Number of active neurons: 10
 >> iter 171000, loss: 0.004748
 >> iter 172000, loss: 0.003006
 >> iter 173000, loss: 0.002627
 >> iter 174000, loss: 0.002123
 >> iter 175000, loss: 0.001947
 >> iter 176000, loss: 0.001804
 >> iter 177000, loss: 0.001698
 >> iter 178000, loss: 0.003081
 >> iter 179000, loss: 0.007674
 >> iter 180000, loss: 0.004228
   Number of active neurons: 10
 >> iter 181000, loss: 0.003397
 >> iter 182000, loss: 0.002501
 >> iter 183000, loss: 0.002056
 >> iter 184000, loss: 0.001737
 >> iter 185000, loss: 0.001594
 >> iter 186000, loss: 0.001493
 >> iter 187000, loss: 0.001430
 >> iter 188000, loss: 0.027403
 >> iter 189000, loss: 0.011168
 >> iter 190000, loss: 0.005227
   Number of active neurons: 10
 >> iter 191000, loss: 0.002847
 >> iter 192000, loss: 0.002006
 >> iter 193000, loss: 0.001630
 >> iter 194000, loss: 0.001491
 >> iter 195000, loss: 0.001416
 >> iter 196000, loss: 0.001588
 >> iter 197000, loss: 0.075489
 >> iter 198000, loss: 0.028948
 >> iter 199000, loss: 0.011712
 >> iter 200000, loss: 0.005375
   Number of active neurons: 10
 >> iter 201000, loss: 0.002930
 >> iter 202000, loss: 0.008000
 >> iter 203000, loss: 0.003897
 >> iter 204000, loss: 0.191105
 >> iter 205000, loss: 0.071922
 >> iter 206000, loss: 0.058997
 >> iter 207000, loss: 0.023253
 >> iter 208000, loss: 0.010049
 >> iter 209000, loss: 0.004885
 >> iter 210000, loss: 0.002985
   Number of active neurons: 10
 >> iter 211000, loss: 0.002296
 >> iter 212000, loss: 0.001973
 >> iter 213000, loss: 0.001818
 >> iter 214000, loss: 0.001736
 >> iter 215000, loss: 0.002289
 >> iter 216000, loss: 0.001776
 >> iter 217000, loss: 0.001542
 >> iter 218000, loss: 0.001452
 >> iter 219000, loss: 0.001407
 >> iter 220000, loss: 0.001452
   Number of active neurons: 10
 >> iter 221000, loss: 0.001381
 >> iter 222000, loss: 0.001450
 >> iter 223000, loss: 0.001366
 >> iter 224000, loss: 0.001306
 >> iter 225000, loss: 0.001250
 >> iter 226000, loss: 0.001317
 >> iter 227000, loss: 0.001220
 >> iter 228000, loss: 0.023911
 >> iter 229000, loss: 0.027041
 >> iter 230000, loss: 0.011019
   Number of active neurons: 10
 >> iter 231000, loss: 0.005113
 >> iter 232000, loss: 0.002755
 >> iter 233000, loss: 0.001988
 >> iter 234000, loss: 0.001595
 >> iter 235000, loss: 0.001375
 >> iter 236000, loss: 0.001256
 >> iter 237000, loss: 0.001206
 >> iter 238000, loss: 0.001244
 >> iter 239000, loss: 0.001390
 >> iter 240000, loss: 0.001269
   Number of active neurons: 10
 >> iter 241000, loss: 0.001622
 >> iter 242000, loss: 0.001307
 >> iter 243000, loss: 0.001285
 >> iter 244000, loss: 0.001170
 >> iter 245000, loss: 0.085432
 >> iter 246000, loss: 0.032464
 >> iter 247000, loss: 0.012932
 >> iter 248000, loss: 0.005613
 >> iter 249000, loss: 0.002968
 >> iter 250000, loss: 0.001954
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.754149
 >> iter 2000, loss: 15.237404
 >> iter 3000, loss: 13.851140
 >> iter 4000, loss: 13.342732
 >> iter 5000, loss: 13.136538
 >> iter 6000, loss: 13.061733
 >> iter 7000, loss: 13.019609
 >> iter 8000, loss: 13.013554
 >> iter 9000, loss: 13.005077
 >> iter 10000, loss: 13.007485
   Number of active neurons: 10
 >> iter 11000, loss: 12.982184
 >> iter 12000, loss: 13.000069
 >> iter 13000, loss: 12.990021
 >> iter 14000, loss: 12.993318
 >> iter 15000, loss: 12.990466
 >> iter 16000, loss: 12.991845
 >> iter 17000, loss: 12.982976
 >> iter 18000, loss: 12.985271
 >> iter 19000, loss: 12.984536
 >> iter 20000, loss: 12.989892
   Number of active neurons: 10
 >> iter 21000, loss: 12.974239
 >> iter 22000, loss: 12.983167
 >> iter 23000, loss: 12.979754
 >> iter 24000, loss: 12.985870
 >> iter 25000, loss: 12.978118
 >> iter 26000, loss: 12.984700
 >> iter 27000, loss: 12.978576
 >> iter 28000, loss: 12.985260
 >> iter 29000, loss: 12.976695
 >> iter 30000, loss: 12.980794
   Number of active neurons: 10
 >> iter 31000, loss: 12.966914
 >> iter 32000, loss: 12.977745
 >> iter 33000, loss: 12.937145
 >> iter 34000, loss: 12.651030
 >> iter 35000, loss: 11.663171
 >> iter 36000, loss: 10.129173
 >> iter 37000, loss: 9.444362
 >> iter 38000, loss: 8.746956
 >> iter 39000, loss: 8.061071
 >> iter 40000, loss: 7.600981
   Number of active neurons: 10
 >> iter 41000, loss: 6.486397
 >> iter 42000, loss: 6.217014
 >> iter 43000, loss: 5.364925
 >> iter 44000, loss: 5.672337
 >> iter 45000, loss: 5.007727
 >> iter 46000, loss: 5.035557
 >> iter 47000, loss: 4.812688
 >> iter 48000, loss: 4.764981
 >> iter 49000, loss: 4.798151
 >> iter 50000, loss: 5.317685
   Number of active neurons: 10
 >> iter 51000, loss: 4.952746
 >> iter 52000, loss: 4.874552
 >> iter 53000, loss: 4.569653
 >> iter 54000, loss: 4.671722
 >> iter 55000, loss: 4.449363
 >> iter 56000, loss: 4.422082
 >> iter 57000, loss: 4.359771
 >> iter 58000, loss: 4.640272
 >> iter 59000, loss: 4.613195
 >> iter 60000, loss: 4.552264
   Number of active neurons: 10
 >> iter 61000, loss: 4.479610
 >> iter 62000, loss: 4.361094
 >> iter 63000, loss: 3.964934
 >> iter 64000, loss: 4.124488
 >> iter 65000, loss: 3.920155
 >> iter 66000, loss: 4.007570
 >> iter 67000, loss: 3.801375
 >> iter 68000, loss: 4.074137
 >> iter 69000, loss: 4.014309
 >> iter 70000, loss: 4.089116
   Number of active neurons: 10
 >> iter 71000, loss: 3.817307
 >> iter 72000, loss: 4.078033
 >> iter 73000, loss: 3.627210
 >> iter 74000, loss: 3.682773
 >> iter 75000, loss: 3.543946
 >> iter 76000, loss: 3.501900
 >> iter 77000, loss: 3.334940
 >> iter 78000, loss: 3.336420
 >> iter 79000, loss: 3.216166
 >> iter 80000, loss: 3.543421
   Number of active neurons: 10
 >> iter 81000, loss: 3.338036
 >> iter 82000, loss: 3.442685
 >> iter 83000, loss: 3.433510
 >> iter 84000, loss: 3.378748
 >> iter 85000, loss: 3.133227
 >> iter 86000, loss: 3.391039
 >> iter 87000, loss: 3.159822
 >> iter 88000, loss: 3.432025
 >> iter 89000, loss: 3.287348
 >> iter 90000, loss: 3.423691
   Number of active neurons: 10
 >> iter 91000, loss: 3.229472
 >> iter 92000, loss: 3.424839
 >> iter 93000, loss: 3.214108
 >> iter 94000, loss: 3.295073
 >> iter 95000, loss: 3.116267
 >> iter 96000, loss: 3.285305
 >> iter 97000, loss: 3.109051
 >> iter 98000, loss: 3.347670
 >> iter 99000, loss: 3.192615
 >> iter 100000, loss: 3.464029
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 5.96388072239
   - Test - Long: 25.4737263137
   - Test - Big: 6.0149398506
   - Test - A: 31.3779081395
   - Test - B: 31.5912272515
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.793343
 >> iter 2000, loss: 15.238210
 >> iter 3000, loss: 13.846069
 >> iter 4000, loss: 13.319203
 >> iter 5000, loss: 13.120453
 >> iter 6000, loss: 13.045145
 >> iter 7000, loss: 13.014148
 >> iter 8000, loss: 12.998640
 >> iter 9000, loss: 12.993618
 >> iter 10000, loss: 12.997142
   Number of active neurons: 10
 >> iter 11000, loss: 12.987638
 >> iter 12000, loss: 12.990383
 >> iter 13000, loss: 12.976030
 >> iter 14000, loss: 12.984067
 >> iter 15000, loss: 12.975586
 >> iter 16000, loss: 12.975830
 >> iter 17000, loss: 12.976607
 >> iter 18000, loss: 12.987160
 >> iter 19000, loss: 12.973155
 >> iter 20000, loss: 12.987202
   Number of active neurons: 10
 >> iter 21000, loss: 12.973688
 >> iter 22000, loss: 12.979249
 >> iter 23000, loss: 12.977997
 >> iter 24000, loss: 12.988836
 >> iter 25000, loss: 12.974095
 >> iter 26000, loss: 12.974484
 >> iter 27000, loss: 12.972732
 >> iter 28000, loss: 12.981453
 >> iter 29000, loss: 12.967859
 >> iter 30000, loss: 12.796082
   Number of active neurons: 10
 >> iter 31000, loss: 12.028517
 >> iter 32000, loss: 7.547249
 >> iter 33000, loss: 2.999603
 >> iter 34000, loss: 1.175064
 >> iter 35000, loss: 0.586778
 >> iter 36000, loss: 0.349494
 >> iter 37000, loss: 0.157345
 >> iter 38000, loss: 0.104906
 >> iter 39000, loss: 0.057544
 >> iter 40000, loss: 0.037452
   Number of active neurons: 10
 >> iter 41000, loss: 0.068804
 >> iter 42000, loss: 0.152201
 >> iter 43000, loss: 0.068208
 >> iter 44000, loss: 0.129935
 >> iter 45000, loss: 0.060345
 >> iter 46000, loss: 0.033011
 >> iter 47000, loss: 0.021066
 >> iter 48000, loss: 0.015849
 >> iter 49000, loss: 0.013160
 >> iter 50000, loss: 0.011670
   Number of active neurons: 10
 >> iter 51000, loss: 0.010694
 >> iter 52000, loss: 0.009995
 >> iter 53000, loss: 0.009478
 >> iter 54000, loss: 0.009016
 >> iter 55000, loss: 0.008543
 >> iter 56000, loss: 0.008670
 >> iter 57000, loss: 0.016150
 >> iter 58000, loss: 0.010544
 >> iter 59000, loss: 0.025206
 >> iter 60000, loss: 0.013571
   Number of active neurons: 10
 >> iter 61000, loss: 0.009394
 >> iter 62000, loss: 0.007398
 >> iter 63000, loss: 0.016597
 >> iter 64000, loss: 0.009703
 >> iter 65000, loss: 0.007115
 >> iter 66000, loss: 0.005917
 >> iter 67000, loss: 0.005532
 >> iter 68000, loss: 0.005962
 >> iter 69000, loss: 0.006396
 >> iter 70000, loss: 0.005614
   Number of active neurons: 10
 >> iter 71000, loss: 0.004992
 >> iter 72000, loss: 0.005046
 >> iter 73000, loss: 0.004512
 >> iter 74000, loss: 0.004409
 >> iter 75000, loss: 0.004729
 >> iter 76000, loss: 0.004298
 >> iter 77000, loss: 0.004568
 >> iter 78000, loss: 0.004111
 >> iter 79000, loss: 0.003880
 >> iter 80000, loss: 0.003642
   Number of active neurons: 10
 >> iter 81000, loss: 0.003659
 >> iter 82000, loss: 0.003486
 >> iter 83000, loss: 0.003540
 >> iter 84000, loss: 0.003306
 >> iter 85000, loss: 0.004518
 >> iter 86000, loss: 0.003782
 >> iter 87000, loss: 0.003383
 >> iter 88000, loss: 0.003144
 >> iter 89000, loss: 0.003003
 >> iter 90000, loss: 0.002973
   Number of active neurons: 10
 >> iter 91000, loss: 0.002882
 >> iter 92000, loss: 0.003071
 >> iter 93000, loss: 0.002947
 >> iter 94000, loss: 0.002784
 >> iter 95000, loss: 0.002730
 >> iter 96000, loss: 0.002650
 >> iter 97000, loss: 0.002601
 >> iter 98000, loss: 0.002695
 >> iter 99000, loss: 0.002570
 >> iter 100000, loss: 0.002610
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.722534
 >> iter 2000, loss: 15.193731
 >> iter 3000, loss: 13.844283
 >> iter 4000, loss: 13.324144
 >> iter 5000, loss: 13.096390
 >> iter 6000, loss: 13.014046
 >> iter 7000, loss: 12.974238
 >> iter 8000, loss: 12.964672
 >> iter 9000, loss: 12.957286
 >> iter 10000, loss: 12.955741
   Number of active neurons: 6
 >> iter 11000, loss: 12.946075
 >> iter 12000, loss: 12.944034
 >> iter 13000, loss: 12.934504
 >> iter 14000, loss: 12.942912
 >> iter 15000, loss: 12.929946
 >> iter 16000, loss: 12.940382
 >> iter 17000, loss: 12.937550
 >> iter 18000, loss: 12.932864
 >> iter 19000, loss: 12.923306
 >> iter 20000, loss: 12.936866
   Number of active neurons: 7
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 7
 >> iter 21000, loss: 12.928646
 >> iter 22000, loss: 12.936672
 >> iter 23000, loss: 12.923127
 >> iter 24000, loss: 12.937572
 >> iter 25000, loss: 12.928478
 >> iter 26000, loss: 12.937859
 >> iter 27000, loss: 12.926124
 >> iter 28000, loss: 12.941454
 >> iter 29000, loss: 12.923112
 >> iter 30000, loss: 12.939974
   Number of active neurons: 6
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 6
 >> iter 31000, loss: 12.923642
 >> iter 32000, loss: 12.934998
 >> iter 33000, loss: 12.927316
 >> iter 34000, loss: 12.934139
 >> iter 35000, loss: 12.921159
 >> iter 36000, loss: 12.928287
 >> iter 37000, loss: 12.922166
 >> iter 38000, loss: 12.934665
 >> iter 39000, loss: 12.925713
 >> iter 40000, loss: 12.942195
   Number of active neurons: 6
   SHOCK
   Setting new limit to 275000.0 iters...
   Number of active neurons: 6
 >> iter 41000, loss: 12.924035
 >> iter 42000, loss: 12.935345
 >> iter 43000, loss: 12.916574
 >> iter 44000, loss: 12.936621
 >> iter 45000, loss: 12.921953
 >> iter 46000, loss: 12.940730
 >> iter 47000, loss: 12.914103
 >> iter 48000, loss: 12.936203
 >> iter 49000, loss: 12.920844
 >> iter 50000, loss: 12.940178
   Number of active neurons: 7
   SHOCK
   Setting new limit to 287500.0 iters...
   Number of active neurons: 7
 >> iter 51000, loss: 12.925732
 >> iter 52000, loss: 12.943612
 >> iter 53000, loss: 12.917815
 >> iter 54000, loss: 12.881466
 >> iter 55000, loss: 12.241850
 >> iter 56000, loss: 11.206210
 >> iter 57000, loss: 9.513404
 >> iter 58000, loss: 8.252702
 >> iter 59000, loss: 7.770004
 >> iter 60000, loss: 5.922305
   Number of active neurons: 10
 >> iter 61000, loss: 3.984912
 >> iter 62000, loss: 1.952406
 >> iter 63000, loss: 1.232510
 >> iter 64000, loss: 0.962708
 >> iter 65000, loss: 0.589293
 >> iter 66000, loss: 0.418175
 >> iter 67000, loss: 0.211191
 >> iter 68000, loss: 0.160540
 >> iter 69000, loss: 0.189460
 >> iter 70000, loss: 0.573720
   Number of active neurons: 10
 >> iter 71000, loss: 0.240447
 >> iter 72000, loss: 0.146983
 >> iter 73000, loss: 0.158111
 >> iter 74000, loss: 0.078916
 >> iter 75000, loss: 0.222872
 >> iter 76000, loss: 0.121921
 >> iter 77000, loss: 0.086727
 >> iter 78000, loss: 0.099594
 >> iter 79000, loss: 0.093369
 >> iter 80000, loss: 0.353416
   Number of active neurons: 10
 >> iter 81000, loss: 0.249811
 >> iter 82000, loss: 0.241002
 >> iter 83000, loss: 0.103161
 >> iter 84000, loss: 0.254105
 >> iter 85000, loss: 0.165490
 >> iter 86000, loss: 0.216503
 >> iter 87000, loss: 0.232043
 >> iter 88000, loss: 0.156651
 >> iter 89000, loss: 0.072269
 >> iter 90000, loss: 0.048761
   Number of active neurons: 10
 >> iter 91000, loss: 0.139740
 >> iter 92000, loss: 0.180871
 >> iter 93000, loss: 0.080899
 >> iter 94000, loss: 0.038515
 >> iter 95000, loss: 0.025392
 >> iter 96000, loss: 0.120286
 >> iter 97000, loss: 0.138437
 >> iter 98000, loss: 0.139278
 >> iter 99000, loss: 0.094765
 >> iter 100000, loss: 0.042424
   Number of active neurons: 10
 >> iter 101000, loss: 0.038848
 >> iter 102000, loss: 0.020427
 >> iter 103000, loss: 0.012986
 >> iter 104000, loss: 0.009706
 >> iter 105000, loss: 0.008088
 >> iter 106000, loss: 0.008768
 >> iter 107000, loss: 0.591692
 >> iter 108000, loss: 0.230222
 >> iter 109000, loss: 0.120158
 >> iter 110000, loss: 0.051584
   Number of active neurons: 10
 >> iter 111000, loss: 0.024952
 >> iter 112000, loss: 0.103915
 >> iter 113000, loss: 0.043930
 >> iter 114000, loss: 0.231750
 >> iter 115000, loss: 0.096080
 >> iter 116000, loss: 0.043650
 >> iter 117000, loss: 0.021067
 >> iter 118000, loss: 0.210578
 >> iter 119000, loss: 0.083621
 >> iter 120000, loss: 0.035948
   Number of active neurons: 10
 >> iter 121000, loss: 0.018061
 >> iter 122000, loss: 0.010850
 >> iter 123000, loss: 0.073685
 >> iter 124000, loss: 0.071587
 >> iter 125000, loss: 0.044239
 >> iter 126000, loss: 0.090662
 >> iter 127000, loss: 0.060256
 >> iter 128000, loss: 0.027894
 >> iter 129000, loss: 0.014496
 >> iter 130000, loss: 0.009257
   Number of active neurons: 10
 >> iter 131000, loss: 0.007019
 >> iter 132000, loss: 0.006315
 >> iter 133000, loss: 0.005638
 >> iter 134000, loss: 0.029961
 >> iter 135000, loss: 0.015474
 >> iter 136000, loss: 0.008831
 >> iter 137000, loss: 0.006523
 >> iter 138000, loss: 0.005242
 >> iter 139000, loss: 0.012436
 >> iter 140000, loss: 0.007767
   Number of active neurons: 10
 >> iter 141000, loss: 0.034610
 >> iter 142000, loss: 0.015355
 >> iter 143000, loss: 0.036809
 >> iter 144000, loss: 0.016271
 >> iter 145000, loss: 0.008542
 >> iter 146000, loss: 0.034801
 >> iter 147000, loss: 0.090067
 >> iter 148000, loss: 0.036488
 >> iter 149000, loss: 0.016070
 >> iter 150000, loss: 0.008446
   Number of active neurons: 10
 >> iter 151000, loss: 0.005424
 >> iter 152000, loss: 0.078256
 >> iter 153000, loss: 0.032031
 >> iter 154000, loss: 0.014426
 >> iter 155000, loss: 0.026290
 >> iter 156000, loss: 0.011926
 >> iter 157000, loss: 0.006635
 >> iter 158000, loss: 0.004687
 >> iter 159000, loss: 0.028194
 >> iter 160000, loss: 0.014830
   Number of active neurons: 10
 >> iter 161000, loss: 0.013702
 >> iter 162000, loss: 0.007161
 >> iter 163000, loss: 0.093936
 >> iter 164000, loss: 0.037314
 >> iter 165000, loss: 0.015926
 >> iter 166000, loss: 0.007854
 >> iter 167000, loss: 0.005293
 >> iter 168000, loss: 0.003908
 >> iter 169000, loss: 0.112090
 >> iter 170000, loss: 0.053747
   Number of active neurons: 10
 >> iter 171000, loss: 0.192464
 >> iter 172000, loss: 0.226959
 >> iter 173000, loss: 0.088245
 >> iter 174000, loss: 0.035987
 >> iter 175000, loss: 0.041723
 >> iter 176000, loss: 0.069591
 >> iter 177000, loss: 0.065259
 >> iter 178000, loss: 0.027198
 >> iter 179000, loss: 0.012925
 >> iter 180000, loss: 0.026652
   Number of active neurons: 10
 >> iter 181000, loss: 0.012701
 >> iter 182000, loss: 0.007459
 >> iter 183000, loss: 0.005207
 >> iter 184000, loss: 0.004280
 >> iter 185000, loss: 0.027892
 >> iter 186000, loss: 0.020156
 >> iter 187000, loss: 0.009759
 >> iter 188000, loss: 0.009516
 >> iter 189000, loss: 0.085031
 >> iter 190000, loss: 0.033816
   Number of active neurons: 10
 >> iter 191000, loss: 0.018525
 >> iter 192000, loss: 0.019134
 >> iter 193000, loss: 0.009473
 >> iter 194000, loss: 0.019673
 >> iter 195000, loss: 0.009497
 >> iter 196000, loss: 0.005592
 >> iter 197000, loss: 0.004017
 >> iter 198000, loss: 0.005710
 >> iter 199000, loss: 0.005217
 >> iter 200000, loss: 0.056166
   Number of active neurons: 10
 >> iter 201000, loss: 0.022542
 >> iter 202000, loss: 0.010117
 >> iter 203000, loss: 0.254255
 >> iter 204000, loss: 0.190260
 >> iter 205000, loss: 0.101172
 >> iter 206000, loss: 0.190749
 >> iter 207000, loss: 0.186713
 >> iter 208000, loss: 0.073132
 >> iter 209000, loss: 0.030405
 >> iter 210000, loss: 0.014309
   Number of active neurons: 10
 >> iter 211000, loss: 0.008345
 >> iter 212000, loss: 0.005698
 >> iter 213000, loss: 0.004662
 >> iter 214000, loss: 0.004117
 >> iter 215000, loss: 0.003963
 >> iter 216000, loss: 0.003622
 >> iter 217000, loss: 0.004595
 >> iter 218000, loss: 0.003824
 >> iter 219000, loss: 0.004960
 >> iter 220000, loss: 0.003796
   Number of active neurons: 10
 >> iter 221000, loss: 0.003368
 >> iter 222000, loss: 0.004352
 >> iter 223000, loss: 0.003429
 >> iter 224000, loss: 0.003022
 >> iter 225000, loss: 0.002853
 >> iter 226000, loss: 0.002693
 >> iter 227000, loss: 0.002581
 >> iter 228000, loss: 0.002485
 >> iter 229000, loss: 0.002428
 >> iter 230000, loss: 0.002368
   Number of active neurons: 10
 >> iter 231000, loss: 0.002296
 >> iter 232000, loss: 0.002366
 >> iter 233000, loss: 0.036528
 >> iter 234000, loss: 0.015155
 >> iter 235000, loss: 0.109134
 >> iter 236000, loss: 0.042254
 >> iter 237000, loss: 0.017418
 >> iter 238000, loss: 0.008426
 >> iter 239000, loss: 0.004920
 >> iter 240000, loss: 0.003455
   Number of active neurons: 10
 >> iter 241000, loss: 0.002957
 >> iter 242000, loss: 0.002552
 >> iter 243000, loss: 0.002357
 >> iter 244000, loss: 0.002270
 >> iter 245000, loss: 0.002200
 >> iter 246000, loss: 0.002161
 >> iter 247000, loss: 0.002080
 >> iter 248000, loss: 0.007523
 >> iter 249000, loss: 0.061507
 >> iter 250000, loss: 0.024529
   Number of active neurons: 10
 >> iter 251000, loss: 0.038347
 >> iter 252000, loss: 0.016256
 >> iter 253000, loss: 0.007526
 >> iter 254000, loss: 0.004193
 >> iter 255000, loss: 0.002917
 >> iter 256000, loss: 0.002375
 >> iter 257000, loss: 0.002150
 >> iter 258000, loss: 0.002029
 >> iter 259000, loss: 0.001954
 >> iter 260000, loss: 0.085768
   Number of active neurons: 10
 >> iter 261000, loss: 0.033066
 >> iter 262000, loss: 0.013521
 >> iter 263000, loss: 0.006336
 >> iter 264000, loss: 0.003545
 >> iter 265000, loss: 0.009844
 >> iter 266000, loss: 0.004814
 >> iter 267000, loss: 0.003058
 >> iter 268000, loss: 0.007181
 >> iter 269000, loss: 0.003717
 >> iter 270000, loss: 0.002396
   Number of active neurons: 10
 >> iter 271000, loss: 0.001894
 >> iter 272000, loss: 0.108787
 >> iter 273000, loss: 0.099768
 >> iter 274000, loss: 0.046197
 >> iter 275000, loss: 0.023273
 >> iter 276000, loss: 0.014279
 >> iter 277000, loss: 0.029899
 >> iter 278000, loss: 0.014010
 >> iter 279000, loss: 0.006805
 >> iter 280000, loss: 0.003856
   Number of active neurons: 10
 >> iter 281000, loss: 0.065462
 >> iter 282000, loss: 0.148352
 >> iter 283000, loss: 0.056423
 >> iter 284000, loss: 0.089018
 >> iter 285000, loss: 0.034869
 >> iter 286000, loss: 0.014599
 >> iter 287000, loss: 0.031401
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.743385
 >> iter 2000, loss: 15.246296
 >> iter 3000, loss: 13.857874
 >> iter 4000, loss: 13.329396
 >> iter 5000, loss: 13.121853
 >> iter 6000, loss: 13.047379
 >> iter 7000, loss: 13.014380
 >> iter 8000, loss: 13.000499
 >> iter 9000, loss: 12.989428
 >> iter 10000, loss: 12.989744
   Number of active neurons: 8
 >> iter 11000, loss: 12.980883
 >> iter 12000, loss: 12.987365
 >> iter 13000, loss: 12.978364
 >> iter 14000, loss: 12.983150
 >> iter 15000, loss: 12.975544
 >> iter 16000, loss: 12.980107
 >> iter 17000, loss: 12.982323
 >> iter 18000, loss: 12.982269
 >> iter 19000, loss: 12.970204
 >> iter 20000, loss: 12.981856
   Number of active neurons: 8
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 8
 >> iter 21000, loss: 12.969336
 >> iter 22000, loss: 12.982526
 >> iter 23000, loss: 12.976490
 >> iter 24000, loss: 12.970090
 >> iter 25000, loss: 12.602364
 >> iter 26000, loss: 12.067370
 >> iter 27000, loss: 10.966126
 >> iter 28000, loss: 9.065401
 >> iter 29000, loss: 7.106887
 >> iter 30000, loss: 6.474073
   Number of active neurons: 10
 >> iter 31000, loss: 5.401993
 >> iter 32000, loss: 4.968669
 >> iter 33000, loss: 4.528881
 >> iter 34000, loss: 4.313978
 >> iter 35000, loss: 3.975298
 >> iter 36000, loss: 4.235094
 >> iter 37000, loss: 3.687505
 >> iter 38000, loss: 3.721082
 >> iter 39000, loss: 3.799090
 >> iter 40000, loss: 3.775725
   Number of active neurons: 10
 >> iter 41000, loss: 3.779051
 >> iter 42000, loss: 3.916158
 >> iter 43000, loss: 3.492301
 >> iter 44000, loss: 3.380002
 >> iter 45000, loss: 2.896759
 >> iter 46000, loss: 2.950424
 >> iter 47000, loss: 2.846441
 >> iter 48000, loss: 3.039757
 >> iter 49000, loss: 2.538579
 >> iter 50000, loss: 2.511403
   Number of active neurons: 10
 >> iter 51000, loss: 2.530134
 >> iter 52000, loss: 2.557371
 >> iter 53000, loss: 2.157187
 >> iter 54000, loss: 2.254951
 >> iter 55000, loss: 2.122574
 >> iter 56000, loss: 2.478231
 >> iter 57000, loss: 2.175157
 >> iter 58000, loss: 2.283775
 >> iter 59000, loss: 2.150486
 >> iter 60000, loss: 2.204497
   Number of active neurons: 10
 >> iter 61000, loss: 2.729668
 >> iter 62000, loss: 2.406470
 >> iter 63000, loss: 2.198132
 >> iter 64000, loss: 2.302884
 >> iter 65000, loss: 2.373619
 >> iter 66000, loss: 2.203382
 >> iter 67000, loss: 1.963887
 >> iter 68000, loss: 2.092723
 >> iter 69000, loss: 1.977235
 >> iter 70000, loss: 2.108627
   Number of active neurons: 10
 >> iter 71000, loss: 1.925837
 >> iter 72000, loss: 2.024558
 >> iter 73000, loss: 2.040938
 >> iter 74000, loss: 2.229395
 >> iter 75000, loss: 1.997439
 >> iter 76000, loss: 3.326952
 >> iter 77000, loss: 2.917492
 >> iter 78000, loss: 2.177232
 >> iter 79000, loss: 1.859983
 >> iter 80000, loss: 1.147262
   Number of active neurons: 10
 >> iter 81000, loss: 0.570283
 >> iter 82000, loss: 0.292148
 >> iter 83000, loss: 0.230374
 >> iter 84000, loss: 0.529709
 >> iter 85000, loss: 0.492892
 >> iter 86000, loss: 0.391795
 >> iter 87000, loss: 0.244193
 >> iter 88000, loss: 0.187456
 >> iter 89000, loss: 0.099050
 >> iter 90000, loss: 0.202311
   Number of active neurons: 10
 >> iter 91000, loss: 0.109268
 >> iter 92000, loss: 0.208821
 >> iter 93000, loss: 0.164424
 >> iter 94000, loss: 0.106065
 >> iter 95000, loss: 0.790691
 >> iter 96000, loss: 0.866712
 >> iter 97000, loss: 0.408363
 >> iter 98000, loss: 0.330543
 >> iter 99000, loss: 0.222747
 >> iter 100000, loss: 0.152450
   Number of active neurons: 10
 >> iter 101000, loss: 0.187817
 >> iter 102000, loss: 0.169170
 >> iter 103000, loss: 0.260946
 >> iter 104000, loss: 0.116070
 >> iter 105000, loss: 0.163512
 >> iter 106000, loss: 0.156540
 >> iter 107000, loss: 0.149232
 >> iter 108000, loss: 0.161346
 >> iter 109000, loss: 0.179442
 >> iter 110000, loss: 0.114471
   Number of active neurons: 10
 >> iter 111000, loss: 0.351252
 >> iter 112000, loss: 0.234307
 >> iter 113000, loss: 0.140171
 >> iter 114000, loss: 0.132293
 >> iter 115000, loss: 0.058619
 >> iter 116000, loss: 0.112039
 >> iter 117000, loss: 0.056774
 >> iter 118000, loss: 0.028967
 >> iter 119000, loss: 0.196239
 >> iter 120000, loss: 0.098026
   Number of active neurons: 10
 >> iter 121000, loss: 0.121189
 >> iter 122000, loss: 0.052888
 >> iter 123000, loss: 0.083070
 >> iter 124000, loss: 0.045162
 >> iter 125000, loss: 0.245949
 >> iter 126000, loss: 0.115062
 >> iter 127000, loss: 0.304866
 >> iter 128000, loss: 0.126577
 >> iter 129000, loss: 0.089499
 >> iter 130000, loss: 0.136638
   Number of active neurons: 10
 >> iter 131000, loss: 0.310653
 >> iter 132000, loss: 0.280185
 >> iter 133000, loss: 0.163324
 >> iter 134000, loss: 0.117580
 >> iter 135000, loss: 0.051331
 >> iter 136000, loss: 0.043806
 >> iter 137000, loss: 0.022764
 >> iter 138000, loss: 0.015202
 >> iter 139000, loss: 0.029560
 >> iter 140000, loss: 0.016823
   Number of active neurons: 10
 >> iter 141000, loss: 0.014560
 >> iter 142000, loss: 0.034046
 >> iter 143000, loss: 0.873345
 >> iter 144000, loss: 0.415792
 >> iter 145000, loss: 0.169063
 >> iter 146000, loss: 0.070767
 >> iter 147000, loss: 0.159446
 >> iter 148000, loss: 0.158503
 >> iter 149000, loss: 0.195269
 >> iter 150000, loss: 0.123089
   Number of active neurons: 10
 >> iter 151000, loss: 0.093455
 >> iter 152000, loss: 0.071311
 >> iter 153000, loss: 0.072705
 >> iter 154000, loss: 0.039463
 >> iter 155000, loss: 0.034492
 >> iter 156000, loss: 0.019761
 >> iter 157000, loss: 0.013850
 >> iter 158000, loss: 0.013243
 >> iter 159000, loss: 0.047072
 >> iter 160000, loss: 0.066552
   Number of active neurons: 10
 >> iter 161000, loss: 0.084903
 >> iter 162000, loss: 0.080038
 >> iter 163000, loss: 0.035345
 >> iter 164000, loss: 0.223434
 >> iter 165000, loss: 0.127559
 >> iter 166000, loss: 0.158937
 >> iter 167000, loss: 0.064699
 >> iter 168000, loss: 0.059827
 >> iter 169000, loss: 0.039013
 >> iter 170000, loss: 0.060421
   Number of active neurons: 10
 >> iter 171000, loss: 0.027388
 >> iter 172000, loss: 0.014753
 >> iter 173000, loss: 0.116671
 >> iter 174000, loss: 0.196596
 >> iter 175000, loss: 0.177031
 >> iter 176000, loss: 0.071064
 >> iter 177000, loss: 0.095014
 >> iter 178000, loss: 0.040999
 >> iter 179000, loss: 0.020201
 >> iter 180000, loss: 0.013034
   Number of active neurons: 10
 >> iter 181000, loss: 0.009161
 >> iter 182000, loss: 0.108994
 >> iter 183000, loss: 0.045100
 >> iter 184000, loss: 0.037208
 >> iter 185000, loss: 0.028957
 >> iter 186000, loss: 0.041455
 >> iter 187000, loss: 0.026009
 >> iter 188000, loss: 0.019774
 >> iter 189000, loss: 0.024133
 >> iter 190000, loss: 0.025866
   Number of active neurons: 10
 >> iter 191000, loss: 0.013442
 >> iter 192000, loss: 0.041153
 >> iter 193000, loss: 0.018930
 >> iter 194000, loss: 0.010602
 >> iter 195000, loss: 0.007239
 >> iter 196000, loss: 0.005905
 >> iter 197000, loss: 0.005296
 >> iter 198000, loss: 0.004895
 >> iter 199000, loss: 0.005242
 >> iter 200000, loss: 0.004729
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.782644
 >> iter 2000, loss: 15.266775
 >> iter 3000, loss: 13.891490
 >> iter 4000, loss: 13.376440
 >> iter 5000, loss: 13.161930
 >> iter 6000, loss: 13.077998
 >> iter 7000, loss: 13.030952
 >> iter 8000, loss: 13.020413
 >> iter 9000, loss: 13.009517
 >> iter 10000, loss: 13.008713
   Number of active neurons: 9
 >> iter 11000, loss: 13.004104
 >> iter 12000, loss: 13.010783
 >> iter 13000, loss: 13.000469
 >> iter 14000, loss: 13.002175
 >> iter 15000, loss: 13.000446
 >> iter 16000, loss: 12.993598
 >> iter 17000, loss: 12.519681
 >> iter 18000, loss: 11.723437
 >> iter 19000, loss: 11.205953
 >> iter 20000, loss: 11.006436
   Number of active neurons: 10
 >> iter 21000, loss: 10.763149
 >> iter 22000, loss: 10.649622
 >> iter 23000, loss: 10.470947
 >> iter 24000, loss: 10.450316
 >> iter 25000, loss: 10.353240
 >> iter 26000, loss: 10.278982
 >> iter 27000, loss: 9.751717
 >> iter 28000, loss: 8.872229
 >> iter 29000, loss: 7.142043
 >> iter 30000, loss: 6.235005
   Number of active neurons: 10
 >> iter 31000, loss: 4.726806
 >> iter 32000, loss: 3.996797
 >> iter 33000, loss: 3.565636
 >> iter 34000, loss: 3.444360
 >> iter 35000, loss: 3.204413
 >> iter 36000, loss: 3.347476
 >> iter 37000, loss: 3.293434
 >> iter 38000, loss: 3.441126
 >> iter 39000, loss: 3.247890
 >> iter 40000, loss: 3.241274
   Number of active neurons: 10
 >> iter 41000, loss: 3.190684
 >> iter 42000, loss: 3.205933
 >> iter 43000, loss: 3.047125
 >> iter 44000, loss: 3.099956
 >> iter 45000, loss: 2.987485
 >> iter 46000, loss: 3.192075
 >> iter 47000, loss: 3.051278
 >> iter 48000, loss: 3.150454
 >> iter 49000, loss: 3.113008
 >> iter 50000, loss: 3.299398
   Number of active neurons: 10
 >> iter 51000, loss: 3.088006
 >> iter 52000, loss: 3.270077
 >> iter 53000, loss: 3.069890
 >> iter 54000, loss: 3.238044
 >> iter 55000, loss: 3.000536
 >> iter 56000, loss: 3.197440
 >> iter 57000, loss: 3.064520
 >> iter 58000, loss: 3.099154
 >> iter 59000, loss: 2.928251
 >> iter 60000, loss: 3.108895
   Number of active neurons: 10
 >> iter 61000, loss: 2.952429
 >> iter 62000, loss: 3.107560
 >> iter 63000, loss: 3.025099
 >> iter 64000, loss: 3.231514
 >> iter 65000, loss: 3.207210
 >> iter 66000, loss: 3.326209
 >> iter 67000, loss: 3.071607
 >> iter 68000, loss: 3.268611
 >> iter 69000, loss: 3.186517
 >> iter 70000, loss: 3.144252
   Number of active neurons: 10
 >> iter 71000, loss: 3.008047
 >> iter 72000, loss: 3.170726
 >> iter 73000, loss: 3.191546
 >> iter 74000, loss: 3.118896
 >> iter 75000, loss: 3.074913
 >> iter 76000, loss: 3.144697
 >> iter 77000, loss: 2.945274
 >> iter 78000, loss: 3.165959
 >> iter 79000, loss: 3.354505
 >> iter 80000, loss: 3.350636
   Number of active neurons: 10
 >> iter 81000, loss: 3.339223
 >> iter 82000, loss: 2.797087
 >> iter 83000, loss: 2.675704
 >> iter 84000, loss: 2.394615
 >> iter 85000, loss: 2.172947
 >> iter 86000, loss: 2.011766
 >> iter 87000, loss: 1.823293
 >> iter 88000, loss: 2.971070
 >> iter 89000, loss: 2.361734
 >> iter 90000, loss: 2.084172
   Number of active neurons: 10
 >> iter 91000, loss: 1.888888
 >> iter 92000, loss: 2.288520
 >> iter 93000, loss: 1.828162
 >> iter 94000, loss: 1.828183
 >> iter 95000, loss: 1.648443
 >> iter 96000, loss: 1.771398
 >> iter 97000, loss: 1.784662
 >> iter 98000, loss: 1.849202
 >> iter 99000, loss: 1.606828
 >> iter 100000, loss: 0.987814
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0489995100049
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.767377
 >> iter 2000, loss: 15.238049
 >> iter 3000, loss: 13.850334
 >> iter 4000, loss: 13.338888
 >> iter 5000, loss: 13.135575
 >> iter 6000, loss: 13.062354
 >> iter 7000, loss: 13.028848
 >> iter 8000, loss: 13.024203
 >> iter 9000, loss: 13.014497
 >> iter 10000, loss: 13.011114
   Number of active neurons: 9
 >> iter 11000, loss: 13.006658
 >> iter 12000, loss: 13.013200
 >> iter 13000, loss: 13.006085
 >> iter 14000, loss: 13.008137
 >> iter 15000, loss: 13.000513
 >> iter 16000, loss: 13.002739
 >> iter 17000, loss: 12.993702
 >> iter 18000, loss: 12.997788
 >> iter 19000, loss: 12.995443
 >> iter 20000, loss: 13.010011
   Number of active neurons: 8
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 8
 >> iter 21000, loss: 12.999553
 >> iter 22000, loss: 13.004164
 >> iter 23000, loss: 12.997507
 >> iter 24000, loss: 13.002582
 >> iter 25000, loss: 12.995791
 >> iter 26000, loss: 12.992652
 >> iter 27000, loss: 12.973307
 >> iter 28000, loss: 12.430747
 >> iter 29000, loss: 11.578583
 >> iter 30000, loss: 11.191288
   Number of active neurons: 10
 >> iter 31000, loss: 10.779775
 >> iter 32000, loss: 10.508307
 >> iter 33000, loss: 9.912217
 >> iter 34000, loss: 9.377331
 >> iter 35000, loss: 7.960586
 >> iter 36000, loss: 3.667414
 >> iter 37000, loss: 2.315557
 >> iter 38000, loss: 1.113755
 >> iter 39000, loss: 0.726154
 >> iter 40000, loss: 0.380662
   Number of active neurons: 10
 >> iter 41000, loss: 0.319316
 >> iter 42000, loss: 0.183052
 >> iter 43000, loss: 0.383197
 >> iter 44000, loss: 0.313258
 >> iter 45000, loss: 0.138474
 >> iter 46000, loss: 0.120540
 >> iter 47000, loss: 0.071593
 >> iter 48000, loss: 0.038577
 >> iter 49000, loss: 0.085304
 >> iter 50000, loss: 0.040727
   Number of active neurons: 10
 >> iter 51000, loss: 0.103312
 >> iter 52000, loss: 0.238233
 >> iter 53000, loss: 0.106521
 >> iter 54000, loss: 0.064944
 >> iter 55000, loss: 0.040882
 >> iter 56000, loss: 0.025576
 >> iter 57000, loss: 0.049897
 >> iter 58000, loss: 0.189323
 >> iter 59000, loss: 0.105651
 >> iter 60000, loss: 0.231696
   Number of active neurons: 10
 >> iter 61000, loss: 0.093986
 >> iter 62000, loss: 0.045773
 >> iter 63000, loss: 0.022597
 >> iter 64000, loss: 0.024999
 >> iter 65000, loss: 0.031544
 >> iter 66000, loss: 0.016331
 >> iter 67000, loss: 0.010625
 >> iter 68000, loss: 0.020531
 >> iter 69000, loss: 0.014814
 >> iter 70000, loss: 0.010244
   Number of active neurons: 10
 >> iter 71000, loss: 0.066140
 >> iter 72000, loss: 0.143052
 >> iter 73000, loss: 0.058250
 >> iter 74000, loss: 0.031454
 >> iter 75000, loss: 0.015428
 >> iter 76000, loss: 0.011773
 >> iter 77000, loss: 0.008080
 >> iter 78000, loss: 0.178361
 >> iter 79000, loss: 0.092163
 >> iter 80000, loss: 0.039248
   Number of active neurons: 10
 >> iter 81000, loss: 0.038442
 >> iter 82000, loss: 0.018027
 >> iter 83000, loss: 0.118622
 >> iter 84000, loss: 0.140073
 >> iter 85000, loss: 0.057122
 >> iter 86000, loss: 0.056935
 >> iter 87000, loss: 0.091278
 >> iter 88000, loss: 0.037642
 >> iter 89000, loss: 0.021603
 >> iter 90000, loss: 0.022542
   Number of active neurons: 10
 >> iter 91000, loss: 0.012460
 >> iter 92000, loss: 0.007514
 >> iter 93000, loss: 0.012192
 >> iter 94000, loss: 0.007708
 >> iter 95000, loss: 0.058198
 >> iter 96000, loss: 0.024642
 >> iter 97000, loss: 0.011992
 >> iter 98000, loss: 0.006970
 >> iter 99000, loss: 0.005299
 >> iter 100000, loss: 0.004230
   Number of active neurons: 10
 >> iter 101000, loss: 0.003873
 >> iter 102000, loss: 0.019383
 >> iter 103000, loss: 0.015767
 >> iter 104000, loss: 0.068675
 >> iter 105000, loss: 0.027721
 >> iter 106000, loss: 0.013725
 >> iter 107000, loss: 0.007834
 >> iter 108000, loss: 0.035297
 >> iter 109000, loss: 0.015109
 >> iter 110000, loss: 0.007736
   Number of active neurons: 10
 >> iter 111000, loss: 0.004871
 >> iter 112000, loss: 0.003719
 >> iter 113000, loss: 0.004324
 >> iter 114000, loss: 0.003883
 >> iter 115000, loss: 0.004111
 >> iter 116000, loss: 0.003718
 >> iter 117000, loss: 0.003441
 >> iter 118000, loss: 0.220159
 >> iter 119000, loss: 0.083817
 >> iter 120000, loss: 0.033407
   Number of active neurons: 10
 >> iter 121000, loss: 0.014468
 >> iter 122000, loss: 0.008161
 >> iter 123000, loss: 0.005253
 >> iter 124000, loss: 0.120508
 >> iter 125000, loss: 0.049920
 >> iter 126000, loss: 0.021741
 >> iter 127000, loss: 0.010139
 >> iter 128000, loss: 0.005652
 >> iter 129000, loss: 0.003850
 >> iter 130000, loss: 0.003253
   Number of active neurons: 10
 >> iter 131000, loss: 0.050408
 >> iter 132000, loss: 0.020624
 >> iter 133000, loss: 0.009514
 >> iter 134000, loss: 0.005253
 >> iter 135000, loss: 0.013666
 >> iter 136000, loss: 0.006738
 >> iter 137000, loss: 0.021940
 >> iter 138000, loss: 0.014420
 >> iter 139000, loss: 0.140735
 >> iter 140000, loss: 0.060770
   Number of active neurons: 10
 >> iter 141000, loss: 0.024412
 >> iter 142000, loss: 0.012106
 >> iter 143000, loss: 0.006187
 >> iter 144000, loss: 0.004001
 >> iter 145000, loss: 0.003394
 >> iter 146000, loss: 0.002970
 >> iter 147000, loss: 0.002587
 >> iter 148000, loss: 0.150629
 >> iter 149000, loss: 0.057675
 >> iter 150000, loss: 0.023388
   Number of active neurons: 10
 >> iter 151000, loss: 0.010224
 >> iter 152000, loss: 0.005279
 >> iter 153000, loss: 0.003344
 >> iter 154000, loss: 0.002642
 >> iter 155000, loss: 0.002384
 >> iter 156000, loss: 0.002194
 >> iter 157000, loss: 0.007099
 >> iter 158000, loss: 0.003861
 >> iter 159000, loss: 0.002652
 >> iter 160000, loss: 0.002152
   Number of active neurons: 10
 >> iter 161000, loss: 0.002087
 >> iter 162000, loss: 0.001877
 >> iter 163000, loss: 0.001869
 >> iter 164000, loss: 0.001778
 >> iter 165000, loss: 0.001711
 >> iter 166000, loss: 0.001642
 >> iter 167000, loss: 0.001579
 >> iter 168000, loss: 0.001623
 >> iter 169000, loss: 0.001537
 >> iter 170000, loss: 0.001481
   Number of active neurons: 10
 >> iter 171000, loss: 0.001423
 >> iter 172000, loss: 0.001404
 >> iter 173000, loss: 0.001365
 >> iter 174000, loss: 0.001368
 >> iter 175000, loss: 0.001941
 >> iter 176000, loss: 0.001644
 >> iter 177000, loss: 0.001438
 >> iter 178000, loss: 0.009247
 >> iter 179000, loss: 0.004205
 >> iter 180000, loss: 0.002496
   Number of active neurons: 10
 >> iter 181000, loss: 0.010600
 >> iter 182000, loss: 0.004864
 >> iter 183000, loss: 0.002764
 >> iter 184000, loss: 0.002055
 >> iter 185000, loss: 0.001585
 >> iter 186000, loss: 0.001414
 >> iter 187000, loss: 0.001275
 >> iter 188000, loss: 0.001256
 >> iter 189000, loss: 0.001966
 >> iter 190000, loss: 0.040224
   Number of active neurons: 10
 >> iter 191000, loss: 0.015763
 >> iter 192000, loss: 0.006697
 >> iter 193000, loss: 0.003292
 >> iter 194000, loss: 0.001971
 >> iter 195000, loss: 0.001476
 >> iter 196000, loss: 0.001290
 >> iter 197000, loss: 0.001181
 >> iter 198000, loss: 0.043819
 >> iter 199000, loss: 0.016893
 >> iter 200000, loss: 0.006980
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.773166
 >> iter 2000, loss: 15.192376
 >> iter 3000, loss: 13.815550
 >> iter 4000, loss: 13.308110
 >> iter 5000, loss: 13.100013
 >> iter 6000, loss: 13.024509
 >> iter 7000, loss: 12.991589
 >> iter 8000, loss: 12.981059
 >> iter 9000, loss: 12.965112
 >> iter 10000, loss: 12.967331
   Number of active neurons: 6
 >> iter 11000, loss: 12.965678
 >> iter 12000, loss: 12.973926
 >> iter 13000, loss: 12.961573
 >> iter 14000, loss: 12.963511
 >> iter 15000, loss: 12.964696
 >> iter 16000, loss: 12.966736
 >> iter 17000, loss: 12.959999
 >> iter 18000, loss: 12.969855
 >> iter 19000, loss: 12.953745
 >> iter 20000, loss: 12.964418
   Number of active neurons: 7
 >> iter 21000, loss: 12.955370
 >> iter 22000, loss: 12.964413
 >> iter 23000, loss: 12.953768
 >> iter 24000, loss: 12.955137
 >> iter 25000, loss: 12.952126
 >> iter 26000, loss: 12.970122
 >> iter 27000, loss: 12.953583
 >> iter 28000, loss: 12.963276
 >> iter 29000, loss: 12.957843
 >> iter 30000, loss: 12.966384
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 31000, loss: 12.954197
 >> iter 32000, loss: 12.965842
 >> iter 33000, loss: 12.956103
 >> iter 34000, loss: 12.961342
 >> iter 35000, loss: 12.954276
 >> iter 36000, loss: 12.964567
 >> iter 37000, loss: 12.953233
 >> iter 38000, loss: 12.964175
 >> iter 39000, loss: 12.949244
 >> iter 40000, loss: 12.964914
   Number of active neurons: 8
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 8
 >> iter 41000, loss: 12.952906
 >> iter 42000, loss: 12.962472
 >> iter 43000, loss: 12.948505
 >> iter 44000, loss: 12.966292
 >> iter 45000, loss: 12.947482
 >> iter 46000, loss: 12.964341
 >> iter 47000, loss: 12.949884
 >> iter 48000, loss: 12.964500
 >> iter 49000, loss: 12.947329
 >> iter 50000, loss: 12.965308
   Number of active neurons: 9
   SHOCK
   Setting new limit to 275000.0 iters...
   Number of active neurons: 9
 >> iter 51000, loss: 12.666802
 >> iter 52000, loss: 11.838078
 >> iter 53000, loss: 10.226065
 >> iter 54000, loss: 8.626618
 >> iter 55000, loss: 7.223019
 >> iter 56000, loss: 6.552514
 >> iter 57000, loss: 5.792961
 >> iter 58000, loss: 5.737065
 >> iter 59000, loss: 5.405961
 >> iter 60000, loss: 5.418595
   Number of active neurons: 10
 >> iter 61000, loss: 4.961702
 >> iter 62000, loss: 5.135522
 >> iter 63000, loss: 4.393820
 >> iter 64000, loss: 4.469075
 >> iter 65000, loss: 4.446594
 >> iter 66000, loss: 4.622784
 >> iter 67000, loss: 4.207900
 >> iter 68000, loss: 4.659807
 >> iter 69000, loss: 4.242468
 >> iter 70000, loss: 4.064367
   Number of active neurons: 10
 >> iter 71000, loss: 3.296410
 >> iter 72000, loss: 3.022801
 >> iter 73000, loss: 2.509359
 >> iter 74000, loss: 2.711005
 >> iter 75000, loss: 2.351545
 >> iter 76000, loss: 2.386582
 >> iter 77000, loss: 2.901388
 >> iter 78000, loss: 2.630554
 >> iter 79000, loss: 2.433692
 >> iter 80000, loss: 2.128035
   Number of active neurons: 10
 >> iter 81000, loss: 1.845432
 >> iter 82000, loss: 1.880371
 >> iter 83000, loss: 1.850402
 >> iter 84000, loss: 1.828032
 >> iter 85000, loss: 1.831490
 >> iter 86000, loss: 1.859932
 >> iter 87000, loss: 1.753763
 >> iter 88000, loss: 1.790816
 >> iter 89000, loss: 1.760017
 >> iter 90000, loss: 1.857694
   Number of active neurons: 10
 >> iter 91000, loss: 1.735570
 >> iter 92000, loss: 1.742338
 >> iter 93000, loss: 1.693122
 >> iter 94000, loss: 2.222756
 >> iter 95000, loss: 2.344357
 >> iter 96000, loss: 2.029563
 >> iter 97000, loss: 1.784635
 >> iter 98000, loss: 1.775959
 >> iter 99000, loss: 1.761982
 >> iter 100000, loss: 1.771276
   Number of active neurons: 10
 >> iter 101000, loss: 1.820241
 >> iter 102000, loss: 1.817552
 >> iter 103000, loss: 1.712884
 >> iter 104000, loss: 1.710211
 >> iter 105000, loss: 1.680421
 >> iter 106000, loss: 1.715695
 >> iter 107000, loss: 1.695644
 >> iter 108000, loss: 1.724619
 >> iter 109000, loss: 1.629787
 >> iter 110000, loss: 1.780882
   Number of active neurons: 10
 >> iter 111000, loss: 1.812101
 >> iter 112000, loss: 1.790785
 >> iter 113000, loss: 1.660676
 >> iter 114000, loss: 1.676946
 >> iter 115000, loss: 1.619014
 >> iter 116000, loss: 1.709462
 >> iter 117000, loss: 1.630969
 >> iter 118000, loss: 1.752088
 >> iter 119000, loss: 1.720216
 >> iter 120000, loss: 1.710605
   Number of active neurons: 10
 >> iter 121000, loss: 1.629347
 >> iter 122000, loss: 1.719870
 >> iter 123000, loss: 1.740711
 >> iter 124000, loss: 1.877754
 >> iter 125000, loss: 1.694476
 >> iter 126000, loss: 3.669206
 >> iter 127000, loss: 3.839688
 >> iter 128000, loss: 3.849782
 >> iter 129000, loss: 3.865792
 >> iter 130000, loss: 3.786467
   Number of active neurons: 10
 >> iter 131000, loss: 3.853646
 >> iter 132000, loss: 3.677350
 >> iter 133000, loss: 3.389761
 >> iter 134000, loss: 3.172238
 >> iter 135000, loss: 3.065482
 >> iter 136000, loss: 3.062597
 >> iter 137000, loss: 2.927170
 >> iter 138000, loss: 3.102227
 >> iter 139000, loss: 3.030805
 >> iter 140000, loss: 3.012433
   Number of active neurons: 10
 >> iter 141000, loss: 3.030814
 >> iter 142000, loss: 3.085527
 >> iter 143000, loss: 2.892870
 >> iter 144000, loss: 2.984761
 >> iter 145000, loss: 2.923668
 >> iter 146000, loss: 2.946425
 >> iter 147000, loss: 2.858052
 >> iter 148000, loss: 2.863933
 >> iter 149000, loss: 2.915446
 >> iter 150000, loss: 3.102246
   Number of active neurons: 10
 >> iter 151000, loss: 2.886483
 >> iter 152000, loss: 3.161080
 >> iter 153000, loss: 3.037635
 >> iter 154000, loss: 2.983668
 >> iter 155000, loss: 2.933078
 >> iter 156000, loss: 3.503434
 >> iter 157000, loss: 3.666512
 >> iter 158000, loss: 3.431766
 >> iter 159000, loss: 3.140749
 >> iter 160000, loss: 3.041788
   Number of active neurons: 10
 >> iter 161000, loss: 2.821167
 >> iter 162000, loss: 2.698913
 >> iter 163000, loss: 2.773916
 >> iter 164000, loss: 2.649999
 >> iter 165000, loss: 2.578518
 >> iter 166000, loss: 2.547707
 >> iter 167000, loss: 2.592140
 >> iter 168000, loss: 2.539638
 >> iter 169000, loss: 2.515273
 >> iter 170000, loss: 2.344430
   Number of active neurons: 10
 >> iter 171000, loss: 2.378488
 >> iter 172000, loss: 2.531444
 >> iter 173000, loss: 2.357309
 >> iter 174000, loss: 2.481714
 >> iter 175000, loss: 2.550280
 >> iter 176000, loss: 2.530860
 >> iter 177000, loss: 2.273091
 >> iter 178000, loss: 2.405962
 >> iter 179000, loss: 2.243950
 >> iter 180000, loss: 2.380294
   Number of active neurons: 10
 >> iter 181000, loss: 2.272301
 >> iter 182000, loss: 2.160924
 >> iter 183000, loss: 2.070158
 >> iter 184000, loss: 2.270399
 >> iter 185000, loss: 2.301931
 >> iter 186000, loss: 2.173551
 >> iter 187000, loss: 2.070522
 >> iter 188000, loss: 2.136390
 >> iter 189000, loss: 2.007660
 >> iter 190000, loss: 2.081988
   Number of active neurons: 10
 >> iter 191000, loss: 2.072053
 >> iter 192000, loss: 2.074052
 >> iter 193000, loss: 2.025319
 >> iter 194000, loss: 2.082250
 >> iter 195000, loss: 2.187998
 >> iter 196000, loss: 2.101490
 >> iter 197000, loss: 2.039200
 >> iter 198000, loss: 2.093685
 >> iter 199000, loss: 2.186903
 >> iter 200000, loss: 2.054283
   Number of active neurons: 10
 >> iter 201000, loss: 2.030442
 >> iter 202000, loss: 2.011451
 >> iter 203000, loss: 2.010903
 >> iter 204000, loss: 2.053737
 >> iter 205000, loss: 2.012186
 >> iter 206000, loss: 1.991585
 >> iter 207000, loss: 2.046220
 >> iter 208000, loss: 2.002674
 >> iter 209000, loss: 2.039796
 >> iter 210000, loss: 2.074761
   Number of active neurons: 10
 >> iter 211000, loss: 2.011782
 >> iter 212000, loss: 2.052157
 >> iter 213000, loss: 2.022188
 >> iter 214000, loss: 1.996269
 >> iter 215000, loss: 1.983681
 >> iter 216000, loss: 1.956955
 >> iter 217000, loss: 1.958466
 >> iter 218000, loss: 1.979363
 >> iter 219000, loss: 1.963718
 >> iter 220000, loss: 2.015925
   Number of active neurons: 10
 >> iter 221000, loss: 2.163777
 >> iter 222000, loss: 2.109749
 >> iter 223000, loss: 2.016549
 >> iter 224000, loss: 1.996907
 >> iter 225000, loss: 1.952388
 >> iter 226000, loss: 1.941837
 >> iter 227000, loss: 1.946459
 >> iter 228000, loss: 1.969470
 >> iter 229000, loss: 1.936817
 >> iter 230000, loss: 2.243154
   Number of active neurons: 10
 >> iter 231000, loss: 2.154005
 >> iter 232000, loss: 2.199010
 >> iter 233000, loss: 2.079890
 >> iter 234000, loss: 2.037340
 >> iter 235000, loss: 2.015484
 >> iter 236000, loss: 2.169824
 >> iter 237000, loss: 2.054701
 >> iter 238000, loss: 2.058488
 >> iter 239000, loss: 1.989441
 >> iter 240000, loss: 1.956619
   Number of active neurons: 10
 >> iter 241000, loss: 1.936745
 >> iter 242000, loss: 1.938313
 >> iter 243000, loss: 1.986968
 >> iter 244000, loss: 1.989758
 >> iter 245000, loss: 2.001242
 >> iter 246000, loss: 1.964225
 >> iter 247000, loss: 1.985007
 >> iter 248000, loss: 2.120258
 >> iter 249000, loss: 2.110492
 >> iter 250000, loss: 1.989247
   Number of active neurons: 10
 >> iter 251000, loss: 1.959912
 >> iter 252000, loss: 1.986396
 >> iter 253000, loss: 2.005961
 >> iter 254000, loss: 1.965567
 >> iter 255000, loss: 1.959511
 >> iter 256000, loss: 1.947244
 >> iter 257000, loss: 1.930786
 >> iter 258000, loss: 1.967536
 >> iter 259000, loss: 1.939387
 >> iter 260000, loss: 2.002724
   Number of active neurons: 10
 >> iter 261000, loss: 1.975189
 >> iter 262000, loss: 1.972752
 >> iter 263000, loss: 1.936883
 >> iter 264000, loss: 1.932086
 >> iter 265000, loss: 2.009650
 >> iter 266000, loss: 2.014658
 >> iter 267000, loss: 1.978070
 >> iter 268000, loss: 2.024993
 >> iter 269000, loss: 1.977337
 >> iter 270000, loss: 1.968459
   Number of active neurons: 10
 >> iter 271000, loss: 1.971131
 >> iter 272000, loss: 2.013723
 >> iter 273000, loss: 2.009607
 >> iter 274000, loss: 2.036208
 >> iter 275000, loss: 1.976720
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 3.89992200156
   - Test - Long: 22.9738513074
   - Test - Big: 3.75696243038
   - Test - A: 31.3779081395
   - Test - B: 7.88614092394
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.762639
 >> iter 2000, loss: 15.199443
 >> iter 3000, loss: 13.819227
 >> iter 4000, loss: 13.314530
 >> iter 5000, loss: 13.110892
 >> iter 6000, loss: 13.036075
 >> iter 7000, loss: 13.003599
 >> iter 8000, loss: 12.998279
 >> iter 9000, loss: 12.982695
 >> iter 10000, loss: 12.994867
   Number of active neurons: 8
 >> iter 11000, loss: 12.978629
 >> iter 12000, loss: 12.989509
 >> iter 13000, loss: 12.980564
 >> iter 14000, loss: 12.984031
 >> iter 15000, loss: 12.977021
 >> iter 16000, loss: 12.986773
 >> iter 17000, loss: 12.983147
 >> iter 18000, loss: 12.986566
 >> iter 19000, loss: 12.971401
 >> iter 20000, loss: 12.980882
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 21000, loss: 12.971331
 >> iter 22000, loss: 12.985523
 >> iter 23000, loss: 12.971004
 >> iter 24000, loss: 12.983607
 >> iter 25000, loss: 12.974086
 >> iter 26000, loss: 12.979190
 >> iter 27000, loss: 12.976129
 >> iter 28000, loss: 12.981821
 >> iter 29000, loss: 12.973214
 >> iter 30000, loss: 12.984201
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 9
 >> iter 31000, loss: 12.977936
 >> iter 32000, loss: 12.974639
 >> iter 33000, loss: 12.968154
 >> iter 34000, loss: 12.923727
 >> iter 35000, loss: 12.560243
 >> iter 36000, loss: 11.560580
 >> iter 37000, loss: 10.317313
 >> iter 38000, loss: 9.619650
 >> iter 39000, loss: 8.998534
 >> iter 40000, loss: 8.055689
   Number of active neurons: 10
 >> iter 41000, loss: 6.958058
 >> iter 42000, loss: 5.853597
 >> iter 43000, loss: 2.764299
 >> iter 44000, loss: 1.201028
 >> iter 45000, loss: 0.525418
 >> iter 46000, loss: 0.659925
 >> iter 47000, loss: 0.386293
 >> iter 48000, loss: 0.894871
 >> iter 49000, loss: 0.587558
 >> iter 50000, loss: 0.291081
   Number of active neurons: 10
 >> iter 51000, loss: 0.131604
 >> iter 52000, loss: 0.070793
 >> iter 53000, loss: 0.094133
 >> iter 54000, loss: 0.131899
 >> iter 55000, loss: 0.189797
 >> iter 56000, loss: 0.087991
 >> iter 57000, loss: 0.043807
 >> iter 58000, loss: 0.026188
 >> iter 59000, loss: 0.018678
 >> iter 60000, loss: 0.014741
   Number of active neurons: 10
 >> iter 61000, loss: 0.014055
 >> iter 62000, loss: 0.063151
 >> iter 63000, loss: 0.030152
 >> iter 64000, loss: 0.017870
 >> iter 65000, loss: 0.032779
 >> iter 66000, loss: 0.023686
 >> iter 67000, loss: 0.014073
 >> iter 68000, loss: 0.010358
 >> iter 69000, loss: 0.158057
 >> iter 70000, loss: 0.074804
   Number of active neurons: 10
 >> iter 71000, loss: 0.162782
 >> iter 72000, loss: 0.165004
 >> iter 73000, loss: 0.068704
 >> iter 74000, loss: 0.047573
 >> iter 75000, loss: 0.023142
 >> iter 76000, loss: 0.013536
 >> iter 77000, loss: 0.009507
 >> iter 78000, loss: 0.007776
 >> iter 79000, loss: 0.006983
 >> iter 80000, loss: 0.007306
   Number of active neurons: 10
 >> iter 81000, loss: 0.006569
 >> iter 82000, loss: 0.005830
 >> iter 83000, loss: 0.005614
 >> iter 84000, loss: 0.106046
 >> iter 85000, loss: 0.092900
 >> iter 86000, loss: 0.115888
 >> iter 87000, loss: 0.116900
 >> iter 88000, loss: 0.282635
 >> iter 89000, loss: 0.109765
 >> iter 90000, loss: 0.090704
   Number of active neurons: 10
 >> iter 91000, loss: 0.039833
 >> iter 92000, loss: 0.019133
 >> iter 93000, loss: 0.010681
 >> iter 94000, loss: 0.007534
 >> iter 95000, loss: 0.005840
 >> iter 96000, loss: 0.008610
 >> iter 97000, loss: 0.006328
 >> iter 98000, loss: 0.005155
 >> iter 99000, loss: 0.011481
 >> iter 100000, loss: 0.165804
   Number of active neurons: 10
 >> iter 101000, loss: 0.065152
 >> iter 102000, loss: 0.031639
 >> iter 103000, loss: 0.033261
 >> iter 104000, loss: 0.015722
 >> iter 105000, loss: 0.009153
 >> iter 106000, loss: 0.007346
 >> iter 107000, loss: 0.005589
 >> iter 108000, loss: 0.005080
 >> iter 109000, loss: 0.004314
 >> iter 110000, loss: 0.015731
   Number of active neurons: 10
 >> iter 111000, loss: 0.008416
 >> iter 112000, loss: 0.005518
 >> iter 113000, loss: 0.004184
 >> iter 114000, loss: 0.003735
 >> iter 115000, loss: 0.003402
 >> iter 116000, loss: 0.003355
 >> iter 117000, loss: 0.003119
 >> iter 118000, loss: 0.003115
 >> iter 119000, loss: 0.002929
 >> iter 120000, loss: 0.002770
   Number of active neurons: 10
 >> iter 121000, loss: 0.002909
 >> iter 122000, loss: 0.002714
 >> iter 123000, loss: 0.002552
 >> iter 124000, loss: 0.002493
 >> iter 125000, loss: 0.002737
 >> iter 126000, loss: 0.002502
 >> iter 127000, loss: 0.002355
 >> iter 128000, loss: 0.002364
 >> iter 129000, loss: 0.002237
 >> iter 130000, loss: 0.002202
   Number of active neurons: 10
 >> iter 131000, loss: 0.002168
 >> iter 132000, loss: 0.002276
 >> iter 133000, loss: 0.002107
 >> iter 134000, loss: 0.002231
 >> iter 135000, loss: 0.055892
 >> iter 136000, loss: 0.022758
 >> iter 137000, loss: 0.009813
 >> iter 138000, loss: 0.004975
 >> iter 139000, loss: 0.003415
 >> iter 140000, loss: 0.011390
   Number of active neurons: 10
 >> iter 141000, loss: 0.005798
 >> iter 142000, loss: 0.003498
 >> iter 143000, loss: 0.040381
 >> iter 144000, loss: 0.041052
 >> iter 145000, loss: 0.016736
 >> iter 146000, loss: 0.007577
 >> iter 147000, loss: 0.004178
 >> iter 148000, loss: 0.002829
 >> iter 149000, loss: 0.002447
 >> iter 150000, loss: 0.002143
   Number of active neurons: 10
 >> iter 151000, loss: 0.001997
 >> iter 152000, loss: 0.001967
 >> iter 153000, loss: 0.001839
 >> iter 154000, loss: 0.072415
 >> iter 155000, loss: 0.028269
 >> iter 156000, loss: 0.011703
 >> iter 157000, loss: 0.005614
 >> iter 158000, loss: 0.003328
 >> iter 159000, loss: 0.002360
 >> iter 160000, loss: 0.001995
   Number of active neurons: 10
 >> iter 161000, loss: 0.001889
 >> iter 162000, loss: 0.001909
 >> iter 163000, loss: 0.001932
 >> iter 164000, loss: 0.001815
 >> iter 165000, loss: 0.252113
 >> iter 166000, loss: 0.094491
 >> iter 167000, loss: 0.186264
 >> iter 168000, loss: 0.070857
 >> iter 169000, loss: 0.028033
 >> iter 170000, loss: 0.014474
   Number of active neurons: 10
 >> iter 171000, loss: 0.007892
 >> iter 172000, loss: 0.004525
 >> iter 173000, loss: 0.003251
 >> iter 174000, loss: 0.003889
 >> iter 175000, loss: 0.002898
 >> iter 176000, loss: 0.002441
 >> iter 177000, loss: 0.002225
 >> iter 178000, loss: 0.002291
 >> iter 179000, loss: 0.002071
 >> iter 180000, loss: 0.002027
   Number of active neurons: 10
 >> iter 181000, loss: 0.079763
 >> iter 182000, loss: 0.030897
 >> iter 183000, loss: 0.012871
 >> iter 184000, loss: 0.006114
 >> iter 185000, loss: 0.003645
 >> iter 186000, loss: 0.003976
 >> iter 187000, loss: 0.006090
 >> iter 188000, loss: 0.003667
 >> iter 189000, loss: 0.002613
 >> iter 190000, loss: 0.002217
   Number of active neurons: 10
 >> iter 191000, loss: 0.002428
 >> iter 192000, loss: 0.002108
 >> iter 193000, loss: 0.001905
 >> iter 194000, loss: 0.001808
 >> iter 195000, loss: 0.001764
 >> iter 196000, loss: 0.001725
 >> iter 197000, loss: 0.001692
 >> iter 198000, loss: 0.001655
 >> iter 199000, loss: 0.001604
 >> iter 200000, loss: 0.001658
   Number of active neurons: 10
 >> iter 201000, loss: 0.001645
 >> iter 202000, loss: 0.001579
 >> iter 203000, loss: 0.002332
 >> iter 204000, loss: 0.001925
 >> iter 205000, loss: 0.002669
 >> iter 206000, loss: 0.002024
 >> iter 207000, loss: 0.001761
 >> iter 208000, loss: 0.001594
 >> iter 209000, loss: 0.001531
 >> iter 210000, loss: 0.001467
   Number of active neurons: 10
 >> iter 211000, loss: 0.004713
 >> iter 212000, loss: 0.002615
 >> iter 213000, loss: 0.001958
 >> iter 214000, loss: 0.001574
 >> iter 215000, loss: 0.001416
 >> iter 216000, loss: 0.001316
 >> iter 217000, loss: 0.011126
 >> iter 218000, loss: 0.177550
 >> iter 219000, loss: 0.066722
 >> iter 220000, loss: 0.037611
   Number of active neurons: 10
 >> iter 221000, loss: 0.030082
 >> iter 222000, loss: 0.012595
 >> iter 223000, loss: 0.006062
 >> iter 224000, loss: 0.003486
 >> iter 225000, loss: 0.002534
 >> iter 226000, loss: 0.002148
 >> iter 227000, loss: 0.001981
 >> iter 228000, loss: 0.195360
 >> iter 229000, loss: 0.077946
 >> iter 230000, loss: 0.030161
   Number of active neurons: 10
 >> iter 231000, loss: 0.012510
 >> iter 232000, loss: 0.107706
 >> iter 233000, loss: 0.041267
 >> iter 234000, loss: 0.017027
 >> iter 235000, loss: 0.007839
 >> iter 236000, loss: 0.004190
 >> iter 237000, loss: 0.002806
 >> iter 238000, loss: 0.002384
 >> iter 239000, loss: 0.002143
 >> iter 240000, loss: 0.097430
   Number of active neurons: 10
 >> iter 241000, loss: 0.044639
 >> iter 242000, loss: 0.045430
 >> iter 243000, loss: 0.018383
 >> iter 244000, loss: 0.026286
 >> iter 245000, loss: 0.011224
 >> iter 246000, loss: 0.018124
 >> iter 247000, loss: 0.008757
 >> iter 248000, loss: 0.023363
 >> iter 249000, loss: 0.010137
 >> iter 250000, loss: 0.005086
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 18.769653
 >> iter 2000, loss: 15.251041
 >> iter 3000, loss: 13.856179
 >> iter 4000, loss: 13.334687
 >> iter 5000, loss: 13.128244
 >> iter 6000, loss: 13.044316
 >> iter 7000, loss: 13.006359
 >> iter 8000, loss: 12.994210
 >> iter 9000, loss: 12.984463
 >> iter 10000, loss: 12.982277
   Number of active neurons: 9
 >> iter 11000, loss: 12.978838
 >> iter 12000, loss: 12.987171
 >> iter 13000, loss: 12.979030
 >> iter 14000, loss: 12.990035
 >> iter 15000, loss: 12.978119
 >> iter 16000, loss: 12.985513
 >> iter 17000, loss: 12.977422
 >> iter 18000, loss: 12.973475
 >> iter 19000, loss: 12.973288
 >> iter 20000, loss: 12.985454
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 21000, loss: 12.976793
 >> iter 22000, loss: 12.986936
 >> iter 23000, loss: 12.973041
 >> iter 24000, loss: 12.985190
 >> iter 25000, loss: 12.972095
 >> iter 26000, loss: 12.974955
 >> iter 27000, loss: 12.977297
 >> iter 28000, loss: 12.988520
 >> iter 29000, loss: 12.974085
 >> iter 30000, loss: 12.986162
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 9
 >> iter 31000, loss: 12.969564
 >> iter 32000, loss: 12.981148
 >> iter 33000, loss: 12.979001
 >> iter 34000, loss: 12.989290
 >> iter 35000, loss: 12.978555
 >> iter 36000, loss: 12.976044
 >> iter 37000, loss: 12.965593
 >> iter 38000, loss: 12.974971
 >> iter 39000, loss: 12.964537
 >> iter 40000, loss: 12.947591
   Number of active neurons: 10
 >> iter 41000, loss: 12.490349
 >> iter 42000, loss: 9.280874
 >> iter 43000, loss: 4.475392
 >> iter 44000, loss: 2.049165
 >> iter 45000, loss: 0.914783
 >> iter 46000, loss: 0.403400
 >> iter 47000, loss: 0.180579
 >> iter 48000, loss: 0.088230
 >> iter 49000, loss: 0.231602
 >> iter 50000, loss: 0.177769
   Number of active neurons: 10
 >> iter 51000, loss: 0.153661
 >> iter 52000, loss: 0.071808
 >> iter 53000, loss: 0.042313
 >> iter 54000, loss: 0.027228
 >> iter 55000, loss: 0.018765
 >> iter 56000, loss: 0.044488
 >> iter 57000, loss: 0.076882
 >> iter 58000, loss: 0.059290
 >> iter 59000, loss: 0.030304
 >> iter 60000, loss: 0.018321
   Number of active neurons: 10
 >> iter 61000, loss: 0.012722
 >> iter 62000, loss: 0.010129
 >> iter 63000, loss: 0.234468
 >> iter 64000, loss: 0.096230
 >> iter 65000, loss: 0.041176
 >> iter 66000, loss: 0.050887
 >> iter 67000, loss: 0.024013
 >> iter 68000, loss: 0.014265
 >> iter 69000, loss: 0.078675
 >> iter 70000, loss: 0.056042
   Number of active neurons: 10
 >> iter 71000, loss: 0.025872
 >> iter 72000, loss: 0.014011
 >> iter 73000, loss: 0.010013
 >> iter 74000, loss: 0.007522
 >> iter 75000, loss: 0.027997
 >> iter 76000, loss: 0.014194
 >> iter 77000, loss: 0.008974
 >> iter 78000, loss: 0.006699
 >> iter 79000, loss: 0.005493
 >> iter 80000, loss: 0.004912
   Number of active neurons: 10
 >> iter 81000, loss: 0.034154
 >> iter 82000, loss: 0.021984
 >> iter 83000, loss: 0.031191
 >> iter 84000, loss: 0.014585
 >> iter 85000, loss: 0.008591
 >> iter 86000, loss: 0.005963
 >> iter 87000, loss: 0.004654
 >> iter 88000, loss: 0.004158
 >> iter 89000, loss: 0.004087
 >> iter 90000, loss: 0.003821
   Number of active neurons: 10
 >> iter 91000, loss: 0.004296
 >> iter 92000, loss: 0.004229
 >> iter 93000, loss: 0.003721
 >> iter 94000, loss: 0.007879
 >> iter 95000, loss: 0.004980
 >> iter 96000, loss: 0.003781
 >> iter 97000, loss: 0.003184
 >> iter 98000, loss: 0.002944
 >> iter 99000, loss: 0.002841
 >> iter 100000, loss: 0.174504
   Number of active neurons: 10
 >> iter 101000, loss: 0.082482
 >> iter 102000, loss: 0.033224
 >> iter 103000, loss: 0.014272
 >> iter 104000, loss: 0.007202
 >> iter 105000, loss: 0.004510
 >> iter 106000, loss: 0.003404
 >> iter 107000, loss: 0.007718
 >> iter 108000, loss: 0.005821
 >> iter 109000, loss: 0.003848
 >> iter 110000, loss: 0.003490
   Number of active neurons: 10
 >> iter 111000, loss: 0.063755
 >> iter 112000, loss: 0.036702
 >> iter 113000, loss: 0.157257
 >> iter 114000, loss: 0.060259
 >> iter 115000, loss: 0.056150
 >> iter 116000, loss: 0.024936
 >> iter 117000, loss: 0.011650
 >> iter 118000, loss: 0.006310
 >> iter 119000, loss: 0.004201
 >> iter 120000, loss: 0.003691
   Number of active neurons: 10
 >> iter 121000, loss: 0.002951
 >> iter 122000, loss: 0.156649
 >> iter 123000, loss: 0.060356
 >> iter 124000, loss: 0.024281
 >> iter 125000, loss: 0.010947
 >> iter 126000, loss: 0.005918
 >> iter 127000, loss: 0.003911
 >> iter 128000, loss: 0.003090
 >> iter 129000, loss: 0.002760
 >> iter 130000, loss: 0.002522
   Number of active neurons: 10
 >> iter 131000, loss: 0.002414
 >> iter 132000, loss: 0.002360
 >> iter 133000, loss: 0.002319
 >> iter 134000, loss: 0.082245
 >> iter 135000, loss: 0.055805
 >> iter 136000, loss: 0.022565
 >> iter 137000, loss: 0.009990
 >> iter 138000, loss: 0.005699
 >> iter 139000, loss: 0.003774
 >> iter 140000, loss: 0.002968
   Number of active neurons: 10
 >> iter 141000, loss: 0.002479
 >> iter 142000, loss: 0.002250
 >> iter 143000, loss: 0.002143
 >> iter 144000, loss: 0.002122
 >> iter 145000, loss: 0.002069
 >> iter 146000, loss: 0.002049
 >> iter 147000, loss: 0.001962
 >> iter 148000, loss: 0.002159
 >> iter 149000, loss: 0.002034
 >> iter 150000, loss: 0.001939
   Number of active neurons: 10
 >> iter 151000, loss: 0.001830
 >> iter 152000, loss: 0.001805
 >> iter 153000, loss: 0.001885
 >> iter 154000, loss: 0.001772
 >> iter 155000, loss: 0.001747
 >> iter 156000, loss: 0.001718
 >> iter 157000, loss: 0.001656
 >> iter 158000, loss: 0.001602
 >> iter 159000, loss: 0.001606
 >> iter 160000, loss: 0.001676
   Number of active neurons: 10
 >> iter 161000, loss: 0.001568
 >> iter 162000, loss: 0.001522
 >> iter 163000, loss: 0.001501
 >> iter 164000, loss: 0.001505
 >> iter 165000, loss: 0.001486
 >> iter 166000, loss: 0.001520
 >> iter 167000, loss: 0.001474
 >> iter 168000, loss: 0.001452
 >> iter 169000, loss: 0.001420
 >> iter 170000, loss: 0.001441
   Number of active neurons: 10
 >> iter 171000, loss: 0.001441
 >> iter 172000, loss: 0.001397
 >> iter 173000, loss: 0.001361
 >> iter 174000, loss: 0.001354
 >> iter 175000, loss: 0.001325
 >> iter 176000, loss: 0.001342
 >> iter 177000, loss: 0.001353
 >> iter 178000, loss: 0.002405
 >> iter 179000, loss: 0.001740
 >> iter 180000, loss: 0.001446
   Number of active neurons: 10
 >> iter 181000, loss: 0.001333
 >> iter 182000, loss: 0.050609
 >> iter 183000, loss: 0.019623
 >> iter 184000, loss: 0.049282
 >> iter 185000, loss: 0.019114
 >> iter 186000, loss: 0.008028
 >> iter 187000, loss: 0.003815
 >> iter 188000, loss: 0.002298
 >> iter 189000, loss: 0.002405
 >> iter 190000, loss: 0.001719
   Number of active neurons: 10
 >> iter 191000, loss: 0.001522
 >> iter 192000, loss: 0.002784
 >> iter 193000, loss: 0.001911
 >> iter 194000, loss: 0.001523
 >> iter 195000, loss: 0.001404
 >> iter 196000, loss: 0.001313
 >> iter 197000, loss: 0.001240
 >> iter 198000, loss: 0.001188
 >> iter 199000, loss: 0.001189
 >> iter 200000, loss: 0.001176
   Number of active neurons: 10
 >> iter 201000, loss: 0.001162
 >> iter 202000, loss: 0.001124
 >> iter 203000, loss: 0.001098
 >> iter 204000, loss: 0.001100
 >> iter 205000, loss: 0.001062
 >> iter 206000, loss: 0.001074
 >> iter 207000, loss: 0.001039
 >> iter 208000, loss: 0.001037
 >> iter 209000, loss: 0.001023
 >> iter 210000, loss: 0.001165
   Number of active neurons: 10
 >> iter 211000, loss: 0.009883
 >> iter 212000, loss: 0.004350
 >> iter 213000, loss: 0.002290
 >> iter 214000, loss: 0.001565
 >> iter 215000, loss: 0.001230
 >> iter 216000, loss: 0.001143
 >> iter 217000, loss: 0.001054
 >> iter 218000, loss: 0.001083
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.757841
 >> iter 2000, loss: 15.266327
 >> iter 3000, loss: 13.885216
 >> iter 4000, loss: 13.338440
 >> iter 5000, loss: 13.119898
 >> iter 6000, loss: 13.051994
 >> iter 7000, loss: 13.016934
 >> iter 8000, loss: 13.003840
 >> iter 9000, loss: 12.988757
 >> iter 10000, loss: 12.994859
   Number of active neurons: 10
 >> iter 11000, loss: 12.981152
 >> iter 12000, loss: 12.991228
 >> iter 13000, loss: 12.973526
 >> iter 14000, loss: 12.978046
 >> iter 15000, loss: 12.973044
 >> iter 16000, loss: 12.977335
 >> iter 17000, loss: 12.966881
 >> iter 18000, loss: 12.972318
 >> iter 19000, loss: 12.962940
 >> iter 20000, loss: 12.967981
   Number of active neurons: 8
 >> iter 21000, loss: 12.952005
 >> iter 22000, loss: 12.977108
 >> iter 23000, loss: 12.957795
 >> iter 24000, loss: 12.972754
 >> iter 25000, loss: 12.961103
 >> iter 26000, loss: 12.953948
 >> iter 27000, loss: 12.163440
 >> iter 28000, loss: 11.426974
 >> iter 29000, loss: 10.979754
 >> iter 30000, loss: 10.733925
   Number of active neurons: 10
 >> iter 31000, loss: 10.422130
 >> iter 32000, loss: 9.960511
 >> iter 33000, loss: 9.346190
 >> iter 34000, loss: 8.916706
 >> iter 35000, loss: 8.712422
 >> iter 36000, loss: 8.339008
 >> iter 37000, loss: 8.434335
 >> iter 38000, loss: 8.415196
 >> iter 39000, loss: 7.725748
 >> iter 40000, loss: 7.335870
   Number of active neurons: 10
 >> iter 41000, loss: 7.204410
 >> iter 42000, loss: 7.091081
 >> iter 43000, loss: 7.127349
 >> iter 44000, loss: 7.227525
 >> iter 45000, loss: 6.993145
 >> iter 46000, loss: 6.680011
 >> iter 47000, loss: 6.250488
 >> iter 48000, loss: 5.943183
 >> iter 49000, loss: 5.617372
 >> iter 50000, loss: 5.711749
   Number of active neurons: 10
 >> iter 51000, loss: 6.032564
 >> iter 52000, loss: 5.936777
 >> iter 53000, loss: 5.324460
 >> iter 54000, loss: 6.294893
 >> iter 55000, loss: 3.977801
 >> iter 56000, loss: 2.224116
 >> iter 57000, loss: 1.338170
 >> iter 58000, loss: 0.835746
 >> iter 59000, loss: 0.851756
 >> iter 60000, loss: 0.515592
   Number of active neurons: 10
 >> iter 61000, loss: 0.423519
 >> iter 62000, loss: 0.377881
 >> iter 63000, loss: 0.235296
 >> iter 64000, loss: 0.279487
 >> iter 65000, loss: 0.292811
 >> iter 66000, loss: 0.630226
 >> iter 67000, loss: 0.382665
 >> iter 68000, loss: 0.282268
 >> iter 69000, loss: 0.570646
 >> iter 70000, loss: 0.573017
   Number of active neurons: 10
 >> iter 71000, loss: 0.309847
 >> iter 72000, loss: 0.346793
 >> iter 73000, loss: 0.259320
 >> iter 74000, loss: 0.585890
 >> iter 75000, loss: 0.311244
 >> iter 76000, loss: 0.634448
 >> iter 77000, loss: 0.492851
 >> iter 78000, loss: 0.348844
 >> iter 79000, loss: 0.307641
 >> iter 80000, loss: 0.265683
   Number of active neurons: 10
 >> iter 81000, loss: 0.369194
 >> iter 82000, loss: 0.257646
 >> iter 83000, loss: 0.157101
 >> iter 84000, loss: 0.178825
 >> iter 85000, loss: 0.116748
 >> iter 86000, loss: 0.092972
 >> iter 87000, loss: 0.082733
 >> iter 88000, loss: 0.276108
 >> iter 89000, loss: 0.431789
 >> iter 90000, loss: 0.351956
   Number of active neurons: 10
 >> iter 91000, loss: 0.156425
 >> iter 92000, loss: 0.108256
 >> iter 93000, loss: 0.080724
 >> iter 94000, loss: 0.075199
 >> iter 95000, loss: 0.118871
 >> iter 96000, loss: 0.062183
 >> iter 97000, loss: 0.037434
 >> iter 98000, loss: 0.072149
 >> iter 99000, loss: 0.038529
 >> iter 100000, loss: 0.043544
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.756534
 >> iter 2000, loss: 15.175015
 >> iter 3000, loss: 13.800289
 >> iter 4000, loss: 13.281717
 >> iter 5000, loss: 13.081995
 >> iter 6000, loss: 13.016570
 >> iter 7000, loss: 12.981756
 >> iter 8000, loss: 12.983093
 >> iter 9000, loss: 12.955588
 >> iter 10000, loss: 12.963355
   Number of active neurons: 7
 >> iter 11000, loss: 12.957881
 >> iter 12000, loss: 12.970783
 >> iter 13000, loss: 12.955126
 >> iter 14000, loss: 12.958472
 >> iter 15000, loss: 12.955767
 >> iter 16000, loss: 12.963280
 >> iter 17000, loss: 12.955171
 >> iter 18000, loss: 12.965012
 >> iter 19000, loss: 12.951537
 >> iter 20000, loss: 12.963195
   Number of active neurons: 7
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 7
 >> iter 21000, loss: 12.953273
 >> iter 22000, loss: 12.959824
 >> iter 23000, loss: 12.947335
 >> iter 24000, loss: 12.966042
 >> iter 25000, loss: 12.954042
 >> iter 26000, loss: 12.962915
 >> iter 27000, loss: 12.955747
 >> iter 28000, loss: 12.964941
 >> iter 29000, loss: 12.955227
 >> iter 30000, loss: 12.967545
   Number of active neurons: 8
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 8
 >> iter 31000, loss: 12.955403
 >> iter 32000, loss: 12.959149
 >> iter 33000, loss: 12.955774
 >> iter 34000, loss: 12.959386
 >> iter 35000, loss: 12.951664
 >> iter 36000, loss: 12.958937
 >> iter 37000, loss: 12.954896
 >> iter 38000, loss: 12.961627
 >> iter 39000, loss: 12.954524
 >> iter 40000, loss: 12.964279
   Number of active neurons: 8
   SHOCK
   Setting new limit to 275000.0 iters...
   Number of active neurons: 8
 >> iter 41000, loss: 12.952431
 >> iter 42000, loss: 12.958683
 >> iter 43000, loss: 12.930790
 >> iter 44000, loss: 12.641485
 >> iter 45000, loss: 9.966676
 >> iter 46000, loss: 4.548312
 >> iter 47000, loss: 2.191688
 >> iter 48000, loss: 0.901540
 >> iter 49000, loss: 0.397460
 >> iter 50000, loss: 0.181557
   Number of active neurons: 10
 >> iter 51000, loss: 0.080438
 >> iter 52000, loss: 0.063066
 >> iter 53000, loss: 0.174052
 >> iter 54000, loss: 0.111526
 >> iter 55000, loss: 0.072737
 >> iter 56000, loss: 0.035723
 >> iter 57000, loss: 0.257115
 >> iter 58000, loss: 0.378108
 >> iter 59000, loss: 0.151419
 >> iter 60000, loss: 0.064358
   Number of active neurons: 10
 >> iter 61000, loss: 0.034777
 >> iter 62000, loss: 0.019754
 >> iter 63000, loss: 0.012533
 >> iter 64000, loss: 0.009226
 >> iter 65000, loss: 0.008670
 >> iter 66000, loss: 0.007455
 >> iter 67000, loss: 0.006432
 >> iter 68000, loss: 0.016397
 >> iter 69000, loss: 0.010068
 >> iter 70000, loss: 0.006855
   Number of active neurons: 10
 >> iter 71000, loss: 0.006377
 >> iter 72000, loss: 0.007803
 >> iter 73000, loss: 0.007397
 >> iter 74000, loss: 0.008190
 >> iter 75000, loss: 0.005526
 >> iter 76000, loss: 0.004157
 >> iter 77000, loss: 0.029316
 >> iter 78000, loss: 0.012968
 >> iter 79000, loss: 0.007138
 >> iter 80000, loss: 0.005083
   Number of active neurons: 10
 >> iter 81000, loss: 0.003903
 >> iter 82000, loss: 0.020739
 >> iter 83000, loss: 0.010131
 >> iter 84000, loss: 0.006875
 >> iter 85000, loss: 0.004539
 >> iter 86000, loss: 0.003189
 >> iter 87000, loss: 0.002684
 >> iter 88000, loss: 0.003753
 >> iter 89000, loss: 0.003336
 >> iter 90000, loss: 0.005260
   Number of active neurons: 10
 >> iter 91000, loss: 0.004128
 >> iter 92000, loss: 0.004289
 >> iter 93000, loss: 0.003664
 >> iter 94000, loss: 0.002769
 >> iter 95000, loss: 0.002142
 >> iter 96000, loss: 0.001884
 >> iter 97000, loss: 0.003205
 >> iter 98000, loss: 0.002268
 >> iter 99000, loss: 0.003362
 >> iter 100000, loss: 0.002851
   Number of active neurons: 10
 >> iter 101000, loss: 0.002058
 >> iter 102000, loss: 0.002154
 >> iter 103000, loss: 0.001847
 >> iter 104000, loss: 0.001735
 >> iter 105000, loss: 0.001640
 >> iter 106000, loss: 0.001498
 >> iter 107000, loss: 0.001552
 >> iter 108000, loss: 0.001377
 >> iter 109000, loss: 0.001339
 >> iter 110000, loss: 0.001618
   Number of active neurons: 10
 >> iter 111000, loss: 0.001364
 >> iter 112000, loss: 0.001693
 >> iter 113000, loss: 0.002616
 >> iter 114000, loss: 0.001941
 >> iter 115000, loss: 0.001973
 >> iter 116000, loss: 0.001884
 >> iter 117000, loss: 0.001458
 >> iter 118000, loss: 0.003131
 >> iter 119000, loss: 0.002838
 >> iter 120000, loss: 0.002197
   Number of active neurons: 10
 >> iter 121000, loss: 0.001543
 >> iter 122000, loss: 0.001994
 >> iter 123000, loss: 0.080334
 >> iter 124000, loss: 0.031137
 >> iter 125000, loss: 0.054632
 >> iter 126000, loss: 0.023010
 >> iter 127000, loss: 0.009520
 >> iter 128000, loss: 0.004519
 >> iter 129000, loss: 0.002588
 >> iter 130000, loss: 0.001915
   Number of active neurons: 10
 >> iter 131000, loss: 0.003338
 >> iter 132000, loss: 0.002198
 >> iter 133000, loss: 0.001753
 >> iter 134000, loss: 0.001604
 >> iter 135000, loss: 0.001404
 >> iter 136000, loss: 0.001342
 >> iter 137000, loss: 0.001278
 >> iter 138000, loss: 0.001358
 >> iter 139000, loss: 0.001252
 >> iter 140000, loss: 0.001187
   Number of active neurons: 10
 >> iter 141000, loss: 0.001182
 >> iter 142000, loss: 0.001093
 >> iter 143000, loss: 0.001078
 >> iter 144000, loss: 0.001069
 >> iter 145000, loss: 0.001586
 >> iter 146000, loss: 0.001233
 >> iter 147000, loss: 0.001235
 >> iter 148000, loss: 0.001140
 >> iter 149000, loss: 0.001009
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.763360
 >> iter 2000, loss: 15.234001
 >> iter 3000, loss: 13.839549
 >> iter 4000, loss: 13.335265
 >> iter 5000, loss: 13.121172
 >> iter 6000, loss: 13.058757
 >> iter 7000, loss: 13.026197
 >> iter 8000, loss: 13.015573
 >> iter 9000, loss: 12.995161
 >> iter 10000, loss: 13.001548
   Number of active neurons: 9
 >> iter 11000, loss: 12.994124
 >> iter 12000, loss: 13.002438
 >> iter 13000, loss: 12.986852
 >> iter 14000, loss: 12.994618
 >> iter 15000, loss: 12.988001
 >> iter 16000, loss: 12.991699
 >> iter 17000, loss: 12.984728
 >> iter 18000, loss: 12.992499
 >> iter 19000, loss: 12.988456
 >> iter 20000, loss: 12.987185
   Number of active neurons: 8
 >> iter 21000, loss: 12.979805
 >> iter 22000, loss: 12.985087
 >> iter 23000, loss: 12.980528
 >> iter 24000, loss: 12.993105
 >> iter 25000, loss: 12.984716
 >> iter 26000, loss: 12.989772
 >> iter 27000, loss: 12.975284
 >> iter 28000, loss: 12.987052
 >> iter 29000, loss: 12.982026
 >> iter 30000, loss: 12.992811
   Number of active neurons: 8
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 8
 >> iter 31000, loss: 12.977988
 >> iter 32000, loss: 12.988192
 >> iter 33000, loss: 12.984711
 >> iter 34000, loss: 12.977413
 >> iter 35000, loss: 12.967658
 >> iter 36000, loss: 12.863509
 >> iter 37000, loss: 11.934443
 >> iter 38000, loss: 11.210466
 >> iter 39000, loss: 10.629523
 >> iter 40000, loss: 10.142447
   Number of active neurons: 10
 >> iter 41000, loss: 9.355904
 >> iter 42000, loss: 8.694633
 >> iter 43000, loss: 6.836025
 >> iter 44000, loss: 3.364709
 >> iter 45000, loss: 2.156238
 >> iter 46000, loss: 1.488644
 >> iter 47000, loss: 0.913986
 >> iter 48000, loss: 0.451196
 >> iter 49000, loss: 0.499110
 >> iter 50000, loss: 0.680235
   Number of active neurons: 10
 >> iter 51000, loss: 0.454106
 >> iter 52000, loss: 0.428463
 >> iter 53000, loss: 0.325685
 >> iter 54000, loss: 0.311628
 >> iter 55000, loss: 0.341117
 >> iter 56000, loss: 0.240819
 >> iter 57000, loss: 0.294395
 >> iter 58000, loss: 0.135049
 >> iter 59000, loss: 0.171854
 >> iter 60000, loss: 0.106610
   Number of active neurons: 10
 >> iter 61000, loss: 0.077513
 >> iter 62000, loss: 0.310923
 >> iter 63000, loss: 0.462587
 >> iter 64000, loss: 0.386352
 >> iter 65000, loss: 0.207281
 >> iter 66000, loss: 0.093530
 >> iter 67000, loss: 0.046855
 >> iter 68000, loss: 0.026080
 >> iter 69000, loss: 0.031220
 >> iter 70000, loss: 0.017846
   Number of active neurons: 10
 >> iter 71000, loss: 0.027268
 >> iter 72000, loss: 0.076962
 >> iter 73000, loss: 0.041385
 >> iter 74000, loss: 0.020272
 >> iter 75000, loss: 0.021227
 >> iter 76000, loss: 0.228616
 >> iter 77000, loss: 0.112052
 >> iter 78000, loss: 0.049043
 >> iter 79000, loss: 0.024296
 >> iter 80000, loss: 0.013242
   Number of active neurons: 10
 >> iter 81000, loss: 0.008582
 >> iter 82000, loss: 0.061566
 >> iter 83000, loss: 0.074585
 >> iter 84000, loss: 0.031618
 >> iter 85000, loss: 0.045412
 >> iter 86000, loss: 0.113187
 >> iter 87000, loss: 0.046220
 >> iter 88000, loss: 0.032428
 >> iter 89000, loss: 0.021372
 >> iter 90000, loss: 0.011463
   Number of active neurons: 10
 >> iter 91000, loss: 0.007199
 >> iter 92000, loss: 0.005317
 >> iter 93000, loss: 0.004552
 >> iter 94000, loss: 0.092014
 >> iter 95000, loss: 0.105146
 >> iter 96000, loss: 0.200603
 >> iter 97000, loss: 0.088433
 >> iter 98000, loss: 0.046090
 >> iter 99000, loss: 0.066562
 >> iter 100000, loss: 0.033018
   Number of active neurons: 10
 >> iter 101000, loss: 0.164275
 >> iter 102000, loss: 0.065704
 >> iter 103000, loss: 0.027928
 >> iter 104000, loss: 0.013564
 >> iter 105000, loss: 0.012873
 >> iter 106000, loss: 0.009608
 >> iter 107000, loss: 0.006296
 >> iter 108000, loss: 0.004967
 >> iter 109000, loss: 0.004412
 >> iter 110000, loss: 0.035701
   Number of active neurons: 10
 >> iter 111000, loss: 0.017155
 >> iter 112000, loss: 0.008535
 >> iter 113000, loss: 0.005241
 >> iter 114000, loss: 0.033715
 >> iter 115000, loss: 0.014776
 >> iter 116000, loss: 0.008583
 >> iter 117000, loss: 0.005305
 >> iter 118000, loss: 0.015197
 >> iter 119000, loss: 0.115826
 >> iter 120000, loss: 0.110150
   Number of active neurons: 10
 >> iter 121000, loss: 0.080703
 >> iter 122000, loss: 0.105525
 >> iter 123000, loss: 0.053200
 >> iter 124000, loss: 0.068437
 >> iter 125000, loss: 0.157999
 >> iter 126000, loss: 0.066636
 >> iter 127000, loss: 0.028938
 >> iter 128000, loss: 0.013502
 >> iter 129000, loss: 0.007580
 >> iter 130000, loss: 0.005648
   Number of active neurons: 10
 >> iter 131000, loss: 0.007367
 >> iter 132000, loss: 0.004926
 >> iter 133000, loss: 0.004291
 >> iter 134000, loss: 0.003544
 >> iter 135000, loss: 0.012557
 >> iter 136000, loss: 0.006545
 >> iter 137000, loss: 0.004222
 >> iter 138000, loss: 0.003251
 >> iter 139000, loss: 0.002806
 >> iter 140000, loss: 0.024753
   Number of active neurons: 10
 >> iter 141000, loss: 0.010957
 >> iter 142000, loss: 0.005722
 >> iter 143000, loss: 0.003868
 >> iter 144000, loss: 0.002888
 >> iter 145000, loss: 0.002488
 >> iter 146000, loss: 0.002334
 >> iter 147000, loss: 0.002172
 >> iter 148000, loss: 0.005324
 >> iter 149000, loss: 0.003319
 >> iter 150000, loss: 0.002470
   Number of active neurons: 10
 >> iter 151000, loss: 0.002111
 >> iter 152000, loss: 0.001930
 >> iter 153000, loss: 0.001855
 >> iter 154000, loss: 0.001772
 >> iter 155000, loss: 0.002167
 >> iter 156000, loss: 0.001847
 >> iter 157000, loss: 0.003632
 >> iter 158000, loss: 0.002411
 >> iter 159000, loss: 0.002970
 >> iter 160000, loss: 0.142800
   Number of active neurons: 10
 >> iter 161000, loss: 0.096476
 >> iter 162000, loss: 0.062526
 >> iter 163000, loss: 0.025229
 >> iter 164000, loss: 0.010946
 >> iter 165000, loss: 0.008830
 >> iter 166000, loss: 0.005154
 >> iter 167000, loss: 0.003449
 >> iter 168000, loss: 0.086210
 >> iter 169000, loss: 0.033330
 >> iter 170000, loss: 0.013800
   Number of active neurons: 10
 >> iter 171000, loss: 0.006658
 >> iter 172000, loss: 0.003865
 >> iter 173000, loss: 0.003174
 >> iter 174000, loss: 0.002485
 >> iter 175000, loss: 0.002207
 >> iter 176000, loss: 0.002031
 >> iter 177000, loss: 0.001904
 >> iter 178000, loss: 0.001892
 >> iter 179000, loss: 0.001775
 >> iter 180000, loss: 0.001769
   Number of active neurons: 10
 >> iter 181000, loss: 0.001747
 >> iter 182000, loss: 0.001646
 >> iter 183000, loss: 0.001607
 >> iter 184000, loss: 0.001536
 >> iter 185000, loss: 0.001508
 >> iter 186000, loss: 0.001456
 >> iter 187000, loss: 0.001433
 >> iter 188000, loss: 0.001397
 >> iter 189000, loss: 0.001384
 >> iter 190000, loss: 0.001363
   Number of active neurons: 10
 >> iter 191000, loss: 0.001382
 >> iter 192000, loss: 0.001338
 >> iter 193000, loss: 0.001303
 >> iter 194000, loss: 0.001299
 >> iter 195000, loss: 0.001314
 >> iter 196000, loss: 0.001334
 >> iter 197000, loss: 0.001249
 >> iter 198000, loss: 0.001206
 >> iter 199000, loss: 0.001177
 >> iter 200000, loss: 0.001152
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.760140
 >> iter 2000, loss: 15.234608
 >> iter 3000, loss: 13.834998
 >> iter 4000, loss: 13.310101
 >> iter 5000, loss: 13.096662
 >> iter 6000, loss: 13.027343
 >> iter 7000, loss: 12.987383
 >> iter 8000, loss: 12.979706
 >> iter 9000, loss: 12.970528
 >> iter 10000, loss: 12.974911
   Number of active neurons: 8
 >> iter 11000, loss: 12.966263
 >> iter 12000, loss: 12.972626
 >> iter 13000, loss: 12.960982
 >> iter 14000, loss: 12.975213
 >> iter 15000, loss: 12.964089
 >> iter 16000, loss: 12.970894
 >> iter 17000, loss: 12.967605
 >> iter 18000, loss: 12.971003
 >> iter 19000, loss: 12.953731
 >> iter 20000, loss: 12.964181
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 21000, loss: 12.963318
 >> iter 22000, loss: 12.975149
 >> iter 23000, loss: 12.948740
 >> iter 24000, loss: 12.869164
 >> iter 25000, loss: 11.990817
 >> iter 26000, loss: 10.857672
 >> iter 27000, loss: 9.719231
 >> iter 28000, loss: 8.759373
 >> iter 29000, loss: 8.066410
 >> iter 30000, loss: 7.245917
   Number of active neurons: 10
 >> iter 31000, loss: 5.610867
 >> iter 32000, loss: 4.601658
 >> iter 33000, loss: 2.892209
 >> iter 34000, loss: 2.395799
 >> iter 35000, loss: 1.527165
 >> iter 36000, loss: 1.848891
 >> iter 37000, loss: 1.368133
 >> iter 38000, loss: 1.045796
 >> iter 39000, loss: 0.672262
 >> iter 40000, loss: 0.906582
   Number of active neurons: 10
 >> iter 41000, loss: 0.726549
 >> iter 42000, loss: 0.443190
 >> iter 43000, loss: 0.389383
 >> iter 44000, loss: 0.564273
 >> iter 45000, loss: 0.470583
 >> iter 46000, loss: 0.570000
 >> iter 47000, loss: 0.342052
 >> iter 48000, loss: 0.697974
 >> iter 49000, loss: 0.374619
 >> iter 50000, loss: 1.027007
   Number of active neurons: 10
 >> iter 51000, loss: 0.815049
 >> iter 52000, loss: 0.449305
 >> iter 53000, loss: 0.292454
 >> iter 54000, loss: 0.178233
 >> iter 55000, loss: 0.208516
 >> iter 56000, loss: 0.325902
 >> iter 57000, loss: 0.307876
 >> iter 58000, loss: 0.264266
 >> iter 59000, loss: 0.194394
 >> iter 60000, loss: 0.230216
   Number of active neurons: 10
 >> iter 61000, loss: 0.196052
 >> iter 62000, loss: 0.139281
 >> iter 63000, loss: 0.238535
 >> iter 64000, loss: 0.107676
 >> iter 65000, loss: 0.091111
 >> iter 66000, loss: 0.050166
 >> iter 67000, loss: 0.038122
 >> iter 68000, loss: 0.153636
 >> iter 69000, loss: 0.237346
 >> iter 70000, loss: 0.146786
   Number of active neurons: 10
 >> iter 71000, loss: 0.145353
 >> iter 72000, loss: 0.225324
 >> iter 73000, loss: 0.240952
 >> iter 74000, loss: 0.304743
 >> iter 75000, loss: 0.156157
 >> iter 76000, loss: 0.191883
 >> iter 77000, loss: 0.149090
 >> iter 78000, loss: 0.112110
 >> iter 79000, loss: 0.144637
 >> iter 80000, loss: 0.878606
   Number of active neurons: 10
 >> iter 81000, loss: 0.430098
 >> iter 82000, loss: 0.179445
 >> iter 83000, loss: 0.101678
 >> iter 84000, loss: 0.208154
 >> iter 85000, loss: 0.260735
 >> iter 86000, loss: 0.239056
 >> iter 87000, loss: 0.212500
 >> iter 88000, loss: 0.393336
 >> iter 89000, loss: 0.234800
 >> iter 90000, loss: 0.115195
   Number of active neurons: 10
 >> iter 91000, loss: 0.058194
 >> iter 92000, loss: 0.059078
 >> iter 93000, loss: 0.031840
 >> iter 94000, loss: 0.024610
 >> iter 95000, loss: 0.022234
 >> iter 96000, loss: 0.017132
 >> iter 97000, loss: 0.016713
 >> iter 98000, loss: 0.013622
 >> iter 99000, loss: 0.010894
 >> iter 100000, loss: 0.018932
   Number of active neurons: 10
 >> iter 101000, loss: 0.012189
 >> iter 102000, loss: 0.009323
 >> iter 103000, loss: 0.101425
 >> iter 104000, loss: 0.047064
 >> iter 105000, loss: 0.022271
 >> iter 106000, loss: 0.013676
 >> iter 107000, loss: 0.108171
 >> iter 108000, loss: 0.236794
 >> iter 109000, loss: 0.130541
 >> iter 110000, loss: 0.054212
   Number of active neurons: 10
 >> iter 111000, loss: 0.143238
 >> iter 112000, loss: 0.058959
 >> iter 113000, loss: 0.026827
 >> iter 114000, loss: 0.222127
 >> iter 115000, loss: 0.124229
 >> iter 116000, loss: 0.053986
 >> iter 117000, loss: 0.028055
 >> iter 118000, loss: 0.162963
 >> iter 119000, loss: 0.150491
 >> iter 120000, loss: 0.086557
   Number of active neurons: 10
 >> iter 121000, loss: 0.394490
 >> iter 122000, loss: 0.234800
 >> iter 123000, loss: 0.095265
 >> iter 124000, loss: 0.042633
 >> iter 125000, loss: 0.026638
 >> iter 126000, loss: 0.016000
 >> iter 127000, loss: 0.012097
 >> iter 128000, loss: 0.027839
 >> iter 129000, loss: 0.015843
 >> iter 130000, loss: 0.011102
   Number of active neurons: 10
 >> iter 131000, loss: 0.069174
 >> iter 132000, loss: 0.030342
 >> iter 133000, loss: 0.015848
 >> iter 134000, loss: 0.009948
 >> iter 135000, loss: 0.007518
 >> iter 136000, loss: 0.008199
 >> iter 137000, loss: 0.006533
 >> iter 138000, loss: 0.230375
 >> iter 139000, loss: 0.195408
 >> iter 140000, loss: 0.076916
   Number of active neurons: 10
 >> iter 141000, loss: 0.032693
 >> iter 142000, loss: 0.016612
 >> iter 143000, loss: 0.022227
 >> iter 144000, loss: 0.044580
 >> iter 145000, loss: 0.053391
 >> iter 146000, loss: 0.034586
 >> iter 147000, loss: 0.021360
 >> iter 148000, loss: 0.011444
 >> iter 149000, loss: 0.017323
 >> iter 150000, loss: 0.010645
   Number of active neurons: 10
 >> iter 151000, loss: 0.007184
 >> iter 152000, loss: 0.006704
 >> iter 153000, loss: 0.005479
 >> iter 154000, loss: 0.064107
 >> iter 155000, loss: 0.034428
 >> iter 156000, loss: 0.080656
 >> iter 157000, loss: 0.233509
 >> iter 158000, loss: 0.095088
 >> iter 159000, loss: 0.071642
 >> iter 160000, loss: 0.411727
   Number of active neurons: 10
 >> iter 161000, loss: 0.170728
 >> iter 162000, loss: 0.216675
 >> iter 163000, loss: 0.097844
 >> iter 164000, loss: 0.140001
 >> iter 165000, loss: 0.081794
 >> iter 166000, loss: 0.091501
 >> iter 167000, loss: 0.039201
 >> iter 168000, loss: 0.124865
 >> iter 169000, loss: 0.055576
 >> iter 170000, loss: 0.026007
   Number of active neurons: 10
 >> iter 171000, loss: 0.060950
 >> iter 172000, loss: 0.027504
 >> iter 173000, loss: 0.014872
 >> iter 174000, loss: 0.015034
 >> iter 175000, loss: 0.009793
 >> iter 176000, loss: 0.007482
 >> iter 177000, loss: 0.014337
 >> iter 178000, loss: 0.063222
 >> iter 179000, loss: 0.047201
 >> iter 180000, loss: 0.021752
   Number of active neurons: 10
 >> iter 181000, loss: 0.012576
 >> iter 182000, loss: 0.008472
 >> iter 183000, loss: 0.007164
 >> iter 184000, loss: 0.017538
 >> iter 185000, loss: 0.014278
 >> iter 186000, loss: 0.020457
 >> iter 187000, loss: 0.010652
 >> iter 188000, loss: 0.043670
 >> iter 189000, loss: 0.063655
 >> iter 190000, loss: 0.027080
   Number of active neurons: 10
 >> iter 191000, loss: 0.052970
 >> iter 192000, loss: 0.095390
 >> iter 193000, loss: 0.039139
 >> iter 194000, loss: 0.018683
 >> iter 195000, loss: 0.009913
 >> iter 196000, loss: 0.006424
 >> iter 197000, loss: 0.571188
 >> iter 198000, loss: 0.218024
 >> iter 199000, loss: 0.182362
 >> iter 200000, loss: 0.280886
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

