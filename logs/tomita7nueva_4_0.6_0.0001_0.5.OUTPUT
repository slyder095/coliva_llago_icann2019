 > Problema: tomita7nueva
 > Args:
   - Hidden size: 4
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.898056
 >> iter 2000, loss: 11.564145
 >> iter 3000, loss: 9.206273
 >> iter 4000, loss: 7.520488
 >> iter 5000, loss: 4.150732
 >> iter 6000, loss: 2.162125
 >> iter 7000, loss: 1.083014
 >> iter 8000, loss: 0.698256
 >> iter 9000, loss: 0.481014
 >> iter 10000, loss: 0.363336
   Number of active neurons: 4
 >> iter 11000, loss: 0.278553
 >> iter 12000, loss: 0.252619
 >> iter 13000, loss: 0.257357
 >> iter 14000, loss: 0.338758
 >> iter 15000, loss: 0.295854
 >> iter 16000, loss: 0.306998
 >> iter 17000, loss: 0.274319
 >> iter 18000, loss: 0.331698
 >> iter 19000, loss: 0.243670
 >> iter 20000, loss: 0.339447
   Number of active neurons: 4
 >> iter 21000, loss: 0.413793
 >> iter 22000, loss: 0.390844
 >> iter 23000, loss: 0.309267
 >> iter 24000, loss: 0.330366
 >> iter 25000, loss: 0.384258
 >> iter 26000, loss: 0.458452
 >> iter 27000, loss: 0.502846
 >> iter 28000, loss: 0.435226
 >> iter 29000, loss: 0.339954
 >> iter 30000, loss: 0.294963
   Number of active neurons: 4
 >> iter 31000, loss: 0.228199
 >> iter 32000, loss: 0.215244
 >> iter 33000, loss: 0.343422
 >> iter 34000, loss: 0.300954
 >> iter 35000, loss: 0.341620
 >> iter 36000, loss: 0.311148
 >> iter 37000, loss: 0.276479
 >> iter 38000, loss: 0.313240
 >> iter 39000, loss: 0.405474
 >> iter 40000, loss: 0.466291
   Number of active neurons: 4
 >> iter 41000, loss: 0.375002
 >> iter 42000, loss: 0.246344
 >> iter 43000, loss: 0.307644
 >> iter 44000, loss: 0.386071
 >> iter 45000, loss: 0.382652
 >> iter 46000, loss: 0.444035
 >> iter 47000, loss: 0.387280
 >> iter 48000, loss: 0.343446
 >> iter 49000, loss: 0.289296
 >> iter 50000, loss: 0.463535
   Number of active neurons: 4
 >> iter 51000, loss: 0.420644
 >> iter 52000, loss: 0.463092
 >> iter 53000, loss: 0.463251
 >> iter 54000, loss: 0.340290
 >> iter 55000, loss: 0.300524
 >> iter 56000, loss: 0.419599
 >> iter 57000, loss: 0.409038
 >> iter 58000, loss: 0.400991
 >> iter 59000, loss: 0.396733
 >> iter 60000, loss: 0.423743
   Number of active neurons: 4
 >> iter 61000, loss: 0.374975
 >> iter 62000, loss: 0.328789
 >> iter 63000, loss: 0.363462
 >> iter 64000, loss: 0.343471
 >> iter 65000, loss: 0.562236
 >> iter 66000, loss: 0.441707
 >> iter 67000, loss: 0.339374
 >> iter 68000, loss: 0.275599
 >> iter 69000, loss: 0.394035
 >> iter 70000, loss: 0.459233
   Number of active neurons: 4
 >> iter 71000, loss: 0.481622
 >> iter 72000, loss: 0.462285
 >> iter 73000, loss: 0.405269
 >> iter 74000, loss: 0.417743
 >> iter 75000, loss: 0.384724
 >> iter 76000, loss: 0.378752
 >> iter 77000, loss: 0.273264
 >> iter 78000, loss: 0.221324
 >> iter 79000, loss: 0.442138
 >> iter 80000, loss: 0.469078
   Number of active neurons: 4
 >> iter 81000, loss: 0.468842
 >> iter 82000, loss: 0.381472
 >> iter 83000, loss: 0.294479
 >> iter 84000, loss: 0.373106
 >> iter 85000, loss: 0.484519
 >> iter 86000, loss: 0.367600
 >> iter 87000, loss: 0.428219
 >> iter 88000, loss: 0.314379
 >> iter 89000, loss: 0.396479
 >> iter 90000, loss: 0.453878
   Number of active neurons: 4
 >> iter 91000, loss: 0.431988
 >> iter 92000, loss: 0.322823
 >> iter 93000, loss: 0.454417
 >> iter 94000, loss: 0.506135
 >> iter 95000, loss: 0.361980
 >> iter 96000, loss: 0.354649
 >> iter 97000, loss: 0.356387
 >> iter 98000, loss: 0.379459
 >> iter 99000, loss: 0.423090
 >> iter 100000, loss: 0.434513
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.585171
 >> iter 2000, loss: 13.088342
 >> iter 3000, loss: 9.286540
 >> iter 4000, loss: 6.503035
 >> iter 5000, loss: 4.320087
 >> iter 6000, loss: 3.004142
 >> iter 7000, loss: 1.518726
 >> iter 8000, loss: 0.911433
 >> iter 9000, loss: 0.519682
 >> iter 10000, loss: 0.356064
   Number of active neurons: 4
 >> iter 11000, loss: 0.378542
 >> iter 12000, loss: 0.281750
 >> iter 13000, loss: 0.314231
 >> iter 14000, loss: 0.297842
 >> iter 15000, loss: 0.232573
 >> iter 16000, loss: 0.189821
 >> iter 17000, loss: 0.203810
 >> iter 18000, loss: 0.212708
 >> iter 19000, loss: 0.259786
 >> iter 20000, loss: 0.263203
   Number of active neurons: 4
 >> iter 21000, loss: 0.273877
 >> iter 22000, loss: 0.342371
 >> iter 23000, loss: 0.211139
 >> iter 24000, loss: 0.369265
 >> iter 25000, loss: 0.365527
 >> iter 26000, loss: 0.411411
 >> iter 27000, loss: 0.333867
 >> iter 28000, loss: 0.277249
 >> iter 29000, loss: 0.428464
 >> iter 30000, loss: 0.315899
   Number of active neurons: 4
 >> iter 31000, loss: 0.279406
 >> iter 32000, loss: 0.226380
 >> iter 33000, loss: 0.313505
 >> iter 34000, loss: 0.295332
 >> iter 35000, loss: 0.383666
 >> iter 36000, loss: 0.303669
 >> iter 37000, loss: 0.268982
 >> iter 38000, loss: 0.301447
 >> iter 39000, loss: 0.306477
 >> iter 40000, loss: 0.368661
   Number of active neurons: 4
 >> iter 41000, loss: 0.340340
 >> iter 42000, loss: 0.323857
 >> iter 43000, loss: 0.323381
 >> iter 44000, loss: 0.226415
 >> iter 45000, loss: 0.256093
 >> iter 46000, loss: 0.337676
 >> iter 47000, loss: 0.431227
 >> iter 48000, loss: 0.268544
 >> iter 49000, loss: 0.213879
 >> iter 50000, loss: 0.292855
   Number of active neurons: 4
 >> iter 51000, loss: 0.251279
 >> iter 52000, loss: 0.313477
 >> iter 53000, loss: 0.293899
 >> iter 54000, loss: 0.374834
 >> iter 55000, loss: 0.385276
 >> iter 56000, loss: 0.257196
 >> iter 57000, loss: 0.331896
 >> iter 58000, loss: 0.333336
 >> iter 59000, loss: 0.364596
 >> iter 60000, loss: 0.373418
   Number of active neurons: 4
 >> iter 61000, loss: 0.317278
 >> iter 62000, loss: 0.384140
 >> iter 63000, loss: 0.306820
 >> iter 64000, loss: 0.268662
 >> iter 65000, loss: 0.267380
 >> iter 66000, loss: 0.403443
 >> iter 67000, loss: 0.489452
 >> iter 68000, loss: 0.504178
 >> iter 69000, loss: 0.430153
 >> iter 70000, loss: 0.369205
   Number of active neurons: 4
 >> iter 71000, loss: 0.482084
 >> iter 72000, loss: 0.381060
 >> iter 73000, loss: 0.363865
 >> iter 74000, loss: 0.352555
 >> iter 75000, loss: 0.284378
 >> iter 76000, loss: 0.274872
 >> iter 77000, loss: 0.282539
 >> iter 78000, loss: 0.285937
 >> iter 79000, loss: 0.242837
 >> iter 80000, loss: 0.339187
   Number of active neurons: 4
 >> iter 81000, loss: 0.260092
 >> iter 82000, loss: 0.356915
 >> iter 83000, loss: 0.379901
 >> iter 84000, loss: 0.328026
 >> iter 85000, loss: 0.318169
 >> iter 86000, loss: 0.352228
 >> iter 87000, loss: 0.378701
 >> iter 88000, loss: 0.361205
 >> iter 89000, loss: 0.417232
 >> iter 90000, loss: 0.365014
   Number of active neurons: 4
 >> iter 91000, loss: 0.304126
 >> iter 92000, loss: 0.395647
 >> iter 93000, loss: 0.335006
 >> iter 94000, loss: 0.242150
 >> iter 95000, loss: 0.309406
 >> iter 96000, loss: 0.400821
 >> iter 97000, loss: 0.307202
 >> iter 98000, loss: 0.351874
 >> iter 99000, loss: 0.358765
 >> iter 100000, loss: 0.444359
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.996627
 >> iter 2000, loss: 13.697452
 >> iter 3000, loss: 9.819038
 >> iter 4000, loss: 7.616572
 >> iter 5000, loss: 8.306333
 >> iter 6000, loss: 7.970940
 >> iter 7000, loss: 7.621457
 >> iter 8000, loss: 7.036655
 >> iter 9000, loss: 6.297728
 >> iter 10000, loss: 4.146722
   Number of active neurons: 4
 >> iter 11000, loss: 2.397189
 >> iter 12000, loss: 1.580306
 >> iter 13000, loss: 1.088256
 >> iter 14000, loss: 0.740681
 >> iter 15000, loss: 0.659626
 >> iter 16000, loss: 0.758724
 >> iter 17000, loss: 0.598248
 >> iter 18000, loss: 0.384562
 >> iter 19000, loss: 0.421362
 >> iter 20000, loss: 0.479417
   Number of active neurons: 4
 >> iter 21000, loss: 0.568112
 >> iter 22000, loss: 0.652198
 >> iter 23000, loss: 0.792626
 >> iter 24000, loss: 0.496058
 >> iter 25000, loss: 0.611789
 >> iter 26000, loss: 0.708305
 >> iter 27000, loss: 0.645521
 >> iter 28000, loss: 0.665497
 >> iter 29000, loss: 0.686499
 >> iter 30000, loss: 0.554824
   Number of active neurons: 4
 >> iter 31000, loss: 0.456687
 >> iter 32000, loss: 0.505259
 >> iter 33000, loss: 0.565858
 >> iter 34000, loss: 0.594442
 >> iter 35000, loss: 0.685858
 >> iter 36000, loss: 0.595351
 >> iter 37000, loss: 0.689147
 >> iter 38000, loss: 0.514757
 >> iter 39000, loss: 0.693183
 >> iter 40000, loss: 0.668764
   Number of active neurons: 4
 >> iter 41000, loss: 0.588720
 >> iter 42000, loss: 0.644161
 >> iter 43000, loss: 0.625060
 >> iter 44000, loss: 0.522520
 >> iter 45000, loss: 0.548860
 >> iter 46000, loss: 0.611316
 >> iter 47000, loss: 0.642193
 >> iter 48000, loss: 0.758446
 >> iter 49000, loss: 0.664262
 >> iter 50000, loss: 0.597176
   Number of active neurons: 4
 >> iter 51000, loss: 0.541284
 >> iter 52000, loss: 0.558601
 >> iter 53000, loss: 0.501125
 >> iter 54000, loss: 0.535600
 >> iter 55000, loss: 0.603773
 >> iter 56000, loss: 0.677193
 >> iter 57000, loss: 0.718037
 >> iter 58000, loss: 0.565866
 >> iter 59000, loss: 0.497262
 >> iter 60000, loss: 0.519441
   Number of active neurons: 4
 >> iter 61000, loss: 0.568871
 >> iter 62000, loss: 0.592906
 >> iter 63000, loss: 0.615112
 >> iter 64000, loss: 0.690493
 >> iter 65000, loss: 0.544107
 >> iter 66000, loss: 0.543915
 >> iter 67000, loss: 0.680082
 >> iter 68000, loss: 0.651506
 >> iter 69000, loss: 0.611562
 >> iter 70000, loss: 0.611085
   Number of active neurons: 4
 >> iter 71000, loss: 0.606394
 >> iter 72000, loss: 0.722664
 >> iter 73000, loss: 0.681439
 >> iter 74000, loss: 0.735547
 >> iter 75000, loss: 0.564861
 >> iter 76000, loss: 0.468263
 >> iter 77000, loss: 0.522662
 >> iter 78000, loss: 0.543810
 >> iter 79000, loss: 0.453400
 >> iter 80000, loss: 0.519487
   Number of active neurons: 4
 >> iter 81000, loss: 0.597071
 >> iter 82000, loss: 0.570337
 >> iter 83000, loss: 0.663884
 >> iter 84000, loss: 0.632080
 >> iter 85000, loss: 0.661463
 >> iter 86000, loss: 0.655291
 >> iter 87000, loss: 0.631200
 >> iter 88000, loss: 0.476293
 >> iter 89000, loss: 0.565671
 >> iter 90000, loss: 0.565587
   Number of active neurons: 4
 >> iter 91000, loss: 0.574563
 >> iter 92000, loss: 0.568662
 >> iter 93000, loss: 0.554072
 >> iter 94000, loss: 0.575614
 >> iter 95000, loss: 0.562897
 >> iter 96000, loss: 0.496998
 >> iter 97000, loss: 0.670278
 >> iter 98000, loss: 0.752397
 >> iter 99000, loss: 0.643804
 >> iter 100000, loss: 0.717885
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.397179
 >> iter 2000, loss: 13.373781
 >> iter 3000, loss: 11.284403
 >> iter 4000, loss: 9.629729
 >> iter 5000, loss: 9.342030
 >> iter 6000, loss: 8.509742
 >> iter 7000, loss: 7.501236
 >> iter 8000, loss: 4.936576
 >> iter 9000, loss: 2.585132
 >> iter 10000, loss: 1.399476
   Number of active neurons: 4
 >> iter 11000, loss: 0.860502
 >> iter 12000, loss: 0.553538
 >> iter 13000, loss: 0.440024
 >> iter 14000, loss: 0.346488
 >> iter 15000, loss: 0.338686
 >> iter 16000, loss: 0.443707
 >> iter 17000, loss: 0.377180
 >> iter 18000, loss: 0.252790
 >> iter 19000, loss: 0.290122
 >> iter 20000, loss: 0.231609
   Number of active neurons: 4
 >> iter 21000, loss: 0.567531
 >> iter 22000, loss: 0.538528
 >> iter 23000, loss: 0.377988
 >> iter 24000, loss: 0.356630
 >> iter 25000, loss: 0.277260
 >> iter 26000, loss: 0.244397
 >> iter 27000, loss: 0.274448
 >> iter 28000, loss: 0.294658
 >> iter 29000, loss: 0.366218
 >> iter 30000, loss: 0.341785
   Number of active neurons: 4
 >> iter 31000, loss: 0.375124
 >> iter 32000, loss: 0.244035
 >> iter 33000, loss: 0.216482
 >> iter 34000, loss: 0.187344
 >> iter 35000, loss: 0.234419
 >> iter 36000, loss: 0.162448
 >> iter 37000, loss: 0.275515
 >> iter 38000, loss: 0.261172
 >> iter 39000, loss: 0.248948
 >> iter 40000, loss: 0.209662
   Number of active neurons: 4
 >> iter 41000, loss: 0.246076
 >> iter 42000, loss: 0.243300
 >> iter 43000, loss: 0.288309
 >> iter 44000, loss: 0.272726
 >> iter 45000, loss: 0.251265
 >> iter 46000, loss: 0.308996
 >> iter 47000, loss: 0.283626
 >> iter 48000, loss: 0.300907
 >> iter 49000, loss: 0.241575
 >> iter 50000, loss: 0.165141
   Number of active neurons: 4
 >> iter 51000, loss: 0.180064
 >> iter 52000, loss: 0.147881
 >> iter 53000, loss: 0.179662
 >> iter 54000, loss: 0.242511
 >> iter 55000, loss: 0.234512
 >> iter 56000, loss: 0.296232
 >> iter 57000, loss: 0.224767
 >> iter 58000, loss: 0.221670
 >> iter 59000, loss: 0.212938
 >> iter 60000, loss: 0.233461
   Number of active neurons: 4
 >> iter 61000, loss: 0.263513
 >> iter 62000, loss: 0.239844
 >> iter 63000, loss: 0.267938
 >> iter 64000, loss: 0.348865
 >> iter 65000, loss: 0.308704
 >> iter 66000, loss: 0.327851
 >> iter 67000, loss: 0.245760
 >> iter 68000, loss: 0.215009
 >> iter 69000, loss: 0.206738
 >> iter 70000, loss: 0.201476
   Number of active neurons: 4
 >> iter 71000, loss: 0.236642
 >> iter 72000, loss: 0.217381
 >> iter 73000, loss: 0.246300
 >> iter 74000, loss: 0.177970
 >> iter 75000, loss: 0.229559
 >> iter 76000, loss: 0.210365
 >> iter 77000, loss: 0.364464
 >> iter 78000, loss: 0.305898
 >> iter 79000, loss: 0.316706
 >> iter 80000, loss: 0.229662
   Number of active neurons: 4
 >> iter 81000, loss: 0.246740
 >> iter 82000, loss: 0.216935
 >> iter 83000, loss: 0.200511
 >> iter 84000, loss: 0.204304
 >> iter 85000, loss: 0.214979
 >> iter 86000, loss: 0.249122
 >> iter 87000, loss: 0.326173
 >> iter 88000, loss: 0.233526
 >> iter 89000, loss: 0.258162
 >> iter 90000, loss: 0.267552
   Number of active neurons: 4
 >> iter 91000, loss: 0.271771
 >> iter 92000, loss: 0.256416
 >> iter 93000, loss: 0.360514
 >> iter 94000, loss: 0.372932
 >> iter 95000, loss: 0.368225
 >> iter 96000, loss: 0.305132
 >> iter 97000, loss: 0.257386
 >> iter 98000, loss: 0.204380
 >> iter 99000, loss: 0.228287
 >> iter 100000, loss: 0.310609
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.461284
 >> iter 2000, loss: 12.209820
 >> iter 3000, loss: 9.908909
 >> iter 4000, loss: 5.964537
 >> iter 5000, loss: 2.770041
 >> iter 6000, loss: 1.359153
 >> iter 7000, loss: 0.833069
 >> iter 8000, loss: 0.536115
 >> iter 9000, loss: 0.309360
 >> iter 10000, loss: 0.265686
   Number of active neurons: 4
 >> iter 11000, loss: 0.226199
 >> iter 12000, loss: 0.270453
 >> iter 13000, loss: 0.279128
 >> iter 14000, loss: 0.304833
 >> iter 15000, loss: 0.217133
 >> iter 16000, loss: 0.187402
 >> iter 17000, loss: 0.256760
 >> iter 18000, loss: 0.279777
 >> iter 19000, loss: 0.223285
 >> iter 20000, loss: 0.173790
   Number of active neurons: 4
 >> iter 21000, loss: 0.332957
 >> iter 22000, loss: 0.276109
 >> iter 23000, loss: 0.284541
 >> iter 24000, loss: 0.253372
 >> iter 25000, loss: 0.230330
 >> iter 26000, loss: 0.208718
 >> iter 27000, loss: 0.154074
 >> iter 28000, loss: 0.232835
 >> iter 29000, loss: 0.236624
 >> iter 30000, loss: 0.232225
   Number of active neurons: 4
 >> iter 31000, loss: 0.366770
 >> iter 32000, loss: 0.280971
 >> iter 33000, loss: 0.372881
 >> iter 34000, loss: 0.271717
 >> iter 35000, loss: 0.292517
 >> iter 36000, loss: 0.324490
 >> iter 37000, loss: 0.386391
 >> iter 38000, loss: 0.413660
 >> iter 39000, loss: 0.323633
 >> iter 40000, loss: 0.421844
   Number of active neurons: 4
 >> iter 41000, loss: 0.397875
 >> iter 42000, loss: 0.417046
 >> iter 43000, loss: 0.264618
 >> iter 44000, loss: 0.360211
 >> iter 45000, loss: 0.306927
 >> iter 46000, loss: 0.281232
 >> iter 47000, loss: 0.315599
 >> iter 48000, loss: 0.386839
 >> iter 49000, loss: 0.418471
 >> iter 50000, loss: 0.260031
   Number of active neurons: 4
 >> iter 51000, loss: 0.331109
 >> iter 52000, loss: 0.227684
 >> iter 53000, loss: 0.366330
 >> iter 54000, loss: 0.361946
 >> iter 55000, loss: 0.289729
 >> iter 56000, loss: 0.328800
 >> iter 57000, loss: 0.290388
 >> iter 58000, loss: 0.304663
 >> iter 59000, loss: 0.276715
 >> iter 60000, loss: 0.319588
   Number of active neurons: 4
 >> iter 61000, loss: 0.287162
 >> iter 62000, loss: 0.315016
 >> iter 63000, loss: 0.267919
 >> iter 64000, loss: 0.492836
 >> iter 65000, loss: 0.475420
 >> iter 66000, loss: 0.263418
 >> iter 67000, loss: 0.308529
 >> iter 68000, loss: 0.427235
 >> iter 69000, loss: 0.378020
 >> iter 70000, loss: 0.337224
   Number of active neurons: 4
 >> iter 71000, loss: 0.385444
 >> iter 72000, loss: 0.287726
 >> iter 73000, loss: 0.272369
 >> iter 74000, loss: 0.285541
 >> iter 75000, loss: 0.441470
 >> iter 76000, loss: 0.453191
 >> iter 77000, loss: 0.361601
 >> iter 78000, loss: 0.354997
 >> iter 79000, loss: 0.341837
 >> iter 80000, loss: 0.387018
   Number of active neurons: 4
 >> iter 81000, loss: 0.426295
 >> iter 82000, loss: 0.278579
 >> iter 83000, loss: 0.281218
 >> iter 84000, loss: 0.287536
 >> iter 85000, loss: 0.310148
 >> iter 86000, loss: 0.270097
 >> iter 87000, loss: 0.261429
 >> iter 88000, loss: 0.307728
 >> iter 89000, loss: 0.261355
 >> iter 90000, loss: 0.185844
   Number of active neurons: 4
 >> iter 91000, loss: 0.229187
 >> iter 92000, loss: 0.194760
 >> iter 93000, loss: 0.280377
 >> iter 94000, loss: 0.196498
 >> iter 95000, loss: 0.294299
 >> iter 96000, loss: 0.332069
 >> iter 97000, loss: 0.256838
 >> iter 98000, loss: 0.276474
 >> iter 99000, loss: 0.302677
 >> iter 100000, loss: 0.281007
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.312557
 >> iter 2000, loss: 11.731236
 >> iter 3000, loss: 7.618320
 >> iter 4000, loss: 4.325762
 >> iter 5000, loss: 2.518504
 >> iter 6000, loss: 1.593829
 >> iter 7000, loss: 1.148755
 >> iter 8000, loss: 0.981901
 >> iter 9000, loss: 0.922505
 >> iter 10000, loss: 0.605615
   Number of active neurons: 4
 >> iter 11000, loss: 0.608990
 >> iter 12000, loss: 0.551480
 >> iter 13000, loss: 0.499217
 >> iter 14000, loss: 0.492745
 >> iter 15000, loss: 0.531453
 >> iter 16000, loss: 0.430985
 >> iter 17000, loss: 0.548893
 >> iter 18000, loss: 0.413945
 >> iter 19000, loss: 0.427097
 >> iter 20000, loss: 0.394420
   Number of active neurons: 4
 >> iter 21000, loss: 0.300533
 >> iter 22000, loss: 0.446532
 >> iter 23000, loss: 0.511231
 >> iter 24000, loss: 0.474181
 >> iter 25000, loss: 0.452875
 >> iter 26000, loss: 0.354771
 >> iter 27000, loss: 0.336248
 >> iter 28000, loss: 0.351984
 >> iter 29000, loss: 0.354903
 >> iter 30000, loss: 0.369974
   Number of active neurons: 4
 >> iter 31000, loss: 0.344990
 >> iter 32000, loss: 0.437204
 >> iter 33000, loss: 0.489542
 >> iter 34000, loss: 0.448376
 >> iter 35000, loss: 0.542380
 >> iter 36000, loss: 0.524426
 >> iter 37000, loss: 0.561819
 >> iter 38000, loss: 0.406307
 >> iter 39000, loss: 0.357822
 >> iter 40000, loss: 0.440043
   Number of active neurons: 4
 >> iter 41000, loss: 0.297446
 >> iter 42000, loss: 0.304161
 >> iter 43000, loss: 0.334105
 >> iter 44000, loss: 0.352093
 >> iter 45000, loss: 0.415480
 >> iter 46000, loss: 0.443531
 >> iter 47000, loss: 0.375727
 >> iter 48000, loss: 0.472967
 >> iter 49000, loss: 0.422965
 >> iter 50000, loss: 0.361247
   Number of active neurons: 4
 >> iter 51000, loss: 0.382621
 >> iter 52000, loss: 0.478167
 >> iter 53000, loss: 0.468537
 >> iter 54000, loss: 0.432889
 >> iter 55000, loss: 0.377472
 >> iter 56000, loss: 0.344312
 >> iter 57000, loss: 0.422861
 >> iter 58000, loss: 0.386779
 >> iter 59000, loss: 0.488271
 >> iter 60000, loss: 0.481635
   Number of active neurons: 4
 >> iter 61000, loss: 0.479326
 >> iter 62000, loss: 0.597903
 >> iter 63000, loss: 0.477964
 >> iter 64000, loss: 0.462240
 >> iter 65000, loss: 0.451200
 >> iter 66000, loss: 0.420585
 >> iter 67000, loss: 0.471562
 >> iter 68000, loss: 0.500617
 >> iter 69000, loss: 0.494166
 >> iter 70000, loss: 0.397822
   Number of active neurons: 4
 >> iter 71000, loss: 0.319359
 >> iter 72000, loss: 0.345278
 >> iter 73000, loss: 0.404851
 >> iter 74000, loss: 0.400660
 >> iter 75000, loss: 0.545458
 >> iter 76000, loss: 0.475762
 >> iter 77000, loss: 0.506437
 >> iter 78000, loss: 0.542487
 >> iter 79000, loss: 0.567336
 >> iter 80000, loss: 0.456209
   Number of active neurons: 4
 >> iter 81000, loss: 0.427580
 >> iter 82000, loss: 0.418459
 >> iter 83000, loss: 0.420785
 >> iter 84000, loss: 0.426083
 >> iter 85000, loss: 0.388186
 >> iter 86000, loss: 0.360553
 >> iter 87000, loss: 0.341859
 >> iter 88000, loss: 0.442470
 >> iter 89000, loss: 0.286042
 >> iter 90000, loss: 0.376634
   Number of active neurons: 4
 >> iter 91000, loss: 0.463851
 >> iter 92000, loss: 0.564989
 >> iter 93000, loss: 0.519790
 >> iter 94000, loss: 0.465799
 >> iter 95000, loss: 0.428480
 >> iter 96000, loss: 0.506844
 >> iter 97000, loss: 0.495927
 >> iter 98000, loss: 0.451560
 >> iter 99000, loss: 0.424605
 >> iter 100000, loss: 0.281877
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 21.037293
 >> iter 2000, loss: 18.735214
 >> iter 3000, loss: 17.828261
 >> iter 4000, loss: 17.557539
 >> iter 5000, loss: 17.393953
 >> iter 6000, loss: 17.399766
 >> iter 7000, loss: 17.334485
 >> iter 8000, loss: 17.377683
 >> iter 9000, loss: 17.326842
 >> iter 10000, loss: 17.376460
   Number of active neurons: 0
 >> iter 11000, loss: 17.324224
 >> iter 12000, loss: 17.376003
 >> iter 13000, loss: 17.320235
 >> iter 14000, loss: 17.374907
 >> iter 15000, loss: 17.320795
 >> iter 16000, loss: 17.374885
 >> iter 17000, loss: 17.322167
 >> iter 18000, loss: 17.374664
 >> iter 19000, loss: 17.320916
 >> iter 20000, loss: 17.374841
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 12.053478
 >> iter 22000, loss: 9.989745
 >> iter 23000, loss: 6.396003
 >> iter 24000, loss: 3.213364
 >> iter 25000, loss: 1.839527
 >> iter 26000, loss: 1.179543
 >> iter 27000, loss: 0.666949
 >> iter 28000, loss: 0.447752
 >> iter 29000, loss: 0.320670
 >> iter 30000, loss: 0.218846
   Number of active neurons: 4
 >> iter 31000, loss: 0.233642
 >> iter 32000, loss: 0.358436
 >> iter 33000, loss: 0.279737
 >> iter 34000, loss: 0.236232
 >> iter 35000, loss: 0.229074
 >> iter 36000, loss: 0.246595
 >> iter 37000, loss: 0.259670
 >> iter 38000, loss: 0.326178
 >> iter 39000, loss: 0.294728
 >> iter 40000, loss: 0.229568
   Number of active neurons: 4
 >> iter 41000, loss: 0.223422
 >> iter 42000, loss: 0.228575
 >> iter 43000, loss: 0.282612
 >> iter 44000, loss: 0.408871
 >> iter 45000, loss: 0.332778
 >> iter 46000, loss: 0.207680
 >> iter 47000, loss: 0.341577
 >> iter 48000, loss: 0.427185
 >> iter 49000, loss: 0.374345
 >> iter 50000, loss: 0.344780
   Number of active neurons: 4
 >> iter 51000, loss: 0.299375
 >> iter 52000, loss: 0.363291
 >> iter 53000, loss: 0.346389
 >> iter 54000, loss: 0.275764
 >> iter 55000, loss: 0.320570
 >> iter 56000, loss: 0.259743
 >> iter 57000, loss: 0.213051
 >> iter 58000, loss: 0.175292
 >> iter 59000, loss: 0.277349
 >> iter 60000, loss: 0.346732
   Number of active neurons: 4
 >> iter 61000, loss: 0.307192
 >> iter 62000, loss: 0.297367
 >> iter 63000, loss: 0.309411
 >> iter 64000, loss: 0.235994
 >> iter 65000, loss: 0.279929
 >> iter 66000, loss: 0.295473
 >> iter 67000, loss: 0.287189
 >> iter 68000, loss: 0.357995
 >> iter 69000, loss: 0.306712
 >> iter 70000, loss: 0.212763
   Number of active neurons: 4
 >> iter 71000, loss: 0.273346
 >> iter 72000, loss: 0.274469
 >> iter 73000, loss: 0.332843
 >> iter 74000, loss: 0.299682
 >> iter 75000, loss: 0.297052
 >> iter 76000, loss: 0.297365
 >> iter 77000, loss: 0.183076
 >> iter 78000, loss: 0.371497
 >> iter 79000, loss: 0.241125
 >> iter 80000, loss: 0.222194
   Number of active neurons: 4
 >> iter 81000, loss: 0.248853
 >> iter 82000, loss: 0.518169
 >> iter 83000, loss: 0.310362
 >> iter 84000, loss: 0.305049
 >> iter 85000, loss: 0.308787
 >> iter 86000, loss: 0.304182
 >> iter 87000, loss: 0.285369
 >> iter 88000, loss: 0.249221
 >> iter 89000, loss: 0.254344
 >> iter 90000, loss: 0.233384
   Number of active neurons: 4
 >> iter 91000, loss: 0.274395
 >> iter 92000, loss: 0.318019
 >> iter 93000, loss: 0.372842
 >> iter 94000, loss: 0.387989
 >> iter 95000, loss: 0.362519
 >> iter 96000, loss: 0.348287
 >> iter 97000, loss: 0.340811
 >> iter 98000, loss: 0.309981
 >> iter 99000, loss: 0.441607
 >> iter 100000, loss: 0.347129
   Number of active neurons: 4
 >> iter 101000, loss: 0.330804
 >> iter 102000, loss: 0.347560
 >> iter 103000, loss: 0.336218
 >> iter 104000, loss: 0.388238
 >> iter 105000, loss: 0.408324
 >> iter 106000, loss: 0.408348
 >> iter 107000, loss: 0.247118
 >> iter 108000, loss: 0.437612
 >> iter 109000, loss: 0.424190
 >> iter 110000, loss: 0.327589
   Number of active neurons: 4
 >> iter 111000, loss: 0.362270
 >> iter 112000, loss: 0.414628
 >> iter 113000, loss: 0.414196
 >> iter 114000, loss: 0.363721
 >> iter 115000, loss: 0.387511
 >> iter 116000, loss: 0.330588
 >> iter 117000, loss: 0.320822
 >> iter 118000, loss: 0.346721
 >> iter 119000, loss: 0.358239
 >> iter 120000, loss: 0.320592
   Number of active neurons: 4
 >> iter 121000, loss: 0.332472
 >> iter 122000, loss: 0.320858
 >> iter 123000, loss: 0.420407
 >> iter 124000, loss: 0.397934
 >> iter 125000, loss: 0.322083
 >> iter 126000, loss: 0.283283
 >> iter 127000, loss: 0.340827
 >> iter 128000, loss: 0.296811
 >> iter 129000, loss: 0.323288
 >> iter 130000, loss: 0.399737
   Number of active neurons: 4
 >> iter 131000, loss: 0.434081
 >> iter 132000, loss: 0.362776
 >> iter 133000, loss: 0.410717
 >> iter 134000, loss: 0.315170
 >> iter 135000, loss: 0.261012
 >> iter 136000, loss: 0.282240
 >> iter 137000, loss: 0.303391
 >> iter 138000, loss: 0.291933
 >> iter 139000, loss: 0.266701
 >> iter 140000, loss: 0.208318
   Number of active neurons: 4
 >> iter 141000, loss: 0.267352
 >> iter 142000, loss: 0.210370
 >> iter 143000, loss: 0.193607
 >> iter 144000, loss: 0.306325
 >> iter 145000, loss: 0.198867
 >> iter 146000, loss: 0.221117
 >> iter 147000, loss: 0.336670
 >> iter 148000, loss: 0.330453
 >> iter 149000, loss: 0.340234
 >> iter 150000, loss: 0.429632
   Number of active neurons: 4
 >> iter 151000, loss: 0.327756
 >> iter 152000, loss: 0.429041
 >> iter 153000, loss: 0.393225
 >> iter 154000, loss: 0.261422
 >> iter 155000, loss: 0.265627
 >> iter 156000, loss: 0.436741
 >> iter 157000, loss: 0.244224
 >> iter 158000, loss: 0.197302
 >> iter 159000, loss: 0.266094
 >> iter 160000, loss: 0.212513
   Number of active neurons: 4
 >> iter 161000, loss: 0.202285
 >> iter 162000, loss: 0.273532
 >> iter 163000, loss: 0.310178
 >> iter 164000, loss: 0.239355
 >> iter 165000, loss: 0.242688
 >> iter 166000, loss: 0.264365
 >> iter 167000, loss: 0.231693
 >> iter 168000, loss: 0.274830
 >> iter 169000, loss: 0.204700
 >> iter 170000, loss: 0.230169
   Number of active neurons: 4
 >> iter 171000, loss: 0.277020
 >> iter 172000, loss: 0.236238
 >> iter 173000, loss: 0.236672
 >> iter 174000, loss: 0.305199
 >> iter 175000, loss: 0.490958
 >> iter 176000, loss: 0.356199
 >> iter 177000, loss: 0.457884
 >> iter 178000, loss: 0.341083
 >> iter 179000, loss: 0.255309
 >> iter 180000, loss: 0.249517
   Number of active neurons: 4
 >> iter 181000, loss: 0.316549
 >> iter 182000, loss: 0.261660
 >> iter 183000, loss: 0.277066
 >> iter 184000, loss: 0.198171
 >> iter 185000, loss: 0.241547
 >> iter 186000, loss: 0.232024
 >> iter 187000, loss: 0.360257
 >> iter 188000, loss: 0.358812
 >> iter 189000, loss: 0.385018
 >> iter 190000, loss: 0.293775
   Number of active neurons: 4
 >> iter 191000, loss: 0.288737
 >> iter 192000, loss: 0.264956
 >> iter 193000, loss: 0.329960
 >> iter 194000, loss: 0.406646
 >> iter 195000, loss: 0.368210
 >> iter 196000, loss: 0.296204
 >> iter 197000, loss: 0.275159
 >> iter 198000, loss: 0.248957
 >> iter 199000, loss: 0.336478
 >> iter 200000, loss: 0.353149
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.379681
 >> iter 2000, loss: 11.931512
 >> iter 3000, loss: 9.341853
 >> iter 4000, loss: 7.117004
 >> iter 5000, loss: 4.014540
 >> iter 6000, loss: 1.954505
 >> iter 7000, loss: 1.164810
 >> iter 8000, loss: 0.611340
 >> iter 9000, loss: 0.380794
 >> iter 10000, loss: 0.343317
   Number of active neurons: 4
 >> iter 11000, loss: 0.303212
 >> iter 12000, loss: 0.284718
 >> iter 13000, loss: 0.229143
 >> iter 14000, loss: 0.284754
 >> iter 15000, loss: 0.236889
 >> iter 16000, loss: 0.292034
 >> iter 17000, loss: 0.256001
 >> iter 18000, loss: 0.223590
 >> iter 19000, loss: 0.321542
 >> iter 20000, loss: 0.375661
   Number of active neurons: 4
 >> iter 21000, loss: 0.333757
 >> iter 22000, loss: 0.304753
 >> iter 23000, loss: 0.278517
 >> iter 24000, loss: 0.363542
 >> iter 25000, loss: 0.234380
 >> iter 26000, loss: 0.305095
 >> iter 27000, loss: 0.360398
 >> iter 28000, loss: 0.349959
 >> iter 29000, loss: 0.276705
 >> iter 30000, loss: 0.453339
   Number of active neurons: 4
 >> iter 31000, loss: 0.416380
 >> iter 32000, loss: 0.460105
 >> iter 33000, loss: 0.448750
 >> iter 34000, loss: 0.508372
 >> iter 35000, loss: 0.402269
 >> iter 36000, loss: 0.366705
 >> iter 37000, loss: 0.449754
 >> iter 38000, loss: 0.463381
 >> iter 39000, loss: 0.540587
 >> iter 40000, loss: 0.478184
   Number of active neurons: 4
 >> iter 41000, loss: 0.428345
 >> iter 42000, loss: 0.484037
 >> iter 43000, loss: 0.421366
 >> iter 44000, loss: 0.406945
 >> iter 45000, loss: 0.430171
 >> iter 46000, loss: 0.319619
 >> iter 47000, loss: 0.357069
 >> iter 48000, loss: 0.339852
 >> iter 49000, loss: 0.375774
 >> iter 50000, loss: 0.298201
   Number of active neurons: 4
 >> iter 51000, loss: 0.409465
 >> iter 52000, loss: 0.459978
 >> iter 53000, loss: 0.405455
 >> iter 54000, loss: 0.394300
 >> iter 55000, loss: 0.365436
 >> iter 56000, loss: 0.393196
 >> iter 57000, loss: 0.358079
 >> iter 58000, loss: 0.306376
 >> iter 59000, loss: 0.311644
 >> iter 60000, loss: 0.381374
   Number of active neurons: 4
 >> iter 61000, loss: 0.313523
 >> iter 62000, loss: 0.270123
 >> iter 63000, loss: 0.311891
 >> iter 64000, loss: 0.294561
 >> iter 65000, loss: 0.309646
 >> iter 66000, loss: 0.492314
 >> iter 67000, loss: 0.389471
 >> iter 68000, loss: 0.405241
 >> iter 69000, loss: 0.435571
 >> iter 70000, loss: 0.389773
   Number of active neurons: 4
 >> iter 71000, loss: 0.354631
 >> iter 72000, loss: 0.303864
 >> iter 73000, loss: 0.269392
 >> iter 74000, loss: 0.388821
 >> iter 75000, loss: 0.372751
 >> iter 76000, loss: 0.322513
 >> iter 77000, loss: 0.309352
 >> iter 78000, loss: 0.294096
 >> iter 79000, loss: 0.217113
 >> iter 80000, loss: 0.311105
   Number of active neurons: 4
 >> iter 81000, loss: 0.340517
 >> iter 82000, loss: 0.311557
 >> iter 83000, loss: 0.253360
 >> iter 84000, loss: 0.345493
 >> iter 85000, loss: 0.339017
 >> iter 86000, loss: 0.244013
 >> iter 87000, loss: 0.373122
 >> iter 88000, loss: 0.381533
 >> iter 89000, loss: 0.512975
 >> iter 90000, loss: 0.378451
   Number of active neurons: 4
 >> iter 91000, loss: 0.427365
 >> iter 92000, loss: 0.346016
 >> iter 93000, loss: 0.250159
 >> iter 94000, loss: 0.263116
 >> iter 95000, loss: 0.292869
 >> iter 96000, loss: 0.326316
 >> iter 97000, loss: 0.355240
 >> iter 98000, loss: 0.406253
 >> iter 99000, loss: 0.380146
 >> iter 100000, loss: 0.480657
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.484407
 >> iter 2000, loss: 13.029212
 >> iter 3000, loss: 10.152525
 >> iter 4000, loss: 6.930035
 >> iter 5000, loss: 5.187478
 >> iter 6000, loss: 4.357280
 >> iter 7000, loss: 3.800476
 >> iter 8000, loss: 3.370944
 >> iter 9000, loss: 3.171436
 >> iter 10000, loss: 3.042360
   Number of active neurons: 4
 >> iter 11000, loss: 3.041551
 >> iter 12000, loss: 3.085450
 >> iter 13000, loss: 3.059489
 >> iter 14000, loss: 2.951212
 >> iter 15000, loss: 2.955700
 >> iter 16000, loss: 2.975734
 >> iter 17000, loss: 3.051282
 >> iter 18000, loss: 3.009748
 >> iter 19000, loss: 3.086824
 >> iter 20000, loss: 3.174140
   Number of active neurons: 4
 >> iter 21000, loss: 3.150816
 >> iter 22000, loss: 3.049036
 >> iter 23000, loss: 3.004914
 >> iter 24000, loss: 3.080261
 >> iter 25000, loss: 2.978785
 >> iter 26000, loss: 2.900751
 >> iter 27000, loss: 2.997895
 >> iter 28000, loss: 3.033456
 >> iter 29000, loss: 2.966611
 >> iter 30000, loss: 2.984664
   Number of active neurons: 4
 >> iter 31000, loss: 2.965286
 >> iter 32000, loss: 2.922308
 >> iter 33000, loss: 2.905982
 >> iter 34000, loss: 2.972725
 >> iter 35000, loss: 2.967214
 >> iter 36000, loss: 2.917276
 >> iter 37000, loss: 3.046846
 >> iter 38000, loss: 3.016807
 >> iter 39000, loss: 2.939147
 >> iter 40000, loss: 3.007371
   Number of active neurons: 4
 >> iter 41000, loss: 2.992305
 >> iter 42000, loss: 3.037755
 >> iter 43000, loss: 3.020950
 >> iter 44000, loss: 2.942209
 >> iter 45000, loss: 2.964888
 >> iter 46000, loss: 2.891731
 >> iter 47000, loss: 2.914286
 >> iter 48000, loss: 3.091555
 >> iter 49000, loss: 2.985406
 >> iter 50000, loss: 2.867418
   Number of active neurons: 4
 >> iter 51000, loss: 2.862119
 >> iter 52000, loss: 2.899908
 >> iter 53000, loss: 2.982258
 >> iter 54000, loss: 3.139329
 >> iter 55000, loss: 2.970074
 >> iter 56000, loss: 2.936392
 >> iter 57000, loss: 2.972855
 >> iter 58000, loss: 2.948667
 >> iter 59000, loss: 2.933077
 >> iter 60000, loss: 2.915252
   Number of active neurons: 4
 >> iter 61000, loss: 2.823230
 >> iter 62000, loss: 2.935113
 >> iter 63000, loss: 2.975172
 >> iter 64000, loss: 3.004056
 >> iter 65000, loss: 2.964891
 >> iter 66000, loss: 2.971942
 >> iter 67000, loss: 2.981957
 >> iter 68000, loss: 3.152910
 >> iter 69000, loss: 2.965726
 >> iter 70000, loss: 3.019463
   Number of active neurons: 4
 >> iter 71000, loss: 2.951183
 >> iter 72000, loss: 3.028145
 >> iter 73000, loss: 3.001659
 >> iter 74000, loss: 3.115685
 >> iter 75000, loss: 3.019150
 >> iter 76000, loss: 2.951917
 >> iter 77000, loss: 2.990828
 >> iter 78000, loss: 3.071667
 >> iter 79000, loss: 2.911475
 >> iter 80000, loss: 2.993396
   Number of active neurons: 4
 >> iter 81000, loss: 2.850338
 >> iter 82000, loss: 2.999398
 >> iter 83000, loss: 2.940024
 >> iter 84000, loss: 2.939913
 >> iter 85000, loss: 2.980140
 >> iter 86000, loss: 2.900491
 >> iter 87000, loss: 3.015108
 >> iter 88000, loss: 3.058152
 >> iter 89000, loss: 3.090196
 >> iter 90000, loss: 3.067243
   Number of active neurons: 4
 >> iter 91000, loss: 3.080613
 >> iter 92000, loss: 3.127703
 >> iter 93000, loss: 3.011449
 >> iter 94000, loss: 3.112406
 >> iter 95000, loss: 2.971218
 >> iter 96000, loss: 3.026193
 >> iter 97000, loss: 2.987263
 >> iter 98000, loss: 2.925223
 >> iter 99000, loss: 3.045947
 >> iter 100000, loss: 3.109436
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 4.87390252195
   - Test - Long: 0.17999100045
   - Test - Big: 5.05394946051
   - Test - A: 0.626624891674
   - Test - B: 18.5987600827
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.363260
 >> iter 2000, loss: 14.035017
 >> iter 3000, loss: 11.774511
 >> iter 4000, loss: 9.020076
 >> iter 5000, loss: 6.847498
 >> iter 6000, loss: 4.945343
 >> iter 7000, loss: 4.011272
 >> iter 8000, loss: 3.411466
 >> iter 9000, loss: 3.204400
 >> iter 10000, loss: 3.063819
   Number of active neurons: 4
 >> iter 11000, loss: 3.093110
 >> iter 12000, loss: 3.072130
 >> iter 13000, loss: 2.666879
 >> iter 14000, loss: 2.639532
 >> iter 15000, loss: 2.483545
 >> iter 16000, loss: 2.126775
 >> iter 17000, loss: 1.993327
 >> iter 18000, loss: 1.620562
 >> iter 19000, loss: 1.084147
 >> iter 20000, loss: 1.100960
   Number of active neurons: 4
 >> iter 21000, loss: 1.115660
 >> iter 22000, loss: 1.148210
 >> iter 23000, loss: 1.412661
 >> iter 24000, loss: 1.351858
 >> iter 25000, loss: 1.161497
 >> iter 26000, loss: 1.031598
 >> iter 27000, loss: 0.883025
 >> iter 28000, loss: 0.889686
 >> iter 29000, loss: 0.946096
 >> iter 30000, loss: 0.890915
   Number of active neurons: 4
 >> iter 31000, loss: 0.850615
 >> iter 32000, loss: 0.943440
 >> iter 33000, loss: 0.739380
 >> iter 34000, loss: 0.771456
 >> iter 35000, loss: 0.775814
 >> iter 36000, loss: 0.764793
 >> iter 37000, loss: 0.684966
 >> iter 38000, loss: 0.855168
 >> iter 39000, loss: 0.765712
 >> iter 40000, loss: 0.765000
   Number of active neurons: 4
 >> iter 41000, loss: 0.754665
 >> iter 42000, loss: 0.821562
 >> iter 43000, loss: 0.783541
 >> iter 44000, loss: 0.651903
 >> iter 45000, loss: 0.682825
 >> iter 46000, loss: 0.759978
 >> iter 47000, loss: 0.813046
 >> iter 48000, loss: 0.708258
 >> iter 49000, loss: 0.764850
 >> iter 50000, loss: 0.633936
   Number of active neurons: 4
 >> iter 51000, loss: 0.957525
 >> iter 52000, loss: 0.958319
 >> iter 53000, loss: 0.742116
 >> iter 54000, loss: 0.738330
 >> iter 55000, loss: 0.604584
 >> iter 56000, loss: 0.675318
 >> iter 57000, loss: 0.806076
 >> iter 58000, loss: 0.774017
 >> iter 59000, loss: 0.677417
 >> iter 60000, loss: 0.665189
   Number of active neurons: 4
 >> iter 61000, loss: 0.550372
 >> iter 62000, loss: 0.602522
 >> iter 63000, loss: 0.549711
 >> iter 64000, loss: 0.541367
 >> iter 65000, loss: 0.610499
 >> iter 66000, loss: 0.683382
 >> iter 67000, loss: 0.676944
 >> iter 68000, loss: 0.601792
 >> iter 69000, loss: 0.566685
 >> iter 70000, loss: 0.531647
   Number of active neurons: 4
 >> iter 71000, loss: 0.509275
 >> iter 72000, loss: 0.602188
 >> iter 73000, loss: 0.496709
 >> iter 74000, loss: 0.541928
 >> iter 75000, loss: 0.510146
 >> iter 76000, loss: 0.409119
 >> iter 77000, loss: 0.385557
 >> iter 78000, loss: 0.600986
 >> iter 79000, loss: 0.468565
 >> iter 80000, loss: 0.465646
   Number of active neurons: 4
 >> iter 81000, loss: 0.433492
 >> iter 82000, loss: 0.727301
 >> iter 83000, loss: 0.599012
 >> iter 84000, loss: 0.654137
 >> iter 85000, loss: 0.609114
 >> iter 86000, loss: 0.540500
 >> iter 87000, loss: 0.586952
 >> iter 88000, loss: 0.550580
 >> iter 89000, loss: 0.524922
 >> iter 90000, loss: 0.569836
   Number of active neurons: 4
 >> iter 91000, loss: 0.508863
 >> iter 92000, loss: 0.404962
 >> iter 93000, loss: 0.368890
 >> iter 94000, loss: 0.451965
 >> iter 95000, loss: 0.569344
 >> iter 96000, loss: 0.527314
 >> iter 97000, loss: 0.593086
 >> iter 98000, loss: 0.496460
 >> iter 99000, loss: 0.468074
 >> iter 100000, loss: 0.493283
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 7.82614492367
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.820424
 >> iter 2000, loss: 12.263656
 >> iter 3000, loss: 10.128321
 >> iter 4000, loss: 8.111936
 >> iter 5000, loss: 5.187078
 >> iter 6000, loss: 2.830499
 >> iter 7000, loss: 1.441518
 >> iter 8000, loss: 0.826659
 >> iter 9000, loss: 0.682563
 >> iter 10000, loss: 0.699742
   Number of active neurons: 4
 >> iter 11000, loss: 0.478683
 >> iter 12000, loss: 0.525157
 >> iter 13000, loss: 0.469926
 >> iter 14000, loss: 0.649346
 >> iter 15000, loss: 0.499024
 >> iter 16000, loss: 0.504357
 >> iter 17000, loss: 0.394324
 >> iter 18000, loss: 0.464608
 >> iter 19000, loss: 0.487148
 >> iter 20000, loss: 0.432742
   Number of active neurons: 4
 >> iter 21000, loss: 0.466676
 >> iter 22000, loss: 0.433374
 >> iter 23000, loss: 0.353510
 >> iter 24000, loss: 0.333567
 >> iter 25000, loss: 0.452148
 >> iter 26000, loss: 0.317185
 >> iter 27000, loss: 0.362677
 >> iter 28000, loss: 0.470238
 >> iter 29000, loss: 0.554987
 >> iter 30000, loss: 0.627582
   Number of active neurons: 4
 >> iter 31000, loss: 0.510094
 >> iter 32000, loss: 0.406349
 >> iter 33000, loss: 0.467987
 >> iter 34000, loss: 0.590010
 >> iter 35000, loss: 0.451953
 >> iter 36000, loss: 0.377502
 >> iter 37000, loss: 0.388700
 >> iter 38000, loss: 0.401236
 >> iter 39000, loss: 0.464734
 >> iter 40000, loss: 0.323075
   Number of active neurons: 4
 >> iter 41000, loss: 0.412961
 >> iter 42000, loss: 0.408106
 >> iter 43000, loss: 0.435457
 >> iter 44000, loss: 0.542482
 >> iter 45000, loss: 0.467784
 >> iter 46000, loss: 0.447511
 >> iter 47000, loss: 0.471852
 >> iter 48000, loss: 0.474919
 >> iter 49000, loss: 0.556721
 >> iter 50000, loss: 0.479269
   Number of active neurons: 4
 >> iter 51000, loss: 0.472016
 >> iter 52000, loss: 0.474509
 >> iter 53000, loss: 0.401874
 >> iter 54000, loss: 0.469870
 >> iter 55000, loss: 0.359061
 >> iter 56000, loss: 0.329752
 >> iter 57000, loss: 0.420710
 >> iter 58000, loss: 0.393331
 >> iter 59000, loss: 0.380676
 >> iter 60000, loss: 0.375469
   Number of active neurons: 4
 >> iter 61000, loss: 0.395159
 >> iter 62000, loss: 0.377863
 >> iter 63000, loss: 0.421662
 >> iter 64000, loss: 0.451222
 >> iter 65000, loss: 0.584374
 >> iter 66000, loss: 0.455670
 >> iter 67000, loss: 0.482189
 >> iter 68000, loss: 0.515371
 >> iter 69000, loss: 0.458083
 >> iter 70000, loss: 0.507972
   Number of active neurons: 4
 >> iter 71000, loss: 0.538557
 >> iter 72000, loss: 0.555062
 >> iter 73000, loss: 0.417664
 >> iter 74000, loss: 0.454459
 >> iter 75000, loss: 0.607408
 >> iter 76000, loss: 0.506613
 >> iter 77000, loss: 0.490241
 >> iter 78000, loss: 0.389493
 >> iter 79000, loss: 0.571739
 >> iter 80000, loss: 0.402404
   Number of active neurons: 4
 >> iter 81000, loss: 0.338884
 >> iter 82000, loss: 0.464502
 >> iter 83000, loss: 0.494928
 >> iter 84000, loss: 0.468810
 >> iter 85000, loss: 0.408155
 >> iter 86000, loss: 0.352301
 >> iter 87000, loss: 0.376387
 >> iter 88000, loss: 0.339220
 >> iter 89000, loss: 0.394550
 >> iter 90000, loss: 0.472960
   Number of active neurons: 4
 >> iter 91000, loss: 0.518101
 >> iter 92000, loss: 0.593091
 >> iter 93000, loss: 0.561532
 >> iter 94000, loss: 0.501812
 >> iter 95000, loss: 0.469747
 >> iter 96000, loss: 0.420049
 >> iter 97000, loss: 0.374308
 >> iter 98000, loss: 0.482774
 >> iter 99000, loss: 0.405027
 >> iter 100000, loss: 0.473656
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.837120
 >> iter 2000, loss: 11.233984
 >> iter 3000, loss: 6.841934
 >> iter 4000, loss: 3.550849
 >> iter 5000, loss: 2.137254
 >> iter 6000, loss: 1.388622
 >> iter 7000, loss: 1.065566
 >> iter 8000, loss: 0.909821
 >> iter 9000, loss: 0.749975
 >> iter 10000, loss: 0.618546
   Number of active neurons: 4
 >> iter 11000, loss: 0.536041
 >> iter 12000, loss: 0.613556
 >> iter 13000, loss: 0.608460
 >> iter 14000, loss: 0.588452
 >> iter 15000, loss: 0.532048
 >> iter 16000, loss: 0.462675
 >> iter 17000, loss: 0.414079
 >> iter 18000, loss: 0.359877
 >> iter 19000, loss: 0.395299
 >> iter 20000, loss: 0.303134
   Number of active neurons: 4
 >> iter 21000, loss: 0.389535
 >> iter 22000, loss: 0.359584
 >> iter 23000, loss: 0.402022
 >> iter 24000, loss: 0.528602
 >> iter 25000, loss: 0.427752
 >> iter 26000, loss: 0.603792
 >> iter 27000, loss: 0.536505
 >> iter 28000, loss: 0.528289
 >> iter 29000, loss: 0.638396
 >> iter 30000, loss: 0.528917
   Number of active neurons: 4
 >> iter 31000, loss: 0.432667
 >> iter 32000, loss: 0.413293
 >> iter 33000, loss: 0.384139
 >> iter 34000, loss: 0.591324
 >> iter 35000, loss: 0.471141
 >> iter 36000, loss: 0.488179
 >> iter 37000, loss: 0.516658
 >> iter 38000, loss: 0.465382
 >> iter 39000, loss: 0.584216
 >> iter 40000, loss: 0.550454
   Number of active neurons: 4
 >> iter 41000, loss: 0.603588
 >> iter 42000, loss: 0.570851
 >> iter 43000, loss: 0.556169
 >> iter 44000, loss: 0.368862
 >> iter 45000, loss: 0.413597
 >> iter 46000, loss: 0.503153
 >> iter 47000, loss: 0.626563
 >> iter 48000, loss: 0.489545
 >> iter 49000, loss: 0.491039
 >> iter 50000, loss: 0.390747
   Number of active neurons: 4
 >> iter 51000, loss: 0.585382
 >> iter 52000, loss: 0.470845
 >> iter 53000, loss: 0.449415
 >> iter 54000, loss: 0.480104
 >> iter 55000, loss: 0.457527
 >> iter 56000, loss: 0.431079
 >> iter 57000, loss: 0.487758
 >> iter 58000, loss: 0.477885
 >> iter 59000, loss: 0.477256
 >> iter 60000, loss: 0.560967
   Number of active neurons: 4
 >> iter 61000, loss: 0.536971
 >> iter 62000, loss: 0.612032
 >> iter 63000, loss: 0.584669
 >> iter 64000, loss: 0.559239
 >> iter 65000, loss: 0.570821
 >> iter 66000, loss: 0.629540
 >> iter 67000, loss: 0.557957
 >> iter 68000, loss: 0.545622
 >> iter 69000, loss: 0.504963
 >> iter 70000, loss: 0.463646
   Number of active neurons: 4
 >> iter 71000, loss: 0.506307
 >> iter 72000, loss: 0.470366
 >> iter 73000, loss: 0.442931
 >> iter 74000, loss: 0.635393
 >> iter 75000, loss: 0.425652
 >> iter 76000, loss: 0.341452
 >> iter 77000, loss: 0.363531
 >> iter 78000, loss: 0.446959
 >> iter 79000, loss: 0.546832
 >> iter 80000, loss: 0.586762
   Number of active neurons: 4
 >> iter 81000, loss: 0.513623
 >> iter 82000, loss: 0.597597
 >> iter 83000, loss: 0.680782
 >> iter 84000, loss: 0.536379
 >> iter 85000, loss: 0.554571
 >> iter 86000, loss: 0.427521
 >> iter 87000, loss: 0.450414
 >> iter 88000, loss: 0.429496
 >> iter 89000, loss: 0.450700
 >> iter 90000, loss: 0.683474
   Number of active neurons: 4
 >> iter 91000, loss: 0.596795
 >> iter 92000, loss: 0.538277
 >> iter 93000, loss: 0.578718
 >> iter 94000, loss: 0.686743
 >> iter 95000, loss: 0.567746
 >> iter 96000, loss: 0.537537
 >> iter 97000, loss: 0.519892
 >> iter 98000, loss: 0.543172
 >> iter 99000, loss: 0.616757
 >> iter 100000, loss: 0.568581
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.524755
 >> iter 2000, loss: 12.462759
 >> iter 3000, loss: 8.390141
 >> iter 4000, loss: 5.212581
 >> iter 5000, loss: 3.234131
 >> iter 6000, loss: 2.188965
 >> iter 7000, loss: 1.748988
 >> iter 8000, loss: 1.251906
 >> iter 9000, loss: 1.354998
 >> iter 10000, loss: 1.684909
   Number of active neurons: 4
 >> iter 11000, loss: 1.598559
 >> iter 12000, loss: 1.358491
 >> iter 13000, loss: 1.503772
 >> iter 14000, loss: 1.149617
 >> iter 15000, loss: 0.877163
 >> iter 16000, loss: 0.646503
 >> iter 17000, loss: 0.673152
 >> iter 18000, loss: 0.623187
 >> iter 19000, loss: 0.700063
 >> iter 20000, loss: 0.613470
   Number of active neurons: 4
 >> iter 21000, loss: 0.594117
 >> iter 22000, loss: 0.666233
 >> iter 23000, loss: 0.594499
 >> iter 24000, loss: 0.626873
 >> iter 25000, loss: 0.452740
 >> iter 26000, loss: 0.414135
 >> iter 27000, loss: 0.590746
 >> iter 28000, loss: 0.562808
 >> iter 29000, loss: 0.544092
 >> iter 30000, loss: 0.653924
   Number of active neurons: 4
 >> iter 31000, loss: 0.610391
 >> iter 32000, loss: 0.574563
 >> iter 33000, loss: 0.638343
 >> iter 34000, loss: 0.720641
 >> iter 35000, loss: 0.830208
 >> iter 36000, loss: 0.699398
 >> iter 37000, loss: 0.617885
 >> iter 38000, loss: 0.552375
 >> iter 39000, loss: 0.508286
 >> iter 40000, loss: 0.464526
   Number of active neurons: 4
 >> iter 41000, loss: 0.480899
 >> iter 42000, loss: 0.642928
 >> iter 43000, loss: 0.495826
 >> iter 44000, loss: 0.459639
 >> iter 45000, loss: 0.621021
 >> iter 46000, loss: 0.675815
 >> iter 47000, loss: 0.505254
 >> iter 48000, loss: 0.568590
 >> iter 49000, loss: 0.533196
 >> iter 50000, loss: 0.428109
   Number of active neurons: 4
 >> iter 51000, loss: 0.631405
 >> iter 52000, loss: 0.479936
 >> iter 53000, loss: 0.633848
 >> iter 54000, loss: 0.510279
 >> iter 55000, loss: 0.602097
 >> iter 56000, loss: 0.636520
 >> iter 57000, loss: 0.509861
 >> iter 58000, loss: 0.498915
 >> iter 59000, loss: 0.646597
 >> iter 60000, loss: 0.586106
   Number of active neurons: 4
 >> iter 61000, loss: 0.654425
 >> iter 62000, loss: 0.418331
 >> iter 63000, loss: 0.433831
 >> iter 64000, loss: 0.619786
 >> iter 65000, loss: 0.671933
 >> iter 66000, loss: 0.596141
 >> iter 67000, loss: 0.525549
 >> iter 68000, loss: 0.601682
 >> iter 69000, loss: 0.599238
 >> iter 70000, loss: 0.596521
   Number of active neurons: 4
 >> iter 71000, loss: 0.577294
 >> iter 72000, loss: 0.604431
 >> iter 73000, loss: 0.687054
 >> iter 74000, loss: 0.691538
 >> iter 75000, loss: 0.626871
 >> iter 76000, loss: 0.774120
 >> iter 77000, loss: 0.709996
 >> iter 78000, loss: 0.615457
 >> iter 79000, loss: 0.578342
 >> iter 80000, loss: 0.570730
   Number of active neurons: 4
 >> iter 81000, loss: 0.712059
 >> iter 82000, loss: 0.601466
 >> iter 83000, loss: 0.690686
 >> iter 84000, loss: 0.702555
 >> iter 85000, loss: 0.756575
 >> iter 86000, loss: 0.661445
 >> iter 87000, loss: 0.493549
 >> iter 88000, loss: 0.494312
 >> iter 89000, loss: 0.624222
 >> iter 90000, loss: 0.625468
   Number of active neurons: 4
 >> iter 91000, loss: 0.635826
 >> iter 92000, loss: 0.683718
 >> iter 93000, loss: 0.630360
 >> iter 94000, loss: 0.692057
 >> iter 95000, loss: 0.605861
 >> iter 96000, loss: 0.656974
 >> iter 97000, loss: 0.714485
 >> iter 98000, loss: 0.678219
 >> iter 99000, loss: 0.659944
 >> iter 100000, loss: 0.580778
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.449811
 >> iter 2000, loss: 11.824446
 >> iter 3000, loss: 7.404177
 >> iter 4000, loss: 4.212983
 >> iter 5000, loss: 2.506792
 >> iter 6000, loss: 1.458888
 >> iter 7000, loss: 0.982663
 >> iter 8000, loss: 0.794715
 >> iter 9000, loss: 0.538315
 >> iter 10000, loss: 0.514642
   Number of active neurons: 4
 >> iter 11000, loss: 0.679365
 >> iter 12000, loss: 0.607848
 >> iter 13000, loss: 0.569738
 >> iter 14000, loss: 0.525496
 >> iter 15000, loss: 0.652916
 >> iter 16000, loss: 0.486517
 >> iter 17000, loss: 0.437340
 >> iter 18000, loss: 0.376835
 >> iter 19000, loss: 0.429048
 >> iter 20000, loss: 0.506272
   Number of active neurons: 4
 >> iter 21000, loss: 0.461661
 >> iter 22000, loss: 0.572617
 >> iter 23000, loss: 0.555088
 >> iter 24000, loss: 0.501012
 >> iter 25000, loss: 0.488058
 >> iter 26000, loss: 0.433309
 >> iter 27000, loss: 0.384026
 >> iter 28000, loss: 0.378243
 >> iter 29000, loss: 0.502126
 >> iter 30000, loss: 0.472312
   Number of active neurons: 4
 >> iter 31000, loss: 0.378713
 >> iter 32000, loss: 0.569707
 >> iter 33000, loss: 0.474722
 >> iter 34000, loss: 0.422488
 >> iter 35000, loss: 0.416636
 >> iter 36000, loss: 0.488907
 >> iter 37000, loss: 0.452843
 >> iter 38000, loss: 0.454321
 >> iter 39000, loss: 0.520301
 >> iter 40000, loss: 0.460912
   Number of active neurons: 4
 >> iter 41000, loss: 0.456173
 >> iter 42000, loss: 0.442279
 >> iter 43000, loss: 0.476820
 >> iter 44000, loss: 0.355118
 >> iter 45000, loss: 0.375822
 >> iter 46000, loss: 0.374386
 >> iter 47000, loss: 0.390592
 >> iter 48000, loss: 0.374629
 >> iter 49000, loss: 0.474814
 >> iter 50000, loss: 0.469021
   Number of active neurons: 4
 >> iter 51000, loss: 0.478479
 >> iter 52000, loss: 0.463480
 >> iter 53000, loss: 0.492424
 >> iter 54000, loss: 0.510223
 >> iter 55000, loss: 0.407830
 >> iter 56000, loss: 0.512706
 >> iter 57000, loss: 0.472946
 >> iter 58000, loss: 0.438917
 >> iter 59000, loss: 0.512775
 >> iter 60000, loss: 0.478844
   Number of active neurons: 4
 >> iter 61000, loss: 0.475634
 >> iter 62000, loss: 0.342048
 >> iter 63000, loss: 0.291698
 >> iter 64000, loss: 0.305468
 >> iter 65000, loss: 0.250146
 >> iter 66000, loss: 0.285095
 >> iter 67000, loss: 0.369331
 >> iter 68000, loss: 0.429091
 >> iter 69000, loss: 0.463064
 >> iter 70000, loss: 0.488634
   Number of active neurons: 4
 >> iter 71000, loss: 0.407655
 >> iter 72000, loss: 0.303616
 >> iter 73000, loss: 0.301049
 >> iter 74000, loss: 0.411399
 >> iter 75000, loss: 0.398543
 >> iter 76000, loss: 0.546580
 >> iter 77000, loss: 0.334384
 >> iter 78000, loss: 0.500997
 >> iter 79000, loss: 0.426285
 >> iter 80000, loss: 0.449779
   Number of active neurons: 4
 >> iter 81000, loss: 0.544359
 >> iter 82000, loss: 0.439687
 >> iter 83000, loss: 0.535524
 >> iter 84000, loss: 0.554721
 >> iter 85000, loss: 0.515460
 >> iter 86000, loss: 0.483404
 >> iter 87000, loss: 0.566024
 >> iter 88000, loss: 0.459180
 >> iter 89000, loss: 0.469163
 >> iter 90000, loss: 0.390060
   Number of active neurons: 4
 >> iter 91000, loss: 0.461270
 >> iter 92000, loss: 0.415118
 >> iter 93000, loss: 0.395598
 >> iter 94000, loss: 0.374527
 >> iter 95000, loss: 0.418631
 >> iter 96000, loss: 0.454250
 >> iter 97000, loss: 0.411878
 >> iter 98000, loss: 0.444002
 >> iter 99000, loss: 0.549769
 >> iter 100000, loss: 0.394002
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.223853
 >> iter 2000, loss: 10.728295
 >> iter 3000, loss: 6.560600
 >> iter 4000, loss: 3.783711
 >> iter 5000, loss: 1.970243
 >> iter 6000, loss: 1.265577
 >> iter 7000, loss: 1.090796
 >> iter 8000, loss: 0.922548
 >> iter 9000, loss: 0.873339
 >> iter 10000, loss: 0.606064
   Number of active neurons: 4
 >> iter 11000, loss: 0.465895
 >> iter 12000, loss: 0.490450
 >> iter 13000, loss: 0.469805
 >> iter 14000, loss: 0.465229
 >> iter 15000, loss: 0.397908
 >> iter 16000, loss: 0.441410
 >> iter 17000, loss: 0.568484
 >> iter 18000, loss: 0.696373
 >> iter 19000, loss: 0.485672
 >> iter 20000, loss: 0.455224
   Number of active neurons: 4
 >> iter 21000, loss: 0.332649
 >> iter 22000, loss: 0.299440
 >> iter 23000, loss: 0.504384
 >> iter 24000, loss: 0.494963
 >> iter 25000, loss: 0.496253
 >> iter 26000, loss: 0.597995
 >> iter 27000, loss: 0.660878
 >> iter 28000, loss: 0.519208
 >> iter 29000, loss: 0.407281
 >> iter 30000, loss: 0.519122
   Number of active neurons: 4
 >> iter 31000, loss: 0.378570
 >> iter 32000, loss: 0.475205
 >> iter 33000, loss: 0.447011
 >> iter 34000, loss: 0.430204
 >> iter 35000, loss: 0.598144
 >> iter 36000, loss: 0.574496
 >> iter 37000, loss: 0.575873
 >> iter 38000, loss: 0.505075
 >> iter 39000, loss: 0.526385
 >> iter 40000, loss: 0.559370
   Number of active neurons: 4
 >> iter 41000, loss: 0.556363
 >> iter 42000, loss: 0.436718
 >> iter 43000, loss: 0.498380
 >> iter 44000, loss: 0.544004
 >> iter 45000, loss: 0.526410
 >> iter 46000, loss: 0.527432
 >> iter 47000, loss: 0.330341
 >> iter 48000, loss: 0.483728
 >> iter 49000, loss: 0.509014
 >> iter 50000, loss: 0.405897
   Number of active neurons: 4
 >> iter 51000, loss: 0.391171
 >> iter 52000, loss: 0.343712
 >> iter 53000, loss: 0.531938
 >> iter 54000, loss: 0.468602
 >> iter 55000, loss: 0.439923
 >> iter 56000, loss: 0.433815
 >> iter 57000, loss: 0.545742
 >> iter 58000, loss: 0.456162
 >> iter 59000, loss: 0.510014
 >> iter 60000, loss: 0.525467
   Number of active neurons: 4
 >> iter 61000, loss: 0.568063
 >> iter 62000, loss: 0.541753
 >> iter 63000, loss: 0.554547
 >> iter 64000, loss: 0.539818
 >> iter 65000, loss: 0.536250
 >> iter 66000, loss: 0.451856
 >> iter 67000, loss: 0.500644
 >> iter 68000, loss: 0.379748
 >> iter 69000, loss: 0.503498
 >> iter 70000, loss: 0.506568
   Number of active neurons: 4
 >> iter 71000, loss: 0.508956
 >> iter 72000, loss: 0.595939
 >> iter 73000, loss: 0.643215
 >> iter 74000, loss: 0.606053
 >> iter 75000, loss: 0.626395
 >> iter 76000, loss: 0.600830
 >> iter 77000, loss: 0.522846
 >> iter 78000, loss: 0.482095
 >> iter 79000, loss: 0.473163
 >> iter 80000, loss: 0.685689
   Number of active neurons: 4
 >> iter 81000, loss: 0.607511
 >> iter 82000, loss: 0.480353
 >> iter 83000, loss: 0.452154
 >> iter 84000, loss: 0.519342
 >> iter 85000, loss: 0.536653
 >> iter 86000, loss: 0.430795
 >> iter 87000, loss: 0.567040
 >> iter 88000, loss: 0.669853
 >> iter 89000, loss: 0.503780
 >> iter 90000, loss: 0.531382
   Number of active neurons: 4
 >> iter 91000, loss: 0.626809
 >> iter 92000, loss: 0.443818
 >> iter 93000, loss: 0.573548
 >> iter 94000, loss: 0.544274
 >> iter 95000, loss: 0.500801
 >> iter 96000, loss: 0.541866
 >> iter 97000, loss: 0.610553
 >> iter 98000, loss: 0.718912
 >> iter 99000, loss: 0.640636
 >> iter 100000, loss: 0.502429
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.368656
 >> iter 2000, loss: 13.687728
 >> iter 3000, loss: 10.162942
 >> iter 4000, loss: 10.939520
 >> iter 5000, loss: 9.986261
 >> iter 6000, loss: 8.963843
 >> iter 7000, loss: 5.569331
 >> iter 8000, loss: 3.024407
 >> iter 9000, loss: 1.751072
 >> iter 10000, loss: 0.974280
   Number of active neurons: 4
 >> iter 11000, loss: 0.898575
 >> iter 12000, loss: 0.759710
 >> iter 13000, loss: 0.718273
 >> iter 14000, loss: 0.695032
 >> iter 15000, loss: 0.664890
 >> iter 16000, loss: 0.647230
 >> iter 17000, loss: 0.535491
 >> iter 18000, loss: 0.513034
 >> iter 19000, loss: 0.593146
 >> iter 20000, loss: 0.614628
   Number of active neurons: 4
 >> iter 21000, loss: 0.642859
 >> iter 22000, loss: 0.664996
 >> iter 23000, loss: 0.662221
 >> iter 24000, loss: 0.505359
 >> iter 25000, loss: 0.586256
 >> iter 26000, loss: 0.595622
 >> iter 27000, loss: 0.500593
 >> iter 28000, loss: 0.517898
 >> iter 29000, loss: 0.611827
 >> iter 30000, loss: 0.708822
   Number of active neurons: 4
 >> iter 31000, loss: 0.532154
 >> iter 32000, loss: 0.594726
 >> iter 33000, loss: 0.772233
 >> iter 34000, loss: 0.565631
 >> iter 35000, loss: 0.675792
 >> iter 36000, loss: 0.543980
 >> iter 37000, loss: 0.609608
 >> iter 38000, loss: 0.602588
 >> iter 39000, loss: 0.498009
 >> iter 40000, loss: 0.533447
   Number of active neurons: 4
 >> iter 41000, loss: 0.531138
 >> iter 42000, loss: 0.763262
 >> iter 43000, loss: 0.591162
 >> iter 44000, loss: 0.528164
 >> iter 45000, loss: 0.543473
 >> iter 46000, loss: 0.510687
 >> iter 47000, loss: 0.455916
 >> iter 48000, loss: 0.616771
 >> iter 49000, loss: 0.554127
 >> iter 50000, loss: 0.460692
   Number of active neurons: 4
 >> iter 51000, loss: 0.549074
 >> iter 52000, loss: 0.512709
 >> iter 53000, loss: 0.466760
 >> iter 54000, loss: 0.604086
 >> iter 55000, loss: 0.568359
 >> iter 56000, loss: 0.407340
 >> iter 57000, loss: 0.523087
 >> iter 58000, loss: 0.630512
 >> iter 59000, loss: 0.525851
 >> iter 60000, loss: 0.409525
   Number of active neurons: 4
 >> iter 61000, loss: 0.559447
 >> iter 62000, loss: 0.669594
 >> iter 63000, loss: 0.635188
 >> iter 64000, loss: 0.719708
 >> iter 65000, loss: 0.675462
 >> iter 66000, loss: 0.668340
 >> iter 67000, loss: 0.600580
 >> iter 68000, loss: 0.591736
 >> iter 69000, loss: 0.702214
 >> iter 70000, loss: 0.540302
   Number of active neurons: 4
 >> iter 71000, loss: 0.593642
 >> iter 72000, loss: 0.487996
 >> iter 73000, loss: 0.546650
 >> iter 74000, loss: 0.614528
 >> iter 75000, loss: 0.577848
 >> iter 76000, loss: 0.639261
 >> iter 77000, loss: 0.743282
 >> iter 78000, loss: 0.658920
 >> iter 79000, loss: 0.546060
 >> iter 80000, loss: 0.520415
   Number of active neurons: 4
 >> iter 81000, loss: 0.500531
 >> iter 82000, loss: 0.416629
 >> iter 83000, loss: 0.473071
 >> iter 84000, loss: 0.522647
 >> iter 85000, loss: 0.466589
 >> iter 86000, loss: 0.489313
 >> iter 87000, loss: 0.643512
 >> iter 88000, loss: 0.628486
 >> iter 89000, loss: 0.760691
 >> iter 90000, loss: 0.711772
   Number of active neurons: 4
 >> iter 91000, loss: 0.610679
 >> iter 92000, loss: 0.541728
 >> iter 93000, loss: 0.595049
 >> iter 94000, loss: 0.530004
 >> iter 95000, loss: 0.681781
 >> iter 96000, loss: 0.617309
 >> iter 97000, loss: 0.642430
 >> iter 98000, loss: 0.577905
 >> iter 99000, loss: 0.682388
 >> iter 100000, loss: 0.745361
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.588574
 >> iter 2000, loss: 13.880678
 >> iter 3000, loss: 12.039646
 >> iter 4000, loss: 10.669275
 >> iter 5000, loss: 8.226162
 >> iter 6000, loss: 6.570083
 >> iter 7000, loss: 4.460963
 >> iter 8000, loss: 2.513185
 >> iter 9000, loss: 1.601321
 >> iter 10000, loss: 1.142526
   Number of active neurons: 4
 >> iter 11000, loss: 0.868355
 >> iter 12000, loss: 0.677755
 >> iter 13000, loss: 0.548438
 >> iter 14000, loss: 0.414268
 >> iter 15000, loss: 0.530336
 >> iter 16000, loss: 0.436163
 >> iter 17000, loss: 0.531891
 >> iter 18000, loss: 0.442449
 >> iter 19000, loss: 0.322946
 >> iter 20000, loss: 0.464898
   Number of active neurons: 4
 >> iter 21000, loss: 0.548758
 >> iter 22000, loss: 0.735240
 >> iter 23000, loss: 0.660141
 >> iter 24000, loss: 0.814451
 >> iter 25000, loss: 0.816226
 >> iter 26000, loss: 0.670076
 >> iter 27000, loss: 0.476728
 >> iter 28000, loss: 0.580306
 >> iter 29000, loss: 0.701540
 >> iter 30000, loss: 0.736839
   Number of active neurons: 4
 >> iter 31000, loss: 0.811173
 >> iter 32000, loss: 0.606300
 >> iter 33000, loss: 0.631166
 >> iter 34000, loss: 0.573257
 >> iter 35000, loss: 0.795070
 >> iter 36000, loss: 0.859440
 >> iter 37000, loss: 0.919054
 >> iter 38000, loss: 0.804079
 >> iter 39000, loss: 0.727385
 >> iter 40000, loss: 0.702751
   Number of active neurons: 4
 >> iter 41000, loss: 0.774850
 >> iter 42000, loss: 0.645560
 >> iter 43000, loss: 0.688043
 >> iter 44000, loss: 0.718602
 >> iter 45000, loss: 0.852347
 >> iter 46000, loss: 0.768697
 >> iter 47000, loss: 0.628194
 >> iter 48000, loss: 0.866817
 >> iter 49000, loss: 0.858320
 >> iter 50000, loss: 0.762968
   Number of active neurons: 4
 >> iter 51000, loss: 0.777798
 >> iter 52000, loss: 0.696555
 >> iter 53000, loss: 0.714190
 >> iter 54000, loss: 0.614023
 >> iter 55000, loss: 0.589237
 >> iter 56000, loss: 0.562659
 >> iter 57000, loss: 0.696158
 >> iter 58000, loss: 0.854923
 >> iter 59000, loss: 0.591981
 >> iter 60000, loss: 0.607329
   Number of active neurons: 4
 >> iter 61000, loss: 0.553231
 >> iter 62000, loss: 0.582345
 >> iter 63000, loss: 0.655905
 >> iter 64000, loss: 0.841205
 >> iter 65000, loss: 0.875337
 >> iter 66000, loss: 0.800382
 >> iter 67000, loss: 0.718227
 >> iter 68000, loss: 0.824817
 >> iter 69000, loss: 0.674150
 >> iter 70000, loss: 0.604011
   Number of active neurons: 4
 >> iter 71000, loss: 0.763886
 >> iter 72000, loss: 0.778919
 >> iter 73000, loss: 0.749412
 >> iter 74000, loss: 0.671932
 >> iter 75000, loss: 0.762392
 >> iter 76000, loss: 0.745437
 >> iter 77000, loss: 0.693989
 >> iter 78000, loss: 0.730159
 >> iter 79000, loss: 0.706477
 >> iter 80000, loss: 0.608113
   Number of active neurons: 4
 >> iter 81000, loss: 0.684685
 >> iter 82000, loss: 0.948207
 >> iter 83000, loss: 0.916450
 >> iter 84000, loss: 0.822844
 >> iter 85000, loss: 0.635416
 >> iter 86000, loss: 0.679729
 >> iter 87000, loss: 0.682396
 >> iter 88000, loss: 0.704980
 >> iter 89000, loss: 0.632394
 >> iter 90000, loss: 0.691936
   Number of active neurons: 4
 >> iter 91000, loss: 0.739261
 >> iter 92000, loss: 0.813009
 >> iter 93000, loss: 0.674206
 >> iter 94000, loss: 0.600125
 >> iter 95000, loss: 0.712777
 >> iter 96000, loss: 0.701116
 >> iter 97000, loss: 0.579487
 >> iter 98000, loss: 0.637893
 >> iter 99000, loss: 0.613135
 >> iter 100000, loss: 0.670664
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.100159
 >> iter 2000, loss: 12.217016
 >> iter 3000, loss: 9.267528
 >> iter 4000, loss: 6.172596
 >> iter 5000, loss: 3.720568
 >> iter 6000, loss: 1.962293
 >> iter 7000, loss: 1.312058
 >> iter 8000, loss: 1.002782
 >> iter 9000, loss: 0.869971
 >> iter 10000, loss: 0.729587
   Number of active neurons: 4
 >> iter 11000, loss: 0.601079
 >> iter 12000, loss: 0.662255
 >> iter 13000, loss: 0.770203
 >> iter 14000, loss: 0.702813
 >> iter 15000, loss: 0.662975
 >> iter 16000, loss: 0.593704
 >> iter 17000, loss: 0.725514
 >> iter 18000, loss: 0.676005
 >> iter 19000, loss: 0.558066
 >> iter 20000, loss: 0.501436
   Number of active neurons: 4
 >> iter 21000, loss: 0.494857
 >> iter 22000, loss: 0.430346
 >> iter 23000, loss: 0.516895
 >> iter 24000, loss: 0.422890
 >> iter 25000, loss: 0.341866
 >> iter 26000, loss: 0.354202
 >> iter 27000, loss: 0.500761
 >> iter 28000, loss: 0.450285
 >> iter 29000, loss: 0.771020
 >> iter 30000, loss: 0.636239
   Number of active neurons: 4
 >> iter 31000, loss: 0.490454
 >> iter 32000, loss: 0.664246
 >> iter 33000, loss: 0.611585
 >> iter 34000, loss: 0.493234
 >> iter 35000, loss: 0.518556
 >> iter 36000, loss: 0.516710
 >> iter 37000, loss: 0.548177
 >> iter 38000, loss: 0.492608
 >> iter 39000, loss: 0.441440
 >> iter 40000, loss: 0.440785
   Number of active neurons: 4
 >> iter 41000, loss: 0.421670
 >> iter 42000, loss: 0.582525
 >> iter 43000, loss: 0.550580
 >> iter 44000, loss: 0.481191
 >> iter 45000, loss: 0.541744
 >> iter 46000, loss: 0.480257
 >> iter 47000, loss: 0.340046
 >> iter 48000, loss: 0.569491
 >> iter 49000, loss: 0.496211
 >> iter 50000, loss: 0.418040
   Number of active neurons: 4
 >> iter 51000, loss: 0.419438
 >> iter 52000, loss: 0.431039
 >> iter 53000, loss: 0.432470
 >> iter 54000, loss: 0.406505
 >> iter 55000, loss: 0.387551
 >> iter 56000, loss: 0.522881
 >> iter 57000, loss: 0.453353
 >> iter 58000, loss: 0.577688
 >> iter 59000, loss: 0.498011
 >> iter 60000, loss: 0.612356
   Number of active neurons: 4
 >> iter 61000, loss: 0.641188
 >> iter 62000, loss: 0.562838
 >> iter 63000, loss: 0.488549
 >> iter 64000, loss: 0.397355
 >> iter 65000, loss: 0.391710
 >> iter 66000, loss: 0.489932
 >> iter 67000, loss: 0.483002
 >> iter 68000, loss: 0.440708
 >> iter 69000, loss: 0.405212
 >> iter 70000, loss: 0.606677
   Number of active neurons: 4
 >> iter 71000, loss: 0.533150
 >> iter 72000, loss: 0.547912
 >> iter 73000, loss: 0.465489
 >> iter 74000, loss: 0.698060
 >> iter 75000, loss: 0.625622
 >> iter 76000, loss: 0.583077
 >> iter 77000, loss: 0.514530
 >> iter 78000, loss: 0.508732
 >> iter 79000, loss: 0.482308
 >> iter 80000, loss: 0.450704
   Number of active neurons: 4
 >> iter 81000, loss: 0.500049
 >> iter 82000, loss: 0.700178
 >> iter 83000, loss: 0.427554
 >> iter 84000, loss: 0.452766
 >> iter 85000, loss: 0.491075
 >> iter 86000, loss: 0.516571
 >> iter 87000, loss: 0.504897
 >> iter 88000, loss: 0.498190
 >> iter 89000, loss: 0.474162
 >> iter 90000, loss: 0.553806
   Number of active neurons: 4
 >> iter 91000, loss: 0.523087
 >> iter 92000, loss: 0.631627
 >> iter 93000, loss: 0.483187
 >> iter 94000, loss: 0.521428
 >> iter 95000, loss: 0.599896
 >> iter 96000, loss: 0.543691
 >> iter 97000, loss: 0.468994
 >> iter 98000, loss: 0.462398
 >> iter 99000, loss: 0.467649
 >> iter 100000, loss: 0.550974
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.355209
 >> iter 2000, loss: 13.132982
 >> iter 3000, loss: 10.181022
 >> iter 4000, loss: 5.172308
 >> iter 5000, loss: 2.561432
 >> iter 6000, loss: 1.297699
 >> iter 7000, loss: 0.802049
 >> iter 8000, loss: 0.428304
 >> iter 9000, loss: 0.300436
 >> iter 10000, loss: 0.259951
   Number of active neurons: 4
 >> iter 11000, loss: 0.329592
 >> iter 12000, loss: 0.221100
 >> iter 13000, loss: 0.190482
 >> iter 14000, loss: 0.135015
 >> iter 15000, loss: 0.207966
 >> iter 16000, loss: 0.262420
 >> iter 17000, loss: 0.227879
 >> iter 18000, loss: 0.247963
 >> iter 19000, loss: 0.251756
 >> iter 20000, loss: 0.312142
   Number of active neurons: 4
 >> iter 21000, loss: 0.427990
 >> iter 22000, loss: 0.334906
 >> iter 23000, loss: 0.302246
 >> iter 24000, loss: 0.317658
 >> iter 25000, loss: 0.306356
 >> iter 26000, loss: 0.239434
 >> iter 27000, loss: 0.283411
 >> iter 28000, loss: 0.302611
 >> iter 29000, loss: 0.318878
 >> iter 30000, loss: 0.357718
   Number of active neurons: 4
 >> iter 31000, loss: 0.259977
 >> iter 32000, loss: 0.178344
 >> iter 33000, loss: 0.265771
 >> iter 34000, loss: 0.296623
 >> iter 35000, loss: 0.285554
 >> iter 36000, loss: 0.244980
 >> iter 37000, loss: 0.256699
 >> iter 38000, loss: 0.250698
 >> iter 39000, loss: 0.213946
 >> iter 40000, loss: 0.206857
   Number of active neurons: 4
 >> iter 41000, loss: 0.177461
 >> iter 42000, loss: 0.329508
 >> iter 43000, loss: 0.240817
 >> iter 44000, loss: 0.352530
 >> iter 45000, loss: 0.282406
 >> iter 46000, loss: 0.255629
 >> iter 47000, loss: 0.228032
 >> iter 48000, loss: 0.243660
 >> iter 49000, loss: 0.302191
 >> iter 50000, loss: 0.347464
   Number of active neurons: 4
 >> iter 51000, loss: 0.347836
 >> iter 52000, loss: 0.317288
 >> iter 53000, loss: 0.254234
 >> iter 54000, loss: 0.225529
 >> iter 55000, loss: 0.160313
 >> iter 56000, loss: 0.313845
 >> iter 57000, loss: 0.294179
 >> iter 58000, loss: 0.412326
 >> iter 59000, loss: 0.420448
 >> iter 60000, loss: 0.341504
   Number of active neurons: 4
 >> iter 61000, loss: 0.243254
 >> iter 62000, loss: 0.227535
 >> iter 63000, loss: 0.267487
 >> iter 64000, loss: 0.296955
 >> iter 65000, loss: 0.349862
 >> iter 66000, loss: 0.280862
 >> iter 67000, loss: 0.343575
 >> iter 68000, loss: 0.267776
 >> iter 69000, loss: 0.263215
 >> iter 70000, loss: 0.253406
   Number of active neurons: 4
 >> iter 71000, loss: 0.220876
 >> iter 72000, loss: 0.229115
 >> iter 73000, loss: 0.355421
 >> iter 74000, loss: 0.287478
 >> iter 75000, loss: 0.243057
 >> iter 76000, loss: 0.239210
 >> iter 77000, loss: 0.224125
 >> iter 78000, loss: 0.209898
 >> iter 79000, loss: 0.315935
 >> iter 80000, loss: 0.224429
   Number of active neurons: 4
 >> iter 81000, loss: 0.197316
 >> iter 82000, loss: 0.190017
 >> iter 83000, loss: 0.191135
 >> iter 84000, loss: 0.226513
 >> iter 85000, loss: 0.289243
 >> iter 86000, loss: 0.264103
 >> iter 87000, loss: 0.259229
 >> iter 88000, loss: 0.237556
 >> iter 89000, loss: 0.307378
 >> iter 90000, loss: 0.233776
   Number of active neurons: 4
 >> iter 91000, loss: 0.296715
 >> iter 92000, loss: 0.176940
 >> iter 93000, loss: 0.224481
 >> iter 94000, loss: 0.244976
 >> iter 95000, loss: 0.203499
 >> iter 96000, loss: 0.186161
 >> iter 97000, loss: 0.207660
 >> iter 98000, loss: 0.193655
 >> iter 99000, loss: 0.257373
 >> iter 100000, loss: 0.245999
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.747819
 >> iter 2000, loss: 12.765546
 >> iter 3000, loss: 10.507056
 >> iter 4000, loss: 8.084218
 >> iter 5000, loss: 5.406917
 >> iter 6000, loss: 2.928014
 >> iter 7000, loss: 1.655924
 >> iter 8000, loss: 1.234221
 >> iter 9000, loss: 0.876124
 >> iter 10000, loss: 0.851775
   Number of active neurons: 4
 >> iter 11000, loss: 0.657116
 >> iter 12000, loss: 0.621707
 >> iter 13000, loss: 0.564131
 >> iter 14000, loss: 0.651450
 >> iter 15000, loss: 0.554834
 >> iter 16000, loss: 0.606965
 >> iter 17000, loss: 0.698467
 >> iter 18000, loss: 0.564218
 >> iter 19000, loss: 0.522953
 >> iter 20000, loss: 0.570444
   Number of active neurons: 4
 >> iter 21000, loss: 0.493256
 >> iter 22000, loss: 0.489079
 >> iter 23000, loss: 0.496906
 >> iter 24000, loss: 0.501474
 >> iter 25000, loss: 0.499085
 >> iter 26000, loss: 0.368131
 >> iter 27000, loss: 0.344314
 >> iter 28000, loss: 0.376261
 >> iter 29000, loss: 0.433929
 >> iter 30000, loss: 0.466730
   Number of active neurons: 4
 >> iter 31000, loss: 0.594640
 >> iter 32000, loss: 0.628013
 >> iter 33000, loss: 0.590996
 >> iter 34000, loss: 0.651733
 >> iter 35000, loss: 0.638483
 >> iter 36000, loss: 0.402581
 >> iter 37000, loss: 0.510843
 >> iter 38000, loss: 0.578574
 >> iter 39000, loss: 0.526186
 >> iter 40000, loss: 0.537311
   Number of active neurons: 4
 >> iter 41000, loss: 0.392551
 >> iter 42000, loss: 0.495361
 >> iter 43000, loss: 0.611392
 >> iter 44000, loss: 0.459457
 >> iter 45000, loss: 0.422273
 >> iter 46000, loss: 0.418357
 >> iter 47000, loss: 0.392877
 >> iter 48000, loss: 0.418097
 >> iter 49000, loss: 0.465149
 >> iter 50000, loss: 0.501798
   Number of active neurons: 4
 >> iter 51000, loss: 0.610838
 >> iter 52000, loss: 0.443669
 >> iter 53000, loss: 0.375108
 >> iter 54000, loss: 0.600137
 >> iter 55000, loss: 0.592806
 >> iter 56000, loss: 0.542800
 >> iter 57000, loss: 0.445423
 >> iter 58000, loss: 0.456784
 >> iter 59000, loss: 0.430840
 >> iter 60000, loss: 0.426540
   Number of active neurons: 4
 >> iter 61000, loss: 0.472018
 >> iter 62000, loss: 0.481055
 >> iter 63000, loss: 0.500638
 >> iter 64000, loss: 0.435238
 >> iter 65000, loss: 0.396612
 >> iter 66000, loss: 0.613539
 >> iter 67000, loss: 0.568105
 >> iter 68000, loss: 0.561400
 >> iter 69000, loss: 0.530457
 >> iter 70000, loss: 0.471485
   Number of active neurons: 4
 >> iter 71000, loss: 0.492533
 >> iter 72000, loss: 0.487717
 >> iter 73000, loss: 0.555558
 >> iter 74000, loss: 0.469778
 >> iter 75000, loss: 0.404874
 >> iter 76000, loss: 0.275268
 >> iter 77000, loss: 0.286935
 >> iter 78000, loss: 0.448898
 >> iter 79000, loss: 0.461101
 >> iter 80000, loss: 0.383953
   Number of active neurons: 4
 >> iter 81000, loss: 0.421828
 >> iter 82000, loss: 0.577866
 >> iter 83000, loss: 0.618339
 >> iter 84000, loss: 0.515566
 >> iter 85000, loss: 0.537816
 >> iter 86000, loss: 0.593894
 >> iter 87000, loss: 0.447673
 >> iter 88000, loss: 0.521137
 >> iter 89000, loss: 0.570477
 >> iter 90000, loss: 0.650326
   Number of active neurons: 4
 >> iter 91000, loss: 0.464734
 >> iter 92000, loss: 0.566389
 >> iter 93000, loss: 0.482271
 >> iter 94000, loss: 0.607502
 >> iter 95000, loss: 0.560390
 >> iter 96000, loss: 0.508314
 >> iter 97000, loss: 0.439645
 >> iter 98000, loss: 0.586553
 >> iter 99000, loss: 0.718627
 >> iter 100000, loss: 0.457196
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

