 > Problema: tomita3nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.972670
 >> iter 2000, loss: 11.615539
 >> iter 3000, loss: 5.123884
 >> iter 4000, loss: 2.245773
 >> iter 5000, loss: 1.045136
 >> iter 6000, loss: 0.661738
 >> iter 7000, loss: 0.413050
 >> iter 8000, loss: 0.439142
 >> iter 9000, loss: 0.304294
 >> iter 10000, loss: 0.321329
   Number of active neurons: 7
 >> iter 11000, loss: 0.410661
 >> iter 12000, loss: 0.278370
 >> iter 13000, loss: 0.325561
 >> iter 14000, loss: 0.335402
 >> iter 15000, loss: 0.445834
 >> iter 16000, loss: 0.306425
 >> iter 17000, loss: 0.251378
 >> iter 18000, loss: 0.433940
 >> iter 19000, loss: 0.302076
 >> iter 20000, loss: 0.307587
   Number of active neurons: 7
 >> iter 21000, loss: 0.408573
 >> iter 22000, loss: 0.560067
 >> iter 23000, loss: 0.426729
 >> iter 24000, loss: 0.330038
 >> iter 25000, loss: 0.425302
 >> iter 26000, loss: 0.540670
 >> iter 27000, loss: 0.407884
 >> iter 28000, loss: 0.310553
 >> iter 29000, loss: 0.292820
 >> iter 30000, loss: 0.358530
   Number of active neurons: 7
 >> iter 31000, loss: 0.368684
 >> iter 32000, loss: 0.297283
 >> iter 33000, loss: 0.464354
 >> iter 34000, loss: 0.424207
 >> iter 35000, loss: 0.378156
 >> iter 36000, loss: 0.283529
 >> iter 37000, loss: 0.284708
 >> iter 38000, loss: 0.224657
 >> iter 39000, loss: 0.207739
 >> iter 40000, loss: 0.305458
   Number of active neurons: 7
 >> iter 41000, loss: 0.233134
 >> iter 42000, loss: 0.209792
 >> iter 43000, loss: 0.394392
 >> iter 44000, loss: 0.394545
 >> iter 45000, loss: 0.535097
 >> iter 46000, loss: 0.314321
 >> iter 47000, loss: 0.272049
 >> iter 48000, loss: 0.510780
 >> iter 49000, loss: 0.348061
 >> iter 50000, loss: 0.406090
   Number of active neurons: 7
 >> iter 51000, loss: 0.243434
 >> iter 52000, loss: 0.352715
 >> iter 53000, loss: 0.478056
 >> iter 54000, loss: 0.425912
 >> iter 55000, loss: 0.286725
 >> iter 56000, loss: 0.400277
 >> iter 57000, loss: 0.404322
 >> iter 58000, loss: 0.421060
 >> iter 59000, loss: 0.409823
 >> iter 60000, loss: 0.362734
   Number of active neurons: 7
 >> iter 61000, loss: 0.226988
 >> iter 62000, loss: 0.245003
 >> iter 63000, loss: 0.295462
 >> iter 64000, loss: 0.174674
 >> iter 65000, loss: 0.233193
 >> iter 66000, loss: 0.214422
 >> iter 67000, loss: 0.241388
 >> iter 68000, loss: 0.339103
 >> iter 69000, loss: 0.393254
 >> iter 70000, loss: 0.370893
   Number of active neurons: 7
 >> iter 71000, loss: 0.297021
 >> iter 72000, loss: 0.320845
 >> iter 73000, loss: 0.326354
 >> iter 74000, loss: 0.387680
 >> iter 75000, loss: 0.443130
 >> iter 76000, loss: 0.446375
 >> iter 77000, loss: 0.471169
 >> iter 78000, loss: 0.314061
 >> iter 79000, loss: 0.240161
 >> iter 80000, loss: 0.239185
   Number of active neurons: 7
 >> iter 81000, loss: 0.293937
 >> iter 82000, loss: 0.238011
 >> iter 83000, loss: 0.248240
 >> iter 84000, loss: 0.392215
 >> iter 85000, loss: 0.302046
 >> iter 86000, loss: 0.428967
 >> iter 87000, loss: 0.470571
 >> iter 88000, loss: 0.553601
 >> iter 89000, loss: 0.421403
 >> iter 90000, loss: 0.471224
   Number of active neurons: 7
 >> iter 91000, loss: 0.562939
 >> iter 92000, loss: 0.431938
 >> iter 93000, loss: 0.402655
 >> iter 94000, loss: 0.301762
 >> iter 95000, loss: 0.461416
 >> iter 96000, loss: 0.362747
 >> iter 97000, loss: 0.438759
 >> iter 98000, loss: 0.283454
 >> iter 99000, loss: 0.299984
 >> iter 100000, loss: 0.321469
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.282626
 >> iter 2000, loss: 14.127242
 >> iter 3000, loss: 10.499689
 >> iter 4000, loss: 8.663258
 >> iter 5000, loss: 7.594819
 >> iter 6000, loss: 7.035530
 >> iter 7000, loss: 7.025976
 >> iter 8000, loss: 5.595151
 >> iter 9000, loss: 3.030764
 >> iter 10000, loss: 1.680464
   Number of active neurons: 8
 >> iter 11000, loss: 1.206194
 >> iter 12000, loss: 0.750417
 >> iter 13000, loss: 0.482591
 >> iter 14000, loss: 0.477195
 >> iter 15000, loss: 0.441459
 >> iter 16000, loss: 0.534951
 >> iter 17000, loss: 0.498420
 >> iter 18000, loss: 0.457844
 >> iter 19000, loss: 0.361934
 >> iter 20000, loss: 0.295231
   Number of active neurons: 8
 >> iter 21000, loss: 0.448438
 >> iter 22000, loss: 0.364157
 >> iter 23000, loss: 0.654175
 >> iter 24000, loss: 0.350609
 >> iter 25000, loss: 0.336823
 >> iter 26000, loss: 0.317102
 >> iter 27000, loss: 0.576688
 >> iter 28000, loss: 0.438846
 >> iter 29000, loss: 0.377077
 >> iter 30000, loss: 0.479435
   Number of active neurons: 8
 >> iter 31000, loss: 0.457658
 >> iter 32000, loss: 0.583922
 >> iter 33000, loss: 0.520412
 >> iter 34000, loss: 0.379395
 >> iter 35000, loss: 0.339495
 >> iter 36000, loss: 0.799144
 >> iter 37000, loss: 0.669533
 >> iter 38000, loss: 0.585415
 >> iter 39000, loss: 0.350699
 >> iter 40000, loss: 0.478553
   Number of active neurons: 7
 >> iter 41000, loss: 0.546973
 >> iter 42000, loss: 0.488238
 >> iter 43000, loss: 0.566642
 >> iter 44000, loss: 0.510204
 >> iter 45000, loss: 0.547694
 >> iter 46000, loss: 0.615979
 >> iter 47000, loss: 0.461980
 >> iter 48000, loss: 0.626384
 >> iter 49000, loss: 0.588534
 >> iter 50000, loss: 0.553913
   Number of active neurons: 7
 >> iter 51000, loss: 0.621437
 >> iter 52000, loss: 0.458931
 >> iter 53000, loss: 0.335694
 >> iter 54000, loss: 0.323550
 >> iter 55000, loss: 0.433889
 >> iter 56000, loss: 0.408023
 >> iter 57000, loss: 0.436779
 >> iter 58000, loss: 0.377138
 >> iter 59000, loss: 0.437110
 >> iter 60000, loss: 0.455598
   Number of active neurons: 6
 >> iter 61000, loss: 0.425383
 >> iter 62000, loss: 0.496571
 >> iter 63000, loss: 0.679748
 >> iter 64000, loss: 0.597456
 >> iter 65000, loss: 0.453913
 >> iter 66000, loss: 0.464111
 >> iter 67000, loss: 0.387142
 >> iter 68000, loss: 0.731523
 >> iter 69000, loss: 0.782180
 >> iter 70000, loss: 0.801358
   Number of active neurons: 7
 >> iter 71000, loss: 0.576770
 >> iter 72000, loss: 0.401785
 >> iter 73000, loss: 0.321332
 >> iter 74000, loss: 0.332551
 >> iter 75000, loss: 0.269242
 >> iter 76000, loss: 0.444256
 >> iter 77000, loss: 0.402641
 >> iter 78000, loss: 0.566637
 >> iter 79000, loss: 0.527260
 >> iter 80000, loss: 0.392668
   Number of active neurons: 6
 >> iter 81000, loss: 0.649773
 >> iter 82000, loss: 0.629754
 >> iter 83000, loss: 0.528357
 >> iter 84000, loss: 0.430680
 >> iter 85000, loss: 0.580513
 >> iter 86000, loss: 0.501577
 >> iter 87000, loss: 0.370913
 >> iter 88000, loss: 0.574478
 >> iter 89000, loss: 0.482017
 >> iter 90000, loss: 0.438634
   Number of active neurons: 6
 >> iter 91000, loss: 0.624897
 >> iter 92000, loss: 0.536375
 >> iter 93000, loss: 0.459445
 >> iter 94000, loss: 0.341412
 >> iter 95000, loss: 0.441808
 >> iter 96000, loss: 0.463241
 >> iter 97000, loss: 0.339661
 >> iter 98000, loss: 0.331736
 >> iter 99000, loss: 0.359440
 >> iter 100000, loss: 0.612982
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.003008
 >> iter 2000, loss: 12.086316
 >> iter 3000, loss: 5.611268
 >> iter 4000, loss: 2.354468
 >> iter 5000, loss: 1.200472
 >> iter 6000, loss: 0.639940
 >> iter 7000, loss: 0.594341
 >> iter 8000, loss: 0.419002
 >> iter 9000, loss: 0.466095
 >> iter 10000, loss: 0.355442
   Number of active neurons: 6
 >> iter 11000, loss: 0.338938
 >> iter 12000, loss: 0.338798
 >> iter 13000, loss: 0.424908
 >> iter 14000, loss: 0.316419
 >> iter 15000, loss: 0.254553
 >> iter 16000, loss: 0.189039
 >> iter 17000, loss: 0.173252
 >> iter 18000, loss: 0.221974
 >> iter 19000, loss: 0.367937
 >> iter 20000, loss: 0.279106
   Number of active neurons: 6
 >> iter 21000, loss: 0.334113
 >> iter 22000, loss: 0.300668
 >> iter 23000, loss: 0.265957
 >> iter 24000, loss: 0.303302
 >> iter 25000, loss: 0.229209
 >> iter 26000, loss: 0.273496
 >> iter 27000, loss: 0.404716
 >> iter 28000, loss: 0.262691
 >> iter 29000, loss: 0.236204
 >> iter 30000, loss: 0.218665
   Number of active neurons: 6
 >> iter 31000, loss: 0.240136
 >> iter 32000, loss: 0.399525
 >> iter 33000, loss: 0.394450
 >> iter 34000, loss: 0.334602
 >> iter 35000, loss: 0.260907
 >> iter 36000, loss: 0.148998
 >> iter 37000, loss: 0.367625
 >> iter 38000, loss: 0.295538
 >> iter 39000, loss: 0.171788
 >> iter 40000, loss: 0.183331
   Number of active neurons: 6
 >> iter 41000, loss: 0.312594
 >> iter 42000, loss: 0.214943
 >> iter 43000, loss: 0.170638
 >> iter 44000, loss: 0.275182
 >> iter 45000, loss: 0.338353
 >> iter 46000, loss: 0.258855
 >> iter 47000, loss: 0.397897
 >> iter 48000, loss: 0.487567
 >> iter 49000, loss: 0.310587
 >> iter 50000, loss: 0.285505
   Number of active neurons: 6
 >> iter 51000, loss: 0.284989
 >> iter 52000, loss: 0.300154
 >> iter 53000, loss: 0.193189
 >> iter 54000, loss: 0.223444
 >> iter 55000, loss: 0.253486
 >> iter 56000, loss: 0.273665
 >> iter 57000, loss: 0.232530
 >> iter 58000, loss: 0.259345
 >> iter 59000, loss: 0.186396
 >> iter 60000, loss: 0.181171
   Number of active neurons: 6
 >> iter 61000, loss: 0.501548
 >> iter 62000, loss: 0.452740
 >> iter 63000, loss: 0.322347
 >> iter 64000, loss: 0.227824
 >> iter 65000, loss: 0.251349
 >> iter 66000, loss: 0.206607
 >> iter 67000, loss: 0.136604
 >> iter 68000, loss: 0.290229
 >> iter 69000, loss: 0.276090
 >> iter 70000, loss: 0.246199
   Number of active neurons: 5
 >> iter 71000, loss: 0.272734
 >> iter 72000, loss: 0.323031
 >> iter 73000, loss: 0.272186
 >> iter 74000, loss: 0.191038
 >> iter 75000, loss: 0.208215
 >> iter 76000, loss: 0.350811
 >> iter 77000, loss: 0.222557
 >> iter 78000, loss: 0.171254
 >> iter 79000, loss: 0.248608
 >> iter 80000, loss: 0.213101
   Number of active neurons: 5
 >> iter 81000, loss: 0.431855
 >> iter 82000, loss: 0.234137
 >> iter 83000, loss: 0.253494
 >> iter 84000, loss: 0.153954
 >> iter 85000, loss: 0.241129
 >> iter 86000, loss: 0.309413
 >> iter 87000, loss: 0.458584
 >> iter 88000, loss: 0.338619
 >> iter 89000, loss: 0.200114
 >> iter 90000, loss: 0.286917
   Number of active neurons: 4
 >> iter 91000, loss: 0.252606
 >> iter 92000, loss: 0.303939
 >> iter 93000, loss: 0.244655
 >> iter 94000, loss: 0.266540
 >> iter 95000, loss: 0.211487
 >> iter 96000, loss: 0.160348
 >> iter 97000, loss: 0.221567
 >> iter 98000, loss: 0.186821
 >> iter 99000, loss: 0.246024
 >> iter 100000, loss: 0.264108
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.039052
 >> iter 2000, loss: 10.147831
 >> iter 3000, loss: 4.967094
 >> iter 4000, loss: 2.522915
 >> iter 5000, loss: 1.737565
 >> iter 6000, loss: 0.984887
 >> iter 7000, loss: 0.901791
 >> iter 8000, loss: 0.739344
 >> iter 9000, loss: 0.568295
 >> iter 10000, loss: 0.617990
   Number of active neurons: 7
 >> iter 11000, loss: 0.668434
 >> iter 12000, loss: 0.647380
 >> iter 13000, loss: 0.448255
 >> iter 14000, loss: 0.442050
 >> iter 15000, loss: 0.500100
 >> iter 16000, loss: 0.572419
 >> iter 17000, loss: 0.485727
 >> iter 18000, loss: 0.495316
 >> iter 19000, loss: 0.502852
 >> iter 20000, loss: 0.564679
   Number of active neurons: 7
 >> iter 21000, loss: 0.871645
 >> iter 22000, loss: 0.744355
 >> iter 23000, loss: 0.509927
 >> iter 24000, loss: 0.352581
 >> iter 25000, loss: 0.386403
 >> iter 26000, loss: 0.385858
 >> iter 27000, loss: 0.622690
 >> iter 28000, loss: 0.511440
 >> iter 29000, loss: 0.477755
 >> iter 30000, loss: 0.454573
   Number of active neurons: 7
 >> iter 31000, loss: 0.534780
 >> iter 32000, loss: 0.451616
 >> iter 33000, loss: 0.342891
 >> iter 34000, loss: 0.304921
 >> iter 35000, loss: 0.634160
 >> iter 36000, loss: 0.397638
 >> iter 37000, loss: 0.482191
 >> iter 38000, loss: 0.381225
 >> iter 39000, loss: 0.361937
 >> iter 40000, loss: 0.372472
   Number of active neurons: 7
 >> iter 41000, loss: 0.415025
 >> iter 42000, loss: 0.365659
 >> iter 43000, loss: 0.404518
 >> iter 44000, loss: 0.366408
 >> iter 45000, loss: 0.490830
 >> iter 46000, loss: 0.473821
 >> iter 47000, loss: 0.365466
 >> iter 48000, loss: 0.344957
 >> iter 49000, loss: 0.488086
 >> iter 50000, loss: 0.441319
   Number of active neurons: 7
 >> iter 51000, loss: 0.351025
 >> iter 52000, loss: 0.404665
 >> iter 53000, loss: 0.559402
 >> iter 54000, loss: 0.442859
 >> iter 55000, loss: 0.438437
 >> iter 56000, loss: 0.488660
 >> iter 57000, loss: 0.482280
 >> iter 58000, loss: 0.609037
 >> iter 59000, loss: 0.534666
 >> iter 60000, loss: 0.423239
   Number of active neurons: 7
 >> iter 61000, loss: 0.465270
 >> iter 62000, loss: 0.605079
 >> iter 63000, loss: 0.599696
 >> iter 64000, loss: 0.459387
 >> iter 65000, loss: 0.524966
 >> iter 66000, loss: 0.444882
 >> iter 67000, loss: 0.455619
 >> iter 68000, loss: 0.403435
 >> iter 69000, loss: 0.337501
 >> iter 70000, loss: 0.384692
   Number of active neurons: 7
 >> iter 71000, loss: 0.512815
 >> iter 72000, loss: 0.442970
 >> iter 73000, loss: 0.450615
 >> iter 74000, loss: 0.412062
 >> iter 75000, loss: 0.352337
 >> iter 76000, loss: 0.302729
 >> iter 77000, loss: 0.309843
 >> iter 78000, loss: 0.396060
 >> iter 79000, loss: 0.359401
 >> iter 80000, loss: 0.333714
   Number of active neurons: 7
 >> iter 81000, loss: 0.449280
 >> iter 82000, loss: 0.393607
 >> iter 83000, loss: 0.465458
 >> iter 84000, loss: 0.460815
 >> iter 85000, loss: 0.545342
 >> iter 86000, loss: 0.475180
 >> iter 87000, loss: 0.434697
 >> iter 88000, loss: 0.339454
 >> iter 89000, loss: 0.428258
 >> iter 90000, loss: 0.369223
   Number of active neurons: 7
 >> iter 91000, loss: 0.358380
 >> iter 92000, loss: 0.346311
 >> iter 93000, loss: 0.480111
 >> iter 94000, loss: 0.445127
 >> iter 95000, loss: 0.402479
 >> iter 96000, loss: 0.338548
 >> iter 97000, loss: 0.587295
 >> iter 98000, loss: 0.454812
 >> iter 99000, loss: 0.452532
 >> iter 100000, loss: 0.410673
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.129922
 >> iter 2000, loss: 13.353207
 >> iter 3000, loss: 6.592101
 >> iter 4000, loss: 3.291354
 >> iter 5000, loss: 1.792525
 >> iter 6000, loss: 1.193803
 >> iter 7000, loss: 0.782273
 >> iter 8000, loss: 0.597177
 >> iter 9000, loss: 0.492468
 >> iter 10000, loss: 0.381190
   Number of active neurons: 5
 >> iter 11000, loss: 0.568419
 >> iter 12000, loss: 0.462419
 >> iter 13000, loss: 0.434378
 >> iter 14000, loss: 0.438878
 >> iter 15000, loss: 0.362136
 >> iter 16000, loss: 0.280276
 >> iter 17000, loss: 0.308551
 >> iter 18000, loss: 0.330781
 >> iter 19000, loss: 0.315165
 >> iter 20000, loss: 0.267994
   Number of active neurons: 5
 >> iter 21000, loss: 0.330591
 >> iter 22000, loss: 0.471273
 >> iter 23000, loss: 0.549397
 >> iter 24000, loss: 0.518622
 >> iter 25000, loss: 0.375422
 >> iter 26000, loss: 0.325612
 >> iter 27000, loss: 0.421883
 >> iter 28000, loss: 0.298766
 >> iter 29000, loss: 0.524584
 >> iter 30000, loss: 0.450984
   Number of active neurons: 5
 >> iter 31000, loss: 0.483448
 >> iter 32000, loss: 0.403228
 >> iter 33000, loss: 0.348706
 >> iter 34000, loss: 0.265478
 >> iter 35000, loss: 0.528888
 >> iter 36000, loss: 0.577132
 >> iter 37000, loss: 0.581483
 >> iter 38000, loss: 0.384703
 >> iter 39000, loss: 0.437881
 >> iter 40000, loss: 0.407286
   Number of active neurons: 5
 >> iter 41000, loss: 0.405591
 >> iter 42000, loss: 0.297010
 >> iter 43000, loss: 0.309282
 >> iter 44000, loss: 0.377824
 >> iter 45000, loss: 0.486705
 >> iter 46000, loss: 0.315652
 >> iter 47000, loss: 0.532307
 >> iter 48000, loss: 0.416455
 >> iter 49000, loss: 0.409349
 >> iter 50000, loss: 0.287441
   Number of active neurons: 4
 >> iter 51000, loss: 0.417681
 >> iter 52000, loss: 0.499590
 >> iter 53000, loss: 0.336163
 >> iter 54000, loss: 0.250843
 >> iter 55000, loss: 0.358878
 >> iter 56000, loss: 0.371628
 >> iter 57000, loss: 0.330687
 >> iter 58000, loss: 0.398280
 >> iter 59000, loss: 0.322406
 >> iter 60000, loss: 0.386605
   Number of active neurons: 4
 >> iter 61000, loss: 0.376654
 >> iter 62000, loss: 0.446637
 >> iter 63000, loss: 0.449780
 >> iter 64000, loss: 0.259863
 >> iter 65000, loss: 0.431498
 >> iter 66000, loss: 0.532583
 >> iter 67000, loss: 0.333592
 >> iter 68000, loss: 0.372023
 >> iter 69000, loss: 0.374040
 >> iter 70000, loss: 0.483194
   Number of active neurons: 4
 >> iter 71000, loss: 0.317606
 >> iter 72000, loss: 0.287005
 >> iter 73000, loss: 0.305075
 >> iter 74000, loss: 0.241545
 >> iter 75000, loss: 0.287187
 >> iter 76000, loss: 0.271931
 >> iter 77000, loss: 0.223605
 >> iter 78000, loss: 0.272411
 >> iter 79000, loss: 0.248881
 >> iter 80000, loss: 0.345620
   Number of active neurons: 4
 >> iter 81000, loss: 0.309290
 >> iter 82000, loss: 0.274724
 >> iter 83000, loss: 0.370710
 >> iter 84000, loss: 0.286964
 >> iter 85000, loss: 0.301165
 >> iter 86000, loss: 0.218321
 >> iter 87000, loss: 0.201583
 >> iter 88000, loss: 0.207468
 >> iter 89000, loss: 0.268202
 >> iter 90000, loss: 0.303970
   Number of active neurons: 4
 >> iter 91000, loss: 0.283033
 >> iter 92000, loss: 0.176383
 >> iter 93000, loss: 0.377901
 >> iter 94000, loss: 0.255381
 >> iter 95000, loss: 0.288371
 >> iter 96000, loss: 0.282344
 >> iter 97000, loss: 0.382453
 >> iter 98000, loss: 0.297697
 >> iter 99000, loss: 0.210115
 >> iter 100000, loss: 0.233031
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.252877
 >> iter 2000, loss: 11.282955
 >> iter 3000, loss: 5.312451
 >> iter 4000, loss: 2.674575
 >> iter 5000, loss: 1.612581
 >> iter 6000, loss: 1.073525
 >> iter 7000, loss: 0.840596
 >> iter 8000, loss: 0.636832
 >> iter 9000, loss: 0.796620
 >> iter 10000, loss: 0.906051
   Number of active neurons: 7
 >> iter 11000, loss: 0.595498
 >> iter 12000, loss: 0.361190
 >> iter 13000, loss: 0.757472
 >> iter 14000, loss: 0.598882
 >> iter 15000, loss: 0.674427
 >> iter 16000, loss: 0.468501
 >> iter 17000, loss: 0.645903
 >> iter 18000, loss: 0.511086
 >> iter 19000, loss: 0.583739
 >> iter 20000, loss: 0.474160
   Number of active neurons: 7
 >> iter 21000, loss: 0.479047
 >> iter 22000, loss: 0.494807
 >> iter 23000, loss: 0.594495
 >> iter 24000, loss: 0.515680
 >> iter 25000, loss: 0.526450
 >> iter 26000, loss: 0.497288
 >> iter 27000, loss: 0.471407
 >> iter 28000, loss: 0.574335
 >> iter 29000, loss: 0.665562
 >> iter 30000, loss: 0.494456
   Number of active neurons: 7
 >> iter 31000, loss: 0.537977
 >> iter 32000, loss: 0.462856
 >> iter 33000, loss: 0.474908
 >> iter 34000, loss: 0.610835
 >> iter 35000, loss: 0.469505
 >> iter 36000, loss: 0.452424
 >> iter 37000, loss: 0.279186
 >> iter 38000, loss: 0.384868
 >> iter 39000, loss: 0.352555
 >> iter 40000, loss: 0.517116
   Number of active neurons: 6
 >> iter 41000, loss: 0.636971
 >> iter 42000, loss: 0.504697
 >> iter 43000, loss: 0.506716
 >> iter 44000, loss: 0.405926
 >> iter 45000, loss: 0.369220
 >> iter 46000, loss: 0.309935
 >> iter 47000, loss: 0.358894
 >> iter 48000, loss: 0.316288
 >> iter 49000, loss: 0.394683
 >> iter 50000, loss: 0.322144
   Number of active neurons: 6
 >> iter 51000, loss: 0.451637
 >> iter 52000, loss: 0.476010
 >> iter 53000, loss: 0.445454
 >> iter 54000, loss: 0.358940
 >> iter 55000, loss: 0.513677
 >> iter 56000, loss: 0.535323
 >> iter 57000, loss: 0.373321
 >> iter 58000, loss: 0.605256
 >> iter 59000, loss: 0.508640
 >> iter 60000, loss: 0.436307
   Number of active neurons: 6
 >> iter 61000, loss: 0.427188
 >> iter 62000, loss: 0.418709
 >> iter 63000, loss: 0.413820
 >> iter 64000, loss: 0.555988
 >> iter 65000, loss: 0.412673
 >> iter 66000, loss: 0.326370
 >> iter 67000, loss: 0.616010
 >> iter 68000, loss: 0.501142
 >> iter 69000, loss: 0.486625
 >> iter 70000, loss: 0.495203
   Number of active neurons: 6
 >> iter 71000, loss: 0.536224
 >> iter 72000, loss: 0.328543
 >> iter 73000, loss: 0.321249
 >> iter 74000, loss: 0.400181
 >> iter 75000, loss: 0.459263
 >> iter 76000, loss: 0.492647
 >> iter 77000, loss: 0.374885
 >> iter 78000, loss: 0.463863
 >> iter 79000, loss: 0.621017
 >> iter 80000, loss: 0.434450
   Number of active neurons: 6
 >> iter 81000, loss: 0.595646
 >> iter 82000, loss: 0.572187
 >> iter 83000, loss: 0.424205
 >> iter 84000, loss: 0.347759
 >> iter 85000, loss: 0.558771
 >> iter 86000, loss: 0.499365
 >> iter 87000, loss: 0.410696
 >> iter 88000, loss: 0.365363
 >> iter 89000, loss: 0.381358
 >> iter 90000, loss: 0.324720
   Number of active neurons: 6
 >> iter 91000, loss: 0.495351
 >> iter 92000, loss: 0.446177
 >> iter 93000, loss: 0.501982
 >> iter 94000, loss: 0.544817
 >> iter 95000, loss: 0.441800
 >> iter 96000, loss: 0.316620
 >> iter 97000, loss: 0.365868
 >> iter 98000, loss: 0.297533
 >> iter 99000, loss: 0.455124
 >> iter 100000, loss: 0.622671
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.191324
 >> iter 2000, loss: 13.641859
 >> iter 3000, loss: 10.699380
 >> iter 4000, loss: 9.080928
 >> iter 5000, loss: 8.635441
 >> iter 6000, loss: 8.174913
 >> iter 7000, loss: 7.362599
 >> iter 8000, loss: 4.530901
 >> iter 9000, loss: 2.508605
 >> iter 10000, loss: 1.337041
   Number of active neurons: 6
 >> iter 11000, loss: 0.817451
 >> iter 12000, loss: 0.736745
 >> iter 13000, loss: 0.678627
 >> iter 14000, loss: 0.543957
 >> iter 15000, loss: 0.433389
 >> iter 16000, loss: 0.485184
 >> iter 17000, loss: 0.496412
 >> iter 18000, loss: 0.380584
 >> iter 19000, loss: 0.521548
 >> iter 20000, loss: 0.445278
   Number of active neurons: 6
 >> iter 21000, loss: 0.428025
 >> iter 22000, loss: 0.596343
 >> iter 23000, loss: 0.690028
 >> iter 24000, loss: 0.544955
 >> iter 25000, loss: 0.375007
 >> iter 26000, loss: 0.562307
 >> iter 27000, loss: 0.596861
 >> iter 28000, loss: 0.504664
 >> iter 29000, loss: 0.432598
 >> iter 30000, loss: 0.517927
   Number of active neurons: 6
 >> iter 31000, loss: 0.502699
 >> iter 32000, loss: 0.358928
 >> iter 33000, loss: 0.465240
 >> iter 34000, loss: 0.332812
 >> iter 35000, loss: 0.279685
 >> iter 36000, loss: 0.338634
 >> iter 37000, loss: 0.411165
 >> iter 38000, loss: 0.364015
 >> iter 39000, loss: 0.301089
 >> iter 40000, loss: 0.250221
   Number of active neurons: 6
 >> iter 41000, loss: 0.271793
 >> iter 42000, loss: 0.372950
 >> iter 43000, loss: 0.326211
 >> iter 44000, loss: 0.222076
 >> iter 45000, loss: 0.381138
 >> iter 46000, loss: 0.345031
 >> iter 47000, loss: 0.381223
 >> iter 48000, loss: 0.373243
 >> iter 49000, loss: 0.291068
 >> iter 50000, loss: 0.331523
   Number of active neurons: 6
 >> iter 51000, loss: 0.290089
 >> iter 52000, loss: 0.267342
 >> iter 53000, loss: 0.372383
 >> iter 54000, loss: 0.404388
 >> iter 55000, loss: 0.388679
 >> iter 56000, loss: 0.387221
 >> iter 57000, loss: 0.482863
 >> iter 58000, loss: 0.330792
 >> iter 59000, loss: 0.185576
 >> iter 60000, loss: 0.316318
   Number of active neurons: 6
 >> iter 61000, loss: 0.271044
 >> iter 62000, loss: 0.304230
 >> iter 63000, loss: 0.398009
 >> iter 64000, loss: 0.423530
 >> iter 65000, loss: 0.430855
 >> iter 66000, loss: 0.328703
 >> iter 67000, loss: 0.373888
 >> iter 68000, loss: 0.285830
 >> iter 69000, loss: 0.197355
 >> iter 70000, loss: 0.258856
   Number of active neurons: 6
 >> iter 71000, loss: 0.472560
 >> iter 72000, loss: 0.254717
 >> iter 73000, loss: 0.262328
 >> iter 74000, loss: 0.300489
 >> iter 75000, loss: 0.238993
 >> iter 76000, loss: 0.264610
 >> iter 77000, loss: 0.403573
 >> iter 78000, loss: 0.219105
 >> iter 79000, loss: 0.359618
 >> iter 80000, loss: 0.367846
   Number of active neurons: 6
 >> iter 81000, loss: 0.400190
 >> iter 82000, loss: 0.240656
 >> iter 83000, loss: 0.270663
 >> iter 84000, loss: 0.335033
 >> iter 85000, loss: 0.270253
 >> iter 86000, loss: 0.226755
 >> iter 87000, loss: 0.306771
 >> iter 88000, loss: 0.348212
 >> iter 89000, loss: 0.350058
 >> iter 90000, loss: 0.230974
   Number of active neurons: 6
 >> iter 91000, loss: 0.218413
 >> iter 92000, loss: 0.314107
 >> iter 93000, loss: 0.260178
 >> iter 94000, loss: 0.248838
 >> iter 95000, loss: 0.290025
 >> iter 96000, loss: 0.258091
 >> iter 97000, loss: 0.388112
 >> iter 98000, loss: 0.364696
 >> iter 99000, loss: 0.256643
 >> iter 100000, loss: 0.357304
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.123856
 >> iter 2000, loss: 10.390418
 >> iter 3000, loss: 4.650320
 >> iter 4000, loss: 2.269827
 >> iter 5000, loss: 1.249929
 >> iter 6000, loss: 0.728413
 >> iter 7000, loss: 0.449294
 >> iter 8000, loss: 0.470632
 >> iter 9000, loss: 0.517293
 >> iter 10000, loss: 0.466893
   Number of active neurons: 5
 >> iter 11000, loss: 0.389019
 >> iter 12000, loss: 0.413616
 >> iter 13000, loss: 0.383456
 >> iter 14000, loss: 0.327006
 >> iter 15000, loss: 0.356404
 >> iter 16000, loss: 0.455211
 >> iter 17000, loss: 0.494090
 >> iter 18000, loss: 0.460454
 >> iter 19000, loss: 0.478580
 >> iter 20000, loss: 0.335143
   Number of active neurons: 5
 >> iter 21000, loss: 0.371888
 >> iter 22000, loss: 0.460939
 >> iter 23000, loss: 0.559537
 >> iter 24000, loss: 0.339297
 >> iter 25000, loss: 0.278066
 >> iter 26000, loss: 0.325843
 >> iter 27000, loss: 0.271769
 >> iter 28000, loss: 0.276810
 >> iter 29000, loss: 0.365758
 >> iter 30000, loss: 0.285614
   Number of active neurons: 5
 >> iter 31000, loss: 0.232575
 >> iter 32000, loss: 0.324728
 >> iter 33000, loss: 0.380298
 >> iter 34000, loss: 0.463142
 >> iter 35000, loss: 0.417321
 >> iter 36000, loss: 0.285338
 >> iter 37000, loss: 0.289809
 >> iter 38000, loss: 0.333362
 >> iter 39000, loss: 0.294606
 >> iter 40000, loss: 0.328091
   Number of active neurons: 5
 >> iter 41000, loss: 0.248410
 >> iter 42000, loss: 0.294893
 >> iter 43000, loss: 0.307290
 >> iter 44000, loss: 0.318378
 >> iter 45000, loss: 0.297740
 >> iter 46000, loss: 0.390167
 >> iter 47000, loss: 0.441603
 >> iter 48000, loss: 0.422812
 >> iter 49000, loss: 0.341379
 >> iter 50000, loss: 0.250040
   Number of active neurons: 5
 >> iter 51000, loss: 0.271020
 >> iter 52000, loss: 0.258212
 >> iter 53000, loss: 0.215257
 >> iter 54000, loss: 0.170559
 >> iter 55000, loss: 0.136037
 >> iter 56000, loss: 0.249632
 >> iter 57000, loss: 0.207442
 >> iter 58000, loss: 0.254403
 >> iter 59000, loss: 0.144822
 >> iter 60000, loss: 0.213767
   Number of active neurons: 5
 >> iter 61000, loss: 0.264059
 >> iter 62000, loss: 0.242088
 >> iter 63000, loss: 0.160782
 >> iter 64000, loss: 0.219920
 >> iter 65000, loss: 0.242002
 >> iter 66000, loss: 0.192457
 >> iter 67000, loss: 0.312343
 >> iter 68000, loss: 0.242655
 >> iter 69000, loss: 0.169616
 >> iter 70000, loss: 0.290660
   Number of active neurons: 5
 >> iter 71000, loss: 0.167325
 >> iter 72000, loss: 0.206429
 >> iter 73000, loss: 0.336650
 >> iter 74000, loss: 0.245613
 >> iter 75000, loss: 0.256263
 >> iter 76000, loss: 0.225083
 >> iter 77000, loss: 0.256948
 >> iter 78000, loss: 0.206840
 >> iter 79000, loss: 0.125022
 >> iter 80000, loss: 0.193122
   Number of active neurons: 4
 >> iter 81000, loss: 0.206904
 >> iter 82000, loss: 0.252603
 >> iter 83000, loss: 0.221595
 >> iter 84000, loss: 0.204931
 >> iter 85000, loss: 0.167676
 >> iter 86000, loss: 0.154119
 >> iter 87000, loss: 0.229999
 >> iter 88000, loss: 0.286639
 >> iter 89000, loss: 0.176241
 >> iter 90000, loss: 0.161105
   Number of active neurons: 4
 >> iter 91000, loss: 0.165782
 >> iter 92000, loss: 0.219621
 >> iter 93000, loss: 0.228642
 >> iter 94000, loss: 0.283875
 >> iter 95000, loss: 0.177815
 >> iter 96000, loss: 0.266670
 >> iter 97000, loss: 0.247769
 >> iter 98000, loss: 0.230973
 >> iter 99000, loss: 0.165123
 >> iter 100000, loss: 0.138715
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.989142
 >> iter 2000, loss: 9.678574
 >> iter 3000, loss: 4.316356
 >> iter 4000, loss: 2.073766
 >> iter 5000, loss: 1.140055
 >> iter 6000, loss: 0.665785
 >> iter 7000, loss: 0.417703
 >> iter 8000, loss: 0.266238
 >> iter 9000, loss: 0.175134
 >> iter 10000, loss: 0.191495
   Number of active neurons: 6
 >> iter 11000, loss: 0.232344
 >> iter 12000, loss: 0.293439
 >> iter 13000, loss: 0.255286
 >> iter 14000, loss: 0.303752
 >> iter 15000, loss: 0.409148
 >> iter 16000, loss: 0.372578
 >> iter 17000, loss: 0.426379
 >> iter 18000, loss: 0.398519
 >> iter 19000, loss: 0.309271
 >> iter 20000, loss: 0.247599
   Number of active neurons: 6
 >> iter 21000, loss: 0.275409
 >> iter 22000, loss: 0.302434
 >> iter 23000, loss: 0.275633
 >> iter 24000, loss: 0.253140
 >> iter 25000, loss: 0.207661
 >> iter 26000, loss: 0.197212
 >> iter 27000, loss: 0.158646
 >> iter 28000, loss: 0.199135
 >> iter 29000, loss: 0.235163
 >> iter 30000, loss: 0.319900
   Number of active neurons: 6
 >> iter 31000, loss: 0.215444
 >> iter 32000, loss: 0.130102
 >> iter 33000, loss: 0.245257
 >> iter 34000, loss: 0.477907
 >> iter 35000, loss: 0.378074
 >> iter 36000, loss: 0.223462
 >> iter 37000, loss: 0.172896
 >> iter 38000, loss: 0.161830
 >> iter 39000, loss: 0.193956
 >> iter 40000, loss: 0.319987
   Number of active neurons: 6
 >> iter 41000, loss: 0.232518
 >> iter 42000, loss: 0.358135
 >> iter 43000, loss: 0.269593
 >> iter 44000, loss: 0.275268
 >> iter 45000, loss: 0.231882
 >> iter 46000, loss: 0.223412
 >> iter 47000, loss: 0.318846
 >> iter 48000, loss: 0.208222
 >> iter 49000, loss: 0.291871
 >> iter 50000, loss: 0.245016
   Number of active neurons: 6
 >> iter 51000, loss: 0.265045
 >> iter 52000, loss: 0.192365
 >> iter 53000, loss: 0.290207
 >> iter 54000, loss: 0.203876
 >> iter 55000, loss: 0.179397
 >> iter 56000, loss: 0.360718
 >> iter 57000, loss: 0.291957
 >> iter 58000, loss: 0.402670
 >> iter 59000, loss: 0.301485
 >> iter 60000, loss: 0.240736
   Number of active neurons: 6
 >> iter 61000, loss: 0.196860
 >> iter 62000, loss: 0.221690
 >> iter 63000, loss: 0.209404
 >> iter 64000, loss: 0.191294
 >> iter 65000, loss: 0.154156
 >> iter 66000, loss: 0.224014
 >> iter 67000, loss: 0.402220
 >> iter 68000, loss: 0.328042
 >> iter 69000, loss: 0.357176
 >> iter 70000, loss: 0.326530
   Number of active neurons: 6
 >> iter 71000, loss: 0.231194
 >> iter 72000, loss: 0.186238
 >> iter 73000, loss: 0.291846
 >> iter 74000, loss: 0.238954
 >> iter 75000, loss: 0.164544
 >> iter 76000, loss: 0.225379
 >> iter 77000, loss: 0.202039
 >> iter 78000, loss: 0.159418
 >> iter 79000, loss: 0.257379
 >> iter 80000, loss: 0.136900
   Number of active neurons: 5
 >> iter 81000, loss: 0.140589
 >> iter 82000, loss: 0.303462
 >> iter 83000, loss: 0.267464
 >> iter 84000, loss: 0.163736
 >> iter 85000, loss: 0.122413
 >> iter 86000, loss: 0.210583
 >> iter 87000, loss: 0.334215
 >> iter 88000, loss: 0.225691
 >> iter 89000, loss: 0.214039
 >> iter 90000, loss: 0.145969
   Number of active neurons: 5
 >> iter 91000, loss: 0.194712
 >> iter 92000, loss: 0.165664
 >> iter 93000, loss: 0.152652
 >> iter 94000, loss: 0.156784
 >> iter 95000, loss: 0.129519
 >> iter 96000, loss: 0.177404
 >> iter 97000, loss: 0.144134
 >> iter 98000, loss: 0.118355
 >> iter 99000, loss: 0.127857
 >> iter 100000, loss: 0.204331
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.926698
 >> iter 2000, loss: 10.933733
 >> iter 3000, loss: 5.271419
 >> iter 4000, loss: 2.517631
 >> iter 5000, loss: 1.359264
 >> iter 6000, loss: 0.895420
 >> iter 7000, loss: 0.582409
 >> iter 8000, loss: 0.412958
 >> iter 9000, loss: 0.517063
 >> iter 10000, loss: 0.280080
   Number of active neurons: 8
 >> iter 11000, loss: 0.211195
 >> iter 12000, loss: 0.291168
 >> iter 13000, loss: 0.462613
 >> iter 14000, loss: 0.450879
 >> iter 15000, loss: 0.303612
 >> iter 16000, loss: 0.432464
 >> iter 17000, loss: 0.378421
 >> iter 18000, loss: 0.352393
 >> iter 19000, loss: 0.308770
 >> iter 20000, loss: 0.318970
   Number of active neurons: 8
 >> iter 21000, loss: 0.425144
 >> iter 22000, loss: 0.339431
 >> iter 23000, loss: 0.286853
 >> iter 24000, loss: 0.299939
 >> iter 25000, loss: 0.234984
 >> iter 26000, loss: 0.263025
 >> iter 27000, loss: 0.367229
 >> iter 28000, loss: 0.223495
 >> iter 29000, loss: 0.247039
 >> iter 30000, loss: 0.177004
   Number of active neurons: 8
 >> iter 31000, loss: 0.233057
 >> iter 32000, loss: 0.322172
 >> iter 33000, loss: 0.434421
 >> iter 34000, loss: 0.242834
 >> iter 35000, loss: 0.311738
 >> iter 36000, loss: 0.229231
 >> iter 37000, loss: 0.197505
 >> iter 38000, loss: 0.211383
 >> iter 39000, loss: 0.202043
 >> iter 40000, loss: 0.333676
   Number of active neurons: 8
 >> iter 41000, loss: 0.203839
 >> iter 42000, loss: 0.179992
 >> iter 43000, loss: 0.239720
 >> iter 44000, loss: 0.175163
 >> iter 45000, loss: 0.121735
 >> iter 46000, loss: 0.164063
 >> iter 47000, loss: 0.193633
 >> iter 48000, loss: 0.251702
 >> iter 49000, loss: 0.218785
 >> iter 50000, loss: 0.265189
   Number of active neurons: 6
 >> iter 51000, loss: 0.436544
 >> iter 52000, loss: 0.247052
 >> iter 53000, loss: 0.219899
 >> iter 54000, loss: 0.186356
 >> iter 55000, loss: 0.276959
 >> iter 56000, loss: 0.257993
 >> iter 57000, loss: 0.255213
 >> iter 58000, loss: 0.203601
 >> iter 59000, loss: 0.182996
 >> iter 60000, loss: 0.279769
   Number of active neurons: 6
 >> iter 61000, loss: 0.196550
 >> iter 62000, loss: 0.177967
 >> iter 63000, loss: 0.287547
 >> iter 64000, loss: 0.312522
 >> iter 65000, loss: 0.250909
 >> iter 66000, loss: 0.318496
 >> iter 67000, loss: 0.210567
 >> iter 68000, loss: 0.158270
 >> iter 69000, loss: 0.165596
 >> iter 70000, loss: 0.330918
   Number of active neurons: 5
 >> iter 71000, loss: 0.281413
 >> iter 72000, loss: 0.291911
 >> iter 73000, loss: 0.235311
 >> iter 74000, loss: 0.159420
 >> iter 75000, loss: 0.113615
 >> iter 76000, loss: 0.268104
 >> iter 77000, loss: 0.236771
 >> iter 78000, loss: 0.185539
 >> iter 79000, loss: 0.217214
 >> iter 80000, loss: 0.182506
   Number of active neurons: 4
 >> iter 81000, loss: 0.427443
 >> iter 82000, loss: 0.241757
 >> iter 83000, loss: 0.204103
 >> iter 84000, loss: 0.156913
 >> iter 85000, loss: 0.204894
 >> iter 86000, loss: 0.176024
 >> iter 87000, loss: 0.251489
 >> iter 88000, loss: 0.205378
 >> iter 89000, loss: 0.142215
 >> iter 90000, loss: 0.208080
   Number of active neurons: 4
 >> iter 91000, loss: 0.256130
 >> iter 92000, loss: 0.133178
 >> iter 93000, loss: 0.199241
 >> iter 94000, loss: 0.304207
 >> iter 95000, loss: 0.234456
 >> iter 96000, loss: 0.192382
 >> iter 97000, loss: 0.221778
 >> iter 98000, loss: 0.160571
 >> iter 99000, loss: 0.141770
 >> iter 100000, loss: 0.176750
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.127939
 >> iter 2000, loss: 11.694263
 >> iter 3000, loss: 5.747360
 >> iter 4000, loss: 3.177275
 >> iter 5000, loss: 1.576836
 >> iter 6000, loss: 0.981014
 >> iter 7000, loss: 0.659088
 >> iter 8000, loss: 0.625075
 >> iter 9000, loss: 0.743065
 >> iter 10000, loss: 0.636559
   Number of active neurons: 5
 >> iter 11000, loss: 0.513220
 >> iter 12000, loss: 0.519853
 >> iter 13000, loss: 0.490294
 >> iter 14000, loss: 0.384890
 >> iter 15000, loss: 0.503740
 >> iter 16000, loss: 0.487766
 >> iter 17000, loss: 0.453554
 >> iter 18000, loss: 0.523675
 >> iter 19000, loss: 0.536400
 >> iter 20000, loss: 0.535028
   Number of active neurons: 5
 >> iter 21000, loss: 0.375036
 >> iter 22000, loss: 0.559698
 >> iter 23000, loss: 0.486568
 >> iter 24000, loss: 0.512322
 >> iter 25000, loss: 0.524838
 >> iter 26000, loss: 0.450988
 >> iter 27000, loss: 0.561175
 >> iter 28000, loss: 0.428581
 >> iter 29000, loss: 0.380300
 >> iter 30000, loss: 0.379864
   Number of active neurons: 5
 >> iter 31000, loss: 0.398614
 >> iter 32000, loss: 0.384730
 >> iter 33000, loss: 0.392458
 >> iter 34000, loss: 0.314623
 >> iter 35000, loss: 0.405558
 >> iter 36000, loss: 0.381010
 >> iter 37000, loss: 0.386507
 >> iter 38000, loss: 0.422665
 >> iter 39000, loss: 0.389056
 >> iter 40000, loss: 0.358979
   Number of active neurons: 5
 >> iter 41000, loss: 0.516630
 >> iter 42000, loss: 0.333563
 >> iter 43000, loss: 0.358592
 >> iter 44000, loss: 0.440269
 >> iter 45000, loss: 0.292860
 >> iter 46000, loss: 0.405944
 >> iter 47000, loss: 0.328679
 >> iter 48000, loss: 0.240981
 >> iter 49000, loss: 0.275744
 >> iter 50000, loss: 0.454711
   Number of active neurons: 5
 >> iter 51000, loss: 0.425870
 >> iter 52000, loss: 0.380742
 >> iter 53000, loss: 0.294392
 >> iter 54000, loss: 0.207721
 >> iter 55000, loss: 0.161452
 >> iter 56000, loss: 0.226132
 >> iter 57000, loss: 0.361643
 >> iter 58000, loss: 0.341268
 >> iter 59000, loss: 0.329015
 >> iter 60000, loss: 0.269967
   Number of active neurons: 5
 >> iter 61000, loss: 0.392710
 >> iter 62000, loss: 0.320121
 >> iter 63000, loss: 0.271819
 >> iter 64000, loss: 0.402531
 >> iter 65000, loss: 0.450042
 >> iter 66000, loss: 0.290087
 >> iter 67000, loss: 0.416406
 >> iter 68000, loss: 0.329571
 >> iter 69000, loss: 0.315262
 >> iter 70000, loss: 0.393650
   Number of active neurons: 5
 >> iter 71000, loss: 0.356393
 >> iter 72000, loss: 0.184555
 >> iter 73000, loss: 0.250120
 >> iter 74000, loss: 0.275200
 >> iter 75000, loss: 0.266045
 >> iter 76000, loss: 0.325071
 >> iter 77000, loss: 0.348941
 >> iter 78000, loss: 0.304499
 >> iter 79000, loss: 0.259295
 >> iter 80000, loss: 0.239226
   Number of active neurons: 5
 >> iter 81000, loss: 0.477015
 >> iter 82000, loss: 0.235593
 >> iter 83000, loss: 0.151309
 >> iter 84000, loss: 0.185511
 >> iter 85000, loss: 0.132196
 >> iter 86000, loss: 0.145364
 >> iter 87000, loss: 0.167750
 >> iter 88000, loss: 0.153520
 >> iter 89000, loss: 0.160989
 >> iter 90000, loss: 0.161585
   Number of active neurons: 5
 >> iter 91000, loss: 0.233736
 >> iter 92000, loss: 0.253623
 >> iter 93000, loss: 0.144708
 >> iter 94000, loss: 0.184659
 >> iter 95000, loss: 0.255086
 >> iter 96000, loss: 0.277372
 >> iter 97000, loss: 0.207653
 >> iter 98000, loss: 0.154038
 >> iter 99000, loss: 0.255340
 >> iter 100000, loss: 0.183571
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.352452
 >> iter 2000, loss: 15.098804
 >> iter 3000, loss: 9.603993
 >> iter 4000, loss: 5.645232
 >> iter 5000, loss: 2.930014
 >> iter 6000, loss: 1.455025
 >> iter 7000, loss: 1.142404
 >> iter 8000, loss: 0.921775
 >> iter 9000, loss: 0.794823
 >> iter 10000, loss: 0.813064
   Number of active neurons: 7
 >> iter 11000, loss: 0.580396
 >> iter 12000, loss: 0.644971
 >> iter 13000, loss: 0.682112
 >> iter 14000, loss: 0.613986
 >> iter 15000, loss: 0.734818
 >> iter 16000, loss: 0.580032
 >> iter 17000, loss: 0.345326
 >> iter 18000, loss: 0.455360
 >> iter 19000, loss: 0.411297
 >> iter 20000, loss: 0.456318
   Number of active neurons: 7
 >> iter 21000, loss: 0.458949
 >> iter 22000, loss: 0.505350
 >> iter 23000, loss: 0.407586
 >> iter 24000, loss: 0.312584
 >> iter 25000, loss: 0.279331
 >> iter 26000, loss: 0.433364
 >> iter 27000, loss: 0.347645
 >> iter 28000, loss: 0.266778
 >> iter 29000, loss: 0.241050
 >> iter 30000, loss: 0.345332
   Number of active neurons: 7
 >> iter 31000, loss: 0.334808
 >> iter 32000, loss: 0.425886
 >> iter 33000, loss: 0.350555
 >> iter 34000, loss: 0.193746
 >> iter 35000, loss: 0.323444
 >> iter 36000, loss: 0.215698
 >> iter 37000, loss: 0.392767
 >> iter 38000, loss: 0.259701
 >> iter 39000, loss: 0.406147
 >> iter 40000, loss: 0.285549
   Number of active neurons: 7
 >> iter 41000, loss: 0.328910
 >> iter 42000, loss: 0.252897
 >> iter 43000, loss: 0.458771
 >> iter 44000, loss: 0.303094
 >> iter 45000, loss: 0.213997
 >> iter 46000, loss: 0.308725
 >> iter 47000, loss: 0.270076
 >> iter 48000, loss: 0.272115
 >> iter 49000, loss: 0.276201
 >> iter 50000, loss: 0.259182
   Number of active neurons: 7
 >> iter 51000, loss: 0.312058
 >> iter 52000, loss: 0.247483
 >> iter 53000, loss: 0.273283
 >> iter 54000, loss: 0.206999
 >> iter 55000, loss: 0.259147
 >> iter 56000, loss: 0.401474
 >> iter 57000, loss: 0.365726
 >> iter 58000, loss: 0.327825
 >> iter 59000, loss: 0.529513
 >> iter 60000, loss: 0.409758
   Number of active neurons: 7
 >> iter 61000, loss: 0.416799
 >> iter 62000, loss: 0.319567
 >> iter 63000, loss: 0.192439
 >> iter 64000, loss: 0.176551
 >> iter 65000, loss: 0.193774
 >> iter 66000, loss: 0.374215
 >> iter 67000, loss: 0.403207
 >> iter 68000, loss: 0.351254
 >> iter 69000, loss: 0.320414
 >> iter 70000, loss: 0.294512
   Number of active neurons: 7
 >> iter 71000, loss: 0.346128
 >> iter 72000, loss: 0.314595
 >> iter 73000, loss: 0.370270
 >> iter 74000, loss: 0.459898
 >> iter 75000, loss: 0.295331
 >> iter 76000, loss: 0.192107
 >> iter 77000, loss: 0.152459
 >> iter 78000, loss: 0.305460
 >> iter 79000, loss: 0.327083
 >> iter 80000, loss: 0.377741
   Number of active neurons: 7
 >> iter 81000, loss: 0.343591
 >> iter 82000, loss: 0.336471
 >> iter 83000, loss: 0.386590
 >> iter 84000, loss: 0.316955
 >> iter 85000, loss: 0.319582
 >> iter 86000, loss: 0.469104
 >> iter 87000, loss: 0.500625
 >> iter 88000, loss: 0.507095
 >> iter 89000, loss: 0.438439
 >> iter 90000, loss: 0.301872
   Number of active neurons: 7
 >> iter 91000, loss: 0.308709
 >> iter 92000, loss: 0.283449
 >> iter 93000, loss: 0.379581
 >> iter 94000, loss: 0.243241
 >> iter 95000, loss: 0.199721
 >> iter 96000, loss: 0.383195
 >> iter 97000, loss: 0.380631
 >> iter 98000, loss: 0.283521
 >> iter 99000, loss: 0.388550
 >> iter 100000, loss: 0.326517
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0039999200016
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 13.0257982801
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.080253
 >> iter 2000, loss: 10.991180
 >> iter 3000, loss: 4.990723
 >> iter 4000, loss: 2.232680
 >> iter 5000, loss: 1.342242
 >> iter 6000, loss: 0.743770
 >> iter 7000, loss: 0.545259
 >> iter 8000, loss: 0.435945
 >> iter 9000, loss: 0.287509
 >> iter 10000, loss: 0.318595
   Number of active neurons: 6
 >> iter 11000, loss: 0.389447
 >> iter 12000, loss: 0.323713
 >> iter 13000, loss: 0.344103
 >> iter 14000, loss: 0.260041
 >> iter 15000, loss: 0.292852
 >> iter 16000, loss: 0.368463
 >> iter 17000, loss: 0.313306
 >> iter 18000, loss: 0.249021
 >> iter 19000, loss: 0.217736
 >> iter 20000, loss: 0.209511
   Number of active neurons: 6
 >> iter 21000, loss: 0.365962
 >> iter 22000, loss: 0.330902
 >> iter 23000, loss: 0.207468
 >> iter 24000, loss: 0.320328
 >> iter 25000, loss: 0.327423
 >> iter 26000, loss: 0.327067
 >> iter 27000, loss: 0.394079
 >> iter 28000, loss: 0.472528
 >> iter 29000, loss: 0.329253
 >> iter 30000, loss: 0.326234
   Number of active neurons: 6
 >> iter 31000, loss: 0.331929
 >> iter 32000, loss: 0.285561
 >> iter 33000, loss: 0.456641
 >> iter 34000, loss: 0.280479
 >> iter 35000, loss: 0.450176
 >> iter 36000, loss: 0.291054
 >> iter 37000, loss: 0.476386
 >> iter 38000, loss: 0.363003
 >> iter 39000, loss: 0.233839
 >> iter 40000, loss: 0.246724
   Number of active neurons: 6
 >> iter 41000, loss: 0.307014
 >> iter 42000, loss: 0.251225
 >> iter 43000, loss: 0.346870
 >> iter 44000, loss: 0.268649
 >> iter 45000, loss: 0.269667
 >> iter 46000, loss: 0.335423
 >> iter 47000, loss: 0.377365
 >> iter 48000, loss: 0.301250
 >> iter 49000, loss: 0.420390
 >> iter 50000, loss: 0.356295
   Number of active neurons: 6
 >> iter 51000, loss: 0.266282
 >> iter 52000, loss: 0.216349
 >> iter 53000, loss: 0.333318
 >> iter 54000, loss: 0.322318
 >> iter 55000, loss: 0.230562
 >> iter 56000, loss: 0.265918
 >> iter 57000, loss: 0.303829
 >> iter 58000, loss: 0.275274
 >> iter 59000, loss: 0.246277
 >> iter 60000, loss: 0.252713
   Number of active neurons: 6
 >> iter 61000, loss: 0.268495
 >> iter 62000, loss: 0.379699
 >> iter 63000, loss: 0.320901
 >> iter 64000, loss: 0.190778
 >> iter 65000, loss: 0.320540
 >> iter 66000, loss: 0.288608
 >> iter 67000, loss: 0.361468
 >> iter 68000, loss: 0.404759
 >> iter 69000, loss: 0.327076
 >> iter 70000, loss: 0.366770
   Number of active neurons: 6
 >> iter 71000, loss: 0.313702
 >> iter 72000, loss: 0.324697
 >> iter 73000, loss: 0.372560
 >> iter 74000, loss: 0.248436
 >> iter 75000, loss: 0.194401
 >> iter 76000, loss: 0.351514
 >> iter 77000, loss: 0.386941
 >> iter 78000, loss: 0.421515
 >> iter 79000, loss: 0.337747
 >> iter 80000, loss: 0.268624
   Number of active neurons: 6
 >> iter 81000, loss: 0.346554
 >> iter 82000, loss: 0.326647
 >> iter 83000, loss: 0.193142
 >> iter 84000, loss: 0.295665
 >> iter 85000, loss: 0.204593
 >> iter 86000, loss: 0.264876
 >> iter 87000, loss: 0.315417
 >> iter 88000, loss: 0.340969
 >> iter 89000, loss: 0.281690
 >> iter 90000, loss: 0.389675
   Number of active neurons: 6
 >> iter 91000, loss: 0.294675
 >> iter 92000, loss: 0.327935
 >> iter 93000, loss: 0.241006
 >> iter 94000, loss: 0.354206
 >> iter 95000, loss: 0.452576
 >> iter 96000, loss: 0.372676
 >> iter 97000, loss: 0.388403
 >> iter 98000, loss: 0.316265
 >> iter 99000, loss: 0.249459
 >> iter 100000, loss: 0.381656
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.996217
 >> iter 2000, loss: 10.902251
 >> iter 3000, loss: 5.256674
 >> iter 4000, loss: 2.590424
 >> iter 5000, loss: 1.263318
 >> iter 6000, loss: 0.667489
 >> iter 7000, loss: 0.410395
 >> iter 8000, loss: 0.344651
 >> iter 9000, loss: 0.244996
 >> iter 10000, loss: 0.313951
   Number of active neurons: 6
 >> iter 11000, loss: 0.282461
 >> iter 12000, loss: 0.316573
 >> iter 13000, loss: 0.433492
 >> iter 14000, loss: 0.403797
 >> iter 15000, loss: 0.431399
 >> iter 16000, loss: 0.491763
 >> iter 17000, loss: 0.543108
 >> iter 18000, loss: 0.453868
 >> iter 19000, loss: 0.472776
 >> iter 20000, loss: 0.395349
   Number of active neurons: 6
 >> iter 21000, loss: 0.675394
 >> iter 22000, loss: 0.535482
 >> iter 23000, loss: 0.569259
 >> iter 24000, loss: 0.477910
 >> iter 25000, loss: 0.520098
 >> iter 26000, loss: 0.373918
 >> iter 27000, loss: 0.284583
 >> iter 28000, loss: 0.327275
 >> iter 29000, loss: 0.418959
 >> iter 30000, loss: 0.451407
   Number of active neurons: 6
 >> iter 31000, loss: 0.374025
 >> iter 32000, loss: 0.380476
 >> iter 33000, loss: 0.446467
 >> iter 34000, loss: 0.355613
 >> iter 35000, loss: 0.352631
 >> iter 36000, loss: 0.225464
 >> iter 37000, loss: 0.251909
 >> iter 38000, loss: 0.320651
 >> iter 39000, loss: 0.219980
 >> iter 40000, loss: 0.276816
   Number of active neurons: 6
 >> iter 41000, loss: 0.318601
 >> iter 42000, loss: 0.231639
 >> iter 43000, loss: 0.269632
 >> iter 44000, loss: 0.211024
 >> iter 45000, loss: 0.260620
 >> iter 46000, loss: 0.415273
 >> iter 47000, loss: 0.276675
 >> iter 48000, loss: 0.177857
 >> iter 49000, loss: 0.255163
 >> iter 50000, loss: 0.339202
   Number of active neurons: 6
 >> iter 51000, loss: 0.303427
 >> iter 52000, loss: 0.265311
 >> iter 53000, loss: 0.311868
 >> iter 54000, loss: 0.261568
 >> iter 55000, loss: 0.237523
 >> iter 56000, loss: 0.289020
 >> iter 57000, loss: 0.193866
 >> iter 58000, loss: 0.150816
 >> iter 59000, loss: 0.257010
 >> iter 60000, loss: 0.243478
   Number of active neurons: 6
 >> iter 61000, loss: 0.325499
 >> iter 62000, loss: 0.375150
 >> iter 63000, loss: 0.264705
 >> iter 64000, loss: 0.157763
 >> iter 65000, loss: 0.225804
 >> iter 66000, loss: 0.338253
 >> iter 67000, loss: 0.290843
 >> iter 68000, loss: 0.166908
 >> iter 69000, loss: 0.214238
 >> iter 70000, loss: 0.182594
   Number of active neurons: 5
 >> iter 71000, loss: 0.239684
 >> iter 72000, loss: 0.167677
 >> iter 73000, loss: 0.389637
 >> iter 74000, loss: 0.312070
 >> iter 75000, loss: 0.343918
 >> iter 76000, loss: 0.225306
 >> iter 77000, loss: 0.386291
 >> iter 78000, loss: 0.310383
 >> iter 79000, loss: 0.216853
 >> iter 80000, loss: 0.241942
   Number of active neurons: 5
 >> iter 81000, loss: 0.195712
 >> iter 82000, loss: 0.155589
 >> iter 83000, loss: 0.173672
 >> iter 84000, loss: 0.250355
 >> iter 85000, loss: 0.197843
 >> iter 86000, loss: 0.234054
 >> iter 87000, loss: 0.307341
 >> iter 88000, loss: 0.248738
 >> iter 89000, loss: 0.166386
 >> iter 90000, loss: 0.157054
   Number of active neurons: 5
 >> iter 91000, loss: 0.223844
 >> iter 92000, loss: 0.262517
 >> iter 93000, loss: 0.356167
 >> iter 94000, loss: 0.262611
 >> iter 95000, loss: 0.175976
 >> iter 96000, loss: 0.134399
 >> iter 97000, loss: 0.199849
 >> iter 98000, loss: 0.316474
 >> iter 99000, loss: 0.232973
 >> iter 100000, loss: 0.184164
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.166659
 >> iter 2000, loss: 11.439978
 >> iter 3000, loss: 5.228887
 >> iter 4000, loss: 2.549942
 >> iter 5000, loss: 1.364631
 >> iter 6000, loss: 1.055720
 >> iter 7000, loss: 0.621970
 >> iter 8000, loss: 0.391593
 >> iter 9000, loss: 0.324434
 >> iter 10000, loss: 0.385128
   Number of active neurons: 6
 >> iter 11000, loss: 0.368052
 >> iter 12000, loss: 0.326817
 >> iter 13000, loss: 0.502703
 >> iter 14000, loss: 0.371552
 >> iter 15000, loss: 0.356911
 >> iter 16000, loss: 0.235279
 >> iter 17000, loss: 0.281090
 >> iter 18000, loss: 0.389110
 >> iter 19000, loss: 0.385297
 >> iter 20000, loss: 0.365785
   Number of active neurons: 6
 >> iter 21000, loss: 0.306495
 >> iter 22000, loss: 0.397214
 >> iter 23000, loss: 0.370665
 >> iter 24000, loss: 0.365409
 >> iter 25000, loss: 0.316424
 >> iter 26000, loss: 0.262595
 >> iter 27000, loss: 0.484990
 >> iter 28000, loss: 0.520005
 >> iter 29000, loss: 0.379757
 >> iter 30000, loss: 0.393555
   Number of active neurons: 6
 >> iter 31000, loss: 0.273095
 >> iter 32000, loss: 0.358378
 >> iter 33000, loss: 0.506311
 >> iter 34000, loss: 0.454822
 >> iter 35000, loss: 0.349400
 >> iter 36000, loss: 0.259727
 >> iter 37000, loss: 0.454155
 >> iter 38000, loss: 0.349198
 >> iter 39000, loss: 0.402589
 >> iter 40000, loss: 0.285718
   Number of active neurons: 6
 >> iter 41000, loss: 0.376015
 >> iter 42000, loss: 0.364442
 >> iter 43000, loss: 0.423653
 >> iter 44000, loss: 0.426046
 >> iter 45000, loss: 0.564052
 >> iter 46000, loss: 0.539860
 >> iter 47000, loss: 0.446020
 >> iter 48000, loss: 0.396263
 >> iter 49000, loss: 0.417709
 >> iter 50000, loss: 0.372970
   Number of active neurons: 5
 >> iter 51000, loss: 0.499457
 >> iter 52000, loss: 0.400941
 >> iter 53000, loss: 0.429637
 >> iter 54000, loss: 0.352116
 >> iter 55000, loss: 0.365443
 >> iter 56000, loss: 0.298403
 >> iter 57000, loss: 0.216266
 >> iter 58000, loss: 0.322842
 >> iter 59000, loss: 0.426060
 >> iter 60000, loss: 0.454016
   Number of active neurons: 5
 >> iter 61000, loss: 0.392950
 >> iter 62000, loss: 0.433646
 >> iter 63000, loss: 0.415149
 >> iter 64000, loss: 0.346872
 >> iter 65000, loss: 0.401382
 >> iter 66000, loss: 0.499452
 >> iter 67000, loss: 0.421878
 >> iter 68000, loss: 0.393462
 >> iter 69000, loss: 0.391943
 >> iter 70000, loss: 0.489298
   Number of active neurons: 5
 >> iter 71000, loss: 0.566820
 >> iter 72000, loss: 0.523836
 >> iter 73000, loss: 0.493787
 >> iter 74000, loss: 0.336664
 >> iter 75000, loss: 0.364777
 >> iter 76000, loss: 0.341842
 >> iter 77000, loss: 0.292465
 >> iter 78000, loss: 0.339747
 >> iter 79000, loss: 0.338459
 >> iter 80000, loss: 0.411864
   Number of active neurons: 5
 >> iter 81000, loss: 0.216067
 >> iter 82000, loss: 0.258543
 >> iter 83000, loss: 0.306695
 >> iter 84000, loss: 0.310580
 >> iter 85000, loss: 0.378229
 >> iter 86000, loss: 0.590509
 >> iter 87000, loss: 0.596767
 >> iter 88000, loss: 0.566147
 >> iter 89000, loss: 0.439233
 >> iter 90000, loss: 0.294394
   Number of active neurons: 4
 >> iter 91000, loss: 0.385746
 >> iter 92000, loss: 0.347908
 >> iter 93000, loss: 0.347172
 >> iter 94000, loss: 0.261895
 >> iter 95000, loss: 0.260046
 >> iter 96000, loss: 0.334408
 >> iter 97000, loss: 0.429024
 >> iter 98000, loss: 0.241231
 >> iter 99000, loss: 0.226578
 >> iter 100000, loss: 0.341042
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.031144
 >> iter 2000, loss: 10.912580
 >> iter 3000, loss: 5.082789
 >> iter 4000, loss: 2.441283
 >> iter 5000, loss: 1.181030
 >> iter 6000, loss: 0.631614
 >> iter 7000, loss: 0.560575
 >> iter 8000, loss: 0.438677
 >> iter 9000, loss: 0.251905
 >> iter 10000, loss: 0.200387
   Number of active neurons: 6
 >> iter 11000, loss: 0.260474
 >> iter 12000, loss: 0.217542
 >> iter 13000, loss: 0.310663
 >> iter 14000, loss: 0.334912
 >> iter 15000, loss: 0.228236
 >> iter 16000, loss: 0.280577
 >> iter 17000, loss: 0.276026
 >> iter 18000, loss: 0.170463
 >> iter 19000, loss: 0.210566
 >> iter 20000, loss: 0.163577
   Number of active neurons: 6
 >> iter 21000, loss: 0.227264
 >> iter 22000, loss: 0.298590
 >> iter 23000, loss: 0.298114
 >> iter 24000, loss: 0.354275
 >> iter 25000, loss: 0.266329
 >> iter 26000, loss: 0.196614
 >> iter 27000, loss: 0.248942
 >> iter 28000, loss: 0.200127
 >> iter 29000, loss: 0.300049
 >> iter 30000, loss: 0.206220
   Number of active neurons: 6
 >> iter 31000, loss: 0.178747
 >> iter 32000, loss: 0.222952
 >> iter 33000, loss: 0.327839
 >> iter 34000, loss: 0.275571
 >> iter 35000, loss: 0.285208
 >> iter 36000, loss: 0.214042
 >> iter 37000, loss: 0.204237
 >> iter 38000, loss: 0.370323
 >> iter 39000, loss: 0.228557
 >> iter 40000, loss: 0.268241
   Number of active neurons: 6
 >> iter 41000, loss: 0.285615
 >> iter 42000, loss: 0.212743
 >> iter 43000, loss: 0.298602
 >> iter 44000, loss: 0.194282
 >> iter 45000, loss: 0.111099
 >> iter 46000, loss: 0.152331
 >> iter 47000, loss: 0.205636
 >> iter 48000, loss: 0.252116
 >> iter 49000, loss: 0.276074
 >> iter 50000, loss: 0.222474
   Number of active neurons: 5
 >> iter 51000, loss: 0.140481
 >> iter 52000, loss: 0.303529
 >> iter 53000, loss: 0.223476
 >> iter 54000, loss: 0.179286
 >> iter 55000, loss: 0.231832
 >> iter 56000, loss: 0.290524
 >> iter 57000, loss: 0.199854
 >> iter 58000, loss: 0.312901
 >> iter 59000, loss: 0.355107
 >> iter 60000, loss: 0.259712
   Number of active neurons: 5
 >> iter 61000, loss: 0.162085
 >> iter 62000, loss: 0.214547
 >> iter 63000, loss: 0.175068
 >> iter 64000, loss: 0.219200
 >> iter 65000, loss: 0.151586
 >> iter 66000, loss: 0.155825
 >> iter 67000, loss: 0.159092
 >> iter 68000, loss: 0.165810
 >> iter 69000, loss: 0.142904
 >> iter 70000, loss: 0.221450
   Number of active neurons: 4
 >> iter 71000, loss: 0.252144
 >> iter 72000, loss: 0.238707
 >> iter 73000, loss: 0.164040
 >> iter 74000, loss: 0.293279
 >> iter 75000, loss: 0.185000
 >> iter 76000, loss: 0.208317
 >> iter 77000, loss: 0.254632
 >> iter 78000, loss: 0.337813
 >> iter 79000, loss: 0.244820
 >> iter 80000, loss: 0.157590
   Number of active neurons: 4
 >> iter 81000, loss: 0.275465
 >> iter 82000, loss: 0.283500
 >> iter 83000, loss: 0.273203
 >> iter 84000, loss: 0.318578
 >> iter 85000, loss: 0.245231
 >> iter 86000, loss: 0.158319
 >> iter 87000, loss: 0.100343
 >> iter 88000, loss: 0.087662
 >> iter 89000, loss: 0.115434
 >> iter 90000, loss: 0.139650
   Number of active neurons: 4
 >> iter 91000, loss: 0.276840
 >> iter 92000, loss: 0.377368
 >> iter 93000, loss: 0.300050
 >> iter 94000, loss: 0.226641
 >> iter 95000, loss: 0.184913
 >> iter 96000, loss: 0.206053
 >> iter 97000, loss: 0.157473
 >> iter 98000, loss: 0.238092
 >> iter 99000, loss: 0.275947
 >> iter 100000, loss: 0.185854
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.184107
 >> iter 2000, loss: 13.495331
 >> iter 3000, loss: 9.447357
 >> iter 4000, loss: 7.664280
 >> iter 5000, loss: 7.061792
 >> iter 6000, loss: 6.607801
 >> iter 7000, loss: 6.560155
 >> iter 8000, loss: 6.444975
 >> iter 9000, loss: 6.447828
 >> iter 10000, loss: 6.321929
   Number of active neurons: 4
 >> iter 11000, loss: 6.390413
 >> iter 12000, loss: 6.339962
 >> iter 13000, loss: 6.391153
 >> iter 14000, loss: 6.218988
 >> iter 15000, loss: 6.422731
   Number of active neurons: 4
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 5.765800
 >> iter 17000, loss: 4.726369
 >> iter 18000, loss: 3.391417
 >> iter 19000, loss: 2.286119
 >> iter 20000, loss: 1.348484
   Number of active neurons: 10
 >> iter 21000, loss: 0.854744
 >> iter 22000, loss: 0.735779
 >> iter 23000, loss: 0.581186
 >> iter 24000, loss: 0.536923
 >> iter 25000, loss: 0.504635
 >> iter 26000, loss: 0.813400
 >> iter 27000, loss: 0.634269
 >> iter 28000, loss: 0.573967
 >> iter 29000, loss: 0.489653
 >> iter 30000, loss: 0.524748
   Number of active neurons: 10
 >> iter 31000, loss: 0.365557
 >> iter 32000, loss: 0.287294
 >> iter 33000, loss: 0.461723
 >> iter 34000, loss: 0.470277
 >> iter 35000, loss: 0.408855
 >> iter 36000, loss: 0.320481
 >> iter 37000, loss: 0.421416
 >> iter 38000, loss: 0.351322
 >> iter 39000, loss: 0.418159
 >> iter 40000, loss: 0.500780
   Number of active neurons: 8
 >> iter 41000, loss: 0.440745
 >> iter 42000, loss: 0.303508
 >> iter 43000, loss: 0.377990
 >> iter 44000, loss: 0.242219
 >> iter 45000, loss: 0.350305
 >> iter 46000, loss: 0.417321
 >> iter 47000, loss: 0.268181
 >> iter 48000, loss: 0.231377
 >> iter 49000, loss: 0.170878
 >> iter 50000, loss: 0.220259
   Number of active neurons: 8
 >> iter 51000, loss: 0.250439
 >> iter 52000, loss: 0.195041
 >> iter 53000, loss: 0.497907
 >> iter 54000, loss: 0.302717
 >> iter 55000, loss: 0.289414
 >> iter 56000, loss: 0.227255
 >> iter 57000, loss: 0.484418
 >> iter 58000, loss: 0.346247
 >> iter 59000, loss: 0.403501
 >> iter 60000, loss: 0.323630
   Number of active neurons: 7
 >> iter 61000, loss: 0.328645
 >> iter 62000, loss: 0.280765
 >> iter 63000, loss: 0.404397
 >> iter 64000, loss: 0.396106
 >> iter 65000, loss: 0.296930
 >> iter 66000, loss: 0.258922
 >> iter 67000, loss: 0.259391
 >> iter 68000, loss: 0.230497
 >> iter 69000, loss: 0.289702
 >> iter 70000, loss: 0.230503
   Number of active neurons: 7
 >> iter 71000, loss: 0.318339
 >> iter 72000, loss: 0.395985
 >> iter 73000, loss: 0.313797
 >> iter 74000, loss: 0.300639
 >> iter 75000, loss: 0.371991
 >> iter 76000, loss: 0.291060
 >> iter 77000, loss: 0.319768
 >> iter 78000, loss: 0.226562
 >> iter 79000, loss: 0.392607
 >> iter 80000, loss: 0.317054
   Number of active neurons: 7
 >> iter 81000, loss: 0.243687
 >> iter 82000, loss: 0.311469
 >> iter 83000, loss: 0.334256
 >> iter 84000, loss: 0.196870
 >> iter 85000, loss: 0.286976
 >> iter 86000, loss: 0.442196
 >> iter 87000, loss: 0.343665
 >> iter 88000, loss: 0.296401
 >> iter 89000, loss: 0.340974
 >> iter 90000, loss: 0.261564
   Number of active neurons: 7
 >> iter 91000, loss: 0.500732
 >> iter 92000, loss: 0.282347
 >> iter 93000, loss: 0.258515
 >> iter 94000, loss: 0.457091
 >> iter 95000, loss: 0.416832
 >> iter 96000, loss: 0.290757
 >> iter 97000, loss: 0.300134
 >> iter 98000, loss: 0.295616
 >> iter 99000, loss: 0.345222
 >> iter 100000, loss: 0.385156
   Number of active neurons: 7
 >> iter 101000, loss: 0.483457
 >> iter 102000, loss: 0.300982
 >> iter 103000, loss: 0.422415
 >> iter 104000, loss: 0.335172
 >> iter 105000, loss: 0.403406
 >> iter 106000, loss: 0.296888
 >> iter 107000, loss: 0.342971
 >> iter 108000, loss: 0.286228
 >> iter 109000, loss: 0.387488
 >> iter 110000, loss: 0.284700
   Number of active neurons: 7
 >> iter 111000, loss: 0.246098
 >> iter 112000, loss: 0.314336
 >> iter 113000, loss: 0.322117
 >> iter 114000, loss: 0.413429
 >> iter 115000, loss: 0.262010
 >> iter 116000, loss: 0.288339
 >> iter 117000, loss: 0.280430
 >> iter 118000, loss: 0.494518
 >> iter 119000, loss: 0.274226
 >> iter 120000, loss: 0.189828
   Number of active neurons: 7
 >> iter 121000, loss: 0.329600
 >> iter 122000, loss: 0.249478
 >> iter 123000, loss: 0.387175
 >> iter 124000, loss: 0.286111
 >> iter 125000, loss: 0.424889
 >> iter 126000, loss: 0.304097
 >> iter 127000, loss: 0.277550
 >> iter 128000, loss: 0.219120
 >> iter 129000, loss: 0.258840
 >> iter 130000, loss: 0.252073
   Number of active neurons: 7
 >> iter 131000, loss: 0.428642
 >> iter 132000, loss: 0.355284
 >> iter 133000, loss: 0.360117
 >> iter 134000, loss: 0.356859
 >> iter 135000, loss: 0.319157
 >> iter 136000, loss: 0.239999
 >> iter 137000, loss: 0.495861
 >> iter 138000, loss: 0.409957
 >> iter 139000, loss: 0.401283
 >> iter 140000, loss: 0.347269
   Number of active neurons: 7
 >> iter 141000, loss: 0.251880
 >> iter 142000, loss: 0.228930
 >> iter 143000, loss: 0.289894
 >> iter 144000, loss: 0.378734
 >> iter 145000, loss: 0.292786
 >> iter 146000, loss: 0.370856
 >> iter 147000, loss: 0.452804
 >> iter 148000, loss: 0.464623
 >> iter 149000, loss: 0.432011
 >> iter 150000, loss: 0.274030
   Number of active neurons: 6
 >> iter 151000, loss: 0.201641
 >> iter 152000, loss: 0.285326
 >> iter 153000, loss: 0.325011
 >> iter 154000, loss: 0.251946
 >> iter 155000, loss: 0.268237
 >> iter 156000, loss: 0.227966
 >> iter 157000, loss: 0.259634
 >> iter 158000, loss: 0.269961
 >> iter 159000, loss: 0.330627
 >> iter 160000, loss: 0.302677
   Number of active neurons: 6
 >> iter 161000, loss: 0.354247
 >> iter 162000, loss: 0.414513
 >> iter 163000, loss: 0.364161
 >> iter 164000, loss: 0.394722
 >> iter 165000, loss: 0.261995
 >> iter 166000, loss: 0.250234
 >> iter 167000, loss: 0.227190
 >> iter 168000, loss: 0.309334
 >> iter 169000, loss: 0.280891
 >> iter 170000, loss: 0.280900
   Number of active neurons: 6
 >> iter 171000, loss: 0.302427
 >> iter 172000, loss: 0.236453
 >> iter 173000, loss: 0.389338
 >> iter 174000, loss: 0.271538
 >> iter 175000, loss: 0.168449
 >> iter 176000, loss: 0.210210
 >> iter 177000, loss: 0.234053
 >> iter 178000, loss: 0.186883
 >> iter 179000, loss: 0.391626
 >> iter 180000, loss: 0.371731
   Number of active neurons: 6
 >> iter 181000, loss: 0.334053
 >> iter 182000, loss: 0.291664
 >> iter 183000, loss: 0.233279
 >> iter 184000, loss: 0.167956
 >> iter 185000, loss: 0.242304
 >> iter 186000, loss: 0.220706
 >> iter 187000, loss: 0.338233
 >> iter 188000, loss: 0.411617
 >> iter 189000, loss: 0.428826
 >> iter 190000, loss: 0.206962
   Number of active neurons: 5
 >> iter 191000, loss: 0.345907
 >> iter 192000, loss: 0.279199
 >> iter 193000, loss: 0.182366
 >> iter 194000, loss: 0.227608
 >> iter 195000, loss: 0.341283
 >> iter 196000, loss: 0.192057
 >> iter 197000, loss: 0.260042
 >> iter 198000, loss: 0.387094
 >> iter 199000, loss: 0.404447
 >> iter 200000, loss: 0.316522
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.239214
 >> iter 2000, loss: 14.358889
 >> iter 3000, loss: 10.524155
 >> iter 4000, loss: 8.136251
 >> iter 5000, loss: 7.276399
 >> iter 6000, loss: 6.674121
 >> iter 7000, loss: 6.585221
 >> iter 8000, loss: 6.340255
 >> iter 9000, loss: 6.424738
 >> iter 10000, loss: 6.365065
   Number of active neurons: 4
 >> iter 11000, loss: 6.373928
 >> iter 12000, loss: 6.219162
 >> iter 13000, loss: 6.362728
 >> iter 14000, loss: 6.253542
 >> iter 15000, loss: 6.297568
 >> iter 16000, loss: 6.251096
 >> iter 17000, loss: 6.390562
 >> iter 18000, loss: 6.245572
 >> iter 19000, loss: 6.303858
 >> iter 20000, loss: 6.196835
   Number of active neurons: 4
 >> iter 21000, loss: 6.323195
 >> iter 22000, loss: 6.160510
 >> iter 23000, loss: 6.278320
 >> iter 24000, loss: 6.063621
 >> iter 25000, loss: 6.309368
   Number of active neurons: 4
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 26000, loss: 5.573151
 >> iter 27000, loss: 3.229162
 >> iter 28000, loss: 1.694817
 >> iter 29000, loss: 1.018477
 >> iter 30000, loss: 0.529354
   Number of active neurons: 10
 >> iter 31000, loss: 0.452008
 >> iter 32000, loss: 0.508832
 >> iter 33000, loss: 0.490541
 >> iter 34000, loss: 0.464926
 >> iter 35000, loss: 0.377839
 >> iter 36000, loss: 0.354690
 >> iter 37000, loss: 0.384323
 >> iter 38000, loss: 0.434311
 >> iter 39000, loss: 0.401358
 >> iter 40000, loss: 0.474176
   Number of active neurons: 10
 >> iter 41000, loss: 0.582972
 >> iter 42000, loss: 0.385032
 >> iter 43000, loss: 0.448971
 >> iter 44000, loss: 0.469990
 >> iter 45000, loss: 0.375609
 >> iter 46000, loss: 0.312612
 >> iter 47000, loss: 0.394826
 >> iter 48000, loss: 0.423589
 >> iter 49000, loss: 0.369683
 >> iter 50000, loss: 0.452415
   Number of active neurons: 9
 >> iter 51000, loss: 0.362286
 >> iter 52000, loss: 0.286183
 >> iter 53000, loss: 0.417215
 >> iter 54000, loss: 0.403249
 >> iter 55000, loss: 0.537069
 >> iter 56000, loss: 0.403495
 >> iter 57000, loss: 0.292028
 >> iter 58000, loss: 0.471980
 >> iter 59000, loss: 0.716256
 >> iter 60000, loss: 0.374078
   Number of active neurons: 9
 >> iter 61000, loss: 0.597713
 >> iter 62000, loss: 0.438517
 >> iter 63000, loss: 0.433467
 >> iter 64000, loss: 0.396871
 >> iter 65000, loss: 0.259731
 >> iter 66000, loss: 0.343107
 >> iter 67000, loss: 0.540669
 >> iter 68000, loss: 0.458866
 >> iter 69000, loss: 0.445242
 >> iter 70000, loss: 0.319943
   Number of active neurons: 9
 >> iter 71000, loss: 0.309695
 >> iter 72000, loss: 0.413772
 >> iter 73000, loss: 0.344242
 >> iter 74000, loss: 0.302864
 >> iter 75000, loss: 0.285865
 >> iter 76000, loss: 0.457015
 >> iter 77000, loss: 0.389688
 >> iter 78000, loss: 0.346750
 >> iter 79000, loss: 0.395580
 >> iter 80000, loss: 0.388048
   Number of active neurons: 9
 >> iter 81000, loss: 0.332133
 >> iter 82000, loss: 0.370187
 >> iter 83000, loss: 0.475473
 >> iter 84000, loss: 0.344458
 >> iter 85000, loss: 0.408211
 >> iter 86000, loss: 0.365636
 >> iter 87000, loss: 0.317731
 >> iter 88000, loss: 0.264986
 >> iter 89000, loss: 0.507071
 >> iter 90000, loss: 0.384575
   Number of active neurons: 9
 >> iter 91000, loss: 0.441354
 >> iter 92000, loss: 0.324754
 >> iter 93000, loss: 0.245530
 >> iter 94000, loss: 0.448550
 >> iter 95000, loss: 0.456779
 >> iter 96000, loss: 0.509906
 >> iter 97000, loss: 0.429753
 >> iter 98000, loss: 0.342897
 >> iter 99000, loss: 0.366602
 >> iter 100000, loss: 0.506376
   Number of active neurons: 9
 >> iter 101000, loss: 0.390831
 >> iter 102000, loss: 0.498362
 >> iter 103000, loss: 0.573252
 >> iter 104000, loss: 0.459119
 >> iter 105000, loss: 0.477766
 >> iter 106000, loss: 0.465611
 >> iter 107000, loss: 0.582694
 >> iter 108000, loss: 0.438832
 >> iter 109000, loss: 0.366916
 >> iter 110000, loss: 0.273722
   Number of active neurons: 9
 >> iter 111000, loss: 0.632233
 >> iter 112000, loss: 0.573416
 >> iter 113000, loss: 0.404446
 >> iter 114000, loss: 0.297209
 >> iter 115000, loss: 0.316687
 >> iter 116000, loss: 0.319313
 >> iter 117000, loss: 0.461711
 >> iter 118000, loss: 0.420231
 >> iter 119000, loss: 0.442576
 >> iter 120000, loss: 0.407438
   Number of active neurons: 9
 >> iter 121000, loss: 0.304509
 >> iter 122000, loss: 0.508533
 >> iter 123000, loss: 0.520804
 >> iter 124000, loss: 0.370426
 >> iter 125000, loss: 0.305779
 >> iter 126000, loss: 0.259189
 >> iter 127000, loss: 0.229926
 >> iter 128000, loss: 0.202451
 >> iter 129000, loss: 0.503597
 >> iter 130000, loss: 0.510104
   Number of active neurons: 9
 >> iter 131000, loss: 0.495068
 >> iter 132000, loss: 0.635732
 >> iter 133000, loss: 0.410660
 >> iter 134000, loss: 0.469971
 >> iter 135000, loss: 0.484789
 >> iter 136000, loss: 0.551313
 >> iter 137000, loss: 0.399069
 >> iter 138000, loss: 0.335684
 >> iter 139000, loss: 0.343130
 >> iter 140000, loss: 0.377032
   Number of active neurons: 9
 >> iter 141000, loss: 0.578505
 >> iter 142000, loss: 0.427084
 >> iter 143000, loss: 0.382743
 >> iter 144000, loss: 0.367837
 >> iter 145000, loss: 0.283140
 >> iter 146000, loss: 0.422013
 >> iter 147000, loss: 0.419923
 >> iter 148000, loss: 0.248261
 >> iter 149000, loss: 0.340221
 >> iter 150000, loss: 0.383783
   Number of active neurons: 8
 >> iter 151000, loss: 0.331721
 >> iter 152000, loss: 0.287483
 >> iter 153000, loss: 0.520276
 >> iter 154000, loss: 0.353249
 >> iter 155000, loss: 0.345299
 >> iter 156000, loss: 0.347301
 >> iter 157000, loss: 0.369430
 >> iter 158000, loss: 0.300083
 >> iter 159000, loss: 0.342226
 >> iter 160000, loss: 0.315295
   Number of active neurons: 7
 >> iter 161000, loss: 0.354925
 >> iter 162000, loss: 0.354039
 >> iter 163000, loss: 0.364579
 >> iter 164000, loss: 0.280934
 >> iter 165000, loss: 0.245968
 >> iter 166000, loss: 0.373534
 >> iter 167000, loss: 0.425719
 >> iter 168000, loss: 0.466969
 >> iter 169000, loss: 0.320699
 >> iter 170000, loss: 0.353156
   Number of active neurons: 7
 >> iter 171000, loss: 0.270490
 >> iter 172000, loss: 0.362220
 >> iter 173000, loss: 0.478445
 >> iter 174000, loss: 0.309488
 >> iter 175000, loss: 0.274182
 >> iter 176000, loss: 0.313669
 >> iter 177000, loss: 0.475170
 >> iter 178000, loss: 0.430326
 >> iter 179000, loss: 0.384020
 >> iter 180000, loss: 0.300208
   Number of active neurons: 7
 >> iter 181000, loss: 0.247217
 >> iter 182000, loss: 0.251349
 >> iter 183000, loss: 0.642422
 >> iter 184000, loss: 0.399058
 >> iter 185000, loss: 0.348473
 >> iter 186000, loss: 0.388334
 >> iter 187000, loss: 0.383431
 >> iter 188000, loss: 0.352476
 >> iter 189000, loss: 0.525936
 >> iter 190000, loss: 0.422304
   Number of active neurons: 7
 >> iter 191000, loss: 0.241154
 >> iter 192000, loss: 0.324375
 >> iter 193000, loss: 0.327085
 >> iter 194000, loss: 0.287536
 >> iter 195000, loss: 0.433956
 >> iter 196000, loss: 0.309287
 >> iter 197000, loss: 0.345907
 >> iter 198000, loss: 0.556708
 >> iter 199000, loss: 0.458432
 >> iter 200000, loss: 0.296411
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 19.171972
 >> iter 2000, loss: 12.143577
 >> iter 3000, loss: 5.892352
 >> iter 4000, loss: 2.801558
 >> iter 5000, loss: 1.564661
 >> iter 6000, loss: 0.957270
 >> iter 7000, loss: 0.663967
 >> iter 8000, loss: 0.678686
 >> iter 9000, loss: 0.872094
 >> iter 10000, loss: 0.566505
   Number of active neurons: 8
 >> iter 11000, loss: 0.784679
 >> iter 12000, loss: 0.474582
 >> iter 13000, loss: 0.613379
 >> iter 14000, loss: 0.494437
 >> iter 15000, loss: 0.461538
 >> iter 16000, loss: 0.448004
 >> iter 17000, loss: 0.805931
 >> iter 18000, loss: 0.571356
 >> iter 19000, loss: 0.803845
 >> iter 20000, loss: 0.629125
   Number of active neurons: 8
 >> iter 21000, loss: 0.411199
 >> iter 22000, loss: 0.384521
 >> iter 23000, loss: 0.567043
 >> iter 24000, loss: 0.431965
 >> iter 25000, loss: 0.417841
 >> iter 26000, loss: 0.315473
 >> iter 27000, loss: 0.510746
 >> iter 28000, loss: 0.553124
 >> iter 29000, loss: 0.495429
 >> iter 30000, loss: 0.618568
   Number of active neurons: 8
 >> iter 31000, loss: 0.537673
 >> iter 32000, loss: 0.444728
 >> iter 33000, loss: 0.595133
 >> iter 34000, loss: 0.505971
 >> iter 35000, loss: 0.635636
 >> iter 36000, loss: 0.501969
 >> iter 37000, loss: 0.360210
 >> iter 38000, loss: 0.456786
 >> iter 39000, loss: 0.586162
 >> iter 40000, loss: 0.569177
   Number of active neurons: 8
 >> iter 41000, loss: 0.521940
 >> iter 42000, loss: 0.467931
 >> iter 43000, loss: 0.485376
 >> iter 44000, loss: 0.462617
 >> iter 45000, loss: 0.384819
 >> iter 46000, loss: 0.526477
 >> iter 47000, loss: 0.563327
 >> iter 48000, loss: 0.496207
 >> iter 49000, loss: 0.414431
 >> iter 50000, loss: 0.489543
   Number of active neurons: 8
 >> iter 51000, loss: 0.508245
 >> iter 52000, loss: 0.549670
 >> iter 53000, loss: 0.552057
 >> iter 54000, loss: 0.493349
 >> iter 55000, loss: 0.682693
 >> iter 56000, loss: 0.478492
 >> iter 57000, loss: 0.357039
 >> iter 58000, loss: 0.622157
 >> iter 59000, loss: 0.742558
 >> iter 60000, loss: 0.580599
   Number of active neurons: 8
 >> iter 61000, loss: 0.551118
 >> iter 62000, loss: 0.431221
 >> iter 63000, loss: 0.447080
 >> iter 64000, loss: 0.522381
 >> iter 65000, loss: 0.460913
 >> iter 66000, loss: 0.334075
 >> iter 67000, loss: 0.327365
 >> iter 68000, loss: 0.400319
 >> iter 69000, loss: 0.499933
 >> iter 70000, loss: 0.528824
   Number of active neurons: 8
 >> iter 71000, loss: 0.516277
 >> iter 72000, loss: 0.446265
 >> iter 73000, loss: 0.563953
 >> iter 74000, loss: 0.569275
 >> iter 75000, loss: 0.540016
 >> iter 76000, loss: 0.500163
 >> iter 77000, loss: 0.523360
 >> iter 78000, loss: 0.385175
 >> iter 79000, loss: 0.612910
 >> iter 80000, loss: 0.543249
   Number of active neurons: 8
 >> iter 81000, loss: 0.659867
 >> iter 82000, loss: 0.451424
 >> iter 83000, loss: 0.342524
 >> iter 84000, loss: 0.534749
 >> iter 85000, loss: 0.593911
 >> iter 86000, loss: 0.481197
 >> iter 87000, loss: 0.383875
 >> iter 88000, loss: 0.404463
 >> iter 89000, loss: 0.377126
 >> iter 90000, loss: 0.378041
   Number of active neurons: 8
 >> iter 91000, loss: 0.378948
 >> iter 92000, loss: 0.409617
 >> iter 93000, loss: 0.511063
 >> iter 94000, loss: 0.644038
 >> iter 95000, loss: 0.385899
 >> iter 96000, loss: 0.341325
 >> iter 97000, loss: 0.344250
 >> iter 98000, loss: 0.565744
 >> iter 99000, loss: 0.504464
 >> iter 100000, loss: 0.491667
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.141654
 >> iter 2000, loss: 13.198974
 >> iter 3000, loss: 8.573478
 >> iter 4000, loss: 4.496380
 >> iter 5000, loss: 2.307579
 >> iter 6000, loss: 1.475709
 >> iter 7000, loss: 1.238157
 >> iter 8000, loss: 0.773817
 >> iter 9000, loss: 0.962311
 >> iter 10000, loss: 0.700128
   Number of active neurons: 7
 >> iter 11000, loss: 1.008510
 >> iter 12000, loss: 0.804905
 >> iter 13000, loss: 0.692605
 >> iter 14000, loss: 0.464200
 >> iter 15000, loss: 0.454464
 >> iter 16000, loss: 0.495966
 >> iter 17000, loss: 0.637164
 >> iter 18000, loss: 0.713381
 >> iter 19000, loss: 0.538080
 >> iter 20000, loss: 0.775336
   Number of active neurons: 6
 >> iter 21000, loss: 0.597870
 >> iter 22000, loss: 0.526129
 >> iter 23000, loss: 0.406030
 >> iter 24000, loss: 0.514328
 >> iter 25000, loss: 0.664903
 >> iter 26000, loss: 0.730739
 >> iter 27000, loss: 0.638863
 >> iter 28000, loss: 0.464492
 >> iter 29000, loss: 0.562648
 >> iter 30000, loss: 0.566317
   Number of active neurons: 6
 >> iter 31000, loss: 0.581152
 >> iter 32000, loss: 0.612452
 >> iter 33000, loss: 0.565021
 >> iter 34000, loss: 0.449438
 >> iter 35000, loss: 0.510216
 >> iter 36000, loss: 0.388000
 >> iter 37000, loss: 0.501570
 >> iter 38000, loss: 0.433872
 >> iter 39000, loss: 0.498928
 >> iter 40000, loss: 0.426657
   Number of active neurons: 6
 >> iter 41000, loss: 0.328263
 >> iter 42000, loss: 0.345683
 >> iter 43000, loss: 0.562578
 >> iter 44000, loss: 0.588399
 >> iter 45000, loss: 0.553008
 >> iter 46000, loss: 0.447413
 >> iter 47000, loss: 0.557617
 >> iter 48000, loss: 0.470797
 >> iter 49000, loss: 0.432185
 >> iter 50000, loss: 0.514745
   Number of active neurons: 6
 >> iter 51000, loss: 0.643505
 >> iter 52000, loss: 0.635306
 >> iter 53000, loss: 0.541657
 >> iter 54000, loss: 0.509406
 >> iter 55000, loss: 0.442701
 >> iter 56000, loss: 0.475321
 >> iter 57000, loss: 0.428894
 >> iter 58000, loss: 0.375646
 >> iter 59000, loss: 0.317522
 >> iter 60000, loss: 0.365100
   Number of active neurons: 6
 >> iter 61000, loss: 0.569631
 >> iter 62000, loss: 0.562568
 >> iter 63000, loss: 0.494297
 >> iter 64000, loss: 0.407694
 >> iter 65000, loss: 0.467266
 >> iter 66000, loss: 0.481700
 >> iter 67000, loss: 0.367295
 >> iter 68000, loss: 0.512592
 >> iter 69000, loss: 0.492397
 >> iter 70000, loss: 0.465321
   Number of active neurons: 6
 >> iter 71000, loss: 0.510303
 >> iter 72000, loss: 0.596716
 >> iter 73000, loss: 0.586110
 >> iter 74000, loss: 0.489738
 >> iter 75000, loss: 0.666485
 >> iter 76000, loss: 0.542717
 >> iter 77000, loss: 0.415580
 >> iter 78000, loss: 0.431315
 >> iter 79000, loss: 0.509623
 >> iter 80000, loss: 0.579419
   Number of active neurons: 6
 >> iter 81000, loss: 0.651893
 >> iter 82000, loss: 0.469118
 >> iter 83000, loss: 0.665376
 >> iter 84000, loss: 0.525686
 >> iter 85000, loss: 0.493945
 >> iter 86000, loss: 0.401361
 >> iter 87000, loss: 0.494254
 >> iter 88000, loss: 0.400992
 >> iter 89000, loss: 0.275023
 >> iter 90000, loss: 0.414646
   Number of active neurons: 6
 >> iter 91000, loss: 0.489858
 >> iter 92000, loss: 0.424244
 >> iter 93000, loss: 0.586997
 >> iter 94000, loss: 0.536304
 >> iter 95000, loss: 0.565239
 >> iter 96000, loss: 0.432805
 >> iter 97000, loss: 0.511929
 >> iter 98000, loss: 0.474689
 >> iter 99000, loss: 0.692405
 >> iter 100000, loss: 0.641388
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

