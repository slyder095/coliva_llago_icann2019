 > Problema: tomita6nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.4
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.708877
 >> iter 2000, loss: 15.140071
 >> iter 3000, loss: 13.773410
 >> iter 4000, loss: 13.266223
 >> iter 5000, loss: 13.064086
 >> iter 6000, loss: 12.997277
 >> iter 7000, loss: 12.966410
 >> iter 8000, loss: 12.951767
 >> iter 9000, loss: 12.943676
 >> iter 10000, loss: 12.950569
   Number of active neurons: 5
 >> iter 11000, loss: 12.939548
 >> iter 12000, loss: 12.945831
 >> iter 13000, loss: 12.933436
 >> iter 14000, loss: 12.947119
 >> iter 15000, loss: 12.939058
 >> iter 16000, loss: 12.947058
 >> iter 17000, loss: 12.938289
 >> iter 18000, loss: 12.941908
 >> iter 19000, loss: 12.935913
 >> iter 20000, loss: 12.943253
   Number of active neurons: 6
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 6
 >> iter 21000, loss: 12.942863
 >> iter 22000, loss: 12.944601
 >> iter 23000, loss: 12.934772
 >> iter 24000, loss: 12.943194
 >> iter 25000, loss: 12.930951
 >> iter 26000, loss: 12.945693
 >> iter 27000, loss: 12.926590
 >> iter 28000, loss: 12.927428
 >> iter 29000, loss: 12.372813
 >> iter 30000, loss: 11.186191
   Number of active neurons: 10
 >> iter 31000, loss: 8.356059
 >> iter 32000, loss: 7.238847
 >> iter 33000, loss: 5.849955
 >> iter 34000, loss: 4.605093
 >> iter 35000, loss: 4.016154
 >> iter 36000, loss: 3.454705
 >> iter 37000, loss: 2.311347
 >> iter 38000, loss: 1.051578
 >> iter 39000, loss: 0.594010
 >> iter 40000, loss: 0.359587
   Number of active neurons: 10
 >> iter 41000, loss: 0.220417
 >> iter 42000, loss: 0.188166
 >> iter 43000, loss: 0.200728
 >> iter 44000, loss: 0.165845
 >> iter 45000, loss: 0.229447
 >> iter 46000, loss: 0.319135
 >> iter 47000, loss: 0.299659
 >> iter 48000, loss: 0.283817
 >> iter 49000, loss: 0.163086
 >> iter 50000, loss: 0.309919
   Number of active neurons: 10
 >> iter 51000, loss: 0.363497
 >> iter 52000, loss: 0.376486
 >> iter 53000, loss: 0.290820
 >> iter 54000, loss: 0.368880
 >> iter 55000, loss: 0.187858
 >> iter 56000, loss: 0.253290
 >> iter 57000, loss: 0.119617
 >> iter 58000, loss: 0.271252
 >> iter 59000, loss: 0.232782
 >> iter 60000, loss: 0.120428
   Number of active neurons: 10
 >> iter 61000, loss: 0.057929
 >> iter 62000, loss: 0.116108
 >> iter 63000, loss: 0.053360
 >> iter 64000, loss: 0.028341
 >> iter 65000, loss: 0.021051
 >> iter 66000, loss: 0.046878
 >> iter 67000, loss: 0.025713
 >> iter 68000, loss: 0.187054
 >> iter 69000, loss: 0.076970
 >> iter 70000, loss: 0.034627
   Number of active neurons: 10
 >> iter 71000, loss: 0.372086
 >> iter 72000, loss: 0.145769
 >> iter 73000, loss: 0.060723
 >> iter 74000, loss: 0.028583
 >> iter 75000, loss: 0.015898
 >> iter 76000, loss: 0.121602
 >> iter 77000, loss: 0.137360
 >> iter 78000, loss: 0.087981
 >> iter 79000, loss: 0.041167
 >> iter 80000, loss: 0.021061
   Number of active neurons: 10
 >> iter 81000, loss: 0.023916
 >> iter 82000, loss: 0.070118
 >> iter 83000, loss: 0.032335
 >> iter 84000, loss: 0.016336
 >> iter 85000, loss: 0.273645
 >> iter 86000, loss: 0.127973
 >> iter 87000, loss: 0.112948
 >> iter 88000, loss: 0.053114
 >> iter 89000, loss: 0.073335
 >> iter 90000, loss: 0.098761
   Number of active neurons: 10
 >> iter 91000, loss: 0.135023
 >> iter 92000, loss: 0.055665
 >> iter 93000, loss: 0.025606
 >> iter 94000, loss: 0.014364
 >> iter 95000, loss: 0.051925
 >> iter 96000, loss: 0.034049
 >> iter 97000, loss: 0.017102
 >> iter 98000, loss: 0.091060
 >> iter 99000, loss: 0.038291
 >> iter 100000, loss: 0.018241
   Number of active neurons: 10
 >> iter 101000, loss: 0.012141
 >> iter 102000, loss: 0.007951
 >> iter 103000, loss: 0.007519
 >> iter 104000, loss: 0.005967
 >> iter 105000, loss: 0.005226
 >> iter 106000, loss: 0.016591
 >> iter 107000, loss: 0.009285
 >> iter 108000, loss: 0.006263
 >> iter 109000, loss: 0.005902
 >> iter 110000, loss: 0.243221
   Number of active neurons: 10
 >> iter 111000, loss: 0.104013
 >> iter 112000, loss: 0.042045
 >> iter 113000, loss: 0.018708
 >> iter 114000, loss: 0.009943
 >> iter 115000, loss: 0.006617
 >> iter 116000, loss: 0.005516
 >> iter 117000, loss: 0.039919
 >> iter 118000, loss: 0.046241
 >> iter 119000, loss: 0.031231
 >> iter 120000, loss: 0.016539
   Number of active neurons: 10
 >> iter 121000, loss: 0.010867
 >> iter 122000, loss: 0.006719
 >> iter 123000, loss: 0.029156
 >> iter 124000, loss: 0.045062
 >> iter 125000, loss: 0.259920
 >> iter 126000, loss: 0.103682
 >> iter 127000, loss: 0.041601
 >> iter 128000, loss: 0.018525
 >> iter 129000, loss: 0.009949
 >> iter 130000, loss: 0.006534
   Number of active neurons: 10
 >> iter 131000, loss: 0.005083
 >> iter 132000, loss: 0.004384
 >> iter 133000, loss: 0.153195
 >> iter 134000, loss: 0.061245
 >> iter 135000, loss: 0.030923
 >> iter 136000, loss: 0.095492
 >> iter 137000, loss: 0.038349
 >> iter 138000, loss: 0.016880
 >> iter 139000, loss: 0.017580
 >> iter 140000, loss: 0.009191
   Number of active neurons: 10
 >> iter 141000, loss: 0.006115
 >> iter 142000, loss: 0.109183
 >> iter 143000, loss: 0.809611
 >> iter 144000, loss: 0.315292
 >> iter 145000, loss: 0.125846
 >> iter 146000, loss: 0.054442
 >> iter 147000, loss: 0.030517
 >> iter 148000, loss: 0.033328
 >> iter 149000, loss: 0.082430
 >> iter 150000, loss: 0.036520
   Number of active neurons: 10
 >> iter 151000, loss: 0.018661
 >> iter 152000, loss: 0.011663
 >> iter 153000, loss: 0.008590
 >> iter 154000, loss: 0.007261
 >> iter 155000, loss: 0.065604
 >> iter 156000, loss: 0.028578
 >> iter 157000, loss: 0.014472
 >> iter 158000, loss: 0.008998
 >> iter 159000, loss: 0.016667
 >> iter 160000, loss: 0.122849
   Number of active neurons: 10
 >> iter 161000, loss: 0.049805
 >> iter 162000, loss: 0.022101
 >> iter 163000, loss: 0.038897
 >> iter 164000, loss: 0.017583
 >> iter 165000, loss: 0.009524
 >> iter 166000, loss: 0.006377
 >> iter 167000, loss: 0.005055
 >> iter 168000, loss: 0.004564
 >> iter 169000, loss: 0.004168
 >> iter 170000, loss: 0.008260
   Number of active neurons: 10
 >> iter 171000, loss: 0.033566
 >> iter 172000, loss: 0.217070
 >> iter 173000, loss: 0.116730
 >> iter 174000, loss: 0.046307
 >> iter 175000, loss: 0.020037
 >> iter 176000, loss: 0.010250
 >> iter 177000, loss: 0.006414
 >> iter 178000, loss: 0.004786
 >> iter 179000, loss: 0.013503
 >> iter 180000, loss: 0.007829
   Number of active neurons: 10
 >> iter 181000, loss: 0.005316
 >> iter 182000, loss: 0.004300
 >> iter 183000, loss: 0.003684
 >> iter 184000, loss: 0.003424
 >> iter 185000, loss: 0.003489
 >> iter 186000, loss: 0.003180
 >> iter 187000, loss: 0.002976
 >> iter 188000, loss: 0.002853
 >> iter 189000, loss: 0.002748
 >> iter 190000, loss: 0.002667
   Number of active neurons: 10
 >> iter 191000, loss: 0.002767
 >> iter 192000, loss: 0.061675
 >> iter 193000, loss: 0.024695
 >> iter 194000, loss: 0.010956
 >> iter 195000, loss: 0.005811
 >> iter 196000, loss: 0.007984
 >> iter 197000, loss: 0.004601
 >> iter 198000, loss: 0.003397
 >> iter 199000, loss: 0.002787
 >> iter 200000, loss: 0.129030
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.689794
 >> iter 2000, loss: 15.155726
 >> iter 3000, loss: 13.799882
 >> iter 4000, loss: 13.291767
 >> iter 5000, loss: 13.078033
 >> iter 6000, loss: 13.012872
 >> iter 7000, loss: 12.975365
 >> iter 8000, loss: 12.971001
 >> iter 9000, loss: 12.954234
 >> iter 10000, loss: 12.963222
   Number of active neurons: 8
 >> iter 11000, loss: 12.949577
 >> iter 12000, loss: 12.956653
 >> iter 13000, loss: 12.952153
 >> iter 14000, loss: 12.961885
 >> iter 15000, loss: 12.951523
 >> iter 16000, loss: 12.959419
 >> iter 17000, loss: 12.951654
 >> iter 18000, loss: 12.956059
 >> iter 19000, loss: 12.952840
 >> iter 20000, loss: 12.958045
   Number of active neurons: 7
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 7
 >> iter 21000, loss: 12.948418
 >> iter 22000, loss: 12.954124
 >> iter 23000, loss: 12.947113
 >> iter 24000, loss: 12.961500
 >> iter 25000, loss: 12.950010
 >> iter 26000, loss: 12.963939
 >> iter 27000, loss: 12.947317
 >> iter 28000, loss: 12.955861
 >> iter 29000, loss: 12.950149
 >> iter 30000, loss: 12.957585
   Number of active neurons: 8
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 8
 >> iter 31000, loss: 12.950831
 >> iter 32000, loss: 12.959218
 >> iter 33000, loss: 12.949492
 >> iter 34000, loss: 12.958257
 >> iter 35000, loss: 12.955860
 >> iter 36000, loss: 12.960640
 >> iter 37000, loss: 12.951406
 >> iter 38000, loss: 12.952752
 >> iter 39000, loss: 12.941839
 >> iter 40000, loss: 12.798089
   Number of active neurons: 9
 >> iter 41000, loss: 11.489825
 >> iter 42000, loss: 5.118955
 >> iter 43000, loss: 1.969842
 >> iter 44000, loss: 0.898036
 >> iter 45000, loss: 0.368598
 >> iter 46000, loss: 0.219760
 >> iter 47000, loss: 0.096078
 >> iter 48000, loss: 0.046722
 >> iter 49000, loss: 0.026239
 >> iter 50000, loss: 0.035851
   Number of active neurons: 10
 >> iter 51000, loss: 0.020813
 >> iter 52000, loss: 0.014416
 >> iter 53000, loss: 0.011177
 >> iter 54000, loss: 0.009671
 >> iter 55000, loss: 0.012499
 >> iter 56000, loss: 0.011930
 >> iter 57000, loss: 0.008954
 >> iter 58000, loss: 0.007315
 >> iter 59000, loss: 0.006528
 >> iter 60000, loss: 0.005829
   Number of active neurons: 10
 >> iter 61000, loss: 0.005238
 >> iter 62000, loss: 0.005145
 >> iter 63000, loss: 0.035600
 >> iter 64000, loss: 0.016425
 >> iter 65000, loss: 0.009441
 >> iter 66000, loss: 0.006324
 >> iter 67000, loss: 0.011327
 >> iter 68000, loss: 0.007157
 >> iter 69000, loss: 0.005124
 >> iter 70000, loss: 0.004287
   Number of active neurons: 10
 >> iter 71000, loss: 0.003847
 >> iter 72000, loss: 0.003596
 >> iter 73000, loss: 0.003829
 >> iter 74000, loss: 0.003385
 >> iter 75000, loss: 0.003205
 >> iter 76000, loss: 0.003075
 >> iter 77000, loss: 0.002884
 >> iter 78000, loss: 0.002793
 >> iter 79000, loss: 0.002648
 >> iter 80000, loss: 0.002547
   Number of active neurons: 10
 >> iter 81000, loss: 0.002476
 >> iter 82000, loss: 0.028119
 >> iter 83000, loss: 0.129149
 >> iter 84000, loss: 0.260016
 >> iter 85000, loss: 0.099080
 >> iter 86000, loss: 0.038935
 >> iter 87000, loss: 0.016617
 >> iter 88000, loss: 0.008106
 >> iter 89000, loss: 0.005174
 >> iter 90000, loss: 0.003738
   Number of active neurons: 10
 >> iter 91000, loss: 0.003165
 >> iter 92000, loss: 0.002959
 >> iter 93000, loss: 0.002781
 >> iter 94000, loss: 0.002574
 >> iter 95000, loss: 0.002420
 >> iter 96000, loss: 0.002287
 >> iter 97000, loss: 0.002199
 >> iter 98000, loss: 0.002158
 >> iter 99000, loss: 0.002079
 >> iter 100000, loss: 0.002148
   Number of active neurons: 10
 >> iter 101000, loss: 0.002015
 >> iter 102000, loss: 0.001975
 >> iter 103000, loss: 0.001909
 >> iter 104000, loss: 0.001875
 >> iter 105000, loss: 0.001816
 >> iter 106000, loss: 0.002028
 >> iter 107000, loss: 0.001939
 >> iter 108000, loss: 0.001792
 >> iter 109000, loss: 0.001725
 >> iter 110000, loss: 0.001705
   Number of active neurons: 10
 >> iter 111000, loss: 0.001641
 >> iter 112000, loss: 0.004221
 >> iter 113000, loss: 0.002652
 >> iter 114000, loss: 0.001970
 >> iter 115000, loss: 0.001712
 >> iter 116000, loss: 0.001590
 >> iter 117000, loss: 0.001503
 >> iter 118000, loss: 0.001610
 >> iter 119000, loss: 0.001463
 >> iter 120000, loss: 0.001438
   Number of active neurons: 10
 >> iter 121000, loss: 0.001401
 >> iter 122000, loss: 0.001397
 >> iter 123000, loss: 0.001349
 >> iter 124000, loss: 0.001332
 >> iter 125000, loss: 0.045927
 >> iter 126000, loss: 0.048530
 >> iter 127000, loss: 0.019510
 >> iter 128000, loss: 0.008505
 >> iter 129000, loss: 0.004299
 >> iter 130000, loss: 0.002584
   Number of active neurons: 10
 >> iter 131000, loss: 0.001867
 >> iter 132000, loss: 0.001572
 >> iter 133000, loss: 0.001462
 >> iter 134000, loss: 0.001545
 >> iter 135000, loss: 0.001411
 >> iter 136000, loss: 0.001340
 >> iter 137000, loss: 0.001308
 >> iter 138000, loss: 0.001292
 >> iter 139000, loss: 0.001499
 >> iter 140000, loss: 0.003350
   Number of active neurons: 10
 >> iter 141000, loss: 0.002898
 >> iter 142000, loss: 0.002042
 >> iter 143000, loss: 0.001587
 >> iter 144000, loss: 0.001385
 >> iter 145000, loss: 0.001264
 >> iter 146000, loss: 0.001281
 >> iter 147000, loss: 0.001203
 >> iter 148000, loss: 0.001129
 >> iter 149000, loss: 0.008653
 >> iter 150000, loss: 0.012422
   Number of active neurons: 10
 >> iter 151000, loss: 0.005436
 >> iter 152000, loss: 0.002886
 >> iter 153000, loss: 0.001774
 >> iter 154000, loss: 0.001375
 >> iter 155000, loss: 0.001935
 >> iter 156000, loss: 0.001399
 >> iter 157000, loss: 0.001184
 >> iter 158000, loss: 0.001123
 >> iter 159000, loss: 0.001043
 >> iter 160000, loss: 0.001001
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.723504
 >> iter 2000, loss: 15.199697
 >> iter 3000, loss: 13.840556
 >> iter 4000, loss: 13.315426
 >> iter 5000, loss: 13.110166
 >> iter 6000, loss: 13.035323
 >> iter 7000, loss: 12.995467
 >> iter 8000, loss: 12.984451
 >> iter 9000, loss: 12.972773
 >> iter 10000, loss: 12.983386
   Number of active neurons: 9
 >> iter 11000, loss: 12.977125
 >> iter 12000, loss: 12.984064
 >> iter 13000, loss: 12.966199
 >> iter 14000, loss: 12.894835
 >> iter 15000, loss: 12.355178
 >> iter 16000, loss: 11.522743
 >> iter 17000, loss: 10.996006
 >> iter 18000, loss: 10.426460
 >> iter 19000, loss: 9.738840
 >> iter 20000, loss: 9.316527
   Number of active neurons: 10
 >> iter 21000, loss: 8.283550
 >> iter 22000, loss: 7.167515
 >> iter 23000, loss: 6.465705
 >> iter 24000, loss: 6.151839
 >> iter 25000, loss: 5.632843
 >> iter 26000, loss: 5.560537
 >> iter 27000, loss: 5.442970
 >> iter 28000, loss: 5.296565
 >> iter 29000, loss: 5.188790
 >> iter 30000, loss: 5.187921
   Number of active neurons: 10
 >> iter 31000, loss: 5.671540
 >> iter 32000, loss: 5.568487
 >> iter 33000, loss: 5.401692
 >> iter 34000, loss: 5.550618
 >> iter 35000, loss: 5.764660
 >> iter 36000, loss: 6.365697
 >> iter 37000, loss: 6.501995
 >> iter 38000, loss: 5.943036
 >> iter 39000, loss: 5.511737
 >> iter 40000, loss: 5.250684
   Number of active neurons: 10
 >> iter 41000, loss: 4.792564
 >> iter 42000, loss: 4.808252
 >> iter 43000, loss: 4.560800
 >> iter 44000, loss: 4.803734
 >> iter 45000, loss: 4.743209
 >> iter 46000, loss: 4.501993
 >> iter 47000, loss: 4.218371
 >> iter 48000, loss: 4.478167
 >> iter 49000, loss: 4.126352
 >> iter 50000, loss: 4.726799
   Number of active neurons: 10
 >> iter 51000, loss: 4.385339
 >> iter 52000, loss: 4.346208
 >> iter 53000, loss: 4.223942
 >> iter 54000, loss: 4.494497
 >> iter 55000, loss: 6.536725
 >> iter 56000, loss: 5.319567
 >> iter 57000, loss: 4.414419
 >> iter 58000, loss: 4.511760
 >> iter 59000, loss: 4.415480
 >> iter 60000, loss: 3.810211
   Number of active neurons: 10
 >> iter 61000, loss: 3.752729
 >> iter 62000, loss: 3.908575
 >> iter 63000, loss: 3.682666
 >> iter 64000, loss: 3.906519
 >> iter 65000, loss: 3.650148
 >> iter 66000, loss: 3.833594
 >> iter 67000, loss: 3.885045
 >> iter 68000, loss: 3.964911
 >> iter 69000, loss: 3.941833
 >> iter 70000, loss: 3.724542
   Number of active neurons: 10
 >> iter 71000, loss: 3.774782
 >> iter 72000, loss: 3.678046
 >> iter 73000, loss: 3.703870
 >> iter 74000, loss: 4.136901
 >> iter 75000, loss: 3.960538
 >> iter 76000, loss: 3.688596
 >> iter 77000, loss: 3.560209
 >> iter 78000, loss: 3.826391
 >> iter 79000, loss: 3.539640
 >> iter 80000, loss: 4.040091
   Number of active neurons: 10
 >> iter 81000, loss: 4.065321
 >> iter 82000, loss: 4.047216
 >> iter 83000, loss: 3.622313
 >> iter 84000, loss: 3.505636
 >> iter 85000, loss: 3.617459
 >> iter 86000, loss: 3.913843
 >> iter 87000, loss: 3.470014
 >> iter 88000, loss: 3.329084
 >> iter 89000, loss: 3.491484
 >> iter 90000, loss: 3.492720
   Number of active neurons: 10
 >> iter 91000, loss: 3.574472
 >> iter 92000, loss: 3.410259
 >> iter 93000, loss: 3.408447
 >> iter 94000, loss: 3.487457
 >> iter 95000, loss: 3.343760
 >> iter 96000, loss: 3.468268
 >> iter 97000, loss: 3.289422
 >> iter 98000, loss: 3.465517
 >> iter 99000, loss: 3.304986
 >> iter 100000, loss: 3.898038
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 5.98188036239
   - Test - Long: 26.0586970651
   - Test - Big: 6.0029399706
   - Test - A: 15.2256516232
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.746054
 >> iter 2000, loss: 15.190994
 >> iter 3000, loss: 13.812487
 >> iter 4000, loss: 13.299713
 >> iter 5000, loss: 13.096954
 >> iter 6000, loss: 13.026914
 >> iter 7000, loss: 12.990510
 >> iter 8000, loss: 12.986709
 >> iter 9000, loss: 12.980094
 >> iter 10000, loss: 12.961712
   Number of active neurons: 8
 >> iter 11000, loss: 12.729591
 >> iter 12000, loss: 12.092438
 >> iter 13000, loss: 9.646165
 >> iter 14000, loss: 3.934931
 >> iter 15000, loss: 1.873665
 >> iter 16000, loss: 0.730001
 >> iter 17000, loss: 0.304501
 >> iter 18000, loss: 0.129474
 >> iter 19000, loss: 0.220968
 >> iter 20000, loss: 0.096649
   Number of active neurons: 10
 >> iter 21000, loss: 0.204769
 >> iter 22000, loss: 0.125281
 >> iter 23000, loss: 0.056112
 >> iter 24000, loss: 0.028964
 >> iter 25000, loss: 0.079411
 >> iter 26000, loss: 0.055059
 >> iter 27000, loss: 0.065555
 >> iter 28000, loss: 0.030259
 >> iter 29000, loss: 0.016485
 >> iter 30000, loss: 0.041665
   Number of active neurons: 10
 >> iter 31000, loss: 0.020797
 >> iter 32000, loss: 0.012781
 >> iter 33000, loss: 0.071811
 >> iter 34000, loss: 0.031573
 >> iter 35000, loss: 0.015787
 >> iter 36000, loss: 0.009752
 >> iter 37000, loss: 0.007088
 >> iter 38000, loss: 0.027262
 >> iter 39000, loss: 0.013602
 >> iter 40000, loss: 0.008147
   Number of active neurons: 10
 >> iter 41000, loss: 0.179253
 >> iter 42000, loss: 0.070316
 >> iter 43000, loss: 0.031717
 >> iter 44000, loss: 0.015651
 >> iter 45000, loss: 0.121822
 >> iter 46000, loss: 0.049086
 >> iter 47000, loss: 0.021962
 >> iter 48000, loss: 0.011432
 >> iter 49000, loss: 0.016003
 >> iter 50000, loss: 0.009022
   Number of active neurons: 10
 >> iter 51000, loss: 0.006132
 >> iter 52000, loss: 0.004823
 >> iter 53000, loss: 0.004228
 >> iter 54000, loss: 0.003975
 >> iter 55000, loss: 0.003714
 >> iter 56000, loss: 0.003732
 >> iter 57000, loss: 0.010754
 >> iter 58000, loss: 0.006139
 >> iter 59000, loss: 0.004219
 >> iter 60000, loss: 0.003416
   Number of active neurons: 10
 >> iter 61000, loss: 0.002946
 >> iter 62000, loss: 0.002721
 >> iter 63000, loss: 0.002615
 >> iter 64000, loss: 0.002455
 >> iter 65000, loss: 0.002384
 >> iter 66000, loss: 0.002338
 >> iter 67000, loss: 0.002257
 >> iter 68000, loss: 0.024164
 >> iter 69000, loss: 0.010679
 >> iter 70000, loss: 0.005484
   Number of active neurons: 10
 >> iter 71000, loss: 0.003529
 >> iter 72000, loss: 0.002671
 >> iter 73000, loss: 0.002336
 >> iter 74000, loss: 0.002194
 >> iter 75000, loss: 0.002159
 >> iter 76000, loss: 0.002001
 >> iter 77000, loss: 0.001962
 >> iter 78000, loss: 0.065404
 >> iter 79000, loss: 0.025860
 >> iter 80000, loss: 0.011017
   Number of active neurons: 10
 >> iter 81000, loss: 0.005353
 >> iter 82000, loss: 0.003319
 >> iter 83000, loss: 0.002375
 >> iter 84000, loss: 0.002074
 >> iter 85000, loss: 0.001837
 >> iter 86000, loss: 0.001718
 >> iter 87000, loss: 0.001656
 >> iter 88000, loss: 0.001622
 >> iter 89000, loss: 0.001560
 >> iter 90000, loss: 0.001537
   Number of active neurons: 10
 >> iter 91000, loss: 0.001459
 >> iter 92000, loss: 0.001450
 >> iter 93000, loss: 0.001418
 >> iter 94000, loss: 0.001409
 >> iter 95000, loss: 0.001362
 >> iter 96000, loss: 0.001366
 >> iter 97000, loss: 0.001320
 >> iter 98000, loss: 0.001288
 >> iter 99000, loss: 0.072130
 >> iter 100000, loss: 0.027668
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.705718
 >> iter 2000, loss: 15.186011
 >> iter 3000, loss: 13.831132
 >> iter 4000, loss: 13.325438
 >> iter 5000, loss: 13.118197
 >> iter 6000, loss: 13.048968
 >> iter 7000, loss: 13.014854
 >> iter 8000, loss: 13.005954
 >> iter 9000, loss: 12.993622
 >> iter 10000, loss: 12.996877
   Number of active neurons: 9
 >> iter 11000, loss: 12.975724
 >> iter 12000, loss: 12.987419
 >> iter 13000, loss: 12.979168
 >> iter 14000, loss: 12.981205
 >> iter 15000, loss: 12.801212
 >> iter 16000, loss: 11.839751
 >> iter 17000, loss: 11.177400
 >> iter 18000, loss: 10.785314
 >> iter 19000, loss: 10.262791
 >> iter 20000, loss: 9.775371
   Number of active neurons: 10
 >> iter 21000, loss: 9.371856
 >> iter 22000, loss: 9.057799
 >> iter 23000, loss: 8.475782
 >> iter 24000, loss: 7.264179
 >> iter 25000, loss: 6.765888
 >> iter 26000, loss: 3.821898
 >> iter 27000, loss: 1.551404
 >> iter 28000, loss: 0.896598
 >> iter 29000, loss: 0.884941
 >> iter 30000, loss: 1.237571
   Number of active neurons: 10
 >> iter 31000, loss: 0.968142
 >> iter 32000, loss: 0.625724
 >> iter 33000, loss: 0.624280
 >> iter 34000, loss: 0.508597
 >> iter 35000, loss: 0.589325
 >> iter 36000, loss: 1.038376
 >> iter 37000, loss: 0.825364
 >> iter 38000, loss: 0.626929
 >> iter 39000, loss: 0.388356
 >> iter 40000, loss: 0.352289
   Number of active neurons: 10
 >> iter 41000, loss: 0.299541
 >> iter 42000, loss: 0.488601
 >> iter 43000, loss: 0.410030
 >> iter 44000, loss: 0.260739
 >> iter 45000, loss: 0.248963
 >> iter 46000, loss: 0.114424
 >> iter 47000, loss: 0.063093
 >> iter 48000, loss: 0.036571
 >> iter 49000, loss: 0.026265
 >> iter 50000, loss: 0.031535
   Number of active neurons: 10
 >> iter 51000, loss: 0.023298
 >> iter 52000, loss: 0.063064
 >> iter 53000, loss: 0.046117
 >> iter 54000, loss: 0.216037
 >> iter 55000, loss: 0.203613
 >> iter 56000, loss: 0.084432
 >> iter 57000, loss: 0.120045
 >> iter 58000, loss: 0.052057
 >> iter 59000, loss: 0.026297
 >> iter 60000, loss: 0.015900
   Number of active neurons: 10
 >> iter 61000, loss: 0.052105
 >> iter 62000, loss: 0.046941
 >> iter 63000, loss: 0.033782
 >> iter 64000, loss: 0.024107
 >> iter 65000, loss: 0.025459
 >> iter 66000, loss: 0.015362
 >> iter 67000, loss: 0.010233
 >> iter 68000, loss: 0.007879
 >> iter 69000, loss: 0.006838
 >> iter 70000, loss: 0.006274
   Number of active neurons: 10
 >> iter 71000, loss: 0.005826
 >> iter 72000, loss: 0.034781
 >> iter 73000, loss: 0.032782
 >> iter 74000, loss: 0.015361
 >> iter 75000, loss: 0.008605
 >> iter 76000, loss: 0.145479
 >> iter 77000, loss: 0.057252
 >> iter 78000, loss: 0.024285
 >> iter 79000, loss: 0.011777
 >> iter 80000, loss: 0.010044
   Number of active neurons: 10
 >> iter 81000, loss: 0.010413
 >> iter 82000, loss: 0.021235
 >> iter 83000, loss: 0.085752
 >> iter 84000, loss: 0.130833
 >> iter 85000, loss: 0.060407
 >> iter 86000, loss: 0.060473
 >> iter 87000, loss: 0.025963
 >> iter 88000, loss: 0.330742
 >> iter 89000, loss: 0.128636
 >> iter 90000, loss: 0.147061
   Number of active neurons: 10
 >> iter 91000, loss: 0.059471
 >> iter 92000, loss: 0.027395
 >> iter 93000, loss: 0.072439
 >> iter 94000, loss: 0.032366
 >> iter 95000, loss: 0.017220
 >> iter 96000, loss: 0.012018
 >> iter 97000, loss: 0.085035
 >> iter 98000, loss: 0.089603
 >> iter 99000, loss: 0.122695
 >> iter 100000, loss: 0.049709
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.742270
 >> iter 2000, loss: 15.162941
 >> iter 3000, loss: 13.800291
 >> iter 4000, loss: 13.292981
 >> iter 5000, loss: 13.089127
 >> iter 6000, loss: 13.022369
 >> iter 7000, loss: 12.989922
 >> iter 8000, loss: 12.986733
 >> iter 9000, loss: 12.978678
 >> iter 10000, loss: 12.985731
   Number of active neurons: 8
 >> iter 11000, loss: 12.975679
 >> iter 12000, loss: 12.971891
 >> iter 13000, loss: 12.962622
 >> iter 14000, loss: 12.976566
 >> iter 15000, loss: 12.957839
 >> iter 16000, loss: 12.974344
 >> iter 17000, loss: 12.964871
 >> iter 18000, loss: 12.973260
 >> iter 19000, loss: 12.963786
 >> iter 20000, loss: 12.977072
   Number of active neurons: 8
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 8
 >> iter 21000, loss: 12.916495
 >> iter 22000, loss: 11.844343
 >> iter 23000, loss: 10.558527
 >> iter 24000, loss: 9.617765
 >> iter 25000, loss: 7.533089
 >> iter 26000, loss: 3.272747
 >> iter 27000, loss: 1.340832
 >> iter 28000, loss: 0.537997
 >> iter 29000, loss: 0.265375
 >> iter 30000, loss: 0.136311
   Number of active neurons: 10
 >> iter 31000, loss: 0.069578
 >> iter 32000, loss: 0.041388
 >> iter 33000, loss: 0.028413
 >> iter 34000, loss: 0.021531
 >> iter 35000, loss: 0.151347
 >> iter 36000, loss: 0.065674
 >> iter 37000, loss: 0.033185
 >> iter 38000, loss: 0.022079
 >> iter 39000, loss: 0.016119
 >> iter 40000, loss: 0.012555
   Number of active neurons: 10
 >> iter 41000, loss: 0.055914
 >> iter 42000, loss: 0.027669
 >> iter 43000, loss: 0.016557
 >> iter 44000, loss: 0.011611
 >> iter 45000, loss: 0.009420
 >> iter 46000, loss: 0.009098
 >> iter 47000, loss: 0.008047
 >> iter 48000, loss: 0.007170
 >> iter 49000, loss: 0.006707
 >> iter 50000, loss: 0.006170
   Number of active neurons: 10
 >> iter 51000, loss: 0.005902
 >> iter 52000, loss: 0.005498
 >> iter 53000, loss: 0.005250
 >> iter 54000, loss: 0.004901
 >> iter 55000, loss: 0.017639
 >> iter 56000, loss: 0.009361
 >> iter 57000, loss: 0.006304
 >> iter 58000, loss: 0.005015
 >> iter 59000, loss: 0.004791
 >> iter 60000, loss: 0.004194
   Number of active neurons: 10
 >> iter 61000, loss: 0.003988
 >> iter 62000, loss: 0.003715
 >> iter 63000, loss: 0.021183
 >> iter 64000, loss: 0.042544
 >> iter 65000, loss: 0.018688
 >> iter 66000, loss: 0.009253
 >> iter 67000, loss: 0.006132
 >> iter 68000, loss: 0.004437
 >> iter 69000, loss: 0.003787
 >> iter 70000, loss: 0.003642
   Number of active neurons: 10
 >> iter 71000, loss: 0.003328
 >> iter 72000, loss: 0.003048
 >> iter 73000, loss: 0.002877
 >> iter 74000, loss: 0.002763
 >> iter 75000, loss: 0.002662
 >> iter 76000, loss: 0.223307
 >> iter 77000, loss: 0.084275
 >> iter 78000, loss: 0.033243
 >> iter 79000, loss: 0.014152
 >> iter 80000, loss: 0.006915
   Number of active neurons: 10
 >> iter 81000, loss: 0.004417
 >> iter 82000, loss: 0.003247
 >> iter 83000, loss: 0.002717
 >> iter 84000, loss: 0.002399
 >> iter 85000, loss: 0.004751
 >> iter 86000, loss: 0.003581
 >> iter 87000, loss: 0.003367
 >> iter 88000, loss: 0.006314
 >> iter 89000, loss: 0.004396
 >> iter 90000, loss: 0.003207
   Number of active neurons: 10
 >> iter 91000, loss: 0.002960
 >> iter 92000, loss: 0.002602
 >> iter 93000, loss: 0.002341
 >> iter 94000, loss: 0.002479
 >> iter 95000, loss: 0.002216
 >> iter 96000, loss: 0.002057
 >> iter 97000, loss: 0.001943
 >> iter 98000, loss: 0.001828
 >> iter 99000, loss: 0.001782
 >> iter 100000, loss: 0.001701
   Number of active neurons: 10
 >> iter 101000, loss: 0.001574
 >> iter 102000, loss: 0.002675
 >> iter 103000, loss: 0.002749
 >> iter 104000, loss: 0.002051
 >> iter 105000, loss: 0.001712
 >> iter 106000, loss: 0.031435
 >> iter 107000, loss: 0.012942
 >> iter 108000, loss: 0.006036
 >> iter 109000, loss: 0.003861
 >> iter 110000, loss: 0.002593
   Number of active neurons: 10
 >> iter 111000, loss: 0.002081
 >> iter 112000, loss: 0.001738
 >> iter 113000, loss: 0.001679
 >> iter 114000, loss: 0.001498
 >> iter 115000, loss: 0.001424
 >> iter 116000, loss: 0.001319
 >> iter 117000, loss: 0.001302
 >> iter 118000, loss: 0.001261
 >> iter 119000, loss: 0.001246
 >> iter 120000, loss: 0.001156
   Number of active neurons: 10
 >> iter 121000, loss: 0.001175
 >> iter 122000, loss: 0.001138
 >> iter 123000, loss: 0.001992
 >> iter 124000, loss: 0.001499
 >> iter 125000, loss: 0.001359
 >> iter 126000, loss: 0.001193
 >> iter 127000, loss: 0.001121
 >> iter 128000, loss: 0.001420
 >> iter 129000, loss: 0.001165
 >> iter 130000, loss: 0.001192
   Number of active neurons: 10
 >> iter 131000, loss: 0.001162
 >> iter 132000, loss: 0.001048
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 18.732378
 >> iter 2000, loss: 15.183093
 >> iter 3000, loss: 13.819199
 >> iter 4000, loss: 13.319025
 >> iter 5000, loss: 13.115979
 >> iter 6000, loss: 13.052077
 >> iter 7000, loss: 13.013837
 >> iter 8000, loss: 13.001003
 >> iter 9000, loss: 12.988469
 >> iter 10000, loss: 12.980278
   Number of active neurons: 7
 >> iter 11000, loss: 12.907657
 >> iter 12000, loss: 12.041621
 >> iter 13000, loss: 11.099948
 >> iter 14000, loss: 9.706709
 >> iter 15000, loss: 8.137292
 >> iter 16000, loss: 6.784823
 >> iter 17000, loss: 6.073883
 >> iter 18000, loss: 5.613315
 >> iter 19000, loss: 4.970302
 >> iter 20000, loss: 4.518843
   Number of active neurons: 10
 >> iter 21000, loss: 4.458805
 >> iter 22000, loss: 4.206435
 >> iter 23000, loss: 3.902669
 >> iter 24000, loss: 4.563102
 >> iter 25000, loss: 4.048910
 >> iter 26000, loss: 1.910352
 >> iter 27000, loss: 1.926902
 >> iter 28000, loss: 0.824345
 >> iter 29000, loss: 0.609658
 >> iter 30000, loss: 0.475224
   Number of active neurons: 10
 >> iter 31000, loss: 0.285638
 >> iter 32000, loss: 0.191487
 >> iter 33000, loss: 0.211849
 >> iter 34000, loss: 0.111281
 >> iter 35000, loss: 0.132793
 >> iter 36000, loss: 0.495910
 >> iter 37000, loss: 0.207374
 >> iter 38000, loss: 0.306342
 >> iter 39000, loss: 0.315869
 >> iter 40000, loss: 0.151966
   Number of active neurons: 10
 >> iter 41000, loss: 0.208093
 >> iter 42000, loss: 0.137142
 >> iter 43000, loss: 0.065897
 >> iter 44000, loss: 0.037113
 >> iter 45000, loss: 0.026224
 >> iter 46000, loss: 0.020148
 >> iter 47000, loss: 0.069946
 >> iter 48000, loss: 0.035619
 >> iter 49000, loss: 0.056502
 >> iter 50000, loss: 0.224946
   Number of active neurons: 10
 >> iter 51000, loss: 0.093275
 >> iter 52000, loss: 0.053791
 >> iter 53000, loss: 0.090460
 >> iter 54000, loss: 0.043383
 >> iter 55000, loss: 0.024518
 >> iter 56000, loss: 0.239808
 >> iter 57000, loss: 0.110551
 >> iter 58000, loss: 0.048877
 >> iter 59000, loss: 0.031594
 >> iter 60000, loss: 0.018515
   Number of active neurons: 10
 >> iter 61000, loss: 0.013131
 >> iter 62000, loss: 0.010888
 >> iter 63000, loss: 0.009591
 >> iter 64000, loss: 0.008781
 >> iter 65000, loss: 0.113804
 >> iter 66000, loss: 0.107777
 >> iter 67000, loss: 0.046106
 >> iter 68000, loss: 0.201087
 >> iter 69000, loss: 0.081500
 >> iter 70000, loss: 0.036250
   Number of active neurons: 10
 >> iter 71000, loss: 0.019173
 >> iter 72000, loss: 0.012253
 >> iter 73000, loss: 0.009350
 >> iter 74000, loss: 0.008051
 >> iter 75000, loss: 0.027974
 >> iter 76000, loss: 0.015293
 >> iter 77000, loss: 0.009824
 >> iter 78000, loss: 0.007502
 >> iter 79000, loss: 0.006670
 >> iter 80000, loss: 0.006191
   Number of active neurons: 10
 >> iter 81000, loss: 0.006003
 >> iter 82000, loss: 0.005667
 >> iter 83000, loss: 0.005447
 >> iter 84000, loss: 0.005237
 >> iter 85000, loss: 0.005319
 >> iter 86000, loss: 0.005219
 >> iter 87000, loss: 0.004927
 >> iter 88000, loss: 0.004734
 >> iter 89000, loss: 0.004656
 >> iter 90000, loss: 0.004474
   Number of active neurons: 10
 >> iter 91000, loss: 0.004458
 >> iter 92000, loss: 0.036806
 >> iter 93000, loss: 0.016539
 >> iter 94000, loss: 0.017684
 >> iter 95000, loss: 0.102201
 >> iter 96000, loss: 0.040949
 >> iter 97000, loss: 0.018119
 >> iter 98000, loss: 0.009429
 >> iter 99000, loss: 0.058048
 >> iter 100000, loss: 0.024687
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 18.697532
 >> iter 2000, loss: 15.135939
 >> iter 3000, loss: 13.782627
 >> iter 4000, loss: 13.276420
 >> iter 5000, loss: 13.079939
 >> iter 6000, loss: 13.012309
 >> iter 7000, loss: 12.977225
 >> iter 8000, loss: 12.970581
 >> iter 9000, loss: 12.958679
 >> iter 10000, loss: 12.973261
   Number of active neurons: 6
 >> iter 11000, loss: 12.963396
 >> iter 12000, loss: 12.962721
 >> iter 13000, loss: 12.958664
 >> iter 14000, loss: 12.964679
 >> iter 15000, loss: 12.956082
 >> iter 16000, loss: 12.967848
 >> iter 17000, loss: 12.960865
 >> iter 18000, loss: 12.962659
 >> iter 19000, loss: 12.947744
 >> iter 20000, loss: 12.955716
   Number of active neurons: 6
 >> iter 21000, loss: 12.899309
 >> iter 22000, loss: 12.036398
 >> iter 23000, loss: 11.320965
 >> iter 24000, loss: 11.025917
 >> iter 25000, loss: 10.736773
 >> iter 26000, loss: 10.422502
 >> iter 27000, loss: 10.005032
 >> iter 28000, loss: 9.442812
 >> iter 29000, loss: 8.785114
 >> iter 30000, loss: 8.424712
   Number of active neurons: 10
 >> iter 31000, loss: 8.135938
 >> iter 32000, loss: 7.530826
 >> iter 33000, loss: 7.173191
 >> iter 34000, loss: 6.782822
 >> iter 35000, loss: 6.482541
 >> iter 36000, loss: 6.460205
 >> iter 37000, loss: 4.450012
 >> iter 38000, loss: 2.557357
 >> iter 39000, loss: 2.174047
 >> iter 40000, loss: 1.609474
   Number of active neurons: 10
 >> iter 41000, loss: 1.358453
 >> iter 42000, loss: 1.521337
 >> iter 43000, loss: 0.751252
 >> iter 44000, loss: 0.486213
 >> iter 45000, loss: 0.644173
 >> iter 46000, loss: 0.356346
 >> iter 47000, loss: 0.569820
 >> iter 48000, loss: 0.339537
 >> iter 49000, loss: 0.385723
 >> iter 50000, loss: 0.280638
   Number of active neurons: 10
 >> iter 51000, loss: 0.206878
 >> iter 52000, loss: 0.284722
 >> iter 53000, loss: 0.206595
 >> iter 54000, loss: 0.525517
 >> iter 55000, loss: 0.231873
 >> iter 56000, loss: 0.137536
 >> iter 57000, loss: 0.278362
 >> iter 58000, loss: 0.367178
 >> iter 59000, loss: 0.189139
 >> iter 60000, loss: 0.175622
   Number of active neurons: 10
 >> iter 61000, loss: 0.147293
 >> iter 62000, loss: 0.266330
 >> iter 63000, loss: 0.117985
 >> iter 64000, loss: 0.083607
 >> iter 65000, loss: 0.128069
 >> iter 66000, loss: 0.121361
 >> iter 67000, loss: 0.126351
 >> iter 68000, loss: 0.118955
 >> iter 69000, loss: 0.282175
 >> iter 70000, loss: 0.454421
   Number of active neurons: 10
 >> iter 71000, loss: 0.213838
 >> iter 72000, loss: 0.133346
 >> iter 73000, loss: 0.097019
 >> iter 74000, loss: 0.175768
 >> iter 75000, loss: 0.098891
 >> iter 76000, loss: 0.063594
 >> iter 77000, loss: 0.044238
 >> iter 78000, loss: 0.026429
 >> iter 79000, loss: 0.072438
 >> iter 80000, loss: 0.040726
   Number of active neurons: 10
 >> iter 81000, loss: 0.075695
 >> iter 82000, loss: 0.051810
 >> iter 83000, loss: 0.027606
 >> iter 84000, loss: 0.019066
 >> iter 85000, loss: 0.014966
 >> iter 86000, loss: 0.130669
 >> iter 87000, loss: 0.056390
 >> iter 88000, loss: 0.028206
 >> iter 89000, loss: 0.060913
 >> iter 90000, loss: 0.057881
   Number of active neurons: 10
 >> iter 91000, loss: 0.031815
 >> iter 92000, loss: 0.132682
 >> iter 93000, loss: 0.145885
 >> iter 94000, loss: 0.198187
 >> iter 95000, loss: 0.191378
 >> iter 96000, loss: 0.084658
 >> iter 97000, loss: 0.040618
 >> iter 98000, loss: 0.096099
 >> iter 99000, loss: 0.365832
 >> iter 100000, loss: 0.353075
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0319993600128
   - Test - Long: 0.0
   - Test - Big: 0.0119998800012
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.683176
 >> iter 2000, loss: 15.187301
 >> iter 3000, loss: 13.824613
 >> iter 4000, loss: 13.296779
 >> iter 5000, loss: 13.097629
 >> iter 6000, loss: 13.011631
 >> iter 7000, loss: 12.975174
 >> iter 8000, loss: 12.977614
 >> iter 9000, loss: 12.961501
 >> iter 10000, loss: 12.972391
   Number of active neurons: 7
 >> iter 11000, loss: 12.955400
 >> iter 12000, loss: 12.964193
 >> iter 13000, loss: 12.957919
 >> iter 14000, loss: 12.964238
 >> iter 15000, loss: 12.956495
 >> iter 16000, loss: 12.970039
 >> iter 17000, loss: 12.960234
 >> iter 18000, loss: 12.960234
 >> iter 19000, loss: 12.954280
 >> iter 20000, loss: 12.965211
   Number of active neurons: 6
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 6
 >> iter 21000, loss: 12.943271
 >> iter 22000, loss: 12.886777
 >> iter 23000, loss: 11.883935
 >> iter 24000, loss: 10.940513
 >> iter 25000, loss: 10.073939
 >> iter 26000, loss: 10.033474
 >> iter 27000, loss: 9.379140
 >> iter 28000, loss: 4.828370
 >> iter 29000, loss: 2.534761
 >> iter 30000, loss: 1.385434
   Number of active neurons: 10
 >> iter 31000, loss: 0.924811
 >> iter 32000, loss: 0.486779
 >> iter 33000, loss: 0.519435
 >> iter 34000, loss: 0.432264
 >> iter 35000, loss: 0.233975
 >> iter 36000, loss: 0.152926
 >> iter 37000, loss: 0.290580
 >> iter 38000, loss: 0.312009
 >> iter 39000, loss: 0.183128
 >> iter 40000, loss: 0.092865
   Number of active neurons: 10
 >> iter 41000, loss: 0.109361
 >> iter 42000, loss: 0.057026
 >> iter 43000, loss: 0.224981
 >> iter 44000, loss: 0.099903
 >> iter 45000, loss: 0.203330
 >> iter 46000, loss: 0.092170
 >> iter 47000, loss: 0.071541
 >> iter 48000, loss: 0.052402
 >> iter 49000, loss: 0.030928
 >> iter 50000, loss: 0.034078
   Number of active neurons: 10
 >> iter 51000, loss: 0.024226
 >> iter 52000, loss: 0.018690
 >> iter 53000, loss: 0.057336
 >> iter 54000, loss: 0.113982
 >> iter 55000, loss: 0.068388
 >> iter 56000, loss: 0.314779
 >> iter 57000, loss: 0.178230
 >> iter 58000, loss: 0.257207
 >> iter 59000, loss: 0.106772
 >> iter 60000, loss: 0.163406
   Number of active neurons: 10
 >> iter 61000, loss: 0.161245
 >> iter 62000, loss: 0.074688
 >> iter 63000, loss: 0.220943
 >> iter 64000, loss: 0.130478
 >> iter 65000, loss: 0.287652
 >> iter 66000, loss: 0.539375
 >> iter 67000, loss: 0.251539
 >> iter 68000, loss: 0.238196
 >> iter 69000, loss: 0.114570
 >> iter 70000, loss: 0.058084
   Number of active neurons: 10
 >> iter 71000, loss: 0.063213
 >> iter 72000, loss: 0.032737
 >> iter 73000, loss: 0.020357
 >> iter 74000, loss: 0.022826
 >> iter 75000, loss: 0.016167
 >> iter 76000, loss: 0.012739
 >> iter 77000, loss: 0.010962
 >> iter 78000, loss: 0.009608
 >> iter 79000, loss: 0.008981
 >> iter 80000, loss: 0.008585
   Number of active neurons: 10
 >> iter 81000, loss: 0.102321
 >> iter 82000, loss: 0.453303
 >> iter 83000, loss: 0.182453
 >> iter 84000, loss: 0.129048
 >> iter 85000, loss: 0.309975
 >> iter 86000, loss: 0.190624
 >> iter 87000, loss: 0.197667
 >> iter 88000, loss: 0.118202
 >> iter 89000, loss: 0.052699
 >> iter 90000, loss: 0.027311
   Number of active neurons: 10
 >> iter 91000, loss: 0.017434
 >> iter 92000, loss: 0.128410
 >> iter 93000, loss: 0.164933
 >> iter 94000, loss: 0.205825
 >> iter 95000, loss: 0.086072
 >> iter 96000, loss: 0.039106
 >> iter 97000, loss: 0.020995
 >> iter 98000, loss: 0.013928
 >> iter 99000, loss: 0.010900
 >> iter 100000, loss: 0.009534
   Number of active neurons: 10
 >> iter 101000, loss: 0.008533
 >> iter 102000, loss: 0.008069
 >> iter 103000, loss: 0.008154
 >> iter 104000, loss: 0.007787
 >> iter 105000, loss: 0.007312
 >> iter 106000, loss: 0.006958
 >> iter 107000, loss: 0.006648
 >> iter 108000, loss: 0.082640
 >> iter 109000, loss: 0.035454
 >> iter 110000, loss: 0.017801
   Number of active neurons: 10
 >> iter 111000, loss: 0.010814
 >> iter 112000, loss: 0.007836
 >> iter 113000, loss: 0.006706
 >> iter 114000, loss: 0.006201
 >> iter 115000, loss: 0.011950
 >> iter 116000, loss: 0.015778
 >> iter 117000, loss: 0.009750
 >> iter 118000, loss: 0.062237
 >> iter 119000, loss: 0.137333
 >> iter 120000, loss: 0.137409
   Number of active neurons: 10
 >> iter 121000, loss: 0.055617
 >> iter 122000, loss: 0.024731
 >> iter 123000, loss: 0.013301
 >> iter 124000, loss: 0.008543
 >> iter 125000, loss: 0.006716
 >> iter 126000, loss: 0.005798
 >> iter 127000, loss: 0.005391
 >> iter 128000, loss: 0.005159
 >> iter 129000, loss: 0.005084
 >> iter 130000, loss: 0.005291
   Number of active neurons: 10
 >> iter 131000, loss: 0.006192
 >> iter 132000, loss: 0.020805
 >> iter 133000, loss: 0.011488
 >> iter 134000, loss: 0.083975
 >> iter 135000, loss: 0.034314
 >> iter 136000, loss: 0.015756
 >> iter 137000, loss: 0.008823
 >> iter 138000, loss: 0.006053
 >> iter 139000, loss: 0.045694
 >> iter 140000, loss: 0.020796
   Number of active neurons: 10
 >> iter 141000, loss: 0.010991
 >> iter 142000, loss: 0.007550
 >> iter 143000, loss: 0.005683
 >> iter 144000, loss: 0.008962
 >> iter 145000, loss: 0.006215
 >> iter 146000, loss: 0.004782
 >> iter 147000, loss: 0.042528
 >> iter 148000, loss: 0.018602
 >> iter 149000, loss: 0.009642
 >> iter 150000, loss: 0.006042
   Number of active neurons: 10
 >> iter 151000, loss: 0.004793
 >> iter 152000, loss: 0.004216
 >> iter 153000, loss: 0.003799
 >> iter 154000, loss: 0.003621
 >> iter 155000, loss: 0.003537
 >> iter 156000, loss: 0.033249
 >> iter 157000, loss: 0.015395
 >> iter 158000, loss: 0.035385
 >> iter 159000, loss: 0.015923
 >> iter 160000, loss: 0.008203
   Number of active neurons: 10
 >> iter 161000, loss: 0.005465
 >> iter 162000, loss: 0.004170
 >> iter 163000, loss: 0.003706
 >> iter 164000, loss: 0.003491
 >> iter 165000, loss: 0.003180
 >> iter 166000, loss: 0.003094
 >> iter 167000, loss: 0.022629
 >> iter 168000, loss: 0.010235
 >> iter 169000, loss: 0.005673
 >> iter 170000, loss: 0.027733
   Number of active neurons: 10
 >> iter 171000, loss: 0.012219
 >> iter 172000, loss: 0.028828
 >> iter 173000, loss: 0.027920
 >> iter 174000, loss: 0.012419
 >> iter 175000, loss: 0.007553
 >> iter 176000, loss: 0.005030
 >> iter 177000, loss: 0.003862
 >> iter 178000, loss: 0.004109
 >> iter 179000, loss: 0.003656
 >> iter 180000, loss: 0.004811
   Number of active neurons: 10
 >> iter 181000, loss: 0.003618
 >> iter 182000, loss: 0.003139
 >> iter 183000, loss: 0.002896
 >> iter 184000, loss: 0.002774
 >> iter 185000, loss: 0.002629
 >> iter 186000, loss: 0.002563
 >> iter 187000, loss: 0.002510
 >> iter 188000, loss: 0.002421
 >> iter 189000, loss: 0.002380
 >> iter 190000, loss: 0.002368
   Number of active neurons: 10
 >> iter 191000, loss: 0.003951
 >> iter 192000, loss: 0.003173
 >> iter 193000, loss: 0.002694
 >> iter 194000, loss: 0.002447
 >> iter 195000, loss: 0.062118
 >> iter 196000, loss: 0.024449
 >> iter 197000, loss: 0.010583
 >> iter 198000, loss: 0.005485
 >> iter 199000, loss: 0.003489
 >> iter 200000, loss: 0.002727
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0069999300007
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.754520
 >> iter 2000, loss: 15.220095
 >> iter 3000, loss: 13.846503
 >> iter 4000, loss: 13.332818
 >> iter 5000, loss: 13.131304
 >> iter 6000, loss: 13.064727
 >> iter 7000, loss: 13.024009
 >> iter 8000, loss: 13.012261
 >> iter 9000, loss: 12.991735
 >> iter 10000, loss: 12.987631
   Number of active neurons: 9
 >> iter 11000, loss: 12.978154
 >> iter 12000, loss: 12.982946
 >> iter 13000, loss: 12.972521
 >> iter 14000, loss: 12.981692
 >> iter 15000, loss: 12.975437
 >> iter 16000, loss: 12.987983
 >> iter 17000, loss: 12.978039
 >> iter 18000, loss: 12.984868
 >> iter 19000, loss: 12.975531
 >> iter 20000, loss: 12.980162
   Number of active neurons: 10
 >> iter 21000, loss: 12.967696
 >> iter 22000, loss: 12.851980
 >> iter 23000, loss: 12.297571
 >> iter 24000, loss: 11.404780
 >> iter 25000, loss: 10.176710
 >> iter 26000, loss: 8.611190
 >> iter 27000, loss: 7.315175
 >> iter 28000, loss: 6.819183
 >> iter 29000, loss: 6.336378
 >> iter 30000, loss: 6.265423
   Number of active neurons: 10
 >> iter 31000, loss: 5.931250
 >> iter 32000, loss: 6.946595
 >> iter 33000, loss: 6.521091
 >> iter 34000, loss: 6.388502
 >> iter 35000, loss: 6.101834
 >> iter 36000, loss: 5.878532
 >> iter 37000, loss: 5.491899
 >> iter 38000, loss: 5.476318
 >> iter 39000, loss: 5.288465
 >> iter 40000, loss: 5.316949
   Number of active neurons: 10
 >> iter 41000, loss: 5.209978
 >> iter 42000, loss: 5.306845
 >> iter 43000, loss: 5.000869
 >> iter 44000, loss: 7.537076
 >> iter 45000, loss: 5.556444
 >> iter 46000, loss: 4.307237
 >> iter 47000, loss: 3.570772
 >> iter 48000, loss: 2.575806
 >> iter 49000, loss: 1.786619
 >> iter 50000, loss: 1.725038
   Number of active neurons: 10
 >> iter 51000, loss: 1.090044
 >> iter 52000, loss: 0.820016
 >> iter 53000, loss: 0.784494
 >> iter 54000, loss: 0.772526
 >> iter 55000, loss: 1.026408
 >> iter 56000, loss: 0.684332
 >> iter 57000, loss: 0.538554
 >> iter 58000, loss: 0.447135
 >> iter 59000, loss: 0.214477
 >> iter 60000, loss: 0.115494
   Number of active neurons: 10
 >> iter 61000, loss: 0.097695
 >> iter 62000, loss: 0.212313
 >> iter 63000, loss: 0.657598
 >> iter 64000, loss: 0.535863
 >> iter 65000, loss: 0.384302
 >> iter 66000, loss: 0.448985
 >> iter 67000, loss: 0.248909
 >> iter 68000, loss: 0.425709
 >> iter 69000, loss: 0.268000
 >> iter 70000, loss: 0.124806
   Number of active neurons: 10
 >> iter 71000, loss: 0.203580
 >> iter 72000, loss: 0.118832
 >> iter 73000, loss: 0.061490
 >> iter 74000, loss: 0.047525
 >> iter 75000, loss: 0.104837
 >> iter 76000, loss: 0.295544
 >> iter 77000, loss: 0.166294
 >> iter 78000, loss: 0.085063
 >> iter 79000, loss: 0.043939
 >> iter 80000, loss: 0.027833
   Number of active neurons: 10
 >> iter 81000, loss: 0.031047
 >> iter 82000, loss: 0.305903
 >> iter 83000, loss: 0.125475
 >> iter 84000, loss: 0.085499
 >> iter 85000, loss: 0.116800
 >> iter 86000, loss: 0.075281
 >> iter 87000, loss: 0.037744
 >> iter 88000, loss: 0.042864
 >> iter 89000, loss: 0.348919
 >> iter 90000, loss: 0.313111
   Number of active neurons: 10
 >> iter 91000, loss: 0.181175
 >> iter 92000, loss: 0.157604
 >> iter 93000, loss: 0.134739
 >> iter 94000, loss: 0.071775
 >> iter 95000, loss: 0.036619
 >> iter 96000, loss: 0.023298
 >> iter 97000, loss: 0.186562
 >> iter 98000, loss: 0.102090
 >> iter 99000, loss: 0.290665
 >> iter 100000, loss: 0.193660
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.706141
 >> iter 2000, loss: 15.192732
 >> iter 3000, loss: 13.837636
 >> iter 4000, loss: 13.326223
 >> iter 5000, loss: 13.124971
 >> iter 6000, loss: 13.046585
 >> iter 7000, loss: 13.008610
 >> iter 8000, loss: 12.994494
 >> iter 9000, loss: 12.991884
 >> iter 10000, loss: 12.996915
   Number of active neurons: 9
 >> iter 11000, loss: 12.986172
 >> iter 12000, loss: 12.990732
 >> iter 13000, loss: 12.978891
 >> iter 14000, loss: 12.983136
 >> iter 15000, loss: 12.974231
 >> iter 16000, loss: 12.964657
 >> iter 17000, loss: 12.923080
 >> iter 18000, loss: 12.596845
 >> iter 19000, loss: 11.167291
 >> iter 20000, loss: 5.332078
   Number of active neurons: 10
 >> iter 21000, loss: 2.197070
 >> iter 22000, loss: 0.919019
 >> iter 23000, loss: 0.412971
 >> iter 24000, loss: 0.258831
 >> iter 25000, loss: 0.145566
 >> iter 26000, loss: 0.142015
 >> iter 27000, loss: 0.163959
 >> iter 28000, loss: 0.075686
 >> iter 29000, loss: 0.042229
 >> iter 30000, loss: 0.028424
   Number of active neurons: 10
 >> iter 31000, loss: 0.021871
 >> iter 32000, loss: 0.017670
 >> iter 33000, loss: 0.015235
 >> iter 34000, loss: 0.142553
 >> iter 35000, loss: 0.061968
 >> iter 36000, loss: 0.039404
 >> iter 37000, loss: 0.022091
 >> iter 38000, loss: 0.014756
 >> iter 39000, loss: 0.011462
 >> iter 40000, loss: 0.010089
   Number of active neurons: 10
 >> iter 41000, loss: 0.009711
 >> iter 42000, loss: 0.008670
 >> iter 43000, loss: 0.259443
 >> iter 44000, loss: 0.110452
 >> iter 45000, loss: 0.046380
 >> iter 46000, loss: 0.022090
 >> iter 47000, loss: 0.013029
 >> iter 48000, loss: 0.009373
 >> iter 49000, loss: 0.007816
 >> iter 50000, loss: 0.006948
   Number of active neurons: 10
 >> iter 51000, loss: 0.006450
 >> iter 52000, loss: 0.006014
 >> iter 53000, loss: 0.093986
 >> iter 54000, loss: 0.039112
 >> iter 55000, loss: 0.018399
 >> iter 56000, loss: 0.010538
 >> iter 57000, loss: 0.007369
 >> iter 58000, loss: 0.005962
 >> iter 59000, loss: 0.005343
 >> iter 60000, loss: 0.005002
   Number of active neurons: 10
 >> iter 61000, loss: 0.004654
 >> iter 62000, loss: 0.004542
 >> iter 63000, loss: 0.004285
 >> iter 64000, loss: 0.004096
 >> iter 65000, loss: 0.004343
 >> iter 66000, loss: 0.004408
 >> iter 67000, loss: 0.004633
 >> iter 68000, loss: 0.080338
 >> iter 69000, loss: 0.032284
 >> iter 70000, loss: 0.030185
   Number of active neurons: 10
 >> iter 71000, loss: 0.013442
 >> iter 72000, loss: 0.031697
 >> iter 73000, loss: 0.014454
 >> iter 74000, loss: 0.007735
 >> iter 75000, loss: 0.005134
 >> iter 76000, loss: 0.004082
 >> iter 77000, loss: 0.003616
 >> iter 78000, loss: 0.003352
 >> iter 79000, loss: 0.003240
 >> iter 80000, loss: 0.003144
   Number of active neurons: 10
 >> iter 81000, loss: 0.003187
 >> iter 82000, loss: 0.003017
 >> iter 83000, loss: 0.002896
 >> iter 84000, loss: 0.002812
 >> iter 85000, loss: 0.002705
 >> iter 86000, loss: 0.002776
 >> iter 87000, loss: 0.002721
 >> iter 88000, loss: 0.002603
 >> iter 89000, loss: 0.002829
 >> iter 90000, loss: 0.002648
   Number of active neurons: 10
 >> iter 91000, loss: 0.002698
 >> iter 92000, loss: 0.002534
 >> iter 93000, loss: 0.002693
 >> iter 94000, loss: 0.002470
 >> iter 95000, loss: 0.032022
 >> iter 96000, loss: 0.013603
 >> iter 97000, loss: 0.024436
 >> iter 98000, loss: 0.010746
 >> iter 99000, loss: 0.005939
 >> iter 100000, loss: 0.003802
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.728536
 >> iter 2000, loss: 15.176744
 >> iter 3000, loss: 13.825065
 >> iter 4000, loss: 13.318721
 >> iter 5000, loss: 13.120497
 >> iter 6000, loss: 13.044730
 >> iter 7000, loss: 13.014024
 >> iter 8000, loss: 13.006352
 >> iter 9000, loss: 12.994640
 >> iter 10000, loss: 13.005240
   Number of active neurons: 9
 >> iter 11000, loss: 12.996823
 >> iter 12000, loss: 13.002493
 >> iter 13000, loss: 12.988553
 >> iter 14000, loss: 12.996440
 >> iter 15000, loss: 12.983846
 >> iter 16000, loss: 12.990030
 >> iter 17000, loss: 12.980625
 >> iter 18000, loss: 12.976622
 >> iter 19000, loss: 12.969984
 >> iter 20000, loss: 12.980308
   Number of active neurons: 9
 >> iter 21000, loss: 12.966925
 >> iter 22000, loss: 12.969023
 >> iter 23000, loss: 12.891126
 >> iter 24000, loss: 12.571241
 >> iter 25000, loss: 11.851332
 >> iter 26000, loss: 10.600759
 >> iter 27000, loss: 5.459661
 >> iter 28000, loss: 2.241444
 >> iter 29000, loss: 0.939529
 >> iter 30000, loss: 0.386920
   Number of active neurons: 10
 >> iter 31000, loss: 0.281170
 >> iter 32000, loss: 0.147829
 >> iter 33000, loss: 0.075118
 >> iter 34000, loss: 0.084208
 >> iter 35000, loss: 0.042124
 >> iter 36000, loss: 0.028135
 >> iter 37000, loss: 0.042389
 >> iter 38000, loss: 0.127994
 >> iter 39000, loss: 0.056741
 >> iter 40000, loss: 0.028270
   Number of active neurons: 10
 >> iter 41000, loss: 0.052377
 >> iter 42000, loss: 0.029821
 >> iter 43000, loss: 0.023013
 >> iter 44000, loss: 0.014019
 >> iter 45000, loss: 0.114123
 >> iter 46000, loss: 0.054577
 >> iter 47000, loss: 0.030441
 >> iter 48000, loss: 0.015808
 >> iter 49000, loss: 0.010132
 >> iter 50000, loss: 0.007533
   Number of active neurons: 10
 >> iter 51000, loss: 0.006425
 >> iter 52000, loss: 0.027421
 >> iter 53000, loss: 0.030546
 >> iter 54000, loss: 0.014996
 >> iter 55000, loss: 0.008884
 >> iter 56000, loss: 0.006231
 >> iter 57000, loss: 0.005198
 >> iter 58000, loss: 0.004395
 >> iter 59000, loss: 0.004024
 >> iter 60000, loss: 0.003713
   Number of active neurons: 10
 >> iter 61000, loss: 0.003584
 >> iter 62000, loss: 0.003708
 >> iter 63000, loss: 0.003337
 >> iter 64000, loss: 0.003138
 >> iter 65000, loss: 0.002985
 >> iter 66000, loss: 0.003144
 >> iter 67000, loss: 0.002827
 >> iter 68000, loss: 0.002916
 >> iter 69000, loss: 0.002870
 >> iter 70000, loss: 0.002821
   Number of active neurons: 10
 >> iter 71000, loss: 0.054167
 >> iter 72000, loss: 0.024399
 >> iter 73000, loss: 0.011202
 >> iter 74000, loss: 0.006261
 >> iter 75000, loss: 0.007346
 >> iter 76000, loss: 0.034786
 >> iter 77000, loss: 0.015204
 >> iter 78000, loss: 0.007370
 >> iter 79000, loss: 0.004439
 >> iter 80000, loss: 0.003314
   Number of active neurons: 10
 >> iter 81000, loss: 0.002923
 >> iter 82000, loss: 0.002526
 >> iter 83000, loss: 0.002536
 >> iter 84000, loss: 0.026489
 >> iter 85000, loss: 0.011209
 >> iter 86000, loss: 0.005518
 >> iter 87000, loss: 0.003428
 >> iter 88000, loss: 0.002884
 >> iter 89000, loss: 0.002286
 >> iter 90000, loss: 0.002076
   Number of active neurons: 10
 >> iter 91000, loss: 0.003343
 >> iter 92000, loss: 0.002829
 >> iter 93000, loss: 0.003013
 >> iter 94000, loss: 0.002394
 >> iter 95000, loss: 0.002062
 >> iter 96000, loss: 0.002117
 >> iter 97000, loss: 0.001891
 >> iter 98000, loss: 0.002154
 >> iter 99000, loss: 0.002266
 >> iter 100000, loss: 0.001843
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.696884
 >> iter 2000, loss: 15.165345
 >> iter 3000, loss: 13.793432
 >> iter 4000, loss: 13.275794
 >> iter 5000, loss: 13.070716
 >> iter 6000, loss: 12.997695
 >> iter 7000, loss: 12.965568
 >> iter 8000, loss: 12.951482
 >> iter 9000, loss: 12.937280
 >> iter 10000, loss: 12.946051
   Number of active neurons: 6
 >> iter 11000, loss: 12.928755
 >> iter 12000, loss: 12.939373
 >> iter 13000, loss: 12.929887
 >> iter 14000, loss: 12.934228
 >> iter 15000, loss: 12.915420
 >> iter 16000, loss: 12.914723
 >> iter 17000, loss: 12.746517
 >> iter 18000, loss: 11.685658
 >> iter 19000, loss: 9.906493
 >> iter 20000, loss: 8.157204
   Number of active neurons: 10
 >> iter 21000, loss: 6.363309
 >> iter 22000, loss: 5.592106
 >> iter 23000, loss: 5.430465
 >> iter 24000, loss: 4.185522
 >> iter 25000, loss: 2.161226
 >> iter 26000, loss: 1.068172
 >> iter 27000, loss: 0.714636
 >> iter 28000, loss: 0.478560
 >> iter 29000, loss: 0.432501
 >> iter 30000, loss: 0.227604
   Number of active neurons: 10
 >> iter 31000, loss: 0.737336
 >> iter 32000, loss: 0.566695
 >> iter 33000, loss: 0.927657
 >> iter 34000, loss: 0.600491
 >> iter 35000, loss: 0.443087
 >> iter 36000, loss: 0.209288
 >> iter 37000, loss: 0.265751
 >> iter 38000, loss: 0.207682
 >> iter 39000, loss: 0.127759
 >> iter 40000, loss: 0.142703
   Number of active neurons: 10
 >> iter 41000, loss: 0.162289
 >> iter 42000, loss: 0.074024
 >> iter 43000, loss: 0.070914
 >> iter 44000, loss: 0.043149
 >> iter 45000, loss: 0.035821
 >> iter 46000, loss: 0.022541
 >> iter 47000, loss: 0.196878
 >> iter 48000, loss: 0.112921
 >> iter 49000, loss: 0.153434
 >> iter 50000, loss: 0.118216
   Number of active neurons: 10
 >> iter 51000, loss: 0.428181
 >> iter 52000, loss: 0.245555
 >> iter 53000, loss: 0.109732
 >> iter 54000, loss: 0.049860
 >> iter 55000, loss: 0.084973
 >> iter 56000, loss: 0.057775
 >> iter 57000, loss: 0.027883
 >> iter 58000, loss: 0.085715
 >> iter 59000, loss: 0.038069
 >> iter 60000, loss: 0.020152
   Number of active neurons: 10
 >> iter 61000, loss: 0.012491
 >> iter 62000, loss: 0.009001
 >> iter 63000, loss: 0.054762
 >> iter 64000, loss: 0.024869
 >> iter 65000, loss: 0.013230
 >> iter 66000, loss: 0.008579
 >> iter 67000, loss: 0.007186
 >> iter 68000, loss: 0.018445
 >> iter 69000, loss: 0.011107
 >> iter 70000, loss: 0.007174
   Number of active neurons: 10
 >> iter 71000, loss: 0.006057
 >> iter 72000, loss: 0.005325
 >> iter 73000, loss: 0.004563
 >> iter 74000, loss: 0.004153
 >> iter 75000, loss: 0.003842
 >> iter 76000, loss: 0.003665
 >> iter 77000, loss: 0.003493
 >> iter 78000, loss: 0.120088
 >> iter 79000, loss: 0.050768
 >> iter 80000, loss: 0.021951
   Number of active neurons: 10
 >> iter 81000, loss: 0.010799
 >> iter 82000, loss: 0.006447
 >> iter 83000, loss: 0.004709
 >> iter 84000, loss: 0.003910
 >> iter 85000, loss: 0.003558
 >> iter 86000, loss: 0.003502
 >> iter 87000, loss: 0.003217
 >> iter 88000, loss: 0.003081
 >> iter 89000, loss: 0.002969
 >> iter 90000, loss: 0.002785
   Number of active neurons: 10
 >> iter 91000, loss: 0.002641
 >> iter 92000, loss: 0.002524
 >> iter 93000, loss: 0.002417
 >> iter 94000, loss: 0.003740
 >> iter 95000, loss: 0.002941
 >> iter 96000, loss: 0.002792
 >> iter 97000, loss: 0.002563
 >> iter 98000, loss: 0.002692
 >> iter 99000, loss: 0.002595
 >> iter 100000, loss: 0.002497
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.733487
 >> iter 2000, loss: 15.160857
 >> iter 3000, loss: 13.790540
 >> iter 4000, loss: 13.269318
 >> iter 5000, loss: 13.063602
 >> iter 6000, loss: 12.994303
 >> iter 7000, loss: 12.957331
 >> iter 8000, loss: 12.960346
 >> iter 9000, loss: 12.946004
 >> iter 10000, loss: 12.962219
   Number of active neurons: 6
 >> iter 11000, loss: 12.945121
 >> iter 12000, loss: 12.949885
 >> iter 13000, loss: 12.939724
 >> iter 14000, loss: 12.945470
 >> iter 15000, loss: 12.941272
 >> iter 16000, loss: 12.948930
 >> iter 17000, loss: 12.940325
 >> iter 18000, loss: 12.945173
 >> iter 19000, loss: 12.938466
 >> iter 20000, loss: 12.947395
   Number of active neurons: 6
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 6
 >> iter 21000, loss: 12.941052
 >> iter 22000, loss: 12.942879
 >> iter 23000, loss: 12.940094
 >> iter 24000, loss: 12.949894
 >> iter 25000, loss: 12.941451
 >> iter 26000, loss: 12.948354
 >> iter 27000, loss: 12.938748
 >> iter 28000, loss: 12.942913
 >> iter 29000, loss: 12.933645
 >> iter 30000, loss: 12.936737
   Number of active neurons: 6
 >> iter 31000, loss: 12.812651
 >> iter 32000, loss: 11.974850
 >> iter 33000, loss: 11.182474
 >> iter 34000, loss: 10.473697
 >> iter 35000, loss: 9.667059
 >> iter 36000, loss: 8.650445
 >> iter 37000, loss: 7.221662
 >> iter 38000, loss: 6.219927
 >> iter 39000, loss: 5.535446
 >> iter 40000, loss: 5.187582
   Number of active neurons: 10
 >> iter 41000, loss: 4.897794
 >> iter 42000, loss: 4.763944
 >> iter 43000, loss: 4.742360
 >> iter 44000, loss: 4.740428
 >> iter 45000, loss: 4.753518
 >> iter 46000, loss: 4.743303
 >> iter 47000, loss: 4.709528
 >> iter 48000, loss: 4.578055
 >> iter 49000, loss: 4.559185
 >> iter 50000, loss: 4.672164
   Number of active neurons: 10
 >> iter 51000, loss: 4.580480
 >> iter 52000, loss: 4.759002
 >> iter 53000, loss: 4.665643
 >> iter 54000, loss: 4.581126
 >> iter 55000, loss: 4.688278
 >> iter 56000, loss: 4.671338
 >> iter 57000, loss: 4.558118
 >> iter 58000, loss: 4.448343
 >> iter 59000, loss: 4.497444
 >> iter 60000, loss: 4.588524
   Number of active neurons: 10
 >> iter 61000, loss: 4.478796
 >> iter 62000, loss: 4.424791
 >> iter 63000, loss: 4.437869
 >> iter 64000, loss: 4.392547
 >> iter 65000, loss: 4.396186
 >> iter 66000, loss: 4.396429
 >> iter 67000, loss: 4.420306
 >> iter 68000, loss: 4.450186
 >> iter 69000, loss: 4.778378
 >> iter 70000, loss: 4.829396
   Number of active neurons: 10
 >> iter 71000, loss: 4.654890
 >> iter 72000, loss: 4.522733
 >> iter 73000, loss: 4.374507
 >> iter 74000, loss: 4.414506
 >> iter 75000, loss: 4.613780
 >> iter 76000, loss: 4.552986
 >> iter 77000, loss: 4.534472
 >> iter 78000, loss: 4.446156
 >> iter 79000, loss: 4.663771
 >> iter 80000, loss: 4.440898
   Number of active neurons: 10
 >> iter 81000, loss: 5.023479
 >> iter 82000, loss: 4.741651
 >> iter 83000, loss: 4.819920
 >> iter 84000, loss: 4.810662
 >> iter 85000, loss: 6.088100
 >> iter 86000, loss: 6.591547
 >> iter 87000, loss: 6.731014
 >> iter 88000, loss: 5.259654
 >> iter 89000, loss: 5.578353
 >> iter 90000, loss: 5.642009
   Number of active neurons: 10
 >> iter 91000, loss: 6.122321
 >> iter 92000, loss: 4.902652
 >> iter 93000, loss: 4.169849
 >> iter 94000, loss: 3.667464
 >> iter 95000, loss: 3.542901
 >> iter 96000, loss: 3.311255
 >> iter 97000, loss: 3.166347
 >> iter 98000, loss: 4.354274
 >> iter 99000, loss: 5.444527
 >> iter 100000, loss: 4.744775
   Number of active neurons: 10
 >> iter 101000, loss: 4.158296
 >> iter 102000, loss: 4.035479
 >> iter 103000, loss: 3.875047
 >> iter 104000, loss: 3.550266
 >> iter 105000, loss: 3.232606
 >> iter 106000, loss: 3.261940
 >> iter 107000, loss: 3.200849
 >> iter 108000, loss: 3.362932
 >> iter 109000, loss: 3.185921
 >> iter 110000, loss: 3.714114
   Number of active neurons: 10
 >> iter 111000, loss: 3.617396
 >> iter 112000, loss: 3.612423
 >> iter 113000, loss: 4.120443
 >> iter 114000, loss: 5.005458
 >> iter 115000, loss: 4.035877
 >> iter 116000, loss: 4.180736
 >> iter 117000, loss: 3.950534
 >> iter 118000, loss: 4.566177
 >> iter 119000, loss: 6.448214
 >> iter 120000, loss: 5.126485
   Number of active neurons: 10
 >> iter 121000, loss: 4.078799
 >> iter 122000, loss: 3.660984
 >> iter 123000, loss: 3.485691
 >> iter 124000, loss: 3.795543
 >> iter 125000, loss: 3.360504
 >> iter 126000, loss: 2.959476
 >> iter 127000, loss: 2.177739
 >> iter 128000, loss: 1.838185
 >> iter 129000, loss: 1.716019
 >> iter 130000, loss: 3.600277
   Number of active neurons: 10
 >> iter 131000, loss: 4.163314
 >> iter 132000, loss: 4.389423
 >> iter 133000, loss: 4.455746
 >> iter 134000, loss: 4.369806
 >> iter 135000, loss: 3.525341
 >> iter 136000, loss: 3.239434
 >> iter 137000, loss: 3.148550
 >> iter 138000, loss: 3.059040
 >> iter 139000, loss: 2.941206
 >> iter 140000, loss: 3.655462
   Number of active neurons: 10
 >> iter 141000, loss: 4.639471
 >> iter 142000, loss: 3.708387
 >> iter 143000, loss: 3.270939
 >> iter 144000, loss: 3.237602
 >> iter 145000, loss: 3.042893
 >> iter 146000, loss: 2.765689
 >> iter 147000, loss: 3.064276
 >> iter 148000, loss: 2.658138
 >> iter 149000, loss: 1.895957
 >> iter 150000, loss: 1.675489
   Number of active neurons: 10
 >> iter 151000, loss: 1.204954
 >> iter 152000, loss: 0.987753
 >> iter 153000, loss: 0.924028
 >> iter 154000, loss: 0.926239
 >> iter 155000, loss: 0.847901
 >> iter 156000, loss: 0.510914
 >> iter 157000, loss: 0.830025
 >> iter 158000, loss: 6.048861
 >> iter 159000, loss: 3.267205
 >> iter 160000, loss: 1.928972
   Number of active neurons: 10
 >> iter 161000, loss: 1.061217
 >> iter 162000, loss: 0.999370
 >> iter 163000, loss: 1.178053
 >> iter 164000, loss: 0.935269
 >> iter 165000, loss: 0.832382
 >> iter 166000, loss: 0.820908
 >> iter 167000, loss: 0.757570
 >> iter 168000, loss: 0.819742
 >> iter 169000, loss: 0.899179
 >> iter 170000, loss: 0.649951
   Number of active neurons: 10
 >> iter 171000, loss: 0.314600
 >> iter 172000, loss: 0.440606
 >> iter 173000, loss: 0.249282
 >> iter 174000, loss: 0.754273
 >> iter 175000, loss: 0.345699
 >> iter 176000, loss: 0.381349
 >> iter 177000, loss: 0.508944
 >> iter 178000, loss: 0.314902
 >> iter 179000, loss: 0.492210
 >> iter 180000, loss: 0.407268
   Number of active neurons: 10
 >> iter 181000, loss: 0.417598
 >> iter 182000, loss: 0.310476
 >> iter 183000, loss: 0.314157
 >> iter 184000, loss: 0.148457
 >> iter 185000, loss: 0.090736
 >> iter 186000, loss: 0.308686
 >> iter 187000, loss: 0.442360
 >> iter 188000, loss: 0.258824
 >> iter 189000, loss: 0.190301
 >> iter 190000, loss: 0.428356
   Number of active neurons: 10
 >> iter 191000, loss: 0.331861
 >> iter 192000, loss: 0.294525
 >> iter 193000, loss: 0.144342
 >> iter 194000, loss: 0.084840
 >> iter 195000, loss: 0.217455
 >> iter 196000, loss: 0.170203
 >> iter 197000, loss: 0.092701
 >> iter 198000, loss: 0.055053
 >> iter 199000, loss: 0.213568
 >> iter 200000, loss: 0.438411
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.749505
 >> iter 2000, loss: 15.213546
 >> iter 3000, loss: 13.840671
 >> iter 4000, loss: 13.324214
 >> iter 5000, loss: 13.109932
 >> iter 6000, loss: 13.036080
 >> iter 7000, loss: 12.994276
 >> iter 8000, loss: 12.990891
 >> iter 9000, loss: 12.976741
 >> iter 10000, loss: 12.980316
   Number of active neurons: 8
 >> iter 11000, loss: 12.970763
 >> iter 12000, loss: 12.976145
 >> iter 13000, loss: 12.967491
 >> iter 14000, loss: 12.978077
 >> iter 15000, loss: 12.968262
 >> iter 16000, loss: 12.982708
 >> iter 17000, loss: 12.974289
 >> iter 18000, loss: 12.975259
 >> iter 19000, loss: 12.962980
 >> iter 20000, loss: 12.969885
   Number of active neurons: 8
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 8
 >> iter 21000, loss: 12.959713
 >> iter 22000, loss: 12.962873
 >> iter 23000, loss: 12.682117
 >> iter 24000, loss: 12.022658
 >> iter 25000, loss: 9.461118
 >> iter 26000, loss: 4.009109
 >> iter 27000, loss: 1.764393
 >> iter 28000, loss: 0.901771
 >> iter 29000, loss: 0.396319
 >> iter 30000, loss: 0.171626
   Number of active neurons: 10
 >> iter 31000, loss: 0.081154
 >> iter 32000, loss: 0.049144
 >> iter 33000, loss: 0.030965
 >> iter 34000, loss: 0.021980
 >> iter 35000, loss: 0.081479
 >> iter 36000, loss: 0.056171
 >> iter 37000, loss: 0.029164
 >> iter 38000, loss: 0.018029
 >> iter 39000, loss: 0.013621
 >> iter 40000, loss: 0.011150
   Number of active neurons: 10
 >> iter 41000, loss: 0.009241
 >> iter 42000, loss: 0.008244
 >> iter 43000, loss: 0.007161
 >> iter 44000, loss: 0.006397
 >> iter 45000, loss: 0.005821
 >> iter 46000, loss: 0.005242
 >> iter 47000, loss: 0.005101
 >> iter 48000, loss: 0.004587
 >> iter 49000, loss: 0.020944
 >> iter 50000, loss: 0.125580
   Number of active neurons: 10
 >> iter 51000, loss: 0.049426
 >> iter 52000, loss: 0.021314
 >> iter 53000, loss: 0.010349
 >> iter 54000, loss: 0.019678
 >> iter 55000, loss: 0.010392
 >> iter 56000, loss: 0.113016
 >> iter 57000, loss: 0.057567
 >> iter 58000, loss: 0.135678
 >> iter 59000, loss: 0.053741
 >> iter 60000, loss: 0.022328
   Number of active neurons: 10
 >> iter 61000, loss: 0.034736
 >> iter 62000, loss: 0.014875
 >> iter 63000, loss: 0.007416
 >> iter 64000, loss: 0.004338
 >> iter 65000, loss: 0.003127
 >> iter 66000, loss: 0.003160
 >> iter 67000, loss: 0.002543
 >> iter 68000, loss: 0.002161
 >> iter 69000, loss: 0.003420
 >> iter 70000, loss: 0.007233
   Number of active neurons: 10
 >> iter 71000, loss: 0.005128
 >> iter 72000, loss: 0.003410
 >> iter 73000, loss: 0.002670
 >> iter 74000, loss: 0.002176
 >> iter 75000, loss: 0.001781
 >> iter 76000, loss: 0.001597
 >> iter 77000, loss: 0.001698
 >> iter 78000, loss: 0.001571
 >> iter 79000, loss: 0.006661
 >> iter 80000, loss: 0.003586
   Number of active neurons: 10
 >> iter 81000, loss: 0.002229
 >> iter 82000, loss: 0.001653
 >> iter 83000, loss: 0.001814
 >> iter 84000, loss: 0.001541
 >> iter 85000, loss: 0.001387
 >> iter 86000, loss: 0.001280
 >> iter 87000, loss: 0.001145
 >> iter 88000, loss: 0.028679
 >> iter 89000, loss: 0.011509
 >> iter 90000, loss: 0.005047
   Number of active neurons: 10
 >> iter 91000, loss: 0.002865
 >> iter 92000, loss: 0.001796
 >> iter 93000, loss: 0.001340
 >> iter 94000, loss: 0.001158
 >> iter 95000, loss: 0.018679
 >> iter 96000, loss: 0.007646
 >> iter 97000, loss: 0.003639
 >> iter 98000, loss: 0.002388
 >> iter 99000, loss: 0.001600
 >> iter 100000, loss: 0.001194
   Number of active neurons: 10
 >> iter 101000, loss: 0.012904
 >> iter 102000, loss: 0.005725
 >> iter 103000, loss: 0.045785
 >> iter 104000, loss: 0.017773
 >> iter 105000, loss: 0.007292
 >> iter 106000, loss: 0.003355
 >> iter 107000, loss: 0.001867
 >> iter 108000, loss: 0.001241
 >> iter 109000, loss: 0.001422
 >> iter 110000, loss: 0.001193
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.733630
 >> iter 2000, loss: 15.205469
 >> iter 3000, loss: 13.834221
 >> iter 4000, loss: 13.328403
 >> iter 5000, loss: 13.122012
 >> iter 6000, loss: 13.042368
 >> iter 7000, loss: 13.004972
 >> iter 8000, loss: 13.005957
 >> iter 9000, loss: 12.990551
 >> iter 10000, loss: 12.992850
   Number of active neurons: 9
 >> iter 11000, loss: 12.976418
 >> iter 12000, loss: 12.987675
 >> iter 13000, loss: 12.975901
 >> iter 14000, loss: 12.980697
 >> iter 15000, loss: 12.974049
 >> iter 16000, loss: 12.979514
 >> iter 17000, loss: 12.972095
 >> iter 18000, loss: 12.973069
 >> iter 19000, loss: 12.963689
 >> iter 20000, loss: 12.973294
   Number of active neurons: 8
 >> iter 21000, loss: 12.961140
 >> iter 22000, loss: 12.974521
 >> iter 23000, loss: 12.964693
 >> iter 24000, loss: 12.974463
 >> iter 25000, loss: 12.955591
 >> iter 26000, loss: 12.966974
 >> iter 27000, loss: 12.962657
 >> iter 28000, loss: 12.945060
 >> iter 29000, loss: 12.177533
 >> iter 30000, loss: 10.608531
   Number of active neurons: 10
 >> iter 31000, loss: 9.580765
 >> iter 32000, loss: 8.602907
 >> iter 33000, loss: 6.891446
 >> iter 34000, loss: 5.947471
 >> iter 35000, loss: 5.188192
 >> iter 36000, loss: 5.016076
 >> iter 37000, loss: 4.447538
 >> iter 38000, loss: 4.701538
 >> iter 39000, loss: 4.634305
 >> iter 40000, loss: 4.675326
   Number of active neurons: 10
 >> iter 41000, loss: 4.602114
 >> iter 42000, loss: 4.733806
 >> iter 43000, loss: 4.355810
 >> iter 44000, loss: 5.050643
 >> iter 45000, loss: 4.718625
 >> iter 46000, loss: 4.496203
 >> iter 47000, loss: 3.924856
 >> iter 48000, loss: 4.221929
 >> iter 49000, loss: 4.050653
 >> iter 50000, loss: 3.844019
   Number of active neurons: 10
 >> iter 51000, loss: 3.520741
 >> iter 52000, loss: 3.400435
 >> iter 53000, loss: 3.303753
 >> iter 54000, loss: 3.411777
 >> iter 55000, loss: 3.201386
 >> iter 56000, loss: 6.782622
 >> iter 57000, loss: 5.688431
 >> iter 58000, loss: 7.617659
 >> iter 59000, loss: 7.815586
 >> iter 60000, loss: 5.577763
   Number of active neurons: 10
 >> iter 61000, loss: 3.712367
 >> iter 62000, loss: 2.506647
 >> iter 63000, loss: 1.455154
 >> iter 64000, loss: 0.790008
 >> iter 65000, loss: 0.503653
 >> iter 66000, loss: 0.456930
 >> iter 67000, loss: 0.289638
 >> iter 68000, loss: 0.193195
 >> iter 69000, loss: 0.138006
 >> iter 70000, loss: 0.076701
   Number of active neurons: 10
 >> iter 71000, loss: 0.047778
 >> iter 72000, loss: 0.074488
 >> iter 73000, loss: 0.124827
 >> iter 74000, loss: 0.062029
 >> iter 75000, loss: 0.036133
 >> iter 76000, loss: 0.026236
 >> iter 77000, loss: 0.159017
 >> iter 78000, loss: 0.085262
 >> iter 79000, loss: 0.041800
 >> iter 80000, loss: 0.071086
   Number of active neurons: 10
 >> iter 81000, loss: 0.035333
 >> iter 82000, loss: 0.156205
 >> iter 83000, loss: 0.175992
 >> iter 84000, loss: 0.076993
 >> iter 85000, loss: 0.037369
 >> iter 86000, loss: 0.274925
 >> iter 87000, loss: 0.168742
 >> iter 88000, loss: 0.071724
 >> iter 89000, loss: 0.034671
 >> iter 90000, loss: 0.020627
   Number of active neurons: 10
 >> iter 91000, loss: 0.014810
 >> iter 92000, loss: 0.012609
 >> iter 93000, loss: 0.048674
 >> iter 94000, loss: 0.024959
 >> iter 95000, loss: 0.273810
 >> iter 96000, loss: 0.133589
 >> iter 97000, loss: 0.055886
 >> iter 98000, loss: 0.049825
 >> iter 99000, loss: 0.024505
 >> iter 100000, loss: 0.014955
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.709478
 >> iter 2000, loss: 15.166332
 >> iter 3000, loss: 13.788466
 >> iter 4000, loss: 13.278134
 >> iter 5000, loss: 13.074012
 >> iter 6000, loss: 12.999579
 >> iter 7000, loss: 12.970034
 >> iter 8000, loss: 12.956156
 >> iter 9000, loss: 12.942158
 >> iter 10000, loss: 12.944963
   Number of active neurons: 5
 >> iter 11000, loss: 12.936746
 >> iter 12000, loss: 12.949245
 >> iter 13000, loss: 12.939247
 >> iter 14000, loss: 12.943045
 >> iter 15000, loss: 12.932868
 >> iter 16000, loss: 12.940304
 >> iter 17000, loss: 12.933191
 >> iter 18000, loss: 12.938647
 >> iter 19000, loss: 12.931409
 >> iter 20000, loss: 12.941663
   Number of active neurons: 7
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 7
 >> iter 21000, loss: 12.932917
 >> iter 22000, loss: 12.939233
 >> iter 23000, loss: 12.761977
 >> iter 24000, loss: 11.240321
 >> iter 25000, loss: 4.896956
 >> iter 26000, loss: 2.069780
 >> iter 27000, loss: 0.880123
 >> iter 28000, loss: 0.390056
 >> iter 29000, loss: 0.229156
 >> iter 30000, loss: 0.155609
   Number of active neurons: 10
 >> iter 31000, loss: 0.196428
 >> iter 32000, loss: 0.492021
 >> iter 33000, loss: 0.204248
 >> iter 34000, loss: 0.090744
 >> iter 35000, loss: 0.107292
 >> iter 36000, loss: 0.049263
 >> iter 37000, loss: 0.025955
 >> iter 38000, loss: 0.017063
 >> iter 39000, loss: 0.041184
 >> iter 40000, loss: 0.021886
   Number of active neurons: 10
 >> iter 41000, loss: 0.013561
 >> iter 42000, loss: 0.009965
 >> iter 43000, loss: 0.008498
 >> iter 44000, loss: 0.009711
 >> iter 45000, loss: 0.007593
 >> iter 46000, loss: 0.006512
 >> iter 47000, loss: 0.005592
 >> iter 48000, loss: 0.005023
 >> iter 49000, loss: 0.004772
 >> iter 50000, loss: 0.004487
   Number of active neurons: 10
 >> iter 51000, loss: 0.004062
 >> iter 52000, loss: 0.003837
 >> iter 53000, loss: 0.026674
 >> iter 54000, loss: 0.057487
 >> iter 55000, loss: 0.024959
 >> iter 56000, loss: 0.011816
 >> iter 57000, loss: 0.007108
 >> iter 58000, loss: 0.004894
 >> iter 59000, loss: 0.100824
 >> iter 60000, loss: 0.071078
   Number of active neurons: 10
 >> iter 61000, loss: 0.028627
 >> iter 62000, loss: 0.012755
 >> iter 63000, loss: 0.007006
 >> iter 64000, loss: 0.004594
 >> iter 65000, loss: 0.003693
 >> iter 66000, loss: 0.003164
 >> iter 67000, loss: 0.003879
 >> iter 68000, loss: 0.003174
 >> iter 69000, loss: 0.002730
 >> iter 70000, loss: 0.002484
   Number of active neurons: 10
 >> iter 71000, loss: 0.002322
 >> iter 72000, loss: 0.002212
 >> iter 73000, loss: 0.002117
 >> iter 74000, loss: 0.007112
 >> iter 75000, loss: 0.004145
 >> iter 76000, loss: 0.002812
 >> iter 77000, loss: 0.003182
 >> iter 78000, loss: 0.002511
 >> iter 79000, loss: 0.002080
 >> iter 80000, loss: 0.001938
   Number of active neurons: 10
 >> iter 81000, loss: 0.001816
 >> iter 82000, loss: 0.001725
 >> iter 83000, loss: 0.001674
 >> iter 84000, loss: 0.001627
 >> iter 85000, loss: 0.001597
 >> iter 86000, loss: 0.001729
 >> iter 87000, loss: 0.001565
 >> iter 88000, loss: 0.001471
 >> iter 89000, loss: 0.001417
 >> iter 90000, loss: 0.001354
   Number of active neurons: 10
 >> iter 91000, loss: 0.001323
 >> iter 92000, loss: 0.001406
 >> iter 93000, loss: 0.001330
 >> iter 94000, loss: 0.001290
 >> iter 95000, loss: 0.001244
 >> iter 96000, loss: 0.001222
 >> iter 97000, loss: 0.002030
 >> iter 98000, loss: 0.002984
 >> iter 99000, loss: 0.003038
 >> iter 100000, loss: 0.002150
   Number of active neurons: 10
 >> iter 101000, loss: 0.001715
 >> iter 102000, loss: 0.006930
 >> iter 103000, loss: 0.003450
 >> iter 104000, loss: 0.002175
 >> iter 105000, loss: 0.002736
 >> iter 106000, loss: 0.001826
 >> iter 107000, loss: 0.001435
 >> iter 108000, loss: 0.001244
 >> iter 109000, loss: 0.001172
 >> iter 110000, loss: 0.001087
   Number of active neurons: 10
 >> iter 111000, loss: 0.001087
 >> iter 112000, loss: 0.001058
 >> iter 113000, loss: 0.001017
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 18.669861
 >> iter 2000, loss: 15.135538
 >> iter 3000, loss: 13.781660
 >> iter 4000, loss: 13.277410
 >> iter 5000, loss: 13.070643
 >> iter 6000, loss: 13.006801
 >> iter 7000, loss: 12.963436
 >> iter 8000, loss: 12.961234
 >> iter 9000, loss: 12.947946
 >> iter 10000, loss: 12.948903
   Number of active neurons: 7
 >> iter 11000, loss: 12.937082
 >> iter 12000, loss: 12.953963
 >> iter 13000, loss: 12.946149
 >> iter 14000, loss: 12.951455
 >> iter 15000, loss: 12.942591
 >> iter 16000, loss: 12.955472
 >> iter 17000, loss: 12.939115
 >> iter 18000, loss: 12.939111
 >> iter 19000, loss: 12.937667
 >> iter 20000, loss: 12.945356
   Number of active neurons: 7
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 7
 >> iter 21000, loss: 12.934913
 >> iter 22000, loss: 12.942121
 >> iter 23000, loss: 12.937145
 >> iter 24000, loss: 12.945237
 >> iter 25000, loss: 12.934483
 >> iter 26000, loss: 12.935042
 >> iter 27000, loss: 12.228389
 >> iter 28000, loss: 11.285212
 >> iter 29000, loss: 9.862068
 >> iter 30000, loss: 8.501439
   Number of active neurons: 10
 >> iter 31000, loss: 7.281608
 >> iter 32000, loss: 6.761165
 >> iter 33000, loss: 6.138477
 >> iter 34000, loss: 6.133832
 >> iter 35000, loss: 5.830853
 >> iter 36000, loss: 5.644273
 >> iter 37000, loss: 6.030220
 >> iter 38000, loss: 5.276786
 >> iter 39000, loss: 4.490788
 >> iter 40000, loss: 3.917820
   Number of active neurons: 10
 >> iter 41000, loss: 4.036372
 >> iter 42000, loss: 3.434029
 >> iter 43000, loss: 3.410406
 >> iter 44000, loss: 3.073372
 >> iter 45000, loss: 3.048755
 >> iter 46000, loss: 3.060929
 >> iter 47000, loss: 2.941232
 >> iter 48000, loss: 3.524481
 >> iter 49000, loss: 3.377395
 >> iter 50000, loss: 3.116785
   Number of active neurons: 10
 >> iter 51000, loss: 2.901129
 >> iter 52000, loss: 1.362519
 >> iter 53000, loss: 0.618788
 >> iter 54000, loss: 0.409030
 >> iter 55000, loss: 0.275687
 >> iter 56000, loss: 0.264035
 >> iter 57000, loss: 0.182696
 >> iter 58000, loss: 0.387451
 >> iter 59000, loss: 0.190368
 >> iter 60000, loss: 0.088628
   Number of active neurons: 10
 >> iter 61000, loss: 0.093548
 >> iter 62000, loss: 0.049026
 >> iter 63000, loss: 0.059958
 >> iter 64000, loss: 0.034387
 >> iter 65000, loss: 0.023053
 >> iter 66000, loss: 0.019904
 >> iter 67000, loss: 0.017163
 >> iter 68000, loss: 0.027464
 >> iter 69000, loss: 0.017190
 >> iter 70000, loss: 0.114633
   Number of active neurons: 10
 >> iter 71000, loss: 0.081475
 >> iter 72000, loss: 0.036945
 >> iter 73000, loss: 0.082097
 >> iter 74000, loss: 0.036627
 >> iter 75000, loss: 0.127797
 >> iter 76000, loss: 0.068809
 >> iter 77000, loss: 0.032296
 >> iter 78000, loss: 0.220194
 >> iter 79000, loss: 0.099554
 >> iter 80000, loss: 0.043717
   Number of active neurons: 10
 >> iter 81000, loss: 0.022603
 >> iter 82000, loss: 0.025982
 >> iter 83000, loss: 0.036402
 >> iter 84000, loss: 0.022059
 >> iter 85000, loss: 0.015327
 >> iter 86000, loss: 0.010246
 >> iter 87000, loss: 0.008258
 >> iter 88000, loss: 0.007243
 >> iter 89000, loss: 0.115444
 >> iter 90000, loss: 0.047061
   Number of active neurons: 10
 >> iter 91000, loss: 0.038105
 >> iter 92000, loss: 0.030450
 >> iter 93000, loss: 0.115757
 >> iter 94000, loss: 0.047699
 >> iter 95000, loss: 0.021950
 >> iter 96000, loss: 0.012075
 >> iter 97000, loss: 0.008391
 >> iter 98000, loss: 0.035626
 >> iter 99000, loss: 0.017240
 >> iter 100000, loss: 0.317621
   Number of active neurons: 10
 >> iter 101000, loss: 0.200324
 >> iter 102000, loss: 0.078774
 >> iter 103000, loss: 0.227184
 >> iter 104000, loss: 0.088816
 >> iter 105000, loss: 0.037413
 >> iter 106000, loss: 0.055696
 >> iter 107000, loss: 0.024914
 >> iter 108000, loss: 0.029433
 >> iter 109000, loss: 0.018100
 >> iter 110000, loss: 0.037798
   Number of active neurons: 10
 >> iter 111000, loss: 0.017696
 >> iter 112000, loss: 0.010433
 >> iter 113000, loss: 0.016164
 >> iter 114000, loss: 0.009725
 >> iter 115000, loss: 0.007912
 >> iter 116000, loss: 0.197207
 >> iter 117000, loss: 0.090705
 >> iter 118000, loss: 0.037462
 >> iter 119000, loss: 0.135171
 >> iter 120000, loss: 0.076302
   Number of active neurons: 10
 >> iter 121000, loss: 0.066247
 >> iter 122000, loss: 0.191372
 >> iter 123000, loss: 0.075421
 >> iter 124000, loss: 0.032039
 >> iter 125000, loss: 0.015761
 >> iter 126000, loss: 0.009517
 >> iter 127000, loss: 0.008610
 >> iter 128000, loss: 0.024482
 >> iter 129000, loss: 0.012290
 >> iter 130000, loss: 0.035230
   Number of active neurons: 10
 >> iter 131000, loss: 0.016418
 >> iter 132000, loss: 0.009212
 >> iter 133000, loss: 0.095398
 >> iter 134000, loss: 0.040253
 >> iter 135000, loss: 0.071200
 >> iter 136000, loss: 0.029672
 >> iter 137000, loss: 0.013938
 >> iter 138000, loss: 0.007941
 >> iter 139000, loss: 0.006763
 >> iter 140000, loss: 0.039799
   Number of active neurons: 10
 >> iter 141000, loss: 0.050969
 >> iter 142000, loss: 0.084152
 >> iter 143000, loss: 0.157412
 >> iter 144000, loss: 0.086315
 >> iter 145000, loss: 0.036270
 >> iter 146000, loss: 0.083765
 >> iter 147000, loss: 0.113951
 >> iter 148000, loss: 0.045907
 >> iter 149000, loss: 0.020299
 >> iter 150000, loss: 0.010681
   Number of active neurons: 10
 >> iter 151000, loss: 0.006938
 >> iter 152000, loss: 0.007768
 >> iter 153000, loss: 0.005662
 >> iter 154000, loss: 0.005107
 >> iter 155000, loss: 0.025616
 >> iter 156000, loss: 0.044138
 >> iter 157000, loss: 0.019313
 >> iter 158000, loss: 0.010088
 >> iter 159000, loss: 0.006408
 >> iter 160000, loss: 0.007717
   Number of active neurons: 10
 >> iter 161000, loss: 0.053941
 >> iter 162000, loss: 0.295304
 >> iter 163000, loss: 0.112406
 >> iter 164000, loss: 0.143306
 >> iter 165000, loss: 0.071880
 >> iter 166000, loss: 0.061057
 >> iter 167000, loss: 0.132768
 >> iter 168000, loss: 0.065468
 >> iter 169000, loss: 0.027684
 >> iter 170000, loss: 0.013496
   Number of active neurons: 10
 >> iter 171000, loss: 0.115315
 >> iter 172000, loss: 0.047021
 >> iter 173000, loss: 0.042147
 >> iter 174000, loss: 0.018766
 >> iter 175000, loss: 0.010674
 >> iter 176000, loss: 0.020544
 >> iter 177000, loss: 0.035293
 >> iter 178000, loss: 0.015934
 >> iter 179000, loss: 0.008551
 >> iter 180000, loss: 0.005679
   Number of active neurons: 10
 >> iter 181000, loss: 0.004454
 >> iter 182000, loss: 0.004227
 >> iter 183000, loss: 0.004162
 >> iter 184000, loss: 0.003854
 >> iter 185000, loss: 0.026996
 >> iter 186000, loss: 0.012191
 >> iter 187000, loss: 0.006743
 >> iter 188000, loss: 0.198810
 >> iter 189000, loss: 0.113205
 >> iter 190000, loss: 0.093040
   Number of active neurons: 10
 >> iter 191000, loss: 0.040033
 >> iter 192000, loss: 0.017601
 >> iter 193000, loss: 0.021981
 >> iter 194000, loss: 3.077357
 >> iter 195000, loss: 2.558337
 >> iter 196000, loss: 1.147986
 >> iter 197000, loss: 0.495430
 >> iter 198000, loss: 0.231649
 >> iter 199000, loss: 0.137873
 >> iter 200000, loss: 0.091116
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0209997900021
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.718589
 >> iter 2000, loss: 15.191345
 >> iter 3000, loss: 13.808144
 >> iter 4000, loss: 13.288995
 >> iter 5000, loss: 13.084485
 >> iter 6000, loss: 13.017564
 >> iter 7000, loss: 12.985007
 >> iter 8000, loss: 12.976252
 >> iter 9000, loss: 12.960592
 >> iter 10000, loss: 12.971104
   Number of active neurons: 7
 >> iter 11000, loss: 12.956031
 >> iter 12000, loss: 12.956740
 >> iter 13000, loss: 12.945914
 >> iter 14000, loss: 12.956592
 >> iter 15000, loss: 12.960512
 >> iter 16000, loss: 12.962876
 >> iter 17000, loss: 12.953883
 >> iter 18000, loss: 12.947413
 >> iter 19000, loss: 12.932227
 >> iter 20000, loss: 12.642814
   Number of active neurons: 8
 >> iter 21000, loss: 11.597559
 >> iter 22000, loss: 10.391620
 >> iter 23000, loss: 9.252949
 >> iter 24000, loss: 5.766420
 >> iter 25000, loss: 2.601934
 >> iter 26000, loss: 1.645855
 >> iter 27000, loss: 0.853034
 >> iter 28000, loss: 0.563535
 >> iter 29000, loss: 0.789750
 >> iter 30000, loss: 0.326794
   Number of active neurons: 10
 >> iter 31000, loss: 0.189912
 >> iter 32000, loss: 0.213556
 >> iter 33000, loss: 0.097102
 >> iter 34000, loss: 0.048128
 >> iter 35000, loss: 0.062539
 >> iter 36000, loss: 0.035224
 >> iter 37000, loss: 0.021816
 >> iter 38000, loss: 0.074043
 >> iter 39000, loss: 0.209941
 >> iter 40000, loss: 0.089890
   Number of active neurons: 10
 >> iter 41000, loss: 0.040621
 >> iter 42000, loss: 0.021580
 >> iter 43000, loss: 0.018045
 >> iter 44000, loss: 0.011868
 >> iter 45000, loss: 0.133256
 >> iter 46000, loss: 0.068883
 >> iter 47000, loss: 0.030623
 >> iter 48000, loss: 0.015740
 >> iter 49000, loss: 0.190945
 >> iter 50000, loss: 0.082283
   Number of active neurons: 10
 >> iter 51000, loss: 0.113809
 >> iter 52000, loss: 0.063264
 >> iter 53000, loss: 0.028183
 >> iter 54000, loss: 0.017651
 >> iter 55000, loss: 0.010336
 >> iter 56000, loss: 0.007516
 >> iter 57000, loss: 0.005750
 >> iter 58000, loss: 0.005815
 >> iter 59000, loss: 0.005011
 >> iter 60000, loss: 0.004464
   Number of active neurons: 10
 >> iter 61000, loss: 0.004206
 >> iter 62000, loss: 0.003753
 >> iter 63000, loss: 0.123112
 >> iter 64000, loss: 0.048297
 >> iter 65000, loss: 0.020297
 >> iter 66000, loss: 0.009821
 >> iter 67000, loss: 0.026713
 >> iter 68000, loss: 0.012155
 >> iter 69000, loss: 0.010684
 >> iter 70000, loss: 0.006414
   Number of active neurons: 10
 >> iter 71000, loss: 0.004327
 >> iter 72000, loss: 0.027394
 >> iter 73000, loss: 0.168632
 >> iter 74000, loss: 0.078635
 >> iter 75000, loss: 0.032066
 >> iter 76000, loss: 0.014176
 >> iter 77000, loss: 0.007550
 >> iter 78000, loss: 0.004777
 >> iter 79000, loss: 0.003817
 >> iter 80000, loss: 0.003320
   Number of active neurons: 10
 >> iter 81000, loss: 0.022594
 >> iter 82000, loss: 0.010351
 >> iter 83000, loss: 0.005671
 >> iter 84000, loss: 0.003754
 >> iter 85000, loss: 0.003782
 >> iter 86000, loss: 0.003224
 >> iter 87000, loss: 0.007129
 >> iter 88000, loss: 0.006519
 >> iter 89000, loss: 0.005511
 >> iter 90000, loss: 0.003448
   Number of active neurons: 10
 >> iter 91000, loss: 0.002558
 >> iter 92000, loss: 0.002202
 >> iter 93000, loss: 0.070488
 >> iter 94000, loss: 0.027478
 >> iter 95000, loss: 0.011492
 >> iter 96000, loss: 0.008717
 >> iter 97000, loss: 0.004950
 >> iter 98000, loss: 0.003149
 >> iter 99000, loss: 0.002481
 >> iter 100000, loss: 0.013636
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.690715
 >> iter 2000, loss: 15.181136
 >> iter 3000, loss: 13.823408
 >> iter 4000, loss: 13.304340
 >> iter 5000, loss: 13.103213
 >> iter 6000, loss: 13.023521
 >> iter 7000, loss: 12.985879
 >> iter 8000, loss: 12.972785
 >> iter 9000, loss: 12.963790
 >> iter 10000, loss: 12.969355
   Number of active neurons: 7
 >> iter 11000, loss: 12.954620
 >> iter 12000, loss: 12.964520
 >> iter 13000, loss: 12.952920
 >> iter 14000, loss: 12.957325
 >> iter 15000, loss: 12.784649
 >> iter 16000, loss: 11.882939
 >> iter 17000, loss: 11.240369
 >> iter 18000, loss: 10.791453
 >> iter 19000, loss: 10.294972
 >> iter 20000, loss: 9.713588
   Number of active neurons: 10
 >> iter 21000, loss: 8.909944
 >> iter 22000, loss: 6.469403
 >> iter 23000, loss: 3.317033
 >> iter 24000, loss: 1.940642
 >> iter 25000, loss: 0.828359
 >> iter 26000, loss: 0.655981
 >> iter 27000, loss: 0.356729
 >> iter 28000, loss: 0.519020
 >> iter 29000, loss: 0.347419
 >> iter 30000, loss: 0.325498
   Number of active neurons: 10
 >> iter 31000, loss: 0.257685
 >> iter 32000, loss: 0.361202
 >> iter 33000, loss: 0.228589
 >> iter 34000, loss: 0.251899
 >> iter 35000, loss: 0.182311
 >> iter 36000, loss: 0.245935
 >> iter 37000, loss: 0.112112
 >> iter 38000, loss: 0.198672
 >> iter 39000, loss: 0.188161
 >> iter 40000, loss: 0.124602
   Number of active neurons: 10
 >> iter 41000, loss: 0.069656
 >> iter 42000, loss: 0.190743
 >> iter 43000, loss: 0.352706
 >> iter 44000, loss: 0.219770
 >> iter 45000, loss: 0.186560
 >> iter 46000, loss: 0.102118
 >> iter 47000, loss: 0.049436
 >> iter 48000, loss: 0.286885
 >> iter 49000, loss: 0.117767
 >> iter 50000, loss: 0.054984
   Number of active neurons: 10
 >> iter 51000, loss: 0.073832
 >> iter 52000, loss: 0.071400
 >> iter 53000, loss: 0.078111
 >> iter 54000, loss: 0.052029
 >> iter 55000, loss: 0.026170
 >> iter 56000, loss: 0.021575
 >> iter 57000, loss: 0.014116
 >> iter 58000, loss: 0.010955
 >> iter 59000, loss: 0.009198
 >> iter 60000, loss: 0.008458
   Number of active neurons: 10
 >> iter 61000, loss: 0.033156
 >> iter 62000, loss: 0.167934
 >> iter 63000, loss: 0.096659
 >> iter 64000, loss: 0.199552
 >> iter 65000, loss: 0.199641
 >> iter 66000, loss: 0.242272
 >> iter 67000, loss: 0.238993
 >> iter 68000, loss: 0.565032
 >> iter 69000, loss: 0.224451
 >> iter 70000, loss: 0.273240
   Number of active neurons: 10
 >> iter 71000, loss: 0.148094
 >> iter 72000, loss: 0.065820
 >> iter 73000, loss: 0.036906
 >> iter 74000, loss: 0.411947
 >> iter 75000, loss: 0.178023
 >> iter 76000, loss: 0.312412
 >> iter 77000, loss: 0.130803
 >> iter 78000, loss: 0.289044
 >> iter 79000, loss: 0.238040
 >> iter 80000, loss: 0.138087
   Number of active neurons: 10
 >> iter 81000, loss: 0.065301
 >> iter 82000, loss: 0.034452
 >> iter 83000, loss: 0.035040
 >> iter 84000, loss: 0.022973
 >> iter 85000, loss: 0.044074
 >> iter 86000, loss: 0.135903
 >> iter 87000, loss: 0.060511
 >> iter 88000, loss: 0.209977
 >> iter 89000, loss: 0.204082
 >> iter 90000, loss: 0.084435
   Number of active neurons: 10
 >> iter 91000, loss: 0.385032
 >> iter 92000, loss: 0.251370
 >> iter 93000, loss: 0.120070
 >> iter 94000, loss: 0.052996
 >> iter 95000, loss: 0.092230
 >> iter 96000, loss: 0.045409
 >> iter 97000, loss: 0.023665
 >> iter 98000, loss: 0.016734
 >> iter 99000, loss: 0.091080
 >> iter 100000, loss: 0.039786
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

