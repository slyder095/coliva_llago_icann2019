 > Problema: tomita1nueva
 > Args:
   - Hidden size: 20
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.950678
 >> iter 2000, loss: 4.073505
 >> iter 3000, loss: 1.528949
 >> iter 4000, loss: 0.589056
 >> iter 5000, loss: 0.236595
 >> iter 6000, loss: 0.107264
 >> iter 7000, loss: 0.058276
 >> iter 8000, loss: 0.044576
 >> iter 9000, loss: 0.044493
 >> iter 10000, loss: 0.036198
   Number of active neurons: 4
 >> iter 11000, loss: 0.030344
 >> iter 12000, loss: 0.029940
 >> iter 13000, loss: 0.030127
 >> iter 14000, loss: 0.030379
 >> iter 15000, loss: 0.050681
 >> iter 16000, loss: 0.036484
 >> iter 17000, loss: 0.031878
 >> iter 18000, loss: 0.028858
 >> iter 19000, loss: 0.027926
 >> iter 20000, loss: 0.025321
   Number of active neurons: 4
 >> iter 21000, loss: 0.027929
 >> iter 22000, loss: 0.033803
 >> iter 23000, loss: 0.028006
 >> iter 24000, loss: 0.025105
 >> iter 25000, loss: 0.023936
 >> iter 26000, loss: 0.029976
 >> iter 27000, loss: 0.030612
 >> iter 28000, loss: 0.024703
 >> iter 29000, loss: 0.024712
 >> iter 30000, loss: 0.021610
   Number of active neurons: 2
 >> iter 31000, loss: 0.022958
 >> iter 32000, loss: 0.024039
 >> iter 33000, loss: 0.027761
 >> iter 34000, loss: 0.023344
 >> iter 35000, loss: 0.027100
 >> iter 36000, loss: 0.026282
 >> iter 37000, loss: 0.028423
 >> iter 38000, loss: 0.024263
 >> iter 39000, loss: 0.032725
 >> iter 40000, loss: 0.024425
   Number of active neurons: 2
 >> iter 41000, loss: 0.029399
 >> iter 42000, loss: 0.022460
 >> iter 43000, loss: 0.022040
 >> iter 44000, loss: 0.021387
 >> iter 45000, loss: 0.023103
 >> iter 46000, loss: 0.029976
 >> iter 47000, loss: 0.034677
 >> iter 48000, loss: 0.025383
 >> iter 49000, loss: 0.022519
 >> iter 50000, loss: 0.019647
   Number of active neurons: 2
 >> iter 51000, loss: 0.020652
 >> iter 52000, loss: 0.020215
 >> iter 53000, loss: 0.021168
 >> iter 54000, loss: 0.023510
 >> iter 55000, loss: 0.023468
 >> iter 56000, loss: 0.023013
 >> iter 57000, loss: 0.027232
 >> iter 58000, loss: 0.025244
 >> iter 59000, loss: 0.023088
 >> iter 60000, loss: 0.021168
   Number of active neurons: 2
 >> iter 61000, loss: 0.019617
 >> iter 62000, loss: 0.019002
 >> iter 63000, loss: 0.021359
 >> iter 64000, loss: 0.020049
 >> iter 65000, loss: 0.032802
 >> iter 66000, loss: 0.028203
 >> iter 67000, loss: 0.023483
 >> iter 68000, loss: 0.027131
 >> iter 69000, loss: 0.024177
 >> iter 70000, loss: 0.026202
   Number of active neurons: 2
 >> iter 71000, loss: 0.021845
 >> iter 72000, loss: 0.023623
 >> iter 73000, loss: 0.022510
 >> iter 74000, loss: 0.027062
 >> iter 75000, loss: 0.021887
 >> iter 76000, loss: 0.027725
 >> iter 77000, loss: 0.024278
 >> iter 78000, loss: 0.023035
 >> iter 79000, loss: 0.024872
 >> iter 80000, loss: 0.026740
   Number of active neurons: 2
 >> iter 81000, loss: 0.034821
 >> iter 82000, loss: 0.035943
 >> iter 83000, loss: 0.026548
 >> iter 84000, loss: 0.021650
 >> iter 85000, loss: 0.035955
 >> iter 86000, loss: 0.025569
 >> iter 87000, loss: 0.027568
 >> iter 88000, loss: 0.026565
 >> iter 89000, loss: 0.022157
 >> iter 90000, loss: 0.032419
   Number of active neurons: 2
 >> iter 91000, loss: 0.026114
 >> iter 92000, loss: 0.023421
 >> iter 93000, loss: 0.024121
 >> iter 94000, loss: 0.025279
 >> iter 95000, loss: 0.021805
 >> iter 96000, loss: 0.020539
 >> iter 97000, loss: 0.020655
 >> iter 98000, loss: 0.035289
 >> iter 99000, loss: 0.026835
 >> iter 100000, loss: 0.021251
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.006669
 >> iter 2000, loss: 4.102256
 >> iter 3000, loss: 1.535209
 >> iter 4000, loss: 0.590236
 >> iter 5000, loss: 0.246256
 >> iter 6000, loss: 0.120972
 >> iter 7000, loss: 0.073737
 >> iter 8000, loss: 0.047355
 >> iter 9000, loss: 0.037299
 >> iter 10000, loss: 0.033408
   Number of active neurons: 6
 >> iter 11000, loss: 0.033186
 >> iter 12000, loss: 0.029518
 >> iter 13000, loss: 0.040761
 >> iter 14000, loss: 0.034552
 >> iter 15000, loss: 0.037938
 >> iter 16000, loss: 0.031346
 >> iter 17000, loss: 0.038008
 >> iter 18000, loss: 0.037506
 >> iter 19000, loss: 0.029744
 >> iter 20000, loss: 0.033182
   Number of active neurons: 4
 >> iter 21000, loss: 0.031241
 >> iter 22000, loss: 0.030054
 >> iter 23000, loss: 0.031979
 >> iter 24000, loss: 0.027763
 >> iter 25000, loss: 0.026602
 >> iter 26000, loss: 0.027020
 >> iter 27000, loss: 0.024647
 >> iter 28000, loss: 0.028164
 >> iter 29000, loss: 0.029103
 >> iter 30000, loss: 0.025857
   Number of active neurons: 3
 >> iter 31000, loss: 0.025999
 >> iter 32000, loss: 0.025345
 >> iter 33000, loss: 0.023961
 >> iter 34000, loss: 0.023133
 >> iter 35000, loss: 0.028599
 >> iter 36000, loss: 0.034736
 >> iter 37000, loss: 0.028318
 >> iter 38000, loss: 0.026197
 >> iter 39000, loss: 0.033783
 >> iter 40000, loss: 0.030816
   Number of active neurons: 2
 >> iter 41000, loss: 0.025049
 >> iter 42000, loss: 0.022133
 >> iter 43000, loss: 0.021667
 >> iter 44000, loss: 0.019552
 >> iter 45000, loss: 0.025300
 >> iter 46000, loss: 0.043973
 >> iter 47000, loss: 0.033421
 >> iter 48000, loss: 0.027221
 >> iter 49000, loss: 0.025155
 >> iter 50000, loss: 0.030209
   Number of active neurons: 2
 >> iter 51000, loss: 0.024566
 >> iter 52000, loss: 0.021196
 >> iter 53000, loss: 0.025940
 >> iter 54000, loss: 0.024837
 >> iter 55000, loss: 0.041569
 >> iter 56000, loss: 0.029937
 >> iter 57000, loss: 0.024897
 >> iter 58000, loss: 0.037007
 >> iter 59000, loss: 0.029845
 >> iter 60000, loss: 0.026847
   Number of active neurons: 1
 >> iter 61000, loss: 0.023685
 >> iter 62000, loss: 0.019800
 >> iter 63000, loss: 0.025287
 >> iter 64000, loss: 0.023320
 >> iter 65000, loss: 0.032232
 >> iter 66000, loss: 0.028158
 >> iter 67000, loss: 0.029812
 >> iter 68000, loss: 0.028332
 >> iter 69000, loss: 0.030543
 >> iter 70000, loss: 0.021286
   Number of active neurons: 1
 >> iter 71000, loss: 0.027271
 >> iter 72000, loss: 0.020625
 >> iter 73000, loss: 0.020872
 >> iter 74000, loss: 0.051244
 >> iter 75000, loss: 0.033351
 >> iter 76000, loss: 0.025509
 >> iter 77000, loss: 0.025876
 >> iter 78000, loss: 0.021275
 >> iter 79000, loss: 0.024590
 >> iter 80000, loss: 0.030947
   Number of active neurons: 1
 >> iter 81000, loss: 0.031744
 >> iter 82000, loss: 0.024241
 >> iter 83000, loss: 0.022574
 >> iter 84000, loss: 0.021096
 >> iter 85000, loss: 0.020133
 >> iter 86000, loss: 0.026284
 >> iter 87000, loss: 0.020406
 >> iter 88000, loss: 0.020326
 >> iter 89000, loss: 0.024536
 >> iter 90000, loss: 0.023497
   Number of active neurons: 1
 >> iter 91000, loss: 0.018497
 >> iter 92000, loss: 0.019064
 >> iter 93000, loss: 0.018818
 >> iter 94000, loss: 0.017574
 >> iter 95000, loss: 0.028791
 >> iter 96000, loss: 0.021390
 >> iter 97000, loss: 0.021324
 >> iter 98000, loss: 0.017582
 >> iter 99000, loss: 0.025930
 >> iter 100000, loss: 0.020539
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.968124
 >> iter 2000, loss: 4.090095
 >> iter 3000, loss: 1.538416
 >> iter 4000, loss: 0.602038
 >> iter 5000, loss: 0.261709
 >> iter 6000, loss: 0.127259
 >> iter 7000, loss: 0.071535
 >> iter 8000, loss: 0.055389
 >> iter 9000, loss: 0.043979
 >> iter 10000, loss: 0.034260
   Number of active neurons: 5
 >> iter 11000, loss: 0.037074
 >> iter 12000, loss: 0.034789
 >> iter 13000, loss: 0.034660
 >> iter 14000, loss: 0.029437
 >> iter 15000, loss: 0.026806
 >> iter 16000, loss: 0.024903
 >> iter 17000, loss: 0.027461
 >> iter 18000, loss: 0.028081
 >> iter 19000, loss: 0.027413
 >> iter 20000, loss: 0.047348
   Number of active neurons: 3
 >> iter 21000, loss: 0.034268
 >> iter 22000, loss: 0.035588
 >> iter 23000, loss: 0.026934
 >> iter 24000, loss: 0.027429
 >> iter 25000, loss: 0.024776
 >> iter 26000, loss: 0.022851
 >> iter 27000, loss: 0.028772
 >> iter 28000, loss: 0.025377
 >> iter 29000, loss: 0.039728
 >> iter 30000, loss: 0.032213
   Number of active neurons: 2
 >> iter 31000, loss: 0.036770
 >> iter 32000, loss: 0.031580
 >> iter 33000, loss: 0.023595
 >> iter 34000, loss: 0.026954
 >> iter 35000, loss: 0.031897
 >> iter 36000, loss: 0.028949
 >> iter 37000, loss: 0.039303
 >> iter 38000, loss: 0.030745
 >> iter 39000, loss: 0.024224
 >> iter 40000, loss: 0.028383
   Number of active neurons: 2
 >> iter 41000, loss: 0.022954
 >> iter 42000, loss: 0.049576
 >> iter 43000, loss: 0.031109
 >> iter 44000, loss: 0.027050
 >> iter 45000, loss: 0.026210
 >> iter 46000, loss: 0.025115
 >> iter 47000, loss: 0.027217
 >> iter 48000, loss: 0.022954
 >> iter 49000, loss: 0.024392
 >> iter 50000, loss: 0.023618
   Number of active neurons: 1
 >> iter 51000, loss: 0.020578
 >> iter 52000, loss: 0.026796
 >> iter 53000, loss: 0.022129
 >> iter 54000, loss: 0.029157
 >> iter 55000, loss: 0.022473
 >> iter 56000, loss: 0.019089
 >> iter 57000, loss: 0.020522
 >> iter 58000, loss: 0.025307
 >> iter 59000, loss: 0.019075
 >> iter 60000, loss: 0.036137
   Number of active neurons: 1
 >> iter 61000, loss: 0.045864
 >> iter 62000, loss: 0.027176
 >> iter 63000, loss: 0.020800
 >> iter 64000, loss: 0.018096
 >> iter 65000, loss: 0.021685
 >> iter 66000, loss: 0.018929
 >> iter 67000, loss: 0.019411
 >> iter 68000, loss: 0.017119
 >> iter 69000, loss: 0.035128
 >> iter 70000, loss: 0.035684
   Number of active neurons: 1
 >> iter 71000, loss: 0.043369
 >> iter 72000, loss: 0.026579
 >> iter 73000, loss: 0.018718
 >> iter 74000, loss: 0.023212
 >> iter 75000, loss: 0.020690
 >> iter 76000, loss: 0.018962
 >> iter 77000, loss: 0.026860
 >> iter 78000, loss: 0.024955
 >> iter 79000, loss: 0.022579
 >> iter 80000, loss: 0.027487
   Number of active neurons: 1
 >> iter 81000, loss: 0.045035
 >> iter 82000, loss: 0.042197
 >> iter 83000, loss: 0.030432
 >> iter 84000, loss: 0.021883
 >> iter 85000, loss: 0.020526
 >> iter 86000, loss: 0.019010
 >> iter 87000, loss: 0.019138
 >> iter 88000, loss: 0.020324
 >> iter 89000, loss: 0.022664
 >> iter 90000, loss: 0.020440
   Number of active neurons: 1
 >> iter 91000, loss: 0.018541
 >> iter 92000, loss: 0.017955
 >> iter 93000, loss: 0.016448
 >> iter 94000, loss: 0.018148
 >> iter 95000, loss: 0.025697
 >> iter 96000, loss: 0.021321
 >> iter 97000, loss: 0.018890
 >> iter 98000, loss: 0.022243
 >> iter 99000, loss: 0.018023
 >> iter 100000, loss: 0.018102
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455178
   Number of active neurons: 0
 >> iter 1000, loss: 10.957473
 >> iter 2000, loss: 4.070275
 >> iter 3000, loss: 1.529754
 >> iter 4000, loss: 0.584631
 >> iter 5000, loss: 0.241353
 >> iter 6000, loss: 0.111412
 >> iter 7000, loss: 0.060438
 >> iter 8000, loss: 0.047249
 >> iter 9000, loss: 0.035896
 >> iter 10000, loss: 0.030941
   Number of active neurons: 2
 >> iter 11000, loss: 0.029682
 >> iter 12000, loss: 0.026778
 >> iter 13000, loss: 0.026978
 >> iter 14000, loss: 0.021873
 >> iter 15000, loss: 0.021032
 >> iter 16000, loss: 0.024170
 >> iter 17000, loss: 0.044154
 >> iter 18000, loss: 0.030764
 >> iter 19000, loss: 0.024280
 >> iter 20000, loss: 0.027977
   Number of active neurons: 2
 >> iter 21000, loss: 0.023505
 >> iter 22000, loss: 0.021631
 >> iter 23000, loss: 0.021988
 >> iter 24000, loss: 0.022651
 >> iter 25000, loss: 0.020232
 >> iter 26000, loss: 0.025718
 >> iter 27000, loss: 0.022299
 >> iter 28000, loss: 0.022107
 >> iter 29000, loss: 0.024311
 >> iter 30000, loss: 0.023296
   Number of active neurons: 2
 >> iter 31000, loss: 0.033582
 >> iter 32000, loss: 0.028315
 >> iter 33000, loss: 0.026196
 >> iter 34000, loss: 0.025279
 >> iter 35000, loss: 0.023364
 >> iter 36000, loss: 0.021254
 >> iter 37000, loss: 0.022954
 >> iter 38000, loss: 0.023811
 >> iter 39000, loss: 0.020391
 >> iter 40000, loss: 0.020909
   Number of active neurons: 2
 >> iter 41000, loss: 0.021109
 >> iter 42000, loss: 0.024002
 >> iter 43000, loss: 0.023685
 >> iter 44000, loss: 0.020519
 >> iter 45000, loss: 0.020084
 >> iter 46000, loss: 0.021134
 >> iter 47000, loss: 0.030368
 >> iter 48000, loss: 0.023605
 >> iter 49000, loss: 0.033407
 >> iter 50000, loss: 0.025904
   Number of active neurons: 2
 >> iter 51000, loss: 0.032254
 >> iter 52000, loss: 0.023720
 >> iter 53000, loss: 0.036183
 >> iter 54000, loss: 0.030619
 >> iter 55000, loss: 0.023418
 >> iter 56000, loss: 0.024604
 >> iter 57000, loss: 0.023953
 >> iter 58000, loss: 0.023067
 >> iter 59000, loss: 0.022094
 >> iter 60000, loss: 0.025577
   Number of active neurons: 2
 >> iter 61000, loss: 0.023319
 >> iter 62000, loss: 0.022118
 >> iter 63000, loss: 0.023352
 >> iter 64000, loss: 0.023309
 >> iter 65000, loss: 0.021952
 >> iter 66000, loss: 0.025835
 >> iter 67000, loss: 0.021449
 >> iter 68000, loss: 0.047768
 >> iter 69000, loss: 0.037345
 >> iter 70000, loss: 0.029989
   Number of active neurons: 2
 >> iter 71000, loss: 0.025023
 >> iter 72000, loss: 0.022821
 >> iter 73000, loss: 0.021831
 >> iter 74000, loss: 0.020769
 >> iter 75000, loss: 0.023833
 >> iter 76000, loss: 0.024243
 >> iter 77000, loss: 0.035582
 >> iter 78000, loss: 0.035729
 >> iter 79000, loss: 0.026886
 >> iter 80000, loss: 0.033101
   Number of active neurons: 2
 >> iter 81000, loss: 0.026093
 >> iter 82000, loss: 0.024827
 >> iter 83000, loss: 0.031453
 >> iter 84000, loss: 0.024933
 >> iter 85000, loss: 0.021404
 >> iter 86000, loss: 0.020552
 >> iter 87000, loss: 0.034897
 >> iter 88000, loss: 0.025698
 >> iter 89000, loss: 0.053129
 >> iter 90000, loss: 0.035516
   Number of active neurons: 2
 >> iter 91000, loss: 0.031986
 >> iter 92000, loss: 0.025504
 >> iter 93000, loss: 0.029320
 >> iter 94000, loss: 0.023364
 >> iter 95000, loss: 0.026015
 >> iter 96000, loss: 0.021309
 >> iter 97000, loss: 0.021718
 >> iter 98000, loss: 0.023121
 >> iter 99000, loss: 0.024335
 >> iter 100000, loss: 0.021512
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.045950
 >> iter 2000, loss: 4.131150
 >> iter 3000, loss: 1.554107
 >> iter 4000, loss: 0.615681
 >> iter 5000, loss: 0.253322
 >> iter 6000, loss: 0.118344
 >> iter 7000, loss: 0.067168
 >> iter 8000, loss: 0.062292
 >> iter 9000, loss: 0.042937
 >> iter 10000, loss: 0.035596
   Number of active neurons: 5
 >> iter 11000, loss: 0.036415
 >> iter 12000, loss: 0.039142
 >> iter 13000, loss: 0.033141
 >> iter 14000, loss: 0.032588
 >> iter 15000, loss: 0.033549
 >> iter 16000, loss: 0.036540
 >> iter 17000, loss: 0.032143
 >> iter 18000, loss: 0.028993
 >> iter 19000, loss: 0.027531
 >> iter 20000, loss: 0.029038
   Number of active neurons: 3
 >> iter 21000, loss: 0.026608
 >> iter 22000, loss: 0.024767
 >> iter 23000, loss: 0.027824
 >> iter 24000, loss: 0.027203
 >> iter 25000, loss: 0.024330
 >> iter 26000, loss: 0.028870
 >> iter 27000, loss: 0.024507
 >> iter 28000, loss: 0.023329
 >> iter 29000, loss: 0.023416
 >> iter 30000, loss: 0.022879
   Number of active neurons: 3
 >> iter 31000, loss: 0.023656
 >> iter 32000, loss: 0.022513
 >> iter 33000, loss: 0.022404
 >> iter 34000, loss: 0.023550
 >> iter 35000, loss: 0.023636
 >> iter 36000, loss: 0.022467
 >> iter 37000, loss: 0.025670
 >> iter 38000, loss: 0.023141
 >> iter 39000, loss: 0.021810
 >> iter 40000, loss: 0.021561
   Number of active neurons: 2
 >> iter 41000, loss: 0.022671
 >> iter 42000, loss: 0.023371
 >> iter 43000, loss: 0.023944
 >> iter 44000, loss: 0.021164
 >> iter 45000, loss: 0.020892
 >> iter 46000, loss: 0.027872
 >> iter 47000, loss: 0.022910
 >> iter 48000, loss: 0.020658
 >> iter 49000, loss: 0.019875
 >> iter 50000, loss: 0.029545
   Number of active neurons: 2
 >> iter 51000, loss: 0.023487
 >> iter 52000, loss: 0.027065
 >> iter 53000, loss: 0.022973
 >> iter 54000, loss: 0.025825
 >> iter 55000, loss: 0.022320
 >> iter 56000, loss: 0.023919
 >> iter 57000, loss: 0.023180
 >> iter 58000, loss: 0.029246
 >> iter 59000, loss: 0.024398
 >> iter 60000, loss: 0.022612
   Number of active neurons: 2
 >> iter 61000, loss: 0.022436
 >> iter 62000, loss: 0.021758
 >> iter 63000, loss: 0.023630
 >> iter 64000, loss: 0.021095
 >> iter 65000, loss: 0.022137
 >> iter 66000, loss: 0.049197
 >> iter 67000, loss: 0.031236
 >> iter 68000, loss: 0.023299
 >> iter 69000, loss: 0.024043
 >> iter 70000, loss: 0.024744
   Number of active neurons: 2
 >> iter 71000, loss: 0.025332
 >> iter 72000, loss: 0.021960
 >> iter 73000, loss: 0.023199
 >> iter 74000, loss: 0.022046
 >> iter 75000, loss: 0.019691
 >> iter 76000, loss: 0.026166
 >> iter 77000, loss: 0.024364
 >> iter 78000, loss: 0.021856
 >> iter 79000, loss: 0.020767
 >> iter 80000, loss: 0.019798
   Number of active neurons: 2
 >> iter 81000, loss: 0.020964
 >> iter 82000, loss: 0.020540
 >> iter 83000, loss: 0.022646
 >> iter 84000, loss: 0.037671
 >> iter 85000, loss: 0.031011
 >> iter 86000, loss: 0.024006
 >> iter 87000, loss: 0.035044
 >> iter 88000, loss: 0.025923
 >> iter 89000, loss: 0.031187
 >> iter 90000, loss: 0.033729
   Number of active neurons: 2
 >> iter 91000, loss: 0.038400
 >> iter 92000, loss: 0.026551
 >> iter 93000, loss: 0.025606
 >> iter 94000, loss: 0.021916
 >> iter 95000, loss: 0.029642
 >> iter 96000, loss: 0.022816
 >> iter 97000, loss: 0.021777
 >> iter 98000, loss: 0.026932
 >> iter 99000, loss: 0.022742
 >> iter 100000, loss: 0.025562
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.911192
 >> iter 2000, loss: 4.061862
 >> iter 3000, loss: 1.525233
 >> iter 4000, loss: 0.586709
 >> iter 5000, loss: 0.244058
 >> iter 6000, loss: 0.111217
 >> iter 7000, loss: 0.058761
 >> iter 8000, loss: 0.047065
 >> iter 9000, loss: 0.035904
 >> iter 10000, loss: 0.031230
   Number of active neurons: 5
 >> iter 11000, loss: 0.029887
 >> iter 12000, loss: 0.030153
 >> iter 13000, loss: 0.033002
 >> iter 14000, loss: 0.029447
 >> iter 15000, loss: 0.030156
 >> iter 16000, loss: 0.027210
 >> iter 17000, loss: 0.025231
 >> iter 18000, loss: 0.040866
 >> iter 19000, loss: 0.031016
 >> iter 20000, loss: 0.034160
   Number of active neurons: 2
 >> iter 21000, loss: 0.027526
 >> iter 22000, loss: 0.028384
 >> iter 23000, loss: 0.024328
 >> iter 24000, loss: 0.032202
 >> iter 25000, loss: 0.026262
 >> iter 26000, loss: 0.030093
 >> iter 27000, loss: 0.022980
 >> iter 28000, loss: 0.024981
 >> iter 29000, loss: 0.022682
 >> iter 30000, loss: 0.023715
   Number of active neurons: 2
 >> iter 31000, loss: 0.027556
 >> iter 32000, loss: 0.024411
 >> iter 33000, loss: 0.021115
 >> iter 34000, loss: 0.033534
 >> iter 35000, loss: 0.023551
 >> iter 36000, loss: 0.022261
 >> iter 37000, loss: 0.021753
 >> iter 38000, loss: 0.026446
 >> iter 39000, loss: 0.025019
 >> iter 40000, loss: 0.024080
   Number of active neurons: 2
 >> iter 41000, loss: 0.030558
 >> iter 42000, loss: 0.025725
 >> iter 43000, loss: 0.023612
 >> iter 44000, loss: 0.022039
 >> iter 45000, loss: 0.020435
 >> iter 46000, loss: 0.019488
 >> iter 47000, loss: 0.021182
 >> iter 48000, loss: 0.023304
 >> iter 49000, loss: 0.021665
 >> iter 50000, loss: 0.020263
   Number of active neurons: 2
 >> iter 51000, loss: 0.020305
 >> iter 52000, loss: 0.023482
 >> iter 53000, loss: 0.021921
 >> iter 54000, loss: 0.022501
 >> iter 55000, loss: 0.020463
 >> iter 56000, loss: 0.021351
 >> iter 57000, loss: 0.022034
 >> iter 58000, loss: 0.020789
 >> iter 59000, loss: 0.020279
 >> iter 60000, loss: 0.024793
   Number of active neurons: 2
 >> iter 61000, loss: 0.025922
 >> iter 62000, loss: 0.021600
 >> iter 63000, loss: 0.031965
 >> iter 64000, loss: 0.027407
 >> iter 65000, loss: 0.025985
 >> iter 66000, loss: 0.025863
 >> iter 67000, loss: 0.070211
 >> iter 68000, loss: 0.077436
 >> iter 69000, loss: 0.044216
 >> iter 70000, loss: 0.029980
   Number of active neurons: 2
 >> iter 71000, loss: 0.024114
 >> iter 72000, loss: 0.023342
 >> iter 73000, loss: 0.027546
 >> iter 74000, loss: 0.021747
 >> iter 75000, loss: 0.022148
 >> iter 76000, loss: 0.020953
 >> iter 77000, loss: 0.031595
 >> iter 78000, loss: 0.028435
 >> iter 79000, loss: 0.028528
 >> iter 80000, loss: 0.022227
   Number of active neurons: 2
 >> iter 81000, loss: 0.027543
 >> iter 82000, loss: 0.027408
 >> iter 83000, loss: 0.027432
 >> iter 84000, loss: 0.023059
 >> iter 85000, loss: 0.048374
 >> iter 86000, loss: 0.032786
 >> iter 87000, loss: 0.025105
 >> iter 88000, loss: 0.023022
 >> iter 89000, loss: 0.027078
 >> iter 90000, loss: 0.023511
   Number of active neurons: 2
 >> iter 91000, loss: 0.024929
 >> iter 92000, loss: 0.037309
 >> iter 93000, loss: 0.028065
 >> iter 94000, loss: 0.036843
 >> iter 95000, loss: 0.028171
 >> iter 96000, loss: 0.028407
 >> iter 97000, loss: 0.036700
 >> iter 98000, loss: 0.043148
 >> iter 99000, loss: 0.042561
 >> iter 100000, loss: 0.028783
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.984436
 >> iter 2000, loss: 4.092640
 >> iter 3000, loss: 1.550649
 >> iter 4000, loss: 0.593190
 >> iter 5000, loss: 0.243870
 >> iter 6000, loss: 0.112768
 >> iter 7000, loss: 0.061076
 >> iter 8000, loss: 0.049512
 >> iter 9000, loss: 0.038199
 >> iter 10000, loss: 0.031958
   Number of active neurons: 6
 >> iter 11000, loss: 0.047477
 >> iter 12000, loss: 0.041348
 >> iter 13000, loss: 0.032347
 >> iter 14000, loss: 0.028771
 >> iter 15000, loss: 0.045404
 >> iter 16000, loss: 0.034405
 >> iter 17000, loss: 0.030600
 >> iter 18000, loss: 0.027907
 >> iter 19000, loss: 0.029006
 >> iter 20000, loss: 0.026449
   Number of active neurons: 4
 >> iter 21000, loss: 0.028741
 >> iter 22000, loss: 0.031341
 >> iter 23000, loss: 0.030168
 >> iter 24000, loss: 0.029573
 >> iter 25000, loss: 0.033885
 >> iter 26000, loss: 0.032090
 >> iter 27000, loss: 0.030678
 >> iter 28000, loss: 0.034680
 >> iter 29000, loss: 0.027120
 >> iter 30000, loss: 0.025849
   Number of active neurons: 4
 >> iter 31000, loss: 0.026333
 >> iter 32000, loss: 0.035884
 >> iter 33000, loss: 0.032307
 >> iter 34000, loss: 0.032511
 >> iter 35000, loss: 0.029196
 >> iter 36000, loss: 0.034633
 >> iter 37000, loss: 0.035440
 >> iter 38000, loss: 0.045143
 >> iter 39000, loss: 0.040842
 >> iter 40000, loss: 0.033129
   Number of active neurons: 4
 >> iter 41000, loss: 0.028602
 >> iter 42000, loss: 0.026611
 >> iter 43000, loss: 0.049476
 >> iter 44000, loss: 0.036016
 >> iter 45000, loss: 0.031356
 >> iter 46000, loss: 0.031054
 >> iter 47000, loss: 0.029248
 >> iter 48000, loss: 0.026079
 >> iter 49000, loss: 0.027582
 >> iter 50000, loss: 0.024870
   Number of active neurons: 3
 >> iter 51000, loss: 0.024627
 >> iter 52000, loss: 0.023357
 >> iter 53000, loss: 0.023426
 >> iter 54000, loss: 0.023543
 >> iter 55000, loss: 0.023056
 >> iter 56000, loss: 0.022939
 >> iter 57000, loss: 0.025208
 >> iter 58000, loss: 0.022360
 >> iter 59000, loss: 0.023185
 >> iter 60000, loss: 0.036552
   Number of active neurons: 1
 >> iter 61000, loss: 0.027981
 >> iter 62000, loss: 0.020654
 >> iter 63000, loss: 0.019076
 >> iter 64000, loss: 0.025688
 >> iter 65000, loss: 0.035669
 >> iter 66000, loss: 0.023979
 >> iter 67000, loss: 0.022360
 >> iter 68000, loss: 0.018776
 >> iter 69000, loss: 0.024608
 >> iter 70000, loss: 0.022589
   Number of active neurons: 1
 >> iter 71000, loss: 0.023217
 >> iter 72000, loss: 0.021629
 >> iter 73000, loss: 0.020194
 >> iter 74000, loss: 0.018303
 >> iter 75000, loss: 0.018293
 >> iter 76000, loss: 0.021967
 >> iter 77000, loss: 0.018290
 >> iter 78000, loss: 0.028650
 >> iter 79000, loss: 0.020498
 >> iter 80000, loss: 0.019088
   Number of active neurons: 1
 >> iter 81000, loss: 0.019771
 >> iter 82000, loss: 0.019432
 >> iter 83000, loss: 0.040376
 >> iter 84000, loss: 0.028874
 >> iter 85000, loss: 0.021046
 >> iter 86000, loss: 0.018528
 >> iter 87000, loss: 0.018805
 >> iter 88000, loss: 0.017317
 >> iter 89000, loss: 0.036560
 >> iter 90000, loss: 0.026053
   Number of active neurons: 1
 >> iter 91000, loss: 0.020011
 >> iter 92000, loss: 0.017043
 >> iter 93000, loss: 0.018348
 >> iter 94000, loss: 0.020838
 >> iter 95000, loss: 0.025200
 >> iter 96000, loss: 0.019038
 >> iter 97000, loss: 0.027247
 >> iter 98000, loss: 0.020420
 >> iter 99000, loss: 0.017371
 >> iter 100000, loss: 0.040797
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.995948
 >> iter 2000, loss: 4.094582
 >> iter 3000, loss: 1.541017
 >> iter 4000, loss: 0.590444
 >> iter 5000, loss: 0.257993
 >> iter 6000, loss: 0.117523
 >> iter 7000, loss: 0.085884
 >> iter 8000, loss: 0.054126
 >> iter 9000, loss: 0.039403
 >> iter 10000, loss: 0.031878
   Number of active neurons: 5
 >> iter 11000, loss: 0.042872
 >> iter 12000, loss: 0.043735
 >> iter 13000, loss: 0.033597
 >> iter 14000, loss: 0.042890
 >> iter 15000, loss: 0.037484
 >> iter 16000, loss: 0.030784
 >> iter 17000, loss: 0.034857
 >> iter 18000, loss: 0.030447
 >> iter 19000, loss: 0.029288
 >> iter 20000, loss: 0.033325
   Number of active neurons: 4
 >> iter 21000, loss: 0.030354
 >> iter 22000, loss: 0.036351
 >> iter 23000, loss: 0.035597
 >> iter 24000, loss: 0.031586
 >> iter 25000, loss: 0.028555
 >> iter 26000, loss: 0.030586
 >> iter 27000, loss: 0.027788
 >> iter 28000, loss: 0.033498
 >> iter 29000, loss: 0.029690
 >> iter 30000, loss: 0.031299
   Number of active neurons: 4
 >> iter 31000, loss: 0.035446
 >> iter 32000, loss: 0.028055
 >> iter 33000, loss: 0.029462
 >> iter 34000, loss: 0.029016
 >> iter 35000, loss: 0.032630
 >> iter 36000, loss: 0.027220
 >> iter 37000, loss: 0.026732
 >> iter 38000, loss: 0.024463
 >> iter 39000, loss: 0.028711
 >> iter 40000, loss: 0.034883
   Number of active neurons: 3
 >> iter 41000, loss: 0.042577
 >> iter 42000, loss: 0.032497
 >> iter 43000, loss: 0.030921
 >> iter 44000, loss: 0.040710
 >> iter 45000, loss: 0.030384
 >> iter 46000, loss: 0.037438
 >> iter 47000, loss: 0.041503
 >> iter 48000, loss: 0.036296
 >> iter 49000, loss: 0.052269
 >> iter 50000, loss: 0.039245
   Number of active neurons: 3
 >> iter 51000, loss: 0.043140
 >> iter 52000, loss: 0.039046
 >> iter 53000, loss: 0.029383
 >> iter 54000, loss: 0.026350
 >> iter 55000, loss: 0.024860
 >> iter 56000, loss: 0.027376
 >> iter 57000, loss: 0.028213
 >> iter 58000, loss: 0.036458
 >> iter 59000, loss: 0.032904
 >> iter 60000, loss: 0.025522
   Number of active neurons: 3
 >> iter 61000, loss: 0.024950
 >> iter 62000, loss: 0.038154
 >> iter 63000, loss: 0.044207
 >> iter 64000, loss: 0.035612
 >> iter 65000, loss: 0.031452
 >> iter 66000, loss: 0.026604
 >> iter 67000, loss: 0.026285
 >> iter 68000, loss: 0.030188
 >> iter 69000, loss: 0.025283
 >> iter 70000, loss: 0.050232
   Number of active neurons: 1
 >> iter 71000, loss: 0.044243
 >> iter 72000, loss: 0.038580
 >> iter 73000, loss: 0.028629
 >> iter 74000, loss: 0.021154
 >> iter 75000, loss: 0.021615
 >> iter 76000, loss: 0.024863
 >> iter 77000, loss: 0.023329
 >> iter 78000, loss: 0.018561
 >> iter 79000, loss: 0.041479
 >> iter 80000, loss: 0.026701
   Number of active neurons: 1
 >> iter 81000, loss: 0.020794
 >> iter 82000, loss: 0.017746
 >> iter 83000, loss: 0.019527
 >> iter 84000, loss: 0.023164
 >> iter 85000, loss: 0.019154
 >> iter 86000, loss: 0.017201
 >> iter 87000, loss: 0.017077
 >> iter 88000, loss: 0.016561
 >> iter 89000, loss: 0.021745
 >> iter 90000, loss: 0.028445
   Number of active neurons: 1
 >> iter 91000, loss: 0.021582
 >> iter 92000, loss: 0.019920
 >> iter 93000, loss: 0.020423
 >> iter 94000, loss: 0.017339
 >> iter 95000, loss: 0.017401
 >> iter 96000, loss: 0.021204
 >> iter 97000, loss: 0.022110
 >> iter 98000, loss: 0.020448
 >> iter 99000, loss: 0.031762
 >> iter 100000, loss: 0.023657
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.928690
 >> iter 2000, loss: 4.067504
 >> iter 3000, loss: 1.524816
 >> iter 4000, loss: 0.592036
 >> iter 5000, loss: 0.241233
 >> iter 6000, loss: 0.111020
 >> iter 7000, loss: 0.063344
 >> iter 8000, loss: 0.045485
 >> iter 9000, loss: 0.036175
 >> iter 10000, loss: 0.034619
   Number of active neurons: 5
 >> iter 11000, loss: 0.031813
 >> iter 12000, loss: 0.027894
 >> iter 13000, loss: 0.027282
 >> iter 14000, loss: 0.029203
 >> iter 15000, loss: 0.036444
 >> iter 16000, loss: 0.030049
 >> iter 17000, loss: 0.027531
 >> iter 18000, loss: 0.023878
 >> iter 19000, loss: 0.024015
 >> iter 20000, loss: 0.032879
   Number of active neurons: 3
 >> iter 21000, loss: 0.031740
 >> iter 22000, loss: 0.032045
 >> iter 23000, loss: 0.031963
 >> iter 24000, loss: 0.029371
 >> iter 25000, loss: 0.035121
 >> iter 26000, loss: 0.027033
 >> iter 27000, loss: 0.026162
 >> iter 28000, loss: 0.030266
 >> iter 29000, loss: 0.030013
 >> iter 30000, loss: 0.026633
   Number of active neurons: 3
 >> iter 31000, loss: 0.033388
 >> iter 32000, loss: 0.027914
 >> iter 33000, loss: 0.034691
 >> iter 34000, loss: 0.051593
 >> iter 35000, loss: 0.033482
 >> iter 36000, loss: 0.040732
 >> iter 37000, loss: 0.039291
 >> iter 38000, loss: 0.031688
 >> iter 39000, loss: 0.034233
 >> iter 40000, loss: 0.029704
   Number of active neurons: 3
 >> iter 41000, loss: 0.026141
 >> iter 42000, loss: 0.025415
 >> iter 43000, loss: 0.023621
 >> iter 44000, loss: 0.024877
 >> iter 45000, loss: 0.027019
 >> iter 46000, loss: 0.039089
 >> iter 47000, loss: 0.053580
 >> iter 48000, loss: 0.033993
 >> iter 49000, loss: 0.030481
 >> iter 50000, loss: 0.026885
   Number of active neurons: 2
 >> iter 51000, loss: 0.023055
 >> iter 52000, loss: 0.026091
 >> iter 53000, loss: 0.024084
 >> iter 54000, loss: 0.035919
 >> iter 55000, loss: 0.026408
 >> iter 56000, loss: 0.025648
 >> iter 57000, loss: 0.026347
 >> iter 58000, loss: 0.027409
 >> iter 59000, loss: 0.034666
 >> iter 60000, loss: 0.032253
   Number of active neurons: 1
 >> iter 61000, loss: 0.024082
 >> iter 62000, loss: 0.020007
 >> iter 63000, loss: 0.018234
 >> iter 64000, loss: 0.020757
 >> iter 65000, loss: 0.020424
 >> iter 66000, loss: 0.019630
 >> iter 67000, loss: 0.019040
 >> iter 68000, loss: 0.019941
 >> iter 69000, loss: 0.018684
 >> iter 70000, loss: 0.027239
   Number of active neurons: 1
 >> iter 71000, loss: 0.026659
 >> iter 72000, loss: 0.020786
 >> iter 73000, loss: 0.028297
 >> iter 74000, loss: 0.021938
 >> iter 75000, loss: 0.021206
 >> iter 76000, loss: 0.019668
 >> iter 77000, loss: 0.020592
 >> iter 78000, loss: 0.020434
 >> iter 79000, loss: 0.019217
 >> iter 80000, loss: 0.034937
   Number of active neurons: 1
 >> iter 81000, loss: 0.025566
 >> iter 82000, loss: 0.018901
 >> iter 83000, loss: 0.023070
 >> iter 84000, loss: 0.024196
 >> iter 85000, loss: 0.024164
 >> iter 86000, loss: 0.019877
 >> iter 87000, loss: 0.017815
 >> iter 88000, loss: 0.018046
 >> iter 89000, loss: 0.038310
 >> iter 90000, loss: 0.025289
   Number of active neurons: 1
 >> iter 91000, loss: 0.022861
 >> iter 92000, loss: 0.021746
 >> iter 93000, loss: 0.037022
 >> iter 94000, loss: 0.029118
 >> iter 95000, loss: 0.022359
 >> iter 96000, loss: 0.018996
 >> iter 97000, loss: 0.019429
 >> iter 98000, loss: 0.017575
 >> iter 99000, loss: 0.018008
 >> iter 100000, loss: 0.017892
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.028563
 >> iter 2000, loss: 4.122004
 >> iter 3000, loss: 1.550280
 >> iter 4000, loss: 0.599906
 >> iter 5000, loss: 0.248574
 >> iter 6000, loss: 0.122224
 >> iter 7000, loss: 0.071089
 >> iter 8000, loss: 0.062289
 >> iter 9000, loss: 0.047935
 >> iter 10000, loss: 0.055273
   Number of active neurons: 7
 >> iter 11000, loss: 0.040000
 >> iter 12000, loss: 0.050376
 >> iter 13000, loss: 0.043849
 >> iter 14000, loss: 0.034096
 >> iter 15000, loss: 0.031452
 >> iter 16000, loss: 0.035944
 >> iter 17000, loss: 0.046411
 >> iter 18000, loss: 0.039244
 >> iter 19000, loss: 0.036523
 >> iter 20000, loss: 0.037283
   Number of active neurons: 4
 >> iter 21000, loss: 0.032543
 >> iter 22000, loss: 0.033846
 >> iter 23000, loss: 0.029798
 >> iter 24000, loss: 0.027603
 >> iter 25000, loss: 0.027165
 >> iter 26000, loss: 0.031997
 >> iter 27000, loss: 0.026575
 >> iter 28000, loss: 0.024469
 >> iter 29000, loss: 0.022426
 >> iter 30000, loss: 0.037463
   Number of active neurons: 2
 >> iter 31000, loss: 0.029531
 >> iter 32000, loss: 0.023881
 >> iter 33000, loss: 0.023447
 >> iter 34000, loss: 0.020616
 >> iter 35000, loss: 0.031668
 >> iter 36000, loss: 0.025172
 >> iter 37000, loss: 0.021920
 >> iter 38000, loss: 0.019387
 >> iter 39000, loss: 0.017782
 >> iter 40000, loss: 0.017602
   Number of active neurons: 1
 >> iter 41000, loss: 0.021105
 >> iter 42000, loss: 0.020384
 >> iter 43000, loss: 0.021548
 >> iter 44000, loss: 0.020364
 >> iter 45000, loss: 0.019782
 >> iter 46000, loss: 0.035118
 >> iter 47000, loss: 0.029552
 >> iter 48000, loss: 0.028149
 >> iter 49000, loss: 0.021222
 >> iter 50000, loss: 0.020222
   Number of active neurons: 1
 >> iter 51000, loss: 0.018698
 >> iter 52000, loss: 0.022018
 >> iter 53000, loss: 0.018934
 >> iter 54000, loss: 0.019292
 >> iter 55000, loss: 0.018243
 >> iter 56000, loss: 0.019049
 >> iter 57000, loss: 0.018381
 >> iter 58000, loss: 0.018804
 >> iter 59000, loss: 0.030684
 >> iter 60000, loss: 0.020993
   Number of active neurons: 1
 >> iter 61000, loss: 0.018523
 >> iter 62000, loss: 0.017503
 >> iter 63000, loss: 0.017952
 >> iter 64000, loss: 0.016404
 >> iter 65000, loss: 0.018611
 >> iter 66000, loss: 0.016224
 >> iter 67000, loss: 0.017349
 >> iter 68000, loss: 0.018364
 >> iter 69000, loss: 0.016360
 >> iter 70000, loss: 0.026637
   Number of active neurons: 1
 >> iter 71000, loss: 0.020278
 >> iter 72000, loss: 0.020151
 >> iter 73000, loss: 0.016995
 >> iter 74000, loss: 0.015706
 >> iter 75000, loss: 0.016969
 >> iter 76000, loss: 0.021242
 >> iter 77000, loss: 0.017500
 >> iter 78000, loss: 0.016795
 >> iter 79000, loss: 0.021209
 >> iter 80000, loss: 0.017831
   Number of active neurons: 1
 >> iter 81000, loss: 0.019535
 >> iter 82000, loss: 0.017498
 >> iter 83000, loss: 0.016945
 >> iter 84000, loss: 0.018532
 >> iter 85000, loss: 0.023996
 >> iter 86000, loss: 0.021923
 >> iter 87000, loss: 0.019285
 >> iter 88000, loss: 0.039010
 >> iter 89000, loss: 0.044402
 >> iter 90000, loss: 0.028631
   Number of active neurons: 1
 >> iter 91000, loss: 0.042519
 >> iter 92000, loss: 0.027954
 >> iter 93000, loss: 0.021860
 >> iter 94000, loss: 0.021231
 >> iter 95000, loss: 0.019870
 >> iter 96000, loss: 0.020226
 >> iter 97000, loss: 0.016750
 >> iter 98000, loss: 0.017103
 >> iter 99000, loss: 0.032744
 >> iter 100000, loss: 0.025517
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.969708
 >> iter 2000, loss: 4.076911
 >> iter 3000, loss: 1.551517
 >> iter 4000, loss: 0.600629
 >> iter 5000, loss: 0.245459
 >> iter 6000, loss: 0.115120
 >> iter 7000, loss: 0.064014
 >> iter 8000, loss: 0.047402
 >> iter 9000, loss: 0.037461
 >> iter 10000, loss: 0.032347
   Number of active neurons: 4
 >> iter 11000, loss: 0.028746
 >> iter 12000, loss: 0.035681
 >> iter 13000, loss: 0.042741
 >> iter 14000, loss: 0.035975
 >> iter 15000, loss: 0.033894
 >> iter 16000, loss: 0.030338
 >> iter 17000, loss: 0.028096
 >> iter 18000, loss: 0.028629
 >> iter 19000, loss: 0.028834
 >> iter 20000, loss: 0.025784
   Number of active neurons: 2
 >> iter 21000, loss: 0.027134
 >> iter 22000, loss: 0.028737
 >> iter 23000, loss: 0.024773
 >> iter 24000, loss: 0.026339
 >> iter 25000, loss: 0.023200
 >> iter 26000, loss: 0.024185
 >> iter 27000, loss: 0.031876
 >> iter 28000, loss: 0.025370
 >> iter 29000, loss: 0.023366
 >> iter 30000, loss: 0.021562
   Number of active neurons: 2
 >> iter 31000, loss: 0.021547
 >> iter 32000, loss: 0.026500
 >> iter 33000, loss: 0.024607
 >> iter 34000, loss: 0.020543
 >> iter 35000, loss: 0.020762
 >> iter 36000, loss: 0.021700
 >> iter 37000, loss: 0.022268
 >> iter 38000, loss: 0.023969
 >> iter 39000, loss: 0.023562
 >> iter 40000, loss: 0.024966
   Number of active neurons: 2
 >> iter 41000, loss: 0.021143
 >> iter 42000, loss: 0.019828
 >> iter 43000, loss: 0.026639
 >> iter 44000, loss: 0.023807
 >> iter 45000, loss: 0.043947
 >> iter 46000, loss: 0.027390
 >> iter 47000, loss: 0.021911
 >> iter 48000, loss: 0.028350
 >> iter 49000, loss: 0.023416
 >> iter 50000, loss: 0.020743
   Number of active neurons: 1
 >> iter 51000, loss: 0.019644
 >> iter 52000, loss: 0.018804
 >> iter 53000, loss: 0.022528
 >> iter 54000, loss: 0.024141
 >> iter 55000, loss: 0.019321
 >> iter 56000, loss: 0.022745
 >> iter 57000, loss: 0.021198
 >> iter 58000, loss: 0.020735
 >> iter 59000, loss: 0.018475
 >> iter 60000, loss: 0.019033
   Number of active neurons: 1
 >> iter 61000, loss: 0.017517
 >> iter 62000, loss: 0.026409
 >> iter 63000, loss: 0.019410
 >> iter 64000, loss: 0.017500
 >> iter 65000, loss: 0.022906
 >> iter 66000, loss: 0.019155
 >> iter 67000, loss: 0.017771
 >> iter 68000, loss: 0.032950
 >> iter 69000, loss: 0.027897
 >> iter 70000, loss: 0.023329
   Number of active neurons: 1
 >> iter 71000, loss: 0.021020
 >> iter 72000, loss: 0.018297
 >> iter 73000, loss: 0.018619
 >> iter 74000, loss: 0.018435
 >> iter 75000, loss: 0.021517
 >> iter 76000, loss: 0.026752
 >> iter 77000, loss: 0.024370
 >> iter 78000, loss: 0.020470
 >> iter 79000, loss: 0.017202
 >> iter 80000, loss: 0.018136
   Number of active neurons: 1
 >> iter 81000, loss: 0.016695
 >> iter 82000, loss: 0.031223
 >> iter 83000, loss: 0.023760
 >> iter 84000, loss: 0.023595
 >> iter 85000, loss: 0.020599
 >> iter 86000, loss: 0.024062
 >> iter 87000, loss: 0.019726
 >> iter 88000, loss: 0.018293
 >> iter 89000, loss: 0.020202
 >> iter 90000, loss: 0.019324
   Number of active neurons: 1
 >> iter 91000, loss: 0.016924
 >> iter 92000, loss: 0.017972
 >> iter 93000, loss: 0.018212
 >> iter 94000, loss: 0.023191
 >> iter 95000, loss: 0.018139
 >> iter 96000, loss: 0.021404
 >> iter 97000, loss: 0.018863
 >> iter 98000, loss: 0.023252
 >> iter 99000, loss: 0.021110
 >> iter 100000, loss: 0.022004
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.007244
 >> iter 2000, loss: 4.109174
 >> iter 3000, loss: 1.541496
 >> iter 4000, loss: 0.591654
 >> iter 5000, loss: 0.248467
 >> iter 6000, loss: 0.110779
 >> iter 7000, loss: 0.071226
 >> iter 8000, loss: 0.045251
 >> iter 9000, loss: 0.034867
 >> iter 10000, loss: 0.032796
   Number of active neurons: 4
 >> iter 11000, loss: 0.057859
 >> iter 12000, loss: 0.040793
 >> iter 13000, loss: 0.035621
 >> iter 14000, loss: 0.031282
 >> iter 15000, loss: 0.027494
 >> iter 16000, loss: 0.040563
 >> iter 17000, loss: 0.039570
 >> iter 18000, loss: 0.029213
 >> iter 19000, loss: 0.026086
 >> iter 20000, loss: 0.023633
   Number of active neurons: 3
 >> iter 21000, loss: 0.023659
 >> iter 22000, loss: 0.026318
 >> iter 23000, loss: 0.029996
 >> iter 24000, loss: 0.034691
 >> iter 25000, loss: 0.027966
 >> iter 26000, loss: 0.026716
 >> iter 27000, loss: 0.031980
 >> iter 28000, loss: 0.028005
 >> iter 29000, loss: 0.031791
 >> iter 30000, loss: 0.028119
   Number of active neurons: 3
 >> iter 31000, loss: 0.050897
 >> iter 32000, loss: 0.038915
 >> iter 33000, loss: 0.049843
 >> iter 34000, loss: 0.033248
 >> iter 35000, loss: 0.037149
 >> iter 36000, loss: 0.033232
 >> iter 37000, loss: 0.039715
 >> iter 38000, loss: 0.031145
 >> iter 39000, loss: 0.033198
 >> iter 40000, loss: 0.028488
   Number of active neurons: 2
 >> iter 41000, loss: 0.025628
 >> iter 42000, loss: 0.022826
 >> iter 43000, loss: 0.028207
 >> iter 44000, loss: 0.023458
 >> iter 45000, loss: 0.026794
 >> iter 46000, loss: 0.021239
 >> iter 47000, loss: 0.021313
 >> iter 48000, loss: 0.023811
 >> iter 49000, loss: 0.025232
 >> iter 50000, loss: 0.024161
   Number of active neurons: 2
 >> iter 51000, loss: 0.021677
 >> iter 52000, loss: 0.021669
 >> iter 53000, loss: 0.037652
 >> iter 54000, loss: 0.027703
 >> iter 55000, loss: 0.027321
 >> iter 56000, loss: 0.025772
 >> iter 57000, loss: 0.022189
 >> iter 58000, loss: 0.031169
 >> iter 59000, loss: 0.024051
 >> iter 60000, loss: 0.020757
   Number of active neurons: 1
 >> iter 61000, loss: 0.020506
 >> iter 62000, loss: 0.021329
 >> iter 63000, loss: 0.021601
 >> iter 64000, loss: 0.024060
 >> iter 65000, loss: 0.029841
 >> iter 66000, loss: 0.065903
 >> iter 67000, loss: 0.039520
 >> iter 68000, loss: 0.024473
 >> iter 69000, loss: 0.021359
 >> iter 70000, loss: 0.018316
   Number of active neurons: 1
 >> iter 71000, loss: 0.021024
 >> iter 72000, loss: 0.034118
 >> iter 73000, loss: 0.027516
 >> iter 74000, loss: 0.019940
 >> iter 75000, loss: 0.018623
 >> iter 76000, loss: 0.026642
 >> iter 77000, loss: 0.020253
 >> iter 78000, loss: 0.046909
 >> iter 79000, loss: 0.027629
 >> iter 80000, loss: 0.020684
   Number of active neurons: 1
 >> iter 81000, loss: 0.019281
 >> iter 82000, loss: 0.017560
 >> iter 83000, loss: 0.027472
 >> iter 84000, loss: 0.037516
 >> iter 85000, loss: 0.029790
 >> iter 86000, loss: 0.027466
 >> iter 87000, loss: 0.020159
 >> iter 88000, loss: 0.024134
 >> iter 89000, loss: 0.018732
 >> iter 90000, loss: 0.016289
   Number of active neurons: 1
 >> iter 91000, loss: 0.016840
 >> iter 92000, loss: 0.015840
 >> iter 93000, loss: 0.023778
 >> iter 94000, loss: 0.021084
 >> iter 95000, loss: 0.018867
 >> iter 96000, loss: 0.021205
 >> iter 97000, loss: 0.017662
 >> iter 98000, loss: 0.025991
 >> iter 99000, loss: 0.021024
 >> iter 100000, loss: 0.021367
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.937075
 >> iter 2000, loss: 4.080149
 >> iter 3000, loss: 1.525604
 >> iter 4000, loss: 0.595478
 >> iter 5000, loss: 0.252558
 >> iter 6000, loss: 0.116920
 >> iter 7000, loss: 0.068224
 >> iter 8000, loss: 0.044398
 >> iter 9000, loss: 0.036618
 >> iter 10000, loss: 0.033891
   Number of active neurons: 5
 >> iter 11000, loss: 0.041802
 >> iter 12000, loss: 0.032459
 >> iter 13000, loss: 0.032821
 >> iter 14000, loss: 0.029183
 >> iter 15000, loss: 0.027765
 >> iter 16000, loss: 0.033260
 >> iter 17000, loss: 0.038085
 >> iter 18000, loss: 0.035525
 >> iter 19000, loss: 0.029734
 >> iter 20000, loss: 0.031718
   Number of active neurons: 4
 >> iter 21000, loss: 0.029250
 >> iter 22000, loss: 0.035043
 >> iter 23000, loss: 0.031092
 >> iter 24000, loss: 0.041333
 >> iter 25000, loss: 0.030617
 >> iter 26000, loss: 0.030001
 >> iter 27000, loss: 0.024908
 >> iter 28000, loss: 0.028044
 >> iter 29000, loss: 0.026301
 >> iter 30000, loss: 0.026200
   Number of active neurons: 3
 >> iter 31000, loss: 0.023942
 >> iter 32000, loss: 0.024628
 >> iter 33000, loss: 0.023518
 >> iter 34000, loss: 0.042552
 >> iter 35000, loss: 0.029254
 >> iter 36000, loss: 0.045966
 >> iter 37000, loss: 0.034406
 >> iter 38000, loss: 0.030333
 >> iter 39000, loss: 0.025456
 >> iter 40000, loss: 0.023742
   Number of active neurons: 2
 >> iter 41000, loss: 0.022145
 >> iter 42000, loss: 0.029781
 >> iter 43000, loss: 0.027199
 >> iter 44000, loss: 0.024096
 >> iter 45000, loss: 0.028870
 >> iter 46000, loss: 0.025102
 >> iter 47000, loss: 0.037895
 >> iter 48000, loss: 0.028409
 >> iter 49000, loss: 0.028850
 >> iter 50000, loss: 0.026589
   Number of active neurons: 2
 >> iter 51000, loss: 0.023147
 >> iter 52000, loss: 0.020135
 >> iter 53000, loss: 0.024794
 >> iter 54000, loss: 0.024655
 >> iter 55000, loss: 0.022598
 >> iter 56000, loss: 0.021592
 >> iter 57000, loss: 0.022577
 >> iter 58000, loss: 0.023133
 >> iter 59000, loss: 0.020620
 >> iter 60000, loss: 0.037832
   Number of active neurons: 2
 >> iter 61000, loss: 0.030139
 >> iter 62000, loss: 0.023434
 >> iter 63000, loss: 0.020970
 >> iter 64000, loss: 0.019665
 >> iter 65000, loss: 0.020465
 >> iter 66000, loss: 0.024544
 >> iter 67000, loss: 0.038681
 >> iter 68000, loss: 0.032646
 >> iter 69000, loss: 0.026189
 >> iter 70000, loss: 0.026716
   Number of active neurons: 2
 >> iter 71000, loss: 0.022788
 >> iter 72000, loss: 0.020862
 >> iter 73000, loss: 0.021041
 >> iter 74000, loss: 0.020320
 >> iter 75000, loss: 0.021369
 >> iter 76000, loss: 0.020024
 >> iter 77000, loss: 0.019303
 >> iter 78000, loss: 0.020795
 >> iter 79000, loss: 0.023642
 >> iter 80000, loss: 0.028511
   Number of active neurons: 1
 >> iter 81000, loss: 0.030319
 >> iter 82000, loss: 0.034303
 >> iter 83000, loss: 0.023668
 >> iter 84000, loss: 0.025509
 >> iter 85000, loss: 0.025953
 >> iter 86000, loss: 0.054118
 >> iter 87000, loss: 0.047985
 >> iter 88000, loss: 0.030007
 >> iter 89000, loss: 0.022678
 >> iter 90000, loss: 0.021505
   Number of active neurons: 1
 >> iter 91000, loss: 0.018841
 >> iter 92000, loss: 0.018541
 >> iter 93000, loss: 0.026368
 >> iter 94000, loss: 0.021177
 >> iter 95000, loss: 0.018859
 >> iter 96000, loss: 0.020993
 >> iter 97000, loss: 0.019393
 >> iter 98000, loss: 0.017431
 >> iter 99000, loss: 0.023217
 >> iter 100000, loss: 0.029778
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.941605
 >> iter 2000, loss: 4.091005
 >> iter 3000, loss: 1.538159
 >> iter 4000, loss: 0.588253
 >> iter 5000, loss: 0.240544
 >> iter 6000, loss: 0.110810
 >> iter 7000, loss: 0.062546
 >> iter 8000, loss: 0.050137
 >> iter 9000, loss: 0.048992
 >> iter 10000, loss: 0.044804
   Number of active neurons: 4
 >> iter 11000, loss: 0.033323
 >> iter 12000, loss: 0.030919
 >> iter 13000, loss: 0.041643
 >> iter 14000, loss: 0.033335
 >> iter 15000, loss: 0.038658
 >> iter 16000, loss: 0.031479
 >> iter 17000, loss: 0.033953
 >> iter 18000, loss: 0.029512
 >> iter 19000, loss: 0.026954
 >> iter 20000, loss: 0.054316
   Number of active neurons: 3
 >> iter 21000, loss: 0.040191
 >> iter 22000, loss: 0.042559
 >> iter 23000, loss: 0.039059
 >> iter 24000, loss: 0.029441
 >> iter 25000, loss: 0.025655
 >> iter 26000, loss: 0.034070
 >> iter 27000, loss: 0.029533
 >> iter 28000, loss: 0.028014
 >> iter 29000, loss: 0.026152
 >> iter 30000, loss: 0.024073
   Number of active neurons: 3
 >> iter 31000, loss: 0.023373
 >> iter 32000, loss: 0.027890
 >> iter 33000, loss: 0.029869
 >> iter 34000, loss: 0.025255
 >> iter 35000, loss: 0.023760
 >> iter 36000, loss: 0.025175
 >> iter 37000, loss: 0.022979
 >> iter 38000, loss: 0.024372
 >> iter 39000, loss: 0.025648
 >> iter 40000, loss: 0.027452
   Number of active neurons: 2
 >> iter 41000, loss: 0.022357
 >> iter 42000, loss: 0.020356
 >> iter 43000, loss: 0.020541
 >> iter 44000, loss: 0.018976
 >> iter 45000, loss: 0.019131
 >> iter 46000, loss: 0.027993
 >> iter 47000, loss: 0.025827
 >> iter 48000, loss: 0.021236
 >> iter 49000, loss: 0.019129
 >> iter 50000, loss: 0.027784
   Number of active neurons: 1
 >> iter 51000, loss: 0.031006
 >> iter 52000, loss: 0.023613
 >> iter 53000, loss: 0.021118
 >> iter 54000, loss: 0.019707
 >> iter 55000, loss: 0.022489
 >> iter 56000, loss: 0.020444
 >> iter 57000, loss: 0.019944
 >> iter 58000, loss: 0.030927
 >> iter 59000, loss: 0.022815
 >> iter 60000, loss: 0.020381
   Number of active neurons: 1
 >> iter 61000, loss: 0.017161
 >> iter 62000, loss: 0.018337
 >> iter 63000, loss: 0.016472
 >> iter 64000, loss: 0.021958
 >> iter 65000, loss: 0.021623
 >> iter 66000, loss: 0.022050
 >> iter 67000, loss: 0.025138
 >> iter 68000, loss: 0.019226
 >> iter 69000, loss: 0.017003
 >> iter 70000, loss: 0.019350
   Number of active neurons: 1
 >> iter 71000, loss: 0.018683
 >> iter 72000, loss: 0.016243
 >> iter 73000, loss: 0.024934
 >> iter 74000, loss: 0.020538
 >> iter 75000, loss: 0.019238
 >> iter 76000, loss: 0.020258
 >> iter 77000, loss: 0.018775
 >> iter 78000, loss: 0.026346
 >> iter 79000, loss: 0.020501
 >> iter 80000, loss: 0.018649
   Number of active neurons: 1
 >> iter 81000, loss: 0.016939
 >> iter 82000, loss: 0.035607
 >> iter 83000, loss: 0.023750
 >> iter 84000, loss: 0.020003
 >> iter 85000, loss: 0.021404
 >> iter 86000, loss: 0.018910
 >> iter 87000, loss: 0.022368
 >> iter 88000, loss: 0.018624
 >> iter 89000, loss: 0.016029
 >> iter 90000, loss: 0.018966
   Number of active neurons: 1
 >> iter 91000, loss: 0.026051
 >> iter 92000, loss: 0.019687
 >> iter 93000, loss: 0.016922
 >> iter 94000, loss: 0.016205
 >> iter 95000, loss: 0.018197
 >> iter 96000, loss: 0.016699
 >> iter 97000, loss: 0.030675
 >> iter 98000, loss: 0.034408
 >> iter 99000, loss: 0.023688
 >> iter 100000, loss: 0.019910
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.991489
 >> iter 2000, loss: 4.104477
 >> iter 3000, loss: 1.552367
 >> iter 4000, loss: 0.603855
 >> iter 5000, loss: 0.252739
 >> iter 6000, loss: 0.115469
 >> iter 7000, loss: 0.074214
 >> iter 8000, loss: 0.049082
 >> iter 9000, loss: 0.040810
 >> iter 10000, loss: 0.037515
   Number of active neurons: 7
 >> iter 11000, loss: 0.038764
 >> iter 12000, loss: 0.036296
 >> iter 13000, loss: 0.033494
 >> iter 14000, loss: 0.031305
 >> iter 15000, loss: 0.046347
 >> iter 16000, loss: 0.056447
 >> iter 17000, loss: 0.040141
 >> iter 18000, loss: 0.033629
 >> iter 19000, loss: 0.031913
 >> iter 20000, loss: 0.038326
   Number of active neurons: 3
 >> iter 21000, loss: 0.030535
 >> iter 22000, loss: 0.036558
 >> iter 23000, loss: 0.034900
 >> iter 24000, loss: 0.033823
 >> iter 25000, loss: 0.030899
 >> iter 26000, loss: 0.027180
 >> iter 27000, loss: 0.036030
 >> iter 28000, loss: 0.027299
 >> iter 29000, loss: 0.025226
 >> iter 30000, loss: 0.022989
   Number of active neurons: 2
 >> iter 31000, loss: 0.025580
 >> iter 32000, loss: 0.022177
 >> iter 33000, loss: 0.028699
 >> iter 34000, loss: 0.024083
 >> iter 35000, loss: 0.049138
 >> iter 36000, loss: 0.028836
 >> iter 37000, loss: 0.024253
 >> iter 38000, loss: 0.045983
 >> iter 39000, loss: 0.030183
 >> iter 40000, loss: 0.023195
   Number of active neurons: 1
 >> iter 41000, loss: 0.021927
 >> iter 42000, loss: 0.025327
 >> iter 43000, loss: 0.029826
 >> iter 44000, loss: 0.022262
 >> iter 45000, loss: 0.020120
 >> iter 46000, loss: 0.020458
 >> iter 47000, loss: 0.019906
 >> iter 48000, loss: 0.019019
 >> iter 49000, loss: 0.016639
 >> iter 50000, loss: 0.026182
   Number of active neurons: 1
 >> iter 51000, loss: 0.041680
 >> iter 52000, loss: 0.031591
 >> iter 53000, loss: 0.022358
 >> iter 54000, loss: 0.017986
 >> iter 55000, loss: 0.019893
 >> iter 56000, loss: 0.018832
 >> iter 57000, loss: 0.016763
 >> iter 58000, loss: 0.016879
 >> iter 59000, loss: 0.016240
 >> iter 60000, loss: 0.024811
   Number of active neurons: 1
 >> iter 61000, loss: 0.035811
 >> iter 62000, loss: 0.025139
 >> iter 63000, loss: 0.032012
 >> iter 64000, loss: 0.021429
 >> iter 65000, loss: 0.021332
 >> iter 66000, loss: 0.026345
 >> iter 67000, loss: 0.022563
 >> iter 68000, loss: 0.019916
 >> iter 69000, loss: 0.041220
 >> iter 70000, loss: 0.029439
   Number of active neurons: 1
 >> iter 71000, loss: 0.021655
 >> iter 72000, loss: 0.034276
 >> iter 73000, loss: 0.022831
 >> iter 74000, loss: 0.023231
 >> iter 75000, loss: 0.020266
 >> iter 76000, loss: 0.019264
 >> iter 77000, loss: 0.027957
 >> iter 78000, loss: 0.021062
 >> iter 79000, loss: 0.018614
 >> iter 80000, loss: 0.017962
   Number of active neurons: 1
 >> iter 81000, loss: 0.026038
 >> iter 82000, loss: 0.033216
 >> iter 83000, loss: 0.027669
 >> iter 84000, loss: 0.023267
 >> iter 85000, loss: 0.021864
 >> iter 86000, loss: 0.017745
 >> iter 87000, loss: 0.022378
 >> iter 88000, loss: 0.021871
 >> iter 89000, loss: 0.020389
 >> iter 90000, loss: 0.019575
   Number of active neurons: 1
 >> iter 91000, loss: 0.017397
 >> iter 92000, loss: 0.023364
 >> iter 93000, loss: 0.018264
 >> iter 94000, loss: 0.018310
 >> iter 95000, loss: 0.019497
 >> iter 96000, loss: 0.019130
 >> iter 97000, loss: 0.018015
 >> iter 98000, loss: 0.019044
 >> iter 99000, loss: 0.021592
 >> iter 100000, loss: 0.022108
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.932748
 >> iter 2000, loss: 4.058071
 >> iter 3000, loss: 1.529903
 >> iter 4000, loss: 0.588924
 >> iter 5000, loss: 0.243336
 >> iter 6000, loss: 0.107165
 >> iter 7000, loss: 0.065358
 >> iter 8000, loss: 0.044459
 >> iter 9000, loss: 0.035982
 >> iter 10000, loss: 0.036704
   Number of active neurons: 3
 >> iter 11000, loss: 0.037232
 >> iter 12000, loss: 0.030883
 >> iter 13000, loss: 0.027372
 >> iter 14000, loss: 0.027731
 >> iter 15000, loss: 0.025471
 >> iter 16000, loss: 0.024732
 >> iter 17000, loss: 0.042173
 >> iter 18000, loss: 0.033290
 >> iter 19000, loss: 0.027698
 >> iter 20000, loss: 0.026403
   Number of active neurons: 3
 >> iter 21000, loss: 0.029776
 >> iter 22000, loss: 0.025784
 >> iter 23000, loss: 0.025686
 >> iter 24000, loss: 0.033861
 >> iter 25000, loss: 0.027422
 >> iter 26000, loss: 0.026287
 >> iter 27000, loss: 0.024763
 >> iter 28000, loss: 0.027010
 >> iter 29000, loss: 0.027694
 >> iter 30000, loss: 0.031426
   Number of active neurons: 3
 >> iter 31000, loss: 0.025680
 >> iter 32000, loss: 0.031996
 >> iter 33000, loss: 0.031624
 >> iter 34000, loss: 0.025202
 >> iter 35000, loss: 0.028299
 >> iter 36000, loss: 0.026366
 >> iter 37000, loss: 0.026707
 >> iter 38000, loss: 0.025200
 >> iter 39000, loss: 0.041337
 >> iter 40000, loss: 0.030581
   Number of active neurons: 2
 >> iter 41000, loss: 0.023667
 >> iter 42000, loss: 0.024158
 >> iter 43000, loss: 0.024867
 >> iter 44000, loss: 0.024151
 >> iter 45000, loss: 0.022647
 >> iter 46000, loss: 0.021224
 >> iter 47000, loss: 0.020960
 >> iter 48000, loss: 0.024068
 >> iter 49000, loss: 0.023164
 >> iter 50000, loss: 0.023645
   Number of active neurons: 2
 >> iter 51000, loss: 0.021101
 >> iter 52000, loss: 0.023249
 >> iter 53000, loss: 0.021529
 >> iter 54000, loss: 0.050849
 >> iter 55000, loss: 0.037155
 >> iter 56000, loss: 0.027001
 >> iter 57000, loss: 0.025051
 >> iter 58000, loss: 0.023279
 >> iter 59000, loss: 0.020671
 >> iter 60000, loss: 0.051615
   Number of active neurons: 2
 >> iter 61000, loss: 0.032076
 >> iter 62000, loss: 0.025890
 >> iter 63000, loss: 0.030810
 >> iter 64000, loss: 0.024208
 >> iter 65000, loss: 0.022649
 >> iter 66000, loss: 0.021652
 >> iter 67000, loss: 0.062761
 >> iter 68000, loss: 0.036353
 >> iter 69000, loss: 0.031009
 >> iter 70000, loss: 0.024379
   Number of active neurons: 2
 >> iter 71000, loss: 0.023443
 >> iter 72000, loss: 0.021968
 >> iter 73000, loss: 0.023661
 >> iter 74000, loss: 0.026281
 >> iter 75000, loss: 0.035749
 >> iter 76000, loss: 0.041672
 >> iter 77000, loss: 0.031018
 >> iter 78000, loss: 0.026918
 >> iter 79000, loss: 0.024563
 >> iter 80000, loss: 0.022935
   Number of active neurons: 2
 >> iter 81000, loss: 0.022241
 >> iter 82000, loss: 0.021567
 >> iter 83000, loss: 0.050490
 >> iter 84000, loss: 0.040144
 >> iter 85000, loss: 0.030454
 >> iter 86000, loss: 0.066372
 >> iter 87000, loss: 0.053213
 >> iter 88000, loss: 0.034210
 >> iter 89000, loss: 0.027067
 >> iter 90000, loss: 0.032698
   Number of active neurons: 2
 >> iter 91000, loss: 0.026149
 >> iter 92000, loss: 0.028975
 >> iter 93000, loss: 0.024158
 >> iter 94000, loss: 0.042109
 >> iter 95000, loss: 0.029420
 >> iter 96000, loss: 0.022947
 >> iter 97000, loss: 0.023380
 >> iter 98000, loss: 0.022776
 >> iter 99000, loss: 0.028758
 >> iter 100000, loss: 0.035971
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.932809
 >> iter 2000, loss: 4.078119
 >> iter 3000, loss: 1.542837
 >> iter 4000, loss: 0.622590
 >> iter 5000, loss: 0.263775
 >> iter 6000, loss: 0.118175
 >> iter 7000, loss: 0.064144
 >> iter 8000, loss: 0.043603
 >> iter 9000, loss: 0.037583
 >> iter 10000, loss: 0.042866
   Number of active neurons: 6
 >> iter 11000, loss: 0.037580
 >> iter 12000, loss: 0.032585
 >> iter 13000, loss: 0.035056
 >> iter 14000, loss: 0.029822
 >> iter 15000, loss: 0.029346
 >> iter 16000, loss: 0.029691
 >> iter 17000, loss: 0.030529
 >> iter 18000, loss: 0.030987
 >> iter 19000, loss: 0.029374
 >> iter 20000, loss: 0.033278
   Number of active neurons: 5
 >> iter 21000, loss: 0.031785
 >> iter 22000, loss: 0.027117
 >> iter 23000, loss: 0.028150
 >> iter 24000, loss: 0.029517
 >> iter 25000, loss: 0.032122
 >> iter 26000, loss: 0.028208
 >> iter 27000, loss: 0.028436
 >> iter 28000, loss: 0.027045
 >> iter 29000, loss: 0.030812
 >> iter 30000, loss: 0.027562
   Number of active neurons: 3
 >> iter 31000, loss: 0.027208
 >> iter 32000, loss: 0.027347
 >> iter 33000, loss: 0.025124
 >> iter 34000, loss: 0.026209
 >> iter 35000, loss: 0.024551
 >> iter 36000, loss: 0.023017
 >> iter 37000, loss: 0.027365
 >> iter 38000, loss: 0.028844
 >> iter 39000, loss: 0.024767
 >> iter 40000, loss: 0.023177
   Number of active neurons: 3
 >> iter 41000, loss: 0.021764
 >> iter 42000, loss: 0.023358
 >> iter 43000, loss: 0.022789
 >> iter 44000, loss: 0.022977
 >> iter 45000, loss: 0.022164
 >> iter 46000, loss: 0.020626
 >> iter 47000, loss: 0.020308
 >> iter 48000, loss: 0.020552
 >> iter 49000, loss: 0.048308
 >> iter 50000, loss: 0.031606
   Number of active neurons: 2
 >> iter 51000, loss: 0.026219
 >> iter 52000, loss: 0.024391
 >> iter 53000, loss: 0.030982
 >> iter 54000, loss: 0.025583
 >> iter 55000, loss: 0.023671
 >> iter 56000, loss: 0.027203
 >> iter 57000, loss: 0.024324
 >> iter 58000, loss: 0.039896
 >> iter 59000, loss: 0.027960
 >> iter 60000, loss: 0.024919
   Number of active neurons: 2
 >> iter 61000, loss: 0.020864
 >> iter 62000, loss: 0.026206
 >> iter 63000, loss: 0.027171
 >> iter 64000, loss: 0.023567
 >> iter 65000, loss: 0.024448
 >> iter 66000, loss: 0.021458
 >> iter 67000, loss: 0.026034
 >> iter 68000, loss: 0.046997
 >> iter 69000, loss: 0.031386
 >> iter 70000, loss: 0.024855
   Number of active neurons: 2
 >> iter 71000, loss: 0.023674
 >> iter 72000, loss: 0.021616
 >> iter 73000, loss: 0.021485
 >> iter 74000, loss: 0.020442
 >> iter 75000, loss: 0.020410
 >> iter 76000, loss: 0.024198
 >> iter 77000, loss: 0.022409
 >> iter 78000, loss: 0.024102
 >> iter 79000, loss: 0.035513
 >> iter 80000, loss: 0.027920
   Number of active neurons: 2
 >> iter 81000, loss: 0.025590
 >> iter 82000, loss: 0.023656
 >> iter 83000, loss: 0.023408
 >> iter 84000, loss: 0.021344
 >> iter 85000, loss: 0.024331
 >> iter 86000, loss: 0.034081
 >> iter 87000, loss: 0.027164
 >> iter 88000, loss: 0.022831
 >> iter 89000, loss: 0.032488
 >> iter 90000, loss: 0.028987
   Number of active neurons: 2
 >> iter 91000, loss: 0.023472
 >> iter 92000, loss: 0.023403
 >> iter 93000, loss: 0.022559
 >> iter 94000, loss: 0.028012
 >> iter 95000, loss: 0.026386
 >> iter 96000, loss: 0.036009
 >> iter 97000, loss: 0.026892
 >> iter 98000, loss: 0.047420
 >> iter 99000, loss: 0.040727
 >> iter 100000, loss: 0.041008
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 10.977557
 >> iter 2000, loss: 4.134837
 >> iter 3000, loss: 1.561059
 >> iter 4000, loss: 0.601506
 >> iter 5000, loss: 0.247872
 >> iter 6000, loss: 0.118608
 >> iter 7000, loss: 0.082227
 >> iter 8000, loss: 0.068022
 >> iter 9000, loss: 0.046082
 >> iter 10000, loss: 0.039713
   Number of active neurons: 6
 >> iter 11000, loss: 0.036734
 >> iter 12000, loss: 0.032825
 >> iter 13000, loss: 0.031126
 >> iter 14000, loss: 0.032667
 >> iter 15000, loss: 0.032475
 >> iter 16000, loss: 0.027505
 >> iter 17000, loss: 0.027068
 >> iter 18000, loss: 0.040187
 >> iter 19000, loss: 0.033056
 >> iter 20000, loss: 0.026637
   Number of active neurons: 3
 >> iter 21000, loss: 0.025697
 >> iter 22000, loss: 0.061067
 >> iter 23000, loss: 0.061171
 >> iter 24000, loss: 0.046173
 >> iter 25000, loss: 0.035404
 >> iter 26000, loss: 0.032378
 >> iter 27000, loss: 0.032158
 >> iter 28000, loss: 0.028237
 >> iter 29000, loss: 0.024619
 >> iter 30000, loss: 0.024191
   Number of active neurons: 2
 >> iter 31000, loss: 0.023877
 >> iter 32000, loss: 0.023790
 >> iter 33000, loss: 0.029008
 >> iter 34000, loss: 0.024803
 >> iter 35000, loss: 0.022465
 >> iter 36000, loss: 0.022245
 >> iter 37000, loss: 0.027811
 >> iter 38000, loss: 0.026906
 >> iter 39000, loss: 0.023345
 >> iter 40000, loss: 0.022506
   Number of active neurons: 2
 >> iter 41000, loss: 0.020970
 >> iter 42000, loss: 0.021153
 >> iter 43000, loss: 0.020719
 >> iter 44000, loss: 0.021966
 >> iter 45000, loss: 0.019911
 >> iter 46000, loss: 0.030773
 >> iter 47000, loss: 0.023200
 >> iter 48000, loss: 0.031543
 >> iter 49000, loss: 0.034741
 >> iter 50000, loss: 0.030262
   Number of active neurons: 1
 >> iter 51000, loss: 0.023231
 >> iter 52000, loss: 0.020763
 >> iter 53000, loss: 0.018783
 >> iter 54000, loss: 0.034295
 >> iter 55000, loss: 0.028679
 >> iter 56000, loss: 0.050911
 >> iter 57000, loss: 0.029802
 >> iter 58000, loss: 0.024996
 >> iter 59000, loss: 0.020968
 >> iter 60000, loss: 0.018594
   Number of active neurons: 1
 >> iter 61000, loss: 0.020436
 >> iter 62000, loss: 0.017131
 >> iter 63000, loss: 0.020791
 >> iter 64000, loss: 0.020139
 >> iter 65000, loss: 0.018379
 >> iter 66000, loss: 0.018860
 >> iter 67000, loss: 0.051546
 >> iter 68000, loss: 0.046410
 >> iter 69000, loss: 0.028522
 >> iter 70000, loss: 0.021322
   Number of active neurons: 1
 >> iter 71000, loss: 0.029008
 >> iter 72000, loss: 0.033045
 >> iter 73000, loss: 0.023730
 >> iter 74000, loss: 0.018895
 >> iter 75000, loss: 0.016914
 >> iter 76000, loss: 0.017676
 >> iter 77000, loss: 0.016434
 >> iter 78000, loss: 0.016827
 >> iter 79000, loss: 0.025647
 >> iter 80000, loss: 0.024171
   Number of active neurons: 1
 >> iter 81000, loss: 0.022813
 >> iter 82000, loss: 0.024012
 >> iter 83000, loss: 0.024881
 >> iter 84000, loss: 0.021181
 >> iter 85000, loss: 0.029717
 >> iter 86000, loss: 0.031608
 >> iter 87000, loss: 0.027276
 >> iter 88000, loss: 0.022447
 >> iter 89000, loss: 0.020712
 >> iter 90000, loss: 0.025594
   Number of active neurons: 1
 >> iter 91000, loss: 0.022271
 >> iter 92000, loss: 0.021215
 >> iter 93000, loss: 0.029972
 >> iter 94000, loss: 0.021475
 >> iter 95000, loss: 0.022102
 >> iter 96000, loss: 0.037246
 >> iter 97000, loss: 0.026051
 >> iter 98000, loss: 0.025680
 >> iter 99000, loss: 0.025748
 >> iter 100000, loss: 0.023079
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.924279
 >> iter 2000, loss: 4.069783
 >> iter 3000, loss: 1.524722
 >> iter 4000, loss: 0.582551
 >> iter 5000, loss: 0.239182
 >> iter 6000, loss: 0.106959
 >> iter 7000, loss: 0.056800
 >> iter 8000, loss: 0.043349
 >> iter 9000, loss: 0.038612
 >> iter 10000, loss: 0.037996
   Number of active neurons: 4
 >> iter 11000, loss: 0.030759
 >> iter 12000, loss: 0.035924
 >> iter 13000, loss: 0.034228
 >> iter 14000, loss: 0.032545
 >> iter 15000, loss: 0.027999
 >> iter 16000, loss: 0.035278
 >> iter 17000, loss: 0.029469
 >> iter 18000, loss: 0.029213
 >> iter 19000, loss: 0.028351
 >> iter 20000, loss: 0.027991
   Number of active neurons: 3
 >> iter 21000, loss: 0.030323
 >> iter 22000, loss: 0.029247
 >> iter 23000, loss: 0.025684
 >> iter 24000, loss: 0.023575
 >> iter 25000, loss: 0.024588
 >> iter 26000, loss: 0.025357
 >> iter 27000, loss: 0.028887
 >> iter 28000, loss: 0.028943
 >> iter 29000, loss: 0.026229
 >> iter 30000, loss: 0.026114
   Number of active neurons: 3
 >> iter 31000, loss: 0.029108
 >> iter 32000, loss: 0.026432
 >> iter 33000, loss: 0.030638
 >> iter 34000, loss: 0.026877
 >> iter 35000, loss: 0.025581
 >> iter 36000, loss: 0.024281
 >> iter 37000, loss: 0.023698
 >> iter 38000, loss: 0.023889
 >> iter 39000, loss: 0.023019
 >> iter 40000, loss: 0.023190
   Number of active neurons: 3
 >> iter 41000, loss: 0.026566
 >> iter 42000, loss: 0.027623
 >> iter 43000, loss: 0.023867
 >> iter 44000, loss: 0.021426
 >> iter 45000, loss: 0.026257
 >> iter 46000, loss: 0.022309
 >> iter 47000, loss: 0.024660
 >> iter 48000, loss: 0.022657
 >> iter 49000, loss: 0.035223
 >> iter 50000, loss: 0.024463
   Number of active neurons: 2
 >> iter 51000, loss: 0.021954
 >> iter 52000, loss: 0.023884
 >> iter 53000, loss: 0.021571
 >> iter 54000, loss: 0.033011
 >> iter 55000, loss: 0.025292
 >> iter 56000, loss: 0.021432
 >> iter 57000, loss: 0.021167
 >> iter 58000, loss: 0.021983
 >> iter 59000, loss: 0.027172
 >> iter 60000, loss: 0.022780
   Number of active neurons: 2
 >> iter 61000, loss: 0.023461
 >> iter 62000, loss: 0.028522
 >> iter 63000, loss: 0.035280
 >> iter 64000, loss: 0.035054
 >> iter 65000, loss: 0.026358
 >> iter 66000, loss: 0.030321
 >> iter 67000, loss: 0.024289
 >> iter 68000, loss: 0.036673
 >> iter 69000, loss: 0.027561
 >> iter 70000, loss: 0.030241
   Number of active neurons: 2
 >> iter 71000, loss: 0.038280
 >> iter 72000, loss: 0.028962
 >> iter 73000, loss: 0.023143
 >> iter 74000, loss: 0.020334
 >> iter 75000, loss: 0.027439
 >> iter 76000, loss: 0.031063
 >> iter 77000, loss: 0.025181
 >> iter 78000, loss: 0.021436
 >> iter 79000, loss: 0.025829
 >> iter 80000, loss: 0.044570
   Number of active neurons: 2
 >> iter 81000, loss: 0.033440
 >> iter 82000, loss: 0.025375
 >> iter 83000, loss: 0.025830
 >> iter 84000, loss: 0.022402
 >> iter 85000, loss: 0.023371
 >> iter 86000, loss: 0.024267
 >> iter 87000, loss: 0.025527
 >> iter 88000, loss: 0.022199
 >> iter 89000, loss: 0.029980
 >> iter 90000, loss: 0.030601
   Number of active neurons: 2
 >> iter 91000, loss: 0.031716
 >> iter 92000, loss: 0.025116
 >> iter 93000, loss: 0.023486
 >> iter 94000, loss: 0.036200
 >> iter 95000, loss: 0.030499
 >> iter 96000, loss: 0.027564
 >> iter 97000, loss: 0.022579
 >> iter 98000, loss: 0.024176
 >> iter 99000, loss: 0.021957
 >> iter 100000, loss: 0.021072
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.956193
 >> iter 2000, loss: 4.082272
 >> iter 3000, loss: 1.561905
 >> iter 4000, loss: 0.600110
 >> iter 5000, loss: 0.247225
 >> iter 6000, loss: 0.111880
 >> iter 7000, loss: 0.068109
 >> iter 8000, loss: 0.048253
 >> iter 9000, loss: 0.037476
 >> iter 10000, loss: 0.037626
   Number of active neurons: 5
 >> iter 11000, loss: 0.040539
 >> iter 12000, loss: 0.033810
 >> iter 13000, loss: 0.047282
 >> iter 14000, loss: 0.036382
 >> iter 15000, loss: 0.040018
 >> iter 16000, loss: 0.038048
 >> iter 17000, loss: 0.032351
 >> iter 18000, loss: 0.040082
 >> iter 19000, loss: 0.034403
 >> iter 20000, loss: 0.031805
   Number of active neurons: 5
 >> iter 21000, loss: 0.031228
 >> iter 22000, loss: 0.028307
 >> iter 23000, loss: 0.033854
 >> iter 24000, loss: 0.029311
 >> iter 25000, loss: 0.026490
 >> iter 26000, loss: 0.043642
 >> iter 27000, loss: 0.034807
 >> iter 28000, loss: 0.029229
 >> iter 29000, loss: 0.051747
 >> iter 30000, loss: 0.035695
   Number of active neurons: 2
 >> iter 31000, loss: 0.026784
 >> iter 32000, loss: 0.032683
 >> iter 33000, loss: 0.024872
 >> iter 34000, loss: 0.033341
 >> iter 35000, loss: 0.026985
 >> iter 36000, loss: 0.021044
 >> iter 37000, loss: 0.021135
 >> iter 38000, loss: 0.018870
 >> iter 39000, loss: 0.019659
 >> iter 40000, loss: 0.019631
   Number of active neurons: 1
 >> iter 41000, loss: 0.019851
 >> iter 42000, loss: 0.018532
 >> iter 43000, loss: 0.019865
 >> iter 44000, loss: 0.018345
 >> iter 45000, loss: 0.032490
 >> iter 46000, loss: 0.021568
 >> iter 47000, loss: 0.023199
 >> iter 48000, loss: 0.018180
 >> iter 49000, loss: 0.019373
 >> iter 50000, loss: 0.019114
   Number of active neurons: 1
 >> iter 51000, loss: 0.016822
 >> iter 52000, loss: 0.019826
 >> iter 53000, loss: 0.017847
 >> iter 54000, loss: 0.019181
 >> iter 55000, loss: 0.021400
 >> iter 56000, loss: 0.024270
 >> iter 57000, loss: 0.022390
 >> iter 58000, loss: 0.017937
 >> iter 59000, loss: 0.027077
 >> iter 60000, loss: 0.029729
   Number of active neurons: 1
 >> iter 61000, loss: 0.020421
 >> iter 62000, loss: 0.018055
 >> iter 63000, loss: 0.019941
 >> iter 64000, loss: 0.027530
 >> iter 65000, loss: 0.023369
 >> iter 66000, loss: 0.025240
 >> iter 67000, loss: 0.021772
 >> iter 68000, loss: 0.033984
 >> iter 69000, loss: 0.022157
 >> iter 70000, loss: 0.022250
   Number of active neurons: 1
 >> iter 71000, loss: 0.020170
 >> iter 72000, loss: 0.018257
 >> iter 73000, loss: 0.028978
 >> iter 74000, loss: 0.044699
 >> iter 75000, loss: 0.027511
 >> iter 76000, loss: 0.020815
 >> iter 77000, loss: 0.018265
 >> iter 78000, loss: 0.018117
 >> iter 79000, loss: 0.041067
 >> iter 80000, loss: 0.026000
   Number of active neurons: 1
 >> iter 81000, loss: 0.019824
 >> iter 82000, loss: 0.017173
 >> iter 83000, loss: 0.019708
 >> iter 84000, loss: 0.024739
 >> iter 85000, loss: 0.021034
 >> iter 86000, loss: 0.040031
 >> iter 87000, loss: 0.027585
 >> iter 88000, loss: 0.020031
 >> iter 89000, loss: 0.020182
 >> iter 90000, loss: 0.019774
   Number of active neurons: 1
 >> iter 91000, loss: 0.021646
 >> iter 92000, loss: 0.032928
 >> iter 93000, loss: 0.029508
 >> iter 94000, loss: 0.027453
 >> iter 95000, loss: 0.022233
 >> iter 96000, loss: 0.021294
 >> iter 97000, loss: 0.025138
 >> iter 98000, loss: 0.021135
 >> iter 99000, loss: 0.020484
 >> iter 100000, loss: 0.019982
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

