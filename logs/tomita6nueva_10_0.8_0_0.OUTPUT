 > Problema: tomita6nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.8
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.010758
 >> iter 2000, loss: 15.458023
 >> iter 3000, loss: 14.002104
 >> iter 4000, loss: 13.443135
 >> iter 5000, loss: 13.203885
 >> iter 6000, loss: 13.117535
 >> iter 7000, loss: 13.071913
 >> iter 8000, loss: 13.058311
 >> iter 9000, loss: 13.031324
 >> iter 10000, loss: 13.026625
   Number of active neurons: 9
 >> iter 11000, loss: 13.013645
 >> iter 12000, loss: 13.018301
 >> iter 13000, loss: 13.008064
 >> iter 14000, loss: 13.015924
 >> iter 15000, loss: 13.002673
 >> iter 16000, loss: 13.005881
 >> iter 17000, loss: 12.996208
 >> iter 18000, loss: 13.010742
 >> iter 19000, loss: 12.985333
 >> iter 20000, loss: 13.002915
   Number of active neurons: 10
 >> iter 21000, loss: 12.992481
 >> iter 22000, loss: 13.005903
 >> iter 23000, loss: 12.986282
 >> iter 24000, loss: 13.006103
 >> iter 25000, loss: 12.989843
 >> iter 26000, loss: 13.003029
 >> iter 27000, loss: 12.990607
 >> iter 28000, loss: 12.997397
 >> iter 29000, loss: 12.987865
 >> iter 30000, loss: 12.989713
   Number of active neurons: 10
 >> iter 31000, loss: 12.988539
 >> iter 32000, loss: 12.981602
 >> iter 33000, loss: 12.958849
 >> iter 34000, loss: 12.486702
 >> iter 35000, loss: 11.701238
 >> iter 36000, loss: 11.225921
 >> iter 37000, loss: 10.784047
 >> iter 38000, loss: 10.628766
 >> iter 39000, loss: 10.454711
 >> iter 40000, loss: 10.324197
   Number of active neurons: 10
 >> iter 41000, loss: 9.546981
 >> iter 42000, loss: 8.552066
 >> iter 43000, loss: 7.413772
 >> iter 44000, loss: 6.322158
 >> iter 45000, loss: 5.341612
 >> iter 46000, loss: 4.061900
 >> iter 47000, loss: 3.090533
 >> iter 48000, loss: 2.522494
 >> iter 49000, loss: 2.259828
 >> iter 50000, loss: 1.806060
   Number of active neurons: 10
 >> iter 51000, loss: 1.698996
 >> iter 52000, loss: 1.926459
 >> iter 53000, loss: 1.429989
 >> iter 54000, loss: 1.282429
 >> iter 55000, loss: 0.826037
 >> iter 56000, loss: 0.952911
 >> iter 57000, loss: 1.030832
 >> iter 58000, loss: 0.564185
 >> iter 59000, loss: 0.671731
 >> iter 60000, loss: 0.854318
   Number of active neurons: 10
 >> iter 61000, loss: 0.459018
 >> iter 62000, loss: 0.855411
 >> iter 63000, loss: 0.630272
 >> iter 64000, loss: 0.481936
 >> iter 65000, loss: 0.515633
 >> iter 66000, loss: 0.365414
 >> iter 67000, loss: 0.392813
 >> iter 68000, loss: 0.635270
 >> iter 69000, loss: 0.448977
 >> iter 70000, loss: 0.513065
   Number of active neurons: 10
 >> iter 71000, loss: 0.256638
 >> iter 72000, loss: 0.458486
 >> iter 73000, loss: 0.301280
 >> iter 74000, loss: 0.485679
 >> iter 75000, loss: 0.501218
 >> iter 76000, loss: 1.068053
 >> iter 77000, loss: 0.485487
 >> iter 78000, loss: 0.570769
 >> iter 79000, loss: 0.492374
 >> iter 80000, loss: 0.297207
   Number of active neurons: 10
 >> iter 81000, loss: 0.199740
 >> iter 82000, loss: 0.193952
 >> iter 83000, loss: 0.409759
 >> iter 84000, loss: 0.326541
 >> iter 85000, loss: 0.159271
 >> iter 86000, loss: 0.235429
 >> iter 87000, loss: 0.274070
 >> iter 88000, loss: 0.401203
 >> iter 89000, loss: 0.239751
 >> iter 90000, loss: 0.369051
   Number of active neurons: 10
 >> iter 91000, loss: 0.634729
 >> iter 92000, loss: 0.648759
 >> iter 93000, loss: 0.830845
 >> iter 94000, loss: 0.603802
 >> iter 95000, loss: 0.473550
 >> iter 96000, loss: 0.290026
 >> iter 97000, loss: 0.238480
 >> iter 98000, loss: 0.141193
 >> iter 99000, loss: 0.076957
 >> iter 100000, loss: 0.084881
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.973626
 >> iter 2000, loss: 15.416593
 >> iter 3000, loss: 13.989902
 >> iter 4000, loss: 13.429715
 >> iter 5000, loss: 13.207217
 >> iter 6000, loss: 13.126507
 >> iter 7000, loss: 13.074682
 >> iter 8000, loss: 13.056632
 >> iter 9000, loss: 13.040679
 >> iter 10000, loss: 13.042974
   Number of active neurons: 10
 >> iter 11000, loss: 13.026286
 >> iter 12000, loss: 13.022399
 >> iter 13000, loss: 13.015186
 >> iter 14000, loss: 13.026082
 >> iter 15000, loss: 13.016254
 >> iter 16000, loss: 13.025911
 >> iter 17000, loss: 13.023101
 >> iter 18000, loss: 13.025152
 >> iter 19000, loss: 13.021756
 >> iter 20000, loss: 13.026849
   Number of active neurons: 10
 >> iter 21000, loss: 13.016003
 >> iter 22000, loss: 13.028656
 >> iter 23000, loss: 13.020675
 >> iter 24000, loss: 13.026293
 >> iter 25000, loss: 13.013662
 >> iter 26000, loss: 13.024334
 >> iter 27000, loss: 13.012238
 >> iter 28000, loss: 13.023071
 >> iter 29000, loss: 13.010044
 >> iter 30000, loss: 13.026976
   Number of active neurons: 10
 >> iter 31000, loss: 13.017973
 >> iter 32000, loss: 13.029063
 >> iter 33000, loss: 13.013816
 >> iter 34000, loss: 13.019477
 >> iter 35000, loss: 13.009373
 >> iter 36000, loss: 13.016407
 >> iter 37000, loss: 13.006798
 >> iter 38000, loss: 13.016946
 >> iter 39000, loss: 13.005123
 >> iter 40000, loss: 13.021570
   Number of active neurons: 10
 >> iter 41000, loss: 12.997694
 >> iter 42000, loss: 12.997304
 >> iter 43000, loss: 12.962448
 >> iter 44000, loss: 12.948957
 >> iter 45000, loss: 12.873055
 >> iter 46000, loss: 12.793484
 >> iter 47000, loss: 12.209841
 >> iter 48000, loss: 11.599462
 >> iter 49000, loss: 11.193260
 >> iter 50000, loss: 11.038981
   Number of active neurons: 10
 >> iter 51000, loss: 10.765340
 >> iter 52000, loss: 10.697782
 >> iter 53000, loss: 10.527884
 >> iter 54000, loss: 10.520019
 >> iter 55000, loss: 10.391273
 >> iter 56000, loss: 10.300865
 >> iter 57000, loss: 9.776451
 >> iter 58000, loss: 9.132056
 >> iter 59000, loss: 7.448891
 >> iter 60000, loss: 5.644352
   Number of active neurons: 10
 >> iter 61000, loss: 5.020870
 >> iter 62000, loss: 4.220905
 >> iter 63000, loss: 3.153848
 >> iter 64000, loss: 2.492668
 >> iter 65000, loss: 2.150315
 >> iter 66000, loss: 1.475655
 >> iter 67000, loss: 1.074013
 >> iter 68000, loss: 1.253017
 >> iter 69000, loss: 1.028347
 >> iter 70000, loss: 1.052384
   Number of active neurons: 10
 >> iter 71000, loss: 0.715891
 >> iter 72000, loss: 0.665920
 >> iter 73000, loss: 0.982219
 >> iter 74000, loss: 0.735975
 >> iter 75000, loss: 0.758733
 >> iter 76000, loss: 0.616361
 >> iter 77000, loss: 0.419380
 >> iter 78000, loss: 0.486909
 >> iter 79000, loss: 0.436789
 >> iter 80000, loss: 0.443839
   Number of active neurons: 10
 >> iter 81000, loss: 0.315591
 >> iter 82000, loss: 0.188887
 >> iter 83000, loss: 0.311748
 >> iter 84000, loss: 0.287370
 >> iter 85000, loss: 0.311450
 >> iter 86000, loss: 0.330311
 >> iter 87000, loss: 0.352277
 >> iter 88000, loss: 0.428440
 >> iter 89000, loss: 0.372167
 >> iter 90000, loss: 0.368671
   Number of active neurons: 10
 >> iter 91000, loss: 0.525982
 >> iter 92000, loss: 0.296906
 >> iter 93000, loss: 0.231628
 >> iter 94000, loss: 0.305722
 >> iter 95000, loss: 0.389932
 >> iter 96000, loss: 0.308740
 >> iter 97000, loss: 0.301901
 >> iter 98000, loss: 0.163317
 >> iter 99000, loss: 0.366341
 >> iter 100000, loss: 0.344284
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.008934
 >> iter 2000, loss: 15.456678
 >> iter 3000, loss: 14.007348
 >> iter 4000, loss: 13.440957
 >> iter 5000, loss: 13.217111
 >> iter 6000, loss: 13.126488
 >> iter 7000, loss: 13.076604
 >> iter 8000, loss: 13.067385
 >> iter 9000, loss: 13.038566
 >> iter 10000, loss: 13.054436
   Number of active neurons: 10
 >> iter 11000, loss: 13.042166
 >> iter 12000, loss: 13.043986
 >> iter 13000, loss: 13.028427
 >> iter 14000, loss: 13.031624
 >> iter 15000, loss: 13.030237
 >> iter 16000, loss: 13.036366
 >> iter 17000, loss: 13.030895
 >> iter 18000, loss: 13.025867
 >> iter 19000, loss: 13.018756
 >> iter 20000, loss: 13.021341
   Number of active neurons: 10
 >> iter 21000, loss: 13.002044
 >> iter 22000, loss: 13.005671
 >> iter 23000, loss: 12.996261
 >> iter 24000, loss: 13.014809
 >> iter 25000, loss: 12.999867
 >> iter 26000, loss: 13.012775
 >> iter 27000, loss: 13.005328
 >> iter 28000, loss: 13.016683
 >> iter 29000, loss: 12.999455
 >> iter 30000, loss: 13.016451
   Number of active neurons: 10
 >> iter 31000, loss: 13.001055
 >> iter 32000, loss: 13.013391
 >> iter 33000, loss: 12.992234
 >> iter 34000, loss: 12.973550
 >> iter 35000, loss: 12.871111
 >> iter 36000, loss: 12.493369
 >> iter 37000, loss: 11.951198
 >> iter 38000, loss: 11.521052
 >> iter 39000, loss: 11.182522
 >> iter 40000, loss: 11.037963
   Number of active neurons: 10
 >> iter 41000, loss: 10.781259
 >> iter 42000, loss: 10.628592
 >> iter 43000, loss: 10.288298
 >> iter 44000, loss: 10.059401
 >> iter 45000, loss: 9.821409
 >> iter 46000, loss: 9.692265
 >> iter 47000, loss: 9.536139
 >> iter 48000, loss: 9.524823
 >> iter 49000, loss: 9.465165
 >> iter 50000, loss: 9.354618
   Number of active neurons: 10
 >> iter 51000, loss: 9.137372
 >> iter 52000, loss: 9.108691
 >> iter 53000, loss: 8.997965
 >> iter 54000, loss: 9.022454
 >> iter 55000, loss: 8.898102
 >> iter 56000, loss: 9.001503
 >> iter 57000, loss: 8.937236
 >> iter 58000, loss: 8.989947
 >> iter 59000, loss: 8.894799
 >> iter 60000, loss: 8.982209
   Number of active neurons: 10
 >> iter 61000, loss: 8.887479
 >> iter 62000, loss: 8.965830
 >> iter 63000, loss: 8.892397
 >> iter 64000, loss: 8.981462
 >> iter 65000, loss: 8.918641
 >> iter 66000, loss: 8.969675
 >> iter 67000, loss: 8.858834
 >> iter 68000, loss: 8.931387
 >> iter 69000, loss: 8.808042
 >> iter 70000, loss: 8.954922
   Number of active neurons: 10
 >> iter 71000, loss: 8.815158
 >> iter 72000, loss: 8.769848
 >> iter 73000, loss: 8.455703
 >> iter 74000, loss: 8.402532
 >> iter 75000, loss: 8.026417
 >> iter 76000, loss: 7.720695
 >> iter 77000, loss: 7.328549
 >> iter 78000, loss: 7.032819
 >> iter 79000, loss: 7.204807
 >> iter 80000, loss: 7.090804
   Number of active neurons: 10
 >> iter 81000, loss: 6.901196
 >> iter 82000, loss: 6.660794
 >> iter 83000, loss: 6.006078
 >> iter 84000, loss: 5.218627
 >> iter 85000, loss: 4.797334
 >> iter 86000, loss: 4.317842
 >> iter 87000, loss: 4.156454
 >> iter 88000, loss: 3.910207
 >> iter 89000, loss: 2.556001
 >> iter 90000, loss: 1.752827
   Number of active neurons: 10
 >> iter 91000, loss: 1.683193
 >> iter 92000, loss: 1.497303
 >> iter 93000, loss: 1.206302
 >> iter 94000, loss: 0.801442
 >> iter 95000, loss: 0.625070
 >> iter 96000, loss: 0.748790
 >> iter 97000, loss: 0.534047
 >> iter 98000, loss: 0.887504
 >> iter 99000, loss: 0.657423
 >> iter 100000, loss: 0.776596
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.089998200036
   - Test - Long: 0.0
   - Test - Big: 0.0489995100049
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.037765
 >> iter 2000, loss: 15.488509
 >> iter 3000, loss: 14.046531
 >> iter 4000, loss: 13.495826
 >> iter 5000, loss: 13.253808
 >> iter 6000, loss: 13.158319
 >> iter 7000, loss: 13.103162
 >> iter 8000, loss: 13.088242
 >> iter 9000, loss: 13.066374
 >> iter 10000, loss: 13.068945
   Number of active neurons: 10
 >> iter 11000, loss: 13.049225
 >> iter 12000, loss: 13.048480
 >> iter 13000, loss: 13.029203
 >> iter 14000, loss: 13.037540
 >> iter 15000, loss: 13.036132
 >> iter 16000, loss: 13.043686
 >> iter 17000, loss: 13.027142
 >> iter 18000, loss: 13.026992
 >> iter 19000, loss: 13.016170
 >> iter 20000, loss: 13.036437
   Number of active neurons: 10
 >> iter 21000, loss: 13.007940
 >> iter 22000, loss: 13.026306
 >> iter 23000, loss: 13.014601
 >> iter 24000, loss: 13.030388
 >> iter 25000, loss: 13.012472
 >> iter 26000, loss: 13.022846
 >> iter 27000, loss: 13.018393
 >> iter 28000, loss: 13.025877
 >> iter 29000, loss: 13.016603
 >> iter 30000, loss: 13.024931
   Number of active neurons: 10
 >> iter 31000, loss: 13.016583
 >> iter 32000, loss: 13.025470
 >> iter 33000, loss: 13.016482
 >> iter 34000, loss: 13.025713
 >> iter 35000, loss: 13.012505
 >> iter 36000, loss: 13.019990
 >> iter 37000, loss: 13.010169
 >> iter 38000, loss: 13.019371
 >> iter 39000, loss: 13.007716
 >> iter 40000, loss: 13.012572
   Number of active neurons: 10
 >> iter 41000, loss: 12.991449
 >> iter 42000, loss: 12.981571
 >> iter 43000, loss: 12.952540
 >> iter 44000, loss: 12.905507
 >> iter 45000, loss: 12.811678
 >> iter 46000, loss: 12.304593
 >> iter 47000, loss: 11.612002
 >> iter 48000, loss: 11.297416
 >> iter 49000, loss: 11.040572
 >> iter 50000, loss: 11.028694
   Number of active neurons: 10
 >> iter 51000, loss: 10.882348
 >> iter 52000, loss: 10.880051
 >> iter 53000, loss: 10.766499
 >> iter 54000, loss: 10.667551
 >> iter 55000, loss: 10.342560
 >> iter 56000, loss: 10.172192
 >> iter 57000, loss: 9.935988
 >> iter 58000, loss: 9.757072
 >> iter 59000, loss: 9.264729
 >> iter 60000, loss: 9.127854
   Number of active neurons: 10
 >> iter 61000, loss: 8.864301
 >> iter 62000, loss: 8.793404
 >> iter 63000, loss: 8.508448
 >> iter 64000, loss: 8.389752
 >> iter 65000, loss: 8.162146
 >> iter 66000, loss: 8.144562
 >> iter 67000, loss: 7.979440
 >> iter 68000, loss: 7.887745
 >> iter 69000, loss: 8.003101
 >> iter 70000, loss: 7.710085
   Number of active neurons: 10
 >> iter 71000, loss: 7.201737
 >> iter 72000, loss: 7.215894
 >> iter 73000, loss: 6.501388
 >> iter 74000, loss: 6.292295
 >> iter 75000, loss: 5.561657
 >> iter 76000, loss: 5.912306
 >> iter 77000, loss: 5.568590
 >> iter 78000, loss: 5.892785
 >> iter 79000, loss: 5.525586
 >> iter 80000, loss: 5.894300
   Number of active neurons: 10
 >> iter 81000, loss: 5.502530
 >> iter 82000, loss: 5.328644
 >> iter 83000, loss: 5.134426
 >> iter 84000, loss: 5.363381
 >> iter 85000, loss: 5.328633
 >> iter 86000, loss: 5.317533
 >> iter 87000, loss: 5.101260
 >> iter 88000, loss: 5.120082
 >> iter 89000, loss: 4.990835
 >> iter 90000, loss: 5.234342
   Number of active neurons: 10
 >> iter 91000, loss: 4.867634
 >> iter 92000, loss: 5.324890
 >> iter 93000, loss: 5.025939
 >> iter 94000, loss: 5.107752
 >> iter 95000, loss: 5.070495
 >> iter 96000, loss: 5.051416
 >> iter 97000, loss: 5.075137
 >> iter 98000, loss: 5.093512
 >> iter 99000, loss: 4.993100
 >> iter 100000, loss: 4.922613
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 7.93984120318
   - Test - Long: 28.3785810709
   - Test - Big: 8.20391796082
   - Test - A: 8.33277781481
   - Test - B: 15.3656422905
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.021707
 >> iter 2000, loss: 15.480060
 >> iter 3000, loss: 14.034917
 >> iter 4000, loss: 13.483459
 >> iter 5000, loss: 13.239703
 >> iter 6000, loss: 13.149482
 >> iter 7000, loss: 13.091349
 >> iter 8000, loss: 13.067114
 >> iter 9000, loss: 13.065400
 >> iter 10000, loss: 13.064293
   Number of active neurons: 10
 >> iter 11000, loss: 13.039294
 >> iter 12000, loss: 13.049450
 >> iter 13000, loss: 13.034435
 >> iter 14000, loss: 13.043822
 >> iter 15000, loss: 13.038836
 >> iter 16000, loss: 13.043916
 >> iter 17000, loss: 13.041180
 >> iter 18000, loss: 13.043885
 >> iter 19000, loss: 13.028965
 >> iter 20000, loss: 13.042427
   Number of active neurons: 10
 >> iter 21000, loss: 13.029276
 >> iter 22000, loss: 13.031195
 >> iter 23000, loss: 13.018016
 >> iter 24000, loss: 13.027797
 >> iter 25000, loss: 13.020038
 >> iter 26000, loss: 13.028051
 >> iter 27000, loss: 13.013326
 >> iter 28000, loss: 13.019986
 >> iter 29000, loss: 13.008507
 >> iter 30000, loss: 13.018264
   Number of active neurons: 10
 >> iter 31000, loss: 13.005582
 >> iter 32000, loss: 13.014151
 >> iter 33000, loss: 13.004566
 >> iter 34000, loss: 13.013077
 >> iter 35000, loss: 13.001303
 >> iter 36000, loss: 13.011398
 >> iter 37000, loss: 13.001039
 >> iter 38000, loss: 13.014474
 >> iter 39000, loss: 12.996656
 >> iter 40000, loss: 13.011512
   Number of active neurons: 10
 >> iter 41000, loss: 12.990378
 >> iter 42000, loss: 13.008710
 >> iter 43000, loss: 12.989375
 >> iter 44000, loss: 12.996894
 >> iter 45000, loss: 12.961307
 >> iter 46000, loss: 12.879932
 >> iter 47000, loss: 12.114776
 >> iter 48000, loss: 11.536190
 >> iter 49000, loss: 11.096517
 >> iter 50000, loss: 10.954493
   Number of active neurons: 10
 >> iter 51000, loss: 10.705621
 >> iter 52000, loss: 10.603617
 >> iter 53000, loss: 10.436335
 >> iter 54000, loss: 10.430176
 >> iter 55000, loss: 10.267183
 >> iter 56000, loss: 10.295849
 >> iter 57000, loss: 10.134475
 >> iter 58000, loss: 10.178624
 >> iter 59000, loss: 10.022979
 >> iter 60000, loss: 10.063436
   Number of active neurons: 10
 >> iter 61000, loss: 9.906335
 >> iter 62000, loss: 9.857480
 >> iter 63000, loss: 9.612341
 >> iter 64000, loss: 9.447392
 >> iter 65000, loss: 9.284750
 >> iter 66000, loss: 9.156272
 >> iter 67000, loss: 8.711993
 >> iter 68000, loss: 8.467555
 >> iter 69000, loss: 7.834931
 >> iter 70000, loss: 7.534012
   Number of active neurons: 10
 >> iter 71000, loss: 6.974570
 >> iter 72000, loss: 6.859907
 >> iter 73000, loss: 6.676178
 >> iter 74000, loss: 6.854708
 >> iter 75000, loss: 6.443008
 >> iter 76000, loss: 6.564117
 >> iter 77000, loss: 6.283074
 >> iter 78000, loss: 6.138836
 >> iter 79000, loss: 5.818053
 >> iter 80000, loss: 5.823142
   Number of active neurons: 10
 >> iter 81000, loss: 5.627049
 >> iter 82000, loss: 5.686256
 >> iter 83000, loss: 5.716077
 >> iter 84000, loss: 5.692119
 >> iter 85000, loss: 5.639355
 >> iter 86000, loss: 5.702103
 >> iter 87000, loss: 5.362380
 >> iter 88000, loss: 5.577917
 >> iter 89000, loss: 5.360982
 >> iter 90000, loss: 5.575103
   Number of active neurons: 10
 >> iter 91000, loss: 5.461157
 >> iter 92000, loss: 5.531203
 >> iter 93000, loss: 5.293768
 >> iter 94000, loss: 5.391076
 >> iter 95000, loss: 5.163592
 >> iter 96000, loss: 4.857613
 >> iter 97000, loss: 4.557107
 >> iter 98000, loss: 4.611694
 >> iter 99000, loss: 4.419545
 >> iter 100000, loss: 4.485893
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 7.42985140297
   - Test - Long: 27.2236388181
   - Test - Big: 7.41492585074
   - Test - A: 0.0
   - Test - B: 15.3923071795
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.015502
 >> iter 2000, loss: 15.466537
 >> iter 3000, loss: 14.031434
 >> iter 4000, loss: 13.468092
 >> iter 5000, loss: 13.222256
 >> iter 6000, loss: 13.138680
 >> iter 7000, loss: 13.080596
 >> iter 8000, loss: 13.072639
 >> iter 9000, loss: 13.051467
 >> iter 10000, loss: 13.047131
   Number of active neurons: 10
 >> iter 11000, loss: 13.029920
 >> iter 12000, loss: 13.027859
 >> iter 13000, loss: 13.025791
 >> iter 14000, loss: 13.030689
 >> iter 15000, loss: 13.027933
 >> iter 16000, loss: 13.032151
 >> iter 17000, loss: 13.025679
 >> iter 18000, loss: 13.026166
 >> iter 19000, loss: 13.013752
 >> iter 20000, loss: 13.018875
   Number of active neurons: 10
 >> iter 21000, loss: 13.011052
 >> iter 22000, loss: 13.027491
 >> iter 23000, loss: 13.001838
 >> iter 24000, loss: 13.010043
 >> iter 25000, loss: 12.995985
 >> iter 26000, loss: 13.006552
 >> iter 27000, loss: 12.989835
 >> iter 28000, loss: 12.999198
 >> iter 29000, loss: 12.988943
 >> iter 30000, loss: 13.007447
   Number of active neurons: 10
 >> iter 31000, loss: 12.996167
 >> iter 32000, loss: 13.002289
 >> iter 33000, loss: 12.993117
 >> iter 34000, loss: 12.997316
 >> iter 35000, loss: 12.972777
 >> iter 36000, loss: 12.946645
 >> iter 37000, loss: 12.862825
 >> iter 38000, loss: 12.534582
 >> iter 39000, loss: 11.781391
 >> iter 40000, loss: 11.368909
   Number of active neurons: 10
 >> iter 41000, loss: 11.027376
 >> iter 42000, loss: 10.886938
 >> iter 43000, loss: 10.647854
 >> iter 44000, loss: 10.525043
 >> iter 45000, loss: 10.357678
 >> iter 46000, loss: 10.343086
 >> iter 47000, loss: 10.217778
 >> iter 48000, loss: 10.208647
 >> iter 49000, loss: 10.148701
 >> iter 50000, loss: 10.144207
   Number of active neurons: 10
 >> iter 51000, loss: 9.937727
 >> iter 52000, loss: 9.893751
 >> iter 53000, loss: 9.591227
 >> iter 54000, loss: 9.568216
 >> iter 55000, loss: 9.286085
 >> iter 56000, loss: 9.287382
 >> iter 57000, loss: 9.032720
 >> iter 58000, loss: 9.063134
 >> iter 59000, loss: 8.941557
 >> iter 60000, loss: 8.808018
   Number of active neurons: 10
 >> iter 61000, loss: 8.361799
 >> iter 62000, loss: 8.262240
 >> iter 63000, loss: 7.930696
 >> iter 64000, loss: 7.678013
 >> iter 65000, loss: 7.092149
 >> iter 66000, loss: 6.722834
 >> iter 67000, loss: 6.168145
 >> iter 68000, loss: 6.281563
 >> iter 69000, loss: 5.893760
 >> iter 70000, loss: 5.315068
   Number of active neurons: 10
 >> iter 71000, loss: 4.768040
 >> iter 72000, loss: 4.329590
 >> iter 73000, loss: 3.995110
 >> iter 74000, loss: 3.490461
 >> iter 75000, loss: 3.600008
 >> iter 76000, loss: 3.857817
 >> iter 77000, loss: 3.266745
 >> iter 78000, loss: 3.421614
 >> iter 79000, loss: 3.639882
 >> iter 80000, loss: 3.553415
   Number of active neurons: 10
 >> iter 81000, loss: 3.524519
 >> iter 82000, loss: 3.419762
 >> iter 83000, loss: 2.597400
 >> iter 84000, loss: 1.737221
 >> iter 85000, loss: 1.854498
 >> iter 86000, loss: 1.689882
 >> iter 87000, loss: 1.602937
 >> iter 88000, loss: 1.444867
 >> iter 89000, loss: 1.987898
 >> iter 90000, loss: 1.600337
   Number of active neurons: 10
 >> iter 91000, loss: 1.677781
 >> iter 92000, loss: 1.395469
 >> iter 93000, loss: 1.245034
 >> iter 94000, loss: 1.461142
 >> iter 95000, loss: 1.536296
 >> iter 96000, loss: 1.459752
 >> iter 97000, loss: 1.421613
 >> iter 98000, loss: 1.272035
 >> iter 99000, loss: 1.467747
 >> iter 100000, loss: 1.114179
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.365992680146
   - Test - Long: 0.0
   - Test - Big: 0.436995630044
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.990914
 >> iter 2000, loss: 15.462887
 >> iter 3000, loss: 14.025057
 >> iter 4000, loss: 13.475010
 >> iter 5000, loss: 13.227516
 >> iter 6000, loss: 13.139123
 >> iter 7000, loss: 13.088059
 >> iter 8000, loss: 13.072912
 >> iter 9000, loss: 13.043491
 >> iter 10000, loss: 13.042015
   Number of active neurons: 10
 >> iter 11000, loss: 13.021216
 >> iter 12000, loss: 13.033307
 >> iter 13000, loss: 13.014069
 >> iter 14000, loss: 13.019708
 >> iter 15000, loss: 13.014922
 >> iter 16000, loss: 13.017965
 >> iter 17000, loss: 13.011439
 >> iter 18000, loss: 13.016638
 >> iter 19000, loss: 13.010946
 >> iter 20000, loss: 13.025849
   Number of active neurons: 10
 >> iter 21000, loss: 13.010524
 >> iter 22000, loss: 13.016975
 >> iter 23000, loss: 12.986738
 >> iter 24000, loss: 12.650130
 >> iter 25000, loss: 11.876235
 >> iter 26000, loss: 11.460943
 >> iter 27000, loss: 11.160734
 >> iter 28000, loss: 11.074524
 >> iter 29000, loss: 10.861923
 >> iter 30000, loss: 10.791635
   Number of active neurons: 10
 >> iter 31000, loss: 10.603551
 >> iter 32000, loss: 10.532611
 >> iter 33000, loss: 10.393820
 >> iter 34000, loss: 10.043599
 >> iter 35000, loss: 9.676422
 >> iter 36000, loss: 9.418209
 >> iter 37000, loss: 9.094091
 >> iter 38000, loss: 8.914510
 >> iter 39000, loss: 8.520339
 >> iter 40000, loss: 8.526161
   Number of active neurons: 10
 >> iter 41000, loss: 8.311939
 >> iter 42000, loss: 8.433573
 >> iter 43000, loss: 8.214218
 >> iter 44000, loss: 8.316469
 >> iter 45000, loss: 8.167372
 >> iter 46000, loss: 8.281787
 >> iter 47000, loss: 8.058522
 >> iter 48000, loss: 8.137901
 >> iter 49000, loss: 7.745473
 >> iter 50000, loss: 7.603159
   Number of active neurons: 10
 >> iter 51000, loss: 7.340828
 >> iter 52000, loss: 7.384621
 >> iter 53000, loss: 7.397453
 >> iter 54000, loss: 7.398918
 >> iter 55000, loss: 7.217033
 >> iter 56000, loss: 7.262313
 >> iter 57000, loss: 7.107793
 >> iter 58000, loss: 7.346422
 >> iter 59000, loss: 7.204517
 >> iter 60000, loss: 7.285341
   Number of active neurons: 10
 >> iter 61000, loss: 7.170579
 >> iter 62000, loss: 7.170379
 >> iter 63000, loss: 7.016605
 >> iter 64000, loss: 7.153724
 >> iter 65000, loss: 7.040144
 >> iter 66000, loss: 7.273200
 >> iter 67000, loss: 7.090908
 >> iter 68000, loss: 7.133858
 >> iter 69000, loss: 6.979103
 >> iter 70000, loss: 7.092086
   Number of active neurons: 10
 >> iter 71000, loss: 6.939962
 >> iter 72000, loss: 7.113266
 >> iter 73000, loss: 6.947589
 >> iter 74000, loss: 7.013384
 >> iter 75000, loss: 6.791662
 >> iter 76000, loss: 6.965081
 >> iter 77000, loss: 6.895738
 >> iter 78000, loss: 6.843827
 >> iter 79000, loss: 6.643554
 >> iter 80000, loss: 6.779948
   Number of active neurons: 10
 >> iter 81000, loss: 6.400918
 >> iter 82000, loss: 6.552172
 >> iter 83000, loss: 6.317907
 >> iter 84000, loss: 6.397119
 >> iter 85000, loss: 6.130185
 >> iter 86000, loss: 6.303626
 >> iter 87000, loss: 6.184727
 >> iter 88000, loss: 6.137818
 >> iter 89000, loss: 5.836690
 >> iter 90000, loss: 5.832001
   Number of active neurons: 10
 >> iter 91000, loss: 5.750261
 >> iter 92000, loss: 5.633507
 >> iter 93000, loss: 5.490325
 >> iter 94000, loss: 5.720347
 >> iter 95000, loss: 5.481838
 >> iter 96000, loss: 5.535720
 >> iter 97000, loss: 5.435767
 >> iter 98000, loss: 5.491917
 >> iter 99000, loss: 5.306509
 >> iter 100000, loss: 5.384089
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 9.94980100398
   - Test - Long: 29.1335433228
   - Test - Big: 10.042899571
   - Test - A: 30.2579828011
   - Test - B: 0.693287114192
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.961968
 >> iter 2000, loss: 15.436379
 >> iter 3000, loss: 13.985267
 >> iter 4000, loss: 13.431091
 >> iter 5000, loss: 13.192098
 >> iter 6000, loss: 13.088411
 >> iter 7000, loss: 13.052855
 >> iter 8000, loss: 13.033254
 >> iter 9000, loss: 13.017457
 >> iter 10000, loss: 13.025626
   Number of active neurons: 10
 >> iter 11000, loss: 13.001781
 >> iter 12000, loss: 13.003910
 >> iter 13000, loss: 12.983328
 >> iter 14000, loss: 12.993977
 >> iter 15000, loss: 12.977217
 >> iter 16000, loss: 12.982469
 >> iter 17000, loss: 12.980693
 >> iter 18000, loss: 12.981114
 >> iter 19000, loss: 12.974858
 >> iter 20000, loss: 12.979220
   Number of active neurons: 10
 >> iter 21000, loss: 12.962489
 >> iter 22000, loss: 12.975120
 >> iter 23000, loss: 12.958767
 >> iter 24000, loss: 12.969865
 >> iter 25000, loss: 12.949945
 >> iter 26000, loss: 12.925922
 >> iter 27000, loss: 12.477115
 >> iter 28000, loss: 11.775377
 >> iter 29000, loss: 11.264632
 >> iter 30000, loss: 11.025078
   Number of active neurons: 10
 >> iter 31000, loss: 10.723027
 >> iter 32000, loss: 10.404230
 >> iter 33000, loss: 10.026070
 >> iter 34000, loss: 9.801652
 >> iter 35000, loss: 9.452341
 >> iter 36000, loss: 9.118674
 >> iter 37000, loss: 8.876544
 >> iter 38000, loss: 8.596592
 >> iter 39000, loss: 8.302308
 >> iter 40000, loss: 8.035678
   Number of active neurons: 10
 >> iter 41000, loss: 7.822904
 >> iter 42000, loss: 7.596460
 >> iter 43000, loss: 7.139902
 >> iter 44000, loss: 6.491364
 >> iter 45000, loss: 5.592311
 >> iter 46000, loss: 4.828973
 >> iter 47000, loss: 5.345874
 >> iter 48000, loss: 4.766506
 >> iter 49000, loss: 4.706698
 >> iter 50000, loss: 4.149725
   Number of active neurons: 10
 >> iter 51000, loss: 4.044768
 >> iter 52000, loss: 3.818306
 >> iter 53000, loss: 3.905501
 >> iter 54000, loss: 3.935094
 >> iter 55000, loss: 4.084032
 >> iter 56000, loss: 3.645026
 >> iter 57000, loss: 3.558444
 >> iter 58000, loss: 3.611328
 >> iter 59000, loss: 4.560293
 >> iter 60000, loss: 3.927685
   Number of active neurons: 10
 >> iter 61000, loss: 3.291159
 >> iter 62000, loss: 2.391699
 >> iter 63000, loss: 1.571867
 >> iter 64000, loss: 1.571508
 >> iter 65000, loss: 1.607208
 >> iter 66000, loss: 1.332535
 >> iter 67000, loss: 1.560774
 >> iter 68000, loss: 1.090431
 >> iter 69000, loss: 0.828678
 >> iter 70000, loss: 0.748194
   Number of active neurons: 10
 >> iter 71000, loss: 0.717304
 >> iter 72000, loss: 0.686953
 >> iter 73000, loss: 0.900949
 >> iter 74000, loss: 0.696988
 >> iter 75000, loss: 0.616681
 >> iter 76000, loss: 0.627914
 >> iter 77000, loss: 0.595754
 >> iter 78000, loss: 0.411936
 >> iter 79000, loss: 0.289522
 >> iter 80000, loss: 0.246960
   Number of active neurons: 10
 >> iter 81000, loss: 0.499318
 >> iter 82000, loss: 0.610232
 >> iter 83000, loss: 0.444745
 >> iter 84000, loss: 0.786140
 >> iter 85000, loss: 0.562231
 >> iter 86000, loss: 0.621427
 >> iter 87000, loss: 0.789130
 >> iter 88000, loss: 0.406784
 >> iter 89000, loss: 0.341270
 >> iter 90000, loss: 0.264100
   Number of active neurons: 10
 >> iter 91000, loss: 0.363846
 >> iter 92000, loss: 0.193727
 >> iter 93000, loss: 0.387207
 >> iter 94000, loss: 0.495657
 >> iter 95000, loss: 0.335531
 >> iter 96000, loss: 0.266211
 >> iter 97000, loss: 0.305194
 >> iter 98000, loss: 0.225142
 >> iter 99000, loss: 0.188372
 >> iter 100000, loss: 0.516203
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0019999600008
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.007320
 >> iter 2000, loss: 15.410663
 >> iter 3000, loss: 13.992460
 >> iter 4000, loss: 13.421852
 >> iter 5000, loss: 13.203240
 >> iter 6000, loss: 13.121454
 >> iter 7000, loss: 13.076276
 >> iter 8000, loss: 13.057998
 >> iter 9000, loss: 13.046236
 >> iter 10000, loss: 13.054056
   Number of active neurons: 10
 >> iter 11000, loss: 13.044447
 >> iter 12000, loss: 13.041215
 >> iter 13000, loss: 13.027094
 >> iter 14000, loss: 13.037324
 >> iter 15000, loss: 13.024742
 >> iter 16000, loss: 13.028314
 >> iter 17000, loss: 13.015772
 >> iter 18000, loss: 13.018404
 >> iter 19000, loss: 13.019384
 >> iter 20000, loss: 13.034411
   Number of active neurons: 10
 >> iter 21000, loss: 13.011466
 >> iter 22000, loss: 13.022668
 >> iter 23000, loss: 13.008411
 >> iter 24000, loss: 13.020947
 >> iter 25000, loss: 13.011074
 >> iter 26000, loss: 13.019801
 >> iter 27000, loss: 13.003808
 >> iter 28000, loss: 13.017670
 >> iter 29000, loss: 13.007502
 >> iter 30000, loss: 13.010915
   Number of active neurons: 9
 >> iter 31000, loss: 12.997178
 >> iter 32000, loss: 13.002188
 >> iter 33000, loss: 12.989340
 >> iter 34000, loss: 12.967715
 >> iter 35000, loss: 12.909580
 >> iter 36000, loss: 12.317402
 >> iter 37000, loss: 11.627255
 >> iter 38000, loss: 11.297390
 >> iter 39000, loss: 10.984578
 >> iter 40000, loss: 10.857721
   Number of active neurons: 10
 >> iter 41000, loss: 10.653531
 >> iter 42000, loss: 10.531823
 >> iter 43000, loss: 10.307982
 >> iter 44000, loss: 10.080181
 >> iter 45000, loss: 9.641835
 >> iter 46000, loss: 9.514562
 >> iter 47000, loss: 9.169980
 >> iter 48000, loss: 8.866234
 >> iter 49000, loss: 8.726576
 >> iter 50000, loss: 8.557199
   Number of active neurons: 10
 >> iter 51000, loss: 8.358002
 >> iter 52000, loss: 8.193384
 >> iter 53000, loss: 8.349339
 >> iter 54000, loss: 7.963025
 >> iter 55000, loss: 7.567957
 >> iter 56000, loss: 7.479645
 >> iter 57000, loss: 7.493960
 >> iter 58000, loss: 7.132134
 >> iter 59000, loss: 7.086934
 >> iter 60000, loss: 7.023328
   Number of active neurons: 10
 >> iter 61000, loss: 6.233340
 >> iter 62000, loss: 5.344976
 >> iter 63000, loss: 5.108164
 >> iter 64000, loss: 4.699132
 >> iter 65000, loss: 4.592832
 >> iter 66000, loss: 4.508226
 >> iter 67000, loss: 4.528052
 >> iter 68000, loss: 4.449853
 >> iter 69000, loss: 4.308080
 >> iter 70000, loss: 4.330668
   Number of active neurons: 10
 >> iter 71000, loss: 4.155148
 >> iter 72000, loss: 4.122109
 >> iter 73000, loss: 2.459382
 >> iter 74000, loss: 1.870703
 >> iter 75000, loss: 1.313713
 >> iter 76000, loss: 0.945068
 >> iter 77000, loss: 0.660688
 >> iter 78000, loss: 0.764178
 >> iter 79000, loss: 0.743972
 >> iter 80000, loss: 0.699039
   Number of active neurons: 10
 >> iter 81000, loss: 0.879215
 >> iter 82000, loss: 0.616564
 >> iter 83000, loss: 0.623105
 >> iter 84000, loss: 0.456599
 >> iter 85000, loss: 0.295209
 >> iter 86000, loss: 0.538981
 >> iter 87000, loss: 0.369542
 >> iter 88000, loss: 0.400942
 >> iter 89000, loss: 0.256974
 >> iter 90000, loss: 0.236739
   Number of active neurons: 10
 >> iter 91000, loss: 0.491696
 >> iter 92000, loss: 0.333347
 >> iter 93000, loss: 0.491407
 >> iter 94000, loss: 0.527754
 >> iter 95000, loss: 0.406819
 >> iter 96000, loss: 0.425117
 >> iter 97000, loss: 0.434258
 >> iter 98000, loss: 0.277434
 >> iter 99000, loss: 0.330531
 >> iter 100000, loss: 0.173421
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.048328
 >> iter 2000, loss: 15.479172
 >> iter 3000, loss: 14.015421
 >> iter 4000, loss: 13.448802
 >> iter 5000, loss: 13.224150
 >> iter 6000, loss: 13.141936
 >> iter 7000, loss: 13.089171
 >> iter 8000, loss: 13.068256
 >> iter 9000, loss: 13.041751
 >> iter 10000, loss: 13.040191
   Number of active neurons: 10
 >> iter 11000, loss: 13.029276
 >> iter 12000, loss: 13.028144
 >> iter 13000, loss: 13.017778
 >> iter 14000, loss: 13.024737
 >> iter 15000, loss: 13.012255
 >> iter 16000, loss: 13.022288
 >> iter 17000, loss: 13.014242
 >> iter 18000, loss: 13.018700
 >> iter 19000, loss: 13.012420
 >> iter 20000, loss: 13.018218
   Number of active neurons: 10
 >> iter 21000, loss: 12.999633
 >> iter 22000, loss: 13.019851
 >> iter 23000, loss: 13.007168
 >> iter 24000, loss: 13.019289
 >> iter 25000, loss: 13.004082
 >> iter 26000, loss: 13.014192
 >> iter 27000, loss: 12.999872
 >> iter 28000, loss: 13.011760
 >> iter 29000, loss: 12.999684
 >> iter 30000, loss: 13.017150
   Number of active neurons: 10
 >> iter 31000, loss: 13.005404
 >> iter 32000, loss: 13.015633
 >> iter 33000, loss: 13.002353
 >> iter 34000, loss: 13.010190
 >> iter 35000, loss: 13.003640
 >> iter 36000, loss: 13.007046
 >> iter 37000, loss: 12.997274
 >> iter 38000, loss: 13.006553
 >> iter 39000, loss: 12.992728
 >> iter 40000, loss: 13.001486
   Number of active neurons: 10
 >> iter 41000, loss: 12.990814
 >> iter 42000, loss: 13.006601
 >> iter 43000, loss: 12.988001
 >> iter 44000, loss: 13.012259
 >> iter 45000, loss: 12.992798
 >> iter 46000, loss: 13.010000
 >> iter 47000, loss: 12.984589
 >> iter 48000, loss: 13.011441
 >> iter 49000, loss: 12.986701
 >> iter 50000, loss: 13.011942
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 51000, loss: 12.990166
 >> iter 52000, loss: 13.008081
 >> iter 53000, loss: 12.980814
 >> iter 54000, loss: 13.009468
 >> iter 55000, loss: 12.979662
 >> iter 56000, loss: 13.007625
 >> iter 57000, loss: 12.979245
 >> iter 58000, loss: 13.002686
 >> iter 59000, loss: 12.980874
 >> iter 60000, loss: 13.010228
   Number of active neurons: 8
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 8
 >> iter 61000, loss: 12.984208
 >> iter 62000, loss: 13.006633
 >> iter 63000, loss: 12.979254
 >> iter 64000, loss: 13.014217
 >> iter 65000, loss: 12.988650
 >> iter 66000, loss: 13.009185
 >> iter 67000, loss: 12.987508
 >> iter 68000, loss: 13.006308
 >> iter 69000, loss: 12.978865
 >> iter 70000, loss: 12.963846
   Number of active neurons: 9
 >> iter 71000, loss: 12.915632
 >> iter 72000, loss: 12.864916
 >> iter 73000, loss: 12.761106
 >> iter 74000, loss: 12.664555
 >> iter 75000, loss: 12.571701
 >> iter 76000, loss: 12.454696
 >> iter 77000, loss: 12.305113
 >> iter 78000, loss: 12.201443
 >> iter 79000, loss: 11.933775
 >> iter 80000, loss: 11.619127
   Number of active neurons: 10
 >> iter 81000, loss: 11.358571
 >> iter 82000, loss: 11.247604
 >> iter 83000, loss: 11.084036
 >> iter 84000, loss: 11.094837
 >> iter 85000, loss: 10.863994
 >> iter 86000, loss: 10.854663
 >> iter 87000, loss: 10.684450
 >> iter 88000, loss: 10.725873
 >> iter 89000, loss: 10.529731
 >> iter 90000, loss: 10.483464
   Number of active neurons: 10
 >> iter 91000, loss: 10.363990
 >> iter 92000, loss: 10.236829
 >> iter 93000, loss: 9.940046
 >> iter 94000, loss: 9.897218
 >> iter 95000, loss: 9.662774
 >> iter 96000, loss: 9.647140
 >> iter 97000, loss: 9.447923
 >> iter 98000, loss: 9.468395
 >> iter 99000, loss: 9.353858
 >> iter 100000, loss: 9.366609
   Number of active neurons: 10
 >> iter 101000, loss: 9.184620
 >> iter 102000, loss: 9.211231
 >> iter 103000, loss: 9.337926
 >> iter 104000, loss: 9.326715
 >> iter 105000, loss: 9.038600
 >> iter 106000, loss: 8.951954
 >> iter 107000, loss: 8.129895
 >> iter 108000, loss: 7.878045
 >> iter 109000, loss: 7.325056
 >> iter 110000, loss: 7.225437
   Number of active neurons: 10
 >> iter 111000, loss: 6.958601
 >> iter 112000, loss: 7.235955
 >> iter 113000, loss: 6.990274
 >> iter 114000, loss: 7.419081
 >> iter 115000, loss: 6.924795
 >> iter 116000, loss: 6.925909
 >> iter 117000, loss: 6.323583
 >> iter 118000, loss: 6.577776
 >> iter 119000, loss: 6.229939
 >> iter 120000, loss: 6.469458
   Number of active neurons: 10
 >> iter 121000, loss: 6.201149
 >> iter 122000, loss: 6.428805
 >> iter 123000, loss: 6.046895
 >> iter 124000, loss: 6.126730
 >> iter 125000, loss: 6.073817
 >> iter 126000, loss: 6.352866
 >> iter 127000, loss: 5.810692
 >> iter 128000, loss: 5.898316
 >> iter 129000, loss: 5.481328
 >> iter 130000, loss: 5.744643
   Number of active neurons: 10
 >> iter 131000, loss: 5.404545
 >> iter 132000, loss: 5.438903
 >> iter 133000, loss: 5.531596
 >> iter 134000, loss: 5.785607
 >> iter 135000, loss: 5.608208
 >> iter 136000, loss: 5.666504
 >> iter 137000, loss: 5.384699
 >> iter 138000, loss: 5.699328
 >> iter 139000, loss: 5.383910
 >> iter 140000, loss: 5.519616
   Number of active neurons: 10
 >> iter 141000, loss: 5.294749
 >> iter 142000, loss: 5.619222
 >> iter 143000, loss: 5.303584
 >> iter 144000, loss: 5.388635
 >> iter 145000, loss: 5.352780
 >> iter 146000, loss: 5.412850
 >> iter 147000, loss: 4.781110
 >> iter 148000, loss: 4.708920
 >> iter 149000, loss: 4.268954
 >> iter 150000, loss: 4.711361
   Number of active neurons: 10
 >> iter 151000, loss: 4.455761
 >> iter 152000, loss: 4.685660
 >> iter 153000, loss: 4.322094
 >> iter 154000, loss: 4.391659
 >> iter 155000, loss: 4.143505
 >> iter 156000, loss: 4.043803
 >> iter 157000, loss: 3.841454
 >> iter 158000, loss: 3.895215
 >> iter 159000, loss: 3.765439
 >> iter 160000, loss: 3.875550
   Number of active neurons: 10
 >> iter 161000, loss: 3.980042
 >> iter 162000, loss: 4.113840
 >> iter 163000, loss: 3.937648
 >> iter 164000, loss: 3.819917
 >> iter 165000, loss: 3.822810
 >> iter 166000, loss: 3.819493
 >> iter 167000, loss: 3.652308
 >> iter 168000, loss: 3.841875
 >> iter 169000, loss: 3.566715
 >> iter 170000, loss: 3.630866
   Number of active neurons: 10
 >> iter 171000, loss: 3.617818
 >> iter 172000, loss: 3.836344
 >> iter 173000, loss: 3.537752
 >> iter 174000, loss: 3.629931
 >> iter 175000, loss: 3.608948
 >> iter 176000, loss: 3.590801
 >> iter 177000, loss: 3.656134
 >> iter 178000, loss: 3.939432
 >> iter 179000, loss: 3.660667
 >> iter 180000, loss: 3.592183
   Number of active neurons: 10
 >> iter 181000, loss: 3.363181
 >> iter 182000, loss: 3.576144
 >> iter 183000, loss: 3.322229
 >> iter 184000, loss: 3.705207
 >> iter 185000, loss: 3.626470
 >> iter 186000, loss: 3.571449
 >> iter 187000, loss: 3.801934
 >> iter 188000, loss: 4.156812
 >> iter 189000, loss: 4.286509
 >> iter 190000, loss: 4.159218
   Number of active neurons: 10
 >> iter 191000, loss: 3.613299
 >> iter 192000, loss: 3.839056
 >> iter 193000, loss: 3.412767
 >> iter 194000, loss: 3.595251
 >> iter 195000, loss: 3.432595
 >> iter 196000, loss: 3.759938
 >> iter 197000, loss: 3.399937
 >> iter 198000, loss: 3.625182
 >> iter 199000, loss: 3.299438
 >> iter 200000, loss: 3.403028
   Number of active neurons: 10
 >> iter 201000, loss: 3.262588
 >> iter 202000, loss: 3.521785
 >> iter 203000, loss: 3.386100
 >> iter 204000, loss: 3.588366
 >> iter 205000, loss: 3.378679
 >> iter 206000, loss: 3.534539
 >> iter 207000, loss: 3.438355
 >> iter 208000, loss: 3.675319
 >> iter 209000, loss: 3.297742
 >> iter 210000, loss: 3.508303
   Number of active neurons: 10
 >> iter 211000, loss: 3.275906
 >> iter 212000, loss: 3.366336
 >> iter 213000, loss: 3.272192
 >> iter 214000, loss: 3.504890
 >> iter 215000, loss: 3.306808
 >> iter 216000, loss: 3.568649
 >> iter 217000, loss: 3.284130
 >> iter 218000, loss: 3.441184
 >> iter 219000, loss: 3.250604
 >> iter 220000, loss: 3.521913
   Number of active neurons: 10
 >> iter 221000, loss: 3.121362
 >> iter 222000, loss: 3.501987
 >> iter 223000, loss: 3.233631
 >> iter 224000, loss: 3.323473
 >> iter 225000, loss: 3.115905
 >> iter 226000, loss: 3.386220
 >> iter 227000, loss: 3.167644
 >> iter 228000, loss: 3.273575
 >> iter 229000, loss: 3.102884
 >> iter 230000, loss: 3.222769
   Number of active neurons: 10
 >> iter 231000, loss: 3.046176
 >> iter 232000, loss: 3.416478
 >> iter 233000, loss: 3.168856
 >> iter 234000, loss: 3.216687
 >> iter 235000, loss: 3.228547
 >> iter 236000, loss: 3.505189
 >> iter 237000, loss: 3.129009
 >> iter 238000, loss: 3.374799
 >> iter 239000, loss: 3.318947
 >> iter 240000, loss: 3.291812
   Number of active neurons: 10
 >> iter 241000, loss: 3.066275
 >> iter 242000, loss: 3.321393
 >> iter 243000, loss: 3.165133
 >> iter 244000, loss: 3.283496
 >> iter 245000, loss: 3.071538
 >> iter 246000, loss: 3.296865
 >> iter 247000, loss: 3.169218
 >> iter 248000, loss: 3.415439
 >> iter 249000, loss: 3.090997
 >> iter 250000, loss: 3.476641
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 5.66188676226
   - Test - Long: 25.7137143143
   - Test - Big: 5.77694223058
   - Test - A: 8.93273781748
   - Test - B: 0.499966668889
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 19.007587
 >> iter 2000, loss: 15.415567
 >> iter 3000, loss: 13.978716
 >> iter 4000, loss: 13.434319
 >> iter 5000, loss: 13.206676
 >> iter 6000, loss: 13.116490
 >> iter 7000, loss: 13.061248
 >> iter 8000, loss: 13.047162
 >> iter 9000, loss: 13.031185
 >> iter 10000, loss: 13.021151
   Number of active neurons: 10
 >> iter 11000, loss: 13.010834
 >> iter 12000, loss: 13.019063
 >> iter 13000, loss: 13.003207
 >> iter 14000, loss: 13.013018
 >> iter 15000, loss: 13.007808
 >> iter 16000, loss: 13.012135
 >> iter 17000, loss: 12.997614
 >> iter 18000, loss: 13.005691
 >> iter 19000, loss: 12.989620
 >> iter 20000, loss: 13.006637
   Number of active neurons: 10
 >> iter 21000, loss: 12.988837
 >> iter 22000, loss: 13.000265
 >> iter 23000, loss: 12.987515
 >> iter 24000, loss: 13.003343
 >> iter 25000, loss: 12.986370
 >> iter 26000, loss: 12.996427
 >> iter 27000, loss: 12.979378
 >> iter 28000, loss: 12.994389
 >> iter 29000, loss: 12.985192
 >> iter 30000, loss: 12.991555
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 31000, loss: 12.967138
 >> iter 32000, loss: 12.982017
 >> iter 33000, loss: 12.976246
 >> iter 34000, loss: 12.965302
 >> iter 35000, loss: 12.547845
 >> iter 36000, loss: 11.841419
 >> iter 37000, loss: 11.310240
 >> iter 38000, loss: 11.101880
 >> iter 39000, loss: 10.867523
 >> iter 40000, loss: 10.802397
   Number of active neurons: 10
 >> iter 41000, loss: 10.606264
 >> iter 42000, loss: 10.426058
 >> iter 43000, loss: 10.107463
 >> iter 44000, loss: 9.833359
 >> iter 45000, loss: 9.378166
 >> iter 46000, loss: 9.198714
 >> iter 47000, loss: 8.869953
 >> iter 48000, loss: 8.837472
 >> iter 49000, loss: 8.773191
 >> iter 50000, loss: 8.894059
   Number of active neurons: 10
 >> iter 51000, loss: 8.508572
 >> iter 52000, loss: 8.263328
 >> iter 53000, loss: 7.949776
 >> iter 54000, loss: 8.037455
 >> iter 55000, loss: 7.325112
 >> iter 56000, loss: 6.997930
 >> iter 57000, loss: 6.307783
 >> iter 58000, loss: 6.235947
 >> iter 59000, loss: 4.049683
 >> iter 60000, loss: 2.572343
   Number of active neurons: 10
 >> iter 61000, loss: 1.806524
 >> iter 62000, loss: 1.456858
 >> iter 63000, loss: 1.127987
 >> iter 64000, loss: 0.963683
 >> iter 65000, loss: 0.937336
 >> iter 66000, loss: 1.015815
 >> iter 67000, loss: 0.867747
 >> iter 68000, loss: 0.731867
 >> iter 69000, loss: 0.987013
 >> iter 70000, loss: 0.773265
   Number of active neurons: 10
 >> iter 71000, loss: 0.927749
 >> iter 72000, loss: 0.865670
 >> iter 73000, loss: 0.735500
 >> iter 74000, loss: 0.636719
 >> iter 75000, loss: 0.534981
 >> iter 76000, loss: 0.519026
 >> iter 77000, loss: 0.425712
 >> iter 78000, loss: 0.428910
 >> iter 79000, loss: 0.296014
 >> iter 80000, loss: 0.201828
   Number of active neurons: 10
 >> iter 81000, loss: 0.213579
 >> iter 82000, loss: 0.341547
 >> iter 83000, loss: 0.289528
 >> iter 84000, loss: 0.642229
 >> iter 85000, loss: 0.598595
 >> iter 86000, loss: 0.367971
 >> iter 87000, loss: 0.542164
 >> iter 88000, loss: 0.300640
 >> iter 89000, loss: 0.419719
 >> iter 90000, loss: 0.376117
   Number of active neurons: 10
 >> iter 91000, loss: 0.280436
 >> iter 92000, loss: 0.243593
 >> iter 93000, loss: 0.236065
 >> iter 94000, loss: 0.152251
 >> iter 95000, loss: 0.326257
 >> iter 96000, loss: 0.343181
 >> iter 97000, loss: 0.338405
 >> iter 98000, loss: 0.187920
 >> iter 99000, loss: 0.427248
 >> iter 100000, loss: 0.229970
   Number of active neurons: 10
 >> iter 101000, loss: 0.382487
 >> iter 102000, loss: 0.380328
 >> iter 103000, loss: 0.471352
 >> iter 104000, loss: 0.286190
 >> iter 105000, loss: 0.239691
 >> iter 106000, loss: 0.498438
 >> iter 107000, loss: 0.403421
 >> iter 108000, loss: 0.328651
 >> iter 109000, loss: 0.252665
 >> iter 110000, loss: 0.345162
   Number of active neurons: 10
 >> iter 111000, loss: 0.290785
 >> iter 112000, loss: 0.285941
 >> iter 113000, loss: 0.203726
 >> iter 114000, loss: 0.328543
 >> iter 115000, loss: 0.334534
 >> iter 116000, loss: 0.311872
 >> iter 117000, loss: 0.230600
 >> iter 118000, loss: 0.194754
 >> iter 119000, loss: 0.555585
 >> iter 120000, loss: 0.331009
   Number of active neurons: 10
 >> iter 121000, loss: 0.270242
 >> iter 122000, loss: 0.239088
 >> iter 123000, loss: 0.132553
 >> iter 124000, loss: 0.261448
 >> iter 125000, loss: 0.362060
 >> iter 126000, loss: 0.513084
 >> iter 127000, loss: 0.336404
 >> iter 128000, loss: 0.148476
 >> iter 129000, loss: 0.130779
 >> iter 130000, loss: 0.130480
   Number of active neurons: 10
 >> iter 131000, loss: 0.201247
 >> iter 132000, loss: 0.155450
 >> iter 133000, loss: 0.084497
 >> iter 134000, loss: 0.050584
 >> iter 135000, loss: 0.189821
 >> iter 136000, loss: 0.144390
 >> iter 137000, loss: 0.230388
 >> iter 138000, loss: 0.136229
 >> iter 139000, loss: 0.093347
 >> iter 140000, loss: 0.070818
   Number of active neurons: 10
 >> iter 141000, loss: 0.042979
 >> iter 142000, loss: 0.034466
 >> iter 143000, loss: 0.154304
 >> iter 144000, loss: 0.069415
 >> iter 145000, loss: 0.234998
 >> iter 146000, loss: 0.222550
 >> iter 147000, loss: 0.170461
 >> iter 148000, loss: 0.083545
 >> iter 149000, loss: 0.152755
 >> iter 150000, loss: 0.266918
   Number of active neurons: 10
 >> iter 151000, loss: 0.337078
 >> iter 152000, loss: 0.195168
 >> iter 153000, loss: 0.142125
 >> iter 154000, loss: 0.092016
 >> iter 155000, loss: 0.210657
 >> iter 156000, loss: 0.098421
 >> iter 157000, loss: 0.106217
 >> iter 158000, loss: 0.111840
 >> iter 159000, loss: 0.052000
 >> iter 160000, loss: 0.034853
   Number of active neurons: 10
 >> iter 161000, loss: 0.146388
 >> iter 162000, loss: 0.252576
 >> iter 163000, loss: 0.129027
 >> iter 164000, loss: 0.059080
 >> iter 165000, loss: 0.041469
 >> iter 166000, loss: 0.024567
 >> iter 167000, loss: 0.053501
 >> iter 168000, loss: 0.035871
 >> iter 169000, loss: 0.044348
 >> iter 170000, loss: 0.081770
   Number of active neurons: 10
 >> iter 171000, loss: 0.044505
 >> iter 172000, loss: 0.050763
 >> iter 173000, loss: 0.264200
 >> iter 174000, loss: 0.208800
 >> iter 175000, loss: 0.122085
 >> iter 176000, loss: 0.091309
 >> iter 177000, loss: 0.111535
 >> iter 178000, loss: 0.050390
 >> iter 179000, loss: 0.038958
 >> iter 180000, loss: 0.021762
   Number of active neurons: 10
 >> iter 181000, loss: 0.053043
 >> iter 182000, loss: 0.026317
 >> iter 183000, loss: 0.065716
 >> iter 184000, loss: 0.030508
 >> iter 185000, loss: 0.063149
 >> iter 186000, loss: 0.188803
 >> iter 187000, loss: 0.238005
 >> iter 188000, loss: 0.160819
 >> iter 189000, loss: 0.261415
 >> iter 190000, loss: 0.162433
   Number of active neurons: 10
 >> iter 191000, loss: 0.145667
 >> iter 192000, loss: 0.063079
 >> iter 193000, loss: 0.050740
 >> iter 194000, loss: 0.095190
 >> iter 195000, loss: 0.113349
 >> iter 196000, loss: 0.050495
 >> iter 197000, loss: 0.100198
 >> iter 198000, loss: 0.180063
 >> iter 199000, loss: 0.245082
 >> iter 200000, loss: 0.191764
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.980507
 >> iter 2000, loss: 15.483486
 >> iter 3000, loss: 14.031105
 >> iter 4000, loss: 13.471392
 >> iter 5000, loss: 13.231604
 >> iter 6000, loss: 13.142118
 >> iter 7000, loss: 13.083173
 >> iter 8000, loss: 13.058334
 >> iter 9000, loss: 13.046342
 >> iter 10000, loss: 13.038673
   Number of active neurons: 9
 >> iter 11000, loss: 13.025519
 >> iter 12000, loss: 13.028131
 >> iter 13000, loss: 13.012982
 >> iter 14000, loss: 13.026124
 >> iter 15000, loss: 13.009364
 >> iter 16000, loss: 13.011926
 >> iter 17000, loss: 13.001574
 >> iter 18000, loss: 13.011299
 >> iter 19000, loss: 12.999345
 >> iter 20000, loss: 13.012673
   Number of active neurons: 10
 >> iter 21000, loss: 12.992816
 >> iter 22000, loss: 13.003629
 >> iter 23000, loss: 12.987873
 >> iter 24000, loss: 12.996690
 >> iter 25000, loss: 12.985527
 >> iter 26000, loss: 12.996963
 >> iter 27000, loss: 12.977121
 >> iter 28000, loss: 12.962375
 >> iter 29000, loss: 12.939364
 >> iter 30000, loss: 12.866779
   Number of active neurons: 10
 >> iter 31000, loss: 12.319881
 >> iter 32000, loss: 11.682326
 >> iter 33000, loss: 11.176594
 >> iter 34000, loss: 10.841464
 >> iter 35000, loss: 10.461561
 >> iter 36000, loss: 10.271484
 >> iter 37000, loss: 9.960257
 >> iter 38000, loss: 9.788526
 >> iter 39000, loss: 9.672936
 >> iter 40000, loss: 9.558476
   Number of active neurons: 10
 >> iter 41000, loss: 9.402324
 >> iter 42000, loss: 9.421639
 >> iter 43000, loss: 9.273796
 >> iter 44000, loss: 9.291614
 >> iter 45000, loss: 9.212414
 >> iter 46000, loss: 9.200608
 >> iter 47000, loss: 9.099850
 >> iter 48000, loss: 9.109879
 >> iter 49000, loss: 9.088505
 >> iter 50000, loss: 9.139465
   Number of active neurons: 10
 >> iter 51000, loss: 9.006107
 >> iter 52000, loss: 9.082371
 >> iter 53000, loss: 8.941880
 >> iter 54000, loss: 8.988128
 >> iter 55000, loss: 8.876265
 >> iter 56000, loss: 8.907663
 >> iter 57000, loss: 8.965669
 >> iter 58000, loss: 8.781078
 >> iter 59000, loss: 8.699971
 >> iter 60000, loss: 8.247790
   Number of active neurons: 10
 >> iter 61000, loss: 7.894048
 >> iter 62000, loss: 7.963474
 >> iter 63000, loss: 7.607138
 >> iter 64000, loss: 7.210280
 >> iter 65000, loss: 6.410423
 >> iter 66000, loss: 5.466793
 >> iter 67000, loss: 4.596181
 >> iter 68000, loss: 4.386861
 >> iter 69000, loss: 3.741153
 >> iter 70000, loss: 3.770580
   Number of active neurons: 10
 >> iter 71000, loss: 3.567794
 >> iter 72000, loss: 3.747553
 >> iter 73000, loss: 3.414922
 >> iter 74000, loss: 3.453715
 >> iter 75000, loss: 3.165574
 >> iter 76000, loss: 3.063820
 >> iter 77000, loss: 2.847523
 >> iter 78000, loss: 2.899119
 >> iter 79000, loss: 2.955245
 >> iter 80000, loss: 3.040257
   Number of active neurons: 10
 >> iter 81000, loss: 2.947788
 >> iter 82000, loss: 2.929210
 >> iter 83000, loss: 2.818024
 >> iter 84000, loss: 2.708487
 >> iter 85000, loss: 2.573857
 >> iter 86000, loss: 2.749607
 >> iter 87000, loss: 2.550429
 >> iter 88000, loss: 2.602363
 >> iter 89000, loss: 2.687822
 >> iter 90000, loss: 2.877143
   Number of active neurons: 10
 >> iter 91000, loss: 2.730212
 >> iter 92000, loss: 2.835379
 >> iter 93000, loss: 2.644315
 >> iter 94000, loss: 2.651487
 >> iter 95000, loss: 2.656543
 >> iter 96000, loss: 2.764098
 >> iter 97000, loss: 2.589096
 >> iter 98000, loss: 2.900753
 >> iter 99000, loss: 2.791714
 >> iter 100000, loss: 2.681650
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 4.62790744185
   - Test - Long: 24.4337783111
   - Test - Big: 4.71995280047
   - Test - A: 0.493300446637
   - Test - B: 0.693287114192
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 18.981980
 >> iter 2000, loss: 15.415431
 >> iter 3000, loss: 13.975037
 >> iter 4000, loss: 13.430508
 >> iter 5000, loss: 13.186921
 >> iter 6000, loss: 13.090921
 >> iter 7000, loss: 13.046161
 >> iter 8000, loss: 13.044516
 >> iter 9000, loss: 13.024738
 >> iter 10000, loss: 13.022194
   Number of active neurons: 10
 >> iter 11000, loss: 13.008282
 >> iter 12000, loss: 13.011066
 >> iter 13000, loss: 12.996383
 >> iter 14000, loss: 12.995496
 >> iter 15000, loss: 12.983592
 >> iter 16000, loss: 12.987696
 >> iter 17000, loss: 12.985013
 >> iter 18000, loss: 12.992094
 >> iter 19000, loss: 12.973819
 >> iter 20000, loss: 12.984751
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 21000, loss: 12.955491
 >> iter 22000, loss: 12.782940
 >> iter 23000, loss: 12.019721
 >> iter 24000, loss: 11.524825
 >> iter 25000, loss: 11.146576
 >> iter 26000, loss: 11.001797
 >> iter 27000, loss: 10.837062
 >> iter 28000, loss: 10.749753
 >> iter 29000, loss: 10.473931
 >> iter 30000, loss: 10.274545
   Number of active neurons: 10
 >> iter 31000, loss: 9.954767
 >> iter 32000, loss: 9.679646
 >> iter 33000, loss: 9.326201
 >> iter 34000, loss: 9.294137
 >> iter 35000, loss: 9.086940
 >> iter 36000, loss: 8.957729
 >> iter 37000, loss: 8.789073
 >> iter 38000, loss: 8.753970
 >> iter 39000, loss: 8.396751
 >> iter 40000, loss: 8.385086
   Number of active neurons: 10
 >> iter 41000, loss: 7.993104
 >> iter 42000, loss: 7.977042
 >> iter 43000, loss: 7.643105
 >> iter 44000, loss: 7.558652
 >> iter 45000, loss: 7.287030
 >> iter 46000, loss: 7.331853
 >> iter 47000, loss: 6.687641
 >> iter 48000, loss: 6.485905
 >> iter 49000, loss: 6.267077
 >> iter 50000, loss: 7.855583
   Number of active neurons: 10
 >> iter 51000, loss: 8.385390
 >> iter 52000, loss: 7.705333
 >> iter 53000, loss: 7.019434
 >> iter 54000, loss: 6.537770
 >> iter 55000, loss: 5.261036
 >> iter 56000, loss: 5.169190
 >> iter 57000, loss: 5.041903
 >> iter 58000, loss: 4.713449
 >> iter 59000, loss: 4.681079
 >> iter 60000, loss: 4.349283
   Number of active neurons: 10
 >> iter 61000, loss: 4.155667
 >> iter 62000, loss: 4.034442
 >> iter 63000, loss: 3.891553
 >> iter 64000, loss: 3.597016
 >> iter 65000, loss: 3.460910
 >> iter 66000, loss: 3.645582
 >> iter 67000, loss: 3.509399
 >> iter 68000, loss: 3.361576
 >> iter 69000, loss: 3.481948
 >> iter 70000, loss: 3.035697
   Number of active neurons: 10
 >> iter 71000, loss: 3.228538
 >> iter 72000, loss: 3.013682
 >> iter 73000, loss: 2.396723
 >> iter 74000, loss: 2.724913
 >> iter 75000, loss: 2.468007
 >> iter 76000, loss: 2.206400
 >> iter 77000, loss: 1.751686
 >> iter 78000, loss: 2.074530
 >> iter 79000, loss: 1.787839
 >> iter 80000, loss: 1.657554
   Number of active neurons: 10
 >> iter 81000, loss: 1.515564
 >> iter 82000, loss: 1.326084
 >> iter 83000, loss: 1.503938
 >> iter 84000, loss: 1.788502
 >> iter 85000, loss: 1.502856
 >> iter 86000, loss: 1.672877
 >> iter 87000, loss: 1.171423
 >> iter 88000, loss: 1.385614
 >> iter 89000, loss: 1.317417
 >> iter 90000, loss: 1.268126
   Number of active neurons: 10
 >> iter 91000, loss: 0.929965
 >> iter 92000, loss: 1.801025
 >> iter 93000, loss: 1.311895
 >> iter 94000, loss: 1.228494
 >> iter 95000, loss: 0.843450
 >> iter 96000, loss: 0.997734
 >> iter 97000, loss: 0.744956
 >> iter 98000, loss: 1.253029
 >> iter 99000, loss: 1.007689
 >> iter 100000, loss: 0.867960
   Number of active neurons: 10
 >> iter 101000, loss: 1.047493
 >> iter 102000, loss: 0.809705
 >> iter 103000, loss: 0.765667
 >> iter 104000, loss: 0.620829
 >> iter 105000, loss: 0.855756
 >> iter 106000, loss: 1.134646
 >> iter 107000, loss: 1.058683
 >> iter 108000, loss: 0.847840
 >> iter 109000, loss: 1.018318
 >> iter 110000, loss: 1.488045
   Number of active neurons: 10
 >> iter 111000, loss: 1.210894
 >> iter 112000, loss: 0.882183
 >> iter 113000, loss: 0.667615
 >> iter 114000, loss: 0.859351
 >> iter 115000, loss: 0.677360
 >> iter 116000, loss: 0.944774
 >> iter 117000, loss: 0.980858
 >> iter 118000, loss: 0.740735
 >> iter 119000, loss: 0.600945
 >> iter 120000, loss: 0.565074
   Number of active neurons: 10
 >> iter 121000, loss: 0.381463
 >> iter 122000, loss: 0.573424
 >> iter 123000, loss: 0.598137
 >> iter 124000, loss: 0.523835
 >> iter 125000, loss: 0.581416
 >> iter 126000, loss: 0.373559
 >> iter 127000, loss: 0.559162
 >> iter 128000, loss: 0.485819
 >> iter 129000, loss: 0.455557
 >> iter 130000, loss: 0.773684
   Number of active neurons: 10
 >> iter 131000, loss: 0.511925
 >> iter 132000, loss: 0.949937
 >> iter 133000, loss: 0.695877
 >> iter 134000, loss: 0.504433
 >> iter 135000, loss: 0.360379
 >> iter 136000, loss: 0.556466
 >> iter 137000, loss: 0.352218
 >> iter 138000, loss: 0.332022
 >> iter 139000, loss: 0.485787
 >> iter 140000, loss: 0.602947
   Number of active neurons: 10
 >> iter 141000, loss: 0.459618
 >> iter 142000, loss: 0.673796
 >> iter 143000, loss: 0.430213
 >> iter 144000, loss: 0.229151
 >> iter 145000, loss: 0.270866
 >> iter 146000, loss: 0.733656
 >> iter 147000, loss: 0.457149
 >> iter 148000, loss: 0.561202
 >> iter 149000, loss: 0.356277
 >> iter 150000, loss: 0.460221
   Number of active neurons: 10
 >> iter 151000, loss: 0.337518
 >> iter 152000, loss: 0.693419
 >> iter 153000, loss: 0.602378
 >> iter 154000, loss: 0.501055
 >> iter 155000, loss: 0.713690
 >> iter 156000, loss: 0.499253
 >> iter 157000, loss: 0.407817
 >> iter 158000, loss: 0.283553
 >> iter 159000, loss: 0.822555
 >> iter 160000, loss: 0.645684
   Number of active neurons: 10
 >> iter 161000, loss: 0.732715
 >> iter 162000, loss: 0.694141
 >> iter 163000, loss: 0.509380
 >> iter 164000, loss: 0.617174
 >> iter 165000, loss: 0.298444
 >> iter 166000, loss: 0.515559
 >> iter 167000, loss: 0.421059
 >> iter 168000, loss: 0.281493
 >> iter 169000, loss: 0.191155
 >> iter 170000, loss: 0.355302
   Number of active neurons: 10
 >> iter 171000, loss: 0.304356
 >> iter 172000, loss: 0.187376
 >> iter 173000, loss: 0.227272
 >> iter 174000, loss: 0.221164
 >> iter 175000, loss: 0.218727
 >> iter 176000, loss: 0.184569
 >> iter 177000, loss: 0.173937
 >> iter 178000, loss: 0.216674
 >> iter 179000, loss: 0.227384
 >> iter 180000, loss: 0.129414
   Number of active neurons: 10
 >> iter 181000, loss: 0.221258
 >> iter 182000, loss: 0.203169
 >> iter 183000, loss: 0.314035
 >> iter 184000, loss: 0.628198
 >> iter 185000, loss: 0.302936
 >> iter 186000, loss: 0.231935
 >> iter 187000, loss: 0.127908
 >> iter 188000, loss: 0.112987
 >> iter 189000, loss: 0.112304
 >> iter 190000, loss: 0.337836
   Number of active neurons: 10
 >> iter 191000, loss: 0.544460
 >> iter 192000, loss: 0.255302
 >> iter 193000, loss: 0.201557
 >> iter 194000, loss: 0.160470
 >> iter 195000, loss: 0.211951
 >> iter 196000, loss: 0.190761
 >> iter 197000, loss: 0.201081
 >> iter 198000, loss: 0.158739
 >> iter 199000, loss: 0.155807
 >> iter 200000, loss: 0.167472
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0079999200008
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.001989
 >> iter 2000, loss: 15.432425
 >> iter 3000, loss: 13.984888
 >> iter 4000, loss: 13.424417
 >> iter 5000, loss: 13.187264
 >> iter 6000, loss: 13.114394
 >> iter 7000, loss: 13.078924
 >> iter 8000, loss: 13.061684
 >> iter 9000, loss: 13.049518
 >> iter 10000, loss: 13.052161
   Number of active neurons: 10
 >> iter 11000, loss: 13.026275
 >> iter 12000, loss: 13.030428
 >> iter 13000, loss: 13.020103
 >> iter 14000, loss: 13.021585
 >> iter 15000, loss: 13.017075
 >> iter 16000, loss: 13.026018
 >> iter 17000, loss: 13.024349
 >> iter 18000, loss: 13.020975
 >> iter 19000, loss: 13.012089
 >> iter 20000, loss: 13.015666
   Number of active neurons: 9
 >> iter 21000, loss: 13.015878
 >> iter 22000, loss: 13.025968
 >> iter 23000, loss: 13.007916
 >> iter 24000, loss: 13.014592
 >> iter 25000, loss: 12.554581
 >> iter 26000, loss: 11.842936
 >> iter 27000, loss: 11.305059
 >> iter 28000, loss: 11.097882
 >> iter 29000, loss: 10.868711
 >> iter 30000, loss: 10.780375
   Number of active neurons: 10
 >> iter 31000, loss: 10.644306
 >> iter 32000, loss: 10.626627
 >> iter 33000, loss: 10.518505
 >> iter 34000, loss: 10.509992
 >> iter 35000, loss: 10.438881
 >> iter 36000, loss: 10.462420
 >> iter 37000, loss: 10.382510
 >> iter 38000, loss: 10.372824
 >> iter 39000, loss: 10.254860
 >> iter 40000, loss: 10.199919
   Number of active neurons: 10
 >> iter 41000, loss: 9.809606
 >> iter 42000, loss: 9.517576
 >> iter 43000, loss: 9.133118
 >> iter 44000, loss: 8.999096
 >> iter 45000, loss: 8.699360
 >> iter 46000, loss: 8.488640
 >> iter 47000, loss: 8.120852
 >> iter 48000, loss: 7.860659
 >> iter 49000, loss: 7.469796
 >> iter 50000, loss: 7.041980
   Number of active neurons: 10
 >> iter 51000, loss: 6.481164
 >> iter 52000, loss: 5.597787
 >> iter 53000, loss: 5.454155
 >> iter 54000, loss: 4.877617
 >> iter 55000, loss: 4.759713
 >> iter 56000, loss: 4.768363
 >> iter 57000, loss: 4.576642
 >> iter 58000, loss: 4.125959
 >> iter 59000, loss: 4.084182
 >> iter 60000, loss: 3.131929
   Number of active neurons: 10
 >> iter 61000, loss: 1.696062
 >> iter 62000, loss: 1.407626
 >> iter 63000, loss: 1.016765
 >> iter 64000, loss: 0.809866
 >> iter 65000, loss: 0.711374
 >> iter 66000, loss: 0.416941
 >> iter 67000, loss: 0.544431
 >> iter 68000, loss: 0.369361
 >> iter 69000, loss: 0.768071
 >> iter 70000, loss: 0.765393
   Number of active neurons: 10
 >> iter 71000, loss: 0.486752
 >> iter 72000, loss: 0.275739
 >> iter 73000, loss: 0.341885
 >> iter 74000, loss: 0.347048
 >> iter 75000, loss: 0.271641
 >> iter 76000, loss: 0.326980
 >> iter 77000, loss: 0.485581
 >> iter 78000, loss: 0.404697
 >> iter 79000, loss: 0.243125
 >> iter 80000, loss: 0.207385
   Number of active neurons: 10
 >> iter 81000, loss: 0.402923
 >> iter 82000, loss: 0.176889
 >> iter 83000, loss: 0.368829
 >> iter 84000, loss: 0.314178
 >> iter 85000, loss: 0.341771
 >> iter 86000, loss: 0.382721
 >> iter 87000, loss: 0.269136
 >> iter 88000, loss: 0.280280
 >> iter 89000, loss: 0.158293
 >> iter 90000, loss: 0.305131
   Number of active neurons: 10
 >> iter 91000, loss: 0.480145
 >> iter 92000, loss: 0.336882
 >> iter 93000, loss: 0.160514
 >> iter 94000, loss: 0.192610
 >> iter 95000, loss: 0.221680
 >> iter 96000, loss: 0.156301
 >> iter 97000, loss: 0.134544
 >> iter 98000, loss: 0.194520
 >> iter 99000, loss: 0.287287
 >> iter 100000, loss: 0.314877
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.985128
 >> iter 2000, loss: 15.467270
 >> iter 3000, loss: 14.034400
 >> iter 4000, loss: 13.478661
 >> iter 5000, loss: 13.242365
 >> iter 6000, loss: 13.155141
 >> iter 7000, loss: 13.100376
 >> iter 8000, loss: 13.085453
 >> iter 9000, loss: 13.065847
 >> iter 10000, loss: 13.073867
   Number of active neurons: 10
 >> iter 11000, loss: 13.057395
 >> iter 12000, loss: 13.047859
 >> iter 13000, loss: 13.039900
 >> iter 14000, loss: 13.044486
 >> iter 15000, loss: 13.039827
 >> iter 16000, loss: 13.040157
 >> iter 17000, loss: 13.039029
 >> iter 18000, loss: 13.039776
 >> iter 19000, loss: 13.023540
 >> iter 20000, loss: 13.031255
   Number of active neurons: 10
 >> iter 21000, loss: 13.021203
 >> iter 22000, loss: 13.030239
 >> iter 23000, loss: 13.015440
 >> iter 24000, loss: 13.027422
 >> iter 25000, loss: 13.014304
 >> iter 26000, loss: 13.030798
 >> iter 27000, loss: 13.015223
 >> iter 28000, loss: 13.025922
 >> iter 29000, loss: 13.016273
 >> iter 30000, loss: 13.028753
   Number of active neurons: 10
 >> iter 31000, loss: 13.013922
 >> iter 32000, loss: 13.029725
 >> iter 33000, loss: 13.020435
 >> iter 34000, loss: 13.028363
 >> iter 35000, loss: 13.015423
 >> iter 36000, loss: 13.021448
 >> iter 37000, loss: 13.012280
 >> iter 38000, loss: 13.023111
 >> iter 39000, loss: 13.010010
 >> iter 40000, loss: 13.024187
   Number of active neurons: 10
 >> iter 41000, loss: 13.012407
 >> iter 42000, loss: 13.028033
 >> iter 43000, loss: 13.005583
 >> iter 44000, loss: 13.025561
 >> iter 45000, loss: 13.007283
 >> iter 46000, loss: 13.032321
 >> iter 47000, loss: 13.011242
 >> iter 48000, loss: 13.033316
 >> iter 49000, loss: 13.007113
 >> iter 50000, loss: 13.030059
   Number of active neurons: 10
 >> iter 51000, loss: 13.009541
 >> iter 52000, loss: 13.032537
 >> iter 53000, loss: 13.006399
 >> iter 54000, loss: 13.032059
 >> iter 55000, loss: 13.003230
 >> iter 56000, loss: 13.025711
 >> iter 57000, loss: 12.999987
 >> iter 58000, loss: 13.026847
 >> iter 59000, loss: 13.001980
 >> iter 60000, loss: 13.026941
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 61000, loss: 13.000835
 >> iter 62000, loss: 13.026777
 >> iter 63000, loss: 13.002716
 >> iter 64000, loss: 13.032053
 >> iter 65000, loss: 13.007703
 >> iter 66000, loss: 13.033509
 >> iter 67000, loss: 13.003752
 >> iter 68000, loss: 13.024830
 >> iter 69000, loss: 13.005441
 >> iter 70000, loss: 13.030670
   Number of active neurons: 10
 >> iter 71000, loss: 13.007355
 >> iter 72000, loss: 13.030178
 >> iter 73000, loss: 13.004090
 >> iter 74000, loss: 13.021743
 >> iter 75000, loss: 12.984555
 >> iter 76000, loss: 12.988005
 >> iter 77000, loss: 12.885204
 >> iter 78000, loss: 12.222386
 >> iter 79000, loss: 11.495019
 >> iter 80000, loss: 11.239383
   Number of active neurons: 10
 >> iter 81000, loss: 10.944758
 >> iter 82000, loss: 10.909891
 >> iter 83000, loss: 10.694006
 >> iter 84000, loss: 10.670188
 >> iter 85000, loss: 10.538082
 >> iter 86000, loss: 10.585972
 >> iter 87000, loss: 10.472580
 >> iter 88000, loss: 10.539342
 >> iter 89000, loss: 10.446240
 >> iter 90000, loss: 10.474805
   Number of active neurons: 10
 >> iter 91000, loss: 10.353454
 >> iter 92000, loss: 10.367004
 >> iter 93000, loss: 10.203126
 >> iter 94000, loss: 10.233384
 >> iter 95000, loss: 10.093995
 >> iter 96000, loss: 10.127874
 >> iter 97000, loss: 10.046007
 >> iter 98000, loss: 10.100695
 >> iter 99000, loss: 10.036428
 >> iter 100000, loss: 10.096120
   Number of active neurons: 10
 >> iter 101000, loss: 9.999437
 >> iter 102000, loss: 10.069500
 >> iter 103000, loss: 9.960122
 >> iter 104000, loss: 10.075638
 >> iter 105000, loss: 9.943369
 >> iter 106000, loss: 9.994214
 >> iter 107000, loss: 9.914805
 >> iter 108000, loss: 10.004397
 >> iter 109000, loss: 9.916872
 >> iter 110000, loss: 10.007635
   Number of active neurons: 10
 >> iter 111000, loss: 9.897600
 >> iter 112000, loss: 9.978937
 >> iter 113000, loss: 9.900648
 >> iter 114000, loss: 9.960660
 >> iter 115000, loss: 9.903791
 >> iter 116000, loss: 9.964838
 >> iter 117000, loss: 9.871060
 >> iter 118000, loss: 9.957720
 >> iter 119000, loss: 9.861851
 >> iter 120000, loss: 9.957688
   Number of active neurons: 10
 >> iter 121000, loss: 9.872516
 >> iter 122000, loss: 9.946824
 >> iter 123000, loss: 9.888090
 >> iter 124000, loss: 9.956756
 >> iter 125000, loss: 9.842762
 >> iter 126000, loss: 9.968148
 >> iter 127000, loss: 9.872390
 >> iter 128000, loss: 9.963591
 >> iter 129000, loss: 9.872769
 >> iter 130000, loss: 9.944402
   Number of active neurons: 10
 >> iter 131000, loss: 9.834568
 >> iter 132000, loss: 9.913820
 >> iter 133000, loss: 9.838268
 >> iter 134000, loss: 9.913574
 >> iter 135000, loss: 9.853245
 >> iter 136000, loss: 9.962493
 >> iter 137000, loss: 9.819049
 >> iter 138000, loss: 9.919443
 >> iter 139000, loss: 9.869849
 >> iter 140000, loss: 9.888395
   Number of active neurons: 10
 >> iter 141000, loss: 9.698156
 >> iter 142000, loss: 9.684740
 >> iter 143000, loss: 9.453258
 >> iter 144000, loss: 9.359946
 >> iter 145000, loss: 9.174023
 >> iter 146000, loss: 9.154392
 >> iter 147000, loss: 8.913021
 >> iter 148000, loss: 8.903451
 >> iter 149000, loss: 8.710263
 >> iter 150000, loss: 8.663074
   Number of active neurons: 10
 >> iter 151000, loss: 8.493825
 >> iter 152000, loss: 8.538916
 >> iter 153000, loss: 8.522544
 >> iter 154000, loss: 8.488666
 >> iter 155000, loss: 8.330456
 >> iter 156000, loss: 8.434484
 >> iter 157000, loss: 8.239068
 >> iter 158000, loss: 8.353226
 >> iter 159000, loss: 8.225562
 >> iter 160000, loss: 8.248076
   Number of active neurons: 10
 >> iter 161000, loss: 8.171898
 >> iter 162000, loss: 8.296757
 >> iter 163000, loss: 8.170094
 >> iter 164000, loss: 8.272730
 >> iter 165000, loss: 8.239754
 >> iter 166000, loss: 8.304952
 >> iter 167000, loss: 8.168858
 >> iter 168000, loss: 8.203247
 >> iter 169000, loss: 8.154753
 >> iter 170000, loss: 8.239405
   Number of active neurons: 10
 >> iter 171000, loss: 8.092325
 >> iter 172000, loss: 8.193027
 >> iter 173000, loss: 8.083508
 >> iter 174000, loss: 8.159503
 >> iter 175000, loss: 8.044725
 >> iter 176000, loss: 8.158137
 >> iter 177000, loss: 7.972346
 >> iter 178000, loss: 8.017027
 >> iter 179000, loss: 7.865664
 >> iter 180000, loss: 7.961702
   Number of active neurons: 10
 >> iter 181000, loss: 7.909180
 >> iter 182000, loss: 7.861529
 >> iter 183000, loss: 7.796569
 >> iter 184000, loss: 7.934850
 >> iter 185000, loss: 7.710848
 >> iter 186000, loss: 7.752676
 >> iter 187000, loss: 8.031863
 >> iter 188000, loss: 8.615244
 >> iter 189000, loss: 8.173118
 >> iter 190000, loss: 7.628534
   Number of active neurons: 10
 >> iter 191000, loss: 7.123006
 >> iter 192000, loss: 7.043237
 >> iter 193000, loss: 7.029288
 >> iter 194000, loss: 6.791175
 >> iter 195000, loss: 6.806833
 >> iter 196000, loss: 6.801209
 >> iter 197000, loss: 6.441827
 >> iter 198000, loss: 6.148012
 >> iter 199000, loss: 5.808925
 >> iter 200000, loss: 5.317303
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 7.53984920302
   - Test - Long: 26.803659817
   - Test - Big: 7.30392696073
   - Test - A: 0.10665955603
   - Test - B: 7.29284714352
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.045643
 >> iter 2000, loss: 15.500500
 >> iter 3000, loss: 14.023876
 >> iter 4000, loss: 13.447345
 >> iter 5000, loss: 13.205836
 >> iter 6000, loss: 13.121512
 >> iter 7000, loss: 13.056472
 >> iter 8000, loss: 13.038474
 >> iter 9000, loss: 13.014904
 >> iter 10000, loss: 13.020975
   Number of active neurons: 10
 >> iter 11000, loss: 13.005418
 >> iter 12000, loss: 13.000652
 >> iter 13000, loss: 12.980100
 >> iter 14000, loss: 13.003047
 >> iter 15000, loss: 12.988198
 >> iter 16000, loss: 12.992312
 >> iter 17000, loss: 12.982226
 >> iter 18000, loss: 12.989424
 >> iter 19000, loss: 12.979491
 >> iter 20000, loss: 12.991297
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 21000, loss: 12.978412
 >> iter 22000, loss: 12.989977
 >> iter 23000, loss: 12.972728
 >> iter 24000, loss: 12.987647
 >> iter 25000, loss: 12.972033
 >> iter 26000, loss: 12.967809
 >> iter 27000, loss: 12.951974
 >> iter 28000, loss: 12.927866
 >> iter 29000, loss: 12.544088
 >> iter 30000, loss: 11.819669
   Number of active neurons: 10
 >> iter 31000, loss: 11.231291
 >> iter 32000, loss: 10.962523
 >> iter 33000, loss: 10.686459
 >> iter 34000, loss: 10.549513
 >> iter 35000, loss: 10.314742
 >> iter 36000, loss: 10.133170
 >> iter 37000, loss: 9.796147
 >> iter 38000, loss: 9.587051
 >> iter 39000, loss: 9.151269
 >> iter 40000, loss: 8.171432
   Number of active neurons: 10
 >> iter 41000, loss: 6.713324
 >> iter 42000, loss: 3.877572
 >> iter 43000, loss: 2.510756
 >> iter 44000, loss: 2.067288
 >> iter 45000, loss: 1.274722
 >> iter 46000, loss: 1.288598
 >> iter 47000, loss: 0.892340
 >> iter 48000, loss: 0.873156
 >> iter 49000, loss: 0.943370
 >> iter 50000, loss: 0.832057
   Number of active neurons: 10
 >> iter 51000, loss: 0.562385
 >> iter 52000, loss: 0.446453
 >> iter 53000, loss: 0.382658
 >> iter 54000, loss: 0.486730
 >> iter 55000, loss: 0.425336
 >> iter 56000, loss: 0.548483
 >> iter 57000, loss: 0.312966
 >> iter 58000, loss: 0.318787
 >> iter 59000, loss: 0.255792
 >> iter 60000, loss: 0.293542
   Number of active neurons: 10
 >> iter 61000, loss: 0.492548
 >> iter 62000, loss: 0.363806
 >> iter 63000, loss: 0.473018
 >> iter 64000, loss: 0.552875
 >> iter 65000, loss: 0.422792
 >> iter 66000, loss: 0.246441
 >> iter 67000, loss: 0.316861
 >> iter 68000, loss: 0.458260
 >> iter 69000, loss: 0.289498
 >> iter 70000, loss: 0.300704
   Number of active neurons: 10
 >> iter 71000, loss: 0.388406
 >> iter 72000, loss: 0.253853
 >> iter 73000, loss: 0.132360
 >> iter 74000, loss: 0.100779
 >> iter 75000, loss: 0.149598
 >> iter 76000, loss: 0.271818
 >> iter 77000, loss: 0.152724
 >> iter 78000, loss: 0.230125
 >> iter 79000, loss: 0.155412
 >> iter 80000, loss: 0.073054
   Number of active neurons: 10
 >> iter 81000, loss: 0.083273
 >> iter 82000, loss: 0.041351
 >> iter 83000, loss: 0.024686
 >> iter 84000, loss: 0.060135
 >> iter 85000, loss: 0.165864
 >> iter 86000, loss: 0.175627
 >> iter 87000, loss: 0.076437
 >> iter 88000, loss: 0.059235
 >> iter 89000, loss: 0.066403
 >> iter 90000, loss: 0.034206
   Number of active neurons: 10
 >> iter 91000, loss: 0.026226
 >> iter 92000, loss: 0.074453
 >> iter 93000, loss: 0.087574
 >> iter 94000, loss: 0.107953
 >> iter 95000, loss: 0.170572
 >> iter 96000, loss: 0.361806
 >> iter 97000, loss: 0.170411
 >> iter 98000, loss: 0.120090
 >> iter 99000, loss: 0.074824
 >> iter 100000, loss: 0.271989
   Number of active neurons: 10
 >> iter 101000, loss: 0.196716
 >> iter 102000, loss: 0.243322
 >> iter 103000, loss: 0.112169
 >> iter 104000, loss: 0.084605
 >> iter 105000, loss: 0.085906
 >> iter 106000, loss: 0.120914
 >> iter 107000, loss: 0.060674
 >> iter 108000, loss: 0.078583
 >> iter 109000, loss: 0.038763
 >> iter 110000, loss: 0.179316
   Number of active neurons: 10
 >> iter 111000, loss: 0.096576
 >> iter 112000, loss: 0.068421
 >> iter 113000, loss: 0.045406
 >> iter 114000, loss: 0.347148
 >> iter 115000, loss: 0.201027
 >> iter 116000, loss: 0.115571
 >> iter 117000, loss: 0.163058
 >> iter 118000, loss: 0.176053
 >> iter 119000, loss: 0.098914
 >> iter 120000, loss: 0.229210
   Number of active neurons: 10
 >> iter 121000, loss: 0.099675
 >> iter 122000, loss: 0.162296
 >> iter 123000, loss: 0.094457
 >> iter 124000, loss: 0.223715
 >> iter 125000, loss: 0.092330
 >> iter 126000, loss: 0.065968
 >> iter 127000, loss: 0.031554
 >> iter 128000, loss: 0.050587
 >> iter 129000, loss: 0.078949
 >> iter 130000, loss: 0.036620
   Number of active neurons: 10
 >> iter 131000, loss: 0.088425
 >> iter 132000, loss: 0.194754
 >> iter 133000, loss: 0.105986
 >> iter 134000, loss: 0.138267
 >> iter 135000, loss: 0.206331
 >> iter 136000, loss: 0.112702
 >> iter 137000, loss: 0.056826
 >> iter 138000, loss: 0.044468
 >> iter 139000, loss: 0.211916
 >> iter 140000, loss: 0.148449
   Number of active neurons: 10
 >> iter 141000, loss: 0.110646
 >> iter 142000, loss: 0.065878
 >> iter 143000, loss: 0.038520
 >> iter 144000, loss: 0.209747
 >> iter 145000, loss: 0.089927
 >> iter 146000, loss: 0.074592
 >> iter 147000, loss: 0.134764
 >> iter 148000, loss: 0.057486
 >> iter 149000, loss: 0.074463
 >> iter 150000, loss: 0.034856
   Number of active neurons: 10
 >> iter 151000, loss: 0.065219
 >> iter 152000, loss: 0.096187
 >> iter 153000, loss: 0.071203
 >> iter 154000, loss: 0.034585
 >> iter 155000, loss: 0.020118
 >> iter 156000, loss: 0.074616
 >> iter 157000, loss: 0.046977
 >> iter 158000, loss: 0.059826
 >> iter 159000, loss: 0.079943
 >> iter 160000, loss: 0.034434
   Number of active neurons: 10
 >> iter 161000, loss: 0.018923
 >> iter 162000, loss: 0.017135
 >> iter 163000, loss: 0.020786
 >> iter 164000, loss: 0.142379
 >> iter 165000, loss: 0.057707
 >> iter 166000, loss: 0.240998
 >> iter 167000, loss: 0.108140
 >> iter 168000, loss: 0.045852
 >> iter 169000, loss: 0.374919
 >> iter 170000, loss: 0.198364
   Number of active neurons: 10
 >> iter 171000, loss: 0.097319
 >> iter 172000, loss: 0.099415
 >> iter 173000, loss: 0.073896
 >> iter 174000, loss: 0.066359
 >> iter 175000, loss: 0.060501
 >> iter 176000, loss: 0.028175
 >> iter 177000, loss: 0.015769
 >> iter 178000, loss: 0.074913
 >> iter 179000, loss: 0.085912
 >> iter 180000, loss: 0.045864
   Number of active neurons: 10
 >> iter 181000, loss: 0.030951
 >> iter 182000, loss: 0.016169
 >> iter 183000, loss: 0.010214
 >> iter 184000, loss: 0.012092
 >> iter 185000, loss: 0.032897
 >> iter 186000, loss: 0.035590
 >> iter 187000, loss: 0.023713
 >> iter 188000, loss: 0.017424
 >> iter 189000, loss: 0.009995
 >> iter 190000, loss: 0.007314
   Number of active neurons: 10
 >> iter 191000, loss: 0.055565
 >> iter 192000, loss: 0.024828
 >> iter 193000, loss: 0.012521
 >> iter 194000, loss: 0.024752
 >> iter 195000, loss: 0.275619
 >> iter 196000, loss: 0.110203
 >> iter 197000, loss: 0.068915
 >> iter 198000, loss: 0.029680
 >> iter 199000, loss: 0.016854
 >> iter 200000, loss: 0.014868
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 19.029564
 >> iter 2000, loss: 15.420533
 >> iter 3000, loss: 13.984559
 >> iter 4000, loss: 13.444336
 >> iter 5000, loss: 13.201872
 >> iter 6000, loss: 13.120581
 >> iter 7000, loss: 13.067828
 >> iter 8000, loss: 13.038172
 >> iter 9000, loss: 13.037849
 >> iter 10000, loss: 13.040921
   Number of active neurons: 10
 >> iter 11000, loss: 13.017569
 >> iter 12000, loss: 13.026237
 >> iter 13000, loss: 13.012065
 >> iter 14000, loss: 13.023990
 >> iter 15000, loss: 13.010336
 >> iter 16000, loss: 13.007153
 >> iter 17000, loss: 12.994654
 >> iter 18000, loss: 12.983314
 >> iter 19000, loss: 12.565074
 >> iter 20000, loss: 11.904689
   Number of active neurons: 10
 >> iter 21000, loss: 11.361316
 >> iter 22000, loss: 11.118177
 >> iter 23000, loss: 10.850170
 >> iter 24000, loss: 10.648478
 >> iter 25000, loss: 10.328896
 >> iter 26000, loss: 10.149592
 >> iter 27000, loss: 9.864175
 >> iter 28000, loss: 9.726859
 >> iter 29000, loss: 9.520968
 >> iter 30000, loss: 9.411877
   Number of active neurons: 10
 >> iter 31000, loss: 9.253821
 >> iter 32000, loss: 9.197315
 >> iter 33000, loss: 9.185672
 >> iter 34000, loss: 9.078781
 >> iter 35000, loss: 8.825793
 >> iter 36000, loss: 8.741423
 >> iter 37000, loss: 8.389460
 >> iter 38000, loss: 8.329182
 >> iter 39000, loss: 8.186301
 >> iter 40000, loss: 8.128936
   Number of active neurons: 10
 >> iter 41000, loss: 7.962360
 >> iter 42000, loss: 7.863571
 >> iter 43000, loss: 7.530118
 >> iter 44000, loss: 7.573700
 >> iter 45000, loss: 7.063789
 >> iter 46000, loss: 7.219167
 >> iter 47000, loss: 6.935768
 >> iter 48000, loss: 6.917143
 >> iter 49000, loss: 6.850954
 >> iter 50000, loss: 6.844162
   Number of active neurons: 10
 >> iter 51000, loss: 6.567695
 >> iter 52000, loss: 6.756193
 >> iter 53000, loss: 6.405952
 >> iter 54000, loss: 6.732773
 >> iter 55000, loss: 6.610349
 >> iter 56000, loss: 6.882849
 >> iter 57000, loss: 6.843352
 >> iter 58000, loss: 6.811561
 >> iter 59000, loss: 6.459694
 >> iter 60000, loss: 5.794097
   Number of active neurons: 10
 >> iter 61000, loss: 5.918639
 >> iter 62000, loss: 5.784958
 >> iter 63000, loss: 5.507155
 >> iter 64000, loss: 5.299144
 >> iter 65000, loss: 5.185022
 >> iter 66000, loss: 5.216712
 >> iter 67000, loss: 5.303909
 >> iter 68000, loss: 5.289845
 >> iter 69000, loss: 5.055912
 >> iter 70000, loss: 5.153596
   Number of active neurons: 10
 >> iter 71000, loss: 4.996591
 >> iter 72000, loss: 5.397800
 >> iter 73000, loss: 4.725791
 >> iter 74000, loss: 4.181031
 >> iter 75000, loss: 3.679971
 >> iter 76000, loss: 3.824188
 >> iter 77000, loss: 3.657715
 >> iter 78000, loss: 3.142263
 >> iter 79000, loss: 3.427566
 >> iter 80000, loss: 3.225424
   Number of active neurons: 10
 >> iter 81000, loss: 3.243446
 >> iter 82000, loss: 3.248278
 >> iter 83000, loss: 3.312463
 >> iter 84000, loss: 3.329599
 >> iter 85000, loss: 3.535750
 >> iter 86000, loss: 3.164236
 >> iter 87000, loss: 3.108938
 >> iter 88000, loss: 3.423018
 >> iter 89000, loss: 3.898136
 >> iter 90000, loss: 3.614038
   Number of active neurons: 10
 >> iter 91000, loss: 3.518130
 >> iter 92000, loss: 3.343489
 >> iter 93000, loss: 3.378841
 >> iter 94000, loss: 3.428335
 >> iter 95000, loss: 3.662163
 >> iter 96000, loss: 3.452719
 >> iter 97000, loss: 3.599506
 >> iter 98000, loss: 3.237318
 >> iter 99000, loss: 3.105318
 >> iter 100000, loss: 2.948950
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 3.95192096158
   - Test - Long: 20.8539573021
   - Test - Big: 3.72596274037
   - Test - A: 0.10665955603
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.983798
 >> iter 2000, loss: 15.458662
 >> iter 3000, loss: 14.004907
 >> iter 4000, loss: 13.440120
 >> iter 5000, loss: 13.213081
 >> iter 6000, loss: 13.121074
 >> iter 7000, loss: 13.073803
 >> iter 8000, loss: 13.061752
 >> iter 9000, loss: 13.040728
 >> iter 10000, loss: 13.048985
   Number of active neurons: 10
 >> iter 11000, loss: 13.039027
 >> iter 12000, loss: 13.059588
 >> iter 13000, loss: 13.046507
 >> iter 14000, loss: 13.047793
 >> iter 15000, loss: 13.037362
 >> iter 16000, loss: 13.040603
 >> iter 17000, loss: 13.035577
 >> iter 18000, loss: 13.037971
 >> iter 19000, loss: 13.033374
 >> iter 20000, loss: 13.038205
   Number of active neurons: 10
 >> iter 21000, loss: 13.023272
 >> iter 22000, loss: 13.030899
 >> iter 23000, loss: 13.015338
 >> iter 24000, loss: 12.767283
 >> iter 25000, loss: 12.036057
 >> iter 26000, loss: 11.525308
 >> iter 27000, loss: 11.187768
 >> iter 28000, loss: 11.107379
 >> iter 29000, loss: 10.948545
 >> iter 30000, loss: 10.969173
   Number of active neurons: 10
 >> iter 31000, loss: 10.853741
 >> iter 32000, loss: 10.840465
 >> iter 33000, loss: 10.706713
 >> iter 34000, loss: 10.579786
 >> iter 35000, loss: 10.350643
 >> iter 36000, loss: 10.155773
 >> iter 37000, loss: 9.804802
 >> iter 38000, loss: 9.449803
 >> iter 39000, loss: 9.047807
 >> iter 40000, loss: 8.639242
   Number of active neurons: 10
 >> iter 41000, loss: 7.221472
 >> iter 42000, loss: 6.465839
 >> iter 43000, loss: 5.988856
 >> iter 44000, loss: 3.901187
 >> iter 45000, loss: 2.633075
 >> iter 46000, loss: 1.376859
 >> iter 47000, loss: 1.332236
 >> iter 48000, loss: 0.975121
 >> iter 49000, loss: 0.818724
 >> iter 50000, loss: 0.741202
   Number of active neurons: 10
 >> iter 51000, loss: 0.540086
 >> iter 52000, loss: 0.480032
 >> iter 53000, loss: 0.478427
 >> iter 54000, loss: 0.439519
 >> iter 55000, loss: 0.378269
 >> iter 56000, loss: 0.319833
 >> iter 57000, loss: 0.476871
 >> iter 58000, loss: 0.272971
 >> iter 59000, loss: 0.275740
 >> iter 60000, loss: 0.205397
   Number of active neurons: 10
 >> iter 61000, loss: 0.436797
 >> iter 62000, loss: 0.356104
 >> iter 63000, loss: 0.384498
 >> iter 64000, loss: 0.379429
 >> iter 65000, loss: 0.400931
 >> iter 66000, loss: 0.190984
 >> iter 67000, loss: 0.232276
 >> iter 68000, loss: 0.129906
 >> iter 69000, loss: 0.070615
 >> iter 70000, loss: 0.115119
   Number of active neurons: 10
 >> iter 71000, loss: 0.121173
 >> iter 72000, loss: 0.168710
 >> iter 73000, loss: 0.113686
 >> iter 74000, loss: 0.173818
 >> iter 75000, loss: 0.139820
 >> iter 76000, loss: 0.145101
 >> iter 77000, loss: 0.181932
 >> iter 78000, loss: 0.195475
 >> iter 79000, loss: 0.161591
 >> iter 80000, loss: 0.207178
   Number of active neurons: 10
 >> iter 81000, loss: 0.088937
 >> iter 82000, loss: 0.155946
 >> iter 83000, loss: 0.096344
 >> iter 84000, loss: 0.073650
 >> iter 85000, loss: 0.113929
 >> iter 86000, loss: 0.238819
 >> iter 87000, loss: 0.177115
 >> iter 88000, loss: 0.264072
 >> iter 89000, loss: 0.258281
 >> iter 90000, loss: 0.176592
   Number of active neurons: 10
 >> iter 91000, loss: 0.098812
 >> iter 92000, loss: 0.086349
 >> iter 93000, loss: 0.106663
 >> iter 94000, loss: 0.073986
 >> iter 95000, loss: 0.130532
 >> iter 96000, loss: 0.221150
 >> iter 97000, loss: 0.178812
 >> iter 98000, loss: 0.077861
 >> iter 99000, loss: 0.067713
 >> iter 100000, loss: 0.111606
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.994028
 >> iter 2000, loss: 15.407259
 >> iter 3000, loss: 13.954462
 >> iter 4000, loss: 13.403039
 >> iter 5000, loss: 13.166244
 >> iter 6000, loss: 13.091255
 >> iter 7000, loss: 13.045735
 >> iter 8000, loss: 13.024243
 >> iter 9000, loss: 13.013665
 >> iter 10000, loss: 13.023919
   Number of active neurons: 10
 >> iter 11000, loss: 13.011086
 >> iter 12000, loss: 13.019454
 >> iter 13000, loss: 13.001110
 >> iter 14000, loss: 13.002296
 >> iter 15000, loss: 12.992928
 >> iter 16000, loss: 13.000463
 >> iter 17000, loss: 12.999156
 >> iter 18000, loss: 12.998888
 >> iter 19000, loss: 12.986909
 >> iter 20000, loss: 12.991588
   Number of active neurons: 9
 >> iter 21000, loss: 12.984301
 >> iter 22000, loss: 13.002927
 >> iter 23000, loss: 12.980692
 >> iter 24000, loss: 12.985761
 >> iter 25000, loss: 12.973684
 >> iter 26000, loss: 12.964282
 >> iter 27000, loss: 12.952507
 >> iter 28000, loss: 12.861398
 >> iter 29000, loss: 12.190785
 >> iter 30000, loss: 11.606987
   Number of active neurons: 10
 >> iter 31000, loss: 11.169183
 >> iter 32000, loss: 10.953467
 >> iter 33000, loss: 10.605952
 >> iter 34000, loss: 10.404028
 >> iter 35000, loss: 10.138644
 >> iter 36000, loss: 9.995560
 >> iter 37000, loss: 9.691146
 >> iter 38000, loss: 9.612151
 >> iter 39000, loss: 9.348945
 >> iter 40000, loss: 8.865114
   Number of active neurons: 10
 >> iter 41000, loss: 7.565172
 >> iter 42000, loss: 6.059646
 >> iter 43000, loss: 5.714755
 >> iter 44000, loss: 3.850635
 >> iter 45000, loss: 2.558327
 >> iter 46000, loss: 1.900162
 >> iter 47000, loss: 1.535674
 >> iter 48000, loss: 0.904299
 >> iter 49000, loss: 1.220058
 >> iter 50000, loss: 0.891962
   Number of active neurons: 10
 >> iter 51000, loss: 0.730360
 >> iter 52000, loss: 0.757345
 >> iter 53000, loss: 0.903487
 >> iter 54000, loss: 0.918219
 >> iter 55000, loss: 0.749488
 >> iter 56000, loss: 0.621838
 >> iter 57000, loss: 0.370641
 >> iter 58000, loss: 0.285726
 >> iter 59000, loss: 0.235670
 >> iter 60000, loss: 0.175213
   Number of active neurons: 10
 >> iter 61000, loss: 0.127953
 >> iter 62000, loss: 0.272736
 >> iter 63000, loss: 0.502402
 >> iter 64000, loss: 0.273065
 >> iter 65000, loss: 0.198163
 >> iter 66000, loss: 0.290418
 >> iter 67000, loss: 0.417560
 >> iter 68000, loss: 0.250741
 >> iter 69000, loss: 0.230525
 >> iter 70000, loss: 0.251997
   Number of active neurons: 10
 >> iter 71000, loss: 0.308743
 >> iter 72000, loss: 0.215396
 >> iter 73000, loss: 0.192952
 >> iter 74000, loss: 0.213938
 >> iter 75000, loss: 0.396941
 >> iter 76000, loss: 0.271339
 >> iter 77000, loss: 0.253390
 >> iter 78000, loss: 0.232691
 >> iter 79000, loss: 0.236131
 >> iter 80000, loss: 0.127370
   Number of active neurons: 10
 >> iter 81000, loss: 0.093838
 >> iter 82000, loss: 0.146747
 >> iter 83000, loss: 0.141202
 >> iter 84000, loss: 0.089984
 >> iter 85000, loss: 0.048373
 >> iter 86000, loss: 0.058889
 >> iter 87000, loss: 0.116709
 >> iter 88000, loss: 0.061950
 >> iter 89000, loss: 0.140360
 >> iter 90000, loss: 0.106462
   Number of active neurons: 10
 >> iter 91000, loss: 0.132671
 >> iter 92000, loss: 0.194925
 >> iter 93000, loss: 0.207354
 >> iter 94000, loss: 0.090855
 >> iter 95000, loss: 0.158737
 >> iter 96000, loss: 0.085864
 >> iter 97000, loss: 0.098302
 >> iter 98000, loss: 0.160913
 >> iter 99000, loss: 0.126498
 >> iter 100000, loss: 0.194812
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.014774
 >> iter 2000, loss: 15.436156
 >> iter 3000, loss: 14.005947
 >> iter 4000, loss: 13.449894
 >> iter 5000, loss: 13.207599
 >> iter 6000, loss: 13.141827
 >> iter 7000, loss: 13.109592
 >> iter 8000, loss: 13.091435
 >> iter 9000, loss: 13.075824
 >> iter 10000, loss: 13.083542
   Number of active neurons: 10
 >> iter 11000, loss: 13.064521
 >> iter 12000, loss: 13.065696
 >> iter 13000, loss: 13.054694
 >> iter 14000, loss: 13.061087
 >> iter 15000, loss: 13.049097
 >> iter 16000, loss: 13.060052
 >> iter 17000, loss: 13.050633
 >> iter 18000, loss: 13.047262
 >> iter 19000, loss: 13.028858
 >> iter 20000, loss: 13.040780
   Number of active neurons: 10
 >> iter 21000, loss: 13.019448
 >> iter 22000, loss: 13.020273
 >> iter 23000, loss: 12.884653
 >> iter 24000, loss: 12.271546
 >> iter 25000, loss: 11.584678
 >> iter 26000, loss: 11.326694
 >> iter 27000, loss: 11.074609
 >> iter 28000, loss: 11.063195
 >> iter 29000, loss: 10.932744
 >> iter 30000, loss: 10.943612
   Number of active neurons: 10
 >> iter 31000, loss: 10.836484
 >> iter 32000, loss: 10.771454
 >> iter 33000, loss: 10.522928
 >> iter 34000, loss: 10.275479
 >> iter 35000, loss: 9.494960
 >> iter 36000, loss: 9.001840
 >> iter 37000, loss: 8.492656
 >> iter 38000, loss: 8.341835
 >> iter 39000, loss: 8.082098
 >> iter 40000, loss: 8.156845
   Number of active neurons: 10
 >> iter 41000, loss: 7.999389
 >> iter 42000, loss: 8.000545
 >> iter 43000, loss: 7.756225
 >> iter 44000, loss: 7.795638
 >> iter 45000, loss: 6.675998
 >> iter 46000, loss: 6.027558
 >> iter 47000, loss: 5.603975
 >> iter 48000, loss: 5.470094
 >> iter 49000, loss: 5.242814
 >> iter 50000, loss: 5.296401
   Number of active neurons: 10
 >> iter 51000, loss: 5.277964
 >> iter 52000, loss: 5.291904
 >> iter 53000, loss: 5.131394
 >> iter 54000, loss: 5.164731
 >> iter 55000, loss: 5.015683
 >> iter 56000, loss: 5.119559
 >> iter 57000, loss: 5.119179
 >> iter 58000, loss: 5.077214
 >> iter 59000, loss: 4.948782
 >> iter 60000, loss: 5.131186
   Number of active neurons: 10
 >> iter 61000, loss: 4.954241
 >> iter 62000, loss: 5.149635
 >> iter 63000, loss: 5.023926
 >> iter 64000, loss: 5.025908
 >> iter 65000, loss: 4.907457
 >> iter 66000, loss: 4.968157
 >> iter 67000, loss: 4.897331
 >> iter 68000, loss: 4.979282
 >> iter 69000, loss: 4.923985
 >> iter 70000, loss: 5.313933
   Number of active neurons: 10
 >> iter 71000, loss: 4.991742
 >> iter 72000, loss: 4.807123
 >> iter 73000, loss: 4.261206
 >> iter 74000, loss: 4.055976
 >> iter 75000, loss: 3.622611
 >> iter 76000, loss: 3.544419
 >> iter 77000, loss: 3.417423
 >> iter 78000, loss: 3.443627
 >> iter 79000, loss: 3.310075
 >> iter 80000, loss: 3.426543
   Number of active neurons: 10
 >> iter 81000, loss: 3.190501
 >> iter 82000, loss: 3.238776
 >> iter 83000, loss: 3.080262
 >> iter 84000, loss: 3.156400
 >> iter 85000, loss: 3.095563
 >> iter 86000, loss: 3.279302
 >> iter 87000, loss: 3.293831
 >> iter 88000, loss: 3.273702
 >> iter 89000, loss: 3.168020
 >> iter 90000, loss: 3.421383
   Number of active neurons: 10
 >> iter 91000, loss: 3.199376
 >> iter 92000, loss: 3.501619
 >> iter 93000, loss: 3.198876
 >> iter 94000, loss: 3.200535
 >> iter 95000, loss: 3.073465
 >> iter 96000, loss: 3.093913
 >> iter 97000, loss: 3.078815
 >> iter 98000, loss: 3.260247
 >> iter 99000, loss: 3.232942
 >> iter 100000, loss: 3.240571
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 5.92388152237
   - Test - Long: 25.6737163142
   - Test - Big: 6.0499395006
   - Test - A: 0.0
   - Test - B: 8.43943737084

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

