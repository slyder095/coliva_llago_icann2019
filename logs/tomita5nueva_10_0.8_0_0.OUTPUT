 > Problema: tomita5nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.8
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.182361
 >> iter 2000, loss: 10.907365
 >> iter 3000, loss: 8.910841
 >> iter 4000, loss: 8.111952
 >> iter 5000, loss: 7.842692
 >> iter 6000, loss: 7.689256
 >> iter 7000, loss: 7.641105
 >> iter 8000, loss: 7.601087
 >> iter 9000, loss: 7.663539
 >> iter 10000, loss: 7.636107
   Number of active neurons: 10
 >> iter 11000, loss: 7.679862
 >> iter 12000, loss: 7.617330
 >> iter 13000, loss: 7.601855
 >> iter 14000, loss: 7.583856
 >> iter 15000, loss: 7.586789
 >> iter 16000, loss: 7.580696
 >> iter 17000, loss: 7.588809
 >> iter 18000, loss: 7.575110
 >> iter 19000, loss: 7.584681
 >> iter 20000, loss: 7.568341
   Number of active neurons: 10
 >> iter 21000, loss: 7.579845
 >> iter 22000, loss: 7.560870
 >> iter 23000, loss: 7.460673
 >> iter 24000, loss: 7.250850
 >> iter 25000, loss: 7.061109
 >> iter 26000, loss: 6.953993
 >> iter 27000, loss: 6.822039
 >> iter 28000, loss: 6.595694
 >> iter 29000, loss: 6.236642
 >> iter 30000, loss: 4.688562
   Number of active neurons: 10
 >> iter 31000, loss: 2.135292
 >> iter 32000, loss: 1.097902
 >> iter 33000, loss: 0.522406
 >> iter 34000, loss: 0.265454
 >> iter 35000, loss: 0.142165
 >> iter 36000, loss: 0.072907
 >> iter 37000, loss: 0.218440
 >> iter 38000, loss: 0.125012
 >> iter 39000, loss: 0.058073
 >> iter 40000, loss: 0.033001
   Number of active neurons: 10
 >> iter 41000, loss: 0.065050
 >> iter 42000, loss: 0.082246
 >> iter 43000, loss: 0.037980
 >> iter 44000, loss: 0.026892
 >> iter 45000, loss: 0.015825
 >> iter 46000, loss: 0.011894
 >> iter 47000, loss: 0.056611
 >> iter 48000, loss: 0.049078
 >> iter 49000, loss: 0.022845
 >> iter 50000, loss: 0.012832
   Number of active neurons: 10
 >> iter 51000, loss: 0.150935
 >> iter 52000, loss: 0.060923
 >> iter 53000, loss: 0.026911
 >> iter 54000, loss: 0.015510
 >> iter 55000, loss: 0.009720
 >> iter 56000, loss: 0.006755
 >> iter 57000, loss: 0.005542
 >> iter 58000, loss: 0.005355
 >> iter 59000, loss: 0.005308
 >> iter 60000, loss: 0.011250
   Number of active neurons: 10
 >> iter 61000, loss: 0.059784
 >> iter 62000, loss: 0.051213
 >> iter 63000, loss: 0.023008
 >> iter 64000, loss: 0.011281
 >> iter 65000, loss: 0.006888
 >> iter 66000, loss: 0.048576
 >> iter 67000, loss: 0.021183
 >> iter 68000, loss: 0.051522
 >> iter 69000, loss: 0.022488
 >> iter 70000, loss: 0.011324
   Number of active neurons: 10
 >> iter 71000, loss: 0.033944
 >> iter 72000, loss: 0.052937
 >> iter 73000, loss: 0.022312
 >> iter 74000, loss: 0.010658
 >> iter 75000, loss: 0.006073
 >> iter 76000, loss: 0.004632
 >> iter 77000, loss: 0.003741
 >> iter 78000, loss: 0.148815
 >> iter 79000, loss: 0.058538
 >> iter 80000, loss: 0.024916
   Number of active neurons: 10
 >> iter 81000, loss: 0.011822
 >> iter 82000, loss: 0.007289
 >> iter 83000, loss: 0.006422
 >> iter 84000, loss: 0.004746
 >> iter 85000, loss: 0.003808
 >> iter 86000, loss: 0.003183
 >> iter 87000, loss: 0.003060
 >> iter 88000, loss: 0.002839
 >> iter 89000, loss: 0.002754
 >> iter 90000, loss: 0.018217
   Number of active neurons: 10
 >> iter 91000, loss: 0.027231
 >> iter 92000, loss: 0.011732
 >> iter 93000, loss: 0.094845
 >> iter 94000, loss: 0.036937
 >> iter 95000, loss: 0.015363
 >> iter 96000, loss: 0.007623
 >> iter 97000, loss: 0.004452
 >> iter 98000, loss: 0.003203
 >> iter 99000, loss: 0.002693
 >> iter 100000, loss: 0.002486
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.206569
 >> iter 2000, loss: 10.906247
 >> iter 3000, loss: 8.925666
 >> iter 4000, loss: 8.118220
 >> iter 5000, loss: 7.775285
 >> iter 6000, loss: 7.668339
 >> iter 7000, loss: 7.597218
 >> iter 8000, loss: 7.564115
 >> iter 9000, loss: 7.555709
 >> iter 10000, loss: 7.547627
   Number of active neurons: 9
 >> iter 11000, loss: 7.545816
 >> iter 12000, loss: 7.531478
 >> iter 13000, loss: 7.538386
 >> iter 14000, loss: 7.527987
 >> iter 15000, loss: 7.533107
 >> iter 16000, loss: 7.520089
 >> iter 17000, loss: 7.531856
 >> iter 18000, loss: 7.516883
 >> iter 19000, loss: 7.536402
 >> iter 20000, loss: 7.544079
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 21000, loss: 7.344826
 >> iter 22000, loss: 7.104703
 >> iter 23000, loss: 6.948857
 >> iter 24000, loss: 6.806216
 >> iter 25000, loss: 6.749912
 >> iter 26000, loss: 6.675403
 >> iter 27000, loss: 6.649245
 >> iter 28000, loss: 6.693075
 >> iter 29000, loss: 6.653219
 >> iter 30000, loss: 6.621399
   Number of active neurons: 10
 >> iter 31000, loss: 6.630492
 >> iter 32000, loss: 6.626737
 >> iter 33000, loss: 6.608395
 >> iter 34000, loss: 6.605826
 >> iter 35000, loss: 6.601530
 >> iter 36000, loss: 6.642969
 >> iter 37000, loss: 6.614499
 >> iter 38000, loss: 6.599004
 >> iter 39000, loss: 6.596264
 >> iter 40000, loss: 6.574761
   Number of active neurons: 10
 >> iter 41000, loss: 6.515607
 >> iter 42000, loss: 6.426523
 >> iter 43000, loss: 6.298680
 >> iter 44000, loss: 6.103910
 >> iter 45000, loss: 6.000150
 >> iter 46000, loss: 5.919599
 >> iter 47000, loss: 5.878763
 >> iter 48000, loss: 5.870780
 >> iter 49000, loss: 5.832398
 >> iter 50000, loss: 5.753292
   Number of active neurons: 10
 >> iter 51000, loss: 5.650220
 >> iter 52000, loss: 5.505308
 >> iter 53000, loss: 5.343118
 >> iter 54000, loss: 5.164145
 >> iter 55000, loss: 4.930237
 >> iter 56000, loss: 4.853713
 >> iter 57000, loss: 4.736393
 >> iter 58000, loss: 4.639785
 >> iter 59000, loss: 4.541572
 >> iter 60000, loss: 4.176583
   Number of active neurons: 10
 >> iter 61000, loss: 3.589136
 >> iter 62000, loss: 2.218513
 >> iter 63000, loss: 1.869927
 >> iter 64000, loss: 1.526589
 >> iter 65000, loss: 1.252631
 >> iter 66000, loss: 0.764138
 >> iter 67000, loss: 0.445618
 >> iter 68000, loss: 0.460924
 >> iter 69000, loss: 0.405184
 >> iter 70000, loss: 0.435735
   Number of active neurons: 10
 >> iter 71000, loss: 0.465796
 >> iter 72000, loss: 0.414635
 >> iter 73000, loss: 0.343825
 >> iter 74000, loss: 0.262075
 >> iter 75000, loss: 0.355057
 >> iter 76000, loss: 0.214516
 >> iter 77000, loss: 0.106533
 >> iter 78000, loss: 0.287881
 >> iter 79000, loss: 0.208677
 >> iter 80000, loss: 0.251506
   Number of active neurons: 10
 >> iter 81000, loss: 0.185688
 >> iter 82000, loss: 0.126903
 >> iter 83000, loss: 0.202334
 >> iter 84000, loss: 0.129584
 >> iter 85000, loss: 0.181888
 >> iter 86000, loss: 0.152399
 >> iter 87000, loss: 0.261261
 >> iter 88000, loss: 0.122093
 >> iter 89000, loss: 0.174707
 >> iter 90000, loss: 0.164716
   Number of active neurons: 10
 >> iter 91000, loss: 0.215989
 >> iter 92000, loss: 0.150591
 >> iter 93000, loss: 0.147743
 >> iter 94000, loss: 0.077041
 >> iter 95000, loss: 0.108758
 >> iter 96000, loss: 0.110317
 >> iter 97000, loss: 0.183427
 >> iter 98000, loss: 0.343604
 >> iter 99000, loss: 0.189039
 >> iter 100000, loss: 0.243324
   Number of active neurons: 10
 >> iter 101000, loss: 0.218037
 >> iter 102000, loss: 0.188160
 >> iter 103000, loss: 0.137774
 >> iter 104000, loss: 0.093236
 >> iter 105000, loss: 0.161253
 >> iter 106000, loss: 0.076165
 >> iter 107000, loss: 0.077413
 >> iter 108000, loss: 0.102273
 >> iter 109000, loss: 0.125461
 >> iter 110000, loss: 0.056202
   Number of active neurons: 10
 >> iter 111000, loss: 0.217598
 >> iter 112000, loss: 0.145075
 >> iter 113000, loss: 0.138598
 >> iter 114000, loss: 0.061389
 >> iter 115000, loss: 0.107377
 >> iter 116000, loss: 0.085936
 >> iter 117000, loss: 0.128708
 >> iter 118000, loss: 0.093971
 >> iter 119000, loss: 0.049151
 >> iter 120000, loss: 0.045392
   Number of active neurons: 10
 >> iter 121000, loss: 0.117784
 >> iter 122000, loss: 0.050034
 >> iter 123000, loss: 0.062546
 >> iter 124000, loss: 0.047784
 >> iter 125000, loss: 0.060434
 >> iter 126000, loss: 0.104599
 >> iter 127000, loss: 0.147484
 >> iter 128000, loss: 0.093350
 >> iter 129000, loss: 0.082218
 >> iter 130000, loss: 0.043748
   Number of active neurons: 10
 >> iter 131000, loss: 0.021207
 >> iter 132000, loss: 0.016260
 >> iter 133000, loss: 0.018267
 >> iter 134000, loss: 0.067091
 >> iter 135000, loss: 0.033333
 >> iter 136000, loss: 0.034035
 >> iter 137000, loss: 0.101693
 >> iter 138000, loss: 0.060752
 >> iter 139000, loss: 0.026907
 >> iter 140000, loss: 0.013643
   Number of active neurons: 10
 >> iter 141000, loss: 0.038902
 >> iter 142000, loss: 0.023679
 >> iter 143000, loss: 0.012443
 >> iter 144000, loss: 0.037203
 >> iter 145000, loss: 0.053410
 >> iter 146000, loss: 0.023231
 >> iter 147000, loss: 0.105681
 >> iter 148000, loss: 0.075230
 >> iter 149000, loss: 0.065235
 >> iter 150000, loss: 0.056184
   Number of active neurons: 10
 >> iter 151000, loss: 0.055269
 >> iter 152000, loss: 0.123620
 >> iter 153000, loss: 0.089191
 >> iter 154000, loss: 0.037454
 >> iter 155000, loss: 0.102456
 >> iter 156000, loss: 0.058523
 >> iter 157000, loss: 0.105977
 >> iter 158000, loss: 0.070716
 >> iter 159000, loss: 0.067720
 >> iter 160000, loss: 0.040510
   Number of active neurons: 10
 >> iter 161000, loss: 0.179917
 >> iter 162000, loss: 0.073717
 >> iter 163000, loss: 0.053579
 >> iter 164000, loss: 0.078409
 >> iter 165000, loss: 0.114487
 >> iter 166000, loss: 0.098280
 >> iter 167000, loss: 0.041936
 >> iter 168000, loss: 0.037374
 >> iter 169000, loss: 0.079024
 >> iter 170000, loss: 0.054123
   Number of active neurons: 10
 >> iter 171000, loss: 0.040532
 >> iter 172000, loss: 0.035326
 >> iter 173000, loss: 0.017264
 >> iter 174000, loss: 0.009968
 >> iter 175000, loss: 0.007098
 >> iter 176000, loss: 0.005568
 >> iter 177000, loss: 0.061333
 >> iter 178000, loss: 0.026082
 >> iter 179000, loss: 0.021583
 >> iter 180000, loss: 0.048775
   Number of active neurons: 10
 >> iter 181000, loss: 0.020666
 >> iter 182000, loss: 0.010171
 >> iter 183000, loss: 0.006105
 >> iter 184000, loss: 0.019691
 >> iter 185000, loss: 0.009496
 >> iter 186000, loss: 0.005769
 >> iter 187000, loss: 0.034064
 >> iter 188000, loss: 0.014771
 >> iter 189000, loss: 0.038889
 >> iter 190000, loss: 0.028877
   Number of active neurons: 10
 >> iter 191000, loss: 0.013364
 >> iter 192000, loss: 0.018309
 >> iter 193000, loss: 0.010264
 >> iter 194000, loss: 0.005930
 >> iter 195000, loss: 0.007337
 >> iter 196000, loss: 0.004520
 >> iter 197000, loss: 0.003353
 >> iter 198000, loss: 0.005042
 >> iter 199000, loss: 0.205191
 >> iter 200000, loss: 0.095018
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 16.020904
 >> iter 2000, loss: 10.825111
 >> iter 3000, loss: 8.818001
 >> iter 4000, loss: 8.077024
 >> iter 5000, loss: 7.774904
 >> iter 6000, loss: 7.655103
 >> iter 7000, loss: 7.616024
 >> iter 8000, loss: 7.632360
 >> iter 9000, loss: 7.602635
 >> iter 10000, loss: 7.577829
   Number of active neurons: 10
 >> iter 11000, loss: 7.577078
 >> iter 12000, loss: 7.563349
 >> iter 13000, loss: 7.571767
 >> iter 14000, loss: 7.560395
 >> iter 15000, loss: 7.568073
 >> iter 16000, loss: 7.562209
 >> iter 17000, loss: 7.566163
 >> iter 18000, loss: 7.557675
 >> iter 19000, loss: 7.566505
 >> iter 20000, loss: 7.558242
   Number of active neurons: 10
 >> iter 21000, loss: 7.570888
 >> iter 22000, loss: 7.560127
 >> iter 23000, loss: 7.565864
 >> iter 24000, loss: 7.556155
 >> iter 25000, loss: 7.569042
 >> iter 26000, loss: 7.557595
 >> iter 27000, loss: 7.563104
 >> iter 28000, loss: 7.553175
 >> iter 29000, loss: 7.564330
 >> iter 30000, loss: 7.557157
   Number of active neurons: 10
 >> iter 31000, loss: 7.562757
 >> iter 32000, loss: 7.571949
 >> iter 33000, loss: 7.573898
 >> iter 34000, loss: 7.555036
 >> iter 35000, loss: 7.560730
 >> iter 36000, loss: 7.554361
 >> iter 37000, loss: 7.562585
 >> iter 38000, loss: 7.560379
 >> iter 39000, loss: 7.557566
 >> iter 40000, loss: 7.566671
   Number of active neurons: 10
 >> iter 41000, loss: 7.621081
 >> iter 42000, loss: 7.549461
 >> iter 43000, loss: 7.468891
 >> iter 44000, loss: 7.242506
 >> iter 45000, loss: 7.069703
 >> iter 46000, loss: 6.968231
 >> iter 47000, loss: 6.938211
 >> iter 48000, loss: 6.891860
 >> iter 49000, loss: 6.831062
 >> iter 50000, loss: 6.742797
   Number of active neurons: 10
 >> iter 51000, loss: 6.546560
 >> iter 52000, loss: 6.309906
 >> iter 53000, loss: 6.179712
 >> iter 54000, loss: 6.016538
 >> iter 55000, loss: 5.619921
 >> iter 56000, loss: 4.070471
 >> iter 57000, loss: 2.065238
 >> iter 58000, loss: 0.876863
 >> iter 59000, loss: 0.449755
 >> iter 60000, loss: 0.237452
   Number of active neurons: 10
 >> iter 61000, loss: 0.124792
 >> iter 62000, loss: 0.133720
 >> iter 63000, loss: 0.312452
 >> iter 64000, loss: 0.199865
 >> iter 65000, loss: 0.090414
 >> iter 66000, loss: 0.075593
 >> iter 67000, loss: 0.072283
 >> iter 68000, loss: 0.064716
 >> iter 69000, loss: 0.043334
 >> iter 70000, loss: 0.039360
   Number of active neurons: 10
 >> iter 71000, loss: 0.021224
 >> iter 72000, loss: 0.014043
 >> iter 73000, loss: 0.010659
 >> iter 74000, loss: 0.014432
 >> iter 75000, loss: 0.021603
 >> iter 76000, loss: 0.013600
 >> iter 77000, loss: 0.058108
 >> iter 78000, loss: 0.025095
 >> iter 79000, loss: 0.015185
 >> iter 80000, loss: 0.011330
   Number of active neurons: 10
 >> iter 81000, loss: 0.014699
 >> iter 82000, loss: 0.012267
 >> iter 83000, loss: 0.007905
 >> iter 84000, loss: 0.005672
 >> iter 85000, loss: 0.004597
 >> iter 86000, loss: 0.004015
 >> iter 87000, loss: 0.023111
 >> iter 88000, loss: 0.010912
 >> iter 89000, loss: 0.024133
 >> iter 90000, loss: 0.016386
   Number of active neurons: 10
 >> iter 91000, loss: 0.081988
 >> iter 92000, loss: 0.034213
 >> iter 93000, loss: 0.014963
 >> iter 94000, loss: 0.013134
 >> iter 95000, loss: 0.006884
 >> iter 96000, loss: 0.006445
 >> iter 97000, loss: 0.004167
 >> iter 98000, loss: 0.003425
 >> iter 99000, loss: 0.004108
 >> iter 100000, loss: 0.018056
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.189115
 >> iter 2000, loss: 10.862019
 >> iter 3000, loss: 8.854814
 >> iter 4000, loss: 8.100178
 >> iter 5000, loss: 7.816433
 >> iter 6000, loss: 7.753119
 >> iter 7000, loss: 7.690418
 >> iter 8000, loss: 7.644815
 >> iter 9000, loss: 7.647760
 >> iter 10000, loss: 7.638129
   Number of active neurons: 10
 >> iter 11000, loss: 7.624948
 >> iter 12000, loss: 7.605078
 >> iter 13000, loss: 7.615265
 >> iter 14000, loss: 7.589261
 >> iter 15000, loss: 7.585808
 >> iter 16000, loss: 7.570349
 >> iter 17000, loss: 7.580326
 >> iter 18000, loss: 7.565795
 >> iter 19000, loss: 7.572506
 >> iter 20000, loss: 7.554178
   Number of active neurons: 10
 >> iter 21000, loss: 7.547736
 >> iter 22000, loss: 7.482080
 >> iter 23000, loss: 7.354941
 >> iter 24000, loss: 7.146759
 >> iter 25000, loss: 6.898758
 >> iter 26000, loss: 6.715976
 >> iter 27000, loss: 6.326350
 >> iter 28000, loss: 6.057499
 >> iter 29000, loss: 5.758737
 >> iter 30000, loss: 5.533341
   Number of active neurons: 10
 >> iter 31000, loss: 5.468391
 >> iter 32000, loss: 5.304408
 >> iter 33000, loss: 5.235474
 >> iter 34000, loss: 5.142094
 >> iter 35000, loss: 5.116045
 >> iter 36000, loss: 5.055405
 >> iter 37000, loss: 5.051814
 >> iter 38000, loss: 5.031930
 >> iter 39000, loss: 5.080403
 >> iter 40000, loss: 5.013306
   Number of active neurons: 10
 >> iter 41000, loss: 5.005816
 >> iter 42000, loss: 4.945119
 >> iter 43000, loss: 4.632659
 >> iter 44000, loss: 3.584454
 >> iter 45000, loss: 1.803593
 >> iter 46000, loss: 1.427901
 >> iter 47000, loss: 0.871215
 >> iter 48000, loss: 0.679813
 >> iter 49000, loss: 0.514607
 >> iter 50000, loss: 0.482886
   Number of active neurons: 10
 >> iter 51000, loss: 0.616581
 >> iter 52000, loss: 0.456696
 >> iter 53000, loss: 0.486130
 >> iter 54000, loss: 0.339337
 >> iter 55000, loss: 0.216769
 >> iter 56000, loss: 0.313309
 >> iter 57000, loss: 0.175037
 >> iter 58000, loss: 0.188056
 >> iter 59000, loss: 0.176647
 >> iter 60000, loss: 0.177170
   Number of active neurons: 10
 >> iter 61000, loss: 0.194468
 >> iter 62000, loss: 0.161119
 >> iter 63000, loss: 0.119610
 >> iter 64000, loss: 0.198742
 >> iter 65000, loss: 0.103738
 >> iter 66000, loss: 0.175767
 >> iter 67000, loss: 0.159222
 >> iter 68000, loss: 0.230932
 >> iter 69000, loss: 0.109028
 >> iter 70000, loss: 0.078185
   Number of active neurons: 10
 >> iter 71000, loss: 0.040133
 >> iter 72000, loss: 0.080065
 >> iter 73000, loss: 0.178626
 >> iter 74000, loss: 0.125504
 >> iter 75000, loss: 0.067974
 >> iter 76000, loss: 0.035339
 >> iter 77000, loss: 0.021556
 >> iter 78000, loss: 0.133784
 >> iter 79000, loss: 0.103010
 >> iter 80000, loss: 0.081270
   Number of active neurons: 10
 >> iter 81000, loss: 0.056929
 >> iter 82000, loss: 0.029996
 >> iter 83000, loss: 0.025172
 >> iter 84000, loss: 0.017071
 >> iter 85000, loss: 0.035534
 >> iter 86000, loss: 0.023162
 >> iter 87000, loss: 0.013734
 >> iter 88000, loss: 0.016496
 >> iter 89000, loss: 0.031852
 >> iter 90000, loss: 0.020704
   Number of active neurons: 10
 >> iter 91000, loss: 0.015060
 >> iter 92000, loss: 0.010624
 >> iter 93000, loss: 0.038847
 >> iter 94000, loss: 0.018872
 >> iter 95000, loss: 0.011092
 >> iter 96000, loss: 0.101504
 >> iter 97000, loss: 0.065952
 >> iter 98000, loss: 0.064283
 >> iter 99000, loss: 0.072465
 >> iter 100000, loss: 0.142042
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0039999600004
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.092843
 >> iter 2000, loss: 10.810310
 >> iter 3000, loss: 8.790592
 >> iter 4000, loss: 8.045876
 >> iter 5000, loss: 7.750371
 >> iter 6000, loss: 7.624293
 >> iter 7000, loss: 7.583741
 >> iter 8000, loss: 7.583882
 >> iter 9000, loss: 7.565568
 >> iter 10000, loss: 7.546240
   Number of active neurons: 9
 >> iter 11000, loss: 7.548756
 >> iter 12000, loss: 7.543847
 >> iter 13000, loss: 7.547116
 >> iter 14000, loss: 7.538256
 >> iter 15000, loss: 7.541924
 >> iter 16000, loss: 7.537162
 >> iter 17000, loss: 7.546246
 >> iter 18000, loss: 7.521231
 >> iter 19000, loss: 7.529261
 >> iter 20000, loss: 7.571953
   Number of active neurons: 10
 >> iter 21000, loss: 7.371716
 >> iter 22000, loss: 7.125099
 >> iter 23000, loss: 7.034454
 >> iter 24000, loss: 6.859375
 >> iter 25000, loss: 6.668807
 >> iter 26000, loss: 6.340918
 >> iter 27000, loss: 4.658441
 >> iter 28000, loss: 2.410197
 >> iter 29000, loss: 1.295919
 >> iter 30000, loss: 0.612428
   Number of active neurons: 10
 >> iter 31000, loss: 0.368068
 >> iter 32000, loss: 0.212065
 >> iter 33000, loss: 0.096162
 >> iter 34000, loss: 0.076513
 >> iter 35000, loss: 0.091306
 >> iter 36000, loss: 0.048924
 >> iter 37000, loss: 0.056113
 >> iter 38000, loss: 0.029531
 >> iter 39000, loss: 0.018275
 >> iter 40000, loss: 0.039208
   Number of active neurons: 10
 >> iter 41000, loss: 0.043899
 >> iter 42000, loss: 0.027783
 >> iter 43000, loss: 0.060493
 >> iter 44000, loss: 0.028455
 >> iter 45000, loss: 0.071830
 >> iter 46000, loss: 0.032110
 >> iter 47000, loss: 0.016120
 >> iter 48000, loss: 0.022401
 >> iter 49000, loss: 0.088638
 >> iter 50000, loss: 0.037177
   Number of active neurons: 10
 >> iter 51000, loss: 0.055221
 >> iter 52000, loss: 0.110730
 >> iter 53000, loss: 0.094796
 >> iter 54000, loss: 0.040535
 >> iter 55000, loss: 0.019689
 >> iter 56000, loss: 0.011680
 >> iter 57000, loss: 0.033174
 >> iter 58000, loss: 0.016574
 >> iter 59000, loss: 0.063099
 >> iter 60000, loss: 0.028533
   Number of active neurons: 10
 >> iter 61000, loss: 0.013707
 >> iter 62000, loss: 0.032039
 >> iter 63000, loss: 0.015386
 >> iter 64000, loss: 0.017312
 >> iter 65000, loss: 0.086987
 >> iter 66000, loss: 0.114168
 >> iter 67000, loss: 0.074717
 >> iter 68000, loss: 0.032704
 >> iter 69000, loss: 0.015196
 >> iter 70000, loss: 0.008576
   Number of active neurons: 10
 >> iter 71000, loss: 0.005770
 >> iter 72000, loss: 0.013941
 >> iter 73000, loss: 0.014337
 >> iter 74000, loss: 0.019531
 >> iter 75000, loss: 0.010002
 >> iter 76000, loss: 0.066480
 >> iter 77000, loss: 0.119710
 >> iter 78000, loss: 0.179215
 >> iter 79000, loss: 0.128612
 >> iter 80000, loss: 0.059680
   Number of active neurons: 10
 >> iter 81000, loss: 0.026824
 >> iter 82000, loss: 0.013238
 >> iter 83000, loss: 0.023943
 >> iter 84000, loss: 0.011980
 >> iter 85000, loss: 0.008012
 >> iter 86000, loss: 0.005526
 >> iter 87000, loss: 0.004686
 >> iter 88000, loss: 0.004178
 >> iter 89000, loss: 0.071473
 >> iter 90000, loss: 0.029524
   Number of active neurons: 10
 >> iter 91000, loss: 0.013381
 >> iter 92000, loss: 0.008609
 >> iter 93000, loss: 0.005430
 >> iter 94000, loss: 0.004203
 >> iter 95000, loss: 0.003561
 >> iter 96000, loss: 0.003179
 >> iter 97000, loss: 0.002979
 >> iter 98000, loss: 0.002809
 >> iter 99000, loss: 0.002747
 >> iter 100000, loss: 0.025436
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.182000
 >> iter 2000, loss: 10.892682
 >> iter 3000, loss: 8.832893
 >> iter 4000, loss: 8.066056
 >> iter 5000, loss: 7.785003
 >> iter 6000, loss: 7.680048
 >> iter 7000, loss: 7.640566
 >> iter 8000, loss: 7.602250
 >> iter 9000, loss: 7.593497
 >> iter 10000, loss: 7.581382
   Number of active neurons: 10
 >> iter 11000, loss: 7.583258
 >> iter 12000, loss: 7.576448
 >> iter 13000, loss: 7.581354
 >> iter 14000, loss: 7.600779
 >> iter 15000, loss: 7.593437
 >> iter 16000, loss: 7.577084
 >> iter 17000, loss: 7.579855
 >> iter 18000, loss: 7.607196
 >> iter 19000, loss: 7.606869
 >> iter 20000, loss: 7.581064
   Number of active neurons: 10
 >> iter 21000, loss: 7.583604
 >> iter 22000, loss: 7.574673
 >> iter 23000, loss: 7.578968
 >> iter 24000, loss: 7.572636
 >> iter 25000, loss: 7.578592
 >> iter 26000, loss: 7.573033
 >> iter 27000, loss: 7.576306
 >> iter 28000, loss: 7.581410
 >> iter 29000, loss: 7.577744
 >> iter 30000, loss: 7.586693
   Number of active neurons: 10
 >> iter 31000, loss: 7.556100
 >> iter 32000, loss: 7.420119
 >> iter 33000, loss: 7.340844
 >> iter 34000, loss: 7.217675
 >> iter 35000, loss: 7.063696
 >> iter 36000, loss: 7.005832
 >> iter 37000, loss: 6.888573
 >> iter 38000, loss: 6.754983
 >> iter 39000, loss: 6.644056
 >> iter 40000, loss: 6.502670
   Number of active neurons: 10
 >> iter 41000, loss: 6.358378
 >> iter 42000, loss: 6.119879
 >> iter 43000, loss: 5.972975
 >> iter 44000, loss: 5.652633
 >> iter 45000, loss: 5.337161
 >> iter 46000, loss: 5.070168
 >> iter 47000, loss: 4.771891
 >> iter 48000, loss: 4.657370
 >> iter 49000, loss: 4.490261
 >> iter 50000, loss: 4.536494
   Number of active neurons: 10
 >> iter 51000, loss: 4.428957
 >> iter 52000, loss: 4.369575
 >> iter 53000, loss: 4.456696
 >> iter 54000, loss: 4.356992
 >> iter 55000, loss: 4.409203
 >> iter 56000, loss: 4.278139
 >> iter 57000, loss: 4.268340
 >> iter 58000, loss: 4.237513
 >> iter 59000, loss: 4.263237
 >> iter 60000, loss: 4.286013
   Number of active neurons: 10
 >> iter 61000, loss: 4.173542
 >> iter 62000, loss: 4.192865
 >> iter 63000, loss: 4.106965
 >> iter 64000, loss: 4.198848
 >> iter 65000, loss: 4.137743
 >> iter 66000, loss: 4.127865
 >> iter 67000, loss: 4.113357
 >> iter 68000, loss: 4.124718
 >> iter 69000, loss: 4.025967
 >> iter 70000, loss: 4.138911
   Number of active neurons: 10
 >> iter 71000, loss: 4.111198
 >> iter 72000, loss: 4.103713
 >> iter 73000, loss: 4.037885
 >> iter 74000, loss: 4.224212
 >> iter 75000, loss: 3.978571
 >> iter 76000, loss: 3.781554
 >> iter 77000, loss: 3.858228
 >> iter 78000, loss: 3.797471
 >> iter 79000, loss: 3.657708
 >> iter 80000, loss: 3.670257
   Number of active neurons: 10
 >> iter 81000, loss: 3.909628
 >> iter 82000, loss: 4.067292
 >> iter 83000, loss: 3.928358
 >> iter 84000, loss: 3.338749
 >> iter 85000, loss: 2.724098
 >> iter 86000, loss: 1.866222
 >> iter 87000, loss: 1.077927
 >> iter 88000, loss: 0.862692
 >> iter 89000, loss: 0.813350
 >> iter 90000, loss: 0.761978
   Number of active neurons: 10
 >> iter 91000, loss: 0.573874
 >> iter 92000, loss: 0.492970
 >> iter 93000, loss: 0.468815
 >> iter 94000, loss: 0.323380
 >> iter 95000, loss: 0.462913
 >> iter 96000, loss: 0.323577
 >> iter 97000, loss: 0.261650
 >> iter 98000, loss: 0.304844
 >> iter 99000, loss: 0.204852
 >> iter 100000, loss: 0.175558
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.234518
 >> iter 2000, loss: 10.992693
 >> iter 3000, loss: 8.894435
 >> iter 4000, loss: 8.131645
 >> iter 5000, loss: 7.862203
 >> iter 6000, loss: 7.696574
 >> iter 7000, loss: 7.648566
 >> iter 8000, loss: 7.625541
 >> iter 9000, loss: 7.613419
 >> iter 10000, loss: 7.628949
   Number of active neurons: 10
 >> iter 11000, loss: 7.610422
 >> iter 12000, loss: 7.589736
 >> iter 13000, loss: 7.591559
 >> iter 14000, loss: 7.578740
 >> iter 15000, loss: 7.588656
 >> iter 16000, loss: 7.601262
 >> iter 17000, loss: 7.611501
 >> iter 18000, loss: 7.635143
 >> iter 19000, loss: 7.622057
 >> iter 20000, loss: 7.419113
   Number of active neurons: 10
 >> iter 21000, loss: 7.186816
 >> iter 22000, loss: 6.968340
 >> iter 23000, loss: 6.844619
 >> iter 24000, loss: 6.749744
 >> iter 25000, loss: 6.685243
 >> iter 26000, loss: 6.552024
 >> iter 27000, loss: 6.414990
 >> iter 28000, loss: 6.318300
 >> iter 29000, loss: 6.086131
 >> iter 30000, loss: 5.897611
   Number of active neurons: 10
 >> iter 31000, loss: 5.517251
 >> iter 32000, loss: 5.213008
 >> iter 33000, loss: 5.052896
 >> iter 34000, loss: 4.889773
 >> iter 35000, loss: 3.800650
 >> iter 36000, loss: 1.767849
 >> iter 37000, loss: 0.944284
 >> iter 38000, loss: 0.460140
 >> iter 39000, loss: 0.595920
 >> iter 40000, loss: 0.423586
   Number of active neurons: 10
 >> iter 41000, loss: 0.336416
 >> iter 42000, loss: 0.193396
 >> iter 43000, loss: 0.132969
 >> iter 44000, loss: 0.125782
 >> iter 45000, loss: 0.167579
 >> iter 46000, loss: 0.232415
 >> iter 47000, loss: 0.219477
 >> iter 48000, loss: 0.159935
 >> iter 49000, loss: 0.218749
 >> iter 50000, loss: 0.253329
   Number of active neurons: 10
 >> iter 51000, loss: 0.135391
 >> iter 52000, loss: 0.128992
 >> iter 53000, loss: 0.149292
 >> iter 54000, loss: 0.116224
 >> iter 55000, loss: 0.209069
 >> iter 56000, loss: 0.258508
 >> iter 57000, loss: 0.211597
 >> iter 58000, loss: 0.091799
 >> iter 59000, loss: 0.065393
 >> iter 60000, loss: 0.047564
   Number of active neurons: 10
 >> iter 61000, loss: 0.084265
 >> iter 62000, loss: 0.052267
 >> iter 63000, loss: 0.173799
 >> iter 64000, loss: 0.082075
 >> iter 65000, loss: 0.046682
 >> iter 66000, loss: 0.024273
 >> iter 67000, loss: 0.055518
 >> iter 68000, loss: 0.027125
 >> iter 69000, loss: 0.182289
 >> iter 70000, loss: 0.113292
   Number of active neurons: 10
 >> iter 71000, loss: 0.098365
 >> iter 72000, loss: 0.128454
 >> iter 73000, loss: 0.055293
 >> iter 74000, loss: 0.100858
 >> iter 75000, loss: 0.052828
 >> iter 76000, loss: 0.025967
 >> iter 77000, loss: 0.067887
 >> iter 78000, loss: 0.031459
 >> iter 79000, loss: 0.037013
 >> iter 80000, loss: 0.033607
   Number of active neurons: 10
 >> iter 81000, loss: 0.152653
 >> iter 82000, loss: 0.062143
 >> iter 83000, loss: 0.028368
 >> iter 84000, loss: 0.034241
 >> iter 85000, loss: 0.017352
 >> iter 86000, loss: 0.010777
 >> iter 87000, loss: 0.013476
 >> iter 88000, loss: 0.051459
 >> iter 89000, loss: 0.025915
 >> iter 90000, loss: 0.019937
   Number of active neurons: 10
 >> iter 91000, loss: 0.034446
 >> iter 92000, loss: 0.016885
 >> iter 93000, loss: 0.045436
 >> iter 94000, loss: 0.025461
 >> iter 95000, loss: 0.012752
 >> iter 96000, loss: 0.057049
 >> iter 97000, loss: 0.054469
 >> iter 98000, loss: 0.058595
 >> iter 99000, loss: 0.025273
 >> iter 100000, loss: 0.033440
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.066006
 >> iter 2000, loss: 10.833609
 >> iter 3000, loss: 8.849291
 >> iter 4000, loss: 8.097161
 >> iter 5000, loss: 7.773468
 >> iter 6000, loss: 7.635541
 >> iter 7000, loss: 7.587972
 >> iter 8000, loss: 7.556823
 >> iter 9000, loss: 7.554442
 >> iter 10000, loss: 7.540148
   Number of active neurons: 9
 >> iter 11000, loss: 7.545939
 >> iter 12000, loss: 7.541188
 >> iter 13000, loss: 7.545313
 >> iter 14000, loss: 7.554381
 >> iter 15000, loss: 7.552389
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 7.535136
 >> iter 17000, loss: 7.546026
 >> iter 18000, loss: 7.535925
 >> iter 19000, loss: 7.543570
 >> iter 20000, loss: 7.535703
   Number of active neurons: 9
 >> iter 21000, loss: 7.540320
 >> iter 22000, loss: 7.531276
 >> iter 23000, loss: 7.538499
 >> iter 24000, loss: 7.530060
 >> iter 25000, loss: 7.546165
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 26000, loss: 7.536781
 >> iter 27000, loss: 7.540636
 >> iter 28000, loss: 7.535837
 >> iter 29000, loss: 7.545031
 >> iter 30000, loss: 7.534565
   Number of active neurons: 9
 >> iter 31000, loss: 7.541525
 >> iter 32000, loss: 7.535185
 >> iter 33000, loss: 7.544851
 >> iter 34000, loss: 7.535401
 >> iter 35000, loss: 7.543371
   Number of active neurons: 9
   SHOCK
   Setting new limit to 275000.0 iters...
 >> iter 36000, loss: 7.537588
 >> iter 37000, loss: 7.545033
 >> iter 38000, loss: 7.529619
 >> iter 39000, loss: 7.540877
 >> iter 40000, loss: 7.530354
   Number of active neurons: 9
 >> iter 41000, loss: 7.540335
 >> iter 42000, loss: 7.523486
 >> iter 43000, loss: 7.526306
 >> iter 44000, loss: 7.418659
 >> iter 45000, loss: 7.294643
 >> iter 46000, loss: 6.942212
 >> iter 47000, loss: 6.431046
 >> iter 48000, loss: 5.961834
 >> iter 49000, loss: 5.690701
 >> iter 50000, loss: 5.590687
   Number of active neurons: 10
 >> iter 51000, loss: 5.305652
 >> iter 52000, loss: 5.157892
 >> iter 53000, loss: 5.077885
 >> iter 54000, loss: 5.012641
 >> iter 55000, loss: 4.977676
 >> iter 56000, loss: 4.944750
 >> iter 57000, loss: 4.974257
 >> iter 58000, loss: 4.925950
 >> iter 59000, loss: 5.203369
 >> iter 60000, loss: 4.887738
   Number of active neurons: 10
 >> iter 61000, loss: 4.736722
 >> iter 62000, loss: 4.614036
 >> iter 63000, loss: 4.619335
 >> iter 64000, loss: 4.566491
 >> iter 65000, loss: 4.532967
 >> iter 66000, loss: 4.481648
 >> iter 67000, loss: 4.508770
 >> iter 68000, loss: 4.444440
 >> iter 69000, loss: 4.484257
 >> iter 70000, loss: 4.450045
   Number of active neurons: 10
 >> iter 71000, loss: 4.448184
 >> iter 72000, loss: 4.457446
 >> iter 73000, loss: 4.456321
 >> iter 74000, loss: 4.425852
 >> iter 75000, loss: 4.399751
 >> iter 76000, loss: 4.308020
 >> iter 77000, loss: 4.115824
 >> iter 78000, loss: 4.039285
 >> iter 79000, loss: 3.928210
 >> iter 80000, loss: 3.946132
   Number of active neurons: 10
 >> iter 81000, loss: 3.955263
 >> iter 82000, loss: 3.867911
 >> iter 83000, loss: 3.807000
 >> iter 84000, loss: 3.824659
 >> iter 85000, loss: 3.828018
 >> iter 86000, loss: 3.842538
 >> iter 87000, loss: 3.938445
 >> iter 88000, loss: 3.954966
 >> iter 89000, loss: 3.878765
 >> iter 90000, loss: 3.899629
   Number of active neurons: 10
 >> iter 91000, loss: 3.889636
 >> iter 92000, loss: 3.935446
 >> iter 93000, loss: 4.034701
 >> iter 94000, loss: 3.984066
 >> iter 95000, loss: 3.920706
 >> iter 96000, loss: 3.943429
 >> iter 97000, loss: 3.851992
 >> iter 98000, loss: 3.859891
 >> iter 99000, loss: 3.802835
 >> iter 100000, loss: 4.024934
   Number of active neurons: 10
 >> iter 101000, loss: 3.849970
 >> iter 102000, loss: 3.858633
 >> iter 103000, loss: 3.950873
 >> iter 104000, loss: 3.854191
 >> iter 105000, loss: 4.024335
 >> iter 106000, loss: 3.929809
 >> iter 107000, loss: 3.866665
 >> iter 108000, loss: 3.846974
 >> iter 109000, loss: 3.807756
 >> iter 110000, loss: 3.809514
   Number of active neurons: 10
 >> iter 111000, loss: 3.692650
 >> iter 112000, loss: 3.837710
 >> iter 113000, loss: 3.884554
 >> iter 114000, loss: 3.834435
 >> iter 115000, loss: 3.926322
 >> iter 116000, loss: 3.881135
 >> iter 117000, loss: 3.761144
 >> iter 118000, loss: 3.865205
 >> iter 119000, loss: 3.777440
 >> iter 120000, loss: 3.830586
   Number of active neurons: 10
 >> iter 121000, loss: 3.838519
 >> iter 122000, loss: 3.908076
 >> iter 123000, loss: 3.829009
 >> iter 124000, loss: 3.973687
 >> iter 125000, loss: 3.914888
 >> iter 126000, loss: 3.828705
 >> iter 127000, loss: 3.801222
 >> iter 128000, loss: 3.756525
 >> iter 129000, loss: 3.976483
 >> iter 130000, loss: 3.866994
   Number of active neurons: 10
 >> iter 131000, loss: 3.812701
 >> iter 132000, loss: 3.762265
 >> iter 133000, loss: 3.980685
 >> iter 134000, loss: 3.821695
 >> iter 135000, loss: 3.765369
 >> iter 136000, loss: 3.803873
 >> iter 137000, loss: 3.827526
 >> iter 138000, loss: 3.835274
 >> iter 139000, loss: 3.745651
 >> iter 140000, loss: 3.926643
   Number of active neurons: 10
 >> iter 141000, loss: 3.991037
 >> iter 142000, loss: 4.252685
 >> iter 143000, loss: 4.119533
 >> iter 144000, loss: 3.912670
 >> iter 145000, loss: 3.919456
 >> iter 146000, loss: 3.647367
 >> iter 147000, loss: 3.507103
 >> iter 148000, loss: 3.646521
 >> iter 149000, loss: 3.407446
 >> iter 150000, loss: 3.244649
   Number of active neurons: 10
 >> iter 151000, loss: 2.946301
 >> iter 152000, loss: 3.530733
 >> iter 153000, loss: 3.017709
 >> iter 154000, loss: 2.870403
 >> iter 155000, loss: 2.908973
 >> iter 156000, loss: 3.250045
 >> iter 157000, loss: 3.017727
 >> iter 158000, loss: 2.896580
 >> iter 159000, loss: 2.829014
 >> iter 160000, loss: 2.820067
   Number of active neurons: 10
 >> iter 161000, loss: 2.697791
 >> iter 162000, loss: 2.740926
 >> iter 163000, loss: 2.742413
 >> iter 164000, loss: 2.735964
 >> iter 165000, loss: 2.603535
 >> iter 166000, loss: 2.687811
 >> iter 167000, loss: 2.962224
 >> iter 168000, loss: 2.912507
 >> iter 169000, loss: 2.944488
 >> iter 170000, loss: 2.945738
   Number of active neurons: 10
 >> iter 171000, loss: 2.750934
 >> iter 172000, loss: 2.826890
 >> iter 173000, loss: 2.666011
 >> iter 174000, loss: 2.680192
 >> iter 175000, loss: 2.556319
 >> iter 176000, loss: 2.695468
 >> iter 177000, loss: 2.475222
 >> iter 178000, loss: 2.558471
 >> iter 179000, loss: 2.513570
 >> iter 180000, loss: 2.685630
   Number of active neurons: 10
 >> iter 181000, loss: 2.298451
 >> iter 182000, loss: 2.368739
 >> iter 183000, loss: 2.512895
 >> iter 184000, loss: 3.654068
 >> iter 185000, loss: 3.421065
 >> iter 186000, loss: 2.947215
 >> iter 187000, loss: 2.841912
 >> iter 188000, loss: 2.991362
 >> iter 189000, loss: 3.205619
 >> iter 190000, loss: 3.181577
   Number of active neurons: 10
 >> iter 191000, loss: 3.129844
 >> iter 192000, loss: 3.278764
 >> iter 193000, loss: 3.028946
 >> iter 194000, loss: 2.803689
 >> iter 195000, loss: 2.569241
 >> iter 196000, loss: 2.430375
 >> iter 197000, loss: 2.484200
 >> iter 198000, loss: 2.518612
 >> iter 199000, loss: 2.681438
 >> iter 200000, loss: 2.435831
   Number of active neurons: 10
 >> iter 201000, loss: 2.560256
 >> iter 202000, loss: 2.505082
 >> iter 203000, loss: 2.170667
 >> iter 204000, loss: 1.965664
 >> iter 205000, loss: 2.187603
 >> iter 206000, loss: 2.293857
 >> iter 207000, loss: 2.158378
 >> iter 208000, loss: 2.030465
 >> iter 209000, loss: 1.982789
 >> iter 210000, loss: 2.016376
   Number of active neurons: 10
 >> iter 211000, loss: 2.180750
 >> iter 212000, loss: 2.060188
 >> iter 213000, loss: 1.737543
 >> iter 214000, loss: 1.663541
 >> iter 215000, loss: 1.983778
 >> iter 216000, loss: 1.780859
 >> iter 217000, loss: 1.761448
 >> iter 218000, loss: 1.751113
 >> iter 219000, loss: 2.042966
 >> iter 220000, loss: 1.774888
   Number of active neurons: 10
 >> iter 221000, loss: 1.216386
 >> iter 222000, loss: 0.892334
 >> iter 223000, loss: 0.632394
 >> iter 224000, loss: 0.583388
 >> iter 225000, loss: 0.480339
 >> iter 226000, loss: 0.511730
 >> iter 227000, loss: 0.491341
 >> iter 228000, loss: 0.409410
 >> iter 229000, loss: 0.284476
 >> iter 230000, loss: 0.496192
   Number of active neurons: 10
 >> iter 231000, loss: 0.618555
 >> iter 232000, loss: 0.623920
 >> iter 233000, loss: 0.479489
 >> iter 234000, loss: 0.516407
 >> iter 235000, loss: 0.477775
 >> iter 236000, loss: 0.343526
 >> iter 237000, loss: 0.292617
 >> iter 238000, loss: 0.314706
 >> iter 239000, loss: 0.360189
 >> iter 240000, loss: 0.299303
   Number of active neurons: 10
 >> iter 241000, loss: 0.210336
 >> iter 242000, loss: 0.176502
 >> iter 243000, loss: 0.223939
 >> iter 244000, loss: 0.275016
 >> iter 245000, loss: 0.250032
 >> iter 246000, loss: 0.213823
 >> iter 247000, loss: 0.246977
 >> iter 248000, loss: 0.261111
 >> iter 249000, loss: 0.302802
 >> iter 250000, loss: 0.253305
   Number of active neurons: 10
 >> iter 251000, loss: 0.220477
 >> iter 252000, loss: 0.330691
 >> iter 253000, loss: 0.161652
 >> iter 254000, loss: 0.344690
 >> iter 255000, loss: 0.227380
 >> iter 256000, loss: 0.191770
 >> iter 257000, loss: 0.215996
 >> iter 258000, loss: 0.360447
 >> iter 259000, loss: 0.229690
 >> iter 260000, loss: 0.514370
   Number of active neurons: 10
 >> iter 261000, loss: 0.340918
 >> iter 262000, loss: 0.231075
 >> iter 263000, loss: 0.183852
 >> iter 264000, loss: 0.180475
 >> iter 265000, loss: 0.125200
 >> iter 266000, loss: 0.088176
 >> iter 267000, loss: 0.121331
 >> iter 268000, loss: 0.122100
 >> iter 269000, loss: 0.191993
 >> iter 270000, loss: 0.182215
   Number of active neurons: 10
 >> iter 271000, loss: 0.183525
 >> iter 272000, loss: 0.141207
 >> iter 273000, loss: 0.157416
 >> iter 274000, loss: 0.399432
 >> iter 275000, loss: 0.249738
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0739985200296
   - Test - Long: 0.0
   - Test - Big: 0.0919990800092
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.185674
 >> iter 2000, loss: 10.861119
 >> iter 3000, loss: 8.843597
 >> iter 4000, loss: 8.115531
 >> iter 5000, loss: 7.797366
 >> iter 6000, loss: 7.688805
 >> iter 7000, loss: 7.637852
 >> iter 8000, loss: 7.615000
 >> iter 9000, loss: 7.615444
 >> iter 10000, loss: 7.596304
   Number of active neurons: 10
 >> iter 11000, loss: 7.596705
 >> iter 12000, loss: 7.586300
 >> iter 13000, loss: 7.592862
 >> iter 14000, loss: 7.580108
 >> iter 15000, loss: 7.583231
 >> iter 16000, loss: 7.576565
 >> iter 17000, loss: 7.581899
 >> iter 18000, loss: 7.573591
 >> iter 19000, loss: 7.580327
 >> iter 20000, loss: 7.572303
   Number of active neurons: 10
 >> iter 21000, loss: 7.581345
 >> iter 22000, loss: 7.574208
 >> iter 23000, loss: 7.581774
 >> iter 24000, loss: 7.573878
 >> iter 25000, loss: 7.580398
 >> iter 26000, loss: 7.573318
 >> iter 27000, loss: 7.579248
 >> iter 28000, loss: 7.575329
 >> iter 29000, loss: 7.580100
 >> iter 30000, loss: 7.577594
   Number of active neurons: 10
 >> iter 31000, loss: 7.579019
 >> iter 32000, loss: 7.574975
 >> iter 33000, loss: 7.580563
 >> iter 34000, loss: 7.569823
 >> iter 35000, loss: 7.618500
 >> iter 36000, loss: 7.578785
 >> iter 37000, loss: 7.493876
 >> iter 38000, loss: 7.231350
 >> iter 39000, loss: 7.007986
 >> iter 40000, loss: 6.851319
   Number of active neurons: 10
 >> iter 41000, loss: 6.842701
 >> iter 42000, loss: 6.694135
 >> iter 43000, loss: 6.409523
 >> iter 44000, loss: 6.147251
 >> iter 45000, loss: 5.971060
 >> iter 46000, loss: 4.596544
 >> iter 47000, loss: 2.486870
 >> iter 48000, loss: 1.475133
 >> iter 49000, loss: 0.907999
 >> iter 50000, loss: 0.706741
   Number of active neurons: 10
 >> iter 51000, loss: 0.409941
 >> iter 52000, loss: 0.483279
 >> iter 53000, loss: 0.478205
 >> iter 54000, loss: 0.302667
 >> iter 55000, loss: 0.425484
 >> iter 56000, loss: 0.307925
 >> iter 57000, loss: 0.172326
 >> iter 58000, loss: 0.113635
 >> iter 59000, loss: 0.079128
 >> iter 60000, loss: 0.141019
   Number of active neurons: 10
 >> iter 61000, loss: 0.068708
 >> iter 62000, loss: 0.119688
 >> iter 63000, loss: 0.106514
 >> iter 64000, loss: 0.090969
 >> iter 65000, loss: 0.120175
 >> iter 66000, loss: 0.135027
 >> iter 67000, loss: 0.063483
 >> iter 68000, loss: 0.040380
 >> iter 69000, loss: 0.197890
 >> iter 70000, loss: 0.210202
   Number of active neurons: 10
 >> iter 71000, loss: 0.113729
 >> iter 72000, loss: 0.052285
 >> iter 73000, loss: 0.067565
 >> iter 74000, loss: 0.094819
 >> iter 75000, loss: 0.093085
 >> iter 76000, loss: 0.101378
 >> iter 77000, loss: 0.071035
 >> iter 78000, loss: 0.034324
 >> iter 79000, loss: 0.019666
 >> iter 80000, loss: 0.013726
   Number of active neurons: 10
 >> iter 81000, loss: 0.015017
 >> iter 82000, loss: 0.020026
 >> iter 83000, loss: 0.020353
 >> iter 84000, loss: 0.029518
 >> iter 85000, loss: 0.016162
 >> iter 86000, loss: 0.050729
 >> iter 87000, loss: 0.081036
 >> iter 88000, loss: 0.103022
 >> iter 89000, loss: 0.043385
 >> iter 90000, loss: 0.020843
   Number of active neurons: 10
 >> iter 91000, loss: 0.017957
 >> iter 92000, loss: 0.020061
 >> iter 93000, loss: 0.198016
 >> iter 94000, loss: 0.079277
 >> iter 95000, loss: 0.034251
 >> iter 96000, loss: 0.068300
 >> iter 97000, loss: 0.042984
 >> iter 98000, loss: 0.020451
 >> iter 99000, loss: 0.013892
 >> iter 100000, loss: 0.128053
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.051975
 >> iter 2000, loss: 10.824069
 >> iter 3000, loss: 8.823509
 >> iter 4000, loss: 8.064902
 >> iter 5000, loss: 7.784110
 >> iter 6000, loss: 7.689335
 >> iter 7000, loss: 7.702960
 >> iter 8000, loss: 7.625018
 >> iter 9000, loss: 7.604032
 >> iter 10000, loss: 7.595369
   Number of active neurons: 10
 >> iter 11000, loss: 7.590348
 >> iter 12000, loss: 7.569597
 >> iter 13000, loss: 7.587941
 >> iter 14000, loss: 7.514666
 >> iter 15000, loss: 7.263106
 >> iter 16000, loss: 7.083542
 >> iter 17000, loss: 6.891191
 >> iter 18000, loss: 6.776503
 >> iter 19000, loss: 6.743168
 >> iter 20000, loss: 6.700008
   Number of active neurons: 10
 >> iter 21000, loss: 6.660829
 >> iter 22000, loss: 6.640310
 >> iter 23000, loss: 6.619890
 >> iter 24000, loss: 6.574965
 >> iter 25000, loss: 6.468876
 >> iter 26000, loss: 6.247785
 >> iter 27000, loss: 6.049399
 >> iter 28000, loss: 5.818706
 >> iter 29000, loss: 5.690051
 >> iter 30000, loss: 5.529851
   Number of active neurons: 10
 >> iter 31000, loss: 5.419606
 >> iter 32000, loss: 5.316300
 >> iter 33000, loss: 5.281639
 >> iter 34000, loss: 5.189644
 >> iter 35000, loss: 5.166392
 >> iter 36000, loss: 5.037852
 >> iter 37000, loss: 4.968641
 >> iter 38000, loss: 4.858794
 >> iter 39000, loss: 4.840113
 >> iter 40000, loss: 4.713737
   Number of active neurons: 10
 >> iter 41000, loss: 4.679563
 >> iter 42000, loss: 4.589952
 >> iter 43000, loss: 4.670281
 >> iter 44000, loss: 4.609592
 >> iter 45000, loss: 4.669301
 >> iter 46000, loss: 4.530105
 >> iter 47000, loss: 4.555050
 >> iter 48000, loss: 4.482006
 >> iter 49000, loss: 4.435448
 >> iter 50000, loss: 4.307712
   Number of active neurons: 10
 >> iter 51000, loss: 4.333619
 >> iter 52000, loss: 4.299681
 >> iter 53000, loss: 4.309896
 >> iter 54000, loss: 4.227908
 >> iter 55000, loss: 4.291431
 >> iter 56000, loss: 4.218110
 >> iter 57000, loss: 4.237449
 >> iter 58000, loss: 4.186714
 >> iter 59000, loss: 4.226243
 >> iter 60000, loss: 4.210170
   Number of active neurons: 10
 >> iter 61000, loss: 4.209249
 >> iter 62000, loss: 4.148113
 >> iter 63000, loss: 4.185349
 >> iter 64000, loss: 4.136346
 >> iter 65000, loss: 4.174388
 >> iter 66000, loss: 4.097841
 >> iter 67000, loss: 4.142680
 >> iter 68000, loss: 4.094077
 >> iter 69000, loss: 4.149122
 >> iter 70000, loss: 4.092177
   Number of active neurons: 10
 >> iter 71000, loss: 4.178969
 >> iter 72000, loss: 4.140363
 >> iter 73000, loss: 4.155893
 >> iter 74000, loss: 4.171198
 >> iter 75000, loss: 4.169452
 >> iter 76000, loss: 4.125210
 >> iter 77000, loss: 4.187606
 >> iter 78000, loss: 4.103295
 >> iter 79000, loss: 4.135163
 >> iter 80000, loss: 4.104622
   Number of active neurons: 10
 >> iter 81000, loss: 4.152718
 >> iter 82000, loss: 4.101385
 >> iter 83000, loss: 4.117597
 >> iter 84000, loss: 4.101722
 >> iter 85000, loss: 4.165520
 >> iter 86000, loss: 4.128029
 >> iter 87000, loss: 4.102580
 >> iter 88000, loss: 4.097526
 >> iter 89000, loss: 4.124958
 >> iter 90000, loss: 4.136096
   Number of active neurons: 10
 >> iter 91000, loss: 4.138371
 >> iter 92000, loss: 4.069052
 >> iter 93000, loss: 4.125636
 >> iter 94000, loss: 4.132119
 >> iter 95000, loss: 4.236485
 >> iter 96000, loss: 4.121326
 >> iter 97000, loss: 4.134611
 >> iter 98000, loss: 4.148640
 >> iter 99000, loss: 4.124495
 >> iter 100000, loss: 4.082091
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 9.85780284394
   - Test - Long: 22.3788810559
   - Test - Big: 9.37990620094
   - Test - A: 16.0589294047
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.146303
 >> iter 2000, loss: 10.952836
 >> iter 3000, loss: 8.885340
 >> iter 4000, loss: 8.072298
 >> iter 5000, loss: 7.841526
 >> iter 6000, loss: 7.708505
 >> iter 7000, loss: 7.663884
 >> iter 8000, loss: 7.603834
 >> iter 9000, loss: 7.587693
 >> iter 10000, loss: 7.579823
   Number of active neurons: 10
 >> iter 11000, loss: 7.575468
 >> iter 12000, loss: 7.564245
 >> iter 13000, loss: 7.570455
 >> iter 14000, loss: 7.580522
 >> iter 15000, loss: 7.574242
 >> iter 16000, loss: 7.561203
 >> iter 17000, loss: 7.564189
 >> iter 18000, loss: 7.584392
 >> iter 19000, loss: 7.577501
 >> iter 20000, loss: 7.561338
   Number of active neurons: 10
 >> iter 21000, loss: 7.603667
 >> iter 22000, loss: 7.589784
 >> iter 23000, loss: 7.570841
 >> iter 24000, loss: 7.514654
 >> iter 25000, loss: 7.416465
 >> iter 26000, loss: 7.167451
 >> iter 27000, loss: 7.084772
 >> iter 28000, loss: 6.892398
 >> iter 29000, loss: 6.787829
 >> iter 30000, loss: 6.722553
   Number of active neurons: 10
 >> iter 31000, loss: 6.626549
 >> iter 32000, loss: 6.393702
 >> iter 33000, loss: 6.071776
 >> iter 34000, loss: 5.828247
 >> iter 35000, loss: 5.721691
 >> iter 36000, loss: 5.589121
 >> iter 37000, loss: 5.568246
 >> iter 38000, loss: 5.398044
 >> iter 39000, loss: 5.266094
 >> iter 40000, loss: 5.134206
   Number of active neurons: 10
 >> iter 41000, loss: 4.998890
 >> iter 42000, loss: 4.834657
 >> iter 43000, loss: 4.634924
 >> iter 44000, loss: 4.070141
 >> iter 45000, loss: 2.098829
 >> iter 46000, loss: 1.266865
 >> iter 47000, loss: 0.726566
 >> iter 48000, loss: 0.511751
 >> iter 49000, loss: 0.342188
 >> iter 50000, loss: 0.402233
   Number of active neurons: 10
 >> iter 51000, loss: 0.358121
 >> iter 52000, loss: 0.482170
 >> iter 53000, loss: 0.337883
 >> iter 54000, loss: 0.237123
 >> iter 55000, loss: 0.310353
 >> iter 56000, loss: 0.194858
 >> iter 57000, loss: 0.214343
 >> iter 58000, loss: 0.281754
 >> iter 59000, loss: 0.185964
 >> iter 60000, loss: 0.199102
   Number of active neurons: 10
 >> iter 61000, loss: 0.125415
 >> iter 62000, loss: 0.095988
 >> iter 63000, loss: 0.052255
 >> iter 64000, loss: 0.299887
 >> iter 65000, loss: 0.169692
 >> iter 66000, loss: 0.257512
 >> iter 67000, loss: 0.129170
 >> iter 68000, loss: 0.291762
 >> iter 69000, loss: 0.132358
 >> iter 70000, loss: 0.079433
   Number of active neurons: 10
 >> iter 71000, loss: 0.076847
 >> iter 72000, loss: 0.187406
 >> iter 73000, loss: 0.121205
 >> iter 74000, loss: 0.057581
 >> iter 75000, loss: 0.082076
 >> iter 76000, loss: 0.076578
 >> iter 77000, loss: 0.099191
 >> iter 78000, loss: 0.110633
 >> iter 79000, loss: 0.069628
 >> iter 80000, loss: 0.053724
   Number of active neurons: 10
 >> iter 81000, loss: 0.037733
 >> iter 82000, loss: 0.138212
 >> iter 83000, loss: 0.148191
 >> iter 84000, loss: 0.086677
 >> iter 85000, loss: 0.074292
 >> iter 86000, loss: 0.047202
 >> iter 87000, loss: 0.023716
 >> iter 88000, loss: 0.023583
 >> iter 89000, loss: 0.014306
 >> iter 90000, loss: 0.099408
   Number of active neurons: 10
 >> iter 91000, loss: 0.076940
 >> iter 92000, loss: 0.097007
 >> iter 93000, loss: 0.045015
 >> iter 94000, loss: 0.029574
 >> iter 95000, loss: 0.212260
 >> iter 96000, loss: 0.110466
 >> iter 97000, loss: 0.110941
 >> iter 98000, loss: 0.073892
 >> iter 99000, loss: 0.037811
 >> iter 100000, loss: 0.028750
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.099278
 >> iter 2000, loss: 10.859974
 >> iter 3000, loss: 8.856707
 >> iter 4000, loss: 8.077226
 >> iter 5000, loss: 7.795253
 >> iter 6000, loss: 7.662818
 >> iter 7000, loss: 7.626303
 >> iter 8000, loss: 7.595691
 >> iter 9000, loss: 7.590655
 >> iter 10000, loss: 7.585586
   Number of active neurons: 9
 >> iter 11000, loss: 7.586494
 >> iter 12000, loss: 7.574308
 >> iter 13000, loss: 7.623094
 >> iter 14000, loss: 7.587612
 >> iter 15000, loss: 7.587696
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 7.575289
 >> iter 17000, loss: 7.582488
 >> iter 18000, loss: 7.571820
 >> iter 19000, loss: 7.585308
 >> iter 20000, loss: 7.573700
   Number of active neurons: 9
 >> iter 21000, loss: 7.579573
 >> iter 22000, loss: 7.573437
 >> iter 23000, loss: 7.578831
 >> iter 24000, loss: 7.569461
 >> iter 25000, loss: 7.578451
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 26000, loss: 7.574216
 >> iter 27000, loss: 7.578383
 >> iter 28000, loss: 7.571117
 >> iter 29000, loss: 7.577487
 >> iter 30000, loss: 7.574500
   Number of active neurons: 9
 >> iter 31000, loss: 7.581107
 >> iter 32000, loss: 7.552511
 >> iter 33000, loss: 7.653048
 >> iter 34000, loss: 7.448473
 >> iter 35000, loss: 7.223791
 >> iter 36000, loss: 7.054625
 >> iter 37000, loss: 6.846920
 >> iter 38000, loss: 6.598258
 >> iter 39000, loss: 6.442113
 >> iter 40000, loss: 6.320987
   Number of active neurons: 10
 >> iter 41000, loss: 6.238036
 >> iter 42000, loss: 6.078599
 >> iter 43000, loss: 5.823231
 >> iter 44000, loss: 5.462457
 >> iter 45000, loss: 4.900596
 >> iter 46000, loss: 4.567457
 >> iter 47000, loss: 2.478705
 >> iter 48000, loss: 1.583442
 >> iter 49000, loss: 0.814516
 >> iter 50000, loss: 0.400464
   Number of active neurons: 10
 >> iter 51000, loss: 0.269884
 >> iter 52000, loss: 0.216473
 >> iter 53000, loss: 0.213480
 >> iter 54000, loss: 0.132478
 >> iter 55000, loss: 0.145131
 >> iter 56000, loss: 0.116481
 >> iter 57000, loss: 0.092255
 >> iter 58000, loss: 0.067381
 >> iter 59000, loss: 0.073559
 >> iter 60000, loss: 0.040047
   Number of active neurons: 10
 >> iter 61000, loss: 0.025810
 >> iter 62000, loss: 0.025445
 >> iter 63000, loss: 0.086648
 >> iter 64000, loss: 0.071854
 >> iter 65000, loss: 0.034808
 >> iter 66000, loss: 0.054256
 >> iter 67000, loss: 0.027548
 >> iter 68000, loss: 0.017418
 >> iter 69000, loss: 0.066018
 >> iter 70000, loss: 0.065337
   Number of active neurons: 10
 >> iter 71000, loss: 0.064025
 >> iter 72000, loss: 0.032186
 >> iter 73000, loss: 0.018334
 >> iter 74000, loss: 0.012534
 >> iter 75000, loss: 0.011705
 >> iter 76000, loss: 0.042377
 >> iter 77000, loss: 0.035950
 >> iter 78000, loss: 0.027693
 >> iter 79000, loss: 0.016710
 >> iter 80000, loss: 0.012346
   Number of active neurons: 10
 >> iter 81000, loss: 0.108191
 >> iter 82000, loss: 0.047423
 >> iter 83000, loss: 0.102766
 >> iter 84000, loss: 0.203547
 >> iter 85000, loss: 0.116341
 >> iter 86000, loss: 0.055103
 >> iter 87000, loss: 0.044671
 >> iter 88000, loss: 0.069420
 >> iter 89000, loss: 0.110572
 >> iter 90000, loss: 0.047451
   Number of active neurons: 10
 >> iter 91000, loss: 0.080563
 >> iter 92000, loss: 0.133325
 >> iter 93000, loss: 0.129412
 >> iter 94000, loss: 0.080986
 >> iter 95000, loss: 0.035638
 >> iter 96000, loss: 0.073931
 >> iter 97000, loss: 0.051911
 >> iter 98000, loss: 0.025626
 >> iter 99000, loss: 0.014407
 >> iter 100000, loss: 0.009989
   Number of active neurons: 10
 >> iter 101000, loss: 0.008128
 >> iter 102000, loss: 0.007011
 >> iter 103000, loss: 0.024311
 >> iter 104000, loss: 0.072662
 >> iter 105000, loss: 0.032635
 >> iter 106000, loss: 0.079201
 >> iter 107000, loss: 0.033666
 >> iter 108000, loss: 0.016379
 >> iter 109000, loss: 0.009804
 >> iter 110000, loss: 0.007214
   Number of active neurons: 10
 >> iter 111000, loss: 0.006212
 >> iter 112000, loss: 0.005564
 >> iter 113000, loss: 0.005179
 >> iter 114000, loss: 0.004987
 >> iter 115000, loss: 0.023128
 >> iter 116000, loss: 0.027849
 >> iter 117000, loss: 0.013748
 >> iter 118000, loss: 0.008197
 >> iter 119000, loss: 0.006166
 >> iter 120000, loss: 0.005107
   Number of active neurons: 10
 >> iter 121000, loss: 0.012804
 >> iter 122000, loss: 0.007445
 >> iter 123000, loss: 0.034200
 >> iter 124000, loss: 0.018572
 >> iter 125000, loss: 0.009385
 >> iter 126000, loss: 0.005968
 >> iter 127000, loss: 0.051365
 >> iter 128000, loss: 0.021638
 >> iter 129000, loss: 0.012204
 >> iter 130000, loss: 0.007102
   Number of active neurons: 10
 >> iter 131000, loss: 0.004951
 >> iter 132000, loss: 0.013040
 >> iter 133000, loss: 0.039479
 >> iter 134000, loss: 0.016874
 >> iter 135000, loss: 0.008879
 >> iter 136000, loss: 0.006099
 >> iter 137000, loss: 0.004327
 >> iter 138000, loss: 0.049215
 >> iter 139000, loss: 0.020469
 >> iter 140000, loss: 0.101736
   Number of active neurons: 10
 >> iter 141000, loss: 0.039944
 >> iter 142000, loss: 0.016923
 >> iter 143000, loss: 0.008330
 >> iter 144000, loss: 0.005101
 >> iter 145000, loss: 0.003946
 >> iter 146000, loss: 0.013788
 >> iter 147000, loss: 0.007039
 >> iter 148000, loss: 0.004533
 >> iter 149000, loss: 0.003508
 >> iter 150000, loss: 0.003161
   Number of active neurons: 10
 >> iter 151000, loss: 0.003168
 >> iter 152000, loss: 0.002998
 >> iter 153000, loss: 0.003137
 >> iter 154000, loss: 0.002851
 >> iter 155000, loss: 0.002829
 >> iter 156000, loss: 0.002655
 >> iter 157000, loss: 0.002626
 >> iter 158000, loss: 0.011001
 >> iter 159000, loss: 0.044790
 >> iter 160000, loss: 0.036311
   Number of active neurons: 10
 >> iter 161000, loss: 0.015180
 >> iter 162000, loss: 0.049569
 >> iter 163000, loss: 0.020764
 >> iter 164000, loss: 0.009512
 >> iter 165000, loss: 0.005503
 >> iter 166000, loss: 0.004581
 >> iter 167000, loss: 0.042395
 >> iter 168000, loss: 0.017329
 >> iter 169000, loss: 0.009566
 >> iter 170000, loss: 0.070669
   Number of active neurons: 10
 >> iter 171000, loss: 0.028161
 >> iter 172000, loss: 0.056534
 >> iter 173000, loss: 0.022747
 >> iter 174000, loss: 0.010153
 >> iter 175000, loss: 0.005988
 >> iter 176000, loss: 0.003941
 >> iter 177000, loss: 0.003032
 >> iter 178000, loss: 0.002689
 >> iter 179000, loss: 0.002476
 >> iter 180000, loss: 0.002417
   Number of active neurons: 10
 >> iter 181000, loss: 0.002266
 >> iter 182000, loss: 0.002513
 >> iter 183000, loss: 0.002383
 >> iter 184000, loss: 0.002234
 >> iter 185000, loss: 0.002161
 >> iter 186000, loss: 0.002125
 >> iter 187000, loss: 0.002053
 >> iter 188000, loss: 0.002031
 >> iter 189000, loss: 0.002019
 >> iter 190000, loss: 0.001987
   Number of active neurons: 10
 >> iter 191000, loss: 0.001936
 >> iter 192000, loss: 0.001926
 >> iter 193000, loss: 0.001870
 >> iter 194000, loss: 0.076649
 >> iter 195000, loss: 0.089620
 >> iter 196000, loss: 0.034354
 >> iter 197000, loss: 0.014144
 >> iter 198000, loss: 0.036820
 >> iter 199000, loss: 0.036291
 >> iter 200000, loss: 0.014890
   Number of active neurons: 10
 >> iter 201000, loss: 0.009577
 >> iter 202000, loss: 0.004970
 >> iter 203000, loss: 0.003240
 >> iter 204000, loss: 0.029115
 >> iter 205000, loss: 0.012114
 >> iter 206000, loss: 0.007582
 >> iter 207000, loss: 0.004218
 >> iter 208000, loss: 0.002987
 >> iter 209000, loss: 0.002408
 >> iter 210000, loss: 0.002220
   Number of active neurons: 10
 >> iter 211000, loss: 0.002109
 >> iter 212000, loss: 0.002016
 >> iter 213000, loss: 0.002178
 >> iter 214000, loss: 0.002082
 >> iter 215000, loss: 0.043309
 >> iter 216000, loss: 0.018163
 >> iter 217000, loss: 0.035359
 >> iter 218000, loss: 0.014354
 >> iter 219000, loss: 0.006692
 >> iter 220000, loss: 0.003727
   Number of active neurons: 10
 >> iter 221000, loss: 0.069483
 >> iter 222000, loss: 0.026783
 >> iter 223000, loss: 0.068236
 >> iter 224000, loss: 0.026415
 >> iter 225000, loss: 0.011025
 >> iter 226000, loss: 0.005349
 >> iter 227000, loss: 0.003195
 >> iter 228000, loss: 0.002397
 >> iter 229000, loss: 0.002045
 >> iter 230000, loss: 0.001944
   Number of active neurons: 10
 >> iter 231000, loss: 0.022520
 >> iter 232000, loss: 0.009567
 >> iter 233000, loss: 0.004720
 >> iter 234000, loss: 0.002915
 >> iter 235000, loss: 0.002223
 >> iter 236000, loss: 0.002116
 >> iter 237000, loss: 0.001913
 >> iter 238000, loss: 0.001830
 >> iter 239000, loss: 0.001753
 >> iter 240000, loss: 0.001890
   Number of active neurons: 10
 >> iter 241000, loss: 0.001789
 >> iter 242000, loss: 0.001738
 >> iter 243000, loss: 0.001666
 >> iter 244000, loss: 0.001651
 >> iter 245000, loss: 0.008951
 >> iter 246000, loss: 0.004635
 >> iter 247000, loss: 0.002701
 >> iter 248000, loss: 0.001965
 >> iter 249000, loss: 0.020842
 >> iter 250000, loss: 0.008766
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.334682
 >> iter 2000, loss: 10.994286
 >> iter 3000, loss: 8.908142
 >> iter 4000, loss: 8.114510
 >> iter 5000, loss: 7.796075
 >> iter 6000, loss: 7.654988
 >> iter 7000, loss: 7.601873
 >> iter 8000, loss: 7.571423
 >> iter 9000, loss: 7.569714
 >> iter 10000, loss: 7.551157
   Number of active neurons: 10
 >> iter 11000, loss: 7.588941
 >> iter 12000, loss: 7.564725
 >> iter 13000, loss: 7.577315
 >> iter 14000, loss: 7.554135
 >> iter 15000, loss: 7.554654
 >> iter 16000, loss: 7.523309
 >> iter 17000, loss: 7.439102
 >> iter 18000, loss: 7.374761
 >> iter 19000, loss: 7.192861
 >> iter 20000, loss: 6.941486
   Number of active neurons: 10
 >> iter 21000, loss: 6.643731
 >> iter 22000, loss: 6.291483
 >> iter 23000, loss: 6.070489
 >> iter 24000, loss: 5.900802
 >> iter 25000, loss: 5.782897
 >> iter 26000, loss: 5.646214
 >> iter 27000, loss: 5.528847
 >> iter 28000, loss: 5.284936
 >> iter 29000, loss: 5.319572
 >> iter 30000, loss: 5.243385
   Number of active neurons: 10
 >> iter 31000, loss: 4.872410
 >> iter 32000, loss: 4.571609
 >> iter 33000, loss: 3.905912
 >> iter 34000, loss: 3.544378
 >> iter 35000, loss: 3.177482
 >> iter 36000, loss: 3.092482
 >> iter 37000, loss: 2.829194
 >> iter 38000, loss: 2.671287
 >> iter 39000, loss: 2.587082
 >> iter 40000, loss: 2.564790
   Number of active neurons: 10
 >> iter 41000, loss: 2.578068
 >> iter 42000, loss: 2.546416
 >> iter 43000, loss: 2.521942
 >> iter 44000, loss: 2.599033
 >> iter 45000, loss: 2.459045
 >> iter 46000, loss: 2.534441
 >> iter 47000, loss: 2.548121
 >> iter 48000, loss: 2.334680
 >> iter 49000, loss: 2.319822
 >> iter 50000, loss: 2.121862
   Number of active neurons: 10
 >> iter 51000, loss: 1.953279
 >> iter 52000, loss: 2.005406
 >> iter 53000, loss: 2.067752
 >> iter 54000, loss: 2.014903
 >> iter 55000, loss: 1.839322
 >> iter 56000, loss: 1.770449
 >> iter 57000, loss: 1.982772
 >> iter 58000, loss: 1.846308
 >> iter 59000, loss: 1.910812
 >> iter 60000, loss: 1.813915
   Number of active neurons: 10
 >> iter 61000, loss: 1.759814
 >> iter 62000, loss: 1.720183
 >> iter 63000, loss: 1.692030
 >> iter 64000, loss: 1.608483
 >> iter 65000, loss: 1.586315
 >> iter 66000, loss: 1.631453
 >> iter 67000, loss: 1.679917
 >> iter 68000, loss: 1.770730
 >> iter 69000, loss: 1.874220
 >> iter 70000, loss: 1.813493
   Number of active neurons: 10
 >> iter 71000, loss: 1.688716
 >> iter 72000, loss: 1.672421
 >> iter 73000, loss: 1.664242
 >> iter 74000, loss: 1.607769
 >> iter 75000, loss: 1.814869
 >> iter 76000, loss: 1.668801
 >> iter 77000, loss: 1.664328
 >> iter 78000, loss: 1.734649
 >> iter 79000, loss: 1.701925
 >> iter 80000, loss: 1.538681
   Number of active neurons: 10
 >> iter 81000, loss: 1.535253
 >> iter 82000, loss: 1.580767
 >> iter 83000, loss: 1.527184
 >> iter 84000, loss: 1.508394
 >> iter 85000, loss: 1.578831
 >> iter 86000, loss: 1.437827
 >> iter 87000, loss: 1.435855
 >> iter 88000, loss: 1.401079
 >> iter 89000, loss: 1.573992
 >> iter 90000, loss: 1.549685
   Number of active neurons: 10
 >> iter 91000, loss: 1.494157
 >> iter 92000, loss: 1.507197
 >> iter 93000, loss: 1.462197
 >> iter 94000, loss: 1.395553
 >> iter 95000, loss: 1.490274
 >> iter 96000, loss: 1.458015
 >> iter 97000, loss: 1.517468
 >> iter 98000, loss: 1.428169
 >> iter 99000, loss: 1.410329
 >> iter 100000, loss: 1.413270
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 3.7559248815
   - Test - Long: 17.8041097945
   - Test - Big: 3.39296607034
   - Test - A: 15.3923071795
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 16.273962
 >> iter 2000, loss: 10.906083
 >> iter 3000, loss: 8.830221
 >> iter 4000, loss: 8.050575
 >> iter 5000, loss: 7.765545
 >> iter 6000, loss: 7.653298
 >> iter 7000, loss: 7.593484
 >> iter 8000, loss: 7.561896
 >> iter 9000, loss: 7.559002
 >> iter 10000, loss: 7.542175
   Number of active neurons: 10
 >> iter 11000, loss: 7.543385
 >> iter 12000, loss: 7.542790
 >> iter 13000, loss: 7.540824
 >> iter 14000, loss: 7.529604
 >> iter 15000, loss: 7.536738
 >> iter 16000, loss: 7.523627
 >> iter 17000, loss: 7.533757
 >> iter 18000, loss: 7.552423
 >> iter 19000, loss: 7.543078
 >> iter 20000, loss: 7.528854
   Number of active neurons: 10
 >> iter 21000, loss: 7.533795
 >> iter 22000, loss: 7.522758
 >> iter 23000, loss: 7.527484
 >> iter 24000, loss: 7.522707
 >> iter 25000, loss: 7.529179
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 26000, loss: 7.529436
 >> iter 27000, loss: 7.567382
 >> iter 28000, loss: 7.516094
 >> iter 29000, loss: 7.194707
 >> iter 30000, loss: 6.968426
   Number of active neurons: 10
 >> iter 31000, loss: 6.911041
 >> iter 32000, loss: 6.781849
 >> iter 33000, loss: 6.703163
 >> iter 34000, loss: 6.539450
 >> iter 35000, loss: 6.398482
 >> iter 36000, loss: 6.141139
 >> iter 37000, loss: 5.983121
 >> iter 38000, loss: 5.856413
 >> iter 39000, loss: 5.729159
 >> iter 40000, loss: 5.539324
   Number of active neurons: 10
 >> iter 41000, loss: 5.374264
 >> iter 42000, loss: 5.262348
 >> iter 43000, loss: 5.162730
 >> iter 44000, loss: 5.096275
 >> iter 45000, loss: 5.077845
 >> iter 46000, loss: 5.056438
 >> iter 47000, loss: 4.969694
 >> iter 48000, loss: 4.862357
 >> iter 49000, loss: 4.813501
 >> iter 50000, loss: 4.743580
   Number of active neurons: 10
 >> iter 51000, loss: 4.752301
 >> iter 52000, loss: 4.677329
 >> iter 53000, loss: 4.678444
 >> iter 54000, loss: 4.626086
 >> iter 55000, loss: 4.652277
 >> iter 56000, loss: 4.575744
 >> iter 57000, loss: 4.612115
 >> iter 58000, loss: 4.533534
 >> iter 59000, loss: 4.581864
 >> iter 60000, loss: 4.513436
   Number of active neurons: 10
 >> iter 61000, loss: 4.557520
 >> iter 62000, loss: 4.525980
 >> iter 63000, loss: 4.543482
 >> iter 64000, loss: 4.503424
 >> iter 65000, loss: 4.545170
 >> iter 66000, loss: 4.509681
 >> iter 67000, loss: 4.595523
 >> iter 68000, loss: 4.569123
 >> iter 69000, loss: 4.532321
 >> iter 70000, loss: 4.510892
   Number of active neurons: 10
 >> iter 71000, loss: 4.533001
 >> iter 72000, loss: 4.480912
 >> iter 73000, loss: 4.493302
 >> iter 74000, loss: 4.508214
 >> iter 75000, loss: 4.515763
 >> iter 76000, loss: 4.474239
 >> iter 77000, loss: 4.507839
 >> iter 78000, loss: 4.472240
 >> iter 79000, loss: 4.492301
 >> iter 80000, loss: 4.479614
   Number of active neurons: 10
 >> iter 81000, loss: 4.493769
 >> iter 82000, loss: 4.517211
 >> iter 83000, loss: 4.533195
 >> iter 84000, loss: 4.480486
 >> iter 85000, loss: 4.508269
 >> iter 86000, loss: 4.487538
 >> iter 87000, loss: 4.528434
 >> iter 88000, loss: 4.482715
 >> iter 89000, loss: 4.476799
 >> iter 90000, loss: 4.487898
   Number of active neurons: 10
 >> iter 91000, loss: 4.468658
 >> iter 92000, loss: 4.473880
 >> iter 93000, loss: 4.489089
 >> iter 94000, loss: 4.475697
 >> iter 95000, loss: 4.476196
 >> iter 96000, loss: 4.463772
 >> iter 97000, loss: 4.472270
 >> iter 98000, loss: 4.472704
 >> iter 99000, loss: 4.459366
 >> iter 100000, loss: 4.470164
   Number of active neurons: 10
 >> iter 101000, loss: 4.464425
 >> iter 102000, loss: 4.470947
 >> iter 103000, loss: 4.468285
 >> iter 104000, loss: 4.472322
 >> iter 105000, loss: 4.454702
 >> iter 106000, loss: 4.468551
 >> iter 107000, loss: 4.460056
 >> iter 108000, loss: 4.482713
 >> iter 109000, loss: 4.477725
 >> iter 110000, loss: 4.487789
   Number of active neurons: 10
 >> iter 111000, loss: 4.480133
 >> iter 112000, loss: 4.469024
 >> iter 113000, loss: 4.479479
 >> iter 114000, loss: 4.483099
 >> iter 115000, loss: 4.484048
 >> iter 116000, loss: 4.475251
 >> iter 117000, loss: 4.476620
 >> iter 118000, loss: 4.474181
 >> iter 119000, loss: 4.475523
 >> iter 120000, loss: 4.474286
   Number of active neurons: 10
 >> iter 121000, loss: 4.474224
 >> iter 122000, loss: 4.450035
 >> iter 123000, loss: 4.474552
 >> iter 124000, loss: 4.471665
 >> iter 125000, loss: 4.487261
 >> iter 126000, loss: 4.462919
 >> iter 127000, loss: 4.495903
 >> iter 128000, loss: 4.458682
 >> iter 129000, loss: 4.473325
 >> iter 130000, loss: 4.454144
   Number of active neurons: 10
 >> iter 131000, loss: 4.464631
 >> iter 132000, loss: 4.449269
 >> iter 133000, loss: 4.469961
 >> iter 134000, loss: 4.463887
 >> iter 135000, loss: 4.489815
 >> iter 136000, loss: 4.465859
 >> iter 137000, loss: 4.473132
 >> iter 138000, loss: 4.461461
 >> iter 139000, loss: 4.473348
 >> iter 140000, loss: 4.479872
   Number of active neurons: 10
 >> iter 141000, loss: 4.504585
 >> iter 142000, loss: 4.476779
 >> iter 143000, loss: 4.475307
 >> iter 144000, loss: 4.456519
 >> iter 145000, loss: 4.474256
 >> iter 146000, loss: 4.452072
 >> iter 147000, loss: 4.472962
 >> iter 148000, loss: 4.457506
 >> iter 149000, loss: 4.515701
 >> iter 150000, loss: 4.493430
   Number of active neurons: 10
 >> iter 151000, loss: 4.470452
 >> iter 152000, loss: 4.464968
 >> iter 153000, loss: 4.467806
 >> iter 154000, loss: 4.458629
 >> iter 155000, loss: 4.489764
 >> iter 156000, loss: 4.482192
 >> iter 157000, loss: 4.464817
 >> iter 158000, loss: 4.471631
 >> iter 159000, loss: 4.540163
 >> iter 160000, loss: 4.544833
   Number of active neurons: 10
 >> iter 161000, loss: 4.498710
 >> iter 162000, loss: 4.857870
 >> iter 163000, loss: 4.702219
 >> iter 164000, loss: 4.596353
 >> iter 165000, loss: 4.576262
 >> iter 166000, loss: 4.530325
 >> iter 167000, loss: 4.553409
 >> iter 168000, loss: 4.553438
 >> iter 169000, loss: 4.589500
 >> iter 170000, loss: 4.527067
   Number of active neurons: 10
 >> iter 171000, loss: 4.512022
 >> iter 172000, loss: 4.496482
 >> iter 173000, loss: 4.500559
 >> iter 174000, loss: 4.513161
 >> iter 175000, loss: 4.460146
 >> iter 176000, loss: 4.485375
 >> iter 177000, loss: 4.468822
 >> iter 178000, loss: 4.488143
 >> iter 179000, loss: 4.456066
 >> iter 180000, loss: 4.488812
   Number of active neurons: 10
 >> iter 181000, loss: 4.492066
 >> iter 182000, loss: 4.489995
 >> iter 183000, loss: 4.779210
 >> iter 184000, loss: 4.590498
 >> iter 185000, loss: 4.450701
 >> iter 186000, loss: 4.458382
 >> iter 187000, loss: 4.371960
 >> iter 188000, loss: 4.461414
 >> iter 189000, loss: 4.583893
 >> iter 190000, loss: 4.495509
   Number of active neurons: 10
 >> iter 191000, loss: 4.365080
 >> iter 192000, loss: 4.570884
 >> iter 193000, loss: 4.421120
 >> iter 194000, loss: 4.409686
 >> iter 195000, loss: 4.380567
 >> iter 196000, loss: 4.389261
 >> iter 197000, loss: 4.828085
 >> iter 198000, loss: 5.021602
 >> iter 199000, loss: 4.694955
 >> iter 200000, loss: 5.069030
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 12.585748285
   - Test - Long: 23.4638268087
   - Test - Big: 12.1288787112
   - Test - A: 10.0459969335
   - Test - B: 11.1059262716
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.294701
 >> iter 2000, loss: 10.909888
 >> iter 3000, loss: 8.984163
 >> iter 4000, loss: 8.146823
 >> iter 5000, loss: 7.802322
 >> iter 6000, loss: 7.664322
 >> iter 7000, loss: 7.638132
 >> iter 8000, loss: 7.622891
 >> iter 9000, loss: 7.612797
 >> iter 10000, loss: 7.590898
   Number of active neurons: 10
 >> iter 11000, loss: 7.587969
 >> iter 12000, loss: 7.580655
 >> iter 13000, loss: 7.582406
 >> iter 14000, loss: 7.580549
 >> iter 15000, loss: 7.587880
 >> iter 16000, loss: 7.577008
 >> iter 17000, loss: 7.582913
 >> iter 18000, loss: 7.576297
 >> iter 19000, loss: 7.593761
 >> iter 20000, loss: 7.589437
   Number of active neurons: 10
 >> iter 21000, loss: 7.591550
 >> iter 22000, loss: 7.622785
 >> iter 23000, loss: 7.599910
 >> iter 24000, loss: 7.580957
 >> iter 25000, loss: 7.583470
 >> iter 26000, loss: 7.575583
 >> iter 27000, loss: 7.582738
 >> iter 28000, loss: 7.577321
 >> iter 29000, loss: 7.581275
 >> iter 30000, loss: 7.577557
   Number of active neurons: 10
 >> iter 31000, loss: 7.582518
 >> iter 32000, loss: 7.576863
 >> iter 33000, loss: 7.589600
 >> iter 34000, loss: 7.578833
 >> iter 35000, loss: 7.584138
 >> iter 36000, loss: 7.577803
 >> iter 37000, loss: 7.580282
 >> iter 38000, loss: 7.570808
 >> iter 39000, loss: 7.575960
 >> iter 40000, loss: 7.567094
   Number of active neurons: 10
 >> iter 41000, loss: 7.572469
 >> iter 42000, loss: 7.558394
 >> iter 43000, loss: 7.565736
 >> iter 44000, loss: 7.605091
 >> iter 45000, loss: 7.586604
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 46000, loss: 7.561666
 >> iter 47000, loss: 7.570970
 >> iter 48000, loss: 7.557058
 >> iter 49000, loss: 7.566691
 >> iter 50000, loss: 7.551449
   Number of active neurons: 9
 >> iter 51000, loss: 7.566579
 >> iter 52000, loss: 7.553987
 >> iter 53000, loss: 7.566351
 >> iter 54000, loss: 7.552082
 >> iter 55000, loss: 7.563833
 >> iter 56000, loss: 7.552047
 >> iter 57000, loss: 7.562770
 >> iter 58000, loss: 7.551584
 >> iter 59000, loss: 7.562285
 >> iter 60000, loss: 7.552489
   Number of active neurons: 9
 >> iter 61000, loss: 7.560256
 >> iter 62000, loss: 7.550330
 >> iter 63000, loss: 7.559265
 >> iter 64000, loss: 7.547872
 >> iter 65000, loss: 7.558358
 >> iter 66000, loss: 7.549375
 >> iter 67000, loss: 7.590847
 >> iter 68000, loss: 7.558121
 >> iter 69000, loss: 7.553714
 >> iter 70000, loss: 7.535300
   Number of active neurons: 10
 >> iter 71000, loss: 7.556401
 >> iter 72000, loss: 7.485737
 >> iter 73000, loss: 7.410124
 >> iter 74000, loss: 7.289576
 >> iter 75000, loss: 7.204716
 >> iter 76000, loss: 7.037974
 >> iter 77000, loss: 6.949854
 >> iter 78000, loss: 6.800872
 >> iter 79000, loss: 6.641041
 >> iter 80000, loss: 6.448842
   Number of active neurons: 10
 >> iter 81000, loss: 6.221745
 >> iter 82000, loss: 6.056215
 >> iter 83000, loss: 6.026840
 >> iter 84000, loss: 5.942401
 >> iter 85000, loss: 5.890813
 >> iter 86000, loss: 5.834453
 >> iter 87000, loss: 5.777675
 >> iter 88000, loss: 5.738816
 >> iter 89000, loss: 5.612574
 >> iter 90000, loss: 5.534983
   Number of active neurons: 10
 >> iter 91000, loss: 5.379609
 >> iter 92000, loss: 5.311166
 >> iter 93000, loss: 5.129316
 >> iter 94000, loss: 4.975087
 >> iter 95000, loss: 4.882220
 >> iter 96000, loss: 4.291146
 >> iter 97000, loss: 2.533140
 >> iter 98000, loss: 1.676110
 >> iter 99000, loss: 1.291969
 >> iter 100000, loss: 0.937595
   Number of active neurons: 10
 >> iter 101000, loss: 0.817729
 >> iter 102000, loss: 0.478808
 >> iter 103000, loss: 0.261089
 >> iter 104000, loss: 0.600132
 >> iter 105000, loss: 0.629531
 >> iter 106000, loss: 0.491828
 >> iter 107000, loss: 0.354253
 >> iter 108000, loss: 0.293626
 >> iter 109000, loss: 0.275824
 >> iter 110000, loss: 0.329987
   Number of active neurons: 10
 >> iter 111000, loss: 0.271145
 >> iter 112000, loss: 0.241394
 >> iter 113000, loss: 0.295595
 >> iter 114000, loss: 0.273796
 >> iter 115000, loss: 0.199347
 >> iter 116000, loss: 0.159593
 >> iter 117000, loss: 0.156645
 >> iter 118000, loss: 0.234645
 >> iter 119000, loss: 0.144313
 >> iter 120000, loss: 0.149196
   Number of active neurons: 10
 >> iter 121000, loss: 0.105070
 >> iter 122000, loss: 0.056863
 >> iter 123000, loss: 0.075211
 >> iter 124000, loss: 0.100323
 >> iter 125000, loss: 0.206853
 >> iter 126000, loss: 0.167312
 >> iter 127000, loss: 0.207093
 >> iter 128000, loss: 0.188890
 >> iter 129000, loss: 0.083671
 >> iter 130000, loss: 0.045008
   Number of active neurons: 10
 >> iter 131000, loss: 0.075137
 >> iter 132000, loss: 0.038337
 >> iter 133000, loss: 0.129043
 >> iter 134000, loss: 0.069354
 >> iter 135000, loss: 0.233673
 >> iter 136000, loss: 0.249872
 >> iter 137000, loss: 0.150105
 >> iter 138000, loss: 0.189902
 >> iter 139000, loss: 0.136569
 >> iter 140000, loss: 0.062155
   Number of active neurons: 10
 >> iter 141000, loss: 0.053590
 >> iter 142000, loss: 0.040480
 >> iter 143000, loss: 0.040687
 >> iter 144000, loss: 0.029333
 >> iter 145000, loss: 0.019057
 >> iter 146000, loss: 0.014206
 >> iter 147000, loss: 0.111768
 >> iter 148000, loss: 0.079978
 >> iter 149000, loss: 0.201365
 >> iter 150000, loss: 0.101238
   Number of active neurons: 10
 >> iter 151000, loss: 0.138189
 >> iter 152000, loss: 0.202074
 >> iter 153000, loss: 0.180292
 >> iter 154000, loss: 0.075398
 >> iter 155000, loss: 0.142204
 >> iter 156000, loss: 0.272894
 >> iter 157000, loss: 0.127200
 >> iter 158000, loss: 0.173563
 >> iter 159000, loss: 0.177871
 >> iter 160000, loss: 0.101192
   Number of active neurons: 10
 >> iter 161000, loss: 0.049732
 >> iter 162000, loss: 0.059338
 >> iter 163000, loss: 0.112206
 >> iter 164000, loss: 0.064747
 >> iter 165000, loss: 0.036334
 >> iter 166000, loss: 0.020713
 >> iter 167000, loss: 0.058215
 >> iter 168000, loss: 0.028724
 >> iter 169000, loss: 0.019644
 >> iter 170000, loss: 0.041712
   Number of active neurons: 10
 >> iter 171000, loss: 0.022486
 >> iter 172000, loss: 0.014680
 >> iter 173000, loss: 0.150035
 >> iter 174000, loss: 0.061959
 >> iter 175000, loss: 0.030398
 >> iter 176000, loss: 0.162956
 >> iter 177000, loss: 0.174797
 >> iter 178000, loss: 0.249775
 >> iter 179000, loss: 0.138578
 >> iter 180000, loss: 0.118570
   Number of active neurons: 10
 >> iter 181000, loss: 0.054685
 >> iter 182000, loss: 0.032717
 >> iter 183000, loss: 0.116113
 >> iter 184000, loss: 0.060510
 >> iter 185000, loss: 0.126551
 >> iter 186000, loss: 0.155517
 >> iter 187000, loss: 0.065643
 >> iter 188000, loss: 0.031441
 >> iter 189000, loss: 0.076040
 >> iter 190000, loss: 0.071170
   Number of active neurons: 10
 >> iter 191000, loss: 0.033461
 >> iter 192000, loss: 0.019410
 >> iter 193000, loss: 0.064175
 >> iter 194000, loss: 0.036363
 >> iter 195000, loss: 0.140730
 >> iter 196000, loss: 0.067434
 >> iter 197000, loss: 0.043878
 >> iter 198000, loss: 0.029064
 >> iter 199000, loss: 0.016044
 >> iter 200000, loss: 0.010684
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 16.033863
 >> iter 2000, loss: 10.876352
 >> iter 3000, loss: 8.832636
 >> iter 4000, loss: 8.070995
 >> iter 5000, loss: 7.765997
 >> iter 6000, loss: 7.672654
 >> iter 7000, loss: 7.604727
 >> iter 8000, loss: 7.573513
 >> iter 9000, loss: 7.571689
 >> iter 10000, loss: 7.558731
   Number of active neurons: 10
 >> iter 11000, loss: 7.563775
 >> iter 12000, loss: 7.553376
 >> iter 13000, loss: 7.600245
 >> iter 14000, loss: 7.570742
 >> iter 15000, loss: 7.611595
 >> iter 16000, loss: 7.569441
 >> iter 17000, loss: 7.565195
 >> iter 18000, loss: 7.589479
 >> iter 19000, loss: 7.706644
 >> iter 20000, loss: 7.600718
   Number of active neurons: 10
 >> iter 21000, loss: 7.603405
 >> iter 22000, loss: 7.562098
 >> iter 23000, loss: 7.554462
 >> iter 24000, loss: 7.540710
 >> iter 25000, loss: 7.549035
 >> iter 26000, loss: 7.533486
 >> iter 27000, loss: 7.540050
 >> iter 28000, loss: 7.496988
 >> iter 29000, loss: 7.300285
 >> iter 30000, loss: 7.070656
   Number of active neurons: 10
 >> iter 31000, loss: 6.859132
 >> iter 32000, loss: 6.749941
 >> iter 33000, loss: 6.697490
 >> iter 34000, loss: 6.667883
 >> iter 35000, loss: 6.641772
 >> iter 36000, loss: 6.610887
 >> iter 37000, loss: 6.488552
 >> iter 38000, loss: 6.359866
 >> iter 39000, loss: 6.167632
 >> iter 40000, loss: 5.971469
   Number of active neurons: 10
 >> iter 41000, loss: 5.872871
 >> iter 42000, loss: 5.740209
 >> iter 43000, loss: 5.661851
 >> iter 44000, loss: 5.576071
 >> iter 45000, loss: 5.530832
 >> iter 46000, loss: 5.527078
 >> iter 47000, loss: 5.475747
 >> iter 48000, loss: 5.451012
 >> iter 49000, loss: 5.420748
 >> iter 50000, loss: 5.339002
   Number of active neurons: 10
 >> iter 51000, loss: 5.310306
 >> iter 52000, loss: 5.287685
 >> iter 53000, loss: 5.255316
 >> iter 54000, loss: 5.340945
 >> iter 55000, loss: 5.232591
 >> iter 56000, loss: 5.061845
 >> iter 57000, loss: 5.011002
 >> iter 58000, loss: 4.875707
 >> iter 59000, loss: 4.825622
 >> iter 60000, loss: 4.828756
   Number of active neurons: 10
 >> iter 61000, loss: 5.033539
 >> iter 62000, loss: 5.038885
 >> iter 63000, loss: 4.172709
 >> iter 64000, loss: 2.280684
 >> iter 65000, loss: 1.258402
 >> iter 66000, loss: 0.666746
 >> iter 67000, loss: 0.426787
 >> iter 68000, loss: 0.231306
 >> iter 69000, loss: 0.379805
 >> iter 70000, loss: 0.357597
   Number of active neurons: 10
 >> iter 71000, loss: 0.223536
 >> iter 72000, loss: 0.326806
 >> iter 73000, loss: 0.163621
 >> iter 74000, loss: 0.085776
 >> iter 75000, loss: 0.077522
 >> iter 76000, loss: 0.106438
 >> iter 77000, loss: 0.126660
 >> iter 78000, loss: 0.113899
 >> iter 79000, loss: 0.054436
 >> iter 80000, loss: 0.033933
   Number of active neurons: 10
 >> iter 81000, loss: 0.025967
 >> iter 82000, loss: 0.114287
 >> iter 83000, loss: 0.075603
 >> iter 84000, loss: 0.051744
 >> iter 85000, loss: 0.026813
 >> iter 86000, loss: 0.041866
 >> iter 87000, loss: 0.021913
 >> iter 88000, loss: 0.045195
 >> iter 89000, loss: 0.069742
 >> iter 90000, loss: 0.063555
   Number of active neurons: 10
 >> iter 91000, loss: 0.046124
 >> iter 92000, loss: 0.124850
 >> iter 93000, loss: 0.128774
 >> iter 94000, loss: 0.061378
 >> iter 95000, loss: 0.142541
 >> iter 96000, loss: 0.063761
 >> iter 97000, loss: 0.042189
 >> iter 98000, loss: 0.022670
 >> iter 99000, loss: 0.014617
 >> iter 100000, loss: 0.051716
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.369477
 >> iter 2000, loss: 10.944242
 >> iter 3000, loss: 8.845861
 >> iter 4000, loss: 8.072466
 >> iter 5000, loss: 7.766752
 >> iter 6000, loss: 7.656327
 >> iter 7000, loss: 7.597665
 >> iter 8000, loss: 7.571716
 >> iter 9000, loss: 7.562135
 >> iter 10000, loss: 7.547096
   Number of active neurons: 9
 >> iter 11000, loss: 7.551391
 >> iter 12000, loss: 7.544626
 >> iter 13000, loss: 7.561379
 >> iter 14000, loss: 7.540471
 >> iter 15000, loss: 7.548681
 >> iter 16000, loss: 7.536943
 >> iter 17000, loss: 7.549142
 >> iter 18000, loss: 7.558954
 >> iter 19000, loss: 7.551245
 >> iter 20000, loss: 7.592112
   Number of active neurons: 10
 >> iter 21000, loss: 7.564089
 >> iter 22000, loss: 7.538325
 >> iter 23000, loss: 7.545907
 >> iter 24000, loss: 7.529654
 >> iter 25000, loss: 7.536144
 >> iter 26000, loss: 7.526475
 >> iter 27000, loss: 7.537028
 >> iter 28000, loss: 7.528376
 >> iter 29000, loss: 7.535513
 >> iter 30000, loss: 7.516675
   Number of active neurons: 9
 >> iter 31000, loss: 7.532998
 >> iter 32000, loss: 7.569981
 >> iter 33000, loss: 7.598308
 >> iter 34000, loss: 7.403724
 >> iter 35000, loss: 7.158619
 >> iter 36000, loss: 6.710447
 >> iter 37000, loss: 6.175908
 >> iter 38000, loss: 5.777462
 >> iter 39000, loss: 5.653326
 >> iter 40000, loss: 5.257845
   Number of active neurons: 10
 >> iter 41000, loss: 5.009409
 >> iter 42000, loss: 4.832618
 >> iter 43000, loss: 4.725917
 >> iter 44000, loss: 4.631610
 >> iter 45000, loss: 4.336791
 >> iter 46000, loss: 4.174344
 >> iter 47000, loss: 4.080738
 >> iter 48000, loss: 4.031120
 >> iter 49000, loss: 3.946122
 >> iter 50000, loss: 3.877964
   Number of active neurons: 10
 >> iter 51000, loss: 3.850167
 >> iter 52000, loss: 3.828937
 >> iter 53000, loss: 3.905959
 >> iter 54000, loss: 3.829402
 >> iter 55000, loss: 3.780103
 >> iter 56000, loss: 3.713980
 >> iter 57000, loss: 3.700081
 >> iter 58000, loss: 3.745031
 >> iter 59000, loss: 3.672968
 >> iter 60000, loss: 3.619802
   Number of active neurons: 10
 >> iter 61000, loss: 3.512570
 >> iter 62000, loss: 3.449103
 >> iter 63000, loss: 3.443634
 >> iter 64000, loss: 3.459956
 >> iter 65000, loss: 3.412030
 >> iter 66000, loss: 3.382302
 >> iter 67000, loss: 3.462844
 >> iter 68000, loss: 3.399608
 >> iter 69000, loss: 3.400644
 >> iter 70000, loss: 3.364189
   Number of active neurons: 10
 >> iter 71000, loss: 3.370166
 >> iter 72000, loss: 3.346806
 >> iter 73000, loss: 3.326695
 >> iter 74000, loss: 3.269129
 >> iter 75000, loss: 3.282250
 >> iter 76000, loss: 3.256169
 >> iter 77000, loss: 3.087905
 >> iter 78000, loss: 2.944578
 >> iter 79000, loss: 2.841788
 >> iter 80000, loss: 2.806238
   Number of active neurons: 10
 >> iter 81000, loss: 2.788302
 >> iter 82000, loss: 2.790749
 >> iter 83000, loss: 2.812721
 >> iter 84000, loss: 2.803548
 >> iter 85000, loss: 2.772182
 >> iter 86000, loss: 2.769982
 >> iter 87000, loss: 2.776561
 >> iter 88000, loss: 2.774434
 >> iter 89000, loss: 2.732236
 >> iter 90000, loss: 2.763289
   Number of active neurons: 10
 >> iter 91000, loss: 2.742322
 >> iter 92000, loss: 2.733377
 >> iter 93000, loss: 2.720099
 >> iter 94000, loss: 2.794659
 >> iter 95000, loss: 2.786024
 >> iter 96000, loss: 2.925885
 >> iter 97000, loss: 2.874580
 >> iter 98000, loss: 2.739016
 >> iter 99000, loss: 2.550265
 >> iter 100000, loss: 2.642964
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 6.54186916262
   - Test - Long: 21.5389230538
   - Test - Big: 6.27693723063
   - Test - A: 16.2455836278
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.174398
 >> iter 2000, loss: 10.829896
 >> iter 3000, loss: 8.816489
 >> iter 4000, loss: 8.046827
 >> iter 5000, loss: 7.751226
 >> iter 6000, loss: 7.634493
 >> iter 7000, loss: 7.600415
 >> iter 8000, loss: 7.576189
 >> iter 9000, loss: 7.579882
 >> iter 10000, loss: 7.567095
   Number of active neurons: 10
 >> iter 11000, loss: 7.575180
 >> iter 12000, loss: 7.563839
 >> iter 13000, loss: 7.569195
 >> iter 14000, loss: 7.560374
 >> iter 15000, loss: 7.561291
 >> iter 16000, loss: 7.551133
 >> iter 17000, loss: 7.562324
 >> iter 18000, loss: 7.550927
 >> iter 19000, loss: 7.556375
 >> iter 20000, loss: 7.592836
   Number of active neurons: 10
 >> iter 21000, loss: 7.577396
 >> iter 22000, loss: 7.542461
 >> iter 23000, loss: 7.532186
 >> iter 24000, loss: 7.526479
 >> iter 25000, loss: 7.292426
 >> iter 26000, loss: 7.140358
 >> iter 27000, loss: 6.957064
 >> iter 28000, loss: 6.806372
 >> iter 29000, loss: 6.742096
 >> iter 30000, loss: 6.703036
   Number of active neurons: 10
 >> iter 31000, loss: 6.662222
 >> iter 32000, loss: 6.651586
 >> iter 33000, loss: 6.647952
 >> iter 34000, loss: 6.633683
 >> iter 35000, loss: 6.632141
 >> iter 36000, loss: 6.610499
 >> iter 37000, loss: 6.624466
 >> iter 38000, loss: 6.607680
 >> iter 39000, loss: 6.624899
 >> iter 40000, loss: 6.618542
   Number of active neurons: 10
 >> iter 41000, loss: 6.657128
 >> iter 42000, loss: 6.613081
 >> iter 43000, loss: 6.591141
 >> iter 44000, loss: 6.560757
 >> iter 45000, loss: 6.524773
 >> iter 46000, loss: 6.373164
 >> iter 47000, loss: 6.391734
 >> iter 48000, loss: 6.280808
 >> iter 49000, loss: 6.247397
 >> iter 50000, loss: 6.085315
   Number of active neurons: 10
 >> iter 51000, loss: 6.045387
 >> iter 52000, loss: 6.050222
 >> iter 53000, loss: 6.007073
 >> iter 54000, loss: 5.993073
 >> iter 55000, loss: 5.835172
 >> iter 56000, loss: 5.612407
 >> iter 57000, loss: 5.453486
 >> iter 58000, loss: 4.725049
 >> iter 59000, loss: 4.028790
 >> iter 60000, loss: 3.143713
   Number of active neurons: 10
 >> iter 61000, loss: 2.549502
 >> iter 62000, loss: 2.041609
 >> iter 63000, loss: 1.799381
 >> iter 64000, loss: 1.569408
 >> iter 65000, loss: 1.518492
 >> iter 66000, loss: 1.387599
 >> iter 67000, loss: 1.106245
 >> iter 68000, loss: 0.872876
 >> iter 69000, loss: 0.879761
 >> iter 70000, loss: 0.747452
   Number of active neurons: 10
 >> iter 71000, loss: 0.908413
 >> iter 72000, loss: 0.954127
 >> iter 73000, loss: 0.989289
 >> iter 74000, loss: 0.882596
 >> iter 75000, loss: 0.680733
 >> iter 76000, loss: 0.658447
 >> iter 77000, loss: 0.595469
 >> iter 78000, loss: 0.545917
 >> iter 79000, loss: 0.628176
 >> iter 80000, loss: 0.651924
   Number of active neurons: 10
 >> iter 81000, loss: 0.658093
 >> iter 82000, loss: 0.526665
 >> iter 83000, loss: 0.338778
 >> iter 84000, loss: 0.315544
 >> iter 85000, loss: 0.349246
 >> iter 86000, loss: 0.348819
 >> iter 87000, loss: 0.366063
 >> iter 88000, loss: 0.392086
 >> iter 89000, loss: 0.301607
 >> iter 90000, loss: 0.167747
   Number of active neurons: 10
 >> iter 91000, loss: 0.183808
 >> iter 92000, loss: 0.207247
 >> iter 93000, loss: 0.280812
 >> iter 94000, loss: 0.232037
 >> iter 95000, loss: 0.177561
 >> iter 96000, loss: 0.195101
 >> iter 97000, loss: 0.226590
 >> iter 98000, loss: 0.252344
 >> iter 99000, loss: 0.210619
 >> iter 100000, loss: 0.185021
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.219680
 >> iter 2000, loss: 10.934693
 >> iter 3000, loss: 8.840722
 >> iter 4000, loss: 8.046890
 >> iter 5000, loss: 7.755739
 >> iter 6000, loss: 7.631711
 >> iter 7000, loss: 7.599265
 >> iter 8000, loss: 7.570927
 >> iter 9000, loss: 7.570889
 >> iter 10000, loss: 7.558864
   Number of active neurons: 9
 >> iter 11000, loss: 7.604990
 >> iter 12000, loss: 7.568534
 >> iter 13000, loss: 7.562798
 >> iter 14000, loss: 7.556085
 >> iter 15000, loss: 7.608580
   Number of active neurons: 8
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 7.480797
 >> iter 17000, loss: 7.430137
 >> iter 18000, loss: 7.170231
 >> iter 19000, loss: 7.029522
 >> iter 20000, loss: 6.776307
   Number of active neurons: 10
 >> iter 21000, loss: 6.453842
 >> iter 22000, loss: 5.828930
 >> iter 23000, loss: 2.918350
 >> iter 24000, loss: 1.475209
 >> iter 25000, loss: 1.076052
 >> iter 26000, loss: 0.594917
 >> iter 27000, loss: 0.314869
 >> iter 28000, loss: 0.259256
 >> iter 29000, loss: 0.161749
 >> iter 30000, loss: 0.120863
   Number of active neurons: 10
 >> iter 31000, loss: 0.161708
 >> iter 32000, loss: 0.080262
 >> iter 33000, loss: 0.040332
 >> iter 34000, loss: 0.051342
 >> iter 35000, loss: 0.056156
 >> iter 36000, loss: 0.029350
 >> iter 37000, loss: 0.042025
 >> iter 38000, loss: 0.069791
 >> iter 39000, loss: 0.060296
 >> iter 40000, loss: 0.053632
   Number of active neurons: 10
 >> iter 41000, loss: 0.027011
 >> iter 42000, loss: 0.053783
 >> iter 43000, loss: 0.038025
 >> iter 44000, loss: 0.100314
 >> iter 45000, loss: 0.070441
 >> iter 46000, loss: 0.031838
 >> iter 47000, loss: 0.016602
 >> iter 48000, loss: 0.010411
 >> iter 49000, loss: 0.007490
 >> iter 50000, loss: 0.006522
   Number of active neurons: 10
 >> iter 51000, loss: 0.017337
 >> iter 52000, loss: 0.010538
 >> iter 53000, loss: 0.007012
 >> iter 54000, loss: 0.005786
 >> iter 55000, loss: 0.005061
 >> iter 56000, loss: 0.006709
 >> iter 57000, loss: 0.063321
 >> iter 58000, loss: 0.035318
 >> iter 59000, loss: 0.026409
 >> iter 60000, loss: 0.014637
   Number of active neurons: 10
 >> iter 61000, loss: 0.019924
 >> iter 62000, loss: 0.042088
 >> iter 63000, loss: 0.017773
 >> iter 64000, loss: 0.009801
 >> iter 65000, loss: 0.005728
 >> iter 66000, loss: 0.012003
 >> iter 67000, loss: 0.028719
 >> iter 68000, loss: 0.014012
 >> iter 69000, loss: 0.011578
 >> iter 70000, loss: 0.006290
   Number of active neurons: 10
 >> iter 71000, loss: 0.004154
 >> iter 72000, loss: 0.016470
 >> iter 73000, loss: 0.007742
 >> iter 74000, loss: 0.004895
 >> iter 75000, loss: 0.003426
 >> iter 76000, loss: 0.003203
 >> iter 77000, loss: 0.002790
 >> iter 78000, loss: 0.004031
 >> iter 79000, loss: 0.012882
 >> iter 80000, loss: 0.006244
   Number of active neurons: 10
 >> iter 81000, loss: 0.022427
 >> iter 82000, loss: 0.009714
 >> iter 83000, loss: 0.031271
 >> iter 84000, loss: 0.013439
 >> iter 85000, loss: 0.006317
 >> iter 86000, loss: 0.005396
 >> iter 87000, loss: 0.003638
 >> iter 88000, loss: 0.003279
 >> iter 89000, loss: 0.002722
 >> iter 90000, loss: 0.002396
   Number of active neurons: 10
 >> iter 91000, loss: 0.002139
 >> iter 92000, loss: 0.002075
 >> iter 93000, loss: 0.001894
 >> iter 94000, loss: 0.001838
 >> iter 95000, loss: 0.020254
 >> iter 96000, loss: 0.055118
 >> iter 97000, loss: 0.021549
 >> iter 98000, loss: 0.043044
 >> iter 99000, loss: 0.020359
 >> iter 100000, loss: 0.008731
   Number of active neurons: 10
 >> iter 101000, loss: 0.004732
 >> iter 102000, loss: 0.002878
 >> iter 103000, loss: 0.002525
 >> iter 104000, loss: 0.002488
 >> iter 105000, loss: 0.002000
 >> iter 106000, loss: 0.001717
 >> iter 107000, loss: 0.002038
 >> iter 108000, loss: 0.001683
 >> iter 109000, loss: 0.001554
 >> iter 110000, loss: 0.001492
   Number of active neurons: 10
 >> iter 111000, loss: 0.001432
 >> iter 112000, loss: 0.001809
 >> iter 113000, loss: 0.001520
 >> iter 114000, loss: 0.001438
 >> iter 115000, loss: 0.002063
 >> iter 116000, loss: 0.001597
 >> iter 117000, loss: 0.015237
 >> iter 118000, loss: 0.006888
 >> iter 119000, loss: 0.004091
 >> iter 120000, loss: 0.009478
   Number of active neurons: 10
 >> iter 121000, loss: 0.004560
 >> iter 122000, loss: 0.002519
 >> iter 123000, loss: 0.002235
 >> iter 124000, loss: 0.001597
 >> iter 125000, loss: 0.002177
 >> iter 126000, loss: 0.005269
 >> iter 127000, loss: 0.003078
 >> iter 128000, loss: 0.001985
 >> iter 129000, loss: 0.001591
 >> iter 130000, loss: 0.001312
   Number of active neurons: 10
 >> iter 131000, loss: 0.027169
 >> iter 132000, loss: 0.010886
 >> iter 133000, loss: 0.004734
 >> iter 134000, loss: 0.002460
 >> iter 135000, loss: 0.006795
 >> iter 136000, loss: 0.003300
 >> iter 137000, loss: 0.015886
 >> iter 138000, loss: 0.008686
 >> iter 139000, loss: 0.003941
 >> iter 140000, loss: 0.009369
   Number of active neurons: 10
 >> iter 141000, loss: 0.014107
 >> iter 142000, loss: 0.005851
 >> iter 143000, loss: 0.002823
 >> iter 144000, loss: 0.001675
 >> iter 145000, loss: 0.001305
 >> iter 146000, loss: 0.001104
 >> iter 147000, loss: 0.001018
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.166639
 >> iter 2000, loss: 10.856351
 >> iter 3000, loss: 8.829354
 >> iter 4000, loss: 8.099818
 >> iter 5000, loss: 7.794992
 >> iter 6000, loss: 7.661379
 >> iter 7000, loss: 7.624029
 >> iter 8000, loss: 7.659598
 >> iter 9000, loss: 7.613665
 >> iter 10000, loss: 7.583733
   Number of active neurons: 10
 >> iter 11000, loss: 7.706301
 >> iter 12000, loss: 7.616790
 >> iter 13000, loss: 7.593796
 >> iter 14000, loss: 7.585114
 >> iter 15000, loss: 7.575948
 >> iter 16000, loss: 7.571178
 >> iter 17000, loss: 7.580728
 >> iter 18000, loss: 7.565104
 >> iter 19000, loss: 7.625474
 >> iter 20000, loss: 7.580641
   Number of active neurons: 10
 >> iter 21000, loss: 7.572420
 >> iter 22000, loss: 7.560622
 >> iter 23000, loss: 7.564704
 >> iter 24000, loss: 7.558017
 >> iter 25000, loss: 7.566892
 >> iter 26000, loss: 7.581079
 >> iter 27000, loss: 7.574252
 >> iter 28000, loss: 7.563220
 >> iter 29000, loss: 7.565404
 >> iter 30000, loss: 7.558221
   Number of active neurons: 10
 >> iter 31000, loss: 7.597468
 >> iter 32000, loss: 7.571895
 >> iter 33000, loss: 7.546907
 >> iter 34000, loss: 7.410306
 >> iter 35000, loss: 7.144134
 >> iter 36000, loss: 6.961984
 >> iter 37000, loss: 6.840715
 >> iter 38000, loss: 6.725057
 >> iter 39000, loss: 6.684037
 >> iter 40000, loss: 6.662293
   Number of active neurons: 10
 >> iter 41000, loss: 6.625369
 >> iter 42000, loss: 6.418461
 >> iter 43000, loss: 6.235214
 >> iter 44000, loss: 5.970534
 >> iter 45000, loss: 5.771538
 >> iter 46000, loss: 5.644113
 >> iter 47000, loss: 5.533246
 >> iter 48000, loss: 5.468606
 >> iter 49000, loss: 5.440092
 >> iter 50000, loss: 5.429932
   Number of active neurons: 10
 >> iter 51000, loss: 5.420369
 >> iter 52000, loss: 5.383793
 >> iter 53000, loss: 5.332947
 >> iter 54000, loss: 5.067854
 >> iter 55000, loss: 5.002397
 >> iter 56000, loss: 4.874739
 >> iter 57000, loss: 4.878755
 >> iter 58000, loss: 4.478591
 >> iter 59000, loss: 4.551998
 >> iter 60000, loss: 4.431026
   Number of active neurons: 10
 >> iter 61000, loss: 4.330384
 >> iter 62000, loss: 4.193019
 >> iter 63000, loss: 4.122754
 >> iter 64000, loss: 3.891663
 >> iter 65000, loss: 3.846430
 >> iter 66000, loss: 3.815201
 >> iter 67000, loss: 3.946425
 >> iter 68000, loss: 3.933543
 >> iter 69000, loss: 3.938892
 >> iter 70000, loss: 3.807730
   Number of active neurons: 10
 >> iter 71000, loss: 3.878156
 >> iter 72000, loss: 3.691677
 >> iter 73000, loss: 3.681702
 >> iter 74000, loss: 3.722771
 >> iter 75000, loss: 3.537893
 >> iter 76000, loss: 3.535105
 >> iter 77000, loss: 3.793664
 >> iter 78000, loss: 3.643075
 >> iter 79000, loss: 4.175946
 >> iter 80000, loss: 4.019229
   Number of active neurons: 10
 >> iter 81000, loss: 3.083533
 >> iter 82000, loss: 2.148647
 >> iter 83000, loss: 1.530837
 >> iter 84000, loss: 1.159876
 >> iter 85000, loss: 1.001955
 >> iter 86000, loss: 1.019494
 >> iter 87000, loss: 0.862973
 >> iter 88000, loss: 0.723769
 >> iter 89000, loss: 0.626844
 >> iter 90000, loss: 0.431891
   Number of active neurons: 10
 >> iter 91000, loss: 0.497818
 >> iter 92000, loss: 0.489252
 >> iter 93000, loss: 0.363063
 >> iter 94000, loss: 0.278508
 >> iter 95000, loss: 0.184945
 >> iter 96000, loss: 0.262018
 >> iter 97000, loss: 0.145846
 >> iter 98000, loss: 0.269970
 >> iter 99000, loss: 0.206945
 >> iter 100000, loss: 0.199221
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

