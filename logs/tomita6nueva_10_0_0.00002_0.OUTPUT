 > Problema: tomita6nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 2e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.653894
 >> iter 2000, loss: 15.120886
 >> iter 3000, loss: 13.783285
 >> iter 4000, loss: 13.285433
 >> iter 5000, loss: 13.086692
 >> iter 6000, loss: 13.013938
 >> iter 7000, loss: 12.975830
 >> iter 8000, loss: 12.967058
 >> iter 9000, loss: 12.953077
 >> iter 10000, loss: 12.957761
   Number of active neurons: 5
 >> iter 11000, loss: 12.946392
 >> iter 12000, loss: 12.952028
 >> iter 13000, loss: 12.941731
 >> iter 14000, loss: 12.949600
 >> iter 15000, loss: 12.942050
 >> iter 16000, loss: 12.947238
 >> iter 17000, loss: 12.938210
 >> iter 18000, loss: 12.725799
 >> iter 19000, loss: 10.175824
 >> iter 20000, loss: 3.862932
   Number of active neurons: 7
 >> iter 21000, loss: 1.464716
 >> iter 22000, loss: 0.567834
 >> iter 23000, loss: 0.231277
 >> iter 24000, loss: 0.103887
 >> iter 25000, loss: 0.054565
 >> iter 26000, loss: 0.034877
 >> iter 27000, loss: 0.026370
 >> iter 28000, loss: 0.022433
 >> iter 29000, loss: 0.020216
 >> iter 30000, loss: 0.018921
   Number of active neurons: 7
 >> iter 31000, loss: 0.017940
 >> iter 32000, loss: 0.017280
 >> iter 33000, loss: 0.016696
 >> iter 34000, loss: 0.016287
 >> iter 35000, loss: 0.015879
 >> iter 36000, loss: 0.015606
 >> iter 37000, loss: 0.015303
 >> iter 38000, loss: 0.015118
 >> iter 39000, loss: 0.014884
 >> iter 40000, loss: 0.014754
   Number of active neurons: 7
 >> iter 41000, loss: 0.014566
 >> iter 42000, loss: 0.014469
 >> iter 43000, loss: 0.014321
 >> iter 44000, loss: 0.014245
 >> iter 45000, loss: 0.014124
 >> iter 46000, loss: 0.014056
 >> iter 47000, loss: 0.013953
 >> iter 48000, loss: 0.013893
 >> iter 49000, loss: 0.013813
 >> iter 50000, loss: 0.013761
   Number of active neurons: 7
 >> iter 51000, loss: 0.013694
 >> iter 52000, loss: 0.013640
 >> iter 53000, loss: 0.013582
 >> iter 54000, loss: 0.013529
 >> iter 55000, loss: 0.013475
 >> iter 56000, loss: 0.013417
 >> iter 57000, loss: 0.013372
 >> iter 58000, loss: 0.013294
 >> iter 59000, loss: 0.013242
 >> iter 60000, loss: 0.013155
   Number of active neurons: 7
 >> iter 61000, loss: 0.013102
 >> iter 62000, loss: 0.013013
 >> iter 63000, loss: 0.012956
 >> iter 64000, loss: 0.012876
 >> iter 65000, loss: 0.012816
 >> iter 66000, loss: 0.012734
 >> iter 67000, loss: 0.012675
 >> iter 68000, loss: 0.012595
 >> iter 69000, loss: 0.012544
 >> iter 70000, loss: 0.012476
   Number of active neurons: 7
 >> iter 71000, loss: 0.012443
 >> iter 72000, loss: 0.012382
 >> iter 73000, loss: 0.012360
 >> iter 74000, loss: 0.012312
 >> iter 75000, loss: 0.012299
 >> iter 76000, loss: 0.012251
 >> iter 77000, loss: 0.012241
 >> iter 78000, loss: 0.012194
 >> iter 79000, loss: 0.012184
 >> iter 80000, loss: 0.012138
   Number of active neurons: 7
 >> iter 81000, loss: 0.012131
 >> iter 82000, loss: 0.012089
 >> iter 83000, loss: 0.012079
 >> iter 84000, loss: 0.012038
 >> iter 85000, loss: 0.012024
 >> iter 86000, loss: 0.011983
 >> iter 87000, loss: 0.011968
 >> iter 88000, loss: 0.011934
 >> iter 89000, loss: 0.011921
 >> iter 90000, loss: 0.011887
   Number of active neurons: 7
 >> iter 91000, loss: 0.011871
 >> iter 92000, loss: 0.011832
 >> iter 93000, loss: 0.011813
 >> iter 94000, loss: 0.011778
 >> iter 95000, loss: 0.011758
 >> iter 96000, loss: 0.011726
 >> iter 97000, loss: 0.011712
 >> iter 98000, loss: 0.011686
 >> iter 99000, loss: 0.011669
 >> iter 100000, loss: 0.011640
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.613533
 >> iter 2000, loss: 15.079466
 >> iter 3000, loss: 13.745499
 >> iter 4000, loss: 13.252664
 >> iter 5000, loss: 13.057011
 >> iter 6000, loss: 12.988514
 >> iter 7000, loss: 12.952680
 >> iter 8000, loss: 12.947034
 >> iter 9000, loss: 12.934396
 >> iter 10000, loss: 12.940913
   Number of active neurons: 4
 >> iter 11000, loss: 12.929888
 >> iter 12000, loss: 12.936564
 >> iter 13000, loss: 12.925961
 >> iter 14000, loss: 12.934600
 >> iter 15000, loss: 12.926500
 >> iter 16000, loss: 12.929317
 >> iter 17000, loss: 12.795653
 >> iter 18000, loss: 11.411369
 >> iter 19000, loss: 10.499879
 >> iter 20000, loss: 10.155545
   Number of active neurons: 5
 >> iter 21000, loss: 9.986398
 >> iter 22000, loss: 9.944651
 >> iter 23000, loss: 9.803560
 >> iter 24000, loss: 5.040701
 >> iter 25000, loss: 1.891782
 >> iter 26000, loss: 0.721187
 >> iter 27000, loss: 0.285319
 >> iter 28000, loss: 0.121989
 >> iter 29000, loss: 0.059743
 >> iter 30000, loss: 0.035647
   Number of active neurons: 6
 >> iter 31000, loss: 0.025437
 >> iter 32000, loss: 0.020882
 >> iter 33000, loss: 0.018526
 >> iter 34000, loss: 0.017139
 >> iter 35000, loss: 0.016176
 >> iter 36000, loss: 0.015456
 >> iter 37000, loss: 0.014870
 >> iter 38000, loss: 0.014384
 >> iter 39000, loss: 0.013968
 >> iter 40000, loss: 0.013613
   Number of active neurons: 6
 >> iter 41000, loss: 0.013298
 >> iter 42000, loss: 0.013028
 >> iter 43000, loss: 0.012786
 >> iter 44000, loss: 0.012576
 >> iter 45000, loss: 0.012389
 >> iter 46000, loss: 0.012224
 >> iter 47000, loss: 0.012075
 >> iter 48000, loss: 0.011939
 >> iter 49000, loss: 0.011813
 >> iter 50000, loss: 0.011702
   Number of active neurons: 6
 >> iter 51000, loss: 0.011594
 >> iter 52000, loss: 0.011492
 >> iter 53000, loss: 0.011388
 >> iter 54000, loss: 0.011295
 >> iter 55000, loss: 0.011203
 >> iter 56000, loss: 0.011127
 >> iter 57000, loss: 0.011054
 >> iter 58000, loss: 0.010989
 >> iter 59000, loss: 0.010930
 >> iter 60000, loss: 0.010868
   Number of active neurons: 6
 >> iter 61000, loss: 0.010817
 >> iter 62000, loss: 0.010763
 >> iter 63000, loss: 0.010718
 >> iter 64000, loss: 0.010668
 >> iter 65000, loss: 0.010636
 >> iter 66000, loss: 0.010585
 >> iter 67000, loss: 0.010560
 >> iter 68000, loss: 0.010511
 >> iter 69000, loss: 0.010490
 >> iter 70000, loss: 0.010440
   Number of active neurons: 6
 >> iter 71000, loss: 0.010425
 >> iter 72000, loss: 0.010374
 >> iter 73000, loss: 0.010360
 >> iter 74000, loss: 0.010312
 >> iter 75000, loss: 0.010298
 >> iter 76000, loss: 0.010248
 >> iter 77000, loss: 0.010238
 >> iter 78000, loss: 0.010186
 >> iter 79000, loss: 0.010176
 >> iter 80000, loss: 0.010121
   Number of active neurons: 6
 >> iter 81000, loss: 0.010112
 >> iter 82000, loss: 0.010056
 >> iter 83000, loss: 0.010048
 >> iter 84000, loss: 0.009991
 >> iter 85000, loss: 0.009984
 >> iter 86000, loss: 0.009925
 >> iter 87000, loss: 0.009917
 >> iter 88000, loss: 0.009860
 >> iter 89000, loss: 0.009852
 >> iter 90000, loss: 0.009787
   Number of active neurons: 6
 >> iter 91000, loss: 0.009768
 >> iter 92000, loss: 0.009700
 >> iter 93000, loss: 0.009683
 >> iter 94000, loss: 0.009619
 >> iter 95000, loss: 0.009606
 >> iter 96000, loss: 0.009548
 >> iter 97000, loss: 0.009537
 >> iter 98000, loss: 0.009486
 >> iter 99000, loss: 0.009475
 >> iter 100000, loss: 0.009433
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.617310
 >> iter 2000, loss: 15.074704
 >> iter 3000, loss: 13.738579
 >> iter 4000, loss: 13.246632
 >> iter 5000, loss: 13.049138
 >> iter 6000, loss: 12.982664
 >> iter 7000, loss: 12.946229
 >> iter 8000, loss: 12.942579
 >> iter 9000, loss: 12.929424
 >> iter 10000, loss: 12.937149
   Number of active neurons: 3
 >> iter 11000, loss: 12.925707
 >> iter 12000, loss: 12.932770
 >> iter 13000, loss: 12.921896
 >> iter 14000, loss: 12.920724
 >> iter 15000, loss: 12.541080
 >> iter 16000, loss: 11.979882
 >> iter 17000, loss: 10.569689
 >> iter 18000, loss: 9.077900
 >> iter 19000, loss: 4.728605
 >> iter 20000, loss: 1.843375
   Number of active neurons: 9
 >> iter 21000, loss: 0.704988
 >> iter 22000, loss: 0.278826
 >> iter 23000, loss: 0.118634
 >> iter 24000, loss: 0.057452
 >> iter 25000, loss: 0.033476
 >> iter 26000, loss: 0.023783
 >> iter 27000, loss: 0.019506
 >> iter 28000, loss: 0.017469
 >> iter 29000, loss: 0.016298
 >> iter 30000, loss: 0.015593
   Number of active neurons: 9
 >> iter 31000, loss: 0.015065
 >> iter 32000, loss: 0.014699
 >> iter 33000, loss: 0.014373
 >> iter 34000, loss: 0.014140
 >> iter 35000, loss: 0.013904
 >> iter 36000, loss: 0.013741
 >> iter 37000, loss: 0.013562
 >> iter 38000, loss: 0.013444
 >> iter 39000, loss: 0.013304
 >> iter 40000, loss: 0.013210
   Number of active neurons: 9
 >> iter 41000, loss: 0.013085
 >> iter 42000, loss: 0.013001
 >> iter 43000, loss: 0.012866
 >> iter 44000, loss: 0.012799
 >> iter 45000, loss: 0.012692
 >> iter 46000, loss: 0.012653
 >> iter 47000, loss: 0.012577
 >> iter 48000, loss: 0.012551
 >> iter 49000, loss: 0.012493
 >> iter 50000, loss: 0.012478
   Number of active neurons: 8
 >> iter 51000, loss: 0.012424
 >> iter 52000, loss: 0.012406
 >> iter 53000, loss: 0.012346
 >> iter 54000, loss: 0.012319
 >> iter 55000, loss: 0.012258
 >> iter 56000, loss: 0.012246
 >> iter 57000, loss: 0.012192
 >> iter 58000, loss: 0.012188
 >> iter 59000, loss: 0.012145
 >> iter 60000, loss: 0.012151
   Number of active neurons: 8
 >> iter 61000, loss: 0.012104
 >> iter 62000, loss: 0.012112
 >> iter 63000, loss: 0.012065
 >> iter 64000, loss: 0.012072
 >> iter 65000, loss: 0.011994
 >> iter 66000, loss: 0.012010
 >> iter 67000, loss: 0.011968
 >> iter 68000, loss: 0.011960
 >> iter 69000, loss: 0.011864
 >> iter 70000, loss: 0.011880
   Number of active neurons: 8
 >> iter 71000, loss: 0.011838
 >> iter 72000, loss: 0.011838
 >> iter 73000, loss: 0.011748
 >> iter 74000, loss: 0.011767
 >> iter 75000, loss: 0.011708
 >> iter 76000, loss: 0.011714
 >> iter 77000, loss: 0.011619
 >> iter 78000, loss: 0.011630
 >> iter 79000, loss: 0.011576
 >> iter 80000, loss: 0.011574
   Number of active neurons: 8
 >> iter 81000, loss: 0.011500
 >> iter 82000, loss: 0.011506
 >> iter 83000, loss: 0.011455
 >> iter 84000, loss: 0.011451
 >> iter 85000, loss: 0.011390
 >> iter 86000, loss: 0.011377
 >> iter 87000, loss: 0.011346
 >> iter 88000, loss: 0.011314
 >> iter 89000, loss: 0.011233
 >> iter 90000, loss: 0.011221
   Number of active neurons: 8
 >> iter 91000, loss: 0.011165
 >> iter 92000, loss: 0.011148
 >> iter 93000, loss: 0.011083
 >> iter 94000, loss: 0.011088
 >> iter 95000, loss: 0.011029
 >> iter 96000, loss: 0.011052
 >> iter 97000, loss: 0.010993
 >> iter 98000, loss: 0.011029
 >> iter 99000, loss: 0.010972
 >> iter 100000, loss: 0.011021
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0019999600008
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.631850
 >> iter 2000, loss: 15.118109
 >> iter 3000, loss: 13.787055
 >> iter 4000, loss: 13.291270
 >> iter 5000, loss: 13.085562
 >> iter 6000, loss: 13.010098
 >> iter 7000, loss: 12.966868
 >> iter 8000, loss: 12.957896
 >> iter 9000, loss: 12.941164
 >> iter 10000, loss: 12.946427
   Number of active neurons: 3
 >> iter 11000, loss: 12.933133
 >> iter 12000, loss: 12.939528
 >> iter 13000, loss: 12.927606
 >> iter 14000, loss: 12.936474
 >> iter 15000, loss: 12.927623
 >> iter 16000, loss: 12.934313
 >> iter 17000, loss: 12.925445
 >> iter 18000, loss: 12.641799
 >> iter 19000, loss: 11.762674
 >> iter 20000, loss: 10.727226
   Number of active neurons: 7
 >> iter 21000, loss: 9.236531
 >> iter 22000, loss: 3.673355
 >> iter 23000, loss: 1.512166
 >> iter 24000, loss: 0.606666
 >> iter 25000, loss: 0.289045
 >> iter 26000, loss: 0.139284
 >> iter 27000, loss: 0.074823
 >> iter 28000, loss: 0.043423
 >> iter 29000, loss: 0.030601
 >> iter 30000, loss: 0.024560
   Number of active neurons: 8
 >> iter 31000, loss: 0.021828
 >> iter 32000, loss: 0.019946
 >> iter 33000, loss: 0.018995
 >> iter 34000, loss: 0.017972
 >> iter 35000, loss: 0.017530
 >> iter 36000, loss: 0.016694
 >> iter 37000, loss: 0.016505
 >> iter 38000, loss: 0.015730
 >> iter 39000, loss: 0.015650
 >> iter 40000, loss: 0.014894
   Number of active neurons: 8
 >> iter 41000, loss: 0.014865
 >> iter 42000, loss: 0.014054
 >> iter 43000, loss: 0.014046
 >> iter 44000, loss: 0.013274
 >> iter 45000, loss: 0.013188
 >> iter 46000, loss: 0.012523
 >> iter 47000, loss: 0.012940
 >> iter 48000, loss: 0.012096
 >> iter 49000, loss: 0.011488
 >> iter 50000, loss: 0.314937
   Number of active neurons: 8
 >> iter 51000, loss: 0.693025
 >> iter 52000, loss: 0.268573
 >> iter 53000, loss: 0.109667
 >> iter 54000, loss: 0.049103
 >> iter 55000, loss: 0.025497
 >> iter 56000, loss: 0.015943
 >> iter 57000, loss: 0.012042
 >> iter 58000, loss: 0.010425
 >> iter 59000, loss: 0.709192
 >> iter 60000, loss: 0.272752
   Number of active neurons: 10
 >> iter 61000, loss: 0.109769
 >> iter 62000, loss: 0.048698
 >> iter 63000, loss: 0.025798
 >> iter 64000, loss: 0.016955
 >> iter 65000, loss: 0.108650
 >> iter 66000, loss: 0.047944
 >> iter 67000, loss: 0.173841
 >> iter 68000, loss: 0.104000
 >> iter 69000, loss: 0.045942
 >> iter 70000, loss: 0.024068
   Number of active neurons: 8
 >> iter 71000, loss: 0.100598
 >> iter 72000, loss: 0.045120
 >> iter 73000, loss: 0.024341
 >> iter 74000, loss: 0.015935
 >> iter 75000, loss: 0.137551
 >> iter 76000, loss: 0.059622
 >> iter 77000, loss: 0.328097
 >> iter 78000, loss: 0.132428
 >> iter 79000, loss: 0.057175
 >> iter 80000, loss: 0.028502
   Number of active neurons: 8
 >> iter 81000, loss: 0.076004
 >> iter 82000, loss: 0.035890
 >> iter 83000, loss: 0.106176
 >> iter 84000, loss: 0.047266
 >> iter 85000, loss: 0.025762
 >> iter 86000, loss: 0.016604
 >> iter 87000, loss: 0.013233
 >> iter 88000, loss: 0.011556
 >> iter 89000, loss: 0.089084
 >> iter 90000, loss: 0.041646
   Number of active neurons: 8
 >> iter 91000, loss: 0.080191
 >> iter 92000, loss: 0.036867
 >> iter 93000, loss: 0.050345
 >> iter 94000, loss: 0.310244
 >> iter 95000, loss: 0.127449
 >> iter 96000, loss: 0.058009
 >> iter 97000, loss: 0.038280
 >> iter 98000, loss: 0.021455
 >> iter 99000, loss: 0.190077
 >> iter 100000, loss: 0.092826
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.621247
 >> iter 2000, loss: 15.095906
 >> iter 3000, loss: 13.761172
 >> iter 4000, loss: 13.266254
 >> iter 5000, loss: 13.064676
 >> iter 6000, loss: 12.993205
 >> iter 7000, loss: 12.952301
 >> iter 8000, loss: 12.944960
 >> iter 9000, loss: 12.928936
 >> iter 10000, loss: 12.934044
   Number of active neurons: 3
 >> iter 11000, loss: 12.921037
 >> iter 12000, loss: 12.925039
 >> iter 13000, loss: 12.881779
 >> iter 14000, loss: 11.127503
 >> iter 15000, loss: 4.383785
 >> iter 16000, loss: 1.670730
 >> iter 17000, loss: 0.648811
 >> iter 18000, loss: 0.266642
 >> iter 19000, loss: 0.119562
 >> iter 20000, loss: 0.062716
   Number of active neurons: 7
 >> iter 21000, loss: 0.039893
 >> iter 22000, loss: 0.029810
 >> iter 23000, loss: 0.025132
 >> iter 24000, loss: 0.022484
 >> iter 25000, loss: 0.020608
 >> iter 26000, loss: 0.019414
 >> iter 27000, loss: 0.023270
 >> iter 28000, loss: 0.020148
 >> iter 29000, loss: 0.018211
 >> iter 30000, loss: 0.017205
   Number of active neurons: 7
 >> iter 31000, loss: 0.016461
 >> iter 32000, loss: 0.016034
 >> iter 33000, loss: 0.015622
 >> iter 34000, loss: 0.015364
 >> iter 35000, loss: 0.017138
 >> iter 36000, loss: 0.016215
 >> iter 37000, loss: 0.015404
 >> iter 38000, loss: 0.014961
 >> iter 39000, loss: 0.014599
 >> iter 40000, loss: 0.014401
   Number of active neurons: 6
 >> iter 41000, loss: 0.014188
 >> iter 42000, loss: 0.014061
 >> iter 43000, loss: 0.013907
 >> iter 44000, loss: 0.013813
 >> iter 45000, loss: 0.014181
 >> iter 46000, loss: 0.013847
 >> iter 47000, loss: 0.013579
 >> iter 48000, loss: 0.013427
 >> iter 49000, loss: 0.013291
 >> iter 50000, loss: 0.013204
   Number of active neurons: 6
 >> iter 51000, loss: 0.017181
 >> iter 52000, loss: 0.014701
 >> iter 53000, loss: 0.013596
 >> iter 54000, loss: 0.013102
 >> iter 55000, loss: 0.012864
 >> iter 56000, loss: 0.012728
 >> iter 57000, loss: 0.019102
 >> iter 58000, loss: 0.015044
 >> iter 59000, loss: 0.013408
 >> iter 60000, loss: 0.012740
   Number of active neurons: 6
 >> iter 61000, loss: 0.015241
 >> iter 62000, loss: 0.013367
 >> iter 63000, loss: 0.024903
 >> iter 64000, loss: 0.016918
 >> iter 65000, loss: 0.013795
 >> iter 66000, loss: 0.012576
 >> iter 67000, loss: 0.019489
 >> iter 68000, loss: 0.014672
 >> iter 69000, loss: 0.015054
 >> iter 70000, loss: 0.013008
   Number of active neurons: 5
 >> iter 71000, loss: 0.012042
 >> iter 72000, loss: 0.011651
 >> iter 73000, loss: 0.019112
 >> iter 74000, loss: 0.014300
 >> iter 75000, loss: 0.012321
 >> iter 76000, loss: 0.011625
 >> iter 77000, loss: 0.012754
 >> iter 78000, loss: 0.011719
 >> iter 79000, loss: 0.011140
 >> iter 80000, loss: 0.010961
   Number of active neurons: 5
 >> iter 81000, loss: 0.011321
 >> iter 82000, loss: 0.010784
 >> iter 83000, loss: 0.010414
 >> iter 84000, loss: 0.010326
 >> iter 85000, loss: 0.010602
 >> iter 86000, loss: 0.010280
 >> iter 87000, loss: 0.011385
 >> iter 88000, loss: 0.009985
 >> iter 89000, loss: 0.009204
 >> iter 90000, loss: 0.009150
   Number of active neurons: 5
 >> iter 91000, loss: 0.008890
 >> iter 92000, loss: 0.008759
 >> iter 93000, loss: 0.008534
 >> iter 94000, loss: 0.008840
 >> iter 95000, loss: 0.008627
 >> iter 96000, loss: 0.008526
 >> iter 97000, loss: 0.008327
 >> iter 98000, loss: 0.008697
 >> iter 99000, loss: 0.008470
 >> iter 100000, loss: 0.008541
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.615758
 >> iter 2000, loss: 15.094273
 >> iter 3000, loss: 13.762486
 >> iter 4000, loss: 13.267261
 >> iter 5000, loss: 13.065119
 >> iter 6000, loss: 12.992790
 >> iter 7000, loss: 12.952128
 >> iter 8000, loss: 12.944482
 >> iter 9000, loss: 12.928748
 >> iter 10000, loss: 12.934009
   Number of active neurons: 3
 >> iter 11000, loss: 12.921110
 >> iter 12000, loss: 12.926686
 >> iter 13000, loss: 12.915023
 >> iter 14000, loss: 12.918697
 >> iter 15000, loss: 12.647492
 >> iter 16000, loss: 11.644664
 >> iter 17000, loss: 7.089316
 >> iter 18000, loss: 2.657803
 >> iter 19000, loss: 1.003666
 >> iter 20000, loss: 0.388591
   Number of active neurons: 8
 >> iter 21000, loss: 0.158757
 >> iter 22000, loss: 0.072202
 >> iter 23000, loss: 0.038928
 >> iter 24000, loss: 0.025803
 >> iter 25000, loss: 0.020187
 >> iter 26000, loss: 0.017636
 >> iter 27000, loss: 0.016184
 >> iter 28000, loss: 0.015346
 >> iter 29000, loss: 0.014677
 >> iter 30000, loss: 0.014243
   Number of active neurons: 8
 >> iter 31000, loss: 0.013822
 >> iter 32000, loss: 0.013535
 >> iter 33000, loss: 0.013232
 >> iter 34000, loss: 0.013017
 >> iter 35000, loss: 0.012787
 >> iter 36000, loss: 0.012619
 >> iter 37000, loss: 0.012436
 >> iter 38000, loss: 0.012299
 >> iter 39000, loss: 0.012151
 >> iter 40000, loss: 0.012041
   Number of active neurons: 8
 >> iter 41000, loss: 0.011920
 >> iter 42000, loss: 0.011815
 >> iter 43000, loss: 0.011704
 >> iter 44000, loss: 0.011602
 >> iter 45000, loss: 0.011507
 >> iter 46000, loss: 0.011416
 >> iter 47000, loss: 0.011336
 >> iter 48000, loss: 0.011253
 >> iter 49000, loss: 0.011189
 >> iter 50000, loss: 0.011117
   Number of active neurons: 8
 >> iter 51000, loss: 0.011058
 >> iter 52000, loss: 0.010994
 >> iter 53000, loss: 0.010941
 >> iter 54000, loss: 0.010887
 >> iter 55000, loss: 0.010842
 >> iter 56000, loss: 0.010791
 >> iter 57000, loss: 0.010755
 >> iter 58000, loss: 0.010704
 >> iter 59000, loss: 0.010674
 >> iter 60000, loss: 0.010627
   Number of active neurons: 8
 >> iter 61000, loss: 0.010607
 >> iter 62000, loss: 0.010560
 >> iter 63000, loss: 0.010539
 >> iter 64000, loss: 0.010505
 >> iter 65000, loss: 0.010483
 >> iter 66000, loss: 0.010453
 >> iter 67000, loss: 0.010436
 >> iter 68000, loss: 0.010409
 >> iter 69000, loss: 0.010394
 >> iter 70000, loss: 0.010370
   Number of active neurons: 8
 >> iter 71000, loss: 0.010356
 >> iter 72000, loss: 0.010337
 >> iter 73000, loss: 0.010318
 >> iter 74000, loss: 0.010299
 >> iter 75000, loss: 0.010276
 >> iter 76000, loss: 0.010247
 >> iter 77000, loss: 0.010230
 >> iter 78000, loss: 0.010202
 >> iter 79000, loss: 0.010195
 >> iter 80000, loss: 0.010164
   Number of active neurons: 8
 >> iter 81000, loss: 0.010162
 >> iter 82000, loss: 0.010130
 >> iter 83000, loss: 0.010124
 >> iter 84000, loss: 0.010090
 >> iter 85000, loss: 0.010086
 >> iter 86000, loss: 0.010053
 >> iter 87000, loss: 0.010055
 >> iter 88000, loss: 0.010024
 >> iter 89000, loss: 0.010026
 >> iter 90000, loss: 0.009992
   Number of active neurons: 8
 >> iter 91000, loss: 0.009995
 >> iter 92000, loss: 0.009962
 >> iter 93000, loss: 0.009970
 >> iter 94000, loss: 0.009938
 >> iter 95000, loss: 0.009949
 >> iter 96000, loss: 0.009916
 >> iter 97000, loss: 0.009932
 >> iter 98000, loss: 0.009897
 >> iter 99000, loss: 0.009910
 >> iter 100000, loss: 0.009870
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.610082
 >> iter 2000, loss: 15.092566
 >> iter 3000, loss: 13.765559
 >> iter 4000, loss: 13.274067
 >> iter 5000, loss: 13.073676
 >> iter 6000, loss: 13.001647
 >> iter 7000, loss: 12.961252
 >> iter 8000, loss: 12.953591
 >> iter 9000, loss: 12.937229
 >> iter 10000, loss: 12.941859
   Number of active neurons: 5
 >> iter 11000, loss: 12.927564
 >> iter 12000, loss: 12.932560
 >> iter 13000, loss: 12.919560
 >> iter 14000, loss: 12.927439
 >> iter 15000, loss: 12.917819
 >> iter 16000, loss: 12.923817
 >> iter 17000, loss: 12.913240
 >> iter 18000, loss: 12.611789
 >> iter 19000, loss: 11.767236
 >> iter 20000, loss: 6.068281
   Number of active neurons: 7
 >> iter 21000, loss: 2.296675
 >> iter 22000, loss: 0.880799
 >> iter 23000, loss: 0.349796
 >> iter 24000, loss: 0.149267
 >> iter 25000, loss: 0.072283
 >> iter 26000, loss: 0.041836
 >> iter 27000, loss: 0.029118
 >> iter 28000, loss: 0.023321
 >> iter 29000, loss: 0.020342
 >> iter 30000, loss: 0.018559
   Number of active neurons: 7
 >> iter 31000, loss: 0.017384
 >> iter 32000, loss: 0.016492
 >> iter 33000, loss: 0.015809
 >> iter 34000, loss: 0.015216
 >> iter 35000, loss: 0.014752
 >> iter 36000, loss: 0.014332
 >> iter 37000, loss: 0.013994
 >> iter 38000, loss: 0.013677
 >> iter 39000, loss: 0.013420
 >> iter 40000, loss: 0.013180
   Number of active neurons: 7
 >> iter 41000, loss: 0.012979
 >> iter 42000, loss: 0.012789
 >> iter 43000, loss: 0.012622
 >> iter 44000, loss: 0.012466
 >> iter 45000, loss: 0.012322
 >> iter 46000, loss: 0.012191
 >> iter 47000, loss: 0.012062
 >> iter 48000, loss: 0.011945
 >> iter 49000, loss: 0.011831
 >> iter 50000, loss: 0.011727
   Number of active neurons: 7
 >> iter 51000, loss: 0.011626
 >> iter 52000, loss: 0.011538
 >> iter 53000, loss: 0.011449
 >> iter 54000, loss: 0.011376
 >> iter 55000, loss: 0.011296
 >> iter 56000, loss: 0.011235
 >> iter 57000, loss: 0.011164
 >> iter 58000, loss: 0.011109
 >> iter 59000, loss: 0.011047
 >> iter 60000, loss: 0.011001
   Number of active neurons: 7
 >> iter 61000, loss: 0.010942
 >> iter 62000, loss: 0.010898
 >> iter 63000, loss: 0.010835
 >> iter 64000, loss: 0.010795
 >> iter 65000, loss: 0.010739
 >> iter 66000, loss: 0.010702
 >> iter 67000, loss: 0.010650
 >> iter 68000, loss: 0.010616
 >> iter 69000, loss: 0.010562
 >> iter 70000, loss: 0.010527
   Number of active neurons: 7
 >> iter 71000, loss: 0.010473
 >> iter 72000, loss: 0.010439
 >> iter 73000, loss: 0.010386
 >> iter 74000, loss: 0.010358
 >> iter 75000, loss: 0.010310
 >> iter 76000, loss: 0.010285
 >> iter 77000, loss: 0.010241
 >> iter 78000, loss: 0.010217
 >> iter 79000, loss: 0.010180
 >> iter 80000, loss: 0.010155
   Number of active neurons: 7
 >> iter 81000, loss: 0.010121
 >> iter 82000, loss: 0.010100
 >> iter 83000, loss: 0.010062
 >> iter 84000, loss: 0.010038
 >> iter 85000, loss: 0.009999
 >> iter 86000, loss: 0.009968
 >> iter 87000, loss: 0.009928
 >> iter 88000, loss: 0.009889
 >> iter 89000, loss: 0.009846
 >> iter 90000, loss: 0.009808
   Number of active neurons: 7
 >> iter 91000, loss: 0.009774
 >> iter 92000, loss: 0.009738
 >> iter 93000, loss: 0.009709
 >> iter 94000, loss: 0.009676
 >> iter 95000, loss: 0.009651
 >> iter 96000, loss: 0.009619
 >> iter 97000, loss: 0.009599
 >> iter 98000, loss: 0.009573
 >> iter 99000, loss: 0.009552
 >> iter 100000, loss: 0.009525
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.643371
 >> iter 2000, loss: 15.110954
 >> iter 3000, loss: 13.774550
 >> iter 4000, loss: 13.277474
 >> iter 5000, loss: 13.077714
 >> iter 6000, loss: 13.006071
 >> iter 7000, loss: 12.968529
 >> iter 8000, loss: 12.961903
 >> iter 9000, loss: 12.948696
 >> iter 10000, loss: 12.954795
   Number of active neurons: 4
 >> iter 11000, loss: 12.943554
 >> iter 12000, loss: 12.949586
 >> iter 13000, loss: 12.939082
 >> iter 14000, loss: 12.945894
 >> iter 15000, loss: 12.934908
 >> iter 16000, loss: 12.691676
 >> iter 17000, loss: 10.080072
 >> iter 18000, loss: 3.758352
 >> iter 19000, loss: 1.401709
 >> iter 20000, loss: 0.529420
   Number of active neurons: 7
 >> iter 21000, loss: 0.206023
 >> iter 22000, loss: 0.085765
 >> iter 23000, loss: 0.040621
 >> iter 24000, loss: 0.023474
 >> iter 25000, loss: 0.016716
 >> iter 26000, loss: 0.013960
 >> iter 27000, loss: 0.012695
 >> iter 28000, loss: 0.012082
 >> iter 29000, loss: 0.011700
 >> iter 30000, loss: 0.011463
   Number of active neurons: 7
 >> iter 31000, loss: 0.011274
 >> iter 32000, loss: 0.011148
 >> iter 33000, loss: 0.011029
 >> iter 34000, loss: 0.010941
 >> iter 35000, loss: 0.010853
 >> iter 36000, loss: 0.010783
 >> iter 37000, loss: 0.010719
 >> iter 38000, loss: 0.010666
 >> iter 39000, loss: 0.010616
 >> iter 40000, loss: 0.010572
   Number of active neurons: 7
 >> iter 41000, loss: 0.010531
 >> iter 42000, loss: 0.010492
 >> iter 43000, loss: 0.010453
 >> iter 44000, loss: 0.010416
 >> iter 45000, loss: 0.010381
 >> iter 46000, loss: 0.010348
 >> iter 47000, loss: 0.010316
 >> iter 48000, loss: 0.010286
 >> iter 49000, loss: 0.010257
 >> iter 50000, loss: 0.010230
   Number of active neurons: 7
 >> iter 51000, loss: 0.010201
 >> iter 52000, loss: 0.010177
 >> iter 53000, loss: 0.010153
 >> iter 54000, loss: 0.010126
 >> iter 55000, loss: 0.010100
 >> iter 56000, loss: 0.010076
 >> iter 57000, loss: 0.010057
 >> iter 58000, loss: 0.010032
 >> iter 59000, loss: 0.010014
 >> iter 60000, loss: 0.009995
   Number of active neurons: 7
 >> iter 61000, loss: 0.009974
 >> iter 62000, loss: 0.009957
 >> iter 63000, loss: 0.009939
 >> iter 64000, loss: 0.009928
 >> iter 65000, loss: 0.009912
 >> iter 66000, loss: 0.009902
 >> iter 67000, loss: 0.009885
 >> iter 68000, loss: 0.009876
 >> iter 69000, loss: 0.009861
 >> iter 70000, loss: 0.009853
   Number of active neurons: 7
 >> iter 71000, loss: 0.009839
 >> iter 72000, loss: 0.009831
 >> iter 73000, loss: 0.009816
 >> iter 74000, loss: 0.009810
 >> iter 75000, loss: 0.009794
 >> iter 76000, loss: 0.009790
 >> iter 77000, loss: 0.009775
 >> iter 78000, loss: 0.009768
 >> iter 79000, loss: 0.009759
 >> iter 80000, loss: 0.009744
   Number of active neurons: 7
 >> iter 81000, loss: 0.009736
 >> iter 82000, loss: 0.009723
 >> iter 83000, loss: 0.009715
 >> iter 84000, loss: 0.009703
 >> iter 85000, loss: 0.009696
 >> iter 86000, loss: 0.009685
 >> iter 87000, loss: 0.009683
 >> iter 88000, loss: 0.009666
 >> iter 89000, loss: 0.009661
 >> iter 90000, loss: 0.009637
   Number of active neurons: 7
 >> iter 91000, loss: 0.009632
 >> iter 92000, loss: 0.009610
 >> iter 93000, loss: 0.009609
 >> iter 94000, loss: 0.009586
 >> iter 95000, loss: 0.009589
 >> iter 96000, loss: 0.009565
 >> iter 97000, loss: 0.009571
 >> iter 98000, loss: 0.009547
 >> iter 99000, loss: 0.009554
 >> iter 100000, loss: 0.009528
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 18.596208
 >> iter 2000, loss: 15.084562
 >> iter 3000, loss: 13.757745
 >> iter 4000, loss: 13.265203
 >> iter 5000, loss: 13.067729
 >> iter 6000, loss: 12.997933
 >> iter 7000, loss: 12.961512
 >> iter 8000, loss: 12.955478
 >> iter 9000, loss: 12.942211
 >> iter 10000, loss: 12.946924
   Number of active neurons: 4
 >> iter 11000, loss: 12.934203
 >> iter 12000, loss: 12.935226
 >> iter 13000, loss: 12.912254
 >> iter 14000, loss: 12.786111
 >> iter 15000, loss: 10.435393
 >> iter 16000, loss: 4.110078
 >> iter 17000, loss: 1.554137
 >> iter 18000, loss: 0.596830
 >> iter 19000, loss: 0.238137
 >> iter 20000, loss: 0.102773
   Number of active neurons: 6
 >> iter 21000, loss: 0.050771
 >> iter 22000, loss: 0.030260
 >> iter 23000, loss: 0.021627
 >> iter 24000, loss: 0.017770
 >> iter 25000, loss: 0.015703
 >> iter 26000, loss: 0.014560
 >> iter 27000, loss: 0.013711
 >> iter 28000, loss: 0.013173
 >> iter 29000, loss: 0.012665
 >> iter 30000, loss: 0.012345
   Number of active neurons: 6
 >> iter 31000, loss: 0.011994
 >> iter 32000, loss: 0.011791
 >> iter 33000, loss: 0.011531
 >> iter 34000, loss: 0.011399
 >> iter 35000, loss: 0.011194
 >> iter 36000, loss: 0.011110
 >> iter 37000, loss: 0.010942
 >> iter 38000, loss: 0.010894
 >> iter 39000, loss: 0.010748
 >> iter 40000, loss: 0.010727
   Number of active neurons: 6
 >> iter 41000, loss: 0.010597
 >> iter 42000, loss: 0.010591
 >> iter 43000, loss: 0.010471
 >> iter 44000, loss: 0.010480
 >> iter 45000, loss: 0.010367
 >> iter 46000, loss: 0.010386
 >> iter 47000, loss: 0.010279
 >> iter 48000, loss: 0.010305
 >> iter 49000, loss: 0.010201
 >> iter 50000, loss: 0.010237
   Number of active neurons: 6
 >> iter 51000, loss: 0.010133
 >> iter 52000, loss: 0.010174
 >> iter 53000, loss: 0.010070
 >> iter 54000, loss: 0.010119
 >> iter 55000, loss: 0.010014
 >> iter 56000, loss: 0.010068
 >> iter 57000, loss: 0.009964
 >> iter 58000, loss: 0.010021
 >> iter 59000, loss: 0.009918
 >> iter 60000, loss: 0.009978
   Number of active neurons: 6
 >> iter 61000, loss: 0.009875
 >> iter 62000, loss: 0.009937
 >> iter 63000, loss: 0.009829
 >> iter 64000, loss: 0.009885
 >> iter 65000, loss: 0.009772
 >> iter 66000, loss: 0.009831
 >> iter 67000, loss: 0.009718
 >> iter 68000, loss: 0.009780
 >> iter 69000, loss: 0.009662
 >> iter 70000, loss: 0.009723
   Number of active neurons: 6
 >> iter 71000, loss: 0.009597
 >> iter 72000, loss: 0.009657
 >> iter 73000, loss: 0.009534
 >> iter 74000, loss: 0.009583
 >> iter 75000, loss: 0.009463
 >> iter 76000, loss: 0.009520
 >> iter 77000, loss: 0.009408
 >> iter 78000, loss: 0.009466
 >> iter 79000, loss: 0.009359
 >> iter 80000, loss: 0.009418
   Number of active neurons: 6
 >> iter 81000, loss: 0.009309
 >> iter 82000, loss: 0.009369
 >> iter 83000, loss: 0.009263
 >> iter 84000, loss: 0.009326
 >> iter 85000, loss: 0.009223
 >> iter 86000, loss: 0.009286
 >> iter 87000, loss: 0.009187
 >> iter 88000, loss: 0.009250
 >> iter 89000, loss: 0.009149
 >> iter 90000, loss: 0.009215
   Number of active neurons: 6
 >> iter 91000, loss: 0.009113
 >> iter 92000, loss: 0.009180
 >> iter 93000, loss: 0.009078
 >> iter 94000, loss: 0.009145
 >> iter 95000, loss: 0.009045
 >> iter 96000, loss: 0.009111
 >> iter 97000, loss: 0.009013
 >> iter 98000, loss: 0.009082
 >> iter 99000, loss: 0.008983
 >> iter 100000, loss: 0.009052
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0049997500125
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.599625
 >> iter 2000, loss: 15.074755
 >> iter 3000, loss: 13.743397
 >> iter 4000, loss: 13.250970
 >> iter 5000, loss: 13.052540
 >> iter 6000, loss: 12.984549
 >> iter 7000, loss: 12.947639
 >> iter 8000, loss: 12.943318
 >> iter 9000, loss: 12.930111
 >> iter 10000, loss: 12.937160
   Number of active neurons: 4
 >> iter 11000, loss: 12.925762
 >> iter 12000, loss: 12.927824
 >> iter 13000, loss: 12.634871
 >> iter 14000, loss: 11.911319
 >> iter 15000, loss: 5.122544
 >> iter 16000, loss: 1.935918
 >> iter 17000, loss: 0.740692
 >> iter 18000, loss: 0.293052
 >> iter 19000, loss: 0.124253
 >> iter 20000, loss: 0.059797
   Number of active neurons: 7
 >> iter 21000, loss: 0.034450
 >> iter 22000, loss: 0.024060
 >> iter 23000, loss: 0.019389
 >> iter 24000, loss: 0.017088
 >> iter 25000, loss: 0.015722
 >> iter 26000, loss: 0.014843
 >> iter 27000, loss: 0.014160
 >> iter 28000, loss: 0.013658
 >> iter 29000, loss: 0.013213
 >> iter 30000, loss: 0.012876
   Number of active neurons: 5
 >> iter 31000, loss: 0.012550
 >> iter 32000, loss: 0.012304
 >> iter 33000, loss: 0.012062
 >> iter 34000, loss: 0.011881
 >> iter 35000, loss: 0.011706
 >> iter 36000, loss: 0.011570
 >> iter 37000, loss: 0.011436
 >> iter 38000, loss: 0.011331
 >> iter 39000, loss: 0.011213
 >> iter 40000, loss: 0.011122
   Number of active neurons: 5
 >> iter 41000, loss: 0.011015
 >> iter 42000, loss: 0.010928
 >> iter 43000, loss: 0.010829
 >> iter 44000, loss: 0.010743
 >> iter 45000, loss: 0.010660
 >> iter 46000, loss: 0.010592
 >> iter 47000, loss: 0.010525
 >> iter 48000, loss: 0.010466
 >> iter 49000, loss: 0.010408
 >> iter 50000, loss: 0.010351
   Number of active neurons: 5
 >> iter 51000, loss: 0.010298
 >> iter 52000, loss: 0.010249
 >> iter 53000, loss: 0.010208
 >> iter 54000, loss: 0.010168
 >> iter 55000, loss: 0.010135
 >> iter 56000, loss: 0.010097
 >> iter 57000, loss: 0.010075
 >> iter 58000, loss: 0.010038
 >> iter 59000, loss: 0.010024
 >> iter 60000, loss: 0.009989
   Number of active neurons: 5
 >> iter 61000, loss: 0.009973
 >> iter 62000, loss: 0.009942
 >> iter 63000, loss: 0.009924
 >> iter 64000, loss: 0.009899
 >> iter 65000, loss: 0.009884
 >> iter 66000, loss: 0.009859
 >> iter 67000, loss: 0.009845
 >> iter 68000, loss: 0.009820
 >> iter 69000, loss: 0.009809
 >> iter 70000, loss: 0.009787
   Number of active neurons: 5
 >> iter 71000, loss: 0.009776
 >> iter 72000, loss: 0.009756
 >> iter 73000, loss: 0.009746
 >> iter 74000, loss: 0.009725
 >> iter 75000, loss: 0.009715
 >> iter 76000, loss: 0.009696
 >> iter 77000, loss: 0.009689
 >> iter 78000, loss: 0.009671
 >> iter 79000, loss: 0.009664
 >> iter 80000, loss: 0.009644
   Number of active neurons: 5
 >> iter 81000, loss: 0.009639
 >> iter 82000, loss: 0.009627
 >> iter 83000, loss: 0.009618
 >> iter 84000, loss: 0.009605
 >> iter 85000, loss: 0.009598
 >> iter 86000, loss: 0.009586
 >> iter 87000, loss: 0.009583
 >> iter 88000, loss: 0.009566
 >> iter 89000, loss: 0.009565
 >> iter 90000, loss: 0.009548
   Number of active neurons: 5
 >> iter 91000, loss: 0.009548
 >> iter 92000, loss: 0.009531
 >> iter 93000, loss: 0.009532
 >> iter 94000, loss: 0.009516
 >> iter 95000, loss: 0.009518
 >> iter 96000, loss: 0.009502
 >> iter 97000, loss: 0.009507
 >> iter 98000, loss: 0.009493
 >> iter 99000, loss: 0.009497
 >> iter 100000, loss: 0.009480
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 18.627015
 >> iter 2000, loss: 15.105474
 >> iter 3000, loss: 13.775902
 >> iter 4000, loss: 13.280458
 >> iter 5000, loss: 13.080213
 >> iter 6000, loss: 13.007773
 >> iter 7000, loss: 12.969670
 >> iter 8000, loss: 12.962493
 >> iter 9000, loss: 12.949108
 >> iter 10000, loss: 12.955119
   Number of active neurons: 5
 >> iter 11000, loss: 12.943919
 >> iter 12000, loss: 12.950361
 >> iter 13000, loss: 12.939924
 >> iter 14000, loss: 12.948525
 >> iter 15000, loss: 12.940691
 >> iter 16000, loss: 12.947306
 >> iter 17000, loss: 12.940778
 >> iter 18000, loss: 12.934291
 >> iter 19000, loss: 12.624286
 >> iter 20000, loss: 11.870895
   Number of active neurons: 6
 >> iter 21000, loss: 7.275382
 >> iter 22000, loss: 2.741641
 >> iter 23000, loss: 1.039711
 >> iter 24000, loss: 0.403481
 >> iter 25000, loss: 0.164983
 >> iter 26000, loss: 0.074478
 >> iter 27000, loss: 0.039518
 >> iter 28000, loss: 0.025462
 >> iter 29000, loss: 0.019473
 >> iter 30000, loss: 0.016687
   Number of active neurons: 8
 >> iter 31000, loss: 0.015202
 >> iter 32000, loss: 0.014331
 >> iter 33000, loss: 0.013687
 >> iter 34000, loss: 0.013245
 >> iter 35000, loss: 0.012817
 >> iter 36000, loss: 0.012506
 >> iter 37000, loss: 0.012149
 >> iter 38000, loss: 0.011878
 >> iter 39000, loss: 0.011551
 >> iter 40000, loss: 0.011310
   Number of active neurons: 8
 >> iter 41000, loss: 0.010994
 >> iter 42000, loss: 0.010771
 >> iter 43000, loss: 0.010470
 >> iter 44000, loss: 0.010292
 >> iter 45000, loss: 0.010025
 >> iter 46000, loss: 0.009893
 >> iter 47000, loss: 0.009677
 >> iter 48000, loss: 0.009612
 >> iter 49000, loss: 0.009459
 >> iter 50000, loss: 0.009445
   Number of active neurons: 8
 >> iter 51000, loss: 0.009334
 >> iter 52000, loss: 0.009340
 >> iter 53000, loss: 0.009254
 >> iter 54000, loss: 0.009267
 >> iter 55000, loss: 0.009189
 >> iter 56000, loss: 0.009219
 >> iter 57000, loss: 0.009157
 >> iter 58000, loss: 0.009198
 >> iter 59000, loss: 0.009143
 >> iter 60000, loss: 0.009191
   Number of active neurons: 8
 >> iter 61000, loss: 0.009143
 >> iter 62000, loss: 0.009192
 >> iter 63000, loss: 0.009143
 >> iter 64000, loss: 0.009187
 >> iter 65000, loss: 0.009136
 >> iter 66000, loss: 0.009166
 >> iter 67000, loss: 0.009120
 >> iter 68000, loss: 0.009148
 >> iter 69000, loss: 0.009104
 >> iter 70000, loss: 0.009138
   Number of active neurons: 8
 >> iter 71000, loss: 0.009091
 >> iter 72000, loss: 0.009131
 >> iter 73000, loss: 0.009084
 >> iter 74000, loss: 0.009128
 >> iter 75000, loss: 0.009075
 >> iter 76000, loss: 0.009117
 >> iter 77000, loss: 0.009063
 >> iter 78000, loss: 0.009102
 >> iter 79000, loss: 0.009047
 >> iter 80000, loss: 0.009087
   Number of active neurons: 8
 >> iter 81000, loss: 0.009034
 >> iter 82000, loss: 0.009074
 >> iter 83000, loss: 0.009022
 >> iter 84000, loss: 0.009058
 >> iter 85000, loss: 0.009007
 >> iter 86000, loss: 0.009039
 >> iter 87000, loss: 0.008986
 >> iter 88000, loss: 0.009017
 >> iter 89000, loss: 0.008964
 >> iter 90000, loss: 0.008995
   Number of active neurons: 8
 >> iter 91000, loss: 0.008940
 >> iter 92000, loss: 0.008970
 >> iter 93000, loss: 0.008912
 >> iter 94000, loss: 0.008941
 >> iter 95000, loss: 0.008883
 >> iter 96000, loss: 0.008911
 >> iter 97000, loss: 0.008854
 >> iter 98000, loss: 0.008885
 >> iter 99000, loss: 0.008828
 >> iter 100000, loss: 0.008861
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.669222
 >> iter 2000, loss: 15.105295
 >> iter 3000, loss: 13.750918
 >> iter 4000, loss: 13.248681
 >> iter 5000, loss: 13.045350
 >> iter 6000, loss: 12.975342
 >> iter 7000, loss: 12.937182
 >> iter 8000, loss: 12.932194
 >> iter 9000, loss: 12.918691
 >> iter 10000, loss: 12.925489
   Number of active neurons: 3
 >> iter 11000, loss: 12.914155
 >> iter 12000, loss: 12.916531
 >> iter 13000, loss: 12.683530
 >> iter 14000, loss: 9.473466
 >> iter 15000, loss: 3.584787
 >> iter 16000, loss: 1.356348
 >> iter 17000, loss: 0.528315
 >> iter 18000, loss: 0.214150
 >> iter 19000, loss: 0.195303
 >> iter 20000, loss: 0.089198
   Number of active neurons: 7
 >> iter 21000, loss: 0.047451
 >> iter 22000, loss: 0.030714
 >> iter 23000, loss: 0.023276
 >> iter 24000, loss: 0.019873
 >> iter 25000, loss: 0.017875
 >> iter 26000, loss: 0.016751
 >> iter 27000, loss: 0.015835
 >> iter 28000, loss: 0.015273
 >> iter 29000, loss: 0.014707
 >> iter 30000, loss: 0.014362
   Number of active neurons: 7
 >> iter 31000, loss: 0.013952
 >> iter 32000, loss: 0.013726
 >> iter 33000, loss: 0.013411
 >> iter 34000, loss: 0.013260
 >> iter 35000, loss: 0.013010
 >> iter 36000, loss: 0.012905
 >> iter 37000, loss: 0.012695
 >> iter 38000, loss: 0.012627
 >> iter 39000, loss: 0.012506
 >> iter 40000, loss: 0.012438
   Number of active neurons: 7
 >> iter 41000, loss: 0.299842
 >> iter 42000, loss: 0.122804
 >> iter 43000, loss: 0.056015
 >> iter 44000, loss: 0.030805
 >> iter 45000, loss: 0.020875
 >> iter 46000, loss: 0.016972
 >> iter 47000, loss: 0.015303
 >> iter 48000, loss: 0.014325
 >> iter 49000, loss: 0.013646
 >> iter 50000, loss: 0.013321
   Number of active neurons: 7
 >> iter 51000, loss: 0.012959
 >> iter 52000, loss: 0.012795
 >> iter 53000, loss: 0.312940
 >> iter 54000, loss: 0.127368
 >> iter 55000, loss: 0.211483
 >> iter 56000, loss: 0.090292
 >> iter 57000, loss: 0.044189
 >> iter 58000, loss: 0.026581
 >> iter 59000, loss: 0.019460
 >> iter 60000, loss: 0.016580
   Number of active neurons: 7
 >> iter 61000, loss: 0.015091
 >> iter 62000, loss: 0.014402
 >> iter 63000, loss: 0.014569
 >> iter 64000, loss: 0.013951
 >> iter 65000, loss: 0.013370
 >> iter 66000, loss: 0.013065
 >> iter 67000, loss: 0.012746
 >> iter 68000, loss: 0.012555
 >> iter 69000, loss: 0.012317
 >> iter 70000, loss: 0.012223
   Number of active neurons: 7
 >> iter 71000, loss: 0.129724
 >> iter 72000, loss: 0.056817
 >> iter 73000, loss: 0.029397
 >> iter 74000, loss: 0.019157
 >> iter 75000, loss: 0.015137
 >> iter 76000, loss: 0.013614
 >> iter 77000, loss: 0.358817
 >> iter 78000, loss: 0.145649
 >> iter 79000, loss: 0.064824
 >> iter 80000, loss: 0.034117
   Number of active neurons: 7
 >> iter 81000, loss: 0.022011
 >> iter 82000, loss: 0.017192
 >> iter 83000, loss: 0.014995
 >> iter 84000, loss: 0.014024
 >> iter 85000, loss: 0.013380
 >> iter 86000, loss: 0.013069
 >> iter 87000, loss: 0.012729
 >> iter 88000, loss: 0.012576
 >> iter 89000, loss: 0.012349
 >> iter 90000, loss: 0.012243
   Number of active neurons: 7
 >> iter 91000, loss: 0.012169
 >> iter 92000, loss: 0.012027
 >> iter 93000, loss: 0.011934
 >> iter 94000, loss: 0.011776
 >> iter 95000, loss: 0.011689
 >> iter 96000, loss: 0.011580
 >> iter 97000, loss: 0.011478
 >> iter 98000, loss: 0.011410
 >> iter 99000, loss: 0.011332
 >> iter 100000, loss: 0.011276
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0119998800012
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.621066
 >> iter 2000, loss: 15.099921
 >> iter 3000, loss: 13.767940
 >> iter 4000, loss: 13.274629
 >> iter 5000, loss: 13.077521
 >> iter 6000, loss: 13.008940
 >> iter 7000, loss: 12.972890
 >> iter 8000, loss: 12.967716
 >> iter 9000, loss: 12.954178
 >> iter 10000, loss: 12.959813
   Number of active neurons: 5
 >> iter 11000, loss: 12.946390
 >> iter 12000, loss: 12.950528
 >> iter 13000, loss: 12.936603
 >> iter 14000, loss: 12.942512
 >> iter 15000, loss: 12.930709
 >> iter 16000, loss: 12.935260
 >> iter 17000, loss: 12.921726
 >> iter 18000, loss: 12.900740
 >> iter 19000, loss: 12.769581
 >> iter 20000, loss: 11.980907
   Number of active neurons: 6
 >> iter 21000, loss: 5.740521
 >> iter 22000, loss: 2.164413
 >> iter 23000, loss: 0.821822
 >> iter 24000, loss: 0.319936
 >> iter 25000, loss: 0.131181
 >> iter 26000, loss: 0.059555
 >> iter 27000, loss: 0.031757
 >> iter 28000, loss: 0.020667
 >> iter 29000, loss: 0.015909
 >> iter 30000, loss: 0.013716
   Number of active neurons: 6
 >> iter 31000, loss: 0.012541
 >> iter 32000, loss: 0.011854
 >> iter 33000, loss: 0.011374
 >> iter 34000, loss: 0.011021
 >> iter 35000, loss: 0.010742
 >> iter 36000, loss: 0.010524
 >> iter 37000, loss: 0.010342
 >> iter 38000, loss: 0.010196
 >> iter 39000, loss: 0.010070
 >> iter 40000, loss: 0.009964
   Number of active neurons: 6
 >> iter 41000, loss: 0.009874
 >> iter 42000, loss: 0.009795
 >> iter 43000, loss: 0.009731
 >> iter 44000, loss: 0.009672
 >> iter 45000, loss: 0.009622
 >> iter 46000, loss: 0.009568
 >> iter 47000, loss: 0.009523
 >> iter 48000, loss: 0.009477
 >> iter 49000, loss: 0.009442
 >> iter 50000, loss: 0.009411
   Number of active neurons: 6
 >> iter 51000, loss: 0.009389
 >> iter 52000, loss: 0.009363
 >> iter 53000, loss: 0.009354
 >> iter 54000, loss: 0.009345
 >> iter 55000, loss: 0.009349
 >> iter 56000, loss: 0.009349
 >> iter 57000, loss: 0.009360
 >> iter 58000, loss: 0.009357
 >> iter 59000, loss: 0.009371
 >> iter 60000, loss: 0.009368
   Number of active neurons: 6
 >> iter 61000, loss: 0.009370
 >> iter 62000, loss: 0.009362
 >> iter 63000, loss: 0.009359
 >> iter 64000, loss: 0.009355
 >> iter 65000, loss: 0.009345
 >> iter 66000, loss: 0.009342
 >> iter 67000, loss: 0.009327
 >> iter 68000, loss: 0.009320
 >> iter 69000, loss: 0.009303
 >> iter 70000, loss: 0.009298
   Number of active neurons: 6
 >> iter 71000, loss: 0.009277
 >> iter 72000, loss: 0.009272
 >> iter 73000, loss: 0.009252
 >> iter 74000, loss: 0.009246
 >> iter 75000, loss: 0.009226
 >> iter 76000, loss: 0.009219
 >> iter 77000, loss: 0.009202
 >> iter 78000, loss: 0.009196
 >> iter 79000, loss: 0.009181
 >> iter 80000, loss: 0.009170
   Number of active neurons: 6
 >> iter 81000, loss: 0.009157
 >> iter 82000, loss: 0.009152
 >> iter 83000, loss: 0.009129
 >> iter 84000, loss: 0.009117
 >> iter 85000, loss: 0.009096
 >> iter 86000, loss: 0.009084
 >> iter 87000, loss: 0.009075
 >> iter 88000, loss: 0.009058
 >> iter 89000, loss: 0.009051
 >> iter 90000, loss: 0.009036
   Number of active neurons: 6
 >> iter 91000, loss: 0.009029
 >> iter 92000, loss: 0.009016
 >> iter 93000, loss: 0.009010
 >> iter 94000, loss: 0.008998
 >> iter 95000, loss: 0.008992
 >> iter 96000, loss: 0.008979
 >> iter 97000, loss: 0.008975
 >> iter 98000, loss: 0.008968
 >> iter 99000, loss: 0.008958
 >> iter 100000, loss: 0.008949
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.604582
 >> iter 2000, loss: 15.080054
 >> iter 3000, loss: 13.751137
 >> iter 4000, loss: 13.259313
 >> iter 5000, loss: 13.060382
 >> iter 6000, loss: 12.990842
 >> iter 7000, loss: 12.952932
 >> iter 8000, loss: 12.947254
 >> iter 9000, loss: 12.933482
 >> iter 10000, loss: 12.940079
   Number of active neurons: 4
 >> iter 11000, loss: 12.928461
 >> iter 12000, loss: 12.934884
 >> iter 13000, loss: 12.924066
 >> iter 14000, loss: 12.929947
 >> iter 15000, loss: 12.731149
 >> iter 16000, loss: 11.927757
 >> iter 17000, loss: 10.120689
 >> iter 18000, loss: 8.977601
 >> iter 19000, loss: 8.578295
 >> iter 20000, loss: 8.270839
   Number of active neurons: 7
 >> iter 21000, loss: 7.340175
 >> iter 22000, loss: 6.075567
 >> iter 23000, loss: 2.724966
 >> iter 24000, loss: 1.087408
 >> iter 25000, loss: 0.515538
 >> iter 26000, loss: 0.227257
 >> iter 27000, loss: 0.113110
 >> iter 28000, loss: 0.068199
 >> iter 29000, loss: 0.047986
 >> iter 30000, loss: 0.039274
   Number of active neurons: 10
 >> iter 31000, loss: 0.034064
 >> iter 32000, loss: 0.031687
 >> iter 33000, loss: 0.029323
 >> iter 34000, loss: 0.028268
 >> iter 35000, loss: 0.026737
 >> iter 36000, loss: 0.026124
 >> iter 37000, loss: 0.025083
 >> iter 38000, loss: 0.024845
 >> iter 39000, loss: 0.023879
 >> iter 40000, loss: 0.023471
   Number of active neurons: 10
 >> iter 41000, loss: 0.022779
 >> iter 42000, loss: 0.022637
 >> iter 43000, loss: 0.021732
 >> iter 44000, loss: 0.021494
 >> iter 45000, loss: 0.021277
 >> iter 46000, loss: 0.021711
 >> iter 47000, loss: 0.020922
 >> iter 48000, loss: 0.020736
 >> iter 49000, loss: 0.020360
 >> iter 50000, loss: 0.020415
   Number of active neurons: 10
 >> iter 51000, loss: 0.020136
 >> iter 52000, loss: 0.020466
 >> iter 53000, loss: 0.019990
 >> iter 54000, loss: 0.020143
 >> iter 55000, loss: 0.019738
 >> iter 56000, loss: 0.019890
 >> iter 57000, loss: 0.019623
 >> iter 58000, loss: 0.019975
 >> iter 59000, loss: 0.019520
 >> iter 60000, loss: 0.019755
   Number of active neurons: 10
 >> iter 61000, loss: 0.019420
 >> iter 62000, loss: 0.019642
 >> iter 63000, loss: 0.019380
 >> iter 64000, loss: 0.020122
 >> iter 65000, loss: 0.019409
 >> iter 66000, loss: 0.603868
 >> iter 67000, loss: 1.946790
 >> iter 68000, loss: 0.755484
 >> iter 69000, loss: 0.305372
 >> iter 70000, loss: 0.135604
   Number of active neurons: 10
 >> iter 71000, loss: 0.070379
 >> iter 72000, loss: 0.045008
 >> iter 73000, loss: 0.034108
 >> iter 74000, loss: 0.029616
 >> iter 75000, loss: 0.026870
 >> iter 76000, loss: 0.025661
 >> iter 77000, loss: 0.024860
 >> iter 78000, loss: 0.024121
 >> iter 79000, loss: 0.023205
 >> iter 80000, loss: 0.023034
   Number of active neurons: 10
 >> iter 81000, loss: 0.022366
 >> iter 82000, loss: 0.022748
 >> iter 83000, loss: 0.021940
 >> iter 84000, loss: 0.021802
 >> iter 85000, loss: 0.021200
 >> iter 86000, loss: 0.021317
 >> iter 87000, loss: 0.020761
 >> iter 88000, loss: 0.020930
 >> iter 89000, loss: 0.020412
 >> iter 90000, loss: 0.020608
   Number of active neurons: 9
 >> iter 91000, loss: 0.020111
 >> iter 92000, loss: 0.020258
 >> iter 93000, loss: 0.019807
 >> iter 94000, loss: 0.019949
 >> iter 95000, loss: 0.019549
 >> iter 96000, loss: 0.019672
 >> iter 97000, loss: 0.019315
 >> iter 98000, loss: 0.019430
 >> iter 99000, loss: 0.019094
 >> iter 100000, loss: 0.019199
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.625458
 >> iter 2000, loss: 15.112562
 >> iter 3000, loss: 13.778814
 >> iter 4000, loss: 13.281161
 >> iter 5000, loss: 13.075851
 >> iter 6000, loss: 13.003053
 >> iter 7000, loss: 12.961484
 >> iter 8000, loss: 12.954243
 >> iter 9000, loss: 12.938000
 >> iter 10000, loss: 12.943335
   Number of active neurons: 4
 >> iter 11000, loss: 12.930110
 >> iter 12000, loss: 12.936070
 >> iter 13000, loss: 12.924185
 >> iter 14000, loss: 12.931968
 >> iter 15000, loss: 12.922474
 >> iter 16000, loss: 12.868929
 >> iter 17000, loss: 12.253658
 >> iter 18000, loss: 10.932392
 >> iter 19000, loss: 9.843700
 >> iter 20000, loss: 9.186113
   Number of active neurons: 7
 >> iter 21000, loss: 4.445431
 >> iter 22000, loss: 1.985674
 >> iter 23000, loss: 0.834345
 >> iter 24000, loss: 0.833554
 >> iter 25000, loss: 0.534375
 >> iter 26000, loss: 0.228780
 >> iter 27000, loss: 0.540960
 >> iter 28000, loss: 0.355934
 >> iter 29000, loss: 0.156546
 >> iter 30000, loss: 0.078545
   Number of active neurons: 8
 >> iter 31000, loss: 0.371819
 >> iter 32000, loss: 0.608466
 >> iter 33000, loss: 0.256420
 >> iter 34000, loss: 0.125237
 >> iter 35000, loss: 0.064077
 >> iter 36000, loss: 0.039007
 >> iter 37000, loss: 0.381577
 >> iter 38000, loss: 0.408361
 >> iter 39000, loss: 0.171805
 >> iter 40000, loss: 0.080077
   Number of active neurons: 8
 >> iter 41000, loss: 0.045003
 >> iter 42000, loss: 0.030037
 >> iter 43000, loss: 0.034292
 >> iter 44000, loss: 0.032357
 >> iter 45000, loss: 0.222619
 >> iter 46000, loss: 0.107489
 >> iter 47000, loss: 0.058851
 >> iter 48000, loss: 0.034899
 >> iter 49000, loss: 0.025483
 >> iter 50000, loss: 0.020916
   Number of active neurons: 7
 >> iter 51000, loss: 0.023166
 >> iter 52000, loss: 0.019393
 >> iter 53000, loss: 0.071151
 >> iter 54000, loss: 0.037453
 >> iter 55000, loss: 0.088591
 >> iter 56000, loss: 0.047253
 >> iter 57000, loss: 0.181626
 >> iter 58000, loss: 0.260059
 >> iter 59000, loss: 0.109041
 >> iter 60000, loss: 0.050977
   Number of active neurons: 8
 >> iter 61000, loss: 0.028955
 >> iter 62000, loss: 0.026111
 >> iter 63000, loss: 0.086439
 >> iter 64000, loss: 0.042065
 >> iter 65000, loss: 0.025787
 >> iter 66000, loss: 0.030781
 >> iter 67000, loss: 0.030238
 >> iter 68000, loss: 0.020308
 >> iter 69000, loss: 0.016409
 >> iter 70000, loss: 0.014742
   Number of active neurons: 8
 >> iter 71000, loss: 0.183140
 >> iter 72000, loss: 0.939709
 >> iter 73000, loss: 0.364690
 >> iter 74000, loss: 0.150447
 >> iter 75000, loss: 0.067534
 >> iter 76000, loss: 0.035638
 >> iter 77000, loss: 0.412872
 >> iter 78000, loss: 0.616519
 >> iter 79000, loss: 0.294872
 >> iter 80000, loss: 0.279931
   Number of active neurons: 8
 >> iter 81000, loss: 0.288163
 >> iter 82000, loss: 0.155285
 >> iter 83000, loss: 0.070406
 >> iter 84000, loss: 0.036843
 >> iter 85000, loss: 0.023855
 >> iter 86000, loss: 0.022553
 >> iter 87000, loss: 0.017763
 >> iter 88000, loss: 0.039427
 >> iter 89000, loss: 0.426639
 >> iter 90000, loss: 0.304301
   Number of active neurons: 8
 >> iter 91000, loss: 0.161356
 >> iter 92000, loss: 0.080822
 >> iter 93000, loss: 0.041399
 >> iter 94000, loss: 0.212777
 >> iter 95000, loss: 0.183112
 >> iter 96000, loss: 0.091607
 >> iter 97000, loss: 0.557787
 >> iter 98000, loss: 0.244517
 >> iter 99000, loss: 0.257328
 >> iter 100000, loss: 0.110481
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0039999200016
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.608871
 >> iter 2000, loss: 15.090024
 >> iter 3000, loss: 13.762752
 >> iter 4000, loss: 13.270715
 >> iter 5000, loss: 13.068120
 >> iter 6000, loss: 12.995380
 >> iter 7000, loss: 12.954752
 >> iter 8000, loss: 12.948511
 >> iter 9000, loss: 12.933674
 >> iter 10000, loss: 12.940628
   Number of active neurons: 3
 >> iter 11000, loss: 12.928397
 >> iter 12000, loss: 12.935380
 >> iter 13000, loss: 12.924001
 >> iter 14000, loss: 12.931188
 >> iter 15000, loss: 12.848565
 >> iter 16000, loss: 12.165004
 >> iter 17000, loss: 6.055228
 >> iter 18000, loss: 2.376304
 >> iter 19000, loss: 0.914543
 >> iter 20000, loss: 0.385103
   Number of active neurons: 9
 >> iter 21000, loss: 0.164899
 >> iter 22000, loss: 0.079533
 >> iter 23000, loss: 0.045588
 >> iter 24000, loss: 0.031663
 >> iter 25000, loss: 0.025207
 >> iter 26000, loss: 0.022090
 >> iter 27000, loss: 0.020134
 >> iter 28000, loss: 0.019004
 >> iter 29000, loss: 0.018037
 >> iter 30000, loss: 0.017429
   Number of active neurons: 7
 >> iter 31000, loss: 0.016801
 >> iter 32000, loss: 0.016391
 >> iter 33000, loss: 0.015928
 >> iter 34000, loss: 0.015622
 >> iter 35000, loss: 0.015266
 >> iter 36000, loss: 0.015028
 >> iter 37000, loss: 0.014733
 >> iter 38000, loss: 0.014538
 >> iter 39000, loss: 0.014287
 >> iter 40000, loss: 0.014148
   Number of active neurons: 7
 >> iter 41000, loss: 0.013950
 >> iter 42000, loss: 0.013836
 >> iter 43000, loss: 0.013672
 >> iter 44000, loss: 0.013572
 >> iter 45000, loss: 0.013431
 >> iter 46000, loss: 0.013350
 >> iter 47000, loss: 0.013225
 >> iter 48000, loss: 0.013158
 >> iter 49000, loss: 0.013056
 >> iter 50000, loss: 0.013005
   Number of active neurons: 6
 >> iter 51000, loss: 0.012910
 >> iter 52000, loss: 0.012870
 >> iter 53000, loss: 0.012773
 >> iter 54000, loss: 0.012734
 >> iter 55000, loss: 0.012638
 >> iter 56000, loss: 0.012608
 >> iter 57000, loss: 0.012522
 >> iter 58000, loss: 0.012499
 >> iter 59000, loss: 0.012425
 >> iter 60000, loss: 0.012413
   Number of active neurons: 6
 >> iter 61000, loss: 0.012337
 >> iter 62000, loss: 0.012326
 >> iter 63000, loss: 0.012249
 >> iter 64000, loss: 0.012247
 >> iter 65000, loss: 0.012172
 >> iter 66000, loss: 0.012166
 >> iter 67000, loss: 0.012092
 >> iter 68000, loss: 0.012082
 >> iter 69000, loss: 0.012017
 >> iter 70000, loss: 0.012006
   Number of active neurons: 7
 >> iter 71000, loss: 0.011951
 >> iter 72000, loss: 0.011939
 >> iter 73000, loss: 0.011883
 >> iter 74000, loss: 0.011878
 >> iter 75000, loss: 0.011820
 >> iter 76000, loss: 0.011806
 >> iter 77000, loss: 0.011742
 >> iter 78000, loss: 0.011720
 >> iter 79000, loss: 0.011655
 >> iter 80000, loss: 0.011631
   Number of active neurons: 6
 >> iter 81000, loss: 0.011571
 >> iter 82000, loss: 0.011551
 >> iter 83000, loss: 0.011490
 >> iter 84000, loss: 0.011471
 >> iter 85000, loss: 0.011406
 >> iter 86000, loss: 0.011388
 >> iter 87000, loss: 0.011314
 >> iter 88000, loss: 0.011297
 >> iter 89000, loss: 0.011225
 >> iter 90000, loss: 0.011209
   Number of active neurons: 6
 >> iter 91000, loss: 0.011139
 >> iter 92000, loss: 0.011119
 >> iter 93000, loss: 0.011052
 >> iter 94000, loss: 0.011025
 >> iter 95000, loss: 0.010951
 >> iter 96000, loss: 0.010907
 >> iter 97000, loss: 0.010823
 >> iter 98000, loss: 0.010778
 >> iter 99000, loss: 0.010693
 >> iter 100000, loss: 0.010652
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0049999500005
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.634251
 >> iter 2000, loss: 15.090576
 >> iter 3000, loss: 13.753634
 >> iter 4000, loss: 13.257759
 >> iter 5000, loss: 13.056404
 >> iter 6000, loss: 12.987162
 >> iter 7000, loss: 12.949332
 >> iter 8000, loss: 12.945012
 >> iter 9000, loss: 12.931490
 >> iter 10000, loss: 12.939139
   Number of active neurons: 3
 >> iter 11000, loss: 12.927441
 >> iter 12000, loss: 12.934602
 >> iter 13000, loss: 12.923432
 >> iter 14000, loss: 12.929130
 >> iter 15000, loss: 12.636283
 >> iter 16000, loss: 8.526237
 >> iter 17000, loss: 3.244665
 >> iter 18000, loss: 1.239704
 >> iter 19000, loss: 0.485991
 >> iter 20000, loss: 0.202164
   Number of active neurons: 8
 >> iter 21000, loss: 0.093995
 >> iter 22000, loss: 0.051784
 >> iter 23000, loss: 0.034456
 >> iter 24000, loss: 0.026914
 >> iter 25000, loss: 0.023106
 >> iter 26000, loss: 0.021031
 >> iter 27000, loss: 0.019605
 >> iter 28000, loss: 0.018676
 >> iter 29000, loss: 0.017860
 >> iter 30000, loss: 0.017293
   Number of active neurons: 6
 >> iter 31000, loss: 0.016698
 >> iter 32000, loss: 0.016298
 >> iter 33000, loss: 0.015859
 >> iter 34000, loss: 0.015580
 >> iter 35000, loss: 0.015236
 >> iter 36000, loss: 0.015036
 >> iter 37000, loss: 0.014739
 >> iter 38000, loss: 0.014576
 >> iter 39000, loss: 0.014302
 >> iter 40000, loss: 0.014175
   Number of active neurons: 6
 >> iter 41000, loss: 0.013927
 >> iter 42000, loss: 0.013829
 >> iter 43000, loss: 0.013605
 >> iter 44000, loss: 0.013520
 >> iter 45000, loss: 0.013306
 >> iter 46000, loss: 0.013248
 >> iter 47000, loss: 0.013057
 >> iter 48000, loss: 0.013024
 >> iter 49000, loss: 0.012862
 >> iter 50000, loss: 0.012850
   Number of active neurons: 6
 >> iter 51000, loss: 0.012699
 >> iter 52000, loss: 0.012715
 >> iter 53000, loss: 0.012571
 >> iter 54000, loss: 0.012597
 >> iter 55000, loss: 0.012452
 >> iter 56000, loss: 0.012482
 >> iter 57000, loss: 0.012348
 >> iter 58000, loss: 0.012381
 >> iter 59000, loss: 0.012261
 >> iter 60000, loss: 0.012295
   Number of active neurons: 6
 >> iter 61000, loss: 0.012178
 >> iter 62000, loss: 0.012216
 >> iter 63000, loss: 0.012102
 >> iter 64000, loss: 0.012145
 >> iter 65000, loss: 0.012038
 >> iter 66000, loss: 0.012082
 >> iter 67000, loss: 0.011984
 >> iter 68000, loss: 0.012018
 >> iter 69000, loss: 0.011918
 >> iter 70000, loss: 0.011951
   Number of active neurons: 6
 >> iter 71000, loss: 0.011857
 >> iter 72000, loss: 0.011894
 >> iter 73000, loss: 0.011791
 >> iter 74000, loss: 0.011827
 >> iter 75000, loss: 0.011709
 >> iter 76000, loss: 0.011735
 >> iter 77000, loss: 0.011619
 >> iter 78000, loss: 0.011648
 >> iter 79000, loss: 0.011535
 >> iter 80000, loss: 0.011566
   Number of active neurons: 6
 >> iter 81000, loss: 0.011460
 >> iter 82000, loss: 0.011497
 >> iter 83000, loss: 0.011389
 >> iter 84000, loss: 0.011432
 >> iter 85000, loss: 0.011321
 >> iter 86000, loss: 0.011361
 >> iter 87000, loss: 0.011237
 >> iter 88000, loss: 0.011276
 >> iter 89000, loss: 0.011157
 >> iter 90000, loss: 0.011205
   Number of active neurons: 6
 >> iter 91000, loss: 0.011094
 >> iter 92000, loss: 0.011145
 >> iter 93000, loss: 0.011043
 >> iter 94000, loss: 0.011092
 >> iter 95000, loss: 0.010996
 >> iter 96000, loss: 0.011045
 >> iter 97000, loss: 0.010951
 >> iter 98000, loss: 0.010996
 >> iter 99000, loss: 0.010902
 >> iter 100000, loss: 0.010944
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.636361
 >> iter 2000, loss: 15.130147
 >> iter 3000, loss: 13.802192
 >> iter 4000, loss: 13.307224
 >> iter 5000, loss: 13.101804
 >> iter 6000, loss: 13.024339
 >> iter 7000, loss: 12.979242
 >> iter 8000, loss: 12.968812
 >> iter 9000, loss: 12.952188
 >> iter 10000, loss: 12.957243
   Number of active neurons: 4
 >> iter 11000, loss: 12.944104
 >> iter 12000, loss: 12.950230
 >> iter 13000, loss: 12.937105
 >> iter 14000, loss: 12.945507
 >> iter 15000, loss: 12.934006
 >> iter 16000, loss: 12.941179
 >> iter 17000, loss: 12.931657
 >> iter 18000, loss: 12.936425
 >> iter 19000, loss: 12.926018
 >> iter 20000, loss: 12.915561
   Number of active neurons: 4
 >> iter 21000, loss: 10.477182
 >> iter 22000, loss: 4.078983
 >> iter 23000, loss: 1.560189
 >> iter 24000, loss: 0.612394
 >> iter 25000, loss: 0.254212
 >> iter 26000, loss: 0.117348
 >> iter 27000, loss: 0.063589
 >> iter 28000, loss: 0.041511
 >> iter 29000, loss: 0.031662
 >> iter 30000, loss: 0.026804
   Number of active neurons: 6
 >> iter 31000, loss: 0.023944
 >> iter 32000, loss: 0.022155
 >> iter 33000, loss: 0.020751
 >> iter 34000, loss: 0.019752
 >> iter 35000, loss: 0.018849
 >> iter 36000, loss: 0.018211
 >> iter 37000, loss: 0.017551
 >> iter 38000, loss: 0.017133
 >> iter 39000, loss: 0.016616
 >> iter 40000, loss: 0.016294
   Number of active neurons: 6
 >> iter 41000, loss: 0.015901
 >> iter 42000, loss: 0.015645
 >> iter 43000, loss: 0.015355
 >> iter 44000, loss: 0.015186
 >> iter 45000, loss: 0.014951
 >> iter 46000, loss: 0.014850
 >> iter 47000, loss: 0.014622
 >> iter 48000, loss: 0.014567
 >> iter 49000, loss: 0.014346
 >> iter 50000, loss: 0.014331
   Number of active neurons: 6
 >> iter 51000, loss: 0.014097
 >> iter 52000, loss: 0.014108
 >> iter 53000, loss: 0.013865
 >> iter 54000, loss: 0.013899
 >> iter 55000, loss: 0.013633
 >> iter 56000, loss: 0.013672
 >> iter 57000, loss: 0.013397
 >> iter 58000, loss: 0.013471
 >> iter 59000, loss: 0.013196
 >> iter 60000, loss: 0.013280
   Number of active neurons: 6
 >> iter 61000, loss: 0.013005
 >> iter 62000, loss: 0.013098
 >> iter 63000, loss: 0.012841
 >> iter 64000, loss: 0.012998
 >> iter 65000, loss: 0.012705
 >> iter 66000, loss: 0.012861
 >> iter 67000, loss: 0.012584
 >> iter 68000, loss: 0.012729
 >> iter 69000, loss: 0.012471
 >> iter 70000, loss: 0.012608
   Number of active neurons: 6
 >> iter 71000, loss: 0.012376
 >> iter 72000, loss: 0.012471
 >> iter 73000, loss: 0.012273
 >> iter 74000, loss: 0.012364
 >> iter 75000, loss: 0.012185
 >> iter 76000, loss: 0.012270
 >> iter 77000, loss: 0.012104
 >> iter 78000, loss: 0.012176
 >> iter 79000, loss: 0.012035
 >> iter 80000, loss: 0.012098
   Number of active neurons: 6
 >> iter 81000, loss: 0.011981
 >> iter 82000, loss: 0.012032
 >> iter 83000, loss: 0.011927
 >> iter 84000, loss: 0.011973
 >> iter 85000, loss: 0.011880
 >> iter 86000, loss: 0.011920
 >> iter 87000, loss: 0.011836
 >> iter 88000, loss: 0.011868
 >> iter 89000, loss: 0.011790
 >> iter 90000, loss: 0.011818
   Number of active neurons: 6
 >> iter 91000, loss: 0.011753
 >> iter 92000, loss: 0.011771
 >> iter 93000, loss: 0.011717
 >> iter 94000, loss: 0.011728
 >> iter 95000, loss: 0.011681
 >> iter 96000, loss: 0.011685
 >> iter 97000, loss: 0.011648
 >> iter 98000, loss: 0.011648
 >> iter 99000, loss: 0.011613
 >> iter 100000, loss: 0.011607
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0139998600014
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.651913
 >> iter 2000, loss: 15.112604
 >> iter 3000, loss: 13.777557
 >> iter 4000, loss: 13.281760
 >> iter 5000, loss: 13.079898
 >> iter 6000, loss: 13.004656
 >> iter 7000, loss: 12.961374
 >> iter 8000, loss: 12.953098
 >> iter 9000, loss: 12.936852
 >> iter 10000, loss: 12.943271
   Number of active neurons: 3
 >> iter 11000, loss: 12.930333
 >> iter 12000, loss: 12.937335
 >> iter 13000, loss: 12.925494
 >> iter 14000, loss: 12.934202
 >> iter 15000, loss: 12.924260
 >> iter 16000, loss: 12.740996
 >> iter 17000, loss: 11.583472
 >> iter 18000, loss: 5.094459
 >> iter 19000, loss: 2.044044
 >> iter 20000, loss: 0.791650
   Number of active neurons: 6
 >> iter 21000, loss: 0.320600
 >> iter 22000, loss: 0.140620
 >> iter 23000, loss: 0.070934
 >> iter 24000, loss: 0.042938
 >> iter 25000, loss: 0.031044
 >> iter 26000, loss: 0.025377
 >> iter 27000, loss: 0.022348
 >> iter 28000, loss: 0.020500
 >> iter 29000, loss: 0.019166
 >> iter 30000, loss: 0.018211
   Number of active neurons: 6
 >> iter 31000, loss: 0.017376
 >> iter 32000, loss: 0.016765
 >> iter 33000, loss: 0.016198
 >> iter 34000, loss: 0.015767
 >> iter 35000, loss: 0.015348
 >> iter 36000, loss: 0.015037
 >> iter 37000, loss: 0.014750
 >> iter 38000, loss: 0.014518
 >> iter 39000, loss: 0.014276
 >> iter 40000, loss: 0.014106
   Number of active neurons: 6
 >> iter 41000, loss: 0.013936
 >> iter 42000, loss: 0.013795
 >> iter 43000, loss: 0.013637
 >> iter 44000, loss: 0.013529
 >> iter 45000, loss: 0.013426
 >> iter 46000, loss: 0.013347
 >> iter 47000, loss: 0.013226
 >> iter 48000, loss: 0.013150
 >> iter 49000, loss: 0.013048
 >> iter 50000, loss: 0.012991
   Number of active neurons: 6
 >> iter 51000, loss: 0.012888
 >> iter 52000, loss: 0.012853
 >> iter 53000, loss: 0.012757
 >> iter 54000, loss: 0.012745
 >> iter 55000, loss: 0.012652
 >> iter 56000, loss: 0.012647
 >> iter 57000, loss: 0.012555
 >> iter 58000, loss: 0.012549
 >> iter 59000, loss: 0.012466
 >> iter 60000, loss: 0.012468
   Number of active neurons: 6
 >> iter 61000, loss: 0.012389
 >> iter 62000, loss: 0.012394
 >> iter 63000, loss: 0.012317
 >> iter 64000, loss: 0.012331
 >> iter 65000, loss: 0.012261
 >> iter 66000, loss: 0.012266
 >> iter 67000, loss: 0.012201
 >> iter 68000, loss: 0.012206
 >> iter 69000, loss: 0.012141
 >> iter 70000, loss: 0.012138
   Number of active neurons: 6
 >> iter 71000, loss: 0.012073
 >> iter 72000, loss: 0.012069
 >> iter 73000, loss: 0.012004
 >> iter 74000, loss: 0.012010
 >> iter 75000, loss: 0.011947
 >> iter 76000, loss: 0.011958
 >> iter 77000, loss: 0.011901
 >> iter 78000, loss: 0.011908
 >> iter 79000, loss: 0.011851
 >> iter 80000, loss: 0.011860
   Number of active neurons: 6
 >> iter 81000, loss: 0.011804
 >> iter 82000, loss: 0.011805
 >> iter 83000, loss: 0.011738
 >> iter 84000, loss: 0.011737
 >> iter 85000, loss: 0.011680
 >> iter 86000, loss: 0.011677
 >> iter 87000, loss: 0.011618
 >> iter 88000, loss: 0.011622
 >> iter 89000, loss: 0.011556
 >> iter 90000, loss: 0.011554
   Number of active neurons: 6
 >> iter 91000, loss: 0.011485
 >> iter 92000, loss: 0.011479
 >> iter 93000, loss: 0.011415
 >> iter 94000, loss: 0.011411
 >> iter 95000, loss: 0.011348
 >> iter 96000, loss: 0.011348
 >> iter 97000, loss: 0.011289
 >> iter 98000, loss: 0.011291
 >> iter 99000, loss: 0.011232
 >> iter 100000, loss: 0.011238
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0109998900011
   - Test - A: 0.0
   - Test - B: 37.0775281648
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.617884
 >> iter 2000, loss: 15.083322
 >> iter 3000, loss: 13.747850
 >> iter 4000, loss: 13.255534
 >> iter 5000, loss: 13.060937
 >> iter 6000, loss: 12.994230
 >> iter 7000, loss: 12.959886
 >> iter 8000, loss: 12.955905
 >> iter 9000, loss: 12.944226
 >> iter 10000, loss: 12.951770
   Number of active neurons: 4
 >> iter 11000, loss: 12.941331
 >> iter 12000, loss: 12.948654
 >> iter 13000, loss: 12.938529
 >> iter 14000, loss: 12.947837
 >> iter 15000, loss: 12.940009
 >> iter 16000, loss: 12.947789
 >> iter 17000, loss: 12.941204
 >> iter 18000, loss: 12.946363
 >> iter 19000, loss: 12.938219
 >> iter 20000, loss: 12.948758
   Number of active neurons: 4
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 4
 >> iter 21000, loss: 12.936629
 >> iter 22000, loss: 12.948102
 >> iter 23000, loss: 12.936812
 >> iter 24000, loss: 12.948101
 >> iter 25000, loss: 12.936245
 >> iter 26000, loss: 12.945860
 >> iter 27000, loss: 12.935697
 >> iter 28000, loss: 12.945206
 >> iter 29000, loss: 12.935577
 >> iter 30000, loss: 12.945737
   Number of active neurons: 4
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 4
 >> iter 31000, loss: 12.927078
 >> iter 32000, loss: 12.126777
 >> iter 33000, loss: 10.791603
 >> iter 34000, loss: 10.228454
 >> iter 35000, loss: 9.411362
 >> iter 36000, loss: 9.101168
 >> iter 37000, loss: 9.053507
 >> iter 38000, loss: 9.244447
 >> iter 39000, loss: 9.198892
 >> iter 40000, loss: 9.156370
   Number of active neurons: 9
 >> iter 41000, loss: 4.392591
 >> iter 42000, loss: 1.665277
 >> iter 43000, loss: 0.643967
 >> iter 44000, loss: 0.261301
 >> iter 45000, loss: 0.115971
 >> iter 46000, loss: 0.060056
 >> iter 47000, loss: 0.037326
 >> iter 48000, loss: 0.027795
 >> iter 49000, loss: 0.023016
 >> iter 50000, loss: 0.020590
   Number of active neurons: 8
 >> iter 51000, loss: 0.018828
 >> iter 52000, loss: 0.017753
 >> iter 53000, loss: 0.016730
 >> iter 54000, loss: 0.016072
 >> iter 55000, loss: 0.015350
 >> iter 56000, loss: 0.014906
 >> iter 57000, loss: 0.014377
 >> iter 58000, loss: 0.014072
 >> iter 59000, loss: 0.013662
 >> iter 60000, loss: 0.013445
   Number of active neurons: 7
 >> iter 61000, loss: 0.013122
 >> iter 62000, loss: 0.012984
 >> iter 63000, loss: 0.012724
 >> iter 64000, loss: 0.012632
 >> iter 65000, loss: 0.012417
 >> iter 66000, loss: 0.012348
 >> iter 67000, loss: 0.012169
 >> iter 68000, loss: 0.012118
 >> iter 69000, loss: 0.011959
 >> iter 70000, loss: 0.011910
   Number of active neurons: 7
 >> iter 71000, loss: 0.011766
 >> iter 72000, loss: 0.011727
 >> iter 73000, loss: 0.011595
 >> iter 74000, loss: 0.011566
 >> iter 75000, loss: 0.011427
 >> iter 76000, loss: 0.011381
 >> iter 77000, loss: 0.011243
 >> iter 78000, loss: 0.011201
 >> iter 79000, loss: 0.011074
 >> iter 80000, loss: 0.011047
   Number of active neurons: 7
 >> iter 81000, loss: 0.010936
 >> iter 82000, loss: 0.010918
 >> iter 83000, loss: 0.010815
 >> iter 84000, loss: 0.010805
 >> iter 85000, loss: 0.010710
 >> iter 86000, loss: 0.010701
 >> iter 87000, loss: 0.010603
 >> iter 88000, loss: 0.010601
 >> iter 89000, loss: 0.010511
 >> iter 90000, loss: 0.010517
   Number of active neurons: 6
 >> iter 91000, loss: 0.010433
 >> iter 92000, loss: 0.010442
 >> iter 93000, loss: 0.010362
 >> iter 94000, loss: 0.010372
 >> iter 95000, loss: 0.010292
 >> iter 96000, loss: 0.010299
 >> iter 97000, loss: 0.010216
 >> iter 98000, loss: 0.010223
 >> iter 99000, loss: 0.010144
 >> iter 100000, loss: 0.010152
   Number of active neurons: 6
 >> iter 101000, loss: 0.010074
 >> iter 102000, loss: 0.010088
 >> iter 103000, loss: 0.010011
 >> iter 104000, loss: 0.010018
 >> iter 105000, loss: 0.009939
 >> iter 106000, loss: 0.009943
 >> iter 107000, loss: 0.009866
 >> iter 108000, loss: 0.009872
 >> iter 109000, loss: 0.009796
 >> iter 110000, loss: 0.009799
   Number of active neurons: 6
 >> iter 111000, loss: 0.009726
 >> iter 112000, loss: 0.009732
 >> iter 113000, loss: 0.009663
 >> iter 114000, loss: 0.009666
 >> iter 115000, loss: 0.009605
 >> iter 116000, loss: 0.009608
 >> iter 117000, loss: 0.009549
 >> iter 118000, loss: 0.009537
 >> iter 119000, loss: 0.009486
 >> iter 120000, loss: 0.009472
   Number of active neurons: 6
 >> iter 121000, loss: 0.009434
 >> iter 122000, loss: 0.009412
 >> iter 123000, loss: 0.009381
 >> iter 124000, loss: 0.009351
 >> iter 125000, loss: 0.009313
 >> iter 126000, loss: 0.009289
 >> iter 127000, loss: 0.009250
 >> iter 128000, loss: 0.009232
 >> iter 129000, loss: 0.009196
 >> iter 130000, loss: 0.009181
   Number of active neurons: 6
 >> iter 131000, loss: 0.009155
 >> iter 132000, loss: 0.009141
 >> iter 133000, loss: 0.009123
 >> iter 134000, loss: 0.009106
 >> iter 135000, loss: 0.009089
 >> iter 136000, loss: 0.009072
 >> iter 137000, loss: 0.009055
 >> iter 138000, loss: 0.009033
 >> iter 139000, loss: 0.009017
 >> iter 140000, loss: 0.008991
   Number of active neurons: 6
 >> iter 141000, loss: 0.008982
 >> iter 142000, loss: 0.008953
 >> iter 143000, loss: 0.008949
 >> iter 144000, loss: 0.008918
 >> iter 145000, loss: 0.008917
 >> iter 146000, loss: 0.008883
 >> iter 147000, loss: 0.008885
 >> iter 148000, loss: 0.008848
 >> iter 149000, loss: 0.008839
 >> iter 150000, loss: 0.008805
   Number of active neurons: 6
 >> iter 151000, loss: 0.008799
 >> iter 152000, loss: 0.008773
 >> iter 153000, loss: 0.008775
 >> iter 154000, loss: 0.008756
 >> iter 155000, loss: 0.008764
 >> iter 156000, loss: 0.008759
 >> iter 157000, loss: 0.008767
 >> iter 158000, loss: 0.008778
 >> iter 159000, loss: 0.008782
 >> iter 160000, loss: 0.008803
   Number of active neurons: 6
 >> iter 161000, loss: 0.008799
 >> iter 162000, loss: 0.008827
 >> iter 163000, loss: 0.008816
 >> iter 164000, loss: 0.008843
 >> iter 165000, loss: 0.008827
 >> iter 166000, loss: 0.008855
 >> iter 167000, loss: 0.008831
 >> iter 168000, loss: 0.008864
 >> iter 169000, loss: 0.008834
 >> iter 170000, loss: 0.008869
   Number of active neurons: 6
 >> iter 171000, loss: 0.008833
 >> iter 172000, loss: 0.008868
 >> iter 173000, loss: 0.008830
 >> iter 174000, loss: 0.008865
 >> iter 175000, loss: 0.008824
 >> iter 176000, loss: 0.008856
 >> iter 177000, loss: 0.008818
 >> iter 178000, loss: 0.008843
 >> iter 179000, loss: 0.008811
 >> iter 180000, loss: 0.008829
   Number of active neurons: 6
 >> iter 181000, loss: 0.008802
 >> iter 182000, loss: 0.008812
 >> iter 183000, loss: 0.008793
 >> iter 184000, loss: 0.008796
 >> iter 185000, loss: 0.008784
 >> iter 186000, loss: 0.008780
 >> iter 187000, loss: 0.008776
 >> iter 188000, loss: 0.008765
 >> iter 189000, loss: 0.008771
 >> iter 190000, loss: 0.008748
   Number of active neurons: 6
 >> iter 191000, loss: 0.008767
 >> iter 192000, loss: 0.008731
 >> iter 193000, loss: 0.008764
 >> iter 194000, loss: 0.008716
 >> iter 195000, loss: 0.008759
 >> iter 196000, loss: 0.008705
 >> iter 197000, loss: 0.008751
 >> iter 198000, loss: 0.008689
 >> iter 199000, loss: 0.008744
 >> iter 200000, loss: 0.008673
   Number of active neurons: 6
 >> iter 201000, loss: 0.008733
 >> iter 202000, loss: 0.008657
 >> iter 203000, loss: 0.008715
 >> iter 204000, loss: 0.008636
 >> iter 205000, loss: 0.008693
 >> iter 206000, loss: 0.008616
 >> iter 207000, loss: 0.008675
 >> iter 208000, loss: 0.008596
 >> iter 209000, loss: 0.008658
 >> iter 210000, loss: 0.008579
   Number of active neurons: 6
 >> iter 211000, loss: 0.008641
 >> iter 212000, loss: 0.008564
 >> iter 213000, loss: 0.008628
 >> iter 214000, loss: 0.008549
 >> iter 215000, loss: 0.008613
 >> iter 216000, loss: 0.008537
 >> iter 217000, loss: 0.008600
 >> iter 218000, loss: 0.008522
 >> iter 219000, loss: 0.008583
 >> iter 220000, loss: 0.008506
   Number of active neurons: 6
 >> iter 221000, loss: 0.008570
 >> iter 222000, loss: 0.008491
 >> iter 223000, loss: 0.008555
 >> iter 224000, loss: 0.008475
 >> iter 225000, loss: 0.008535
 >> iter 226000, loss: 0.008454
 >> iter 227000, loss: 0.008511
 >> iter 228000, loss: 0.008435
 >> iter 229000, loss: 0.008491
 >> iter 230000, loss: 0.008419
   Number of active neurons: 6
 >> iter 231000, loss: 0.008472
 >> iter 232000, loss: 0.008408
 >> iter 233000, loss: 0.008454
 >> iter 234000, loss: 0.008391
 >> iter 235000, loss: 0.008431
 >> iter 236000, loss: 0.008375
 >> iter 237000, loss: 0.008415
 >> iter 238000, loss: 0.008365
 >> iter 239000, loss: 0.008403
 >> iter 240000, loss: 0.008358
   Number of active neurons: 5
 >> iter 241000, loss: 0.008391
 >> iter 242000, loss: 0.008352
 >> iter 243000, loss: 0.008385
 >> iter 244000, loss: 0.008348
 >> iter 245000, loss: 0.008376
 >> iter 246000, loss: 0.008346
 >> iter 247000, loss: 0.008368
 >> iter 248000, loss: 0.008346
 >> iter 249000, loss: 0.008365
 >> iter 250000, loss: 0.008346
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

