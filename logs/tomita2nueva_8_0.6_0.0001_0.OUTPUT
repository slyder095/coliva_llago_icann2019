 > Problema: tomita2nueva
 > Args:
   - Hidden size: 8
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.498514
 >> iter 2000, loss: 4.420143
 >> iter 3000, loss: 1.689292
 >> iter 4000, loss: 0.654985
 >> iter 5000, loss: 0.290850
 >> iter 6000, loss: 0.164767
 >> iter 7000, loss: 0.097412
 >> iter 8000, loss: 0.079199
 >> iter 9000, loss: 0.090032
 >> iter 10000, loss: 0.087966
   Number of active neurons: 4
 >> iter 11000, loss: 0.066649
 >> iter 12000, loss: 0.071942
 >> iter 13000, loss: 0.055765
 >> iter 14000, loss: 0.044270
 >> iter 15000, loss: 0.042461
 >> iter 16000, loss: 0.058805
 >> iter 17000, loss: 0.050823
 >> iter 18000, loss: 0.053259
 >> iter 19000, loss: 0.047371
 >> iter 20000, loss: 0.045371
   Number of active neurons: 4
 >> iter 21000, loss: 0.045842
 >> iter 22000, loss: 0.053753
 >> iter 23000, loss: 0.054469
 >> iter 24000, loss: 0.053360
 >> iter 25000, loss: 0.057198
 >> iter 26000, loss: 0.048241
 >> iter 27000, loss: 0.048046
 >> iter 28000, loss: 0.066568
 >> iter 29000, loss: 0.048653
 >> iter 30000, loss: 0.037807
   Number of active neurons: 3
 >> iter 31000, loss: 0.043945
 >> iter 32000, loss: 0.043649
 >> iter 33000, loss: 0.045433
 >> iter 34000, loss: 0.042300
 >> iter 35000, loss: 0.054439
 >> iter 36000, loss: 0.039787
 >> iter 37000, loss: 0.059486
 >> iter 38000, loss: 0.045085
 >> iter 39000, loss: 0.061809
 >> iter 40000, loss: 0.045271
   Number of active neurons: 3
 >> iter 41000, loss: 0.044638
 >> iter 42000, loss: 0.038724
 >> iter 43000, loss: 0.032742
 >> iter 44000, loss: 0.044782
 >> iter 45000, loss: 0.045739
 >> iter 46000, loss: 0.038667
 >> iter 47000, loss: 0.042790
 >> iter 48000, loss: 0.058443
 >> iter 49000, loss: 0.051800
 >> iter 50000, loss: 0.049944
   Number of active neurons: 3
 >> iter 51000, loss: 0.048322
 >> iter 52000, loss: 0.053640
 >> iter 53000, loss: 0.040399
 >> iter 54000, loss: 0.035297
 >> iter 55000, loss: 0.035103
 >> iter 56000, loss: 0.039045
 >> iter 57000, loss: 0.051648
 >> iter 58000, loss: 0.038575
 >> iter 59000, loss: 0.044121
 >> iter 60000, loss: 0.070507
   Number of active neurons: 3
 >> iter 61000, loss: 0.055618
 >> iter 62000, loss: 0.058591
 >> iter 63000, loss: 0.049402
 >> iter 64000, loss: 0.035172
 >> iter 65000, loss: 0.045801
 >> iter 66000, loss: 0.040418
 >> iter 67000, loss: 0.031507
 >> iter 68000, loss: 0.052428
 >> iter 69000, loss: 0.047532
 >> iter 70000, loss: 0.071060
   Number of active neurons: 2
 >> iter 71000, loss: 0.073892
 >> iter 72000, loss: 0.084011
 >> iter 73000, loss: 0.067978
 >> iter 74000, loss: 0.055672
 >> iter 75000, loss: 0.042080
 >> iter 76000, loss: 0.042177
 >> iter 77000, loss: 0.059891
 >> iter 78000, loss: 0.042602
 >> iter 79000, loss: 0.041752
 >> iter 80000, loss: 0.045503
   Number of active neurons: 2
 >> iter 81000, loss: 0.055333
 >> iter 82000, loss: 0.041643
 >> iter 83000, loss: 0.044166
 >> iter 84000, loss: 0.051109
 >> iter 85000, loss: 0.063407
 >> iter 86000, loss: 0.057175
 >> iter 87000, loss: 0.054352
 >> iter 88000, loss: 0.065920
 >> iter 89000, loss: 0.054715
 >> iter 90000, loss: 0.057117
   Number of active neurons: 2
 >> iter 91000, loss: 0.065561
 >> iter 92000, loss: 0.047962
 >> iter 93000, loss: 0.037886
 >> iter 94000, loss: 0.051907
 >> iter 95000, loss: 0.046150
 >> iter 96000, loss: 0.037616
 >> iter 97000, loss: 0.050400
 >> iter 98000, loss: 0.047153
 >> iter 99000, loss: 0.046624
 >> iter 100000, loss: 0.038004
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.371602
 >> iter 2000, loss: 4.362299
 >> iter 3000, loss: 1.683530
 >> iter 4000, loss: 0.698241
 >> iter 5000, loss: 0.298425
 >> iter 6000, loss: 0.147158
 >> iter 7000, loss: 0.104408
 >> iter 8000, loss: 0.074316
 >> iter 9000, loss: 0.072620
 >> iter 10000, loss: 0.076117
   Number of active neurons: 6
 >> iter 11000, loss: 0.071134
 >> iter 12000, loss: 0.059748
 >> iter 13000, loss: 0.078895
 >> iter 14000, loss: 0.059202
 >> iter 15000, loss: 0.074143
 >> iter 16000, loss: 0.066717
 >> iter 17000, loss: 0.049957
 >> iter 18000, loss: 0.063305
 >> iter 19000, loss: 0.065268
 >> iter 20000, loss: 0.053012
   Number of active neurons: 6
 >> iter 21000, loss: 0.054069
 >> iter 22000, loss: 0.068506
 >> iter 23000, loss: 0.064428
 >> iter 24000, loss: 0.058280
 >> iter 25000, loss: 0.059138
 >> iter 26000, loss: 0.066017
 >> iter 27000, loss: 0.061663
 >> iter 28000, loss: 0.053117
 >> iter 29000, loss: 0.044226
 >> iter 30000, loss: 0.047666
   Number of active neurons: 6
 >> iter 31000, loss: 0.045888
 >> iter 32000, loss: 0.063970
 >> iter 33000, loss: 0.062904
 >> iter 34000, loss: 0.061353
 >> iter 35000, loss: 0.051955
 >> iter 36000, loss: 0.050649
 >> iter 37000, loss: 0.045423
 >> iter 38000, loss: 0.045927
 >> iter 39000, loss: 0.050949
 >> iter 40000, loss: 0.086881
   Number of active neurons: 6
 >> iter 41000, loss: 0.079391
 >> iter 42000, loss: 0.051839
 >> iter 43000, loss: 0.072154
 >> iter 44000, loss: 0.068456
 >> iter 45000, loss: 0.068239
 >> iter 46000, loss: 0.066943
 >> iter 47000, loss: 0.057709
 >> iter 48000, loss: 0.059458
 >> iter 49000, loss: 0.046802
 >> iter 50000, loss: 0.057127
   Number of active neurons: 5
 >> iter 51000, loss: 0.062007
 >> iter 52000, loss: 0.054672
 >> iter 53000, loss: 0.042425
 >> iter 54000, loss: 0.036332
 >> iter 55000, loss: 0.048945
 >> iter 56000, loss: 0.042362
 >> iter 57000, loss: 0.037240
 >> iter 58000, loss: 0.044154
 >> iter 59000, loss: 0.041136
 >> iter 60000, loss: 0.057500
   Number of active neurons: 4
 >> iter 61000, loss: 0.046133
 >> iter 62000, loss: 0.031846
 >> iter 63000, loss: 0.053706
 >> iter 64000, loss: 0.067690
 >> iter 65000, loss: 0.054141
 >> iter 66000, loss: 0.061249
 >> iter 67000, loss: 0.051025
 >> iter 68000, loss: 0.047418
 >> iter 69000, loss: 0.063144
 >> iter 70000, loss: 0.056341
   Number of active neurons: 3
 >> iter 71000, loss: 0.062849
 >> iter 72000, loss: 0.046416
 >> iter 73000, loss: 0.034863
 >> iter 74000, loss: 0.058507
 >> iter 75000, loss: 0.056934
 >> iter 76000, loss: 0.072705
 >> iter 77000, loss: 0.060664
 >> iter 78000, loss: 0.059216
 >> iter 79000, loss: 0.037912
 >> iter 80000, loss: 0.054713
   Number of active neurons: 3
 >> iter 81000, loss: 0.038279
 >> iter 82000, loss: 0.044451
 >> iter 83000, loss: 0.058182
 >> iter 84000, loss: 0.042270
 >> iter 85000, loss: 0.065580
 >> iter 86000, loss: 0.048365
 >> iter 87000, loss: 0.046702
 >> iter 88000, loss: 0.046513
 >> iter 89000, loss: 0.048323
 >> iter 90000, loss: 0.045842
   Number of active neurons: 3
 >> iter 91000, loss: 0.060752
 >> iter 92000, loss: 0.056040
 >> iter 93000, loss: 0.050781
 >> iter 94000, loss: 0.043227
 >> iter 95000, loss: 0.035087
 >> iter 96000, loss: 0.034270
 >> iter 97000, loss: 0.037211
 >> iter 98000, loss: 0.053006
 >> iter 99000, loss: 0.052675
 >> iter 100000, loss: 0.038876
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.386602
 >> iter 2000, loss: 4.364992
 >> iter 3000, loss: 1.715685
 >> iter 4000, loss: 0.693091
 >> iter 5000, loss: 0.312250
 >> iter 6000, loss: 0.172382
 >> iter 7000, loss: 0.107287
 >> iter 8000, loss: 0.064091
 >> iter 9000, loss: 0.067174
 >> iter 10000, loss: 0.068069
   Number of active neurons: 7
 >> iter 11000, loss: 0.057317
 >> iter 12000, loss: 0.057819
 >> iter 13000, loss: 0.060878
 >> iter 14000, loss: 0.086242
 >> iter 15000, loss: 0.061799
 >> iter 16000, loss: 0.051597
 >> iter 17000, loss: 0.059741
 >> iter 18000, loss: 0.073490
 >> iter 19000, loss: 0.069711
 >> iter 20000, loss: 0.061216
   Number of active neurons: 6
 >> iter 21000, loss: 0.053496
 >> iter 22000, loss: 0.054707
 >> iter 23000, loss: 0.050908
 >> iter 24000, loss: 0.044456
 >> iter 25000, loss: 0.053784
 >> iter 26000, loss: 0.058098
 >> iter 27000, loss: 0.082955
 >> iter 28000, loss: 0.070190
 >> iter 29000, loss: 0.058699
 >> iter 30000, loss: 0.046942
   Number of active neurons: 4
 >> iter 31000, loss: 0.049785
 >> iter 32000, loss: 0.044150
 >> iter 33000, loss: 0.066426
 >> iter 34000, loss: 0.051020
 >> iter 35000, loss: 0.044574
 >> iter 36000, loss: 0.054522
 >> iter 37000, loss: 0.064672
 >> iter 38000, loss: 0.048331
 >> iter 39000, loss: 0.059394
 >> iter 40000, loss: 0.049238
   Number of active neurons: 4
 >> iter 41000, loss: 0.052098
 >> iter 42000, loss: 0.039461
 >> iter 43000, loss: 0.032092
 >> iter 44000, loss: 0.033301
 >> iter 45000, loss: 0.053486
 >> iter 46000, loss: 0.060496
 >> iter 47000, loss: 0.049012
 >> iter 48000, loss: 0.059302
 >> iter 49000, loss: 0.054555
 >> iter 50000, loss: 0.056929
   Number of active neurons: 3
 >> iter 51000, loss: 0.048467
 >> iter 52000, loss: 0.037482
 >> iter 53000, loss: 0.044648
 >> iter 54000, loss: 0.043509
 >> iter 55000, loss: 0.050184
 >> iter 56000, loss: 0.062287
 >> iter 57000, loss: 0.072295
 >> iter 58000, loss: 0.061779
 >> iter 59000, loss: 0.059574
 >> iter 60000, loss: 0.057655
   Number of active neurons: 3
 >> iter 61000, loss: 0.061708
 >> iter 62000, loss: 0.048175
 >> iter 63000, loss: 0.042998
 >> iter 64000, loss: 0.055150
 >> iter 65000, loss: 0.052861
 >> iter 66000, loss: 0.057657
 >> iter 67000, loss: 0.048493
 >> iter 68000, loss: 0.061127
 >> iter 69000, loss: 0.055763
 >> iter 70000, loss: 0.048156
   Number of active neurons: 3
 >> iter 71000, loss: 0.075984
 >> iter 72000, loss: 0.063529
 >> iter 73000, loss: 0.049743
 >> iter 74000, loss: 0.048159
 >> iter 75000, loss: 0.057721
 >> iter 76000, loss: 0.054257
 >> iter 77000, loss: 0.049465
 >> iter 78000, loss: 0.045465
 >> iter 79000, loss: 0.059253
 >> iter 80000, loss: 0.053297
   Number of active neurons: 3
 >> iter 81000, loss: 0.054476
 >> iter 82000, loss: 0.034573
 >> iter 83000, loss: 0.050300
 >> iter 84000, loss: 0.054304
 >> iter 85000, loss: 0.059607
 >> iter 86000, loss: 0.049816
 >> iter 87000, loss: 0.040910
 >> iter 88000, loss: 0.057058
 >> iter 89000, loss: 0.058618
 >> iter 90000, loss: 0.056916
   Number of active neurons: 3
 >> iter 91000, loss: 0.056549
 >> iter 92000, loss: 0.044440
 >> iter 93000, loss: 0.042686
 >> iter 94000, loss: 0.038713
 >> iter 95000, loss: 0.046090
 >> iter 96000, loss: 0.049053
 >> iter 97000, loss: 0.044578
 >> iter 98000, loss: 0.062334
 >> iter 99000, loss: 0.042131
 >> iter 100000, loss: 0.044674
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.498961
 >> iter 2000, loss: 4.465357
 >> iter 3000, loss: 1.741738
 >> iter 4000, loss: 0.734044
 >> iter 5000, loss: 0.317415
 >> iter 6000, loss: 0.168347
 >> iter 7000, loss: 0.112454
 >> iter 8000, loss: 0.071556
 >> iter 9000, loss: 0.073107
 >> iter 10000, loss: 0.066068
   Number of active neurons: 6
 >> iter 11000, loss: 0.081716
 >> iter 12000, loss: 0.074361
 >> iter 13000, loss: 0.067677
 >> iter 14000, loss: 0.050522
 >> iter 15000, loss: 0.048276
 >> iter 16000, loss: 0.044196
 >> iter 17000, loss: 0.053949
 >> iter 18000, loss: 0.042192
 >> iter 19000, loss: 0.060642
 >> iter 20000, loss: 0.050064
   Number of active neurons: 5
 >> iter 21000, loss: 0.061142
 >> iter 22000, loss: 0.059905
 >> iter 23000, loss: 0.058649
 >> iter 24000, loss: 0.051687
 >> iter 25000, loss: 0.050015
 >> iter 26000, loss: 0.050241
 >> iter 27000, loss: 0.067166
 >> iter 28000, loss: 0.060435
 >> iter 29000, loss: 0.052901
 >> iter 30000, loss: 0.046633
   Number of active neurons: 5
 >> iter 31000, loss: 0.057601
 >> iter 32000, loss: 0.046774
 >> iter 33000, loss: 0.049163
 >> iter 34000, loss: 0.040938
 >> iter 35000, loss: 0.042442
 >> iter 36000, loss: 0.038957
 >> iter 37000, loss: 0.061873
 >> iter 38000, loss: 0.050699
 >> iter 39000, loss: 0.037372
 >> iter 40000, loss: 0.048649
   Number of active neurons: 4
 >> iter 41000, loss: 0.053838
 >> iter 42000, loss: 0.043469
 >> iter 43000, loss: 0.043814
 >> iter 44000, loss: 0.052382
 >> iter 45000, loss: 0.040980
 >> iter 46000, loss: 0.054582
 >> iter 47000, loss: 0.063029
 >> iter 48000, loss: 0.063023
 >> iter 49000, loss: 0.051069
 >> iter 50000, loss: 0.037974
   Number of active neurons: 3
 >> iter 51000, loss: 0.049767
 >> iter 52000, loss: 0.045439
 >> iter 53000, loss: 0.048770
 >> iter 54000, loss: 0.034048
 >> iter 55000, loss: 0.034326
 >> iter 56000, loss: 0.045157
 >> iter 57000, loss: 0.047074
 >> iter 58000, loss: 0.052434
 >> iter 59000, loss: 0.047377
 >> iter 60000, loss: 0.046802
   Number of active neurons: 3
 >> iter 61000, loss: 0.058090
 >> iter 62000, loss: 0.053362
 >> iter 63000, loss: 0.049282
 >> iter 64000, loss: 0.036506
 >> iter 65000, loss: 0.063439
 >> iter 66000, loss: 0.047657
 >> iter 67000, loss: 0.048597
 >> iter 68000, loss: 0.041700
 >> iter 69000, loss: 0.053539
 >> iter 70000, loss: 0.078107
   Number of active neurons: 3
 >> iter 71000, loss: 0.060039
 >> iter 72000, loss: 0.042688
 >> iter 73000, loss: 0.040085
 >> iter 74000, loss: 0.039902
 >> iter 75000, loss: 0.052993
 >> iter 76000, loss: 0.050228
 >> iter 77000, loss: 0.051751
 >> iter 78000, loss: 0.051013
 >> iter 79000, loss: 0.041850
 >> iter 80000, loss: 0.045899
   Number of active neurons: 3
 >> iter 81000, loss: 0.063756
 >> iter 82000, loss: 0.053754
 >> iter 83000, loss: 0.040273
 >> iter 84000, loss: 0.051425
 >> iter 85000, loss: 0.035124
 >> iter 86000, loss: 0.043446
 >> iter 87000, loss: 0.051265
 >> iter 88000, loss: 0.039524
 >> iter 89000, loss: 0.047163
 >> iter 90000, loss: 0.053114
   Number of active neurons: 3
 >> iter 91000, loss: 0.057286
 >> iter 92000, loss: 0.045290
 >> iter 93000, loss: 0.047163
 >> iter 94000, loss: 0.034442
 >> iter 95000, loss: 0.041459
 >> iter 96000, loss: 0.059531
 >> iter 97000, loss: 0.045278
 >> iter 98000, loss: 0.044137
 >> iter 99000, loss: 0.041402
 >> iter 100000, loss: 0.042760
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.376900
 >> iter 2000, loss: 4.466216
 >> iter 3000, loss: 1.742550
 >> iter 4000, loss: 0.705612
 >> iter 5000, loss: 0.300569
 >> iter 6000, loss: 0.152112
 >> iter 7000, loss: 0.104715
 >> iter 8000, loss: 0.090527
 >> iter 9000, loss: 0.083648
 >> iter 10000, loss: 0.081501
   Number of active neurons: 6
 >> iter 11000, loss: 0.074546
 >> iter 12000, loss: 0.072767
 >> iter 13000, loss: 0.064966
 >> iter 14000, loss: 0.048245
 >> iter 15000, loss: 0.050857
 >> iter 16000, loss: 0.054771
 >> iter 17000, loss: 0.057771
 >> iter 18000, loss: 0.054399
 >> iter 19000, loss: 0.064003
 >> iter 20000, loss: 0.051568
   Number of active neurons: 6
 >> iter 21000, loss: 0.063868
 >> iter 22000, loss: 0.053851
 >> iter 23000, loss: 0.066885
 >> iter 24000, loss: 0.060127
 >> iter 25000, loss: 0.056230
 >> iter 26000, loss: 0.049839
 >> iter 27000, loss: 0.043727
 >> iter 28000, loss: 0.049710
 >> iter 29000, loss: 0.044995
 >> iter 30000, loss: 0.048942
   Number of active neurons: 5
 >> iter 31000, loss: 0.059798
 >> iter 32000, loss: 0.051991
 >> iter 33000, loss: 0.058371
 >> iter 34000, loss: 0.065432
 >> iter 35000, loss: 0.099736
 >> iter 36000, loss: 0.058537
 >> iter 37000, loss: 0.043223
 >> iter 38000, loss: 0.043686
 >> iter 39000, loss: 0.038531
 >> iter 40000, loss: 0.043245
   Number of active neurons: 5
 >> iter 41000, loss: 0.038777
 >> iter 42000, loss: 0.046120
 >> iter 43000, loss: 0.066846
 >> iter 44000, loss: 0.065673
 >> iter 45000, loss: 0.061631
 >> iter 46000, loss: 0.045774
 >> iter 47000, loss: 0.048704
 >> iter 48000, loss: 0.067224
 >> iter 49000, loss: 0.077187
 >> iter 50000, loss: 0.048009
   Number of active neurons: 5
 >> iter 51000, loss: 0.035691
 >> iter 52000, loss: 0.042081
 >> iter 53000, loss: 0.043722
 >> iter 54000, loss: 0.053471
 >> iter 55000, loss: 0.063795
 >> iter 56000, loss: 0.049518
 >> iter 57000, loss: 0.047183
 >> iter 58000, loss: 0.040965
 >> iter 59000, loss: 0.040684
 >> iter 60000, loss: 0.034540
   Number of active neurons: 4
 >> iter 61000, loss: 0.050580
 >> iter 62000, loss: 0.052003
 >> iter 63000, loss: 0.065371
 >> iter 64000, loss: 0.055726
 >> iter 65000, loss: 0.044594
 >> iter 66000, loss: 0.049233
 >> iter 67000, loss: 0.039972
 >> iter 68000, loss: 0.066531
 >> iter 69000, loss: 0.067501
 >> iter 70000, loss: 0.052830
   Number of active neurons: 4
 >> iter 71000, loss: 0.078025
 >> iter 72000, loss: 0.081290
 >> iter 73000, loss: 0.050046
 >> iter 74000, loss: 0.076028
 >> iter 75000, loss: 0.076787
 >> iter 76000, loss: 0.057230
 >> iter 77000, loss: 0.064416
 >> iter 78000, loss: 0.049947
 >> iter 79000, loss: 0.045176
 >> iter 80000, loss: 0.041608
   Number of active neurons: 4
 >> iter 81000, loss: 0.051264
 >> iter 82000, loss: 0.041337
 >> iter 83000, loss: 0.045798
 >> iter 84000, loss: 0.064850
 >> iter 85000, loss: 0.051579
 >> iter 86000, loss: 0.047504
 >> iter 87000, loss: 0.038213
 >> iter 88000, loss: 0.052199
 >> iter 89000, loss: 0.049030
 >> iter 90000, loss: 0.052079
   Number of active neurons: 3
 >> iter 91000, loss: 0.053393
 >> iter 92000, loss: 0.063567
 >> iter 93000, loss: 0.061292
 >> iter 94000, loss: 0.048071
 >> iter 95000, loss: 0.035355
 >> iter 96000, loss: 0.051823
 >> iter 97000, loss: 0.045040
 >> iter 98000, loss: 0.056456
 >> iter 99000, loss: 0.050250
 >> iter 100000, loss: 0.042661
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.340157
 >> iter 2000, loss: 4.380589
 >> iter 3000, loss: 1.706378
 >> iter 4000, loss: 0.686669
 >> iter 5000, loss: 0.302394
 >> iter 6000, loss: 0.148197
 >> iter 7000, loss: 0.104172
 >> iter 8000, loss: 0.102444
 >> iter 9000, loss: 0.074673
 >> iter 10000, loss: 0.070083
   Number of active neurons: 7
 >> iter 11000, loss: 0.064408
 >> iter 12000, loss: 0.049010
 >> iter 13000, loss: 0.051686
 >> iter 14000, loss: 0.068764
 >> iter 15000, loss: 0.053756
 >> iter 16000, loss: 0.061626
 >> iter 17000, loss: 0.054769
 >> iter 18000, loss: 0.068875
 >> iter 19000, loss: 0.062896
 >> iter 20000, loss: 0.058190
   Number of active neurons: 6
 >> iter 21000, loss: 0.051617
 >> iter 22000, loss: 0.049915
 >> iter 23000, loss: 0.048416
 >> iter 24000, loss: 0.049911
 >> iter 25000, loss: 0.070318
 >> iter 26000, loss: 0.050263
 >> iter 27000, loss: 0.056290
 >> iter 28000, loss: 0.052347
 >> iter 29000, loss: 0.059904
 >> iter 30000, loss: 0.062317
   Number of active neurons: 5
 >> iter 31000, loss: 0.063101
 >> iter 32000, loss: 0.060113
 >> iter 33000, loss: 0.044301
 >> iter 34000, loss: 0.040402
 >> iter 35000, loss: 0.040286
 >> iter 36000, loss: 0.039911
 >> iter 37000, loss: 0.046600
 >> iter 38000, loss: 0.045277
 >> iter 39000, loss: 0.034939
 >> iter 40000, loss: 0.057689
   Number of active neurons: 4
 >> iter 41000, loss: 0.046960
 >> iter 42000, loss: 0.059974
 >> iter 43000, loss: 0.058262
 >> iter 44000, loss: 0.039401
 >> iter 45000, loss: 0.053259
 >> iter 46000, loss: 0.043820
 >> iter 47000, loss: 0.039853
 >> iter 48000, loss: 0.033325
 >> iter 49000, loss: 0.039760
 >> iter 50000, loss: 0.034774
   Number of active neurons: 4
 >> iter 51000, loss: 0.050613
 >> iter 52000, loss: 0.045319
 >> iter 53000, loss: 0.041413
 >> iter 54000, loss: 0.042013
 >> iter 55000, loss: 0.050616
 >> iter 56000, loss: 0.043147
 >> iter 57000, loss: 0.042280
 >> iter 58000, loss: 0.046099
 >> iter 59000, loss: 0.042821
 >> iter 60000, loss: 0.041165
   Number of active neurons: 4
 >> iter 61000, loss: 0.051074
 >> iter 62000, loss: 0.038316
 >> iter 63000, loss: 0.039899
 >> iter 64000, loss: 0.035063
 >> iter 65000, loss: 0.047030
 >> iter 66000, loss: 0.037807
 >> iter 67000, loss: 0.065405
 >> iter 68000, loss: 0.065202
 >> iter 69000, loss: 0.042678
 >> iter 70000, loss: 0.065569
   Number of active neurons: 4
 >> iter 71000, loss: 0.050468
 >> iter 72000, loss: 0.036028
 >> iter 73000, loss: 0.048258
 >> iter 74000, loss: 0.045728
 >> iter 75000, loss: 0.046918
 >> iter 76000, loss: 0.042399
 >> iter 77000, loss: 0.079451
 >> iter 78000, loss: 0.051266
 >> iter 79000, loss: 0.056897
 >> iter 80000, loss: 0.067488
   Number of active neurons: 4
 >> iter 81000, loss: 0.055068
 >> iter 82000, loss: 0.056306
 >> iter 83000, loss: 0.054794
 >> iter 84000, loss: 0.058207
 >> iter 85000, loss: 0.054238
 >> iter 86000, loss: 0.059257
 >> iter 87000, loss: 0.068768
 >> iter 88000, loss: 0.077021
 >> iter 89000, loss: 0.061304
 >> iter 90000, loss: 0.048347
   Number of active neurons: 3
 >> iter 91000, loss: 0.053321
 >> iter 92000, loss: 0.051762
 >> iter 93000, loss: 0.054481
 >> iter 94000, loss: 0.062026
 >> iter 95000, loss: 0.045700
 >> iter 96000, loss: 0.051486
 >> iter 97000, loss: 0.043641
 >> iter 98000, loss: 0.057464
 >> iter 99000, loss: 0.060593
 >> iter 100000, loss: 0.063134
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.298989
 >> iter 2000, loss: 4.339390
 >> iter 3000, loss: 1.674676
 >> iter 4000, loss: 0.675457
 >> iter 5000, loss: 0.316407
 >> iter 6000, loss: 0.179912
 >> iter 7000, loss: 0.107387
 >> iter 8000, loss: 0.080307
 >> iter 9000, loss: 0.073314
 >> iter 10000, loss: 0.068208
   Number of active neurons: 5
 >> iter 11000, loss: 0.062825
 >> iter 12000, loss: 0.056163
 >> iter 13000, loss: 0.063852
 >> iter 14000, loss: 0.057225
 >> iter 15000, loss: 0.063635
 >> iter 16000, loss: 0.055903
 >> iter 17000, loss: 0.043860
 >> iter 18000, loss: 0.051999
 >> iter 19000, loss: 0.052559
 >> iter 20000, loss: 0.056026
   Number of active neurons: 5
 >> iter 21000, loss: 0.047124
 >> iter 22000, loss: 0.053057
 >> iter 23000, loss: 0.060872
 >> iter 24000, loss: 0.072893
 >> iter 25000, loss: 0.063158
 >> iter 26000, loss: 0.055666
 >> iter 27000, loss: 0.047292
 >> iter 28000, loss: 0.069700
 >> iter 29000, loss: 0.049951
 >> iter 30000, loss: 0.073646
   Number of active neurons: 5
 >> iter 31000, loss: 0.051564
 >> iter 32000, loss: 0.043213
 >> iter 33000, loss: 0.047120
 >> iter 34000, loss: 0.042265
 >> iter 35000, loss: 0.034879
 >> iter 36000, loss: 0.052325
 >> iter 37000, loss: 0.039148
 >> iter 38000, loss: 0.058603
 >> iter 39000, loss: 0.084912
 >> iter 40000, loss: 0.063429
   Number of active neurons: 4
 >> iter 41000, loss: 0.056338
 >> iter 42000, loss: 0.041083
 >> iter 43000, loss: 0.044056
 >> iter 44000, loss: 0.047488
 >> iter 45000, loss: 0.050559
 >> iter 46000, loss: 0.060497
 >> iter 47000, loss: 0.063200
 >> iter 48000, loss: 0.048256
 >> iter 49000, loss: 0.040620
 >> iter 50000, loss: 0.051037
   Number of active neurons: 4
 >> iter 51000, loss: 0.045764
 >> iter 52000, loss: 0.044114
 >> iter 53000, loss: 0.061129
 >> iter 54000, loss: 0.047209
 >> iter 55000, loss: 0.036748
 >> iter 56000, loss: 0.046304
 >> iter 57000, loss: 0.051915
 >> iter 58000, loss: 0.039383
 >> iter 59000, loss: 0.050595
 >> iter 60000, loss: 0.048505
   Number of active neurons: 4
 >> iter 61000, loss: 0.041137
 >> iter 62000, loss: 0.048769
 >> iter 63000, loss: 0.057886
 >> iter 64000, loss: 0.060323
 >> iter 65000, loss: 0.044326
 >> iter 66000, loss: 0.046674
 >> iter 67000, loss: 0.055172
 >> iter 68000, loss: 0.036793
 >> iter 69000, loss: 0.050201
 >> iter 70000, loss: 0.043193
   Number of active neurons: 3
 >> iter 71000, loss: 0.067485
 >> iter 72000, loss: 0.061932
 >> iter 73000, loss: 0.054508
 >> iter 74000, loss: 0.046514
 >> iter 75000, loss: 0.043077
 >> iter 76000, loss: 0.051152
 >> iter 77000, loss: 0.046884
 >> iter 78000, loss: 0.036333
 >> iter 79000, loss: 0.030667
 >> iter 80000, loss: 0.053447
   Number of active neurons: 3
 >> iter 81000, loss: 0.048044
 >> iter 82000, loss: 0.041507
 >> iter 83000, loss: 0.058254
 >> iter 84000, loss: 0.072968
 >> iter 85000, loss: 0.065173
 >> iter 86000, loss: 0.047015
 >> iter 87000, loss: 0.070623
 >> iter 88000, loss: 0.063006
 >> iter 89000, loss: 0.045102
 >> iter 90000, loss: 0.048270
   Number of active neurons: 3
 >> iter 91000, loss: 0.038854
 >> iter 92000, loss: 0.052460
 >> iter 93000, loss: 0.056134
 >> iter 94000, loss: 0.050605
 >> iter 95000, loss: 0.043583
 >> iter 96000, loss: 0.050659
 >> iter 97000, loss: 0.044170
 >> iter 98000, loss: 0.040134
 >> iter 99000, loss: 0.057765
 >> iter 100000, loss: 0.051755
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.443972
 >> iter 2000, loss: 4.427885
 >> iter 3000, loss: 1.712956
 >> iter 4000, loss: 0.685851
 >> iter 5000, loss: 0.285027
 >> iter 6000, loss: 0.145235
 >> iter 7000, loss: 0.114961
 >> iter 8000, loss: 0.091879
 >> iter 9000, loss: 0.079189
 >> iter 10000, loss: 0.080552
   Number of active neurons: 5
 >> iter 11000, loss: 0.055069
 >> iter 12000, loss: 0.067389
 >> iter 13000, loss: 0.058139
 >> iter 14000, loss: 0.046455
 >> iter 15000, loss: 0.053925
 >> iter 16000, loss: 0.055976
 >> iter 17000, loss: 0.055780
 >> iter 18000, loss: 0.049559
 >> iter 19000, loss: 0.053621
 >> iter 20000, loss: 0.063209
   Number of active neurons: 4
 >> iter 21000, loss: 0.041524
 >> iter 22000, loss: 0.046899
 >> iter 23000, loss: 0.066892
 >> iter 24000, loss: 0.046059
 >> iter 25000, loss: 0.041317
 >> iter 26000, loss: 0.046954
 >> iter 27000, loss: 0.050345
 >> iter 28000, loss: 0.038129
 >> iter 29000, loss: 0.045241
 >> iter 30000, loss: 0.037714
   Number of active neurons: 4
 >> iter 31000, loss: 0.058084
 >> iter 32000, loss: 0.058997
 >> iter 33000, loss: 0.070497
 >> iter 34000, loss: 0.049651
 >> iter 35000, loss: 0.041811
 >> iter 36000, loss: 0.030492
 >> iter 37000, loss: 0.064340
 >> iter 38000, loss: 0.054905
 >> iter 39000, loss: 0.051344
 >> iter 40000, loss: 0.059260
   Number of active neurons: 4
 >> iter 41000, loss: 0.061366
 >> iter 42000, loss: 0.043940
 >> iter 43000, loss: 0.048729
 >> iter 44000, loss: 0.046207
 >> iter 45000, loss: 0.062380
 >> iter 46000, loss: 0.053836
 >> iter 47000, loss: 0.047247
 >> iter 48000, loss: 0.034590
 >> iter 49000, loss: 0.036128
 >> iter 50000, loss: 0.037089
   Number of active neurons: 4
 >> iter 51000, loss: 0.064928
 >> iter 52000, loss: 0.061523
 >> iter 53000, loss: 0.047273
 >> iter 54000, loss: 0.042859
 >> iter 55000, loss: 0.033328
 >> iter 56000, loss: 0.036035
 >> iter 57000, loss: 0.042302
 >> iter 58000, loss: 0.045739
 >> iter 59000, loss: 0.051779
 >> iter 60000, loss: 0.048521
   Number of active neurons: 4
 >> iter 61000, loss: 0.040094
 >> iter 62000, loss: 0.065539
 >> iter 63000, loss: 0.073415
 >> iter 64000, loss: 0.055752
 >> iter 65000, loss: 0.045227
 >> iter 66000, loss: 0.046838
 >> iter 67000, loss: 0.040677
 >> iter 68000, loss: 0.042542
 >> iter 69000, loss: 0.043227
 >> iter 70000, loss: 0.045867
   Number of active neurons: 3
 >> iter 71000, loss: 0.042071
 >> iter 72000, loss: 0.047898
 >> iter 73000, loss: 0.050845
 >> iter 74000, loss: 0.051915
 >> iter 75000, loss: 0.047612
 >> iter 76000, loss: 0.053788
 >> iter 77000, loss: 0.052850
 >> iter 78000, loss: 0.042223
 >> iter 79000, loss: 0.043185
 >> iter 80000, loss: 0.034517
   Number of active neurons: 3
 >> iter 81000, loss: 0.053340
 >> iter 82000, loss: 0.044130
 >> iter 83000, loss: 0.061112
 >> iter 84000, loss: 0.056026
 >> iter 85000, loss: 0.037500
 >> iter 86000, loss: 0.037483
 >> iter 87000, loss: 0.048883
 >> iter 88000, loss: 0.045967
 >> iter 89000, loss: 0.043692
 >> iter 90000, loss: 0.039708
   Number of active neurons: 3
 >> iter 91000, loss: 0.045132
 >> iter 92000, loss: 0.050395
 >> iter 93000, loss: 0.042260
 >> iter 94000, loss: 0.038415
 >> iter 95000, loss: 0.048996
 >> iter 96000, loss: 0.041725
 >> iter 97000, loss: 0.035429
 >> iter 98000, loss: 0.049866
 >> iter 99000, loss: 0.055762
 >> iter 100000, loss: 0.039075
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.240485
 >> iter 2000, loss: 4.321448
 >> iter 3000, loss: 1.671915
 >> iter 4000, loss: 0.707334
 >> iter 5000, loss: 0.341814
 >> iter 6000, loss: 0.175922
 >> iter 7000, loss: 0.120935
 >> iter 8000, loss: 0.082958
 >> iter 9000, loss: 0.080666
 >> iter 10000, loss: 0.053610
   Number of active neurons: 6
 >> iter 11000, loss: 0.066127
 >> iter 12000, loss: 0.069552
 >> iter 13000, loss: 0.059360
 >> iter 14000, loss: 0.061460
 >> iter 15000, loss: 0.067572
 >> iter 16000, loss: 0.059871
 >> iter 17000, loss: 0.061180
 >> iter 18000, loss: 0.053449
 >> iter 19000, loss: 0.072832
 >> iter 20000, loss: 0.060355
   Number of active neurons: 5
 >> iter 21000, loss: 0.061696
 >> iter 22000, loss: 0.063427
 >> iter 23000, loss: 0.069238
 >> iter 24000, loss: 0.056920
 >> iter 25000, loss: 0.049442
 >> iter 26000, loss: 0.074799
 >> iter 27000, loss: 0.056708
 >> iter 28000, loss: 0.053129
 >> iter 29000, loss: 0.060840
 >> iter 30000, loss: 0.045248
   Number of active neurons: 5
 >> iter 31000, loss: 0.051684
 >> iter 32000, loss: 0.053222
 >> iter 33000, loss: 0.096988
 >> iter 34000, loss: 0.065393
 >> iter 35000, loss: 0.061172
 >> iter 36000, loss: 0.056981
 >> iter 37000, loss: 0.069451
 >> iter 38000, loss: 0.060936
 >> iter 39000, loss: 0.054712
 >> iter 40000, loss: 0.045720
   Number of active neurons: 4
 >> iter 41000, loss: 0.040467
 >> iter 42000, loss: 0.053521
 >> iter 43000, loss: 0.064097
 >> iter 44000, loss: 0.043047
 >> iter 45000, loss: 0.058104
 >> iter 46000, loss: 0.055004
 >> iter 47000, loss: 0.047600
 >> iter 48000, loss: 0.042516
 >> iter 49000, loss: 0.046495
 >> iter 50000, loss: 0.068677
   Number of active neurons: 4
 >> iter 51000, loss: 0.067794
 >> iter 52000, loss: 0.061087
 >> iter 53000, loss: 0.057152
 >> iter 54000, loss: 0.048987
 >> iter 55000, loss: 0.037675
 >> iter 56000, loss: 0.033036
 >> iter 57000, loss: 0.035996
 >> iter 58000, loss: 0.059523
 >> iter 59000, loss: 0.058234
 >> iter 60000, loss: 0.055333
   Number of active neurons: 4
 >> iter 61000, loss: 0.048645
 >> iter 62000, loss: 0.055672
 >> iter 63000, loss: 0.057288
 >> iter 64000, loss: 0.055213
 >> iter 65000, loss: 0.055888
 >> iter 66000, loss: 0.050213
 >> iter 67000, loss: 0.038503
 >> iter 68000, loss: 0.045395
 >> iter 69000, loss: 0.041820
 >> iter 70000, loss: 0.055290
   Number of active neurons: 4
 >> iter 71000, loss: 0.049861
 >> iter 72000, loss: 0.052450
 >> iter 73000, loss: 0.041132
 >> iter 74000, loss: 0.042098
 >> iter 75000, loss: 0.049896
 >> iter 76000, loss: 0.052280
 >> iter 77000, loss: 0.079184
 >> iter 78000, loss: 0.063710
 >> iter 79000, loss: 0.080577
 >> iter 80000, loss: 0.050852
   Number of active neurons: 3
 >> iter 81000, loss: 0.096753
 >> iter 82000, loss: 0.066686
 >> iter 83000, loss: 0.056078
 >> iter 84000, loss: 0.070976
 >> iter 85000, loss: 0.069537
 >> iter 86000, loss: 0.060005
 >> iter 87000, loss: 0.050960
 >> iter 88000, loss: 0.067860
 >> iter 89000, loss: 0.060972
 >> iter 90000, loss: 0.071014
   Number of active neurons: 3
 >> iter 91000, loss: 0.046409
 >> iter 92000, loss: 0.034383
 >> iter 93000, loss: 0.055520
 >> iter 94000, loss: 0.052173
 >> iter 95000, loss: 0.043470
 >> iter 96000, loss: 0.057017
 >> iter 97000, loss: 0.058006
 >> iter 98000, loss: 0.054092
 >> iter 99000, loss: 0.050057
 >> iter 100000, loss: 0.053022
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455181
   Number of active neurons: 0
 >> iter 1000, loss: 11.258341
 >> iter 2000, loss: 4.305986
 >> iter 3000, loss: 1.662854
 >> iter 4000, loss: 0.679478
 >> iter 5000, loss: 0.293155
 >> iter 6000, loss: 0.154933
 >> iter 7000, loss: 0.082962
 >> iter 8000, loss: 0.072563
 >> iter 9000, loss: 0.061237
 >> iter 10000, loss: 0.064685
   Number of active neurons: 5
 >> iter 11000, loss: 0.049731
 >> iter 12000, loss: 0.055306
 >> iter 13000, loss: 0.056216
 >> iter 14000, loss: 0.053428
 >> iter 15000, loss: 0.045626
 >> iter 16000, loss: 0.053613
 >> iter 17000, loss: 0.050485
 >> iter 18000, loss: 0.065657
 >> iter 19000, loss: 0.061872
 >> iter 20000, loss: 0.066477
   Number of active neurons: 5
 >> iter 21000, loss: 0.054480
 >> iter 22000, loss: 0.053248
 >> iter 23000, loss: 0.080975
 >> iter 24000, loss: 0.050500
 >> iter 25000, loss: 0.042370
 >> iter 26000, loss: 0.066575
 >> iter 27000, loss: 0.055902
 >> iter 28000, loss: 0.045095
 >> iter 29000, loss: 0.059249
 >> iter 30000, loss: 0.056599
   Number of active neurons: 5
 >> iter 31000, loss: 0.050137
 >> iter 32000, loss: 0.053990
 >> iter 33000, loss: 0.061811
 >> iter 34000, loss: 0.053696
 >> iter 35000, loss: 0.059933
 >> iter 36000, loss: 0.052368
 >> iter 37000, loss: 0.040934
 >> iter 38000, loss: 0.073484
 >> iter 39000, loss: 0.069186
 >> iter 40000, loss: 0.055592
   Number of active neurons: 5
 >> iter 41000, loss: 0.062501
 >> iter 42000, loss: 0.076042
 >> iter 43000, loss: 0.056061
 >> iter 44000, loss: 0.048143
 >> iter 45000, loss: 0.055042
 >> iter 46000, loss: 0.050110
 >> iter 47000, loss: 0.044354
 >> iter 48000, loss: 0.046932
 >> iter 49000, loss: 0.044335
 >> iter 50000, loss: 0.046468
   Number of active neurons: 5
 >> iter 51000, loss: 0.043249
 >> iter 52000, loss: 0.048562
 >> iter 53000, loss: 0.054669
 >> iter 54000, loss: 0.045876
 >> iter 55000, loss: 0.048978
 >> iter 56000, loss: 0.045889
 >> iter 57000, loss: 0.042890
 >> iter 58000, loss: 0.064950
 >> iter 59000, loss: 0.042333
 >> iter 60000, loss: 0.053916
   Number of active neurons: 4
 >> iter 61000, loss: 0.056958
 >> iter 62000, loss: 0.040546
 >> iter 63000, loss: 0.032449
 >> iter 64000, loss: 0.038123
 >> iter 65000, loss: 0.040486
 >> iter 66000, loss: 0.037644
 >> iter 67000, loss: 0.060291
 >> iter 68000, loss: 0.057847
 >> iter 69000, loss: 0.043245
 >> iter 70000, loss: 0.045936
   Number of active neurons: 4
 >> iter 71000, loss: 0.035132
 >> iter 72000, loss: 0.054724
 >> iter 73000, loss: 0.056730
 >> iter 74000, loss: 0.055660
 >> iter 75000, loss: 0.043272
 >> iter 76000, loss: 0.040137
 >> iter 77000, loss: 0.060369
 >> iter 78000, loss: 0.047004
 >> iter 79000, loss: 0.046727
 >> iter 80000, loss: 0.063012
   Number of active neurons: 4
 >> iter 81000, loss: 0.062965
 >> iter 82000, loss: 0.048006
 >> iter 83000, loss: 0.048300
 >> iter 84000, loss: 0.042114
 >> iter 85000, loss: 0.046934
 >> iter 86000, loss: 0.041556
 >> iter 87000, loss: 0.060656
 >> iter 88000, loss: 0.039446
 >> iter 89000, loss: 0.047570
 >> iter 90000, loss: 0.032977
   Number of active neurons: 4
 >> iter 91000, loss: 0.044314
 >> iter 92000, loss: 0.043332
 >> iter 93000, loss: 0.056878
 >> iter 94000, loss: 0.055497
 >> iter 95000, loss: 0.050720
 >> iter 96000, loss: 0.043649
 >> iter 97000, loss: 0.040956
 >> iter 98000, loss: 0.049760
 >> iter 99000, loss: 0.040580
 >> iter 100000, loss: 0.048389
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.471299
 >> iter 2000, loss: 4.481848
 >> iter 3000, loss: 1.758304
 >> iter 4000, loss: 0.728123
 >> iter 5000, loss: 0.331265
 >> iter 6000, loss: 0.179449
 >> iter 7000, loss: 0.117129
 >> iter 8000, loss: 0.090312
 >> iter 9000, loss: 0.093462
 >> iter 10000, loss: 0.073156
   Number of active neurons: 6
 >> iter 11000, loss: 0.060021
 >> iter 12000, loss: 0.081279
 >> iter 13000, loss: 0.066900
 >> iter 14000, loss: 0.075089
 >> iter 15000, loss: 0.068707
 >> iter 16000, loss: 0.076422
 >> iter 17000, loss: 0.073646
 >> iter 18000, loss: 0.047540
 >> iter 19000, loss: 0.071374
 >> iter 20000, loss: 0.083420
   Number of active neurons: 6
 >> iter 21000, loss: 0.059003
 >> iter 22000, loss: 0.050983
 >> iter 23000, loss: 0.073395
 >> iter 24000, loss: 0.071197
 >> iter 25000, loss: 0.078319
 >> iter 26000, loss: 0.072933
 >> iter 27000, loss: 0.046515
 >> iter 28000, loss: 0.044995
 >> iter 29000, loss: 0.062011
 >> iter 30000, loss: 0.050534
   Number of active neurons: 6
 >> iter 31000, loss: 0.080215
 >> iter 32000, loss: 0.063586
 >> iter 33000, loss: 0.054680
 >> iter 34000, loss: 0.062272
 >> iter 35000, loss: 0.053639
 >> iter 36000, loss: 0.050027
 >> iter 37000, loss: 0.048573
 >> iter 38000, loss: 0.055750
 >> iter 39000, loss: 0.055740
 >> iter 40000, loss: 0.064555
   Number of active neurons: 5
 >> iter 41000, loss: 0.048352
 >> iter 42000, loss: 0.040737
 >> iter 43000, loss: 0.044511
 >> iter 44000, loss: 0.051361
 >> iter 45000, loss: 0.044768
 >> iter 46000, loss: 0.044521
 >> iter 47000, loss: 0.043095
 >> iter 48000, loss: 0.046052
 >> iter 49000, loss: 0.049864
 >> iter 50000, loss: 0.049924
   Number of active neurons: 5
 >> iter 51000, loss: 0.047589
 >> iter 52000, loss: 0.051817
 >> iter 53000, loss: 0.049528
 >> iter 54000, loss: 0.055075
 >> iter 55000, loss: 0.054149
 >> iter 56000, loss: 0.049591
 >> iter 57000, loss: 0.041024
 >> iter 58000, loss: 0.038535
 >> iter 59000, loss: 0.034704
 >> iter 60000, loss: 0.041951
   Number of active neurons: 5
 >> iter 61000, loss: 0.055776
 >> iter 62000, loss: 0.035573
 >> iter 63000, loss: 0.055139
 >> iter 64000, loss: 0.042448
 >> iter 65000, loss: 0.063513
 >> iter 66000, loss: 0.058159
 >> iter 67000, loss: 0.045277
 >> iter 68000, loss: 0.039686
 >> iter 69000, loss: 0.038352
 >> iter 70000, loss: 0.039228
   Number of active neurons: 5
 >> iter 71000, loss: 0.052253
 >> iter 72000, loss: 0.051943
 >> iter 73000, loss: 0.053386
 >> iter 74000, loss: 0.042982
 >> iter 75000, loss: 0.056121
 >> iter 76000, loss: 0.047899
 >> iter 77000, loss: 0.047390
 >> iter 78000, loss: 0.061392
 >> iter 79000, loss: 0.051522
 >> iter 80000, loss: 0.055625
   Number of active neurons: 5
 >> iter 81000, loss: 0.038242
 >> iter 82000, loss: 0.060483
 >> iter 83000, loss: 0.054518
 >> iter 84000, loss: 0.066384
 >> iter 85000, loss: 0.049742
 >> iter 86000, loss: 0.061750
 >> iter 87000, loss: 0.061947
 >> iter 88000, loss: 0.057942
 >> iter 89000, loss: 0.070426
 >> iter 90000, loss: 0.051395
   Number of active neurons: 4
 >> iter 91000, loss: 0.036366
 >> iter 92000, loss: 0.062393
 >> iter 93000, loss: 0.039369
 >> iter 94000, loss: 0.040742
 >> iter 95000, loss: 0.074989
 >> iter 96000, loss: 0.052503
 >> iter 97000, loss: 0.048320
 >> iter 98000, loss: 0.046792
 >> iter 99000, loss: 0.045666
 >> iter 100000, loss: 0.037327
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.421964
 >> iter 2000, loss: 4.433724
 >> iter 3000, loss: 1.714847
 >> iter 4000, loss: 0.686051
 >> iter 5000, loss: 0.320823
 >> iter 6000, loss: 0.161673
 >> iter 7000, loss: 0.117204
 >> iter 8000, loss: 0.096043
 >> iter 9000, loss: 0.068088
 >> iter 10000, loss: 0.061760
   Number of active neurons: 5
 >> iter 11000, loss: 0.054252
 >> iter 12000, loss: 0.045612
 >> iter 13000, loss: 0.057054
 >> iter 14000, loss: 0.056768
 >> iter 15000, loss: 0.066071
 >> iter 16000, loss: 0.063782
 >> iter 17000, loss: 0.051394
 >> iter 18000, loss: 0.056899
 >> iter 19000, loss: 0.084317
 >> iter 20000, loss: 0.070639
   Number of active neurons: 4
 >> iter 21000, loss: 0.052402
 >> iter 22000, loss: 0.051362
 >> iter 23000, loss: 0.051804
 >> iter 24000, loss: 0.055236
 >> iter 25000, loss: 0.052592
 >> iter 26000, loss: 0.045831
 >> iter 27000, loss: 0.042106
 >> iter 28000, loss: 0.049043
 >> iter 29000, loss: 0.067670
 >> iter 30000, loss: 0.053363
   Number of active neurons: 3
 >> iter 31000, loss: 0.066847
 >> iter 32000, loss: 0.074371
 >> iter 33000, loss: 0.054239
 >> iter 34000, loss: 0.043330
 >> iter 35000, loss: 0.038962
 >> iter 36000, loss: 0.051790
 >> iter 37000, loss: 0.048390
 >> iter 38000, loss: 0.038183
 >> iter 39000, loss: 0.047325
 >> iter 40000, loss: 0.042256
   Number of active neurons: 3
 >> iter 41000, loss: 0.071288
 >> iter 42000, loss: 0.059457
 >> iter 43000, loss: 0.046514
 >> iter 44000, loss: 0.041834
 >> iter 45000, loss: 0.064723
 >> iter 46000, loss: 0.065271
 >> iter 47000, loss: 0.049296
 >> iter 48000, loss: 0.060087
 >> iter 49000, loss: 0.042882
 >> iter 50000, loss: 0.043566
   Number of active neurons: 3
 >> iter 51000, loss: 0.037860
 >> iter 52000, loss: 0.037659
 >> iter 53000, loss: 0.043991
 >> iter 54000, loss: 0.039477
 >> iter 55000, loss: 0.043063
 >> iter 56000, loss: 0.059310
 >> iter 57000, loss: 0.053999
 >> iter 58000, loss: 0.047225
 >> iter 59000, loss: 0.047780
 >> iter 60000, loss: 0.057577
   Number of active neurons: 3
 >> iter 61000, loss: 0.053378
 >> iter 62000, loss: 0.059461
 >> iter 63000, loss: 0.051507
 >> iter 64000, loss: 0.038972
 >> iter 65000, loss: 0.042345
 >> iter 66000, loss: 0.029512
 >> iter 67000, loss: 0.032649
 >> iter 68000, loss: 0.050233
 >> iter 69000, loss: 0.041761
 >> iter 70000, loss: 0.084647
   Number of active neurons: 3
 >> iter 71000, loss: 0.074225
 >> iter 72000, loss: 0.050762
 >> iter 73000, loss: 0.043416
 >> iter 74000, loss: 0.043437
 >> iter 75000, loss: 0.043805
 >> iter 76000, loss: 0.053821
 >> iter 77000, loss: 0.047608
 >> iter 78000, loss: 0.041136
 >> iter 79000, loss: 0.046087
 >> iter 80000, loss: 0.049603
   Number of active neurons: 2
 >> iter 81000, loss: 0.044843
 >> iter 82000, loss: 0.049567
 >> iter 83000, loss: 0.040752
 >> iter 84000, loss: 0.035297
 >> iter 85000, loss: 0.034996
 >> iter 86000, loss: 0.048447
 >> iter 87000, loss: 0.051855
 >> iter 88000, loss: 0.052156
 >> iter 89000, loss: 0.050325
 >> iter 90000, loss: 0.050205
   Number of active neurons: 2
 >> iter 91000, loss: 0.056639
 >> iter 92000, loss: 0.046907
 >> iter 93000, loss: 0.053696
 >> iter 94000, loss: 0.062210
 >> iter 95000, loss: 0.042679
 >> iter 96000, loss: 0.053331
 >> iter 97000, loss: 0.038246
 >> iter 98000, loss: 0.054525
 >> iter 99000, loss: 0.052403
 >> iter 100000, loss: 0.071396
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.377738
 >> iter 2000, loss: 4.415303
 >> iter 3000, loss: 1.710459
 >> iter 4000, loss: 0.696286
 >> iter 5000, loss: 0.301470
 >> iter 6000, loss: 0.160928
 >> iter 7000, loss: 0.102139
 >> iter 8000, loss: 0.087981
 >> iter 9000, loss: 0.078063
 >> iter 10000, loss: 0.056243
   Number of active neurons: 7
 >> iter 11000, loss: 0.060273
 >> iter 12000, loss: 0.053444
 >> iter 13000, loss: 0.075895
 >> iter 14000, loss: 0.060894
 >> iter 15000, loss: 0.068517
 >> iter 16000, loss: 0.051541
 >> iter 17000, loss: 0.051125
 >> iter 18000, loss: 0.046837
 >> iter 19000, loss: 0.052252
 >> iter 20000, loss: 0.046643
   Number of active neurons: 6
 >> iter 21000, loss: 0.037656
 >> iter 22000, loss: 0.037833
 >> iter 23000, loss: 0.099208
 >> iter 24000, loss: 0.071273
 >> iter 25000, loss: 0.051030
 >> iter 26000, loss: 0.037514
 >> iter 27000, loss: 0.043946
 >> iter 28000, loss: 0.043626
 >> iter 29000, loss: 0.041208
 >> iter 30000, loss: 0.047860
   Number of active neurons: 6
 >> iter 31000, loss: 0.046323
 >> iter 32000, loss: 0.054094
 >> iter 33000, loss: 0.054164
 >> iter 34000, loss: 0.044346
 >> iter 35000, loss: 0.043497
 >> iter 36000, loss: 0.056579
 >> iter 37000, loss: 0.056479
 >> iter 38000, loss: 0.052449
 >> iter 39000, loss: 0.059309
 >> iter 40000, loss: 0.057542
   Number of active neurons: 3
 >> iter 41000, loss: 0.044226
 >> iter 42000, loss: 0.062571
 >> iter 43000, loss: 0.052284
 >> iter 44000, loss: 0.048532
 >> iter 45000, loss: 0.071395
 >> iter 46000, loss: 0.047660
 >> iter 47000, loss: 0.052885
 >> iter 48000, loss: 0.040206
 >> iter 49000, loss: 0.041150
 >> iter 50000, loss: 0.043745
   Number of active neurons: 3
 >> iter 51000, loss: 0.037582
 >> iter 52000, loss: 0.035108
 >> iter 53000, loss: 0.063119
 >> iter 54000, loss: 0.051510
 >> iter 55000, loss: 0.044776
 >> iter 56000, loss: 0.050163
 >> iter 57000, loss: 0.036464
 >> iter 58000, loss: 0.038869
 >> iter 59000, loss: 0.045357
 >> iter 60000, loss: 0.064093
   Number of active neurons: 3
 >> iter 61000, loss: 0.045611
 >> iter 62000, loss: 0.040786
 >> iter 63000, loss: 0.047532
 >> iter 64000, loss: 0.057241
 >> iter 65000, loss: 0.065612
 >> iter 66000, loss: 0.040435
 >> iter 67000, loss: 0.056008
 >> iter 68000, loss: 0.055039
 >> iter 69000, loss: 0.052100
 >> iter 70000, loss: 0.049587
   Number of active neurons: 3
 >> iter 71000, loss: 0.059130
 >> iter 72000, loss: 0.059775
 >> iter 73000, loss: 0.040511
 >> iter 74000, loss: 0.049510
 >> iter 75000, loss: 0.046786
 >> iter 76000, loss: 0.072520
 >> iter 77000, loss: 0.049867
 >> iter 78000, loss: 0.055095
 >> iter 79000, loss: 0.053309
 >> iter 80000, loss: 0.040790
   Number of active neurons: 3
 >> iter 81000, loss: 0.058423
 >> iter 82000, loss: 0.056589
 >> iter 83000, loss: 0.057000
 >> iter 84000, loss: 0.038518
 >> iter 85000, loss: 0.049664
 >> iter 86000, loss: 0.062851
 >> iter 87000, loss: 0.063095
 >> iter 88000, loss: 0.044670
 >> iter 89000, loss: 0.032695
 >> iter 90000, loss: 0.035707
   Number of active neurons: 3
 >> iter 91000, loss: 0.051434
 >> iter 92000, loss: 0.043867
 >> iter 93000, loss: 0.040791
 >> iter 94000, loss: 0.043294
 >> iter 95000, loss: 0.042407
 >> iter 96000, loss: 0.038485
 >> iter 97000, loss: 0.057471
 >> iter 98000, loss: 0.046270
 >> iter 99000, loss: 0.037871
 >> iter 100000, loss: 0.047772
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.333970
 >> iter 2000, loss: 4.368118
 >> iter 3000, loss: 1.700143
 >> iter 4000, loss: 0.675936
 >> iter 5000, loss: 0.284378
 >> iter 6000, loss: 0.151503
 >> iter 7000, loss: 0.093021
 >> iter 8000, loss: 0.071806
 >> iter 9000, loss: 0.064223
 >> iter 10000, loss: 0.073696
   Number of active neurons: 6
 >> iter 11000, loss: 0.065208
 >> iter 12000, loss: 0.074175
 >> iter 13000, loss: 0.060326
 >> iter 14000, loss: 0.063189
 >> iter 15000, loss: 0.058448
 >> iter 16000, loss: 0.048745
 >> iter 17000, loss: 0.058597
 >> iter 18000, loss: 0.059055
 >> iter 19000, loss: 0.077898
 >> iter 20000, loss: 0.052009
   Number of active neurons: 6
 >> iter 21000, loss: 0.061163
 >> iter 22000, loss: 0.054044
 >> iter 23000, loss: 0.059301
 >> iter 24000, loss: 0.071320
 >> iter 25000, loss: 0.077642
 >> iter 26000, loss: 0.057478
 >> iter 27000, loss: 0.082385
 >> iter 28000, loss: 0.075250
 >> iter 29000, loss: 0.070324
 >> iter 30000, loss: 0.066868
   Number of active neurons: 5
 >> iter 31000, loss: 0.062230
 >> iter 32000, loss: 0.059605
 >> iter 33000, loss: 0.047202
 >> iter 34000, loss: 0.046387
 >> iter 35000, loss: 0.047117
 >> iter 36000, loss: 0.045062
 >> iter 37000, loss: 0.036678
 >> iter 38000, loss: 0.037363
 >> iter 39000, loss: 0.058769
 >> iter 40000, loss: 0.049232
   Number of active neurons: 5
 >> iter 41000, loss: 0.056649
 >> iter 42000, loss: 0.039243
 >> iter 43000, loss: 0.042713
 >> iter 44000, loss: 0.053626
 >> iter 45000, loss: 0.048162
 >> iter 46000, loss: 0.051822
 >> iter 47000, loss: 0.051750
 >> iter 48000, loss: 0.059927
 >> iter 49000, loss: 0.043187
 >> iter 50000, loss: 0.043821
   Number of active neurons: 5
 >> iter 51000, loss: 0.052976
 >> iter 52000, loss: 0.043377
 >> iter 53000, loss: 0.042261
 >> iter 54000, loss: 0.053108
 >> iter 55000, loss: 0.049250
 >> iter 56000, loss: 0.058703
 >> iter 57000, loss: 0.058619
 >> iter 58000, loss: 0.048253
 >> iter 59000, loss: 0.062056
 >> iter 60000, loss: 0.044547
   Number of active neurons: 3
 >> iter 61000, loss: 0.062879
 >> iter 62000, loss: 0.045781
 >> iter 63000, loss: 0.047952
 >> iter 64000, loss: 0.069793
 >> iter 65000, loss: 0.064669
 >> iter 66000, loss: 0.059058
 >> iter 67000, loss: 0.061551
 >> iter 68000, loss: 0.045246
 >> iter 69000, loss: 0.035346
 >> iter 70000, loss: 0.041074
   Number of active neurons: 3
 >> iter 71000, loss: 0.055368
 >> iter 72000, loss: 0.051768
 >> iter 73000, loss: 0.044680
 >> iter 74000, loss: 0.047768
 >> iter 75000, loss: 0.061756
 >> iter 76000, loss: 0.040820
 >> iter 77000, loss: 0.040900
 >> iter 78000, loss: 0.032941
 >> iter 79000, loss: 0.037608
 >> iter 80000, loss: 0.044368
   Number of active neurons: 3
 >> iter 81000, loss: 0.052825
 >> iter 82000, loss: 0.040129
 >> iter 83000, loss: 0.043099
 >> iter 84000, loss: 0.037182
 >> iter 85000, loss: 0.084794
 >> iter 86000, loss: 0.070802
 >> iter 87000, loss: 0.059306
 >> iter 88000, loss: 0.055066
 >> iter 89000, loss: 0.054395
 >> iter 90000, loss: 0.073005
   Number of active neurons: 3
 >> iter 91000, loss: 0.056630
 >> iter 92000, loss: 0.045208
 >> iter 93000, loss: 0.052736
 >> iter 94000, loss: 0.049098
 >> iter 95000, loss: 0.038142
 >> iter 96000, loss: 0.043233
 >> iter 97000, loss: 0.046970
 >> iter 98000, loss: 0.042205
 >> iter 99000, loss: 0.032105
 >> iter 100000, loss: 0.042037
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.357552
 >> iter 2000, loss: 4.414886
 >> iter 3000, loss: 1.698007
 >> iter 4000, loss: 0.684636
 >> iter 5000, loss: 0.315907
 >> iter 6000, loss: 0.198955
 >> iter 7000, loss: 0.118095
 >> iter 8000, loss: 0.083097
 >> iter 9000, loss: 0.060625
 >> iter 10000, loss: 0.055244
   Number of active neurons: 6
 >> iter 11000, loss: 0.060967
 >> iter 12000, loss: 0.064788
 >> iter 13000, loss: 0.099642
 >> iter 14000, loss: 0.080488
 >> iter 15000, loss: 0.060754
 >> iter 16000, loss: 0.073228
 >> iter 17000, loss: 0.086693
 >> iter 18000, loss: 0.080063
 >> iter 19000, loss: 0.069975
 >> iter 20000, loss: 0.069280
   Number of active neurons: 6
 >> iter 21000, loss: 0.074944
 >> iter 22000, loss: 0.093180
 >> iter 23000, loss: 0.086702
 >> iter 24000, loss: 0.063323
 >> iter 25000, loss: 0.069332
 >> iter 26000, loss: 0.077775
 >> iter 27000, loss: 0.054072
 >> iter 28000, loss: 0.060647
 >> iter 29000, loss: 0.080740
 >> iter 30000, loss: 0.052171
   Number of active neurons: 6
 >> iter 31000, loss: 0.058140
 >> iter 32000, loss: 0.057420
 >> iter 33000, loss: 0.071680
 >> iter 34000, loss: 0.068694
 >> iter 35000, loss: 0.056347
 >> iter 36000, loss: 0.065611
 >> iter 37000, loss: 0.056818
 >> iter 38000, loss: 0.050154
 >> iter 39000, loss: 0.063623
 >> iter 40000, loss: 0.056271
   Number of active neurons: 6
 >> iter 41000, loss: 0.056296
 >> iter 42000, loss: 0.047396
 >> iter 43000, loss: 0.053578
 >> iter 44000, loss: 0.073160
 >> iter 45000, loss: 0.065580
 >> iter 46000, loss: 0.043766
 >> iter 47000, loss: 0.045983
 >> iter 48000, loss: 0.043694
 >> iter 49000, loss: 0.051268
 >> iter 50000, loss: 0.043574
   Number of active neurons: 5
 >> iter 51000, loss: 0.064825
 >> iter 52000, loss: 0.051441
 >> iter 53000, loss: 0.064862
 >> iter 54000, loss: 0.070723
 >> iter 55000, loss: 0.055509
 >> iter 56000, loss: 0.042441
 >> iter 57000, loss: 0.078026
 >> iter 58000, loss: 0.056616
 >> iter 59000, loss: 0.039770
 >> iter 60000, loss: 0.035782
   Number of active neurons: 4
 >> iter 61000, loss: 0.034609
 >> iter 62000, loss: 0.043635
 >> iter 63000, loss: 0.060242
 >> iter 64000, loss: 0.067857
 >> iter 65000, loss: 0.067699
 >> iter 66000, loss: 0.043226
 >> iter 67000, loss: 0.046608
 >> iter 68000, loss: 0.039763
 >> iter 69000, loss: 0.037362
 >> iter 70000, loss: 0.053717
   Number of active neurons: 3
 >> iter 71000, loss: 0.048657
 >> iter 72000, loss: 0.039234
 >> iter 73000, loss: 0.044325
 >> iter 74000, loss: 0.048332
 >> iter 75000, loss: 0.046792
 >> iter 76000, loss: 0.042495
 >> iter 77000, loss: 0.048871
 >> iter 78000, loss: 0.049662
 >> iter 79000, loss: 0.058273
 >> iter 80000, loss: 0.064161
   Number of active neurons: 3
 >> iter 81000, loss: 0.054191
 >> iter 82000, loss: 0.042581
 >> iter 83000, loss: 0.049383
 >> iter 84000, loss: 0.043482
 >> iter 85000, loss: 0.045994
 >> iter 86000, loss: 0.038183
 >> iter 87000, loss: 0.036692
 >> iter 88000, loss: 0.053730
 >> iter 89000, loss: 0.059465
 >> iter 90000, loss: 0.077140
   Number of active neurons: 3
 >> iter 91000, loss: 0.046118
 >> iter 92000, loss: 0.039491
 >> iter 93000, loss: 0.041067
 >> iter 94000, loss: 0.053141
 >> iter 95000, loss: 0.047836
 >> iter 96000, loss: 0.037526
 >> iter 97000, loss: 0.055731
 >> iter 98000, loss: 0.050126
 >> iter 99000, loss: 0.046311
 >> iter 100000, loss: 0.059514
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.399702
 >> iter 2000, loss: 4.417358
 >> iter 3000, loss: 1.743098
 >> iter 4000, loss: 0.691872
 >> iter 5000, loss: 0.316831
 >> iter 6000, loss: 0.177330
 >> iter 7000, loss: 0.127466
 >> iter 8000, loss: 0.100243
 >> iter 9000, loss: 0.066733
 >> iter 10000, loss: 0.062613
   Number of active neurons: 7
 >> iter 11000, loss: 0.065783
 >> iter 12000, loss: 0.057585
 >> iter 13000, loss: 0.060364
 >> iter 14000, loss: 0.080190
 >> iter 15000, loss: 0.067562
 >> iter 16000, loss: 0.064202
 >> iter 17000, loss: 0.090969
 >> iter 18000, loss: 0.062184
 >> iter 19000, loss: 0.062931
 >> iter 20000, loss: 0.059605
   Number of active neurons: 6
 >> iter 21000, loss: 0.064896
 >> iter 22000, loss: 0.053295
 >> iter 23000, loss: 0.081084
 >> iter 24000, loss: 0.055137
 >> iter 25000, loss: 0.054996
 >> iter 26000, loss: 0.060329
 >> iter 27000, loss: 0.049876
 >> iter 28000, loss: 0.043111
 >> iter 29000, loss: 0.049321
 >> iter 30000, loss: 0.072709
   Number of active neurons: 6
 >> iter 31000, loss: 0.061058
 >> iter 32000, loss: 0.081377
 >> iter 33000, loss: 0.053565
 >> iter 34000, loss: 0.047114
 >> iter 35000, loss: 0.060941
 >> iter 36000, loss: 0.079427
 >> iter 37000, loss: 0.060282
 >> iter 38000, loss: 0.050798
 >> iter 39000, loss: 0.049588
 >> iter 40000, loss: 0.062479
   Number of active neurons: 6
 >> iter 41000, loss: 0.045255
 >> iter 42000, loss: 0.055394
 >> iter 43000, loss: 0.052318
 >> iter 44000, loss: 0.052806
 >> iter 45000, loss: 0.055538
 >> iter 46000, loss: 0.051774
 >> iter 47000, loss: 0.045282
 >> iter 48000, loss: 0.045767
 >> iter 49000, loss: 0.047226
 >> iter 50000, loss: 0.049248
   Number of active neurons: 6
 >> iter 51000, loss: 0.045291
 >> iter 52000, loss: 0.048949
 >> iter 53000, loss: 0.056051
 >> iter 54000, loss: 0.052523
 >> iter 55000, loss: 0.051060
 >> iter 56000, loss: 0.060598
 >> iter 57000, loss: 0.054251
 >> iter 58000, loss: 0.053274
 >> iter 59000, loss: 0.054584
 >> iter 60000, loss: 0.066608
   Number of active neurons: 4
 >> iter 61000, loss: 0.054574
 >> iter 62000, loss: 0.046093
 >> iter 63000, loss: 0.039317
 >> iter 64000, loss: 0.049850
 >> iter 65000, loss: 0.056040
 >> iter 66000, loss: 0.046494
 >> iter 67000, loss: 0.071285
 >> iter 68000, loss: 0.046585
 >> iter 69000, loss: 0.038434
 >> iter 70000, loss: 0.071725
   Number of active neurons: 4
 >> iter 71000, loss: 0.056853
 >> iter 72000, loss: 0.047592
 >> iter 73000, loss: 0.061046
 >> iter 74000, loss: 0.049091
 >> iter 75000, loss: 0.040435
 >> iter 76000, loss: 0.051180
 >> iter 77000, loss: 0.047084
 >> iter 78000, loss: 0.042744
 >> iter 79000, loss: 0.045468
 >> iter 80000, loss: 0.044476
   Number of active neurons: 4
 >> iter 81000, loss: 0.047808
 >> iter 82000, loss: 0.049011
 >> iter 83000, loss: 0.051109
 >> iter 84000, loss: 0.051401
 >> iter 85000, loss: 0.045558
 >> iter 86000, loss: 0.045822
 >> iter 87000, loss: 0.048089
 >> iter 88000, loss: 0.049199
 >> iter 89000, loss: 0.038497
 >> iter 90000, loss: 0.032418
   Number of active neurons: 4
 >> iter 91000, loss: 0.037155
 >> iter 92000, loss: 0.030734
 >> iter 93000, loss: 0.030076
 >> iter 94000, loss: 0.033418
 >> iter 95000, loss: 0.039836
 >> iter 96000, loss: 0.061719
 >> iter 97000, loss: 0.058888
 >> iter 98000, loss: 0.050148
 >> iter 99000, loss: 0.045602
 >> iter 100000, loss: 0.038058
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.355595
 >> iter 2000, loss: 4.407081
 >> iter 3000, loss: 1.699977
 >> iter 4000, loss: 0.683346
 >> iter 5000, loss: 0.300645
 >> iter 6000, loss: 0.170384
 >> iter 7000, loss: 0.131439
 >> iter 8000, loss: 0.084160
 >> iter 9000, loss: 0.069993
 >> iter 10000, loss: 0.058548
   Number of active neurons: 6
 >> iter 11000, loss: 0.047944
 >> iter 12000, loss: 0.044816
 >> iter 13000, loss: 0.056195
 >> iter 14000, loss: 0.073951
 >> iter 15000, loss: 0.067713
 >> iter 16000, loss: 0.050815
 >> iter 17000, loss: 0.048487
 >> iter 18000, loss: 0.061882
 >> iter 19000, loss: 0.062719
 >> iter 20000, loss: 0.049460
   Number of active neurons: 6
 >> iter 21000, loss: 0.057054
 >> iter 22000, loss: 0.056432
 >> iter 23000, loss: 0.054637
 >> iter 24000, loss: 0.069889
 >> iter 25000, loss: 0.052587
 >> iter 26000, loss: 0.053631
 >> iter 27000, loss: 0.054337
 >> iter 28000, loss: 0.059058
 >> iter 29000, loss: 0.079303
 >> iter 30000, loss: 0.078259
   Number of active neurons: 6
 >> iter 31000, loss: 0.054085
 >> iter 32000, loss: 0.039226
 >> iter 33000, loss: 0.062761
 >> iter 34000, loss: 0.064206
 >> iter 35000, loss: 0.063882
 >> iter 36000, loss: 0.062061
 >> iter 37000, loss: 0.074426
 >> iter 38000, loss: 0.070339
 >> iter 39000, loss: 0.068514
 >> iter 40000, loss: 0.075827
   Number of active neurons: 5
 >> iter 41000, loss: 0.054228
 >> iter 42000, loss: 0.041700
 >> iter 43000, loss: 0.048910
 >> iter 44000, loss: 0.049781
 >> iter 45000, loss: 0.049608
 >> iter 46000, loss: 0.050361
 >> iter 47000, loss: 0.058986
 >> iter 48000, loss: 0.049828
 >> iter 49000, loss: 0.046926
 >> iter 50000, loss: 0.035791
   Number of active neurons: 4
 >> iter 51000, loss: 0.078622
 >> iter 52000, loss: 0.072165
 >> iter 53000, loss: 0.064850
 >> iter 54000, loss: 0.051535
 >> iter 55000, loss: 0.056095
 >> iter 56000, loss: 0.047918
 >> iter 57000, loss: 0.049465
 >> iter 58000, loss: 0.050060
 >> iter 59000, loss: 0.044582
 >> iter 60000, loss: 0.060293
   Number of active neurons: 4
 >> iter 61000, loss: 0.057456
 >> iter 62000, loss: 0.070958
 >> iter 63000, loss: 0.055935
 >> iter 64000, loss: 0.047472
 >> iter 65000, loss: 0.047507
 >> iter 66000, loss: 0.050256
 >> iter 67000, loss: 0.037601
 >> iter 68000, loss: 0.050923
 >> iter 69000, loss: 0.042341
 >> iter 70000, loss: 0.041694
   Number of active neurons: 3
 >> iter 71000, loss: 0.055316
 >> iter 72000, loss: 0.043599
 >> iter 73000, loss: 0.040025
 >> iter 74000, loss: 0.047037
 >> iter 75000, loss: 0.035635
 >> iter 76000, loss: 0.047351
 >> iter 77000, loss: 0.042185
 >> iter 78000, loss: 0.037064
 >> iter 79000, loss: 0.055145
 >> iter 80000, loss: 0.063276
   Number of active neurons: 2
 >> iter 81000, loss: 0.052376
 >> iter 82000, loss: 0.044844
 >> iter 83000, loss: 0.051738
 >> iter 84000, loss: 0.062384
 >> iter 85000, loss: 0.051050
 >> iter 86000, loss: 0.038117
 >> iter 87000, loss: 0.033441
 >> iter 88000, loss: 0.037854
 >> iter 89000, loss: 0.050460
 >> iter 90000, loss: 0.051116
   Number of active neurons: 2
 >> iter 91000, loss: 0.042837
 >> iter 92000, loss: 0.039857
 >> iter 93000, loss: 0.041202
 >> iter 94000, loss: 0.032275
 >> iter 95000, loss: 0.065674
 >> iter 96000, loss: 0.059772
 >> iter 97000, loss: 0.055142
 >> iter 98000, loss: 0.037171
 >> iter 99000, loss: 0.044643
 >> iter 100000, loss: 0.043014
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.410576
 >> iter 2000, loss: 4.454142
 >> iter 3000, loss: 1.781567
 >> iter 4000, loss: 0.757154
 >> iter 5000, loss: 0.376489
 >> iter 6000, loss: 0.172646
 >> iter 7000, loss: 0.108315
 >> iter 8000, loss: 0.079388
 >> iter 9000, loss: 0.069517
 >> iter 10000, loss: 0.063284
   Number of active neurons: 7
 >> iter 11000, loss: 0.056460
 >> iter 12000, loss: 0.052108
 >> iter 13000, loss: 0.059333
 >> iter 14000, loss: 0.052118
 >> iter 15000, loss: 0.075157
 >> iter 16000, loss: 0.055817
 >> iter 17000, loss: 0.053033
 >> iter 18000, loss: 0.045948
 >> iter 19000, loss: 0.089201
 >> iter 20000, loss: 0.084334
   Number of active neurons: 6
 >> iter 21000, loss: 0.069102
 >> iter 22000, loss: 0.062768
 >> iter 23000, loss: 0.054555
 >> iter 24000, loss: 0.044151
 >> iter 25000, loss: 0.040345
 >> iter 26000, loss: 0.048847
 >> iter 27000, loss: 0.048640
 >> iter 28000, loss: 0.058681
 >> iter 29000, loss: 0.055851
 >> iter 30000, loss: 0.057543
   Number of active neurons: 5
 >> iter 31000, loss: 0.050465
 >> iter 32000, loss: 0.048627
 >> iter 33000, loss: 0.053372
 >> iter 34000, loss: 0.059527
 >> iter 35000, loss: 0.062230
 >> iter 36000, loss: 0.069718
 >> iter 37000, loss: 0.047532
 >> iter 38000, loss: 0.059602
 >> iter 39000, loss: 0.054750
 >> iter 40000, loss: 0.050415
   Number of active neurons: 4
 >> iter 41000, loss: 0.039326
 >> iter 42000, loss: 0.044228
 >> iter 43000, loss: 0.041537
 >> iter 44000, loss: 0.052054
 >> iter 45000, loss: 0.065993
 >> iter 46000, loss: 0.061687
 >> iter 47000, loss: 0.072531
 >> iter 48000, loss: 0.060490
 >> iter 49000, loss: 0.060518
 >> iter 50000, loss: 0.043782
   Number of active neurons: 3
 >> iter 51000, loss: 0.044083
 >> iter 52000, loss: 0.035270
 >> iter 53000, loss: 0.038117
 >> iter 54000, loss: 0.040140
 >> iter 55000, loss: 0.058046
 >> iter 56000, loss: 0.045652
 >> iter 57000, loss: 0.056993
 >> iter 58000, loss: 0.062183
 >> iter 59000, loss: 0.057457
 >> iter 60000, loss: 0.044223
   Number of active neurons: 2
 >> iter 61000, loss: 0.047156
 >> iter 62000, loss: 0.046543
 >> iter 63000, loss: 0.045279
 >> iter 64000, loss: 0.067902
 >> iter 65000, loss: 0.070800
 >> iter 66000, loss: 0.046337
 >> iter 67000, loss: 0.043839
 >> iter 68000, loss: 0.042496
 >> iter 69000, loss: 0.061574
 >> iter 70000, loss: 0.055543
   Number of active neurons: 2
 >> iter 71000, loss: 0.058374
 >> iter 72000, loss: 0.039774
 >> iter 73000, loss: 0.041911
 >> iter 74000, loss: 0.045077
 >> iter 75000, loss: 0.032172
 >> iter 76000, loss: 0.042152
 >> iter 77000, loss: 0.052993
 >> iter 78000, loss: 0.037333
 >> iter 79000, loss: 0.054528
 >> iter 80000, loss: 0.043677
   Number of active neurons: 2
 >> iter 81000, loss: 0.044903
 >> iter 82000, loss: 0.057407
 >> iter 83000, loss: 0.048369
 >> iter 84000, loss: 0.033287
 >> iter 85000, loss: 0.037320
 >> iter 86000, loss: 0.039207
 >> iter 87000, loss: 0.040042
 >> iter 88000, loss: 0.048699
 >> iter 89000, loss: 0.035877
 >> iter 90000, loss: 0.041238
   Number of active neurons: 2
 >> iter 91000, loss: 0.050064
 >> iter 92000, loss: 0.036819
 >> iter 93000, loss: 0.039135
 >> iter 94000, loss: 0.056338
 >> iter 95000, loss: 0.047344
 >> iter 96000, loss: 0.039592
 >> iter 97000, loss: 0.049607
 >> iter 98000, loss: 0.044956
 >> iter 99000, loss: 0.045524
 >> iter 100000, loss: 0.037621
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.315731
 >> iter 2000, loss: 4.356505
 >> iter 3000, loss: 1.688254
 >> iter 4000, loss: 0.676478
 >> iter 5000, loss: 0.309003
 >> iter 6000, loss: 0.164444
 >> iter 7000, loss: 0.104689
 >> iter 8000, loss: 0.080502
 >> iter 9000, loss: 0.088891
 >> iter 10000, loss: 0.085979
   Number of active neurons: 6
 >> iter 11000, loss: 0.069030
 >> iter 12000, loss: 0.049324
 >> iter 13000, loss: 0.064021
 >> iter 14000, loss: 0.047931
 >> iter 15000, loss: 0.039440
 >> iter 16000, loss: 0.053466
 >> iter 17000, loss: 0.060911
 >> iter 18000, loss: 0.067864
 >> iter 19000, loss: 0.057263
 >> iter 20000, loss: 0.063163
   Number of active neurons: 6
 >> iter 21000, loss: 0.045207
 >> iter 22000, loss: 0.045707
 >> iter 23000, loss: 0.049163
 >> iter 24000, loss: 0.062228
 >> iter 25000, loss: 0.060099
 >> iter 26000, loss: 0.054539
 >> iter 27000, loss: 0.052854
 >> iter 28000, loss: 0.043768
 >> iter 29000, loss: 0.041341
 >> iter 30000, loss: 0.049130
   Number of active neurons: 5
 >> iter 31000, loss: 0.041871
 >> iter 32000, loss: 0.070610
 >> iter 33000, loss: 0.061708
 >> iter 34000, loss: 0.046088
 >> iter 35000, loss: 0.055342
 >> iter 36000, loss: 0.053637
 >> iter 37000, loss: 0.052295
 >> iter 38000, loss: 0.039486
 >> iter 39000, loss: 0.052409
 >> iter 40000, loss: 0.044474
   Number of active neurons: 4
 >> iter 41000, loss: 0.050134
 >> iter 42000, loss: 0.062664
 >> iter 43000, loss: 0.054876
 >> iter 44000, loss: 0.049755
 >> iter 45000, loss: 0.071097
 >> iter 46000, loss: 0.052715
 >> iter 47000, loss: 0.075593
 >> iter 48000, loss: 0.061543
 >> iter 49000, loss: 0.048144
 >> iter 50000, loss: 0.052308
   Number of active neurons: 4
 >> iter 51000, loss: 0.045395
 >> iter 52000, loss: 0.053910
 >> iter 53000, loss: 0.043327
 >> iter 54000, loss: 0.044494
 >> iter 55000, loss: 0.051506
 >> iter 56000, loss: 0.053273
 >> iter 57000, loss: 0.062281
 >> iter 58000, loss: 0.046724
 >> iter 59000, loss: 0.048279
 >> iter 60000, loss: 0.038163
   Number of active neurons: 4
 >> iter 61000, loss: 0.067404
 >> iter 62000, loss: 0.066404
 >> iter 63000, loss: 0.061611
 >> iter 64000, loss: 0.043089
 >> iter 65000, loss: 0.055189
 >> iter 66000, loss: 0.054408
 >> iter 67000, loss: 0.064694
 >> iter 68000, loss: 0.061021
 >> iter 69000, loss: 0.050620
 >> iter 70000, loss: 0.047468
   Number of active neurons: 4
 >> iter 71000, loss: 0.059271
 >> iter 72000, loss: 0.059431
 >> iter 73000, loss: 0.050039
 >> iter 74000, loss: 0.052022
 >> iter 75000, loss: 0.048516
 >> iter 76000, loss: 0.043671
 >> iter 77000, loss: 0.042290
 >> iter 78000, loss: 0.038998
 >> iter 79000, loss: 0.056060
 >> iter 80000, loss: 0.048027
   Number of active neurons: 3
 >> iter 81000, loss: 0.073151
 >> iter 82000, loss: 0.048795
 >> iter 83000, loss: 0.040842
 >> iter 84000, loss: 0.060376
 >> iter 85000, loss: 0.059780
 >> iter 86000, loss: 0.055360
 >> iter 87000, loss: 0.045317
 >> iter 88000, loss: 0.060245
 >> iter 89000, loss: 0.067263
 >> iter 90000, loss: 0.050397
   Number of active neurons: 3
 >> iter 91000, loss: 0.046985
 >> iter 92000, loss: 0.050426
 >> iter 93000, loss: 0.046549
 >> iter 94000, loss: 0.062033
 >> iter 95000, loss: 0.050966
 >> iter 96000, loss: 0.042063
 >> iter 97000, loss: 0.032740
 >> iter 98000, loss: 0.029444
 >> iter 99000, loss: 0.040841
 >> iter 100000, loss: 0.043319
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 11.428403
 >> iter 2000, loss: 4.491797
 >> iter 3000, loss: 1.752795
 >> iter 4000, loss: 0.730149
 >> iter 5000, loss: 0.325196
 >> iter 6000, loss: 0.162678
 >> iter 7000, loss: 0.092042
 >> iter 8000, loss: 0.075038
 >> iter 9000, loss: 0.076594
 >> iter 10000, loss: 0.083567
   Number of active neurons: 5
 >> iter 11000, loss: 0.067643
 >> iter 12000, loss: 0.058301
 >> iter 13000, loss: 0.059829
 >> iter 14000, loss: 0.057007
 >> iter 15000, loss: 0.055612
 >> iter 16000, loss: 0.049214
 >> iter 17000, loss: 0.044154
 >> iter 18000, loss: 0.047038
 >> iter 19000, loss: 0.063508
 >> iter 20000, loss: 0.054784
   Number of active neurons: 4
 >> iter 21000, loss: 0.052468
 >> iter 22000, loss: 0.045012
 >> iter 23000, loss: 0.054209
 >> iter 24000, loss: 0.072722
 >> iter 25000, loss: 0.060884
 >> iter 26000, loss: 0.065570
 >> iter 27000, loss: 0.045584
 >> iter 28000, loss: 0.042470
 >> iter 29000, loss: 0.047401
 >> iter 30000, loss: 0.040696
   Number of active neurons: 3
 >> iter 31000, loss: 0.039926
 >> iter 32000, loss: 0.047934
 >> iter 33000, loss: 0.041321
 >> iter 34000, loss: 0.040650
 >> iter 35000, loss: 0.052140
 >> iter 36000, loss: 0.066165
 >> iter 37000, loss: 0.049390
 >> iter 38000, loss: 0.067682
 >> iter 39000, loss: 0.045450
 >> iter 40000, loss: 0.037400
   Number of active neurons: 3
 >> iter 41000, loss: 0.047304
 >> iter 42000, loss: 0.049726
 >> iter 43000, loss: 0.052878
 >> iter 44000, loss: 0.052301
 >> iter 45000, loss: 0.041561
 >> iter 46000, loss: 0.048360
 >> iter 47000, loss: 0.048266
 >> iter 48000, loss: 0.036886
 >> iter 49000, loss: 0.029206
 >> iter 50000, loss: 0.039408
   Number of active neurons: 3
 >> iter 51000, loss: 0.049050
 >> iter 52000, loss: 0.047750
 >> iter 53000, loss: 0.059489
 >> iter 54000, loss: 0.045057
 >> iter 55000, loss: 0.042920
 >> iter 56000, loss: 0.054577
 >> iter 57000, loss: 0.053194
 >> iter 58000, loss: 0.053855
 >> iter 59000, loss: 0.045342
 >> iter 60000, loss: 0.062476
   Number of active neurons: 3
 >> iter 61000, loss: 0.058180
 >> iter 62000, loss: 0.043854
 >> iter 63000, loss: 0.051289
 >> iter 64000, loss: 0.041556
 >> iter 65000, loss: 0.053678
 >> iter 66000, loss: 0.050203
 >> iter 67000, loss: 0.048312
 >> iter 68000, loss: 0.039697
 >> iter 69000, loss: 0.037291
 >> iter 70000, loss: 0.039889
   Number of active neurons: 3
 >> iter 71000, loss: 0.035839
 >> iter 72000, loss: 0.047975
 >> iter 73000, loss: 0.046289
 >> iter 74000, loss: 0.055753
 >> iter 75000, loss: 0.056130
 >> iter 76000, loss: 0.049338
 >> iter 77000, loss: 0.061553
 >> iter 78000, loss: 0.060031
 >> iter 79000, loss: 0.048307
 >> iter 80000, loss: 0.052020
   Number of active neurons: 3
 >> iter 81000, loss: 0.048180
 >> iter 82000, loss: 0.038250
 >> iter 83000, loss: 0.037056
 >> iter 84000, loss: 0.044287
 >> iter 85000, loss: 0.054694
 >> iter 86000, loss: 0.051086
 >> iter 87000, loss: 0.042101
 >> iter 88000, loss: 0.047636
 >> iter 89000, loss: 0.034660
 >> iter 90000, loss: 0.062681
   Number of active neurons: 3
 >> iter 91000, loss: 0.058596
 >> iter 92000, loss: 0.057442
 >> iter 93000, loss: 0.055187
 >> iter 94000, loss: 0.046838
 >> iter 95000, loss: 0.037727
 >> iter 96000, loss: 0.032623
 >> iter 97000, loss: 0.045016
 >> iter 98000, loss: 0.050780
 >> iter 99000, loss: 0.042590
 >> iter 100000, loss: 0.049591
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

