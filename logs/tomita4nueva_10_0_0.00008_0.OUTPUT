 > Problema: tomita4nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 8e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.602723
 >> iter 2000, loss: 6.646181
 >> iter 3000, loss: 2.539754
 >> iter 4000, loss: 0.962332
 >> iter 5000, loss: 0.390476
 >> iter 6000, loss: 0.160753
 >> iter 7000, loss: 0.095210
 >> iter 8000, loss: 0.093754
 >> iter 9000, loss: 0.058492
 >> iter 10000, loss: 0.041343
   Number of active neurons: 3
 >> iter 11000, loss: 0.027928
 >> iter 12000, loss: 0.108895
 >> iter 13000, loss: 0.157747
 >> iter 14000, loss: 0.229160
 >> iter 15000, loss: 0.100396
 >> iter 16000, loss: 0.138982
 >> iter 17000, loss: 0.229807
 >> iter 18000, loss: 0.101096
 >> iter 19000, loss: 0.056355
 >> iter 20000, loss: 0.260927
   Number of active neurons: 3
 >> iter 21000, loss: 0.155830
 >> iter 22000, loss: 0.154730
 >> iter 23000, loss: 0.116705
 >> iter 24000, loss: 0.136050
 >> iter 25000, loss: 0.112182
 >> iter 26000, loss: 0.058990
 >> iter 27000, loss: 0.071647
 >> iter 28000, loss: 0.127292
 >> iter 29000, loss: 0.113635
 >> iter 30000, loss: 0.175794
   Number of active neurons: 3
 >> iter 31000, loss: 0.114139
 >> iter 32000, loss: 0.115849
 >> iter 33000, loss: 0.091413
 >> iter 34000, loss: 0.114735
 >> iter 35000, loss: 0.071534
 >> iter 36000, loss: 0.108728
 >> iter 37000, loss: 0.106537
 >> iter 38000, loss: 0.054925
 >> iter 39000, loss: 0.156996
 >> iter 40000, loss: 0.142699
   Number of active neurons: 3
 >> iter 41000, loss: 0.119106
 >> iter 42000, loss: 0.123793
 >> iter 43000, loss: 0.072666
 >> iter 44000, loss: 0.045523
 >> iter 45000, loss: 0.072239
 >> iter 46000, loss: 0.044601
 >> iter 47000, loss: 0.148525
 >> iter 48000, loss: 0.079578
 >> iter 49000, loss: 0.080578
 >> iter 50000, loss: 0.054111
   Number of active neurons: 3
 >> iter 51000, loss: 0.090949
 >> iter 52000, loss: 0.119697
 >> iter 53000, loss: 0.209463
 >> iter 54000, loss: 0.165378
 >> iter 55000, loss: 0.179179
 >> iter 56000, loss: 0.096162
 >> iter 57000, loss: 0.243154
 >> iter 58000, loss: 0.171674
 >> iter 59000, loss: 0.321638
 >> iter 60000, loss: 0.201621
   Number of active neurons: 3
 >> iter 61000, loss: 0.144329
 >> iter 62000, loss: 0.221981
 >> iter 63000, loss: 0.279882
 >> iter 64000, loss: 0.178046
 >> iter 65000, loss: 0.215270
 >> iter 66000, loss: 0.243148
 >> iter 67000, loss: 0.147026
 >> iter 68000, loss: 0.220185
 >> iter 69000, loss: 0.302256
 >> iter 70000, loss: 0.238822
   Number of active neurons: 3
 >> iter 71000, loss: 0.223329
 >> iter 72000, loss: 0.160747
 >> iter 73000, loss: 0.074204
 >> iter 74000, loss: 0.046368
 >> iter 75000, loss: 0.029546
 >> iter 76000, loss: 0.348068
 >> iter 77000, loss: 0.172625
 >> iter 78000, loss: 0.565290
 >> iter 79000, loss: 0.227217
 >> iter 80000, loss: 0.204200
   Number of active neurons: 3
 >> iter 81000, loss: 0.248321
 >> iter 82000, loss: 0.208077
 >> iter 83000, loss: 0.091094
 >> iter 84000, loss: 0.330795
 >> iter 85000, loss: 0.140856
 >> iter 86000, loss: 0.129287
 >> iter 87000, loss: 0.061860
 >> iter 88000, loss: 0.157672
 >> iter 89000, loss: 0.203083
 >> iter 90000, loss: 0.199219
   Number of active neurons: 3
 >> iter 91000, loss: 0.108993
 >> iter 92000, loss: 0.119763
 >> iter 93000, loss: 0.057257
 >> iter 94000, loss: 0.140837
 >> iter 95000, loss: 0.196184
 >> iter 96000, loss: 0.165679
 >> iter 97000, loss: 0.075291
 >> iter 98000, loss: 0.188329
 >> iter 99000, loss: 0.082888
 >> iter 100000, loss: 0.126435
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 15.779531
 >> iter 2000, loss: 6.713171
 >> iter 3000, loss: 2.530561
 >> iter 4000, loss: 0.969997
 >> iter 5000, loss: 0.395220
 >> iter 6000, loss: 0.170646
 >> iter 7000, loss: 0.103309
 >> iter 8000, loss: 0.132000
 >> iter 9000, loss: 0.085332
 >> iter 10000, loss: 0.418225
   Number of active neurons: 2
 >> iter 11000, loss: 0.173230
 >> iter 12000, loss: 0.276602
 >> iter 13000, loss: 0.144026
 >> iter 14000, loss: 0.073251
 >> iter 15000, loss: 0.101993
 >> iter 16000, loss: 0.100895
 >> iter 17000, loss: 0.234284
 >> iter 18000, loss: 0.159087
 >> iter 19000, loss: 0.668924
 >> iter 20000, loss: 0.521649
   Number of active neurons: 2
 >> iter 21000, loss: 0.784208
 >> iter 22000, loss: 0.452254
 >> iter 23000, loss: 0.300095
 >> iter 24000, loss: 0.164871
 >> iter 25000, loss: 0.080382
 >> iter 26000, loss: 0.148526
 >> iter 27000, loss: 0.090580
 >> iter 28000, loss: 0.092642
 >> iter 29000, loss: 0.074217
 >> iter 30000, loss: 0.425766
   Number of active neurons: 3
 >> iter 31000, loss: 0.197112
 >> iter 32000, loss: 0.198118
 >> iter 33000, loss: 0.107299
 >> iter 34000, loss: 0.208402
 >> iter 35000, loss: 0.336467
 >> iter 36000, loss: 0.468769
 >> iter 37000, loss: 0.194891
 >> iter 38000, loss: 0.417734
 >> iter 39000, loss: 0.175318
 >> iter 40000, loss: 0.179196
   Number of active neurons: 3
 >> iter 41000, loss: 0.082000
 >> iter 42000, loss: 0.285883
 >> iter 43000, loss: 0.121617
 >> iter 44000, loss: 0.512695
 >> iter 45000, loss: 0.209970
 >> iter 46000, loss: 0.197228
 >> iter 47000, loss: 0.088178
 >> iter 48000, loss: 0.057791
 >> iter 49000, loss: 0.102089
 >> iter 50000, loss: 0.146754
   Number of active neurons: 3
 >> iter 51000, loss: 0.067606
 >> iter 52000, loss: 0.158644
 >> iter 53000, loss: 0.099896
 >> iter 54000, loss: 0.188231
 >> iter 55000, loss: 0.083026
 >> iter 56000, loss: 0.126709
 >> iter 57000, loss: 0.059656
 >> iter 58000, loss: 0.187483
 >> iter 59000, loss: 0.199143
 >> iter 60000, loss: 0.284255
   Number of active neurons: 3
 >> iter 61000, loss: 0.120161
 >> iter 62000, loss: 0.121815
 >> iter 63000, loss: 0.058671
 >> iter 64000, loss: 0.160838
 >> iter 65000, loss: 0.094753
 >> iter 66000, loss: 0.161472
 >> iter 67000, loss: 0.215174
 >> iter 68000, loss: 0.215786
 >> iter 69000, loss: 0.097582
 >> iter 70000, loss: 0.256710
   Number of active neurons: 3
 >> iter 71000, loss: 0.248389
 >> iter 72000, loss: 0.110529
 >> iter 73000, loss: 0.055079
 >> iter 74000, loss: 0.503982
 >> iter 75000, loss: 0.205183
 >> iter 76000, loss: 0.186281
 >> iter 77000, loss: 0.150545
 >> iter 78000, loss: 0.179968
 >> iter 79000, loss: 0.143161
 >> iter 80000, loss: 0.205646
   Number of active neurons: 3
 >> iter 81000, loss: 0.089667
 >> iter 82000, loss: 0.323074
 >> iter 83000, loss: 0.247882
 >> iter 84000, loss: 0.108760
 >> iter 85000, loss: 0.275193
 >> iter 86000, loss: 0.345327
 >> iter 87000, loss: 0.147944
 >> iter 88000, loss: 0.188692
 >> iter 89000, loss: 0.085217
 >> iter 90000, loss: 0.325996
   Number of active neurons: 3
 >> iter 91000, loss: 0.136400
 >> iter 92000, loss: 0.322442
 >> iter 93000, loss: 0.135406
 >> iter 94000, loss: 0.138815
 >> iter 95000, loss: 0.065313
 >> iter 96000, loss: 0.117047
 >> iter 97000, loss: 0.056060
 >> iter 98000, loss: 0.231603
 >> iter 99000, loss: 0.194599
 >> iter 100000, loss: 0.454054
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0069999300007
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.027299
 >> iter 2000, loss: 6.384957
 >> iter 3000, loss: 2.388745
 >> iter 4000, loss: 0.904992
 >> iter 5000, loss: 0.353371
 >> iter 6000, loss: 0.148075
 >> iter 7000, loss: 0.091575
 >> iter 8000, loss: 0.050226
 >> iter 9000, loss: 0.084716
 >> iter 10000, loss: 0.058513
   Number of active neurons: 2
 >> iter 11000, loss: 0.060323
 >> iter 12000, loss: 0.092020
 >> iter 13000, loss: 0.145946
 >> iter 14000, loss: 0.617624
 >> iter 15000, loss: 0.362599
 >> iter 16000, loss: 0.157515
 >> iter 17000, loss: 0.075594
 >> iter 18000, loss: 0.057375
 >> iter 19000, loss: 0.102909
 >> iter 20000, loss: 0.059159
   Number of active neurons: 2
 >> iter 21000, loss: 0.094485
 >> iter 22000, loss: 0.059214
 >> iter 23000, loss: 0.112245
 >> iter 24000, loss: 0.348730
 >> iter 25000, loss: 0.233690
 >> iter 26000, loss: 0.142362
 >> iter 27000, loss: 0.107646
 >> iter 28000, loss: 0.320688
 >> iter 29000, loss: 0.482917
 >> iter 30000, loss: 0.326547
   Number of active neurons: 2
 >> iter 31000, loss: 0.149614
 >> iter 32000, loss: 0.078543
 >> iter 33000, loss: 0.237833
 >> iter 34000, loss: 0.337260
 >> iter 35000, loss: 0.242880
 >> iter 36000, loss: 0.111250
 >> iter 37000, loss: 0.510758
 >> iter 38000, loss: 0.260016
 >> iter 39000, loss: 0.144035
 >> iter 40000, loss: 0.075156
   Number of active neurons: 2
 >> iter 41000, loss: 0.064271
 >> iter 42000, loss: 0.440794
 >> iter 43000, loss: 0.184125
 >> iter 44000, loss: 0.238005
 >> iter 45000, loss: 0.154277
 >> iter 46000, loss: 0.240832
 >> iter 47000, loss: 0.109061
 >> iter 48000, loss: 0.108138
 >> iter 49000, loss: 0.220819
 >> iter 50000, loss: 0.107513
   Number of active neurons: 2
 >> iter 51000, loss: 0.216635
 >> iter 52000, loss: 0.100985
 >> iter 53000, loss: 0.232068
 >> iter 54000, loss: 0.242718
 >> iter 55000, loss: 0.273190
 >> iter 56000, loss: 0.152408
 >> iter 57000, loss: 0.227337
 >> iter 58000, loss: 0.566638
 >> iter 59000, loss: 0.237108
 >> iter 60000, loss: 0.110172
   Number of active neurons: 2
 >> iter 61000, loss: 0.147218
 >> iter 62000, loss: 0.119645
 >> iter 63000, loss: 0.060816
 >> iter 64000, loss: 0.038965
 >> iter 65000, loss: 0.560785
 >> iter 66000, loss: 0.742131
 >> iter 67000, loss: 0.451783
 >> iter 68000, loss: 0.374723
 >> iter 69000, loss: 0.395182
 >> iter 70000, loss: 0.230741
   Number of active neurons: 3
 >> iter 71000, loss: 0.534160
 >> iter 72000, loss: 0.226486
 >> iter 73000, loss: 0.389724
 >> iter 74000, loss: 0.169958
 >> iter 75000, loss: 0.336020
 >> iter 76000, loss: 0.149730
 >> iter 77000, loss: 0.191801
 >> iter 78000, loss: 0.464831
 >> iter 79000, loss: 0.202694
 >> iter 80000, loss: 0.096848
   Number of active neurons: 3
 >> iter 81000, loss: 0.053108
 >> iter 82000, loss: 0.073290
 >> iter 83000, loss: 0.062281
 >> iter 84000, loss: 0.550074
 >> iter 85000, loss: 0.281254
 >> iter 86000, loss: 0.261637
 >> iter 87000, loss: 0.368162
 >> iter 88000, loss: 0.159296
 >> iter 89000, loss: 0.077062
 >> iter 90000, loss: 0.048223
   Number of active neurons: 2
 >> iter 91000, loss: 0.204277
 >> iter 92000, loss: 0.126682
 >> iter 93000, loss: 0.088453
 >> iter 94000, loss: 0.129455
 >> iter 95000, loss: 0.088661
 >> iter 96000, loss: 0.394698
 >> iter 97000, loss: 0.203269
 >> iter 98000, loss: 0.288222
 >> iter 99000, loss: 0.124866
 >> iter 100000, loss: 0.289280
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.782583
 >> iter 2000, loss: 6.387311
 >> iter 3000, loss: 2.402803
 >> iter 4000, loss: 1.023861
 >> iter 5000, loss: 0.520278
 >> iter 6000, loss: 0.408421
 >> iter 7000, loss: 0.460489
 >> iter 8000, loss: 0.435765
 >> iter 9000, loss: 0.357498
 >> iter 10000, loss: 0.296403
   Number of active neurons: 6
 >> iter 11000, loss: 0.190695
 >> iter 12000, loss: 0.373338
 >> iter 13000, loss: 0.262561
 >> iter 14000, loss: 0.599091
 >> iter 15000, loss: 0.245756
 >> iter 16000, loss: 0.244205
 >> iter 17000, loss: 0.178072
 >> iter 18000, loss: 0.442435
 >> iter 19000, loss: 0.380143
 >> iter 20000, loss: 0.205359
   Number of active neurons: 5
 >> iter 21000, loss: 0.194893
 >> iter 22000, loss: 0.553555
 >> iter 23000, loss: 0.229234
 >> iter 24000, loss: 0.358991
 >> iter 25000, loss: 0.217552
 >> iter 26000, loss: 0.626678
 >> iter 27000, loss: 0.263510
 >> iter 28000, loss: 0.285230
 >> iter 29000, loss: 0.141993
 >> iter 30000, loss: 0.107518
   Number of active neurons: 5
 >> iter 31000, loss: 0.152095
 >> iter 32000, loss: 0.275763
 >> iter 33000, loss: 0.120425
 >> iter 34000, loss: 0.279272
 >> iter 35000, loss: 0.146159
 >> iter 36000, loss: 0.297804
 >> iter 37000, loss: 0.197646
 >> iter 38000, loss: 0.292408
 >> iter 39000, loss: 0.126672
 >> iter 40000, loss: 0.245491
   Number of active neurons: 4
 >> iter 41000, loss: 0.182375
 >> iter 42000, loss: 0.089430
 >> iter 43000, loss: 0.241425
 >> iter 44000, loss: 0.432423
 >> iter 45000, loss: 0.181334
 >> iter 46000, loss: 0.261959
 >> iter 47000, loss: 0.112936
 >> iter 48000, loss: 0.174307
 >> iter 49000, loss: 0.144015
 >> iter 50000, loss: 0.312318
   Number of active neurons: 4
 >> iter 51000, loss: 0.135303
 >> iter 52000, loss: 0.234048
 >> iter 53000, loss: 0.144429
 >> iter 54000, loss: 0.330198
 >> iter 55000, loss: 0.144154
 >> iter 56000, loss: 0.237135
 >> iter 57000, loss: 0.130718
 >> iter 58000, loss: 0.236692
 >> iter 59000, loss: 0.127272
 >> iter 60000, loss: 0.174513
   Number of active neurons: 4
 >> iter 61000, loss: 0.099408
 >> iter 62000, loss: 0.300078
 >> iter 63000, loss: 0.143329
 >> iter 64000, loss: 0.325452
 >> iter 65000, loss: 0.138446
 >> iter 66000, loss: 0.339556
 >> iter 67000, loss: 0.143479
 >> iter 68000, loss: 0.367393
 >> iter 69000, loss: 0.154913
 >> iter 70000, loss: 0.299483
   Number of active neurons: 4
 >> iter 71000, loss: 0.127819
 >> iter 72000, loss: 0.277312
 >> iter 73000, loss: 0.184379
 >> iter 74000, loss: 0.230178
 >> iter 75000, loss: 0.191164
 >> iter 76000, loss: 0.183017
 >> iter 77000, loss: 0.204886
 >> iter 78000, loss: 0.191884
 >> iter 79000, loss: 0.143247
 >> iter 80000, loss: 0.186819
   Number of active neurons: 4
 >> iter 81000, loss: 0.142258
 >> iter 82000, loss: 0.194091
 >> iter 83000, loss: 0.216619
 >> iter 84000, loss: 0.190846
 >> iter 85000, loss: 0.085931
 >> iter 86000, loss: 0.252019
 >> iter 87000, loss: 0.110415
 >> iter 88000, loss: 0.286269
 >> iter 89000, loss: 0.155889
 >> iter 90000, loss: 0.176923
   Number of active neurons: 3
 >> iter 91000, loss: 0.102483
 >> iter 92000, loss: 0.059274
 >> iter 93000, loss: 0.035096
 >> iter 94000, loss: 0.137018
 >> iter 95000, loss: 0.134497
 >> iter 96000, loss: 0.279120
 >> iter 97000, loss: 0.117866
 >> iter 98000, loss: 0.251475
 >> iter 99000, loss: 0.129915
 >> iter 100000, loss: 0.168102
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.00799984000319
   - Test - Long: 0.0849957502125
   - Test - Big: 0.0089999100009
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.982778
 >> iter 2000, loss: 6.184273
 >> iter 3000, loss: 2.305008
 >> iter 4000, loss: 1.086106
 >> iter 5000, loss: 0.422967
 >> iter 6000, loss: 0.218659
 >> iter 7000, loss: 0.161562
 >> iter 8000, loss: 0.252090
 >> iter 9000, loss: 0.123846
 >> iter 10000, loss: 0.121081
   Number of active neurons: 3
 >> iter 11000, loss: 0.120474
 >> iter 12000, loss: 0.061645
 >> iter 13000, loss: 0.089482
 >> iter 14000, loss: 0.204613
 >> iter 15000, loss: 0.277560
 >> iter 16000, loss: 0.218683
 >> iter 17000, loss: 0.098573
 >> iter 18000, loss: 0.230023
 >> iter 19000, loss: 0.102044
 >> iter 20000, loss: 0.142309
   Number of active neurons: 3
 >> iter 21000, loss: 0.222748
 >> iter 22000, loss: 0.280954
 >> iter 23000, loss: 0.121289
 >> iter 24000, loss: 0.163140
 >> iter 25000, loss: 0.203458
 >> iter 26000, loss: 0.194117
 >> iter 27000, loss: 0.307932
 >> iter 28000, loss: 0.278706
 >> iter 29000, loss: 0.165991
 >> iter 30000, loss: 0.141984
   Number of active neurons: 3
 >> iter 31000, loss: 0.160907
 >> iter 32000, loss: 0.184039
 >> iter 33000, loss: 0.226906
 >> iter 34000, loss: 0.257134
 >> iter 35000, loss: 0.204644
 >> iter 36000, loss: 0.188060
 >> iter 37000, loss: 0.131031
 >> iter 38000, loss: 0.118988
 >> iter 39000, loss: 0.131309
 >> iter 40000, loss: 0.409012
   Number of active neurons: 3
 >> iter 41000, loss: 0.434462
 >> iter 42000, loss: 0.234746
 >> iter 43000, loss: 0.143233
 >> iter 44000, loss: 0.164600
 >> iter 45000, loss: 0.118298
 >> iter 46000, loss: 0.365564
 >> iter 47000, loss: 0.183875
 >> iter 48000, loss: 0.356878
 >> iter 49000, loss: 0.241865
 >> iter 50000, loss: 0.107156
   Number of active neurons: 3
 >> iter 51000, loss: 0.150435
 >> iter 52000, loss: 0.072864
 >> iter 53000, loss: 0.185689
 >> iter 54000, loss: 0.266511
 >> iter 55000, loss: 0.282548
 >> iter 56000, loss: 0.273997
 >> iter 57000, loss: 0.137919
 >> iter 58000, loss: 0.155059
 >> iter 59000, loss: 0.094700
 >> iter 60000, loss: 0.266784
   Number of active neurons: 3
 >> iter 61000, loss: 0.131522
 >> iter 62000, loss: 0.440491
 >> iter 63000, loss: 0.495564
 >> iter 64000, loss: 0.204050
 >> iter 65000, loss: 0.092939
 >> iter 66000, loss: 0.147539
 >> iter 67000, loss: 0.135309
 >> iter 68000, loss: 0.208831
 >> iter 69000, loss: 0.116370
 >> iter 70000, loss: 0.115222
   Number of active neurons: 3
 >> iter 71000, loss: 0.151666
 >> iter 72000, loss: 0.071116
 >> iter 73000, loss: 0.215693
 >> iter 74000, loss: 0.098549
 >> iter 75000, loss: 0.087915
 >> iter 76000, loss: 0.111793
 >> iter 77000, loss: 0.110636
 >> iter 78000, loss: 0.055110
 >> iter 79000, loss: 0.139093
 >> iter 80000, loss: 0.089520
   Number of active neurons: 3
 >> iter 81000, loss: 0.224791
 >> iter 82000, loss: 0.098668
 >> iter 83000, loss: 0.150260
 >> iter 84000, loss: 0.073560
 >> iter 85000, loss: 0.089535
 >> iter 86000, loss: 0.138455
 >> iter 87000, loss: 0.174785
 >> iter 88000, loss: 0.202252
 >> iter 89000, loss: 0.189840
 >> iter 90000, loss: 0.212753
   Number of active neurons: 3
 >> iter 91000, loss: 0.344315
 >> iter 92000, loss: 0.186923
 >> iter 93000, loss: 0.163328
 >> iter 94000, loss: 0.258788
 >> iter 95000, loss: 0.226722
 >> iter 96000, loss: 0.258503
 >> iter 97000, loss: 0.280861
 >> iter 98000, loss: 0.123220
 >> iter 99000, loss: 0.269141
 >> iter 100000, loss: 0.118542
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0129998700013
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.975178
 >> iter 2000, loss: 6.307213
 >> iter 3000, loss: 2.347384
 >> iter 4000, loss: 0.883140
 >> iter 5000, loss: 0.419241
 >> iter 6000, loss: 0.216100
 >> iter 7000, loss: 0.146232
 >> iter 8000, loss: 0.139223
 >> iter 9000, loss: 0.083189
 >> iter 10000, loss: 0.241358
   Number of active neurons: 4
 >> iter 11000, loss: 0.108697
 >> iter 12000, loss: 0.365439
 >> iter 13000, loss: 0.346214
 >> iter 14000, loss: 0.146854
 >> iter 15000, loss: 0.148351
 >> iter 16000, loss: 0.178127
 >> iter 17000, loss: 0.082711
 >> iter 18000, loss: 0.163891
 >> iter 19000, loss: 0.115013
 >> iter 20000, loss: 0.125334
   Number of active neurons: 4
 >> iter 21000, loss: 0.102805
 >> iter 22000, loss: 0.205388
 >> iter 23000, loss: 0.092735
 >> iter 24000, loss: 0.321725
 >> iter 25000, loss: 0.143319
 >> iter 26000, loss: 0.269644
 >> iter 27000, loss: 0.117986
 >> iter 28000, loss: 0.158227
 >> iter 29000, loss: 0.074644
 >> iter 30000, loss: 0.129791
   Number of active neurons: 4
 >> iter 31000, loss: 0.062733
 >> iter 32000, loss: 0.368129
 >> iter 33000, loss: 0.152806
 >> iter 34000, loss: 0.520472
 >> iter 35000, loss: 0.217510
 >> iter 36000, loss: 0.684782
 >> iter 37000, loss: 0.389689
 >> iter 38000, loss: 0.165115
 >> iter 39000, loss: 0.118899
 >> iter 40000, loss: 0.328819
   Number of active neurons: 4
 >> iter 41000, loss: 0.307567
 >> iter 42000, loss: 0.225195
 >> iter 43000, loss: 0.141840
 >> iter 44000, loss: 0.183877
 >> iter 45000, loss: 0.416558
 >> iter 46000, loss: 0.178213
 >> iter 47000, loss: 0.235829
 >> iter 48000, loss: 0.108805
 >> iter 49000, loss: 0.220645
 >> iter 50000, loss: 0.217423
   Number of active neurons: 4
 >> iter 51000, loss: 0.214364
 >> iter 52000, loss: 0.106052
 >> iter 53000, loss: 0.233363
 >> iter 54000, loss: 0.110671
 >> iter 55000, loss: 0.235051
 >> iter 56000, loss: 0.107717
 >> iter 57000, loss: 0.263863
 >> iter 58000, loss: 0.213877
 >> iter 59000, loss: 0.098526
 >> iter 60000, loss: 0.315851
   Number of active neurons: 4
 >> iter 61000, loss: 0.135926
 >> iter 62000, loss: 0.161631
 >> iter 63000, loss: 0.163255
 >> iter 64000, loss: 0.199409
 >> iter 65000, loss: 0.132809
 >> iter 66000, loss: 0.302362
 >> iter 67000, loss: 0.356124
 >> iter 68000, loss: 0.154027
 >> iter 69000, loss: 0.075798
 >> iter 70000, loss: 0.322553
   Number of active neurons: 3
 >> iter 71000, loss: 0.138999
 >> iter 72000, loss: 0.125508
 >> iter 73000, loss: 0.224693
 >> iter 74000, loss: 0.427650
 >> iter 75000, loss: 0.179297
 >> iter 76000, loss: 0.363112
 >> iter 77000, loss: 0.245824
 >> iter 78000, loss: 0.392405
 >> iter 79000, loss: 0.165245
 >> iter 80000, loss: 0.331704
   Number of active neurons: 4
 >> iter 81000, loss: 0.140840
 >> iter 82000, loss: 0.354879
 >> iter 83000, loss: 0.203874
 >> iter 84000, loss: 0.339064
 >> iter 85000, loss: 0.144582
 >> iter 86000, loss: 0.351881
 >> iter 87000, loss: 0.166218
 >> iter 88000, loss: 0.311407
 >> iter 89000, loss: 0.286416
 >> iter 90000, loss: 0.482929
   Number of active neurons: 3
 >> iter 91000, loss: 0.357493
 >> iter 92000, loss: 0.164937
 >> iter 93000, loss: 0.098467
 >> iter 94000, loss: 0.173068
 >> iter 95000, loss: 0.117064
 >> iter 96000, loss: 0.214543
 >> iter 97000, loss: 0.096941
 >> iter 98000, loss: 0.175558
 >> iter 99000, loss: 0.080384
 >> iter 100000, loss: 0.305516
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.00799984000319
   - Test - Long: 0.009999500025
   - Test - Big: 0.0089999100009
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.768537
 >> iter 2000, loss: 6.570392
 >> iter 3000, loss: 2.518459
 >> iter 4000, loss: 1.256092
 >> iter 5000, loss: 0.555077
 >> iter 6000, loss: 0.743698
 >> iter 7000, loss: 0.372100
 >> iter 8000, loss: 0.162536
 >> iter 9000, loss: 0.079815
 >> iter 10000, loss: 0.132732
   Number of active neurons: 3
 >> iter 11000, loss: 0.065849
 >> iter 12000, loss: 0.262237
 >> iter 13000, loss: 0.116862
 >> iter 14000, loss: 0.150476
 >> iter 15000, loss: 0.072927
 >> iter 16000, loss: 0.280199
 >> iter 17000, loss: 0.248192
 >> iter 18000, loss: 0.279836
 >> iter 19000, loss: 0.293739
 >> iter 20000, loss: 0.538803
   Number of active neurons: 3
 >> iter 21000, loss: 0.296606
 >> iter 22000, loss: 0.268905
 >> iter 23000, loss: 0.122333
 >> iter 24000, loss: 0.065933
 >> iter 25000, loss: 0.069234
 >> iter 26000, loss: 0.087221
 >> iter 27000, loss: 0.142576
 >> iter 28000, loss: 0.364340
 >> iter 29000, loss: 0.156456
 >> iter 30000, loss: 0.150872
   Number of active neurons: 3
 >> iter 31000, loss: 0.093161
 >> iter 32000, loss: 0.263588
 >> iter 33000, loss: 0.712720
 >> iter 34000, loss: 0.780636
 >> iter 35000, loss: 0.384193
 >> iter 36000, loss: 0.267917
 >> iter 37000, loss: 0.121271
 >> iter 38000, loss: 0.105289
 >> iter 39000, loss: 0.097197
 >> iter 40000, loss: 0.106156
   Number of active neurons: 2
 >> iter 41000, loss: 0.091685
 >> iter 42000, loss: 0.219984
 >> iter 43000, loss: 0.123042
 >> iter 44000, loss: 0.064273
 >> iter 45000, loss: 0.046534
 >> iter 46000, loss: 0.054233
 >> iter 47000, loss: 0.235611
 >> iter 48000, loss: 0.211291
 >> iter 49000, loss: 0.096006
 >> iter 50000, loss: 0.138882
   Number of active neurons: 2
 >> iter 51000, loss: 0.173987
 >> iter 52000, loss: 0.246182
 >> iter 53000, loss: 0.135514
 >> iter 54000, loss: 0.114363
 >> iter 55000, loss: 0.085175
 >> iter 56000, loss: 0.278994
 >> iter 57000, loss: 0.301224
 >> iter 58000, loss: 0.134117
 >> iter 59000, loss: 0.198275
 >> iter 60000, loss: 0.096708
   Number of active neurons: 3
 >> iter 61000, loss: 0.186856
 >> iter 62000, loss: 0.230575
 >> iter 63000, loss: 0.316922
 >> iter 64000, loss: 0.145839
 >> iter 65000, loss: 0.091254
 >> iter 66000, loss: 0.052325
 >> iter 67000, loss: 0.307094
 >> iter 68000, loss: 0.270530
 >> iter 69000, loss: 0.144921
 >> iter 70000, loss: 0.923871
   Number of active neurons: 3
 >> iter 71000, loss: 0.377115
 >> iter 72000, loss: 0.162259
 >> iter 73000, loss: 0.437586
 >> iter 74000, loss: 0.186175
 >> iter 75000, loss: 0.150395
 >> iter 76000, loss: 0.074396
 >> iter 77000, loss: 0.136760
 >> iter 78000, loss: 0.067622
 >> iter 79000, loss: 0.189117
 >> iter 80000, loss: 0.131980
   Number of active neurons: 2
 >> iter 81000, loss: 0.102913
 >> iter 82000, loss: 0.297365
 >> iter 83000, loss: 0.181292
 >> iter 84000, loss: 0.086600
 >> iter 85000, loss: 0.242390
 >> iter 86000, loss: 0.108885
 >> iter 87000, loss: 0.223574
 >> iter 88000, loss: 0.208584
 >> iter 89000, loss: 0.196082
 >> iter 90000, loss: 0.143012
   Number of active neurons: 3
 >> iter 91000, loss: 0.096745
 >> iter 92000, loss: 0.055940
 >> iter 93000, loss: 0.425777
 >> iter 94000, loss: 0.408415
 >> iter 95000, loss: 0.194137
 >> iter 96000, loss: 0.272644
 >> iter 97000, loss: 0.371085
 >> iter 98000, loss: 0.471700
 >> iter 99000, loss: 0.233169
 >> iter 100000, loss: 0.138836
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.246137
 >> iter 2000, loss: 6.779455
 >> iter 3000, loss: 2.618125
 >> iter 4000, loss: 0.989410
 >> iter 5000, loss: 0.467599
 >> iter 6000, loss: 0.231350
 >> iter 7000, loss: 0.169417
 >> iter 8000, loss: 0.413643
 >> iter 9000, loss: 0.245834
 >> iter 10000, loss: 0.115256
   Number of active neurons: 3
 >> iter 11000, loss: 0.270269
 >> iter 12000, loss: 0.120871
 >> iter 13000, loss: 0.137984
 >> iter 14000, loss: 0.140792
 >> iter 15000, loss: 0.264116
 >> iter 16000, loss: 0.301910
 >> iter 17000, loss: 0.166311
 >> iter 18000, loss: 0.299589
 >> iter 19000, loss: 0.190077
 >> iter 20000, loss: 0.088566
   Number of active neurons: 3
 >> iter 21000, loss: 0.180646
 >> iter 22000, loss: 0.084522
 >> iter 23000, loss: 0.171850
 >> iter 24000, loss: 0.191034
 >> iter 25000, loss: 0.215495
 >> iter 26000, loss: 0.242159
 >> iter 27000, loss: 0.151901
 >> iter 28000, loss: 0.176371
 >> iter 29000, loss: 0.184613
 >> iter 30000, loss: 0.363725
   Number of active neurons: 3
 >> iter 31000, loss: 0.217427
 >> iter 32000, loss: 0.320180
 >> iter 33000, loss: 0.135538
 >> iter 34000, loss: 0.214266
 >> iter 35000, loss: 0.206211
 >> iter 36000, loss: 0.215938
 >> iter 37000, loss: 0.122902
 >> iter 38000, loss: 0.444874
 >> iter 39000, loss: 0.183841
 >> iter 40000, loss: 0.124442
   Number of active neurons: 3
 >> iter 41000, loss: 0.077992
 >> iter 42000, loss: 0.117648
 >> iter 43000, loss: 0.151193
 >> iter 44000, loss: 0.137888
 >> iter 45000, loss: 0.098517
 >> iter 46000, loss: 0.196103
 >> iter 47000, loss: 0.217866
 >> iter 48000, loss: 0.295286
 >> iter 49000, loss: 0.126507
 >> iter 50000, loss: 0.159226
   Number of active neurons: 3
 >> iter 51000, loss: 0.173010
 >> iter 52000, loss: 0.245230
 >> iter 53000, loss: 0.106406
 >> iter 54000, loss: 0.248925
 >> iter 55000, loss: 0.106234
 >> iter 56000, loss: 0.157905
 >> iter 57000, loss: 0.169202
 >> iter 58000, loss: 0.310221
 >> iter 59000, loss: 0.130183
 >> iter 60000, loss: 0.170432
   Number of active neurons: 3
 >> iter 61000, loss: 0.155043
 >> iter 62000, loss: 0.337387
 >> iter 63000, loss: 0.142899
 >> iter 64000, loss: 0.174623
 >> iter 65000, loss: 0.144696
 >> iter 66000, loss: 0.374641
 >> iter 67000, loss: 0.155629
 >> iter 68000, loss: 0.383520
 >> iter 69000, loss: 0.255694
 >> iter 70000, loss: 0.208859
   Number of active neurons: 3
 >> iter 71000, loss: 0.092360
 >> iter 72000, loss: 0.131656
 >> iter 73000, loss: 0.121071
 >> iter 74000, loss: 0.059857
 >> iter 75000, loss: 0.118248
 >> iter 76000, loss: 0.649668
 >> iter 77000, loss: 0.260979
 >> iter 78000, loss: 0.211355
 >> iter 79000, loss: 0.093502
 >> iter 80000, loss: 0.110848
   Number of active neurons: 3
 >> iter 81000, loss: 0.140381
 >> iter 82000, loss: 0.170579
 >> iter 83000, loss: 0.077223
 >> iter 84000, loss: 0.123315
 >> iter 85000, loss: 0.123608
 >> iter 86000, loss: 0.163310
 >> iter 87000, loss: 0.146705
 >> iter 88000, loss: 0.180485
 >> iter 89000, loss: 0.165900
 >> iter 90000, loss: 0.213650
   Number of active neurons: 3
 >> iter 91000, loss: 0.092885
 >> iter 92000, loss: 0.120975
 >> iter 93000, loss: 0.057148
 >> iter 94000, loss: 0.097443
 >> iter 95000, loss: 0.047969
 >> iter 96000, loss: 0.147198
 >> iter 97000, loss: 0.067105
 >> iter 98000, loss: 0.106139
 >> iter 99000, loss: 0.051392
 >> iter 100000, loss: 0.098685
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.998998
 >> iter 2000, loss: 6.724121
 >> iter 3000, loss: 2.582676
 >> iter 4000, loss: 1.090031
 >> iter 5000, loss: 0.472896
 >> iter 6000, loss: 0.356865
 >> iter 7000, loss: 0.174915
 >> iter 8000, loss: 0.430581
 >> iter 9000, loss: 0.225815
 >> iter 10000, loss: 0.225839
   Number of active neurons: 3
 >> iter 11000, loss: 0.101388
 >> iter 12000, loss: 0.086580
 >> iter 13000, loss: 0.084844
 >> iter 14000, loss: 0.049606
 >> iter 15000, loss: 0.079000
 >> iter 16000, loss: 0.117033
 >> iter 17000, loss: 0.215659
 >> iter 18000, loss: 0.119465
 >> iter 19000, loss: 0.058285
 >> iter 20000, loss: 0.137579
   Number of active neurons: 3
 >> iter 21000, loss: 0.076266
 >> iter 22000, loss: 0.137111
 >> iter 23000, loss: 0.079241
 >> iter 24000, loss: 0.193964
 >> iter 25000, loss: 0.086369
 >> iter 26000, loss: 0.113178
 >> iter 27000, loss: 0.328352
 >> iter 28000, loss: 0.384075
 >> iter 29000, loss: 0.161042
 >> iter 30000, loss: 0.224339
   Number of active neurons: 3
 >> iter 31000, loss: 0.098064
 >> iter 32000, loss: 0.153454
 >> iter 33000, loss: 0.070438
 >> iter 34000, loss: 0.186543
 >> iter 35000, loss: 0.083352
 >> iter 36000, loss: 0.132665
 >> iter 37000, loss: 0.186218
 >> iter 38000, loss: 0.175604
 >> iter 39000, loss: 0.079213
 >> iter 40000, loss: 0.660697
   Number of active neurons: 3
 >> iter 41000, loss: 0.266495
 >> iter 42000, loss: 0.120469
 >> iter 43000, loss: 0.058954
 >> iter 44000, loss: 0.073998
 >> iter 45000, loss: 0.068288
 >> iter 46000, loss: 0.150935
 >> iter 47000, loss: 0.092170
 >> iter 48000, loss: 0.586078
 >> iter 49000, loss: 0.237345
 >> iter 50000, loss: 0.207094
   Number of active neurons: 3
 >> iter 51000, loss: 0.091927
 >> iter 52000, loss: 0.135671
 >> iter 53000, loss: 0.064241
 >> iter 54000, loss: 0.273387
 >> iter 55000, loss: 0.284132
 >> iter 56000, loss: 0.271522
 >> iter 57000, loss: 0.135394
 >> iter 58000, loss: 0.067835
 >> iter 59000, loss: 0.060854
 >> iter 60000, loss: 0.109207
   Number of active neurons: 3
 >> iter 61000, loss: 0.052915
 >> iter 62000, loss: 0.083203
 >> iter 63000, loss: 0.088935
 >> iter 64000, loss: 0.302848
 >> iter 65000, loss: 0.175260
 >> iter 66000, loss: 0.187985
 >> iter 67000, loss: 0.083534
 >> iter 68000, loss: 0.121816
 >> iter 69000, loss: 0.125545
 >> iter 70000, loss: 0.136349
   Number of active neurons: 3
 >> iter 71000, loss: 0.063843
 >> iter 72000, loss: 0.493908
 >> iter 73000, loss: 0.218665
 >> iter 74000, loss: 0.194521
 >> iter 75000, loss: 0.104067
 >> iter 76000, loss: 0.056235
 >> iter 77000, loss: 0.055905
 >> iter 78000, loss: 0.045477
 >> iter 79000, loss: 0.121858
 >> iter 80000, loss: 0.296538
   Number of active neurons: 3
 >> iter 81000, loss: 0.125154
 >> iter 82000, loss: 0.192724
 >> iter 83000, loss: 0.164803
 >> iter 84000, loss: 0.200661
 >> iter 85000, loss: 0.106287
 >> iter 86000, loss: 0.234442
 >> iter 87000, loss: 0.102839
 >> iter 88000, loss: 0.116037
 >> iter 89000, loss: 0.055913
 >> iter 90000, loss: 0.104864
   Number of active neurons: 3
 >> iter 91000, loss: 0.061218
 >> iter 92000, loss: 0.099258
 >> iter 93000, loss: 0.093783
 >> iter 94000, loss: 0.138484
 >> iter 95000, loss: 0.189065
 >> iter 96000, loss: 0.182264
 >> iter 97000, loss: 0.141902
 >> iter 98000, loss: 0.312316
 >> iter 99000, loss: 0.131512
 >> iter 100000, loss: 0.180228
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.00799984000319
   - Test - Long: 0.0849957502125
   - Test - Big: 0.0089999100009
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.151998
 >> iter 2000, loss: 5.675224
 >> iter 3000, loss: 2.154226
 >> iter 4000, loss: 0.996950
 >> iter 5000, loss: 0.428033
 >> iter 6000, loss: 0.312373
 >> iter 7000, loss: 0.134025
 >> iter 8000, loss: 0.173094
 >> iter 9000, loss: 0.180483
 >> iter 10000, loss: 0.269973
   Number of active neurons: 3
 >> iter 11000, loss: 0.154475
 >> iter 12000, loss: 0.131920
 >> iter 13000, loss: 0.104752
 >> iter 14000, loss: 0.060325
 >> iter 15000, loss: 0.331694
 >> iter 16000, loss: 0.145473
 >> iter 17000, loss: 0.266992
 >> iter 18000, loss: 0.477698
 >> iter 19000, loss: 0.266905
 >> iter 20000, loss: 0.180331
   Number of active neurons: 3
 >> iter 21000, loss: 0.130576
 >> iter 22000, loss: 0.239707
 >> iter 23000, loss: 0.132992
 >> iter 24000, loss: 0.519644
 >> iter 25000, loss: 0.305427
 >> iter 26000, loss: 0.344035
 >> iter 27000, loss: 0.220935
 >> iter 28000, loss: 0.267219
 >> iter 29000, loss: 0.192652
 >> iter 30000, loss: 0.424060
   Number of active neurons: 3
 >> iter 31000, loss: 0.243460
 >> iter 32000, loss: 0.411424
 >> iter 33000, loss: 0.197858
 >> iter 34000, loss: 0.227477
 >> iter 35000, loss: 0.199108
 >> iter 36000, loss: 0.341337
 >> iter 37000, loss: 0.252096
 >> iter 38000, loss: 0.142666
 >> iter 39000, loss: 0.111237
 >> iter 40000, loss: 0.171401
   Number of active neurons: 3
 >> iter 41000, loss: 0.369004
 >> iter 42000, loss: 0.907535
 >> iter 43000, loss: 0.385536
 >> iter 44000, loss: 0.270329
 >> iter 45000, loss: 0.236070
 >> iter 46000, loss: 0.233350
 >> iter 47000, loss: 0.201135
 >> iter 48000, loss: 0.094981
 >> iter 49000, loss: 0.070930
 >> iter 50000, loss: 0.289042
   Number of active neurons: 3
 >> iter 51000, loss: 0.363625
 >> iter 52000, loss: 0.155792
 >> iter 53000, loss: 0.096169
 >> iter 54000, loss: 0.318874
 >> iter 55000, loss: 0.159416
 >> iter 56000, loss: 0.075646
 >> iter 57000, loss: 0.062975
 >> iter 58000, loss: 0.278723
 >> iter 59000, loss: 0.120282
 >> iter 60000, loss: 0.227065
   Number of active neurons: 3
 >> iter 61000, loss: 0.100326
 >> iter 62000, loss: 0.313185
 >> iter 63000, loss: 0.133652
 >> iter 64000, loss: 0.168776
 >> iter 65000, loss: 0.133460
 >> iter 66000, loss: 0.392182
 >> iter 67000, loss: 0.209254
 >> iter 68000, loss: 0.355331
 >> iter 69000, loss: 0.190540
 >> iter 70000, loss: 0.332540
   Number of active neurons: 3
 >> iter 71000, loss: 0.192245
 >> iter 72000, loss: 0.087713
 >> iter 73000, loss: 0.120679
 >> iter 74000, loss: 0.119942
 >> iter 75000, loss: 0.260174
 >> iter 76000, loss: 0.168380
 >> iter 77000, loss: 0.202069
 >> iter 78000, loss: 0.092846
 >> iter 79000, loss: 0.209893
 >> iter 80000, loss: 0.338414
   Number of active neurons: 3
 >> iter 81000, loss: 0.366213
 >> iter 82000, loss: 0.162005
 >> iter 83000, loss: 0.091936
 >> iter 84000, loss: 0.222094
 >> iter 85000, loss: 0.100714
 >> iter 86000, loss: 0.328953
 >> iter 87000, loss: 0.275485
 >> iter 88000, loss: 0.180119
 >> iter 89000, loss: 0.082586
 >> iter 90000, loss: 0.219634
   Number of active neurons: 3
 >> iter 91000, loss: 0.097783
 >> iter 92000, loss: 0.118866
 >> iter 93000, loss: 0.056846
 >> iter 94000, loss: 0.241943
 >> iter 95000, loss: 0.194260
 >> iter 96000, loss: 0.408019
 >> iter 97000, loss: 0.173919
 >> iter 98000, loss: 0.207917
 >> iter 99000, loss: 0.092655
 >> iter 100000, loss: 0.205905
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.723252
 >> iter 2000, loss: 6.958804
 >> iter 3000, loss: 2.641075
 >> iter 4000, loss: 1.109242
 >> iter 5000, loss: 0.720403
 >> iter 6000, loss: 0.636992
 >> iter 7000, loss: 0.289966
 >> iter 8000, loss: 0.408846
 >> iter 9000, loss: 0.194563
 >> iter 10000, loss: 0.152843
   Number of active neurons: 5
 >> iter 11000, loss: 0.112380
 >> iter 12000, loss: 0.278653
 >> iter 13000, loss: 0.122321
 >> iter 14000, loss: 0.219087
 >> iter 15000, loss: 0.100062
 >> iter 16000, loss: 0.209972
 >> iter 17000, loss: 0.197332
 >> iter 18000, loss: 0.291612
 >> iter 19000, loss: 0.124825
 >> iter 20000, loss: 0.171939
   Number of active neurons: 4
 >> iter 21000, loss: 0.152628
 >> iter 22000, loss: 0.376239
 >> iter 23000, loss: 0.160028
 >> iter 24000, loss: 0.114999
 >> iter 25000, loss: 0.264007
 >> iter 26000, loss: 0.224103
 >> iter 27000, loss: 0.123673
 >> iter 28000, loss: 0.080340
 >> iter 29000, loss: 0.186061
 >> iter 30000, loss: 0.195991
   Number of active neurons: 4
 >> iter 31000, loss: 0.297995
 >> iter 32000, loss: 0.236940
 >> iter 33000, loss: 0.136160
 >> iter 34000, loss: 0.150221
 >> iter 35000, loss: 0.096362
 >> iter 36000, loss: 0.202305
 >> iter 37000, loss: 0.091708
 >> iter 38000, loss: 0.067614
 >> iter 39000, loss: 0.098266
 >> iter 40000, loss: 0.222246
   Number of active neurons: 4
 >> iter 41000, loss: 0.122795
 >> iter 42000, loss: 0.065055
 >> iter 43000, loss: 0.211100
 >> iter 44000, loss: 0.311269
 >> iter 45000, loss: 0.133087
 >> iter 46000, loss: 0.178178
 >> iter 47000, loss: 0.081953
 >> iter 48000, loss: 0.199130
 >> iter 49000, loss: 0.093068
 >> iter 50000, loss: 0.124023
   Number of active neurons: 4
 >> iter 51000, loss: 0.083931
 >> iter 52000, loss: 0.334661
 >> iter 53000, loss: 0.141035
 >> iter 54000, loss: 0.201076
 >> iter 55000, loss: 0.092714
 >> iter 56000, loss: 0.120928
 >> iter 57000, loss: 0.149013
 >> iter 58000, loss: 0.167185
 >> iter 59000, loss: 0.076860
 >> iter 60000, loss: 0.429969
   Number of active neurons: 3
 >> iter 61000, loss: 0.178143
 >> iter 62000, loss: 0.220936
 >> iter 63000, loss: 0.100130
 >> iter 64000, loss: 0.148398
 >> iter 65000, loss: 0.139806
 >> iter 66000, loss: 0.293143
 >> iter 67000, loss: 0.125582
 >> iter 68000, loss: 0.167799
 >> iter 69000, loss: 0.096906
 >> iter 70000, loss: 0.160762
   Number of active neurons: 3
 >> iter 71000, loss: 0.134236
 >> iter 72000, loss: 0.145010
 >> iter 73000, loss: 0.067373
 >> iter 74000, loss: 0.300892
 >> iter 75000, loss: 0.126614
 >> iter 76000, loss: 0.137568
 >> iter 77000, loss: 0.083257
 >> iter 78000, loss: 0.111218
 >> iter 79000, loss: 0.053699
 >> iter 80000, loss: 0.162591
   Number of active neurons: 3
 >> iter 81000, loss: 0.144647
 >> iter 82000, loss: 0.193070
 >> iter 83000, loss: 0.084893
 >> iter 84000, loss: 0.070209
 >> iter 85000, loss: 0.255035
 >> iter 86000, loss: 0.110790
 >> iter 87000, loss: 0.055612
 >> iter 88000, loss: 0.149270
 >> iter 89000, loss: 0.069392
 >> iter 90000, loss: 0.221263
   Number of active neurons: 3
 >> iter 91000, loss: 0.299669
 >> iter 92000, loss: 0.149689
 >> iter 93000, loss: 0.071890
 >> iter 94000, loss: 0.121159
 >> iter 95000, loss: 0.058947
 >> iter 96000, loss: 0.073625
 >> iter 97000, loss: 0.067692
 >> iter 98000, loss: 0.126431
 >> iter 99000, loss: 0.059612
 >> iter 100000, loss: 0.151883
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.987171
 >> iter 2000, loss: 6.544216
 >> iter 3000, loss: 2.493752
 >> iter 4000, loss: 0.997579
 >> iter 5000, loss: 0.387739
 >> iter 6000, loss: 0.537698
 >> iter 7000, loss: 0.221182
 >> iter 8000, loss: 0.179102
 >> iter 9000, loss: 0.083601
 >> iter 10000, loss: 0.213148
   Number of active neurons: 4
 >> iter 11000, loss: 0.127493
 >> iter 12000, loss: 0.288056
 >> iter 13000, loss: 0.122839
 >> iter 14000, loss: 0.182417
 >> iter 15000, loss: 0.180479
 >> iter 16000, loss: 0.172862
 >> iter 17000, loss: 0.227642
 >> iter 18000, loss: 0.367828
 >> iter 19000, loss: 0.154113
 >> iter 20000, loss: 0.460527
   Number of active neurons: 4
 >> iter 21000, loss: 0.221103
 >> iter 22000, loss: 0.420571
 >> iter 23000, loss: 0.174218
 >> iter 24000, loss: 0.262279
 >> iter 25000, loss: 0.112735
 >> iter 26000, loss: 0.385839
 >> iter 27000, loss: 0.220331
 >> iter 28000, loss: 0.453508
 >> iter 29000, loss: 0.187508
 >> iter 30000, loss: 0.162678
   Number of active neurons: 3
 >> iter 31000, loss: 0.791840
 >> iter 32000, loss: 0.385461
 >> iter 33000, loss: 0.163095
 >> iter 34000, loss: 0.138721
 >> iter 35000, loss: 0.066296
 >> iter 36000, loss: 0.147930
 >> iter 37000, loss: 0.067877
 >> iter 38000, loss: 0.069762
 >> iter 39000, loss: 0.154133
 >> iter 40000, loss: 0.158182
   Number of active neurons: 3
 >> iter 41000, loss: 0.071795
 >> iter 42000, loss: 0.059618
 >> iter 43000, loss: 0.196095
 >> iter 44000, loss: 0.089553
 >> iter 45000, loss: 0.103929
 >> iter 46000, loss: 0.132694
 >> iter 47000, loss: 0.061674
 >> iter 48000, loss: 0.194526
 >> iter 49000, loss: 0.169094
 >> iter 50000, loss: 0.244975
   Number of active neurons: 3
 >> iter 51000, loss: 0.127618
 >> iter 52000, loss: 0.066559
 >> iter 53000, loss: 0.058742
 >> iter 54000, loss: 0.042706
 >> iter 55000, loss: 0.335146
 >> iter 56000, loss: 0.304275
 >> iter 57000, loss: 0.129686
 >> iter 58000, loss: 0.174738
 >> iter 59000, loss: 0.078605
 >> iter 60000, loss: 0.116865
   Number of active neurons: 3
 >> iter 61000, loss: 0.055611
 >> iter 62000, loss: 0.184414
 >> iter 63000, loss: 0.081438
 >> iter 64000, loss: 0.357389
 >> iter 65000, loss: 0.231313
 >> iter 66000, loss: 0.170691
 >> iter 67000, loss: 0.096170
 >> iter 68000, loss: 0.148548
 >> iter 69000, loss: 0.087660
 >> iter 70000, loss: 0.063141
   Number of active neurons: 3
 >> iter 71000, loss: 0.035614
 >> iter 72000, loss: 0.042225
 >> iter 73000, loss: 0.128588
 >> iter 74000, loss: 0.102107
 >> iter 75000, loss: 0.050322
 >> iter 76000, loss: 0.040725
 >> iter 77000, loss: 0.252749
 >> iter 78000, loss: 0.340336
 >> iter 79000, loss: 0.143199
 >> iter 80000, loss: 0.181238
   Number of active neurons: 3
 >> iter 81000, loss: 0.081650
 >> iter 82000, loss: 0.162951
 >> iter 83000, loss: 0.159306
 >> iter 84000, loss: 0.146274
 >> iter 85000, loss: 0.098349
 >> iter 86000, loss: 0.167763
 >> iter 87000, loss: 0.159672
 >> iter 88000, loss: 0.194694
 >> iter 89000, loss: 0.172209
 >> iter 90000, loss: 0.161649
   Number of active neurons: 3
 >> iter 91000, loss: 0.075096
 >> iter 92000, loss: 0.206566
 >> iter 93000, loss: 0.091686
 >> iter 94000, loss: 0.134714
 >> iter 95000, loss: 0.063355
 >> iter 96000, loss: 0.168174
 >> iter 97000, loss: 0.445576
 >> iter 98000, loss: 0.184518
 >> iter 99000, loss: 0.083602
 >> iter 100000, loss: 0.125444
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.711221
 >> iter 2000, loss: 6.089188
 >> iter 3000, loss: 2.273359
 >> iter 4000, loss: 0.859182
 >> iter 5000, loss: 0.377676
 >> iter 6000, loss: 0.222319
 >> iter 7000, loss: 0.263652
 >> iter 8000, loss: 0.186630
 >> iter 9000, loss: 0.144801
 >> iter 10000, loss: 0.194071
   Number of active neurons: 3
 >> iter 11000, loss: 0.106666
 >> iter 12000, loss: 0.126617
 >> iter 13000, loss: 0.059801
 >> iter 14000, loss: 0.118799
 >> iter 15000, loss: 0.055949
 >> iter 16000, loss: 0.040365
 >> iter 17000, loss: 0.105586
 >> iter 18000, loss: 0.432216
 >> iter 19000, loss: 0.246231
 >> iter 20000, loss: 0.173010
   Number of active neurons: 3
 >> iter 21000, loss: 0.078984
 >> iter 22000, loss: 0.484351
 >> iter 23000, loss: 0.196484
 >> iter 24000, loss: 0.190806
 >> iter 25000, loss: 0.087662
 >> iter 26000, loss: 0.120574
 >> iter 27000, loss: 0.057401
 >> iter 28000, loss: 0.183094
 >> iter 29000, loss: 0.144823
 >> iter 30000, loss: 0.462426
   Number of active neurons: 3
 >> iter 31000, loss: 0.189657
 >> iter 32000, loss: 0.200766
 >> iter 33000, loss: 0.155832
 >> iter 34000, loss: 0.174811
 >> iter 35000, loss: 0.097669
 >> iter 36000, loss: 0.168213
 >> iter 37000, loss: 0.075781
 >> iter 38000, loss: 0.173909
 >> iter 39000, loss: 0.288691
 >> iter 40000, loss: 0.123198
   Number of active neurons: 3
 >> iter 41000, loss: 0.161901
 >> iter 42000, loss: 0.141614
 >> iter 43000, loss: 0.066844
 >> iter 44000, loss: 0.156756
 >> iter 45000, loss: 0.230767
 >> iter 46000, loss: 0.176924
 >> iter 47000, loss: 0.079155
 >> iter 48000, loss: 0.121145
 >> iter 49000, loss: 0.058081
 >> iter 50000, loss: 0.119372
   Number of active neurons: 3
 >> iter 51000, loss: 0.056676
 >> iter 52000, loss: 0.115946
 >> iter 53000, loss: 0.055122
 >> iter 54000, loss: 0.276414
 >> iter 55000, loss: 0.116043
 >> iter 56000, loss: 0.370692
 >> iter 57000, loss: 0.151720
 >> iter 58000, loss: 0.169037
 >> iter 59000, loss: 0.075582
 >> iter 60000, loss: 0.292335
   Number of active neurons: 3
 >> iter 61000, loss: 0.281670
 >> iter 62000, loss: 0.180855
 >> iter 63000, loss: 0.081541
 >> iter 64000, loss: 0.162713
 >> iter 65000, loss: 0.330062
 >> iter 66000, loss: 0.206401
 >> iter 67000, loss: 0.091032
 >> iter 68000, loss: 0.245088
 >> iter 69000, loss: 0.189103
 >> iter 70000, loss: 0.162644
   Number of active neurons: 3
 >> iter 71000, loss: 0.074322
 >> iter 72000, loss: 0.162708
 >> iter 73000, loss: 0.252792
 >> iter 74000, loss: 0.178925
 >> iter 75000, loss: 0.154426
 >> iter 76000, loss: 0.163905
 >> iter 77000, loss: 0.090330
 >> iter 78000, loss: 0.314450
 >> iter 79000, loss: 0.156562
 >> iter 80000, loss: 0.178377
   Number of active neurons: 3
 >> iter 81000, loss: 0.156353
 >> iter 82000, loss: 0.084371
 >> iter 83000, loss: 0.183342
 >> iter 84000, loss: 0.170657
 >> iter 85000, loss: 0.077581
 >> iter 86000, loss: 0.157269
 >> iter 87000, loss: 0.159340
 >> iter 88000, loss: 0.186241
 >> iter 89000, loss: 0.083625
 >> iter 90000, loss: 0.226348
   Number of active neurons: 3
 >> iter 91000, loss: 0.098699
 >> iter 92000, loss: 0.232898
 >> iter 93000, loss: 0.101305
 >> iter 94000, loss: 0.407150
 >> iter 95000, loss: 0.194079
 >> iter 96000, loss: 0.196553
 >> iter 97000, loss: 0.155110
 >> iter 98000, loss: 0.316503
 >> iter 99000, loss: 0.133186
 >> iter 100000, loss: 0.312364
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0319993600128
   - Test - Long: 0.09999500025
   - Test - Big: 0.0109998900011
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.983078
 >> iter 2000, loss: 6.624956
 >> iter 3000, loss: 2.507856
 >> iter 4000, loss: 1.263042
 >> iter 5000, loss: 0.539265
 >> iter 6000, loss: 0.220256
 >> iter 7000, loss: 0.275597
 >> iter 8000, loss: 0.251070
 >> iter 9000, loss: 0.147742
 >> iter 10000, loss: 0.138226
   Number of active neurons: 4
 >> iter 11000, loss: 0.254449
 >> iter 12000, loss: 0.166380
 >> iter 13000, loss: 0.198700
 >> iter 14000, loss: 0.146654
 >> iter 15000, loss: 0.225361
 >> iter 16000, loss: 0.201565
 >> iter 17000, loss: 0.198437
 >> iter 18000, loss: 0.246114
 >> iter 19000, loss: 0.107242
 >> iter 20000, loss: 0.165198
   Number of active neurons: 4
 >> iter 21000, loss: 0.361464
 >> iter 22000, loss: 0.387533
 >> iter 23000, loss: 0.508078
 >> iter 24000, loss: 0.311469
 >> iter 25000, loss: 0.134482
 >> iter 26000, loss: 0.181843
 >> iter 27000, loss: 0.093821
 >> iter 28000, loss: 0.181333
 >> iter 29000, loss: 0.191327
 >> iter 30000, loss: 0.190493
   Number of active neurons: 4
 >> iter 31000, loss: 0.107832
 >> iter 32000, loss: 0.167837
 >> iter 33000, loss: 0.098566
 >> iter 34000, loss: 0.130893
 >> iter 35000, loss: 0.076276
 >> iter 36000, loss: 0.046285
 >> iter 37000, loss: 0.028163
 >> iter 38000, loss: 0.044586
 >> iter 39000, loss: 0.027288
 >> iter 40000, loss: 0.321778
   Number of active neurons: 3
 >> iter 41000, loss: 0.132218
 >> iter 42000, loss: 0.163445
 >> iter 43000, loss: 0.148213
 >> iter 44000, loss: 0.277970
 >> iter 45000, loss: 0.143757
 >> iter 46000, loss: 0.179952
 >> iter 47000, loss: 0.104239
 >> iter 48000, loss: 0.060627
 >> iter 49000, loss: 0.119251
 >> iter 50000, loss: 0.372417
   Number of active neurons: 3
 >> iter 51000, loss: 0.154103
 >> iter 52000, loss: 0.168619
 >> iter 53000, loss: 0.076105
 >> iter 54000, loss: 0.223596
 >> iter 55000, loss: 0.096854
 >> iter 56000, loss: 0.126747
 >> iter 57000, loss: 0.059128
 >> iter 58000, loss: 0.044629
 >> iter 59000, loss: 0.052786
 >> iter 60000, loss: 0.600157
   Number of active neurons: 3
 >> iter 61000, loss: 0.339003
 >> iter 62000, loss: 0.235986
 >> iter 63000, loss: 0.103580
 >> iter 64000, loss: 0.057685
 >> iter 65000, loss: 0.036192
 >> iter 66000, loss: 0.090090
 >> iter 67000, loss: 0.066858
 >> iter 68000, loss: 0.112889
 >> iter 69000, loss: 0.053897
 >> iter 70000, loss: 0.113357
   Number of active neurons: 3
 >> iter 71000, loss: 0.076771
 >> iter 72000, loss: 0.221745
 >> iter 73000, loss: 0.201742
 >> iter 74000, loss: 0.161630
 >> iter 75000, loss: 0.073180
 >> iter 76000, loss: 0.058993
 >> iter 77000, loss: 0.176194
 >> iter 78000, loss: 0.193810
 >> iter 79000, loss: 0.225246
 >> iter 80000, loss: 0.147826
   Number of active neurons: 3
 >> iter 81000, loss: 0.159846
 >> iter 82000, loss: 0.317702
 >> iter 83000, loss: 0.135183
 >> iter 84000, loss: 0.321883
 >> iter 85000, loss: 0.135394
 >> iter 86000, loss: 0.078218
 >> iter 87000, loss: 0.042530
 >> iter 88000, loss: 0.163536
 >> iter 89000, loss: 0.186153
 >> iter 90000, loss: 0.161386
   Number of active neurons: 3
 >> iter 91000, loss: 0.237157
 >> iter 92000, loss: 0.217802
 >> iter 93000, loss: 0.171988
 >> iter 94000, loss: 0.149754
 >> iter 95000, loss: 0.116520
 >> iter 96000, loss: 0.062525
 >> iter 97000, loss: 0.084889
 >> iter 98000, loss: 0.056959
 >> iter 99000, loss: 0.760386
 >> iter 100000, loss: 0.438417
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.606161
 >> iter 2000, loss: 6.402897
 >> iter 3000, loss: 2.392706
 >> iter 4000, loss: 1.034290
 >> iter 5000, loss: 0.400976
 >> iter 6000, loss: 0.223406
 >> iter 7000, loss: 0.193308
 >> iter 8000, loss: 0.187834
 >> iter 9000, loss: 0.547505
 >> iter 10000, loss: 0.342211
   Number of active neurons: 3
 >> iter 11000, loss: 0.209725
 >> iter 12000, loss: 0.097376
 >> iter 13000, loss: 0.174689
 >> iter 14000, loss: 0.179985
 >> iter 15000, loss: 0.178936
 >> iter 16000, loss: 0.112909
 >> iter 17000, loss: 0.136634
 >> iter 18000, loss: 0.068028
 >> iter 19000, loss: 0.341103
 >> iter 20000, loss: 0.293726
   Number of active neurons: 3
 >> iter 21000, loss: 0.186388
 >> iter 22000, loss: 0.192205
 >> iter 23000, loss: 0.151629
 >> iter 24000, loss: 0.073069
 >> iter 25000, loss: 0.276253
 >> iter 26000, loss: 0.235225
 >> iter 27000, loss: 0.110068
 >> iter 28000, loss: 0.191190
 >> iter 29000, loss: 0.152568
 >> iter 30000, loss: 0.073507
   Number of active neurons: 3
 >> iter 31000, loss: 0.206553
 >> iter 32000, loss: 0.182033
 >> iter 33000, loss: 0.165051
 >> iter 34000, loss: 0.184383
 >> iter 35000, loss: 0.117776
 >> iter 36000, loss: 0.272833
 >> iter 37000, loss: 0.355708
 >> iter 38000, loss: 0.191981
 >> iter 39000, loss: 0.297762
 >> iter 40000, loss: 0.226406
   Number of active neurons: 3
 >> iter 41000, loss: 0.109635
 >> iter 42000, loss: 0.148703
 >> iter 43000, loss: 0.127532
 >> iter 44000, loss: 0.195843
 >> iter 45000, loss: 0.239772
 >> iter 46000, loss: 0.150439
 >> iter 47000, loss: 0.236835
 >> iter 48000, loss: 0.247320
 >> iter 49000, loss: 0.110414
 >> iter 50000, loss: 0.056239
   Number of active neurons: 3
 >> iter 51000, loss: 0.232580
 >> iter 52000, loss: 0.254689
 >> iter 53000, loss: 0.202113
 >> iter 54000, loss: 0.093879
 >> iter 55000, loss: 0.210822
 >> iter 56000, loss: 0.303154
 >> iter 57000, loss: 0.200946
 >> iter 58000, loss: 0.157947
 >> iter 59000, loss: 0.184144
 >> iter 60000, loss: 0.188059
   Number of active neurons: 3
 >> iter 61000, loss: 0.190168
 >> iter 62000, loss: 0.362475
 >> iter 63000, loss: 0.154261
 >> iter 64000, loss: 0.179874
 >> iter 65000, loss: 0.353568
 >> iter 66000, loss: 0.253850
 >> iter 67000, loss: 0.111513
 >> iter 68000, loss: 0.175389
 >> iter 69000, loss: 0.182792
 >> iter 70000, loss: 0.084708
   Number of active neurons: 3
 >> iter 71000, loss: 0.070557
 >> iter 72000, loss: 0.172963
 >> iter 73000, loss: 0.276523
 >> iter 74000, loss: 0.267047
 >> iter 75000, loss: 0.177018
 >> iter 76000, loss: 0.136780
 >> iter 77000, loss: 0.150265
 >> iter 78000, loss: 0.166471
 >> iter 79000, loss: 0.077133
 >> iter 80000, loss: 0.201842
   Number of active neurons: 3
 >> iter 81000, loss: 0.165424
 >> iter 82000, loss: 0.176410
 >> iter 83000, loss: 0.078349
 >> iter 84000, loss: 0.264646
 >> iter 85000, loss: 0.134850
 >> iter 86000, loss: 0.232863
 >> iter 87000, loss: 0.099644
 >> iter 88000, loss: 0.140014
 >> iter 89000, loss: 0.064671
 >> iter 90000, loss: 0.114339
   Number of active neurons: 3
 >> iter 91000, loss: 0.154418
 >> iter 92000, loss: 0.174218
 >> iter 93000, loss: 0.077665
 >> iter 94000, loss: 0.481324
 >> iter 95000, loss: 0.195460
 >> iter 96000, loss: 0.195438
 >> iter 97000, loss: 0.086475
 >> iter 98000, loss: 0.165452
 >> iter 99000, loss: 0.074743
 >> iter 100000, loss: 0.127451
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.890044
 >> iter 2000, loss: 6.212765
 >> iter 3000, loss: 2.369518
 >> iter 4000, loss: 0.898050
 >> iter 5000, loss: 0.397089
 >> iter 6000, loss: 0.166326
 >> iter 7000, loss: 0.130793
 >> iter 8000, loss: 0.065582
 >> iter 9000, loss: 0.116254
 >> iter 10000, loss: 0.060958
   Number of active neurons: 4
 >> iter 11000, loss: 0.423994
 >> iter 12000, loss: 0.180715
 >> iter 13000, loss: 0.170932
 >> iter 14000, loss: 0.184028
 >> iter 15000, loss: 0.103355
 >> iter 16000, loss: 0.332480
 >> iter 17000, loss: 0.195305
 >> iter 18000, loss: 0.274090
 >> iter 19000, loss: 0.467736
 >> iter 20000, loss: 0.470618
   Number of active neurons: 3
 >> iter 21000, loss: 0.194484
 >> iter 22000, loss: 0.211461
 >> iter 23000, loss: 0.198565
 >> iter 24000, loss: 0.191042
 >> iter 25000, loss: 0.085835
 >> iter 26000, loss: 0.141766
 >> iter 27000, loss: 0.102591
 >> iter 28000, loss: 0.145914
 >> iter 29000, loss: 0.128089
 >> iter 30000, loss: 0.080958
   Number of active neurons: 3
 >> iter 31000, loss: 0.065397
 >> iter 32000, loss: 0.375806
 >> iter 33000, loss: 0.218682
 >> iter 34000, loss: 0.173617
 >> iter 35000, loss: 0.078423
 >> iter 36000, loss: 0.152702
 >> iter 37000, loss: 0.170962
 >> iter 38000, loss: 0.240244
 >> iter 39000, loss: 0.194400
 >> iter 40000, loss: 0.174128
   Number of active neurons: 3
 >> iter 41000, loss: 0.078766
 >> iter 42000, loss: 0.235682
 >> iter 43000, loss: 0.100729
 >> iter 44000, loss: 0.166518
 >> iter 45000, loss: 0.122462
 >> iter 46000, loss: 0.359886
 >> iter 47000, loss: 0.149747
 >> iter 48000, loss: 0.180963
 >> iter 49000, loss: 0.127095
 >> iter 50000, loss: 0.071500
   Number of active neurons: 3
 >> iter 51000, loss: 0.039635
 >> iter 52000, loss: 0.112526
 >> iter 53000, loss: 0.054005
 >> iter 54000, loss: 0.123217
 >> iter 55000, loss: 0.057617
 >> iter 56000, loss: 0.184422
 >> iter 57000, loss: 0.178684
 >> iter 58000, loss: 0.165111
 >> iter 59000, loss: 0.098265
 >> iter 60000, loss: 0.167142
   Number of active neurons: 3
 >> iter 61000, loss: 0.159486
 >> iter 62000, loss: 0.150485
 >> iter 63000, loss: 0.069105
 >> iter 64000, loss: 0.162811
 >> iter 65000, loss: 0.074548
 >> iter 66000, loss: 0.164889
 >> iter 67000, loss: 0.097268
 >> iter 68000, loss: 0.167310
 >> iter 69000, loss: 0.138290
 >> iter 70000, loss: 0.175622
   Number of active neurons: 3
 >> iter 71000, loss: 0.101046
 >> iter 72000, loss: 0.208363
 >> iter 73000, loss: 0.207973
 >> iter 74000, loss: 0.157001
 >> iter 75000, loss: 0.071880
 >> iter 76000, loss: 0.116517
 >> iter 77000, loss: 0.056025
 >> iter 78000, loss: 0.223590
 >> iter 79000, loss: 0.097322
 >> iter 80000, loss: 0.608093
   Number of active neurons: 3
 >> iter 81000, loss: 0.246251
 >> iter 82000, loss: 0.129703
 >> iter 83000, loss: 0.230650
 >> iter 84000, loss: 0.218112
 >> iter 85000, loss: 0.153605
 >> iter 86000, loss: 0.140661
 >> iter 87000, loss: 0.250801
 >> iter 88000, loss: 0.205112
 >> iter 89000, loss: 0.192227
 >> iter 90000, loss: 0.216434
   Number of active neurons: 3
 >> iter 91000, loss: 0.095261
 >> iter 92000, loss: 0.177019
 >> iter 93000, loss: 0.145424
 >> iter 94000, loss: 0.408795
 >> iter 95000, loss: 0.168193
 >> iter 96000, loss: 0.313737
 >> iter 97000, loss: 0.153396
 >> iter 98000, loss: 0.171902
 >> iter 99000, loss: 0.077495
 >> iter 100000, loss: 0.053645
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.276678
 >> iter 2000, loss: 6.529968
 >> iter 3000, loss: 2.436131
 >> iter 4000, loss: 1.036912
 >> iter 5000, loss: 0.457807
 >> iter 6000, loss: 0.783215
 >> iter 7000, loss: 0.422275
 >> iter 8000, loss: 0.404566
 >> iter 9000, loss: 0.263448
 >> iter 10000, loss: 0.309772
   Number of active neurons: 3
 >> iter 11000, loss: 0.325934
 >> iter 12000, loss: 1.018199
 >> iter 13000, loss: 0.473842
 >> iter 14000, loss: 0.380178
 >> iter 15000, loss: 0.183226
 >> iter 16000, loss: 0.893076
 >> iter 17000, loss: 0.464784
 >> iter 18000, loss: 0.210053
 >> iter 19000, loss: 0.094987
 >> iter 20000, loss: 0.834377
   Number of active neurons: 3
 >> iter 21000, loss: 0.428809
 >> iter 22000, loss: 0.466932
 >> iter 23000, loss: 0.196193
 >> iter 24000, loss: 0.247931
 >> iter 25000, loss: 0.134494
 >> iter 26000, loss: 0.840598
 >> iter 27000, loss: 0.597400
 >> iter 28000, loss: 0.246247
 >> iter 29000, loss: 0.108890
 >> iter 30000, loss: 0.186942
   Number of active neurons: 3
 >> iter 31000, loss: 0.413149
 >> iter 32000, loss: 0.230970
 >> iter 33000, loss: 0.129059
 >> iter 34000, loss: 0.578225
 >> iter 35000, loss: 0.432363
 >> iter 36000, loss: 0.932622
 >> iter 37000, loss: 0.484652
 >> iter 38000, loss: 0.373372
 >> iter 39000, loss: 0.423324
 >> iter 40000, loss: 0.398585
   Number of active neurons: 4
 >> iter 41000, loss: 0.208562
 >> iter 42000, loss: 0.465719
 >> iter 43000, loss: 0.222984
 >> iter 44000, loss: 0.885220
 >> iter 45000, loss: 0.426690
 >> iter 46000, loss: 0.305596
 >> iter 47000, loss: 0.133611
 >> iter 48000, loss: 0.259920
 >> iter 49000, loss: 0.322626
 >> iter 50000, loss: 0.249083
   Number of active neurons: 3
 >> iter 51000, loss: 0.423814
 >> iter 52000, loss: 0.386595
 >> iter 53000, loss: 0.486365
 >> iter 54000, loss: 0.843344
 >> iter 55000, loss: 0.446537
 >> iter 56000, loss: 0.608526
 >> iter 57000, loss: 0.323146
 >> iter 58000, loss: 0.511540
 >> iter 59000, loss: 0.497613
 >> iter 60000, loss: 0.212521
   Number of active neurons: 3
 >> iter 61000, loss: 0.095960
 >> iter 62000, loss: 0.126331
 >> iter 63000, loss: 0.236413
 >> iter 64000, loss: 0.536250
 >> iter 65000, loss: 0.580547
 >> iter 66000, loss: 0.402085
 >> iter 67000, loss: 0.346166
 >> iter 68000, loss: 0.473762
 >> iter 69000, loss: 0.312839
 >> iter 70000, loss: 0.249589
   Number of active neurons: 4
 >> iter 71000, loss: 0.110746
 >> iter 72000, loss: 0.352990
 >> iter 73000, loss: 0.197156
 >> iter 74000, loss: 0.382852
 >> iter 75000, loss: 0.197885
 >> iter 76000, loss: 0.416420
 >> iter 77000, loss: 0.173293
 >> iter 78000, loss: 0.349670
 >> iter 79000, loss: 0.172060
 >> iter 80000, loss: 0.338057
   Number of active neurons: 4
 >> iter 81000, loss: 0.144749
 >> iter 82000, loss: 0.164311
 >> iter 83000, loss: 0.100281
 >> iter 84000, loss: 0.088025
 >> iter 85000, loss: 0.168028
 >> iter 86000, loss: 0.195648
 >> iter 87000, loss: 0.166802
 >> iter 88000, loss: 0.219030
 >> iter 89000, loss: 0.190803
 >> iter 90000, loss: 0.209422
   Number of active neurons: 4
 >> iter 91000, loss: 0.106240
 >> iter 92000, loss: 0.577637
 >> iter 93000, loss: 0.239375
 >> iter 94000, loss: 0.307604
 >> iter 95000, loss: 0.174109
 >> iter 96000, loss: 0.354669
 >> iter 97000, loss: 0.227011
 >> iter 98000, loss: 0.245029
 >> iter 99000, loss: 0.184338
 >> iter 100000, loss: 0.234356
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0019999600008
   - Test - Long: 0.0
   - Test - Big: 0.0079999200008
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.322643
 >> iter 2000, loss: 6.383915
 >> iter 3000, loss: 2.406425
 >> iter 4000, loss: 0.904421
 >> iter 5000, loss: 0.448689
 >> iter 6000, loss: 0.184949
 >> iter 7000, loss: 0.180566
 >> iter 8000, loss: 0.228263
 >> iter 9000, loss: 0.328656
 >> iter 10000, loss: 0.253228
   Number of active neurons: 5
 >> iter 11000, loss: 0.248644
 >> iter 12000, loss: 0.235113
 >> iter 13000, loss: 0.174013
 >> iter 14000, loss: 0.196694
 >> iter 15000, loss: 0.271170
 >> iter 16000, loss: 0.232560
 >> iter 17000, loss: 0.230275
 >> iter 18000, loss: 0.322076
 >> iter 19000, loss: 0.226597
 >> iter 20000, loss: 0.202483
   Number of active neurons: 4
 >> iter 21000, loss: 0.155407
 >> iter 22000, loss: 0.183340
 >> iter 23000, loss: 0.147577
 >> iter 24000, loss: 0.082816
 >> iter 25000, loss: 0.113279
 >> iter 26000, loss: 0.066030
 >> iter 27000, loss: 0.108345
 >> iter 28000, loss: 0.236168
 >> iter 29000, loss: 0.147648
 >> iter 30000, loss: 0.183869
   Number of active neurons: 4
 >> iter 31000, loss: 0.179754
 >> iter 32000, loss: 0.205327
 >> iter 33000, loss: 0.191383
 >> iter 34000, loss: 0.314306
 >> iter 35000, loss: 0.134123
 >> iter 36000, loss: 0.292647
 >> iter 37000, loss: 0.124720
 >> iter 38000, loss: 0.402867
 >> iter 39000, loss: 0.167612
 >> iter 40000, loss: 0.312951
   Number of active neurons: 4
 >> iter 41000, loss: 0.132688
 >> iter 42000, loss: 0.183283
 >> iter 43000, loss: 0.175186
 >> iter 44000, loss: 0.208490
 >> iter 45000, loss: 0.193239
 >> iter 46000, loss: 0.116028
 >> iter 47000, loss: 0.186813
 >> iter 48000, loss: 0.088433
 >> iter 49000, loss: 0.403619
 >> iter 50000, loss: 0.266243
   Number of active neurons: 3
 >> iter 51000, loss: 0.115682
 >> iter 52000, loss: 0.153717
 >> iter 53000, loss: 0.112392
 >> iter 54000, loss: 0.204275
 >> iter 55000, loss: 0.090170
 >> iter 56000, loss: 0.051260
 >> iter 57000, loss: 0.055375
 >> iter 58000, loss: 0.286307
 >> iter 59000, loss: 0.120954
 >> iter 60000, loss: 0.271635
   Number of active neurons: 3
 >> iter 61000, loss: 0.115782
 >> iter 62000, loss: 0.165599
 >> iter 63000, loss: 0.097752
 >> iter 64000, loss: 0.063693
 >> iter 65000, loss: 0.035850
 >> iter 66000, loss: 0.114728
 >> iter 67000, loss: 0.054571
 >> iter 68000, loss: 0.446750
 >> iter 69000, loss: 0.180444
 >> iter 70000, loss: 0.193733
   Number of active neurons: 3
 >> iter 71000, loss: 0.275195
 >> iter 72000, loss: 0.232940
 >> iter 73000, loss: 0.101428
 >> iter 74000, loss: 0.133390
 >> iter 75000, loss: 0.062547
 >> iter 76000, loss: 0.355874
 >> iter 77000, loss: 0.205653
 >> iter 78000, loss: 0.210450
 >> iter 79000, loss: 0.180312
 >> iter 80000, loss: 0.205655
   Number of active neurons: 3
 >> iter 81000, loss: 0.090496
 >> iter 82000, loss: 0.161291
 >> iter 83000, loss: 0.573130
 >> iter 84000, loss: 0.233206
 >> iter 85000, loss: 0.195135
 >> iter 86000, loss: 0.183230
 >> iter 87000, loss: 0.126597
 >> iter 88000, loss: 0.139071
 >> iter 89000, loss: 0.104361
 >> iter 90000, loss: 0.125765
   Number of active neurons: 3
 >> iter 91000, loss: 0.059835
 >> iter 92000, loss: 0.111450
 >> iter 93000, loss: 0.054040
 >> iter 94000, loss: 0.207650
 >> iter 95000, loss: 0.090621
 >> iter 96000, loss: 0.354644
 >> iter 97000, loss: 0.270824
 >> iter 98000, loss: 0.224973
 >> iter 99000, loss: 0.097891
 >> iter 100000, loss: 0.126621
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.012285
 >> iter 2000, loss: 6.224417
 >> iter 3000, loss: 2.420644
 >> iter 4000, loss: 1.012425
 >> iter 5000, loss: 0.711712
 >> iter 6000, loss: 0.378838
 >> iter 7000, loss: 0.238167
 >> iter 8000, loss: 0.204681
 >> iter 9000, loss: 0.148233
 >> iter 10000, loss: 0.217082
   Number of active neurons: 4
 >> iter 11000, loss: 0.236432
 >> iter 12000, loss: 0.372577
 >> iter 13000, loss: 0.182175
 >> iter 14000, loss: 0.147258
 >> iter 15000, loss: 0.195614
 >> iter 16000, loss: 0.358015
 >> iter 17000, loss: 0.152895
 >> iter 18000, loss: 0.139781
 >> iter 19000, loss: 0.140514
 >> iter 20000, loss: 0.232154
   Number of active neurons: 3
 >> iter 21000, loss: 0.139731
 >> iter 22000, loss: 0.180235
 >> iter 23000, loss: 0.083009
 >> iter 24000, loss: 0.201420
 >> iter 25000, loss: 0.090872
 >> iter 26000, loss: 0.277793
 >> iter 27000, loss: 0.128226
 >> iter 28000, loss: 0.179773
 >> iter 29000, loss: 0.121093
 >> iter 30000, loss: 0.315398
   Number of active neurons: 3
 >> iter 31000, loss: 0.193922
 >> iter 32000, loss: 0.362108
 >> iter 33000, loss: 0.176768
 >> iter 34000, loss: 0.371256
 >> iter 35000, loss: 0.201000
 >> iter 36000, loss: 0.430963
 >> iter 37000, loss: 0.237693
 >> iter 38000, loss: 0.419714
 >> iter 39000, loss: 0.183531
 >> iter 40000, loss: 0.307583
   Number of active neurons: 3
 >> iter 41000, loss: 0.254513
 >> iter 42000, loss: 0.294198
 >> iter 43000, loss: 0.127374
 >> iter 44000, loss: 0.065469
 >> iter 45000, loss: 0.113203
 >> iter 46000, loss: 0.141494
 >> iter 47000, loss: 0.155113
 >> iter 48000, loss: 0.437522
 >> iter 49000, loss: 0.235870
 >> iter 50000, loss: 0.243053
   Number of active neurons: 3
 >> iter 51000, loss: 0.154068
 >> iter 52000, loss: 0.094597
 >> iter 53000, loss: 0.126807
 >> iter 54000, loss: 0.245659
 >> iter 55000, loss: 0.152934
 >> iter 56000, loss: 0.071834
 >> iter 57000, loss: 0.170107
 >> iter 58000, loss: 0.280005
 >> iter 59000, loss: 0.139085
 >> iter 60000, loss: 0.278855
   Number of active neurons: 3
 >> iter 61000, loss: 0.179738
 >> iter 62000, loss: 0.214974
 >> iter 63000, loss: 0.162668
 >> iter 64000, loss: 0.265380
 >> iter 65000, loss: 0.252619
 >> iter 66000, loss: 0.178928
 >> iter 67000, loss: 0.103114
 >> iter 68000, loss: 0.181309
 >> iter 69000, loss: 0.158567
 >> iter 70000, loss: 0.395866
   Number of active neurons: 3
 >> iter 71000, loss: 0.166149
 >> iter 72000, loss: 0.113396
 >> iter 73000, loss: 0.127273
 >> iter 74000, loss: 0.184906
 >> iter 75000, loss: 0.112559
 >> iter 76000, loss: 0.283642
 >> iter 77000, loss: 0.196867
 >> iter 78000, loss: 0.208586
 >> iter 79000, loss: 0.277599
 >> iter 80000, loss: 0.352768
   Number of active neurons: 3
 >> iter 81000, loss: 0.432311
 >> iter 82000, loss: 0.400626
 >> iter 83000, loss: 0.171131
 >> iter 84000, loss: 0.321778
 >> iter 85000, loss: 0.138989
 >> iter 86000, loss: 0.319030
 >> iter 87000, loss: 0.253969
 >> iter 88000, loss: 0.253213
 >> iter 89000, loss: 0.157531
 >> iter 90000, loss: 0.214455
   Number of active neurons: 3
 >> iter 91000, loss: 0.173347
 >> iter 92000, loss: 0.419158
 >> iter 93000, loss: 0.246060
 >> iter 94000, loss: 0.342495
 >> iter 95000, loss: 0.144921
 >> iter 96000, loss: 0.206402
 >> iter 97000, loss: 0.332921
 >> iter 98000, loss: 0.144996
 >> iter 99000, loss: 0.150196
 >> iter 100000, loss: 0.072321
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.102167
 >> iter 2000, loss: 6.879057
 >> iter 3000, loss: 2.568711
 >> iter 4000, loss: 0.969348
 >> iter 5000, loss: 0.456327
 >> iter 6000, loss: 0.433744
 >> iter 7000, loss: 0.202050
 >> iter 8000, loss: 0.101904
 >> iter 9000, loss: 0.093028
 >> iter 10000, loss: 0.150176
   Number of active neurons: 5
 >> iter 11000, loss: 0.228310
 >> iter 12000, loss: 0.137810
 >> iter 13000, loss: 0.181096
 >> iter 14000, loss: 0.225927
 >> iter 15000, loss: 0.123168
 >> iter 16000, loss: 0.124017
 >> iter 17000, loss: 0.086712
 >> iter 18000, loss: 0.093933
 >> iter 19000, loss: 0.073670
 >> iter 20000, loss: 0.256883
   Number of active neurons: 3
 >> iter 21000, loss: 0.404776
 >> iter 22000, loss: 0.266241
 >> iter 23000, loss: 0.115956
 >> iter 24000, loss: 0.133473
 >> iter 25000, loss: 0.063620
 >> iter 26000, loss: 0.157794
 >> iter 27000, loss: 0.071424
 >> iter 28000, loss: 0.049472
 >> iter 29000, loss: 0.054963
 >> iter 30000, loss: 0.065332
   Number of active neurons: 3
 >> iter 31000, loss: 0.142958
 >> iter 32000, loss: 0.074283
 >> iter 33000, loss: 0.102531
 >> iter 34000, loss: 0.314883
 >> iter 35000, loss: 0.132261
 >> iter 36000, loss: 0.078436
 >> iter 37000, loss: 0.089226
 >> iter 38000, loss: 0.170902
 >> iter 39000, loss: 0.093101
 >> iter 40000, loss: 0.226875
   Number of active neurons: 3
 >> iter 41000, loss: 0.185533
 >> iter 42000, loss: 0.197421
 >> iter 43000, loss: 0.121695
 >> iter 44000, loss: 0.239321
 >> iter 45000, loss: 0.102819
 >> iter 46000, loss: 0.115386
 >> iter 47000, loss: 0.055683
 >> iter 48000, loss: 0.150302
 >> iter 49000, loss: 0.068876
 >> iter 50000, loss: 0.111817
   Number of active neurons: 3
 >> iter 51000, loss: 0.054890
 >> iter 52000, loss: 0.122515
 >> iter 53000, loss: 0.219659
 >> iter 54000, loss: 0.175137
 >> iter 55000, loss: 0.078974
 >> iter 56000, loss: 0.162841
 >> iter 57000, loss: 0.203260
 >> iter 58000, loss: 0.171799
 >> iter 59000, loss: 0.139052
 >> iter 60000, loss: 0.194431
   Number of active neurons: 3
 >> iter 61000, loss: 0.087749
 >> iter 62000, loss: 0.234847
 >> iter 63000, loss: 0.213423
 >> iter 64000, loss: 0.172432
 >> iter 65000, loss: 0.079859
 >> iter 66000, loss: 0.579650
 >> iter 67000, loss: 0.235639
 >> iter 68000, loss: 0.230341
 >> iter 69000, loss: 0.101150
 >> iter 70000, loss: 0.168295
   Number of active neurons: 3
 >> iter 71000, loss: 0.097207
 >> iter 72000, loss: 0.158955
 >> iter 73000, loss: 0.331817
 >> iter 74000, loss: 0.236512
 >> iter 75000, loss: 0.102867
 >> iter 76000, loss: 0.055521
 >> iter 77000, loss: 0.036490
 >> iter 78000, loss: 0.156269
 >> iter 79000, loss: 0.198256
 >> iter 80000, loss: 0.360982
   Number of active neurons: 3
 >> iter 81000, loss: 0.150445
 >> iter 82000, loss: 0.187702
 >> iter 83000, loss: 0.084174
 >> iter 84000, loss: 0.146343
 >> iter 85000, loss: 0.067787
 >> iter 86000, loss: 0.323617
 >> iter 87000, loss: 0.180298
 >> iter 88000, loss: 0.329499
 >> iter 89000, loss: 0.140101
 >> iter 90000, loss: 0.211799
   Number of active neurons: 3
 >> iter 91000, loss: 0.096853
 >> iter 92000, loss: 0.429045
 >> iter 93000, loss: 0.177795
 >> iter 94000, loss: 0.138007
 >> iter 95000, loss: 0.066108
 >> iter 96000, loss: 0.156886
 >> iter 97000, loss: 0.091365
 >> iter 98000, loss: 0.291681
 >> iter 99000, loss: 0.123386
 >> iter 100000, loss: 0.072007
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

