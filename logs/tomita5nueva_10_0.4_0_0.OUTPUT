 > Problema: tomita5nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.4
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.625956
 >> iter 2000, loss: 10.552048
 >> iter 3000, loss: 8.671527
 >> iter 4000, loss: 7.960302
 >> iter 5000, loss: 7.698759
 >> iter 6000, loss: 7.570491
 >> iter 7000, loss: 7.260395
 >> iter 8000, loss: 6.466659
 >> iter 9000, loss: 5.809016
 >> iter 10000, loss: 5.371509
   Number of active neurons: 10
 >> iter 11000, loss: 4.773833
 >> iter 12000, loss: 5.072517
 >> iter 13000, loss: 2.126189
 >> iter 14000, loss: 0.811083
 >> iter 15000, loss: 0.339176
 >> iter 16000, loss: 0.177630
 >> iter 17000, loss: 0.108355
 >> iter 18000, loss: 0.049962
 >> iter 19000, loss: 0.038008
 >> iter 20000, loss: 0.021041
   Number of active neurons: 10
 >> iter 21000, loss: 0.015529
 >> iter 22000, loss: 0.010868
 >> iter 23000, loss: 0.008433
 >> iter 24000, loss: 0.007045
 >> iter 25000, loss: 0.027211
 >> iter 26000, loss: 0.013708
 >> iter 27000, loss: 0.008381
 >> iter 28000, loss: 0.006247
 >> iter 29000, loss: 0.005866
 >> iter 30000, loss: 0.004929
   Number of active neurons: 10
 >> iter 31000, loss: 0.004319
 >> iter 32000, loss: 0.003956
 >> iter 33000, loss: 0.004075
 >> iter 34000, loss: 0.003783
 >> iter 35000, loss: 0.003473
 >> iter 36000, loss: 0.003209
 >> iter 37000, loss: 0.003111
 >> iter 38000, loss: 0.002948
 >> iter 39000, loss: 0.002772
 >> iter 40000, loss: 0.002634
   Number of active neurons: 10
 >> iter 41000, loss: 0.002525
 >> iter 42000, loss: 0.002529
 >> iter 43000, loss: 0.002376
 >> iter 44000, loss: 0.002262
 >> iter 45000, loss: 0.002174
 >> iter 46000, loss: 0.002037
 >> iter 47000, loss: 0.001974
 >> iter 48000, loss: 0.001911
 >> iter 49000, loss: 0.001887
 >> iter 50000, loss: 0.001790
   Number of active neurons: 10
 >> iter 51000, loss: 0.001796
 >> iter 52000, loss: 0.001737
 >> iter 53000, loss: 0.001677
 >> iter 54000, loss: 0.001590
 >> iter 55000, loss: 0.001567
 >> iter 56000, loss: 0.001482
 >> iter 57000, loss: 0.001472
 >> iter 58000, loss: 0.001476
 >> iter 59000, loss: 0.001474
 >> iter 60000, loss: 0.001417
   Number of active neurons: 10
 >> iter 61000, loss: 0.001399
 >> iter 62000, loss: 0.001405
 >> iter 63000, loss: 0.001350
 >> iter 64000, loss: 0.001276
 >> iter 65000, loss: 0.001285
 >> iter 66000, loss: 0.001227
 >> iter 67000, loss: 0.001187
 >> iter 68000, loss: 0.001187
 >> iter 69000, loss: 0.001202
 >> iter 70000, loss: 0.001148
   Number of active neurons: 10
 >> iter 71000, loss: 0.001118
 >> iter 72000, loss: 0.001123
 >> iter 73000, loss: 0.001095
 >> iter 74000, loss: 0.001048
 >> iter 75000, loss: 0.001063
 >> iter 76000, loss: 0.001074
 >> iter 77000, loss: 0.001019
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.733233
 >> iter 2000, loss: 10.641839
 >> iter 3000, loss: 8.710924
 >> iter 4000, loss: 7.980090
 >> iter 5000, loss: 7.714669
 >> iter 6000, loss: 7.599035
 >> iter 7000, loss: 7.489927
 >> iter 8000, loss: 7.138687
 >> iter 9000, loss: 6.733160
 >> iter 10000, loss: 6.104868
   Number of active neurons: 10
 >> iter 11000, loss: 5.674789
 >> iter 12000, loss: 5.436562
 >> iter 13000, loss: 5.240839
 >> iter 14000, loss: 5.059777
 >> iter 15000, loss: 4.574056
 >> iter 16000, loss: 2.864931
 >> iter 17000, loss: 1.189985
 >> iter 18000, loss: 0.489923
 >> iter 19000, loss: 0.202617
 >> iter 20000, loss: 0.138559
   Number of active neurons: 10
 >> iter 21000, loss: 0.065870
 >> iter 22000, loss: 0.035690
 >> iter 23000, loss: 0.045836
 >> iter 24000, loss: 0.038069
 >> iter 25000, loss: 0.022336
 >> iter 26000, loss: 0.065380
 >> iter 27000, loss: 0.034451
 >> iter 28000, loss: 0.019122
 >> iter 29000, loss: 0.021664
 >> iter 30000, loss: 0.078018
   Number of active neurons: 10
 >> iter 31000, loss: 0.035414
 >> iter 32000, loss: 0.018614
 >> iter 33000, loss: 0.011682
 >> iter 34000, loss: 0.009777
 >> iter 35000, loss: 0.026968
 >> iter 36000, loss: 0.014683
 >> iter 37000, loss: 0.010353
 >> iter 38000, loss: 0.007856
 >> iter 39000, loss: 0.007358
 >> iter 40000, loss: 0.006216
   Number of active neurons: 10
 >> iter 41000, loss: 0.005309
 >> iter 42000, loss: 0.005069
 >> iter 43000, loss: 0.004535
 >> iter 44000, loss: 0.006444
 >> iter 45000, loss: 0.114827
 >> iter 46000, loss: 0.046286
 >> iter 47000, loss: 0.021762
 >> iter 48000, loss: 0.011175
 >> iter 49000, loss: 0.006728
 >> iter 50000, loss: 0.005073
   Number of active neurons: 10
 >> iter 51000, loss: 0.009557
 >> iter 52000, loss: 0.006394
 >> iter 53000, loss: 0.017586
 >> iter 54000, loss: 0.010648
 >> iter 55000, loss: 0.006720
 >> iter 56000, loss: 0.004866
 >> iter 57000, loss: 0.004143
 >> iter 58000, loss: 0.004615
 >> iter 59000, loss: 0.004553
 >> iter 60000, loss: 0.004139
   Number of active neurons: 10
 >> iter 61000, loss: 0.003953
 >> iter 62000, loss: 0.003721
 >> iter 63000, loss: 0.013994
 >> iter 64000, loss: 0.007672
 >> iter 65000, loss: 0.004770
 >> iter 66000, loss: 0.003541
 >> iter 67000, loss: 0.003061
 >> iter 68000, loss: 0.003097
 >> iter 69000, loss: 0.002645
 >> iter 70000, loss: 0.002589
   Number of active neurons: 10
 >> iter 71000, loss: 0.002424
 >> iter 72000, loss: 0.002298
 >> iter 73000, loss: 0.002227
 >> iter 74000, loss: 0.002170
 >> iter 75000, loss: 0.002166
 >> iter 76000, loss: 0.002277
 >> iter 77000, loss: 0.002130
 >> iter 78000, loss: 0.002289
 >> iter 79000, loss: 0.002087
 >> iter 80000, loss: 0.002077
   Number of active neurons: 10
 >> iter 81000, loss: 0.001929
 >> iter 82000, loss: 0.001842
 >> iter 83000, loss: 0.002732
 >> iter 84000, loss: 0.002285
 >> iter 85000, loss: 0.002481
 >> iter 86000, loss: 0.002076
 >> iter 87000, loss: 0.023777
 >> iter 88000, loss: 0.009957
 >> iter 89000, loss: 0.005232
 >> iter 90000, loss: 0.052458
   Number of active neurons: 10
 >> iter 91000, loss: 0.020726
 >> iter 92000, loss: 0.009805
 >> iter 93000, loss: 0.008686
 >> iter 94000, loss: 0.015420
 >> iter 95000, loss: 0.007458
 >> iter 96000, loss: 0.013647
 >> iter 97000, loss: 0.006386
 >> iter 98000, loss: 0.003711
 >> iter 99000, loss: 0.002651
 >> iter 100000, loss: 0.002284
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.649644
 >> iter 2000, loss: 10.564737
 >> iter 3000, loss: 8.686554
 >> iter 4000, loss: 7.973916
 >> iter 5000, loss: 7.707795
 >> iter 6000, loss: 7.597206
 >> iter 7000, loss: 7.561626
 >> iter 8000, loss: 7.389065
 >> iter 9000, loss: 6.810626
 >> iter 10000, loss: 6.004714
   Number of active neurons: 10
 >> iter 11000, loss: 5.536051
 >> iter 12000, loss: 4.678290
 >> iter 13000, loss: 1.869579
 >> iter 14000, loss: 0.717806
 >> iter 15000, loss: 0.283628
 >> iter 16000, loss: 0.117879
 >> iter 17000, loss: 0.054538
 >> iter 18000, loss: 0.029225
 >> iter 19000, loss: 0.018332
 >> iter 20000, loss: 0.024804
   Number of active neurons: 10
 >> iter 21000, loss: 0.017398
 >> iter 22000, loss: 0.040324
 >> iter 23000, loss: 0.026671
 >> iter 24000, loss: 0.015369
 >> iter 25000, loss: 0.010481
 >> iter 26000, loss: 0.008064
 >> iter 27000, loss: 0.033212
 >> iter 28000, loss: 0.016795
 >> iter 29000, loss: 0.009891
 >> iter 30000, loss: 0.007002
   Number of active neurons: 10
 >> iter 31000, loss: 0.005664
 >> iter 32000, loss: 0.005443
 >> iter 33000, loss: 0.004703
 >> iter 34000, loss: 0.004317
 >> iter 35000, loss: 0.004061
 >> iter 36000, loss: 0.003784
 >> iter 37000, loss: 0.003628
 >> iter 38000, loss: 0.003412
 >> iter 39000, loss: 0.003387
 >> iter 40000, loss: 0.036022
   Number of active neurons: 10
 >> iter 41000, loss: 0.046227
 >> iter 42000, loss: 0.033243
 >> iter 43000, loss: 0.015303
 >> iter 44000, loss: 0.008113
 >> iter 45000, loss: 0.005259
 >> iter 46000, loss: 0.004187
 >> iter 47000, loss: 0.003574
 >> iter 48000, loss: 0.003270
 >> iter 49000, loss: 0.003034
 >> iter 50000, loss: 0.002773
   Number of active neurons: 10
 >> iter 51000, loss: 0.002548
 >> iter 52000, loss: 0.002547
 >> iter 53000, loss: 0.002608
 >> iter 54000, loss: 0.002517
 >> iter 55000, loss: 0.002331
 >> iter 56000, loss: 0.002208
 >> iter 57000, loss: 0.002098
 >> iter 58000, loss: 0.002003
 >> iter 59000, loss: 0.001942
 >> iter 60000, loss: 0.001892
   Number of active neurons: 10
 >> iter 61000, loss: 0.001886
 >> iter 62000, loss: 0.001784
 >> iter 63000, loss: 0.001777
 >> iter 64000, loss: 0.001763
 >> iter 65000, loss: 0.001676
 >> iter 66000, loss: 0.001763
 >> iter 67000, loss: 0.001600
 >> iter 68000, loss: 0.001589
 >> iter 69000, loss: 0.001592
 >> iter 70000, loss: 0.001523
   Number of active neurons: 10
 >> iter 71000, loss: 0.001481
 >> iter 72000, loss: 0.001470
 >> iter 73000, loss: 0.001406
 >> iter 74000, loss: 0.001375
 >> iter 75000, loss: 0.001354
 >> iter 76000, loss: 0.001337
 >> iter 77000, loss: 0.004807
 >> iter 78000, loss: 0.002818
 >> iter 79000, loss: 0.002057
 >> iter 80000, loss: 0.001643
   Number of active neurons: 10
 >> iter 81000, loss: 0.001431
 >> iter 82000, loss: 0.001340
 >> iter 83000, loss: 0.095652
 >> iter 84000, loss: 0.038012
 >> iter 85000, loss: 0.015240
 >> iter 86000, loss: 0.006738
 >> iter 87000, loss: 0.003481
 >> iter 88000, loss: 0.002221
 >> iter 89000, loss: 0.011223
 >> iter 90000, loss: 0.005384
   Number of active neurons: 10
 >> iter 91000, loss: 0.003009
 >> iter 92000, loss: 0.002124
 >> iter 93000, loss: 0.001798
 >> iter 94000, loss: 0.001598
 >> iter 95000, loss: 0.001385
 >> iter 96000, loss: 0.001377
 >> iter 97000, loss: 0.002192
 >> iter 98000, loss: 0.001760
 >> iter 99000, loss: 0.001423
 >> iter 100000, loss: 0.001319
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.739217
 >> iter 2000, loss: 10.610554
 >> iter 3000, loss: 8.693290
 >> iter 4000, loss: 7.967229
 >> iter 5000, loss: 7.708049
 >> iter 6000, loss: 7.604486
 >> iter 7000, loss: 7.553889
 >> iter 8000, loss: 7.265869
 >> iter 9000, loss: 6.839259
 >> iter 10000, loss: 6.148812
   Number of active neurons: 10
 >> iter 11000, loss: 5.694084
 >> iter 12000, loss: 5.330814
 >> iter 13000, loss: 5.008890
 >> iter 14000, loss: 4.933062
 >> iter 15000, loss: 3.274882
 >> iter 16000, loss: 1.382004
 >> iter 17000, loss: 0.615088
 >> iter 18000, loss: 0.244563
 >> iter 19000, loss: 0.102146
 >> iter 20000, loss: 0.050240
   Number of active neurons: 10
 >> iter 21000, loss: 0.025896
 >> iter 22000, loss: 0.018971
 >> iter 23000, loss: 0.012657
 >> iter 24000, loss: 0.009905
 >> iter 25000, loss: 0.008214
 >> iter 26000, loss: 0.006866
 >> iter 27000, loss: 0.006690
 >> iter 28000, loss: 0.006529
 >> iter 29000, loss: 0.005419
 >> iter 30000, loss: 0.005154
   Number of active neurons: 10
 >> iter 31000, loss: 0.004593
 >> iter 32000, loss: 0.004172
 >> iter 33000, loss: 0.003890
 >> iter 34000, loss: 0.003594
 >> iter 35000, loss: 0.003433
 >> iter 36000, loss: 0.003163
 >> iter 37000, loss: 0.003022
 >> iter 38000, loss: 0.002917
 >> iter 39000, loss: 0.002766
 >> iter 40000, loss: 0.002628
   Number of active neurons: 10
 >> iter 41000, loss: 0.002678
 >> iter 42000, loss: 0.002524
 >> iter 43000, loss: 0.002813
 >> iter 44000, loss: 0.002559
 >> iter 45000, loss: 0.002429
 >> iter 46000, loss: 0.002210
 >> iter 47000, loss: 0.002115
 >> iter 48000, loss: 0.002004
 >> iter 49000, loss: 0.001971
 >> iter 50000, loss: 0.001884
   Number of active neurons: 10
 >> iter 51000, loss: 0.001832
 >> iter 52000, loss: 0.001786
 >> iter 53000, loss: 0.001781
 >> iter 54000, loss: 0.001714
 >> iter 55000, loss: 0.001635
 >> iter 56000, loss: 0.001615
 >> iter 57000, loss: 0.001560
 >> iter 58000, loss: 0.001521
 >> iter 59000, loss: 0.001462
 >> iter 60000, loss: 0.001450
   Number of active neurons: 10
 >> iter 61000, loss: 0.001420
 >> iter 62000, loss: 0.001445
 >> iter 63000, loss: 0.001393
 >> iter 64000, loss: 0.001376
 >> iter 65000, loss: 0.001548
 >> iter 66000, loss: 0.001592
 >> iter 67000, loss: 0.001382
 >> iter 68000, loss: 0.001309
 >> iter 69000, loss: 0.001444
 >> iter 70000, loss: 0.001396
   Number of active neurons: 10
 >> iter 71000, loss: 0.149017
 >> iter 72000, loss: 0.056023
 >> iter 73000, loss: 0.021729
 >> iter 74000, loss: 0.009067
 >> iter 75000, loss: 0.004317
 >> iter 76000, loss: 0.043192
 >> iter 77000, loss: 0.017133
 >> iter 78000, loss: 0.007451
 >> iter 79000, loss: 0.003839
 >> iter 80000, loss: 0.002395
   Number of active neurons: 10
 >> iter 81000, loss: 0.001787
 >> iter 82000, loss: 0.001541
 >> iter 83000, loss: 0.001443
 >> iter 84000, loss: 0.001431
 >> iter 85000, loss: 0.001316
 >> iter 86000, loss: 0.001280
 >> iter 87000, loss: 0.001268
 >> iter 88000, loss: 0.001236
 >> iter 89000, loss: 0.001394
 >> iter 90000, loss: 0.001270
   Number of active neurons: 10
 >> iter 91000, loss: 0.001249
 >> iter 92000, loss: 0.001171
 >> iter 93000, loss: 0.001112
 >> iter 94000, loss: 0.001083
 >> iter 95000, loss: 0.001098
 >> iter 96000, loss: 0.001063
 >> iter 97000, loss: 0.001062
 >> iter 98000, loss: 0.001024
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 15.708546
 >> iter 2000, loss: 10.592867
 >> iter 3000, loss: 8.695144
 >> iter 4000, loss: 7.972542
 >> iter 5000, loss: 7.717794
 >> iter 6000, loss: 7.639503
 >> iter 7000, loss: 7.590716
 >> iter 8000, loss: 7.558098
 >> iter 9000, loss: 7.535148
 >> iter 10000, loss: 7.187002
   Number of active neurons: 10
 >> iter 11000, loss: 6.338293
 >> iter 12000, loss: 5.769306
 >> iter 13000, loss: 5.459901
 >> iter 14000, loss: 4.529849
 >> iter 15000, loss: 1.899150
 >> iter 16000, loss: 0.769807
 >> iter 17000, loss: 0.316729
 >> iter 18000, loss: 0.130157
 >> iter 19000, loss: 0.058507
 >> iter 20000, loss: 0.030285
   Number of active neurons: 10
 >> iter 21000, loss: 0.018363
 >> iter 22000, loss: 0.035178
 >> iter 23000, loss: 0.019023
 >> iter 24000, loss: 0.012422
 >> iter 25000, loss: 0.009280
 >> iter 26000, loss: 0.007855
 >> iter 27000, loss: 0.006822
 >> iter 28000, loss: 0.006350
 >> iter 29000, loss: 0.005979
 >> iter 30000, loss: 0.006056
   Number of active neurons: 10
 >> iter 31000, loss: 0.048200
 >> iter 32000, loss: 0.021593
 >> iter 33000, loss: 0.010962
 >> iter 34000, loss: 0.006909
 >> iter 35000, loss: 0.005294
 >> iter 36000, loss: 0.004444
 >> iter 37000, loss: 0.003956
 >> iter 38000, loss: 0.003648
 >> iter 39000, loss: 0.030665
 >> iter 40000, loss: 0.013733
   Number of active neurons: 10
 >> iter 41000, loss: 0.007352
 >> iter 42000, loss: 0.004875
 >> iter 43000, loss: 0.003902
 >> iter 44000, loss: 0.003328
 >> iter 45000, loss: 0.003112
 >> iter 46000, loss: 0.002986
 >> iter 47000, loss: 0.002816
 >> iter 48000, loss: 0.002655
 >> iter 49000, loss: 0.002490
 >> iter 50000, loss: 0.002632
   Number of active neurons: 10
 >> iter 51000, loss: 0.002450
 >> iter 52000, loss: 0.002418
 >> iter 53000, loss: 0.002745
 >> iter 54000, loss: 0.002472
 >> iter 55000, loss: 0.002233
 >> iter 56000, loss: 0.002179
 >> iter 57000, loss: 0.003468
 >> iter 58000, loss: 0.002739
 >> iter 59000, loss: 0.002365
 >> iter 60000, loss: 0.002100
   Number of active neurons: 10
 >> iter 61000, loss: 0.001955
 >> iter 62000, loss: 0.001853
 >> iter 63000, loss: 0.001835
 >> iter 64000, loss: 0.019757
 >> iter 65000, loss: 0.008531
 >> iter 66000, loss: 0.004364
 >> iter 67000, loss: 0.003008
 >> iter 68000, loss: 0.002335
 >> iter 69000, loss: 0.001970
 >> iter 70000, loss: 0.001843
   Number of active neurons: 10
 >> iter 71000, loss: 0.001826
 >> iter 72000, loss: 0.001654
 >> iter 73000, loss: 0.001591
 >> iter 74000, loss: 0.001522
 >> iter 75000, loss: 0.001499
 >> iter 76000, loss: 0.001474
 >> iter 77000, loss: 0.001409
 >> iter 78000, loss: 0.001396
 >> iter 79000, loss: 0.001345
 >> iter 80000, loss: 0.001314
   Number of active neurons: 10
 >> iter 81000, loss: 0.001297
 >> iter 82000, loss: 0.001302
 >> iter 83000, loss: 0.001259
 >> iter 84000, loss: 0.001230
 >> iter 85000, loss: 0.001224
 >> iter 86000, loss: 0.001209
 >> iter 87000, loss: 0.002200
 >> iter 88000, loss: 0.013664
 >> iter 89000, loss: 0.006011
 >> iter 90000, loss: 0.003283
   Number of active neurons: 10
 >> iter 91000, loss: 0.002106
 >> iter 92000, loss: 0.001742
 >> iter 93000, loss: 0.001479
 >> iter 94000, loss: 0.001309
 >> iter 95000, loss: 0.001241
 >> iter 96000, loss: 0.001411
 >> iter 97000, loss: 0.001236
 >> iter 98000, loss: 0.001194
 >> iter 99000, loss: 0.001115
 >> iter 100000, loss: 0.001118
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.652605
 >> iter 2000, loss: 10.556473
 >> iter 3000, loss: 8.664620
 >> iter 4000, loss: 7.942798
 >> iter 5000, loss: 7.684792
 >> iter 6000, loss: 7.565643
 >> iter 7000, loss: 7.273681
 >> iter 8000, loss: 6.599993
 >> iter 9000, loss: 5.969729
 >> iter 10000, loss: 5.547133
   Number of active neurons: 10
 >> iter 11000, loss: 5.317713
 >> iter 12000, loss: 4.984850
 >> iter 13000, loss: 2.228837
 >> iter 14000, loss: 0.935325
 >> iter 15000, loss: 0.391762
 >> iter 16000, loss: 0.207887
 >> iter 17000, loss: 0.094205
 >> iter 18000, loss: 0.049873
 >> iter 19000, loss: 0.037345
 >> iter 20000, loss: 0.024642
   Number of active neurons: 10
 >> iter 21000, loss: 0.018433
 >> iter 22000, loss: 0.013930
 >> iter 23000, loss: 0.012140
 >> iter 24000, loss: 0.009891
 >> iter 25000, loss: 0.022729
 >> iter 26000, loss: 0.098176
 >> iter 27000, loss: 0.041575
 >> iter 28000, loss: 0.019663
 >> iter 29000, loss: 0.011275
 >> iter 30000, loss: 0.007789
   Number of active neurons: 10
 >> iter 31000, loss: 0.006152
 >> iter 32000, loss: 0.005514
 >> iter 33000, loss: 0.004998
 >> iter 34000, loss: 0.004847
 >> iter 35000, loss: 0.004682
 >> iter 36000, loss: 0.004316
 >> iter 37000, loss: 0.004096
 >> iter 38000, loss: 0.003925
 >> iter 39000, loss: 0.003600
 >> iter 40000, loss: 0.003376
   Number of active neurons: 10
 >> iter 41000, loss: 0.003321
 >> iter 42000, loss: 0.003560
 >> iter 43000, loss: 0.003501
 >> iter 44000, loss: 0.003387
 >> iter 45000, loss: 0.029672
 >> iter 46000, loss: 0.013243
 >> iter 47000, loss: 0.007001
 >> iter 48000, loss: 0.004424
 >> iter 49000, loss: 0.003427
 >> iter 50000, loss: 0.003208
   Number of active neurons: 10
 >> iter 51000, loss: 0.017234
 >> iter 52000, loss: 0.008155
 >> iter 53000, loss: 0.004596
 >> iter 54000, loss: 0.003269
 >> iter 55000, loss: 0.002690
 >> iter 56000, loss: 0.002410
 >> iter 57000, loss: 0.002437
 >> iter 58000, loss: 0.002351
 >> iter 59000, loss: 0.002109
 >> iter 60000, loss: 0.002035
   Number of active neurons: 10
 >> iter 61000, loss: 0.001963
 >> iter 62000, loss: 0.002033
 >> iter 63000, loss: 0.001939
 >> iter 64000, loss: 0.001844
 >> iter 65000, loss: 0.001782
 >> iter 66000, loss: 0.001804
 >> iter 67000, loss: 0.001808
 >> iter 68000, loss: 0.001762
 >> iter 69000, loss: 0.023343
 >> iter 70000, loss: 0.075480
   Number of active neurons: 10
 >> iter 71000, loss: 0.035719
 >> iter 72000, loss: 0.014741
 >> iter 73000, loss: 0.007143
 >> iter 74000, loss: 0.003902
 >> iter 75000, loss: 0.002616
 >> iter 76000, loss: 0.002135
 >> iter 77000, loss: 0.001812
 >> iter 78000, loss: 0.001680
 >> iter 79000, loss: 0.001598
 >> iter 80000, loss: 0.001564
   Number of active neurons: 10
 >> iter 81000, loss: 0.001539
 >> iter 82000, loss: 0.001538
 >> iter 83000, loss: 0.001474
 >> iter 84000, loss: 0.001714
 >> iter 85000, loss: 0.001552
 >> iter 86000, loss: 0.001548
 >> iter 87000, loss: 0.001467
 >> iter 88000, loss: 0.001505
 >> iter 89000, loss: 0.001375
 >> iter 90000, loss: 0.001338
   Number of active neurons: 10
 >> iter 91000, loss: 0.001293
 >> iter 92000, loss: 0.001509
 >> iter 93000, loss: 0.001344
 >> iter 94000, loss: 0.046728
 >> iter 95000, loss: 0.018116
 >> iter 96000, loss: 0.007530
 >> iter 97000, loss: 0.003790
 >> iter 98000, loss: 0.002220
 >> iter 99000, loss: 0.001615
 >> iter 100000, loss: 0.001375
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.654503
 >> iter 2000, loss: 10.550196
 >> iter 3000, loss: 8.665456
 >> iter 4000, loss: 7.960035
 >> iter 5000, loss: 7.706370
 >> iter 6000, loss: 7.595422
 >> iter 7000, loss: 7.555988
 >> iter 8000, loss: 7.336023
 >> iter 9000, loss: 6.979190
 >> iter 10000, loss: 6.268618
   Number of active neurons: 10
 >> iter 11000, loss: 5.674689
 >> iter 12000, loss: 5.110857
 >> iter 13000, loss: 2.517684
 >> iter 14000, loss: 1.064543
 >> iter 15000, loss: 0.515211
 >> iter 16000, loss: 0.301407
 >> iter 17000, loss: 0.127276
 >> iter 18000, loss: 0.058685
 >> iter 19000, loss: 0.045423
 >> iter 20000, loss: 0.025879
   Number of active neurons: 10
 >> iter 21000, loss: 0.017348
 >> iter 22000, loss: 0.042950
 >> iter 23000, loss: 0.022460
 >> iter 24000, loss: 0.013782
 >> iter 25000, loss: 0.045897
 >> iter 26000, loss: 0.022366
 >> iter 27000, loss: 0.013233
 >> iter 28000, loss: 0.013705
 >> iter 29000, loss: 0.009137
 >> iter 30000, loss: 0.006829
   Number of active neurons: 10
 >> iter 31000, loss: 0.005509
 >> iter 32000, loss: 0.004797
 >> iter 33000, loss: 0.011035
 >> iter 34000, loss: 0.006943
 >> iter 35000, loss: 0.008670
 >> iter 36000, loss: 0.005726
 >> iter 37000, loss: 0.004420
 >> iter 38000, loss: 0.003789
 >> iter 39000, loss: 0.003447
 >> iter 40000, loss: 0.094839
   Number of active neurons: 10
 >> iter 41000, loss: 0.037715
 >> iter 42000, loss: 0.016119
 >> iter 43000, loss: 0.007943
 >> iter 44000, loss: 0.004844
 >> iter 45000, loss: 0.003954
 >> iter 46000, loss: 0.003292
 >> iter 47000, loss: 0.002996
 >> iter 48000, loss: 0.002716
 >> iter 49000, loss: 0.002515
 >> iter 50000, loss: 0.049660
   Number of active neurons: 10
 >> iter 51000, loss: 0.114145
 >> iter 52000, loss: 0.044104
 >> iter 53000, loss: 0.018124
 >> iter 54000, loss: 0.008472
 >> iter 55000, loss: 0.004750
 >> iter 56000, loss: 0.063961
 >> iter 57000, loss: 0.025502
 >> iter 58000, loss: 0.027461
 >> iter 59000, loss: 0.014497
 >> iter 60000, loss: 0.007205
   Number of active neurons: 10
 >> iter 61000, loss: 0.004211
 >> iter 62000, loss: 0.003034
 >> iter 63000, loss: 0.002501
 >> iter 64000, loss: 0.002210
 >> iter 65000, loss: 0.002036
 >> iter 66000, loss: 0.001950
 >> iter 67000, loss: 0.021630
 >> iter 68000, loss: 0.009384
 >> iter 69000, loss: 0.028182
 >> iter 70000, loss: 0.011773
   Number of active neurons: 10
 >> iter 71000, loss: 0.005567
 >> iter 72000, loss: 0.003231
 >> iter 73000, loss: 0.002393
 >> iter 74000, loss: 0.002092
 >> iter 75000, loss: 0.001907
 >> iter 76000, loss: 0.001783
 >> iter 77000, loss: 0.001667
 >> iter 78000, loss: 0.001683
 >> iter 79000, loss: 0.001562
 >> iter 80000, loss: 0.001543
   Number of active neurons: 10
 >> iter 81000, loss: 0.001494
 >> iter 82000, loss: 0.001519
 >> iter 83000, loss: 0.001442
 >> iter 84000, loss: 0.007881
 >> iter 85000, loss: 0.015170
 >> iter 86000, loss: 0.006580
 >> iter 87000, loss: 0.003338
 >> iter 88000, loss: 0.002095
 >> iter 89000, loss: 0.001731
 >> iter 90000, loss: 0.001503
   Number of active neurons: 10
 >> iter 91000, loss: 0.001361
 >> iter 92000, loss: 0.001314
 >> iter 93000, loss: 0.001306
 >> iter 94000, loss: 0.001275
 >> iter 95000, loss: 0.001216
 >> iter 96000, loss: 0.001163
 >> iter 97000, loss: 0.006080
 >> iter 98000, loss: 0.003072
 >> iter 99000, loss: 0.001881
 >> iter 100000, loss: 0.023998
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.720215
 >> iter 2000, loss: 10.551257
 >> iter 3000, loss: 8.648818
 >> iter 4000, loss: 7.928610
 >> iter 5000, loss: 7.672879
 >> iter 6000, loss: 7.408529
 >> iter 7000, loss: 6.975862
 >> iter 8000, loss: 6.267532
 >> iter 9000, loss: 5.787202
 >> iter 10000, loss: 5.555999
   Number of active neurons: 10
 >> iter 11000, loss: 2.454051
 >> iter 12000, loss: 1.047205
 >> iter 13000, loss: 0.450317
 >> iter 14000, loss: 0.215455
 >> iter 15000, loss: 0.102824
 >> iter 16000, loss: 0.129762
 >> iter 17000, loss: 0.059872
 >> iter 18000, loss: 0.031439
 >> iter 19000, loss: 0.020114
 >> iter 20000, loss: 0.048847
   Number of active neurons: 10
 >> iter 21000, loss: 0.025417
 >> iter 22000, loss: 0.015718
 >> iter 23000, loss: 0.011834
 >> iter 24000, loss: 0.029821
 >> iter 25000, loss: 0.017913
 >> iter 26000, loss: 0.011381
 >> iter 27000, loss: 0.032250
 >> iter 28000, loss: 0.016631
 >> iter 29000, loss: 0.021003
 >> iter 30000, loss: 0.011801
   Number of active neurons: 10
 >> iter 31000, loss: 0.007963
 >> iter 32000, loss: 0.006220
 >> iter 33000, loss: 0.056036
 >> iter 34000, loss: 0.024305
 >> iter 35000, loss: 0.012118
 >> iter 36000, loss: 0.007440
 >> iter 37000, loss: 0.005391
 >> iter 38000, loss: 0.004634
 >> iter 39000, loss: 0.004249
 >> iter 40000, loss: 0.004072
   Number of active neurons: 10
 >> iter 41000, loss: 0.003808
 >> iter 42000, loss: 0.003762
 >> iter 43000, loss: 0.003414
 >> iter 44000, loss: 0.003286
 >> iter 45000, loss: 0.003218
 >> iter 46000, loss: 0.003047
 >> iter 47000, loss: 0.002988
 >> iter 48000, loss: 0.002960
 >> iter 49000, loss: 0.002736
 >> iter 50000, loss: 0.002631
   Number of active neurons: 10
 >> iter 51000, loss: 0.002525
 >> iter 52000, loss: 0.002600
 >> iter 53000, loss: 0.002525
 >> iter 54000, loss: 0.002378
 >> iter 55000, loss: 0.002292
 >> iter 56000, loss: 0.002307
 >> iter 57000, loss: 0.002265
 >> iter 58000, loss: 0.002979
 >> iter 59000, loss: 0.002673
 >> iter 60000, loss: 0.002325
   Number of active neurons: 10
 >> iter 61000, loss: 0.002084
 >> iter 62000, loss: 0.002274
 >> iter 63000, loss: 0.002458
 >> iter 64000, loss: 0.002121
 >> iter 65000, loss: 0.001952
 >> iter 66000, loss: 0.001876
 >> iter 67000, loss: 0.001786
 >> iter 68000, loss: 0.001757
 >> iter 69000, loss: 0.001732
 >> iter 70000, loss: 0.001752
   Number of active neurons: 10
 >> iter 71000, loss: 0.001684
 >> iter 72000, loss: 0.001598
 >> iter 73000, loss: 0.001617
 >> iter 74000, loss: 0.001514
 >> iter 75000, loss: 0.001547
 >> iter 76000, loss: 0.001508
 >> iter 77000, loss: 0.001423
 >> iter 78000, loss: 0.001407
 >> iter 79000, loss: 0.001406
 >> iter 80000, loss: 0.001414
   Number of active neurons: 10
 >> iter 81000, loss: 0.001325
 >> iter 82000, loss: 0.001350
 >> iter 83000, loss: 0.001335
 >> iter 84000, loss: 0.001261
 >> iter 85000, loss: 0.001269
 >> iter 86000, loss: 0.001241
 >> iter 87000, loss: 0.001230
 >> iter 88000, loss: 0.001229
 >> iter 89000, loss: 0.001231
 >> iter 90000, loss: 0.001265
   Number of active neurons: 10
 >> iter 91000, loss: 0.001238
 >> iter 92000, loss: 0.001168
 >> iter 93000, loss: 0.001316
 >> iter 94000, loss: 0.001168
 >> iter 95000, loss: 0.001116
 >> iter 96000, loss: 0.001131
 >> iter 97000, loss: 0.001079
 >> iter 98000, loss: 0.001067
 >> iter 99000, loss: 0.001067
 >> iter 100000, loss: 0.001040
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.635369
 >> iter 2000, loss: 10.565786
 >> iter 3000, loss: 8.676132
 >> iter 4000, loss: 7.952797
 >> iter 5000, loss: 7.694999
 >> iter 6000, loss: 7.589793
 >> iter 7000, loss: 7.465998
 >> iter 8000, loss: 6.951583
 >> iter 9000, loss: 6.005623
 >> iter 10000, loss: 2.319255
   Number of active neurons: 10
 >> iter 11000, loss: 0.906670
 >> iter 12000, loss: 0.371532
 >> iter 13000, loss: 0.165583
 >> iter 14000, loss: 0.072824
 >> iter 15000, loss: 0.035808
 >> iter 16000, loss: 0.020830
 >> iter 17000, loss: 0.022833
 >> iter 18000, loss: 0.014775
 >> iter 19000, loss: 0.038324
 >> iter 20000, loss: 0.019713
   Number of active neurons: 10
 >> iter 21000, loss: 0.011977
 >> iter 22000, loss: 0.008564
 >> iter 23000, loss: 0.006981
 >> iter 24000, loss: 0.006031
 >> iter 25000, loss: 0.005762
 >> iter 26000, loss: 0.005196
 >> iter 27000, loss: 0.005275
 >> iter 28000, loss: 0.004957
 >> iter 29000, loss: 0.004497
 >> iter 30000, loss: 0.004089
   Number of active neurons: 10
 >> iter 31000, loss: 0.003867
 >> iter 32000, loss: 0.003891
 >> iter 33000, loss: 0.003619
 >> iter 34000, loss: 0.003380
 >> iter 35000, loss: 0.106946
 >> iter 36000, loss: 0.146321
 >> iter 37000, loss: 0.057463
 >> iter 38000, loss: 0.024048
 >> iter 39000, loss: 0.011387
 >> iter 40000, loss: 0.006536
   Number of active neurons: 10
 >> iter 41000, loss: 0.004631
 >> iter 42000, loss: 0.003774
 >> iter 43000, loss: 0.003316
 >> iter 44000, loss: 0.003071
 >> iter 45000, loss: 0.002901
 >> iter 46000, loss: 0.002718
 >> iter 47000, loss: 0.002625
 >> iter 48000, loss: 0.002552
 >> iter 49000, loss: 0.002473
 >> iter 50000, loss: 0.002383
   Number of active neurons: 10
 >> iter 51000, loss: 0.002330
 >> iter 52000, loss: 0.002236
 >> iter 53000, loss: 0.002263
 >> iter 54000, loss: 0.002145
 >> iter 55000, loss: 0.002087
 >> iter 56000, loss: 0.002018
 >> iter 57000, loss: 0.001939
 >> iter 58000, loss: 0.001860
 >> iter 59000, loss: 0.001814
 >> iter 60000, loss: 0.001758
   Number of active neurons: 10
 >> iter 61000, loss: 0.001744
 >> iter 62000, loss: 0.001686
 >> iter 63000, loss: 0.001654
 >> iter 64000, loss: 0.001612
 >> iter 65000, loss: 0.001581
 >> iter 66000, loss: 0.001553
 >> iter 67000, loss: 0.001522
 >> iter 68000, loss: 0.001471
 >> iter 69000, loss: 0.001458
 >> iter 70000, loss: 0.001463
   Number of active neurons: 10
 >> iter 71000, loss: 0.001411
 >> iter 72000, loss: 0.001373
 >> iter 73000, loss: 0.001419
 >> iter 74000, loss: 0.001370
 >> iter 75000, loss: 0.001380
 >> iter 76000, loss: 0.001308
 >> iter 77000, loss: 0.001306
 >> iter 78000, loss: 0.001264
 >> iter 79000, loss: 0.001971
 >> iter 80000, loss: 0.001754
   Number of active neurons: 10
 >> iter 81000, loss: 0.001584
 >> iter 82000, loss: 0.001392
 >> iter 83000, loss: 0.001307
 >> iter 84000, loss: 0.001260
 >> iter 85000, loss: 0.001467
 >> iter 86000, loss: 0.001291
 >> iter 87000, loss: 0.001186
 >> iter 88000, loss: 0.001151
 >> iter 89000, loss: 0.001110
 >> iter 90000, loss: 0.003602
   Number of active neurons: 10
 >> iter 91000, loss: 0.026312
 >> iter 92000, loss: 0.010775
 >> iter 93000, loss: 0.004821
 >> iter 94000, loss: 0.002581
 >> iter 95000, loss: 0.001734
 >> iter 96000, loss: 0.001383
 >> iter 97000, loss: 0.001250
 >> iter 98000, loss: 0.001205
 >> iter 99000, loss: 0.001135
 >> iter 100000, loss: 0.001139
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.665731
 >> iter 2000, loss: 10.581092
 >> iter 3000, loss: 8.567294
 >> iter 4000, loss: 7.486580
 >> iter 5000, loss: 6.603697
 >> iter 6000, loss: 5.680239
 >> iter 7000, loss: 4.924086
 >> iter 8000, loss: 2.051288
 >> iter 9000, loss: 0.857667
 >> iter 10000, loss: 0.346089
   Number of active neurons: 10
 >> iter 11000, loss: 0.361542
 >> iter 12000, loss: 0.181370
 >> iter 13000, loss: 0.165879
 >> iter 14000, loss: 0.088890
 >> iter 15000, loss: 0.049049
 >> iter 16000, loss: 0.027481
 >> iter 17000, loss: 0.018177
 >> iter 18000, loss: 0.013194
 >> iter 19000, loss: 0.035759
 >> iter 20000, loss: 0.077808
   Number of active neurons: 10
 >> iter 21000, loss: 0.040615
 >> iter 22000, loss: 0.029481
 >> iter 23000, loss: 0.019512
 >> iter 24000, loss: 0.012612
 >> iter 25000, loss: 0.009112
 >> iter 26000, loss: 0.007351
 >> iter 27000, loss: 0.006223
 >> iter 28000, loss: 0.005418
 >> iter 29000, loss: 0.004859
 >> iter 30000, loss: 0.004460
   Number of active neurons: 10
 >> iter 31000, loss: 0.004135
 >> iter 32000, loss: 0.003991
 >> iter 33000, loss: 0.003763
 >> iter 34000, loss: 0.003579
 >> iter 35000, loss: 0.003434
 >> iter 36000, loss: 0.003268
 >> iter 37000, loss: 0.003130
 >> iter 38000, loss: 0.003173
 >> iter 39000, loss: 0.002955
 >> iter 40000, loss: 0.002813
   Number of active neurons: 10
 >> iter 41000, loss: 0.002677
 >> iter 42000, loss: 0.002552
 >> iter 43000, loss: 0.002549
 >> iter 44000, loss: 0.002425
 >> iter 45000, loss: 0.002375
 >> iter 46000, loss: 0.002351
 >> iter 47000, loss: 0.002215
 >> iter 48000, loss: 0.002124
 >> iter 49000, loss: 0.004644
 >> iter 50000, loss: 0.014720
   Number of active neurons: 10
 >> iter 51000, loss: 0.007332
 >> iter 52000, loss: 0.011230
 >> iter 53000, loss: 0.005649
 >> iter 54000, loss: 0.016054
 >> iter 55000, loss: 0.007357
 >> iter 56000, loss: 0.004086
 >> iter 57000, loss: 0.017219
 >> iter 58000, loss: 0.007669
 >> iter 59000, loss: 0.004104
 >> iter 60000, loss: 0.002708
   Number of active neurons: 10
 >> iter 61000, loss: 0.002077
 >> iter 62000, loss: 0.001838
 >> iter 63000, loss: 0.001721
 >> iter 64000, loss: 0.001623
 >> iter 65000, loss: 0.001578
 >> iter 66000, loss: 0.001514
 >> iter 67000, loss: 0.001466
 >> iter 68000, loss: 0.001401
 >> iter 69000, loss: 0.001413
 >> iter 70000, loss: 0.001375
   Number of active neurons: 10
 >> iter 71000, loss: 0.001346
 >> iter 72000, loss: 0.001310
 >> iter 73000, loss: 0.001340
 >> iter 74000, loss: 0.001288
 >> iter 75000, loss: 0.001217
 >> iter 76000, loss: 0.001230
 >> iter 77000, loss: 0.001192
 >> iter 78000, loss: 0.001154
 >> iter 79000, loss: 0.001168
 >> iter 80000, loss: 0.001160
   Number of active neurons: 10
 >> iter 81000, loss: 0.001137
 >> iter 82000, loss: 0.001105
 >> iter 83000, loss: 0.001080
 >> iter 84000, loss: 0.001072
 >> iter 85000, loss: 0.001039
 >> iter 86000, loss: 0.001016
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.638025
 >> iter 2000, loss: 10.545241
 >> iter 3000, loss: 8.649954
 >> iter 4000, loss: 7.926914
 >> iter 5000, loss: 7.668168
 >> iter 6000, loss: 7.537793
 >> iter 7000, loss: 7.323890
 >> iter 8000, loss: 6.932943
 >> iter 9000, loss: 6.746470
 >> iter 10000, loss: 6.599772
   Number of active neurons: 9
 >> iter 11000, loss: 6.295944
 >> iter 12000, loss: 5.881829
 >> iter 13000, loss: 5.505600
 >> iter 14000, loss: 5.028177
 >> iter 15000, loss: 4.602676
 >> iter 16000, loss: 4.330677
 >> iter 17000, loss: 4.439571
 >> iter 18000, loss: 2.330315
 >> iter 19000, loss: 1.087648
 >> iter 20000, loss: 0.506293
   Number of active neurons: 10
 >> iter 21000, loss: 0.250914
 >> iter 22000, loss: 0.229752
 >> iter 23000, loss: 0.128464
 >> iter 24000, loss: 0.165033
 >> iter 25000, loss: 0.194390
 >> iter 26000, loss: 0.181101
 >> iter 27000, loss: 0.099425
 >> iter 28000, loss: 0.058084
 >> iter 29000, loss: 0.688223
 >> iter 30000, loss: 0.389452
   Number of active neurons: 10
 >> iter 31000, loss: 0.172487
 >> iter 32000, loss: 0.086572
 >> iter 33000, loss: 0.103078
 >> iter 34000, loss: 0.055603
 >> iter 35000, loss: 0.132069
 >> iter 36000, loss: 0.093261
 >> iter 37000, loss: 0.055232
 >> iter 38000, loss: 0.191825
 >> iter 39000, loss: 0.087311
 >> iter 40000, loss: 0.047069
   Number of active neurons: 10
 >> iter 41000, loss: 0.039276
 >> iter 42000, loss: 0.028154
 >> iter 43000, loss: 0.106831
 >> iter 44000, loss: 0.183372
 >> iter 45000, loss: 0.320143
 >> iter 46000, loss: 0.166723
 >> iter 47000, loss: 0.131063
 >> iter 48000, loss: 0.095958
 >> iter 49000, loss: 0.048505
 >> iter 50000, loss: 0.028213
   Number of active neurons: 10
 >> iter 51000, loss: 0.020054
 >> iter 52000, loss: 0.017307
 >> iter 53000, loss: 0.033266
 >> iter 54000, loss: 0.039794
 >> iter 55000, loss: 0.080775
 >> iter 56000, loss: 0.038466
 >> iter 57000, loss: 0.039076
 >> iter 58000, loss: 0.021958
 >> iter 59000, loss: 0.015395
 >> iter 60000, loss: 0.012199
   Number of active neurons: 10
 >> iter 61000, loss: 0.014091
 >> iter 62000, loss: 0.012282
 >> iter 63000, loss: 0.111970
 >> iter 64000, loss: 0.254991
 >> iter 65000, loss: 0.157815
 >> iter 66000, loss: 0.065809
 >> iter 67000, loss: 0.053656
 >> iter 68000, loss: 0.067931
 >> iter 69000, loss: 0.032648
 >> iter 70000, loss: 0.018689
   Number of active neurons: 10
 >> iter 71000, loss: 0.014289
 >> iter 72000, loss: 0.011644
 >> iter 73000, loss: 0.010536
 >> iter 74000, loss: 0.009378
 >> iter 75000, loss: 0.010823
 >> iter 76000, loss: 0.009046
 >> iter 77000, loss: 0.008128
 >> iter 78000, loss: 0.010086
 >> iter 79000, loss: 0.061401
 >> iter 80000, loss: 0.027762
   Number of active neurons: 10
 >> iter 81000, loss: 0.015065
 >> iter 82000, loss: 0.009814
 >> iter 83000, loss: 0.008251
 >> iter 84000, loss: 0.295722
 >> iter 85000, loss: 0.117053
 >> iter 86000, loss: 0.049838
 >> iter 87000, loss: 0.023266
 >> iter 88000, loss: 0.013219
 >> iter 89000, loss: 0.009828
 >> iter 90000, loss: 0.007971
   Number of active neurons: 10
 >> iter 91000, loss: 0.007444
 >> iter 92000, loss: 0.008154
 >> iter 93000, loss: 0.006816
 >> iter 94000, loss: 0.006462
 >> iter 95000, loss: 0.206609
 >> iter 96000, loss: 0.082081
 >> iter 97000, loss: 0.070737
 >> iter 98000, loss: 0.030349
 >> iter 99000, loss: 0.015114
 >> iter 100000, loss: 0.009241
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 15.636660
 >> iter 2000, loss: 10.568177
 >> iter 3000, loss: 8.682776
 >> iter 4000, loss: 7.897363
 >> iter 5000, loss: 7.193850
 >> iter 6000, loss: 6.397468
 >> iter 7000, loss: 5.772055
 >> iter 8000, loss: 2.733139
 >> iter 9000, loss: 1.078018
 >> iter 10000, loss: 0.416342
   Number of active neurons: 10
 >> iter 11000, loss: 0.166878
 >> iter 12000, loss: 0.071734
 >> iter 13000, loss: 0.035917
 >> iter 14000, loss: 0.028573
 >> iter 15000, loss: 0.043820
 >> iter 16000, loss: 0.022385
 >> iter 17000, loss: 0.013653
 >> iter 18000, loss: 0.009737
 >> iter 19000, loss: 0.008013
 >> iter 20000, loss: 0.006971
   Number of active neurons: 10
 >> iter 21000, loss: 0.006178
 >> iter 22000, loss: 0.005761
 >> iter 23000, loss: 0.128941
 >> iter 24000, loss: 0.051622
 >> iter 25000, loss: 0.023209
 >> iter 26000, loss: 0.012163
 >> iter 27000, loss: 0.007617
 >> iter 28000, loss: 0.005538
 >> iter 29000, loss: 0.004964
 >> iter 30000, loss: 0.004169
   Number of active neurons: 10
 >> iter 31000, loss: 0.004272
 >> iter 32000, loss: 0.003933
 >> iter 33000, loss: 0.054849
 >> iter 34000, loss: 0.022798
 >> iter 35000, loss: 0.010647
 >> iter 36000, loss: 0.010424
 >> iter 37000, loss: 0.005748
 >> iter 38000, loss: 0.004095
 >> iter 39000, loss: 0.003292
 >> iter 40000, loss: 0.002923
   Number of active neurons: 10
 >> iter 41000, loss: 0.002723
 >> iter 42000, loss: 0.002510
 >> iter 43000, loss: 0.002399
 >> iter 44000, loss: 0.002301
 >> iter 45000, loss: 0.002188
 >> iter 46000, loss: 0.002267
 >> iter 47000, loss: 0.002179
 >> iter 48000, loss: 0.002092
 >> iter 49000, loss: 0.002476
 >> iter 50000, loss: 0.002094
   Number of active neurons: 10
 >> iter 51000, loss: 0.001996
 >> iter 52000, loss: 0.001945
 >> iter 53000, loss: 0.002260
 >> iter 54000, loss: 0.002086
 >> iter 55000, loss: 0.002031
 >> iter 56000, loss: 0.001860
 >> iter 57000, loss: 0.001794
 >> iter 58000, loss: 0.001655
 >> iter 59000, loss: 0.001575
 >> iter 60000, loss: 0.001504
   Number of active neurons: 10
 >> iter 61000, loss: 0.001461
 >> iter 62000, loss: 0.001454
 >> iter 63000, loss: 0.001459
 >> iter 64000, loss: 0.001362
 >> iter 65000, loss: 0.001356
 >> iter 66000, loss: 0.001339
 >> iter 67000, loss: 0.001412
 >> iter 68000, loss: 0.001330
 >> iter 69000, loss: 0.001300
 >> iter 70000, loss: 0.001251
   Number of active neurons: 10
 >> iter 71000, loss: 0.001208
 >> iter 72000, loss: 0.001209
 >> iter 73000, loss: 0.018124
 >> iter 74000, loss: 0.007565
 >> iter 75000, loss: 0.003808
 >> iter 76000, loss: 0.002243
 >> iter 77000, loss: 0.001605
 >> iter 78000, loss: 0.001337
 >> iter 79000, loss: 0.001225
 >> iter 80000, loss: 0.001260
   Number of active neurons: 10
 >> iter 81000, loss: 0.001187
 >> iter 82000, loss: 0.001134
 >> iter 83000, loss: 0.001088
 >> iter 84000, loss: 0.001058
 >> iter 85000, loss: 0.001037
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.731181
 >> iter 2000, loss: 10.586592
 >> iter 3000, loss: 8.759380
 >> iter 4000, loss: 8.003802
 >> iter 5000, loss: 7.632709
 >> iter 6000, loss: 6.984973
 >> iter 7000, loss: 6.150814
 >> iter 8000, loss: 5.729126
 >> iter 9000, loss: 5.512810
 >> iter 10000, loss: 5.236123
   Number of active neurons: 10
 >> iter 11000, loss: 4.885237
 >> iter 12000, loss: 4.432263
 >> iter 13000, loss: 4.443582
 >> iter 14000, loss: 4.287794
 >> iter 15000, loss: 2.998444
 >> iter 16000, loss: 1.227167
 >> iter 17000, loss: 0.518416
 >> iter 18000, loss: 0.317187
 >> iter 19000, loss: 0.138507
 >> iter 20000, loss: 0.134754
   Number of active neurons: 10
 >> iter 21000, loss: 0.146151
 >> iter 22000, loss: 0.127768
 >> iter 23000, loss: 0.203589
 >> iter 24000, loss: 0.087712
 >> iter 25000, loss: 0.041927
 >> iter 26000, loss: 0.064681
 >> iter 27000, loss: 0.045157
 >> iter 28000, loss: 0.058750
 >> iter 29000, loss: 0.037263
 >> iter 30000, loss: 0.033964
   Number of active neurons: 10
 >> iter 31000, loss: 0.017241
 >> iter 32000, loss: 0.010814
 >> iter 33000, loss: 0.007704
 >> iter 34000, loss: 0.006513
 >> iter 35000, loss: 0.005705
 >> iter 36000, loss: 0.005346
 >> iter 37000, loss: 0.065443
 >> iter 38000, loss: 0.028789
 >> iter 39000, loss: 0.013878
 >> iter 40000, loss: 0.010315
   Number of active neurons: 10
 >> iter 41000, loss: 0.006551
 >> iter 42000, loss: 0.005003
 >> iter 43000, loss: 0.004126
 >> iter 44000, loss: 0.003769
 >> iter 45000, loss: 0.003462
 >> iter 46000, loss: 0.003571
 >> iter 47000, loss: 0.003246
 >> iter 48000, loss: 0.016107
 >> iter 49000, loss: 0.007893
 >> iter 50000, loss: 0.010815
   Number of active neurons: 10
 >> iter 51000, loss: 0.006034
 >> iter 52000, loss: 0.004219
 >> iter 53000, loss: 0.014368
 >> iter 54000, loss: 0.012439
 >> iter 55000, loss: 0.056095
 >> iter 56000, loss: 0.022665
 >> iter 57000, loss: 0.010127
 >> iter 58000, loss: 0.005981
 >> iter 59000, loss: 0.007080
 >> iter 60000, loss: 0.004958
   Number of active neurons: 10
 >> iter 61000, loss: 0.003470
 >> iter 62000, loss: 0.002693
 >> iter 63000, loss: 0.002473
 >> iter 64000, loss: 0.168070
 >> iter 65000, loss: 0.065609
 >> iter 66000, loss: 0.026460
 >> iter 67000, loss: 0.021076
 >> iter 68000, loss: 0.010606
 >> iter 69000, loss: 0.024488
 >> iter 70000, loss: 0.010656
   Number of active neurons: 10
 >> iter 71000, loss: 0.005395
 >> iter 72000, loss: 0.003586
 >> iter 73000, loss: 0.063284
 >> iter 74000, loss: 0.048867
 >> iter 75000, loss: 0.020126
 >> iter 76000, loss: 0.009261
 >> iter 77000, loss: 0.005164
 >> iter 78000, loss: 0.003581
 >> iter 79000, loss: 0.003363
 >> iter 80000, loss: 0.002736
   Number of active neurons: 10
 >> iter 81000, loss: 0.032656
 >> iter 82000, loss: 0.015039
 >> iter 83000, loss: 0.007464
 >> iter 84000, loss: 0.004289
 >> iter 85000, loss: 0.003079
 >> iter 86000, loss: 0.002464
 >> iter 87000, loss: 0.002170
 >> iter 88000, loss: 0.002031
 >> iter 89000, loss: 0.001959
 >> iter 90000, loss: 0.001831
   Number of active neurons: 10
 >> iter 91000, loss: 0.001736
 >> iter 92000, loss: 0.051051
 >> iter 93000, loss: 0.042419
 >> iter 94000, loss: 0.017162
 >> iter 95000, loss: 0.008055
 >> iter 96000, loss: 0.004280
 >> iter 97000, loss: 0.002802
 >> iter 98000, loss: 0.002200
 >> iter 99000, loss: 0.001963
 >> iter 100000, loss: 0.001782
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 15.651553
 >> iter 2000, loss: 10.572623
 >> iter 3000, loss: 8.682782
 >> iter 4000, loss: 7.961363
 >> iter 5000, loss: 7.707115
 >> iter 6000, loss: 7.595222
 >> iter 7000, loss: 7.563650
 >> iter 8000, loss: 7.539466
 >> iter 9000, loss: 7.536218
 >> iter 10000, loss: 7.527764
   Number of active neurons: 6
 >> iter 11000, loss: 7.535495
 >> iter 12000, loss: 7.521707
 >> iter 13000, loss: 7.520901
 >> iter 14000, loss: 7.278864
 >> iter 15000, loss: 6.864818
 >> iter 16000, loss: 6.114181
 >> iter 17000, loss: 5.819960
 >> iter 18000, loss: 5.198953
 >> iter 19000, loss: 3.389785
 >> iter 20000, loss: 1.323443
   Number of active neurons: 10
 >> iter 21000, loss: 0.536788
 >> iter 22000, loss: 0.230361
 >> iter 23000, loss: 0.100493
 >> iter 24000, loss: 0.048297
 >> iter 25000, loss: 0.042056
 >> iter 26000, loss: 0.023798
 >> iter 27000, loss: 0.016014
 >> iter 28000, loss: 0.025218
 >> iter 29000, loss: 0.103508
 >> iter 30000, loss: 0.044790
   Number of active neurons: 10
 >> iter 31000, loss: 0.022234
 >> iter 32000, loss: 0.024176
 >> iter 33000, loss: 0.031080
 >> iter 34000, loss: 0.016071
 >> iter 35000, loss: 0.010409
 >> iter 36000, loss: 0.007681
 >> iter 37000, loss: 0.006312
 >> iter 38000, loss: 0.005627
 >> iter 39000, loss: 0.005986
 >> iter 40000, loss: 0.005332
   Number of active neurons: 10
 >> iter 41000, loss: 0.004858
 >> iter 42000, loss: 0.004403
 >> iter 43000, loss: 0.022572
 >> iter 44000, loss: 0.011231
 >> iter 45000, loss: 0.006536
 >> iter 46000, loss: 0.007423
 >> iter 47000, loss: 0.004892
 >> iter 48000, loss: 0.147373
 >> iter 49000, loss: 0.057573
 >> iter 50000, loss: 0.023881
   Number of active neurons: 10
 >> iter 51000, loss: 0.011291
 >> iter 52000, loss: 0.006390
 >> iter 53000, loss: 0.004415
 >> iter 54000, loss: 0.003583
 >> iter 55000, loss: 0.003065
 >> iter 56000, loss: 0.003372
 >> iter 57000, loss: 0.002869
 >> iter 58000, loss: 0.015551
 >> iter 59000, loss: 0.007733
 >> iter 60000, loss: 0.004417
   Number of active neurons: 10
 >> iter 61000, loss: 0.003327
 >> iter 62000, loss: 0.002761
 >> iter 63000, loss: 0.002461
 >> iter 64000, loss: 0.002262
 >> iter 65000, loss: 0.002171
 >> iter 66000, loss: 0.002261
 >> iter 67000, loss: 0.002177
 >> iter 68000, loss: 0.002079
 >> iter 69000, loss: 0.002024
 >> iter 70000, loss: 0.001867
   Number of active neurons: 10
 >> iter 71000, loss: 0.001837
 >> iter 72000, loss: 0.001821
 >> iter 73000, loss: 0.001742
 >> iter 74000, loss: 0.015495
 >> iter 75000, loss: 0.007149
 >> iter 76000, loss: 0.003806
 >> iter 77000, loss: 0.002578
 >> iter 78000, loss: 0.002088
 >> iter 79000, loss: 0.001756
 >> iter 80000, loss: 0.001606
   Number of active neurons: 10
 >> iter 81000, loss: 0.076278
 >> iter 82000, loss: 0.029435
 >> iter 83000, loss: 0.051411
 >> iter 84000, loss: 0.020258
 >> iter 85000, loss: 0.008560
 >> iter 86000, loss: 0.004266
 >> iter 87000, loss: 0.002640
 >> iter 88000, loss: 0.002009
 >> iter 89000, loss: 0.001727
 >> iter 90000, loss: 0.001614
   Number of active neurons: 10
 >> iter 91000, loss: 0.001521
 >> iter 92000, loss: 0.001599
 >> iter 93000, loss: 0.001425
 >> iter 94000, loss: 0.020169
 >> iter 95000, loss: 0.008368
 >> iter 96000, loss: 0.003936
 >> iter 97000, loss: 0.002276
 >> iter 98000, loss: 0.001671
 >> iter 99000, loss: 0.001522
 >> iter 100000, loss: 0.001360
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.663926
 >> iter 2000, loss: 10.564260
 >> iter 3000, loss: 8.672279
 >> iter 4000, loss: 7.952554
 >> iter 5000, loss: 7.692275
 >> iter 6000, loss: 7.580499
 >> iter 7000, loss: 7.541641
 >> iter 8000, loss: 7.398353
 >> iter 9000, loss: 6.989764
 >> iter 10000, loss: 6.165212
   Number of active neurons: 10
 >> iter 11000, loss: 5.484902
 >> iter 12000, loss: 2.301719
 >> iter 13000, loss: 0.995218
 >> iter 14000, loss: 0.392942
 >> iter 15000, loss: 0.160110
 >> iter 16000, loss: 0.071984
 >> iter 17000, loss: 0.036483
 >> iter 18000, loss: 0.025600
 >> iter 19000, loss: 0.017826
 >> iter 20000, loss: 0.012908
   Number of active neurons: 10
 >> iter 21000, loss: 0.010152
 >> iter 22000, loss: 0.008283
 >> iter 23000, loss: 0.007256
 >> iter 24000, loss: 0.006625
 >> iter 25000, loss: 0.005860
 >> iter 26000, loss: 0.005357
 >> iter 27000, loss: 0.004960
 >> iter 28000, loss: 0.004886
 >> iter 29000, loss: 0.004759
 >> iter 30000, loss: 0.004560
   Number of active neurons: 10
 >> iter 31000, loss: 0.004229
 >> iter 32000, loss: 0.003962
 >> iter 33000, loss: 0.047556
 >> iter 34000, loss: 0.020333
 >> iter 35000, loss: 0.009973
 >> iter 36000, loss: 0.006038
 >> iter 37000, loss: 0.004342
 >> iter 38000, loss: 0.004007
 >> iter 39000, loss: 0.003482
 >> iter 40000, loss: 0.003237
   Number of active neurons: 10
 >> iter 41000, loss: 0.003244
 >> iter 42000, loss: 0.002952
 >> iter 43000, loss: 0.004895
 >> iter 44000, loss: 0.023428
 >> iter 45000, loss: 0.010552
 >> iter 46000, loss: 0.005609
 >> iter 47000, loss: 0.003617
 >> iter 48000, loss: 0.002826
 >> iter 49000, loss: 0.002448
 >> iter 50000, loss: 0.002296
   Number of active neurons: 10
 >> iter 51000, loss: 0.002195
 >> iter 52000, loss: 0.002204
 >> iter 53000, loss: 0.002088
 >> iter 54000, loss: 0.001977
 >> iter 55000, loss: 0.001877
 >> iter 56000, loss: 0.001820
 >> iter 57000, loss: 0.002018
 >> iter 58000, loss: 0.001854
 >> iter 59000, loss: 0.001766
 >> iter 60000, loss: 0.001714
   Number of active neurons: 10
 >> iter 61000, loss: 0.001683
 >> iter 62000, loss: 0.001652
 >> iter 63000, loss: 0.001609
 >> iter 64000, loss: 0.001665
 >> iter 65000, loss: 0.001549
 >> iter 66000, loss: 0.001514
 >> iter 67000, loss: 0.001473
 >> iter 68000, loss: 0.001528
 >> iter 69000, loss: 0.001540
 >> iter 70000, loss: 0.001541
   Number of active neurons: 10
 >> iter 71000, loss: 0.001441
 >> iter 72000, loss: 0.001464
 >> iter 73000, loss: 0.001408
 >> iter 74000, loss: 0.001332
 >> iter 75000, loss: 0.001313
 >> iter 76000, loss: 0.001285
 >> iter 77000, loss: 0.001257
 >> iter 78000, loss: 0.001238
 >> iter 79000, loss: 0.001260
 >> iter 80000, loss: 0.097278
   Number of active neurons: 10
 >> iter 81000, loss: 0.054846
 >> iter 82000, loss: 0.035387
 >> iter 83000, loss: 0.014133
 >> iter 84000, loss: 0.006209
 >> iter 85000, loss: 0.003241
 >> iter 86000, loss: 0.002151
 >> iter 87000, loss: 0.001658
 >> iter 88000, loss: 0.008053
 >> iter 89000, loss: 0.003893
 >> iter 90000, loss: 0.002307
   Number of active neurons: 10
 >> iter 91000, loss: 0.001724
 >> iter 92000, loss: 0.001489
 >> iter 93000, loss: 0.001362
 >> iter 94000, loss: 0.001249
 >> iter 95000, loss: 0.001380
 >> iter 96000, loss: 0.001236
 >> iter 97000, loss: 0.001166
 >> iter 98000, loss: 0.001151
 >> iter 99000, loss: 0.001235
 >> iter 100000, loss: 0.001133
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.696580
 >> iter 2000, loss: 10.558736
 >> iter 3000, loss: 8.668827
 >> iter 4000, loss: 7.980920
 >> iter 5000, loss: 7.706884
 >> iter 6000, loss: 7.594415
 >> iter 7000, loss: 7.562356
 >> iter 8000, loss: 7.538029
 >> iter 9000, loss: 7.540075
 >> iter 10000, loss: 7.529794
   Number of active neurons: 6
 >> iter 11000, loss: 7.534402
 >> iter 12000, loss: 7.418287
 >> iter 13000, loss: 7.047879
 >> iter 14000, loss: 6.311314
 >> iter 15000, loss: 5.741345
 >> iter 16000, loss: 3.992287
 >> iter 17000, loss: 1.693255
 >> iter 18000, loss: 0.870964
 >> iter 19000, loss: 0.442519
 >> iter 20000, loss: 0.236312
   Number of active neurons: 10
 >> iter 21000, loss: 0.120310
 >> iter 22000, loss: 0.301332
 >> iter 23000, loss: 0.139662
 >> iter 24000, loss: 0.066662
 >> iter 25000, loss: 0.037159
 >> iter 26000, loss: 0.036105
 >> iter 27000, loss: 0.050262
 >> iter 28000, loss: 0.027548
 >> iter 29000, loss: 0.019394
 >> iter 30000, loss: 0.014858
   Number of active neurons: 10
 >> iter 31000, loss: 0.017571
 >> iter 32000, loss: 0.013267
 >> iter 33000, loss: 0.010650
 >> iter 34000, loss: 0.202610
 >> iter 35000, loss: 0.083531
 >> iter 36000, loss: 0.036894
 >> iter 37000, loss: 0.019269
 >> iter 38000, loss: 0.012013
 >> iter 39000, loss: 0.084419
 >> iter 40000, loss: 0.057837
   Number of active neurons: 10
 >> iter 41000, loss: 0.059594
 >> iter 42000, loss: 0.026679
 >> iter 43000, loss: 0.013518
 >> iter 44000, loss: 0.008664
 >> iter 45000, loss: 0.006519
 >> iter 46000, loss: 0.005489
 >> iter 47000, loss: 0.004947
 >> iter 48000, loss: 0.004631
 >> iter 49000, loss: 0.045919
 >> iter 50000, loss: 0.020275
   Number of active neurons: 10
 >> iter 51000, loss: 0.010227
 >> iter 52000, loss: 0.006344
 >> iter 53000, loss: 0.004850
 >> iter 54000, loss: 0.003999
 >> iter 55000, loss: 0.003710
 >> iter 56000, loss: 0.004196
 >> iter 57000, loss: 0.004449
 >> iter 58000, loss: 0.003773
 >> iter 59000, loss: 0.003380
 >> iter 60000, loss: 0.003079
   Number of active neurons: 10
 >> iter 61000, loss: 0.002998
 >> iter 62000, loss: 0.003134
 >> iter 63000, loss: 0.002901
 >> iter 64000, loss: 0.002788
 >> iter 65000, loss: 0.002590
 >> iter 66000, loss: 0.002487
 >> iter 67000, loss: 0.002388
 >> iter 68000, loss: 0.010332
 >> iter 69000, loss: 0.005295
 >> iter 70000, loss: 0.003642
   Number of active neurons: 10
 >> iter 71000, loss: 0.002716
 >> iter 72000, loss: 0.002383
 >> iter 73000, loss: 0.002128
 >> iter 74000, loss: 0.002126
 >> iter 75000, loss: 0.002028
 >> iter 76000, loss: 0.001873
 >> iter 77000, loss: 0.001852
 >> iter 78000, loss: 0.001918
 >> iter 79000, loss: 0.001901
 >> iter 80000, loss: 0.001805
   Number of active neurons: 10
 >> iter 81000, loss: 0.002826
 >> iter 82000, loss: 0.002185
 >> iter 83000, loss: 0.001846
 >> iter 84000, loss: 0.101824
 >> iter 85000, loss: 0.038849
 >> iter 86000, loss: 0.015541
 >> iter 87000, loss: 0.006870
 >> iter 88000, loss: 0.003674
 >> iter 89000, loss: 0.002382
 >> iter 90000, loss: 0.001934
   Number of active neurons: 10
 >> iter 91000, loss: 0.001731
 >> iter 92000, loss: 0.001596
 >> iter 93000, loss: 0.001581
 >> iter 94000, loss: 0.001504
 >> iter 95000, loss: 0.001472
 >> iter 96000, loss: 0.001900
 >> iter 97000, loss: 0.001598
 >> iter 98000, loss: 0.001435
 >> iter 99000, loss: 0.001432
 >> iter 100000, loss: 0.001334
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.709772
 >> iter 2000, loss: 10.599680
 >> iter 3000, loss: 8.871902
 >> iter 4000, loss: 8.063225
 >> iter 5000, loss: 7.769594
 >> iter 6000, loss: 7.640528
 >> iter 7000, loss: 7.500886
 >> iter 8000, loss: 7.150995
 >> iter 9000, loss: 6.544991
 >> iter 10000, loss: 5.933138
   Number of active neurons: 10
 >> iter 11000, loss: 5.611110
 >> iter 12000, loss: 5.492892
 >> iter 13000, loss: 5.331994
 >> iter 14000, loss: 4.961927
 >> iter 15000, loss: 2.061830
 >> iter 16000, loss: 0.948239
 >> iter 17000, loss: 0.393777
 >> iter 18000, loss: 0.160859
 >> iter 19000, loss: 0.072832
 >> iter 20000, loss: 0.057153
   Number of active neurons: 10
 >> iter 21000, loss: 0.035381
 >> iter 22000, loss: 0.039369
 >> iter 23000, loss: 0.021879
 >> iter 24000, loss: 0.013497
 >> iter 25000, loss: 0.033564
 >> iter 26000, loss: 0.017066
 >> iter 27000, loss: 0.010868
 >> iter 28000, loss: 0.007972
 >> iter 29000, loss: 0.033406
 >> iter 30000, loss: 0.076149
   Number of active neurons: 10
 >> iter 31000, loss: 0.031822
 >> iter 32000, loss: 0.015133
 >> iter 33000, loss: 0.165794
 >> iter 34000, loss: 0.065626
 >> iter 35000, loss: 0.027952
 >> iter 36000, loss: 0.013606
 >> iter 37000, loss: 0.229457
 >> iter 38000, loss: 0.089793
 >> iter 39000, loss: 0.037332
 >> iter 40000, loss: 0.017428
   Number of active neurons: 10
 >> iter 41000, loss: 0.009823
 >> iter 42000, loss: 0.053859
 >> iter 43000, loss: 0.023477
 >> iter 44000, loss: 0.011708
 >> iter 45000, loss: 0.007161
 >> iter 46000, loss: 0.005203
 >> iter 47000, loss: 0.004305
 >> iter 48000, loss: 0.029234
 >> iter 49000, loss: 0.013431
 >> iter 50000, loss: 0.007275
   Number of active neurons: 10
 >> iter 51000, loss: 0.004827
 >> iter 52000, loss: 0.003752
 >> iter 53000, loss: 0.003276
 >> iter 54000, loss: 0.003131
 >> iter 55000, loss: 0.003016
 >> iter 56000, loss: 0.002746
 >> iter 57000, loss: 0.002590
 >> iter 58000, loss: 0.002447
 >> iter 59000, loss: 0.002368
 >> iter 60000, loss: 0.002361
   Number of active neurons: 10
 >> iter 61000, loss: 0.002214
 >> iter 62000, loss: 0.002135
 >> iter 63000, loss: 0.002115
 >> iter 64000, loss: 0.002044
 >> iter 65000, loss: 0.001955
 >> iter 66000, loss: 0.001869
 >> iter 67000, loss: 0.001955
 >> iter 68000, loss: 0.001850
 >> iter 69000, loss: 0.001793
 >> iter 70000, loss: 0.002057
   Number of active neurons: 10
 >> iter 71000, loss: 0.001976
 >> iter 72000, loss: 0.001832
 >> iter 73000, loss: 0.001729
 >> iter 74000, loss: 0.001664
 >> iter 75000, loss: 0.001678
 >> iter 76000, loss: 0.001554
 >> iter 77000, loss: 0.001543
 >> iter 78000, loss: 0.001534
 >> iter 79000, loss: 0.001471
 >> iter 80000, loss: 0.001412
   Number of active neurons: 10
 >> iter 81000, loss: 0.001353
 >> iter 82000, loss: 0.001374
 >> iter 83000, loss: 0.001326
 >> iter 84000, loss: 0.001390
 >> iter 85000, loss: 0.001309
 >> iter 86000, loss: 0.001246
 >> iter 87000, loss: 0.001212
 >> iter 88000, loss: 0.001219
 >> iter 89000, loss: 0.001175
 >> iter 90000, loss: 0.009291
   Number of active neurons: 10
 >> iter 91000, loss: 0.005983
 >> iter 92000, loss: 0.003081
 >> iter 93000, loss: 0.001968
 >> iter 94000, loss: 0.001584
 >> iter 95000, loss: 0.001371
 >> iter 96000, loss: 0.001241
 >> iter 97000, loss: 0.001192
 >> iter 98000, loss: 0.001163
 >> iter 99000, loss: 0.001071
 >> iter 100000, loss: 0.001057
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 15.732826
 >> iter 2000, loss: 10.615355
 >> iter 3000, loss: 8.737881
 >> iter 4000, loss: 8.020981
 >> iter 5000, loss: 7.764383
 >> iter 6000, loss: 7.654099
 >> iter 7000, loss: 7.609545
 >> iter 8000, loss: 7.574228
 >> iter 9000, loss: 7.417605
 >> iter 10000, loss: 7.000355
   Number of active neurons: 10
 >> iter 11000, loss: 6.586258
 >> iter 12000, loss: 5.954994
 >> iter 13000, loss: 4.167167
 >> iter 14000, loss: 1.695915
 >> iter 15000, loss: 0.682965
 >> iter 16000, loss: 0.272611
 >> iter 17000, loss: 0.115223
 >> iter 18000, loss: 0.055259
 >> iter 19000, loss: 0.030492
 >> iter 20000, loss: 0.019858
   Number of active neurons: 10
 >> iter 21000, loss: 0.015077
 >> iter 22000, loss: 0.011879
 >> iter 23000, loss: 0.009936
 >> iter 24000, loss: 0.009161
 >> iter 25000, loss: 0.008072
 >> iter 26000, loss: 0.007381
 >> iter 27000, loss: 0.006680
 >> iter 28000, loss: 0.006206
 >> iter 29000, loss: 0.005886
 >> iter 30000, loss: 0.005445
   Number of active neurons: 10
 >> iter 31000, loss: 0.005412
 >> iter 32000, loss: 0.005052
 >> iter 33000, loss: 0.004798
 >> iter 34000, loss: 0.004578
 >> iter 35000, loss: 0.004292
 >> iter 36000, loss: 0.004092
 >> iter 37000, loss: 0.004880
 >> iter 38000, loss: 0.004651
 >> iter 39000, loss: 0.004282
 >> iter 40000, loss: 0.003898
   Number of active neurons: 10
 >> iter 41000, loss: 0.004036
 >> iter 42000, loss: 0.003547
 >> iter 43000, loss: 0.003266
 >> iter 44000, loss: 0.003095
 >> iter 45000, loss: 0.003003
 >> iter 46000, loss: 0.002959
 >> iter 47000, loss: 0.002777
 >> iter 48000, loss: 0.002660
 >> iter 49000, loss: 0.002581
 >> iter 50000, loss: 0.016054
   Number of active neurons: 10
 >> iter 51000, loss: 0.007988
 >> iter 52000, loss: 0.005230
 >> iter 53000, loss: 0.003699
 >> iter 54000, loss: 0.002921
 >> iter 55000, loss: 0.002769
 >> iter 56000, loss: 0.002468
 >> iter 57000, loss: 0.002260
 >> iter 58000, loss: 0.002261
 >> iter 59000, loss: 0.002137
 >> iter 60000, loss: 0.002064
   Number of active neurons: 10
 >> iter 61000, loss: 0.002010
 >> iter 62000, loss: 0.002009
 >> iter 63000, loss: 0.001911
 >> iter 64000, loss: 0.002064
 >> iter 65000, loss: 0.001950
 >> iter 66000, loss: 0.001847
 >> iter 67000, loss: 0.001876
 >> iter 68000, loss: 0.001726
 >> iter 69000, loss: 0.001760
 >> iter 70000, loss: 0.001829
   Number of active neurons: 10
 >> iter 71000, loss: 0.001677
 >> iter 72000, loss: 0.001630
 >> iter 73000, loss: 0.001563
 >> iter 74000, loss: 0.001526
 >> iter 75000, loss: 0.001488
 >> iter 76000, loss: 0.072382
 >> iter 77000, loss: 0.027918
 >> iter 78000, loss: 0.017230
 >> iter 79000, loss: 0.007419
 >> iter 80000, loss: 0.003853
   Number of active neurons: 10
 >> iter 81000, loss: 0.002397
 >> iter 82000, loss: 0.001838
 >> iter 83000, loss: 0.001646
 >> iter 84000, loss: 0.001550
 >> iter 85000, loss: 0.001430
 >> iter 86000, loss: 0.001391
 >> iter 87000, loss: 0.001348
 >> iter 88000, loss: 0.001334
 >> iter 89000, loss: 0.001314
 >> iter 90000, loss: 0.001296
   Number of active neurons: 10
 >> iter 91000, loss: 0.001582
 >> iter 92000, loss: 0.001360
 >> iter 93000, loss: 0.001273
 >> iter 94000, loss: 0.001224
 >> iter 95000, loss: 0.001186
 >> iter 96000, loss: 0.001238
 >> iter 97000, loss: 0.001257
 >> iter 98000, loss: 0.001162
 >> iter 99000, loss: 0.162959
 >> iter 100000, loss: 0.061159
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.650938
 >> iter 2000, loss: 10.571383
 >> iter 3000, loss: 8.733469
 >> iter 4000, loss: 7.978768
 >> iter 5000, loss: 7.703637
 >> iter 6000, loss: 7.585980
 >> iter 7000, loss: 7.420589
 >> iter 8000, loss: 7.014203
 >> iter 9000, loss: 6.406848
 >> iter 10000, loss: 5.832380
   Number of active neurons: 10
 >> iter 11000, loss: 5.510466
 >> iter 12000, loss: 5.144288
 >> iter 13000, loss: 2.382809
 >> iter 14000, loss: 1.061350
 >> iter 15000, loss: 0.461063
 >> iter 16000, loss: 0.260507
 >> iter 17000, loss: 0.141044
 >> iter 18000, loss: 0.108244
 >> iter 19000, loss: 0.113806
 >> iter 20000, loss: 0.085230
   Number of active neurons: 10
 >> iter 21000, loss: 0.068134
 >> iter 22000, loss: 0.102458
 >> iter 23000, loss: 0.046074
 >> iter 24000, loss: 0.023430
 >> iter 25000, loss: 0.014428
 >> iter 26000, loss: 0.024240
 >> iter 27000, loss: 0.014101
 >> iter 28000, loss: 0.019616
 >> iter 29000, loss: 0.011163
 >> iter 30000, loss: 0.007798
   Number of active neurons: 10
 >> iter 31000, loss: 0.005932
 >> iter 32000, loss: 0.005414
 >> iter 33000, loss: 0.004754
 >> iter 34000, loss: 0.004340
 >> iter 35000, loss: 0.004106
 >> iter 36000, loss: 0.003795
 >> iter 37000, loss: 0.003431
 >> iter 38000, loss: 0.003305
 >> iter 39000, loss: 0.008131
 >> iter 40000, loss: 0.005430
   Number of active neurons: 10
 >> iter 41000, loss: 0.003961
 >> iter 42000, loss: 0.005064
 >> iter 43000, loss: 0.004353
 >> iter 44000, loss: 0.003647
 >> iter 45000, loss: 0.003064
 >> iter 46000, loss: 0.002736
 >> iter 47000, loss: 0.002379
 >> iter 48000, loss: 0.002324
 >> iter 49000, loss: 0.002463
 >> iter 50000, loss: 0.002133
   Number of active neurons: 10
 >> iter 51000, loss: 0.001968
 >> iter 52000, loss: 0.002041
 >> iter 53000, loss: 0.001923
 >> iter 54000, loss: 0.002513
 >> iter 55000, loss: 0.002293
 >> iter 56000, loss: 0.006093
 >> iter 57000, loss: 0.003572
 >> iter 58000, loss: 0.002893
 >> iter 59000, loss: 0.002251
 >> iter 60000, loss: 0.001909
   Number of active neurons: 10
 >> iter 61000, loss: 0.001869
 >> iter 62000, loss: 0.001725
 >> iter 63000, loss: 0.001613
 >> iter 64000, loss: 0.001568
 >> iter 65000, loss: 0.006102
 >> iter 66000, loss: 0.003566
 >> iter 67000, loss: 0.002297
 >> iter 68000, loss: 0.001689
 >> iter 69000, loss: 0.001454
 >> iter 70000, loss: 0.001324
   Number of active neurons: 10
 >> iter 71000, loss: 0.001413
 >> iter 72000, loss: 0.001319
 >> iter 73000, loss: 0.015309
 >> iter 74000, loss: 0.006648
 >> iter 75000, loss: 0.004825
 >> iter 76000, loss: 0.002981
 >> iter 77000, loss: 0.002020
 >> iter 78000, loss: 0.001886
 >> iter 79000, loss: 0.001580
 >> iter 80000, loss: 0.001362
   Number of active neurons: 10
 >> iter 81000, loss: 0.001371
 >> iter 82000, loss: 0.001421
 >> iter 83000, loss: 0.001302
 >> iter 84000, loss: 0.001117
 >> iter 85000, loss: 0.009420
 >> iter 86000, loss: 0.004225
 >> iter 87000, loss: 0.002324
 >> iter 88000, loss: 0.001609
 >> iter 89000, loss: 0.001286
 >> iter 90000, loss: 0.001103
   Number of active neurons: 10
 >> iter 91000, loss: 0.001009
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.702574
 >> iter 2000, loss: 10.570713
 >> iter 3000, loss: 8.662804
 >> iter 4000, loss: 7.953756
 >> iter 5000, loss: 7.707518
 >> iter 6000, loss: 7.251515
 >> iter 7000, loss: 6.664006
 >> iter 8000, loss: 4.277177
 >> iter 9000, loss: 1.673443
 >> iter 10000, loss: 0.642526
   Number of active neurons: 10
 >> iter 11000, loss: 0.261361
 >> iter 12000, loss: 0.109414
 >> iter 13000, loss: 0.050987
 >> iter 14000, loss: 0.027609
 >> iter 15000, loss: 0.019274
 >> iter 16000, loss: 0.013759
 >> iter 17000, loss: 0.010790
 >> iter 18000, loss: 0.009021
 >> iter 19000, loss: 0.007972
 >> iter 20000, loss: 0.008540
   Number of active neurons: 10
 >> iter 21000, loss: 0.007348
 >> iter 22000, loss: 0.006555
 >> iter 23000, loss: 0.006526
 >> iter 24000, loss: 0.005630
 >> iter 25000, loss: 0.005137
 >> iter 26000, loss: 0.004693
 >> iter 27000, loss: 0.046904
 >> iter 28000, loss: 0.020147
 >> iter 29000, loss: 0.015695
 >> iter 30000, loss: 0.008669
   Number of active neurons: 10
 >> iter 31000, loss: 0.005795
 >> iter 32000, loss: 0.004481
 >> iter 33000, loss: 0.003891
 >> iter 34000, loss: 0.003513
 >> iter 35000, loss: 0.003336
 >> iter 36000, loss: 0.003210
 >> iter 37000, loss: 0.002981
 >> iter 38000, loss: 0.002827
 >> iter 39000, loss: 0.002711
 >> iter 40000, loss: 0.002583
   Number of active neurons: 10
 >> iter 41000, loss: 0.002454
 >> iter 42000, loss: 0.002368
 >> iter 43000, loss: 0.002296
 >> iter 44000, loss: 0.002263
 >> iter 45000, loss: 0.002180
 >> iter 46000, loss: 0.002121
 >> iter 47000, loss: 0.002066
 >> iter 48000, loss: 0.002036
 >> iter 49000, loss: 0.001958
 >> iter 50000, loss: 0.001900
   Number of active neurons: 10
 >> iter 51000, loss: 0.001851
 >> iter 52000, loss: 0.001828
 >> iter 53000, loss: 0.001772
 >> iter 54000, loss: 0.001708
 >> iter 55000, loss: 0.001715
 >> iter 56000, loss: 0.001701
 >> iter 57000, loss: 0.001606
 >> iter 58000, loss: 0.001554
 >> iter 59000, loss: 0.001601
 >> iter 60000, loss: 0.001543
   Number of active neurons: 10
 >> iter 61000, loss: 0.001597
 >> iter 62000, loss: 0.001508
 >> iter 63000, loss: 0.001575
 >> iter 64000, loss: 0.030627
 >> iter 65000, loss: 0.036155
 >> iter 66000, loss: 0.014778
 >> iter 67000, loss: 0.006640
 >> iter 68000, loss: 0.003521
 >> iter 69000, loss: 0.002295
 >> iter 70000, loss: 0.001807
   Number of active neurons: 10
 >> iter 71000, loss: 0.001725
 >> iter 72000, loss: 0.001496
 >> iter 73000, loss: 0.001387
 >> iter 74000, loss: 0.001315
 >> iter 75000, loss: 0.001275
 >> iter 76000, loss: 0.001250
 >> iter 77000, loss: 0.001234
 >> iter 78000, loss: 0.001224
 >> iter 79000, loss: 0.001178
 >> iter 80000, loss: 0.001158
   Number of active neurons: 10
 >> iter 81000, loss: 0.001136
 >> iter 82000, loss: 0.001122
 >> iter 83000, loss: 0.001110
 >> iter 84000, loss: 0.001053
 >> iter 85000, loss: 0.001238
 >> iter 86000, loss: 0.001117
 >> iter 87000, loss: 0.001047
 >> iter 88000, loss: 0.001018
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

