 > Problema: tomita4nueva
 > Args:
   - Hidden size: 6
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.504992
 >> iter 2000, loss: 11.722903
 >> iter 3000, loss: 6.059304
 >> iter 4000, loss: 3.066060
 >> iter 5000, loss: 1.804712
 >> iter 6000, loss: 0.947344
 >> iter 7000, loss: 0.907963
 >> iter 8000, loss: 0.608226
 >> iter 9000, loss: 0.543916
 >> iter 10000, loss: 0.378102
   Number of active neurons: 6
 >> iter 11000, loss: 0.556943
 >> iter 12000, loss: 0.630121
 >> iter 13000, loss: 0.449435
 >> iter 14000, loss: 0.350977
 >> iter 15000, loss: 0.519613
 >> iter 16000, loss: 0.463906
 >> iter 17000, loss: 0.329910
 >> iter 18000, loss: 0.518031
 >> iter 19000, loss: 0.645153
 >> iter 20000, loss: 0.494420
   Number of active neurons: 6
 >> iter 21000, loss: 0.616239
 >> iter 22000, loss: 0.588999
 >> iter 23000, loss: 0.448661
 >> iter 24000, loss: 0.354900
 >> iter 25000, loss: 0.451296
 >> iter 26000, loss: 0.448695
 >> iter 27000, loss: 0.339803
 >> iter 28000, loss: 0.404740
 >> iter 29000, loss: 0.380695
 >> iter 30000, loss: 0.305603
   Number of active neurons: 5
 >> iter 31000, loss: 0.351661
 >> iter 32000, loss: 0.312197
 >> iter 33000, loss: 0.410283
 >> iter 34000, loss: 0.291604
 >> iter 35000, loss: 0.559629
 >> iter 36000, loss: 0.357712
 >> iter 37000, loss: 0.295893
 >> iter 38000, loss: 0.248242
 >> iter 39000, loss: 0.261297
 >> iter 40000, loss: 0.304565
   Number of active neurons: 4
 >> iter 41000, loss: 0.573697
 >> iter 42000, loss: 0.459686
 >> iter 43000, loss: 0.264799
 >> iter 44000, loss: 0.224571
 >> iter 45000, loss: 0.394121
 >> iter 46000, loss: 0.424765
 >> iter 47000, loss: 0.509520
 >> iter 48000, loss: 0.308506
 >> iter 49000, loss: 0.342258
 >> iter 50000, loss: 0.296233
   Number of active neurons: 4
 >> iter 51000, loss: 0.337530
 >> iter 52000, loss: 0.234091
 >> iter 53000, loss: 0.184184
 >> iter 54000, loss: 0.288085
 >> iter 55000, loss: 0.183828
 >> iter 56000, loss: 0.255391
 >> iter 57000, loss: 0.238902
 >> iter 58000, loss: 0.531108
 >> iter 59000, loss: 0.489819
 >> iter 60000, loss: 0.659775
   Number of active neurons: 4
 >> iter 61000, loss: 0.475151
 >> iter 62000, loss: 0.510243
 >> iter 63000, loss: 0.324562
 >> iter 64000, loss: 0.481557
 >> iter 65000, loss: 0.369684
 >> iter 66000, loss: 0.342711
 >> iter 67000, loss: 0.415731
 >> iter 68000, loss: 0.406227
 >> iter 69000, loss: 0.592894
 >> iter 70000, loss: 0.369547
   Number of active neurons: 4
 >> iter 71000, loss: 0.401393
 >> iter 72000, loss: 0.394402
 >> iter 73000, loss: 0.345845
 >> iter 74000, loss: 0.269912
 >> iter 75000, loss: 0.533136
 >> iter 76000, loss: 0.463678
 >> iter 77000, loss: 0.487702
 >> iter 78000, loss: 0.419825
 >> iter 79000, loss: 0.367130
 >> iter 80000, loss: 0.407845
   Number of active neurons: 4
 >> iter 81000, loss: 0.450929
 >> iter 82000, loss: 0.582637
 >> iter 83000, loss: 0.568714
 >> iter 84000, loss: 0.528144
 >> iter 85000, loss: 0.555761
 >> iter 86000, loss: 0.410278
 >> iter 87000, loss: 0.399287
 >> iter 88000, loss: 0.461103
 >> iter 89000, loss: 0.375849
 >> iter 90000, loss: 0.497737
   Number of active neurons: 4
 >> iter 91000, loss: 0.303846
 >> iter 92000, loss: 0.407519
 >> iter 93000, loss: 0.577176
 >> iter 94000, loss: 0.677996
 >> iter 95000, loss: 0.508041
 >> iter 96000, loss: 0.489143
 >> iter 97000, loss: 0.384326
 >> iter 98000, loss: 0.419076
 >> iter 99000, loss: 0.392424
 >> iter 100000, loss: 0.308091
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.167559
 >> iter 2000, loss: 9.210627
 >> iter 3000, loss: 4.325270
 >> iter 4000, loss: 1.960697
 >> iter 5000, loss: 0.942745
 >> iter 6000, loss: 0.633977
 >> iter 7000, loss: 0.563865
 >> iter 8000, loss: 0.421197
 >> iter 9000, loss: 0.347407
 >> iter 10000, loss: 0.361441
   Number of active neurons: 6
 >> iter 11000, loss: 0.433069
 >> iter 12000, loss: 0.329896
 >> iter 13000, loss: 0.218505
 >> iter 14000, loss: 0.320908
 >> iter 15000, loss: 0.340955
 >> iter 16000, loss: 0.165505
 >> iter 17000, loss: 0.246840
 >> iter 18000, loss: 0.224124
 >> iter 19000, loss: 0.243969
 >> iter 20000, loss: 0.158072
   Number of active neurons: 5
 >> iter 21000, loss: 0.227957
 >> iter 22000, loss: 0.321677
 >> iter 23000, loss: 0.387119
 >> iter 24000, loss: 0.254057
 >> iter 25000, loss: 0.302099
 >> iter 26000, loss: 0.297162
 >> iter 27000, loss: 0.447785
 >> iter 28000, loss: 0.215732
 >> iter 29000, loss: 0.180491
 >> iter 30000, loss: 0.162272
   Number of active neurons: 5
 >> iter 31000, loss: 0.176311
 >> iter 32000, loss: 0.200818
 >> iter 33000, loss: 0.504920
 >> iter 34000, loss: 0.239467
 >> iter 35000, loss: 0.161479
 >> iter 36000, loss: 0.184413
 >> iter 37000, loss: 0.132002
 >> iter 38000, loss: 0.237181
 >> iter 39000, loss: 0.201474
 >> iter 40000, loss: 0.171679
   Number of active neurons: 4
 >> iter 41000, loss: 0.167919
 >> iter 42000, loss: 0.123886
 >> iter 43000, loss: 0.083440
 >> iter 44000, loss: 0.215662
 >> iter 45000, loss: 0.278496
 >> iter 46000, loss: 0.259971
 >> iter 47000, loss: 0.395260
 >> iter 48000, loss: 0.304364
 >> iter 49000, loss: 0.302163
 >> iter 50000, loss: 0.440320
   Number of active neurons: 3
 >> iter 51000, loss: 0.198084
 >> iter 52000, loss: 0.122789
 >> iter 53000, loss: 0.148367
 >> iter 54000, loss: 0.240966
 >> iter 55000, loss: 0.278335
 >> iter 56000, loss: 0.361159
 >> iter 57000, loss: 0.296639
 >> iter 58000, loss: 0.370637
 >> iter 59000, loss: 0.230418
 >> iter 60000, loss: 0.309454
   Number of active neurons: 3
 >> iter 61000, loss: 0.170552
 >> iter 62000, loss: 0.204162
 >> iter 63000, loss: 0.141799
 >> iter 64000, loss: 0.240918
 >> iter 65000, loss: 0.231757
 >> iter 66000, loss: 0.254312
 >> iter 67000, loss: 0.346781
 >> iter 68000, loss: 0.263655
 >> iter 69000, loss: 0.188785
 >> iter 70000, loss: 0.260247
   Number of active neurons: 3
 >> iter 71000, loss: 0.171480
 >> iter 72000, loss: 0.181630
 >> iter 73000, loss: 0.089253
 >> iter 74000, loss: 0.215241
 >> iter 75000, loss: 0.280190
 >> iter 76000, loss: 0.213028
 >> iter 77000, loss: 0.202699
 >> iter 78000, loss: 0.170205
 >> iter 79000, loss: 0.091341
 >> iter 80000, loss: 0.149472
   Number of active neurons: 3
 >> iter 81000, loss: 0.394367
 >> iter 82000, loss: 0.233217
 >> iter 83000, loss: 0.138576
 >> iter 84000, loss: 0.218629
 >> iter 85000, loss: 0.262647
 >> iter 86000, loss: 0.214931
 >> iter 87000, loss: 0.165875
 >> iter 88000, loss: 0.265530
 >> iter 89000, loss: 0.236304
 >> iter 90000, loss: 0.260884
   Number of active neurons: 3
 >> iter 91000, loss: 0.364137
 >> iter 92000, loss: 0.297574
 >> iter 93000, loss: 0.355746
 >> iter 94000, loss: 0.213226
 >> iter 95000, loss: 0.215429
 >> iter 96000, loss: 0.250490
 >> iter 97000, loss: 0.347099
 >> iter 98000, loss: 0.243072
 >> iter 99000, loss: 0.259772
 >> iter 100000, loss: 0.151703
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.429553
 >> iter 2000, loss: 8.289393
 >> iter 3000, loss: 3.748777
 >> iter 4000, loss: 1.650529
 >> iter 5000, loss: 0.934699
 >> iter 6000, loss: 0.504846
 >> iter 7000, loss: 0.391417
 >> iter 8000, loss: 0.525188
 >> iter 9000, loss: 0.425452
 >> iter 10000, loss: 0.355455
   Number of active neurons: 5
 >> iter 11000, loss: 0.311393
 >> iter 12000, loss: 0.407769
 >> iter 13000, loss: 0.400239
 >> iter 14000, loss: 0.336257
 >> iter 15000, loss: 0.301150
 >> iter 16000, loss: 0.355480
 >> iter 17000, loss: 0.158533
 >> iter 18000, loss: 0.215553
 >> iter 19000, loss: 0.217723
 >> iter 20000, loss: 0.253834
   Number of active neurons: 5
 >> iter 21000, loss: 0.301855
 >> iter 22000, loss: 0.344998
 >> iter 23000, loss: 0.322844
 >> iter 24000, loss: 0.192996
 >> iter 25000, loss: 0.300075
 >> iter 26000, loss: 0.346662
 >> iter 27000, loss: 0.321200
 >> iter 28000, loss: 0.420429
 >> iter 29000, loss: 0.380597
 >> iter 30000, loss: 0.465607
   Number of active neurons: 5
 >> iter 31000, loss: 0.268639
 >> iter 32000, loss: 0.233919
 >> iter 33000, loss: 0.424890
 >> iter 34000, loss: 0.364613
 >> iter 35000, loss: 0.266773
 >> iter 36000, loss: 0.192190
 >> iter 37000, loss: 0.281424
 >> iter 38000, loss: 0.298076
 >> iter 39000, loss: 0.183649
 >> iter 40000, loss: 0.224090
   Number of active neurons: 4
 >> iter 41000, loss: 0.443385
 >> iter 42000, loss: 0.304802
 >> iter 43000, loss: 0.486431
 >> iter 44000, loss: 0.429589
 >> iter 45000, loss: 0.298034
 >> iter 46000, loss: 0.364627
 >> iter 47000, loss: 0.442480
 >> iter 48000, loss: 0.420728
 >> iter 49000, loss: 0.272637
 >> iter 50000, loss: 0.297320
   Number of active neurons: 3
 >> iter 51000, loss: 0.327979
 >> iter 52000, loss: 0.307096
 >> iter 53000, loss: 0.186646
 >> iter 54000, loss: 0.232258
 >> iter 55000, loss: 0.261486
 >> iter 56000, loss: 0.392059
 >> iter 57000, loss: 0.387618
 >> iter 58000, loss: 0.275292
 >> iter 59000, loss: 0.327490
 >> iter 60000, loss: 0.260700
   Number of active neurons: 3
 >> iter 61000, loss: 0.403605
 >> iter 62000, loss: 0.509524
 >> iter 63000, loss: 0.296642
 >> iter 64000, loss: 0.272592
 >> iter 65000, loss: 0.240084
 >> iter 66000, loss: 0.287909
 >> iter 67000, loss: 0.243839
 >> iter 68000, loss: 0.299696
 >> iter 69000, loss: 0.441931
 >> iter 70000, loss: 0.327499
   Number of active neurons: 3
 >> iter 71000, loss: 0.208465
 >> iter 72000, loss: 0.250501
 >> iter 73000, loss: 0.236790
 >> iter 74000, loss: 0.246796
 >> iter 75000, loss: 0.205618
 >> iter 76000, loss: 0.203817
 >> iter 77000, loss: 0.275109
 >> iter 78000, loss: 0.308739
 >> iter 79000, loss: 0.172409
 >> iter 80000, loss: 0.283192
   Number of active neurons: 3
 >> iter 81000, loss: 0.170802
 >> iter 82000, loss: 0.148843
 >> iter 83000, loss: 0.344173
 >> iter 84000, loss: 0.388477
 >> iter 85000, loss: 0.241362
 >> iter 86000, loss: 0.155841
 >> iter 87000, loss: 0.332477
 >> iter 88000, loss: 0.248920
 >> iter 89000, loss: 0.219410
 >> iter 90000, loss: 0.290393
   Number of active neurons: 3
 >> iter 91000, loss: 0.352937
 >> iter 92000, loss: 0.324397
 >> iter 93000, loss: 0.293746
 >> iter 94000, loss: 0.374380
 >> iter 95000, loss: 0.239957
 >> iter 96000, loss: 0.235072
 >> iter 97000, loss: 0.149160
 >> iter 98000, loss: 0.247337
 >> iter 99000, loss: 0.279380
 >> iter 100000, loss: 0.230371
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.700615
 >> iter 2000, loss: 11.425511
 >> iter 3000, loss: 6.475541
 >> iter 4000, loss: 3.443867
 >> iter 5000, loss: 2.093853
 >> iter 6000, loss: 1.142612
 >> iter 7000, loss: 0.836706
 >> iter 8000, loss: 0.671478
 >> iter 9000, loss: 0.637531
 >> iter 10000, loss: 0.485352
   Number of active neurons: 6
 >> iter 11000, loss: 0.672820
 >> iter 12000, loss: 0.500911
 >> iter 13000, loss: 0.248596
 >> iter 14000, loss: 0.256064
 >> iter 15000, loss: 0.220054
 >> iter 16000, loss: 0.241285
 >> iter 17000, loss: 0.261602
 >> iter 18000, loss: 0.292646
 >> iter 19000, loss: 0.404657
 >> iter 20000, loss: 0.408556
   Number of active neurons: 6
 >> iter 21000, loss: 0.389276
 >> iter 22000, loss: 0.271518
 >> iter 23000, loss: 0.280484
 >> iter 24000, loss: 0.367842
 >> iter 25000, loss: 0.454843
 >> iter 26000, loss: 0.895927
 >> iter 27000, loss: 0.556670
 >> iter 28000, loss: 0.440981
 >> iter 29000, loss: 0.433331
 >> iter 30000, loss: 0.317486
   Number of active neurons: 5
 >> iter 31000, loss: 0.342635
 >> iter 32000, loss: 0.491850
 >> iter 33000, loss: 0.353237
 >> iter 34000, loss: 0.367951
 >> iter 35000, loss: 0.284573
 >> iter 36000, loss: 0.331075
 >> iter 37000, loss: 0.267798
 >> iter 38000, loss: 0.392896
 >> iter 39000, loss: 0.406248
 >> iter 40000, loss: 0.381537
   Number of active neurons: 5
 >> iter 41000, loss: 0.450466
 >> iter 42000, loss: 0.442843
 >> iter 43000, loss: 0.435076
 >> iter 44000, loss: 0.297557
 >> iter 45000, loss: 0.483942
 >> iter 46000, loss: 0.463936
 >> iter 47000, loss: 0.660071
 >> iter 48000, loss: 0.451365
 >> iter 49000, loss: 0.335569
 >> iter 50000, loss: 0.395401
   Number of active neurons: 5
 >> iter 51000, loss: 0.392862
 >> iter 52000, loss: 0.294319
 >> iter 53000, loss: 0.393793
 >> iter 54000, loss: 0.551142
 >> iter 55000, loss: 0.421656
 >> iter 56000, loss: 0.431543
 >> iter 57000, loss: 0.471492
 >> iter 58000, loss: 0.798677
 >> iter 59000, loss: 0.439539
 >> iter 60000, loss: 0.520919
   Number of active neurons: 5
 >> iter 61000, loss: 0.475901
 >> iter 62000, loss: 0.469821
 >> iter 63000, loss: 0.586168
 >> iter 64000, loss: 0.438570
 >> iter 65000, loss: 0.361377
 >> iter 66000, loss: 0.382579
 >> iter 67000, loss: 0.343533
 >> iter 68000, loss: 0.405473
 >> iter 69000, loss: 0.474774
 >> iter 70000, loss: 0.283813
   Number of active neurons: 5
 >> iter 71000, loss: 0.387406
 >> iter 72000, loss: 0.513114
 >> iter 73000, loss: 0.508636
 >> iter 74000, loss: 0.476168
 >> iter 75000, loss: 0.545543
 >> iter 76000, loss: 0.348515
 >> iter 77000, loss: 0.455070
 >> iter 78000, loss: 0.546487
 >> iter 79000, loss: 0.496778
 >> iter 80000, loss: 0.406634
   Number of active neurons: 5
 >> iter 81000, loss: 0.539869
 >> iter 82000, loss: 0.629971
 >> iter 83000, loss: 0.449782
 >> iter 84000, loss: 0.297637
 >> iter 85000, loss: 0.423929
 >> iter 86000, loss: 0.397727
 >> iter 87000, loss: 0.589188
 >> iter 88000, loss: 0.496585
 >> iter 89000, loss: 0.386663
 >> iter 90000, loss: 0.368685
   Number of active neurons: 5
 >> iter 91000, loss: 0.261553
 >> iter 92000, loss: 0.370962
 >> iter 93000, loss: 0.397597
 >> iter 94000, loss: 0.405845
 >> iter 95000, loss: 0.315794
 >> iter 96000, loss: 0.632040
 >> iter 97000, loss: 0.504830
 >> iter 98000, loss: 0.419973
 >> iter 99000, loss: 0.397718
 >> iter 100000, loss: 0.249189
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.471333
 >> iter 2000, loss: 8.349881
 >> iter 3000, loss: 3.588159
 >> iter 4000, loss: 1.671936
 >> iter 5000, loss: 0.805014
 >> iter 6000, loss: 0.633386
 >> iter 7000, loss: 0.550899
 >> iter 8000, loss: 0.339635
 >> iter 9000, loss: 0.413537
 >> iter 10000, loss: 0.440017
   Number of active neurons: 4
 >> iter 11000, loss: 0.413510
 >> iter 12000, loss: 0.275096
 >> iter 13000, loss: 0.230312
 >> iter 14000, loss: 0.218751
 >> iter 15000, loss: 0.163764
 >> iter 16000, loss: 0.188676
 >> iter 17000, loss: 0.326592
 >> iter 18000, loss: 0.458554
 >> iter 19000, loss: 0.480959
 >> iter 20000, loss: 0.386380
   Number of active neurons: 3
 >> iter 21000, loss: 0.410424
 >> iter 22000, loss: 0.202401
 >> iter 23000, loss: 0.175145
 >> iter 24000, loss: 0.370344
 >> iter 25000, loss: 0.261883
 >> iter 26000, loss: 0.365690
 >> iter 27000, loss: 0.258604
 >> iter 28000, loss: 0.331789
 >> iter 29000, loss: 0.250567
 >> iter 30000, loss: 0.248819
   Number of active neurons: 3
 >> iter 31000, loss: 0.346066
 >> iter 32000, loss: 0.556226
 >> iter 33000, loss: 0.429940
 >> iter 34000, loss: 0.293332
 >> iter 35000, loss: 0.207290
 >> iter 36000, loss: 0.216526
 >> iter 37000, loss: 0.175306
 >> iter 38000, loss: 0.211023
 >> iter 39000, loss: 0.324951
 >> iter 40000, loss: 0.287748
   Number of active neurons: 3
 >> iter 41000, loss: 0.200092
 >> iter 42000, loss: 0.163923
 >> iter 43000, loss: 0.404896
 >> iter 44000, loss: 0.380376
 >> iter 45000, loss: 0.239795
 >> iter 46000, loss: 0.137905
 >> iter 47000, loss: 0.384332
 >> iter 48000, loss: 0.323888
 >> iter 49000, loss: 0.430881
 >> iter 50000, loss: 0.240526
   Number of active neurons: 3
 >> iter 51000, loss: 0.239355
 >> iter 52000, loss: 0.171790
 >> iter 53000, loss: 0.326038
 >> iter 54000, loss: 0.494171
 >> iter 55000, loss: 0.519706
 >> iter 56000, loss: 0.365270
 >> iter 57000, loss: 0.489126
 >> iter 58000, loss: 0.403271
 >> iter 59000, loss: 0.221016
 >> iter 60000, loss: 0.375309
   Number of active neurons: 3
 >> iter 61000, loss: 0.276927
 >> iter 62000, loss: 0.177703
 >> iter 63000, loss: 0.244119
 >> iter 64000, loss: 0.193285
 >> iter 65000, loss: 0.295736
 >> iter 66000, loss: 0.239889
 >> iter 67000, loss: 0.251628
 >> iter 68000, loss: 0.152980
 >> iter 69000, loss: 0.196989
 >> iter 70000, loss: 0.323556
   Number of active neurons: 3
 >> iter 71000, loss: 0.340578
 >> iter 72000, loss: 0.313851
 >> iter 73000, loss: 0.345851
 >> iter 74000, loss: 0.284778
 >> iter 75000, loss: 0.323273
 >> iter 76000, loss: 0.281551
 >> iter 77000, loss: 0.204072
 >> iter 78000, loss: 0.307318
 >> iter 79000, loss: 0.219612
 >> iter 80000, loss: 0.218806
   Number of active neurons: 3
 >> iter 81000, loss: 0.125092
 >> iter 82000, loss: 0.075403
 >> iter 83000, loss: 0.135285
 >> iter 84000, loss: 0.162015
 >> iter 85000, loss: 0.293192
 >> iter 86000, loss: 0.206498
 >> iter 87000, loss: 0.233044
 >> iter 88000, loss: 0.164964
 >> iter 89000, loss: 0.446595
 >> iter 90000, loss: 0.319584
   Number of active neurons: 3
 >> iter 91000, loss: 0.199981
 >> iter 92000, loss: 0.146781
 >> iter 93000, loss: 0.335421
 >> iter 94000, loss: 0.318932
 >> iter 95000, loss: 0.317816
 >> iter 96000, loss: 0.354972
 >> iter 97000, loss: 0.390515
 >> iter 98000, loss: 0.240817
 >> iter 99000, loss: 0.164697
 >> iter 100000, loss: 0.114010
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 20.524748
 >> iter 2000, loss: 18.054274
 >> iter 3000, loss: 17.068459
 >> iter 4000, loss: 15.624164
 >> iter 5000, loss: 9.970128
 >> iter 6000, loss: 4.754648
 >> iter 7000, loss: 2.200858
 >> iter 8000, loss: 1.195925
 >> iter 9000, loss: 0.816062
 >> iter 10000, loss: 0.515380
   Number of active neurons: 5
 >> iter 11000, loss: 0.578694
 >> iter 12000, loss: 0.821467
 >> iter 13000, loss: 0.504285
 >> iter 14000, loss: 0.466699
 >> iter 15000, loss: 0.384769
 >> iter 16000, loss: 0.262515
 >> iter 17000, loss: 0.248819
 >> iter 18000, loss: 0.274520
 >> iter 19000, loss: 0.336435
 >> iter 20000, loss: 0.329927
   Number of active neurons: 4
 >> iter 21000, loss: 0.427165
 >> iter 22000, loss: 0.327355
 >> iter 23000, loss: 0.456288
 >> iter 24000, loss: 0.323171
 >> iter 25000, loss: 0.436161
 >> iter 26000, loss: 0.296248
 >> iter 27000, loss: 0.242823
 >> iter 28000, loss: 0.522566
 >> iter 29000, loss: 0.349184
 >> iter 30000, loss: 0.535888
   Number of active neurons: 4
 >> iter 31000, loss: 0.402749
 >> iter 32000, loss: 0.429624
 >> iter 33000, loss: 0.387854
 >> iter 34000, loss: 0.365162
 >> iter 35000, loss: 0.199399
 >> iter 36000, loss: 0.242592
 >> iter 37000, loss: 0.400353
 >> iter 38000, loss: 0.453901
 >> iter 39000, loss: 0.378775
 >> iter 40000, loss: 0.276616
   Number of active neurons: 4
 >> iter 41000, loss: 0.289520
 >> iter 42000, loss: 0.423062
 >> iter 43000, loss: 0.344559
 >> iter 44000, loss: 0.525804
 >> iter 45000, loss: 0.250029
 >> iter 46000, loss: 0.393312
 >> iter 47000, loss: 0.550501
 >> iter 48000, loss: 0.388797
 >> iter 49000, loss: 0.225991
 >> iter 50000, loss: 0.206983
   Number of active neurons: 4
 >> iter 51000, loss: 0.216108
 >> iter 52000, loss: 0.527489
 >> iter 53000, loss: 0.336569
 >> iter 54000, loss: 0.398236
 >> iter 55000, loss: 0.296938
 >> iter 56000, loss: 0.399460
 >> iter 57000, loss: 0.437925
 >> iter 58000, loss: 0.267257
 >> iter 59000, loss: 0.184084
 >> iter 60000, loss: 0.101962
   Number of active neurons: 4
 >> iter 61000, loss: 0.373726
 >> iter 62000, loss: 0.319925
 >> iter 63000, loss: 0.348397
 >> iter 64000, loss: 0.249727
 >> iter 65000, loss: 0.229987
 >> iter 66000, loss: 0.167806
 >> iter 67000, loss: 0.255735
 >> iter 68000, loss: 0.170770
 >> iter 69000, loss: 0.232440
 >> iter 70000, loss: 0.173864
   Number of active neurons: 4
 >> iter 71000, loss: 0.293470
 >> iter 72000, loss: 0.381267
 >> iter 73000, loss: 0.383492
 >> iter 74000, loss: 0.494584
 >> iter 75000, loss: 0.414513
 >> iter 76000, loss: 0.520885
 >> iter 77000, loss: 0.281946
 >> iter 78000, loss: 0.290488
 >> iter 79000, loss: 0.151333
 >> iter 80000, loss: 0.219162
   Number of active neurons: 4
 >> iter 81000, loss: 0.226486
 >> iter 82000, loss: 0.129172
 >> iter 83000, loss: 0.130265
 >> iter 84000, loss: 0.190477
 >> iter 85000, loss: 0.229666
 >> iter 86000, loss: 0.236801
 >> iter 87000, loss: 0.146228
 >> iter 88000, loss: 0.208651
 >> iter 89000, loss: 0.162882
 >> iter 90000, loss: 0.197753
   Number of active neurons: 3
 >> iter 91000, loss: 0.337500
 >> iter 92000, loss: 0.219520
 >> iter 93000, loss: 0.182842
 >> iter 94000, loss: 0.118814
 >> iter 95000, loss: 0.307962
 >> iter 96000, loss: 0.277002
 >> iter 97000, loss: 0.361981
 >> iter 98000, loss: 0.231279
 >> iter 99000, loss: 0.244549
 >> iter 100000, loss: 0.141865
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.603872
 >> iter 2000, loss: 9.830689
 >> iter 3000, loss: 4.403486
 >> iter 4000, loss: 1.975807
 >> iter 5000, loss: 0.968968
 >> iter 6000, loss: 0.738362
 >> iter 7000, loss: 0.578753
 >> iter 8000, loss: 0.592529
 >> iter 9000, loss: 0.577858
 >> iter 10000, loss: 0.423840
   Number of active neurons: 4
 >> iter 11000, loss: 0.440668
 >> iter 12000, loss: 0.369492
 >> iter 13000, loss: 0.365911
 >> iter 14000, loss: 0.356571
 >> iter 15000, loss: 0.223411
 >> iter 16000, loss: 0.248865
 >> iter 17000, loss: 0.368370
 >> iter 18000, loss: 0.242632
 >> iter 19000, loss: 0.400872
 >> iter 20000, loss: 0.285426
   Number of active neurons: 4
 >> iter 21000, loss: 0.294083
 >> iter 22000, loss: 0.211493
 >> iter 23000, loss: 0.436306
 >> iter 24000, loss: 0.394793
 >> iter 25000, loss: 0.233525
 >> iter 26000, loss: 0.136650
 >> iter 27000, loss: 0.401772
 >> iter 28000, loss: 0.324714
 >> iter 29000, loss: 0.246846
 >> iter 30000, loss: 0.197618
   Number of active neurons: 4
 >> iter 31000, loss: 0.208330
 >> iter 32000, loss: 0.231317
 >> iter 33000, loss: 0.197499
 >> iter 34000, loss: 0.244611
 >> iter 35000, loss: 0.177990
 >> iter 36000, loss: 0.132145
 >> iter 37000, loss: 0.201353
 >> iter 38000, loss: 0.245290
 >> iter 39000, loss: 0.377727
 >> iter 40000, loss: 0.279175
   Number of active neurons: 3
 >> iter 41000, loss: 0.203611
 >> iter 42000, loss: 0.101962
 >> iter 43000, loss: 0.166979
 >> iter 44000, loss: 0.261512
 >> iter 45000, loss: 0.293736
 >> iter 46000, loss: 0.270521
 >> iter 47000, loss: 0.296077
 >> iter 48000, loss: 0.395845
 >> iter 49000, loss: 0.307035
 >> iter 50000, loss: 0.226791
   Number of active neurons: 3
 >> iter 51000, loss: 0.269218
 >> iter 52000, loss: 0.194842
 >> iter 53000, loss: 0.172223
 >> iter 54000, loss: 0.116029
 >> iter 55000, loss: 0.150057
 >> iter 56000, loss: 0.409568
 >> iter 57000, loss: 0.196062
 >> iter 58000, loss: 0.258977
 >> iter 59000, loss: 0.227624
 >> iter 60000, loss: 0.142863
   Number of active neurons: 3
 >> iter 61000, loss: 0.243519
 >> iter 62000, loss: 0.377642
 >> iter 63000, loss: 0.214320
 >> iter 64000, loss: 0.149174
 >> iter 65000, loss: 0.219384
 >> iter 66000, loss: 0.135051
 >> iter 67000, loss: 0.251462
 >> iter 68000, loss: 0.307901
 >> iter 69000, loss: 0.295248
 >> iter 70000, loss: 0.224383
   Number of active neurons: 3
 >> iter 71000, loss: 0.168218
 >> iter 72000, loss: 0.270308
 >> iter 73000, loss: 0.180491
 >> iter 74000, loss: 0.103677
 >> iter 75000, loss: 0.221450
 >> iter 76000, loss: 0.213089
 >> iter 77000, loss: 0.170147
 >> iter 78000, loss: 0.270930
 >> iter 79000, loss: 0.475797
 >> iter 80000, loss: 0.313430
   Number of active neurons: 3
 >> iter 81000, loss: 0.216028
 >> iter 82000, loss: 0.339960
 >> iter 83000, loss: 0.341345
 >> iter 84000, loss: 0.217420
 >> iter 85000, loss: 0.223378
 >> iter 86000, loss: 0.195039
 >> iter 87000, loss: 0.236186
 >> iter 88000, loss: 0.267197
 >> iter 89000, loss: 0.270403
 >> iter 90000, loss: 0.225104
   Number of active neurons: 3
 >> iter 91000, loss: 0.178900
 >> iter 92000, loss: 0.286693
 >> iter 93000, loss: 0.189810
 >> iter 94000, loss: 0.122044
 >> iter 95000, loss: 0.161203
 >> iter 96000, loss: 0.230691
 >> iter 97000, loss: 0.230829
 >> iter 98000, loss: 0.416014
 >> iter 99000, loss: 0.371307
 >> iter 100000, loss: 0.340274
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.684959
 >> iter 2000, loss: 11.413883
 >> iter 3000, loss: 8.565107
 >> iter 4000, loss: 6.104815
 >> iter 5000, loss: 3.030636
 >> iter 6000, loss: 1.603869
 >> iter 7000, loss: 0.882774
 >> iter 8000, loss: 0.555944
 >> iter 9000, loss: 0.647643
 >> iter 10000, loss: 0.375078
   Number of active neurons: 4
 >> iter 11000, loss: 0.389307
 >> iter 12000, loss: 0.582704
 >> iter 13000, loss: 0.334060
 >> iter 14000, loss: 0.341195
 >> iter 15000, loss: 0.444452
 >> iter 16000, loss: 0.405821
 >> iter 17000, loss: 0.224947
 >> iter 18000, loss: 0.208615
 >> iter 19000, loss: 0.228282
 >> iter 20000, loss: 0.343238
   Number of active neurons: 4
 >> iter 21000, loss: 0.278535
 >> iter 22000, loss: 0.252909
 >> iter 23000, loss: 0.261747
 >> iter 24000, loss: 0.261499
 >> iter 25000, loss: 0.197466
 >> iter 26000, loss: 0.378912
 >> iter 27000, loss: 0.338348
 >> iter 28000, loss: 0.227132
 >> iter 29000, loss: 0.195612
 >> iter 30000, loss: 0.245062
   Number of active neurons: 4
 >> iter 31000, loss: 0.295035
 >> iter 32000, loss: 0.282484
 >> iter 33000, loss: 0.285363
 >> iter 34000, loss: 0.240551
 >> iter 35000, loss: 0.310527
 >> iter 36000, loss: 0.181948
 >> iter 37000, loss: 0.104704
 >> iter 38000, loss: 0.089990
 >> iter 39000, loss: 0.315499
 >> iter 40000, loss: 0.305299
   Number of active neurons: 3
 >> iter 41000, loss: 0.159659
 >> iter 42000, loss: 0.162928
 >> iter 43000, loss: 0.199480
 >> iter 44000, loss: 0.229616
 >> iter 45000, loss: 0.327001
 >> iter 46000, loss: 0.200645
 >> iter 47000, loss: 0.215290
 >> iter 48000, loss: 0.155010
 >> iter 49000, loss: 0.222353
 >> iter 50000, loss: 0.339437
   Number of active neurons: 3
 >> iter 51000, loss: 0.446310
 >> iter 52000, loss: 0.365716
 >> iter 53000, loss: 0.241923
 >> iter 54000, loss: 0.139274
 >> iter 55000, loss: 0.365501
 >> iter 56000, loss: 0.215191
 >> iter 57000, loss: 0.212533
 >> iter 58000, loss: 0.204611
 >> iter 59000, loss: 0.231441
 >> iter 60000, loss: 0.205454
   Number of active neurons: 3
 >> iter 61000, loss: 0.240147
 >> iter 62000, loss: 0.168800
 >> iter 63000, loss: 0.310627
 >> iter 64000, loss: 0.217436
 >> iter 65000, loss: 0.181912
 >> iter 66000, loss: 0.242684
 >> iter 67000, loss: 0.345669
 >> iter 68000, loss: 0.270253
 >> iter 69000, loss: 0.190208
 >> iter 70000, loss: 0.202326
   Number of active neurons: 3
 >> iter 71000, loss: 0.275682
 >> iter 72000, loss: 0.187293
 >> iter 73000, loss: 0.155306
 >> iter 74000, loss: 0.124971
 >> iter 75000, loss: 0.207581
 >> iter 76000, loss: 0.194129
 >> iter 77000, loss: 0.379741
 >> iter 78000, loss: 0.302399
 >> iter 79000, loss: 0.173488
 >> iter 80000, loss: 0.152462
   Number of active neurons: 3
 >> iter 81000, loss: 0.428562
 >> iter 82000, loss: 0.301537
 >> iter 83000, loss: 0.218163
 >> iter 84000, loss: 0.251144
 >> iter 85000, loss: 0.258205
 >> iter 86000, loss: 0.230950
 >> iter 87000, loss: 0.287063
 >> iter 88000, loss: 0.379531
 >> iter 89000, loss: 0.231535
 >> iter 90000, loss: 0.377560
   Number of active neurons: 3
 >> iter 91000, loss: 0.202633
 >> iter 92000, loss: 0.146831
 >> iter 93000, loss: 0.277939
 >> iter 94000, loss: 0.327032
 >> iter 95000, loss: 0.314816
 >> iter 96000, loss: 0.249037
 >> iter 97000, loss: 0.254716
 >> iter 98000, loss: 0.298192
 >> iter 99000, loss: 0.204168
 >> iter 100000, loss: 0.143996
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.228775
 >> iter 2000, loss: 10.671508
 >> iter 3000, loss: 5.638888
 >> iter 4000, loss: 2.832552
 >> iter 5000, loss: 1.770589
 >> iter 6000, loss: 1.255336
 >> iter 7000, loss: 0.879819
 >> iter 8000, loss: 0.774107
 >> iter 9000, loss: 0.717029
 >> iter 10000, loss: 0.833050
   Number of active neurons: 6
 >> iter 11000, loss: 0.770451
 >> iter 12000, loss: 0.741205
 >> iter 13000, loss: 0.647928
 >> iter 14000, loss: 0.494919
 >> iter 15000, loss: 0.398847
 >> iter 16000, loss: 0.568372
 >> iter 17000, loss: 0.501288
 >> iter 18000, loss: 0.420048
 >> iter 19000, loss: 0.400379
 >> iter 20000, loss: 0.525403
   Number of active neurons: 6
 >> iter 21000, loss: 0.590424
 >> iter 22000, loss: 0.539142
 >> iter 23000, loss: 0.523004
 >> iter 24000, loss: 0.478003
 >> iter 25000, loss: 0.373987
 >> iter 26000, loss: 0.377251
 >> iter 27000, loss: 0.430433
 >> iter 28000, loss: 0.448855
 >> iter 29000, loss: 0.642047
 >> iter 30000, loss: 0.332244
   Number of active neurons: 5
 >> iter 31000, loss: 0.519006
 >> iter 32000, loss: 0.405948
 >> iter 33000, loss: 0.608834
 >> iter 34000, loss: 0.497000
 >> iter 35000, loss: 0.603334
 >> iter 36000, loss: 0.568365
 >> iter 37000, loss: 0.649205
 >> iter 38000, loss: 0.621500
 >> iter 39000, loss: 0.468522
 >> iter 40000, loss: 0.416138
   Number of active neurons: 4
 >> iter 41000, loss: 0.694633
 >> iter 42000, loss: 0.628006
 >> iter 43000, loss: 0.553548
 >> iter 44000, loss: 0.388200
 >> iter 45000, loss: 0.566362
 >> iter 46000, loss: 0.533632
 >> iter 47000, loss: 0.670335
 >> iter 48000, loss: 0.621179
 >> iter 49000, loss: 0.526460
 >> iter 50000, loss: 0.295870
   Number of active neurons: 6
 >> iter 51000, loss: 0.303269
 >> iter 52000, loss: 0.289639
 >> iter 53000, loss: 0.510348
 >> iter 54000, loss: 0.589415
 >> iter 55000, loss: 0.413516
 >> iter 56000, loss: 0.499903
 >> iter 57000, loss: 0.438822
 >> iter 58000, loss: 0.449772
 >> iter 59000, loss: 0.734566
 >> iter 60000, loss: 0.476886
   Number of active neurons: 6
 >> iter 61000, loss: 0.499942
 >> iter 62000, loss: 0.424802
 >> iter 63000, loss: 0.583823
 >> iter 64000, loss: 0.419729
 >> iter 65000, loss: 0.360379
 >> iter 66000, loss: 0.578524
 >> iter 67000, loss: 0.494209
 >> iter 68000, loss: 0.419604
 >> iter 69000, loss: 0.479377
 >> iter 70000, loss: 0.541667
   Number of active neurons: 6
 >> iter 71000, loss: 0.497615
 >> iter 72000, loss: 0.464478
 >> iter 73000, loss: 0.261091
 >> iter 74000, loss: 0.504557
 >> iter 75000, loss: 0.319719
 >> iter 76000, loss: 0.392877
 >> iter 77000, loss: 0.257784
 >> iter 78000, loss: 0.307210
 >> iter 79000, loss: 0.475048
 >> iter 80000, loss: 0.323219
   Number of active neurons: 5
 >> iter 81000, loss: 0.370438
 >> iter 82000, loss: 0.494180
 >> iter 83000, loss: 0.635969
 >> iter 84000, loss: 0.406310
 >> iter 85000, loss: 0.320963
 >> iter 86000, loss: 0.310643
 >> iter 87000, loss: 0.391442
 >> iter 88000, loss: 0.324890
 >> iter 89000, loss: 0.170926
 >> iter 90000, loss: 0.321664
   Number of active neurons: 6
 >> iter 91000, loss: 0.590802
 >> iter 92000, loss: 0.444801
 >> iter 93000, loss: 0.416240
 >> iter 94000, loss: 0.328146
 >> iter 95000, loss: 0.492349
 >> iter 96000, loss: 0.415149
 >> iter 97000, loss: 0.350977
 >> iter 98000, loss: 0.415593
 >> iter 99000, loss: 0.371453
 >> iter 100000, loss: 0.367293
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 17.599491
 >> iter 2000, loss: 9.119100
 >> iter 3000, loss: 4.137913
 >> iter 4000, loss: 1.875239
 >> iter 5000, loss: 1.032881
 >> iter 6000, loss: 0.588256
 >> iter 7000, loss: 0.595251
 >> iter 8000, loss: 0.500686
 >> iter 9000, loss: 0.355018
 >> iter 10000, loss: 0.305588
   Number of active neurons: 5
 >> iter 11000, loss: 0.604181
 >> iter 12000, loss: 0.301881
 >> iter 13000, loss: 0.554491
 >> iter 14000, loss: 0.511762
 >> iter 15000, loss: 0.342483
 >> iter 16000, loss: 0.257850
 >> iter 17000, loss: 0.398363
 >> iter 18000, loss: 0.423451
 >> iter 19000, loss: 0.229052
 >> iter 20000, loss: 0.483790
   Number of active neurons: 5
 >> iter 21000, loss: 0.326482
 >> iter 22000, loss: 0.376232
 >> iter 23000, loss: 0.497716
 >> iter 24000, loss: 0.494353
 >> iter 25000, loss: 0.551036
 >> iter 26000, loss: 0.347162
 >> iter 27000, loss: 0.320034
 >> iter 28000, loss: 0.432775
 >> iter 29000, loss: 0.261526
 >> iter 30000, loss: 0.271436
   Number of active neurons: 5
 >> iter 31000, loss: 0.443051
 >> iter 32000, loss: 0.244402
 >> iter 33000, loss: 0.177766
 >> iter 34000, loss: 0.152185
 >> iter 35000, loss: 0.291695
 >> iter 36000, loss: 0.339685
 >> iter 37000, loss: 0.321053
 >> iter 38000, loss: 0.335103
 >> iter 39000, loss: 0.288675
 >> iter 40000, loss: 0.424258
   Number of active neurons: 4
 >> iter 41000, loss: 0.205188
 >> iter 42000, loss: 0.158468
 >> iter 43000, loss: 0.263603
 >> iter 44000, loss: 0.290369
 >> iter 45000, loss: 0.399040
 >> iter 46000, loss: 0.243132
 >> iter 47000, loss: 0.194920
 >> iter 48000, loss: 0.233259
 >> iter 49000, loss: 0.147532
 >> iter 50000, loss: 0.119068
   Number of active neurons: 4
 >> iter 51000, loss: 0.195391
 >> iter 52000, loss: 0.301700
 >> iter 53000, loss: 0.287116
 >> iter 54000, loss: 0.209732
 >> iter 55000, loss: 0.274399
 >> iter 56000, loss: 0.413464
 >> iter 57000, loss: 0.258652
 >> iter 58000, loss: 0.129866
 >> iter 59000, loss: 0.282137
 >> iter 60000, loss: 0.180422
   Number of active neurons: 4
 >> iter 61000, loss: 0.160070
 >> iter 62000, loss: 0.228600
 >> iter 63000, loss: 0.315349
 >> iter 64000, loss: 0.172180
 >> iter 65000, loss: 0.347474
 >> iter 66000, loss: 0.225477
 >> iter 67000, loss: 0.115136
 >> iter 68000, loss: 0.112596
 >> iter 69000, loss: 0.154377
 >> iter 70000, loss: 0.163146
   Number of active neurons: 4
 >> iter 71000, loss: 0.258746
 >> iter 72000, loss: 0.235273
 >> iter 73000, loss: 0.219624
 >> iter 74000, loss: 0.204923
 >> iter 75000, loss: 0.269193
 >> iter 76000, loss: 0.308379
 >> iter 77000, loss: 0.243069
 >> iter 78000, loss: 0.245751
 >> iter 79000, loss: 0.150047
 >> iter 80000, loss: 0.185996
   Number of active neurons: 4
 >> iter 81000, loss: 0.133516
 >> iter 82000, loss: 0.292399
 >> iter 83000, loss: 0.254027
 >> iter 84000, loss: 0.272194
 >> iter 85000, loss: 0.173593
 >> iter 86000, loss: 0.376441
 >> iter 87000, loss: 0.248431
 >> iter 88000, loss: 0.231818
 >> iter 89000, loss: 0.204632
 >> iter 90000, loss: 0.505781
   Number of active neurons: 4
 >> iter 91000, loss: 0.324112
 >> iter 92000, loss: 0.311161
 >> iter 93000, loss: 0.250324
 >> iter 94000, loss: 0.540825
 >> iter 95000, loss: 0.274169
 >> iter 96000, loss: 0.381444
 >> iter 97000, loss: 0.179655
 >> iter 98000, loss: 0.378840
 >> iter 99000, loss: 0.266260
 >> iter 100000, loss: 0.379950
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.795667
 >> iter 2000, loss: 9.055633
 >> iter 3000, loss: 4.133479
 >> iter 4000, loss: 1.940109
 >> iter 5000, loss: 1.033290
 >> iter 6000, loss: 0.692878
 >> iter 7000, loss: 0.469468
 >> iter 8000, loss: 0.470853
 >> iter 9000, loss: 0.442185
 >> iter 10000, loss: 0.406486
   Number of active neurons: 4
 >> iter 11000, loss: 0.288090
 >> iter 12000, loss: 0.327924
 >> iter 13000, loss: 0.256899
 >> iter 14000, loss: 0.294554
 >> iter 15000, loss: 0.534006
 >> iter 16000, loss: 0.455533
 >> iter 17000, loss: 0.288150
 >> iter 18000, loss: 0.211748
 >> iter 19000, loss: 0.420186
 >> iter 20000, loss: 0.433341
   Number of active neurons: 4
 >> iter 21000, loss: 0.398071
 >> iter 22000, loss: 0.330704
 >> iter 23000, loss: 0.345404
 >> iter 24000, loss: 0.315954
 >> iter 25000, loss: 0.352176
 >> iter 26000, loss: 0.321978
 >> iter 27000, loss: 0.234268
 >> iter 28000, loss: 0.270254
 >> iter 29000, loss: 0.269795
 >> iter 30000, loss: 0.275316
   Number of active neurons: 4
 >> iter 31000, loss: 0.212956
 >> iter 32000, loss: 0.251779
 >> iter 33000, loss: 0.295214
 >> iter 34000, loss: 0.403551
 >> iter 35000, loss: 0.270951
 >> iter 36000, loss: 0.132635
 >> iter 37000, loss: 0.253004
 >> iter 38000, loss: 0.229714
 >> iter 39000, loss: 0.259325
 >> iter 40000, loss: 0.221686
   Number of active neurons: 4
 >> iter 41000, loss: 0.146759
 >> iter 42000, loss: 0.284366
 >> iter 43000, loss: 0.159084
 >> iter 44000, loss: 0.178306
 >> iter 45000, loss: 0.294999
 >> iter 46000, loss: 0.419108
 >> iter 47000, loss: 0.334755
 >> iter 48000, loss: 0.236865
 >> iter 49000, loss: 0.351913
 >> iter 50000, loss: 0.205283
   Number of active neurons: 4
 >> iter 51000, loss: 0.139383
 >> iter 52000, loss: 0.384102
 >> iter 53000, loss: 0.301993
 >> iter 54000, loss: 0.293825
 >> iter 55000, loss: 0.298429
 >> iter 56000, loss: 0.193361
 >> iter 57000, loss: 0.253637
 >> iter 58000, loss: 0.342192
 >> iter 59000, loss: 0.296051
 >> iter 60000, loss: 0.180700
   Number of active neurons: 4
 >> iter 61000, loss: 0.245651
 >> iter 62000, loss: 0.246543
 >> iter 63000, loss: 0.357668
 >> iter 64000, loss: 0.276589
 >> iter 65000, loss: 0.174703
 >> iter 66000, loss: 0.171112
 >> iter 67000, loss: 0.091504
 >> iter 68000, loss: 0.211343
 >> iter 69000, loss: 0.158178
 >> iter 70000, loss: 0.174623
   Number of active neurons: 4
 >> iter 71000, loss: 0.274605
 >> iter 72000, loss: 0.271433
 >> iter 73000, loss: 0.319799
 >> iter 74000, loss: 0.314376
 >> iter 75000, loss: 0.236176
 >> iter 76000, loss: 0.384701
 >> iter 77000, loss: 0.330272
 >> iter 78000, loss: 0.254245
 >> iter 79000, loss: 0.294599
 >> iter 80000, loss: 0.291716
   Number of active neurons: 4
 >> iter 81000, loss: 0.211531
 >> iter 82000, loss: 0.206392
 >> iter 83000, loss: 0.268772
 >> iter 84000, loss: 0.201315
 >> iter 85000, loss: 0.180321
 >> iter 86000, loss: 0.420691
 >> iter 87000, loss: 0.330096
 >> iter 88000, loss: 0.320084
 >> iter 89000, loss: 0.191238
 >> iter 90000, loss: 0.174511
   Number of active neurons: 4
 >> iter 91000, loss: 0.269166
 >> iter 92000, loss: 0.221985
 >> iter 93000, loss: 0.265728
 >> iter 94000, loss: 0.227906
 >> iter 95000, loss: 0.235886
 >> iter 96000, loss: 0.144802
 >> iter 97000, loss: 0.217242
 >> iter 98000, loss: 0.169171
 >> iter 99000, loss: 0.174234
 >> iter 100000, loss: 0.139707
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.542390
 >> iter 2000, loss: 11.089420
 >> iter 3000, loss: 5.400951
 >> iter 4000, loss: 2.465993
 >> iter 5000, loss: 1.479195
 >> iter 6000, loss: 0.803731
 >> iter 7000, loss: 0.473953
 >> iter 8000, loss: 0.417365
 >> iter 9000, loss: 0.519759
 >> iter 10000, loss: 0.294798
   Number of active neurons: 5
 >> iter 11000, loss: 0.458252
 >> iter 12000, loss: 0.661556
 >> iter 13000, loss: 0.589080
 >> iter 14000, loss: 0.508732
 >> iter 15000, loss: 0.454828
 >> iter 16000, loss: 0.480851
 >> iter 17000, loss: 0.522652
 >> iter 18000, loss: 0.391606
 >> iter 19000, loss: 0.301821
 >> iter 20000, loss: 0.381198
   Number of active neurons: 5
 >> iter 21000, loss: 0.354987
 >> iter 22000, loss: 0.289498
 >> iter 23000, loss: 0.303749
 >> iter 24000, loss: 0.358009
 >> iter 25000, loss: 0.384083
 >> iter 26000, loss: 0.486786
 >> iter 27000, loss: 0.442426
 >> iter 28000, loss: 0.235543
 >> iter 29000, loss: 0.555785
 >> iter 30000, loss: 0.369525
   Number of active neurons: 5
 >> iter 31000, loss: 0.353196
 >> iter 32000, loss: 0.403957
 >> iter 33000, loss: 0.312507
 >> iter 34000, loss: 0.416210
 >> iter 35000, loss: 0.287523
 >> iter 36000, loss: 0.332548
 >> iter 37000, loss: 0.344165
 >> iter 38000, loss: 0.294053
 >> iter 39000, loss: 0.341426
 >> iter 40000, loss: 0.278645
   Number of active neurons: 5
 >> iter 41000, loss: 0.448076
 >> iter 42000, loss: 0.341766
 >> iter 43000, loss: 0.268207
 >> iter 44000, loss: 0.377175
 >> iter 45000, loss: 0.421281
 >> iter 46000, loss: 0.417272
 >> iter 47000, loss: 0.263865
 >> iter 48000, loss: 0.324489
 >> iter 49000, loss: 0.266997
 >> iter 50000, loss: 0.465966
   Number of active neurons: 5
 >> iter 51000, loss: 0.452845
 >> iter 52000, loss: 0.310287
 >> iter 53000, loss: 0.424777
 >> iter 54000, loss: 0.304122
 >> iter 55000, loss: 0.218655
 >> iter 56000, loss: 0.269894
 >> iter 57000, loss: 0.264052
 >> iter 58000, loss: 0.323778
 >> iter 59000, loss: 0.189191
 >> iter 60000, loss: 0.194434
   Number of active neurons: 5
 >> iter 61000, loss: 0.281581
 >> iter 62000, loss: 0.505434
 >> iter 63000, loss: 0.441997
 >> iter 64000, loss: 0.344604
 >> iter 65000, loss: 0.377112
 >> iter 66000, loss: 0.271176
 >> iter 67000, loss: 0.271644
 >> iter 68000, loss: 0.335309
 >> iter 69000, loss: 0.208233
 >> iter 70000, loss: 0.166602
   Number of active neurons: 5
 >> iter 71000, loss: 0.234509
 >> iter 72000, loss: 0.308095
 >> iter 73000, loss: 0.262857
 >> iter 74000, loss: 0.254330
 >> iter 75000, loss: 0.272622
 >> iter 76000, loss: 0.237764
 >> iter 77000, loss: 0.241857
 >> iter 78000, loss: 0.441902
 >> iter 79000, loss: 0.270372
 >> iter 80000, loss: 0.208981
   Number of active neurons: 4
 >> iter 81000, loss: 0.173995
 >> iter 82000, loss: 0.185253
 >> iter 83000, loss: 0.166148
 >> iter 84000, loss: 0.269043
 >> iter 85000, loss: 0.159191
 >> iter 86000, loss: 0.250526
 >> iter 87000, loss: 0.315031
 >> iter 88000, loss: 0.312764
 >> iter 89000, loss: 0.348956
 >> iter 90000, loss: 0.362782
   Number of active neurons: 4
 >> iter 91000, loss: 0.292521
 >> iter 92000, loss: 0.510338
 >> iter 93000, loss: 0.285038
 >> iter 94000, loss: 0.313419
 >> iter 95000, loss: 0.306920
 >> iter 96000, loss: 0.206387
 >> iter 97000, loss: 0.259528
 >> iter 98000, loss: 0.410588
 >> iter 99000, loss: 0.258673
 >> iter 100000, loss: 0.252191
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.113788
 >> iter 2000, loss: 13.584090
 >> iter 3000, loss: 8.373075
 >> iter 4000, loss: 3.910863
 >> iter 5000, loss: 2.226566
 >> iter 6000, loss: 1.506742
 >> iter 7000, loss: 0.992272
 >> iter 8000, loss: 0.801008
 >> iter 9000, loss: 0.613313
 >> iter 10000, loss: 0.559550
   Number of active neurons: 5
 >> iter 11000, loss: 0.573822
 >> iter 12000, loss: 0.563723
 >> iter 13000, loss: 0.641530
 >> iter 14000, loss: 0.452834
 >> iter 15000, loss: 0.656879
 >> iter 16000, loss: 0.601281
 >> iter 17000, loss: 0.404603
 >> iter 18000, loss: 0.473149
 >> iter 19000, loss: 0.413822
 >> iter 20000, loss: 0.639754
   Number of active neurons: 5
 >> iter 21000, loss: 0.563329
 >> iter 22000, loss: 0.562842
 >> iter 23000, loss: 0.479550
 >> iter 24000, loss: 0.527461
 >> iter 25000, loss: 0.610514
 >> iter 26000, loss: 0.674698
 >> iter 27000, loss: 0.755050
 >> iter 28000, loss: 0.626404
 >> iter 29000, loss: 0.437973
 >> iter 30000, loss: 0.380243
   Number of active neurons: 6
 >> iter 31000, loss: 0.558419
 >> iter 32000, loss: 0.687224
 >> iter 33000, loss: 0.486681
 >> iter 34000, loss: 0.520539
 >> iter 35000, loss: 0.452189
 >> iter 36000, loss: 0.489738
 >> iter 37000, loss: 0.427520
 >> iter 38000, loss: 0.643612
 >> iter 39000, loss: 0.475306
 >> iter 40000, loss: 0.516920
   Number of active neurons: 6
 >> iter 41000, loss: 0.534949
 >> iter 42000, loss: 0.488989
 >> iter 43000, loss: 0.551958
 >> iter 44000, loss: 0.527158
 >> iter 45000, loss: 0.406539
 >> iter 46000, loss: 0.549638
 >> iter 47000, loss: 0.265142
 >> iter 48000, loss: 0.392606
 >> iter 49000, loss: 0.433257
 >> iter 50000, loss: 0.374795
   Number of active neurons: 6
 >> iter 51000, loss: 0.243584
 >> iter 52000, loss: 0.739943
 >> iter 53000, loss: 0.583802
 >> iter 54000, loss: 0.382516
 >> iter 55000, loss: 0.551308
 >> iter 56000, loss: 0.292047
 >> iter 57000, loss: 0.344494
 >> iter 58000, loss: 0.287038
 >> iter 59000, loss: 0.218574
 >> iter 60000, loss: 0.573956
   Number of active neurons: 5
 >> iter 61000, loss: 0.346769
 >> iter 62000, loss: 0.413399
 >> iter 63000, loss: 0.255574
 >> iter 64000, loss: 0.409140
 >> iter 65000, loss: 0.315034
 >> iter 66000, loss: 0.282977
 >> iter 67000, loss: 0.346208
 >> iter 68000, loss: 0.439713
 >> iter 69000, loss: 0.563575
 >> iter 70000, loss: 0.473983
   Number of active neurons: 6
 >> iter 71000, loss: 0.386775
 >> iter 72000, loss: 0.289233
 >> iter 73000, loss: 0.393315
 >> iter 74000, loss: 0.390940
 >> iter 75000, loss: 0.351259
 >> iter 76000, loss: 0.284597
 >> iter 77000, loss: 0.578278
 >> iter 78000, loss: 0.526826
 >> iter 79000, loss: 0.379623
 >> iter 80000, loss: 0.336327
   Number of active neurons: 6
 >> iter 81000, loss: 0.360960
 >> iter 82000, loss: 0.271333
 >> iter 83000, loss: 0.354739
 >> iter 84000, loss: 0.367702
 >> iter 85000, loss: 0.515324
 >> iter 86000, loss: 0.478385
 >> iter 87000, loss: 0.309913
 >> iter 88000, loss: 0.401143
 >> iter 89000, loss: 0.369187
 >> iter 90000, loss: 0.273576
   Number of active neurons: 6
 >> iter 91000, loss: 0.325435
 >> iter 92000, loss: 0.328723
 >> iter 93000, loss: 0.298063
 >> iter 94000, loss: 0.269492
 >> iter 95000, loss: 0.401661
 >> iter 96000, loss: 0.348407
 >> iter 97000, loss: 0.349497
 >> iter 98000, loss: 0.289668
 >> iter 99000, loss: 0.450859
 >> iter 100000, loss: 0.490223
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524742
 >> iter 2000, loss: 18.054274
 >> iter 3000, loss: 17.068459
 >> iter 4000, loss: 16.779377
 >> iter 5000, loss: 16.602174
 >> iter 6000, loss: 16.153649
 >> iter 7000, loss: 12.610793
 >> iter 8000, loss: 7.690580
 >> iter 9000, loss: 3.738291
 >> iter 10000, loss: 2.145556
   Number of active neurons: 6
 >> iter 11000, loss: 1.259303
 >> iter 12000, loss: 0.675780
 >> iter 13000, loss: 0.479539
 >> iter 14000, loss: 0.406394
 >> iter 15000, loss: 0.449188
 >> iter 16000, loss: 0.427452
 >> iter 17000, loss: 0.562371
 >> iter 18000, loss: 0.458134
 >> iter 19000, loss: 0.312925
 >> iter 20000, loss: 0.521661
   Number of active neurons: 6
 >> iter 21000, loss: 0.421965
 >> iter 22000, loss: 0.649908
 >> iter 23000, loss: 0.852541
 >> iter 24000, loss: 0.484558
 >> iter 25000, loss: 0.563744
 >> iter 26000, loss: 0.493001
 >> iter 27000, loss: 0.356693
 >> iter 28000, loss: 0.411909
 >> iter 29000, loss: 0.426691
 >> iter 30000, loss: 0.458690
   Number of active neurons: 6
 >> iter 31000, loss: 0.593158
 >> iter 32000, loss: 0.463587
 >> iter 33000, loss: 0.353865
 >> iter 34000, loss: 0.630106
 >> iter 35000, loss: 0.465222
 >> iter 36000, loss: 0.567613
 >> iter 37000, loss: 0.415814
 >> iter 38000, loss: 0.543508
 >> iter 39000, loss: 0.384943
 >> iter 40000, loss: 0.489221
   Number of active neurons: 6
 >> iter 41000, loss: 0.444766
 >> iter 42000, loss: 0.523207
 >> iter 43000, loss: 0.425595
 >> iter 44000, loss: 0.597580
 >> iter 45000, loss: 0.416295
 >> iter 46000, loss: 0.426914
 >> iter 47000, loss: 0.623690
 >> iter 48000, loss: 0.578326
 >> iter 49000, loss: 0.540273
 >> iter 50000, loss: 0.504651
   Number of active neurons: 5
 >> iter 51000, loss: 0.355846
 >> iter 52000, loss: 0.606055
 >> iter 53000, loss: 0.554151
 >> iter 54000, loss: 0.380447
 >> iter 55000, loss: 0.431403
 >> iter 56000, loss: 0.547767
 >> iter 57000, loss: 0.518742
 >> iter 58000, loss: 0.548615
 >> iter 59000, loss: 0.519718
 >> iter 60000, loss: 0.600032
   Number of active neurons: 5
 >> iter 61000, loss: 0.394615
 >> iter 62000, loss: 0.476688
 >> iter 63000, loss: 0.470377
 >> iter 64000, loss: 0.638212
 >> iter 65000, loss: 0.590391
 >> iter 66000, loss: 0.431422
 >> iter 67000, loss: 0.466421
 >> iter 68000, loss: 0.390995
 >> iter 69000, loss: 0.664133
 >> iter 70000, loss: 0.713458
   Number of active neurons: 6
 >> iter 71000, loss: 0.482077
 >> iter 72000, loss: 0.523326
 >> iter 73000, loss: 0.574008
 >> iter 74000, loss: 0.424924
 >> iter 75000, loss: 0.524243
 >> iter 76000, loss: 0.434253
 >> iter 77000, loss: 0.436313
 >> iter 78000, loss: 0.499655
 >> iter 79000, loss: 0.675414
 >> iter 80000, loss: 0.638936
   Number of active neurons: 6
 >> iter 81000, loss: 0.589231
 >> iter 82000, loss: 0.425180
 >> iter 83000, loss: 0.375523
 >> iter 84000, loss: 0.512246
 >> iter 85000, loss: 0.509275
 >> iter 86000, loss: 0.537311
 >> iter 87000, loss: 0.417206
 >> iter 88000, loss: 0.375048
 >> iter 89000, loss: 0.491809
 >> iter 90000, loss: 0.460948
   Number of active neurons: 6
 >> iter 91000, loss: 0.310257
 >> iter 92000, loss: 0.417290
 >> iter 93000, loss: 0.615983
 >> iter 94000, loss: 0.357036
 >> iter 95000, loss: 0.486719
 >> iter 96000, loss: 0.381937
 >> iter 97000, loss: 0.455948
 >> iter 98000, loss: 0.243526
 >> iter 99000, loss: 0.383057
 >> iter 100000, loss: 0.254001
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.440111
 >> iter 2000, loss: 10.881755
 >> iter 3000, loss: 5.354891
 >> iter 4000, loss: 2.416382
 >> iter 5000, loss: 1.397871
 >> iter 6000, loss: 0.904802
 >> iter 7000, loss: 0.547023
 >> iter 8000, loss: 0.431390
 >> iter 9000, loss: 0.367452
 >> iter 10000, loss: 0.334735
   Number of active neurons: 5
 >> iter 11000, loss: 0.422949
 >> iter 12000, loss: 0.397359
 >> iter 13000, loss: 0.483596
 >> iter 14000, loss: 0.433310
 >> iter 15000, loss: 0.491633
 >> iter 16000, loss: 0.415655
 >> iter 17000, loss: 0.257969
 >> iter 18000, loss: 0.354126
 >> iter 19000, loss: 0.261642
 >> iter 20000, loss: 0.326587
   Number of active neurons: 5
 >> iter 21000, loss: 0.468111
 >> iter 22000, loss: 0.500970
 >> iter 23000, loss: 0.357020
 >> iter 24000, loss: 0.346274
 >> iter 25000, loss: 0.202951
 >> iter 26000, loss: 0.229675
 >> iter 27000, loss: 0.131495
 >> iter 28000, loss: 0.128106
 >> iter 29000, loss: 0.221839
 >> iter 30000, loss: 0.167325
   Number of active neurons: 5
 >> iter 31000, loss: 0.463947
 >> iter 32000, loss: 0.387205
 >> iter 33000, loss: 0.328964
 >> iter 34000, loss: 0.349525
 >> iter 35000, loss: 0.217290
 >> iter 36000, loss: 0.292168
 >> iter 37000, loss: 0.205321
 >> iter 38000, loss: 0.281322
 >> iter 39000, loss: 0.172085
 >> iter 40000, loss: 0.214486
   Number of active neurons: 4
 >> iter 41000, loss: 0.199990
 >> iter 42000, loss: 0.276850
 >> iter 43000, loss: 0.249245
 >> iter 44000, loss: 0.181859
 >> iter 45000, loss: 0.240462
 >> iter 46000, loss: 0.236065
 >> iter 47000, loss: 0.319363
 >> iter 48000, loss: 0.308804
 >> iter 49000, loss: 0.181165
 >> iter 50000, loss: 0.248736
   Number of active neurons: 3
 >> iter 51000, loss: 0.305313
 >> iter 52000, loss: 0.164899
 >> iter 53000, loss: 0.093158
 >> iter 54000, loss: 0.071213
 >> iter 55000, loss: 0.221106
 >> iter 56000, loss: 0.427678
 >> iter 57000, loss: 0.379485
 >> iter 58000, loss: 0.306930
 >> iter 59000, loss: 0.209572
 >> iter 60000, loss: 0.338797
   Number of active neurons: 3
 >> iter 61000, loss: 0.160461
 >> iter 62000, loss: 0.163309
 >> iter 63000, loss: 0.150725
 >> iter 64000, loss: 0.230130
 >> iter 65000, loss: 0.277352
 >> iter 66000, loss: 0.184390
 >> iter 67000, loss: 0.368681
 >> iter 68000, loss: 0.219157
 >> iter 69000, loss: 0.207914
 >> iter 70000, loss: 0.410723
   Number of active neurons: 3
 >> iter 71000, loss: 0.255039
 >> iter 72000, loss: 0.305490
 >> iter 73000, loss: 0.254542
 >> iter 74000, loss: 0.266551
 >> iter 75000, loss: 0.410802
 >> iter 76000, loss: 0.323437
 >> iter 77000, loss: 0.362449
 >> iter 78000, loss: 0.315961
 >> iter 79000, loss: 0.206772
 >> iter 80000, loss: 0.166595
   Number of active neurons: 3
 >> iter 81000, loss: 0.091136
 >> iter 82000, loss: 0.345457
 >> iter 83000, loss: 0.306848
 >> iter 84000, loss: 0.296628
 >> iter 85000, loss: 0.260249
 >> iter 86000, loss: 0.171521
 >> iter 87000, loss: 0.285730
 >> iter 88000, loss: 0.253122
 >> iter 89000, loss: 0.174281
 >> iter 90000, loss: 0.240653
   Number of active neurons: 3
 >> iter 91000, loss: 0.307331
 >> iter 92000, loss: 0.343690
 >> iter 93000, loss: 0.359728
 >> iter 94000, loss: 0.241347
 >> iter 95000, loss: 0.214168
 >> iter 96000, loss: 0.187396
 >> iter 97000, loss: 0.131327
 >> iter 98000, loss: 0.327570
 >> iter 99000, loss: 0.373883
 >> iter 100000, loss: 0.345168
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.561255
 >> iter 2000, loss: 11.074227
 >> iter 3000, loss: 5.671027
 >> iter 4000, loss: 3.233447
 >> iter 5000, loss: 1.944750
 >> iter 6000, loss: 1.011523
 >> iter 7000, loss: 0.840282
 >> iter 8000, loss: 0.522171
 >> iter 9000, loss: 0.734416
 >> iter 10000, loss: 0.734351
   Number of active neurons: 6
 >> iter 11000, loss: 0.593568
 >> iter 12000, loss: 0.367663
 >> iter 13000, loss: 0.565466
 >> iter 14000, loss: 0.458043
 >> iter 15000, loss: 0.372970
 >> iter 16000, loss: 0.271749
 >> iter 17000, loss: 0.369063
 >> iter 18000, loss: 0.491690
 >> iter 19000, loss: 0.483506
 >> iter 20000, loss: 0.576815
   Number of active neurons: 5
 >> iter 21000, loss: 0.557001
 >> iter 22000, loss: 0.618583
 >> iter 23000, loss: 0.557768
 >> iter 24000, loss: 0.840087
 >> iter 25000, loss: 0.528647
 >> iter 26000, loss: 0.481678
 >> iter 27000, loss: 0.458733
 >> iter 28000, loss: 0.309422
 >> iter 29000, loss: 0.495741
 >> iter 30000, loss: 0.489146
   Number of active neurons: 5
 >> iter 31000, loss: 0.378928
 >> iter 32000, loss: 0.548744
 >> iter 33000, loss: 0.517312
 >> iter 34000, loss: 0.593816
 >> iter 35000, loss: 0.421663
 >> iter 36000, loss: 0.371315
 >> iter 37000, loss: 0.385497
 >> iter 38000, loss: 0.290317
 >> iter 39000, loss: 0.499761
 >> iter 40000, loss: 0.464661
   Number of active neurons: 5
 >> iter 41000, loss: 0.316139
 >> iter 42000, loss: 0.354202
 >> iter 43000, loss: 0.393205
 >> iter 44000, loss: 0.388234
 >> iter 45000, loss: 0.393777
 >> iter 46000, loss: 0.304728
 >> iter 47000, loss: 0.196928
 >> iter 48000, loss: 0.196087
 >> iter 49000, loss: 0.357039
 >> iter 50000, loss: 0.330876
   Number of active neurons: 6
 >> iter 51000, loss: 0.476288
 >> iter 52000, loss: 0.350248
 >> iter 53000, loss: 0.425291
 >> iter 54000, loss: 0.499912
 >> iter 55000, loss: 0.594067
 >> iter 56000, loss: 0.540952
 >> iter 57000, loss: 0.430934
 >> iter 58000, loss: 0.440083
 >> iter 59000, loss: 0.324472
 >> iter 60000, loss: 0.693410
   Number of active neurons: 5
 >> iter 61000, loss: 0.553284
 >> iter 62000, loss: 0.590798
 >> iter 63000, loss: 0.417039
 >> iter 64000, loss: 0.339849
 >> iter 65000, loss: 0.386248
 >> iter 66000, loss: 0.408532
 >> iter 67000, loss: 0.361996
 >> iter 68000, loss: 0.636038
 >> iter 69000, loss: 0.408810
 >> iter 70000, loss: 0.419704
   Number of active neurons: 6
 >> iter 71000, loss: 0.410390
 >> iter 72000, loss: 0.453329
 >> iter 73000, loss: 0.352487
 >> iter 74000, loss: 0.374472
 >> iter 75000, loss: 0.335677
 >> iter 76000, loss: 0.333528
 >> iter 77000, loss: 0.395820
 >> iter 78000, loss: 0.679887
 >> iter 79000, loss: 0.443997
 >> iter 80000, loss: 0.266770
   Number of active neurons: 6
 >> iter 81000, loss: 0.363847
 >> iter 82000, loss: 0.503424
 >> iter 83000, loss: 0.399313
 >> iter 84000, loss: 0.386003
 >> iter 85000, loss: 0.359411
 >> iter 86000, loss: 0.278044
 >> iter 87000, loss: 0.339000
 >> iter 88000, loss: 0.374823
 >> iter 89000, loss: 0.454853
 >> iter 90000, loss: 0.433942
   Number of active neurons: 6
 >> iter 91000, loss: 0.349389
 >> iter 92000, loss: 0.497857
 >> iter 93000, loss: 0.354919
 >> iter 94000, loss: 0.359776
 >> iter 95000, loss: 0.431694
 >> iter 96000, loss: 0.420560
 >> iter 97000, loss: 0.324824
 >> iter 98000, loss: 0.322561
 >> iter 99000, loss: 0.370613
 >> iter 100000, loss: 0.609309
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524754
 >> iter 2000, loss: 18.054272
 >> iter 3000, loss: 17.068458
 >> iter 4000, loss: 16.779366
 >> iter 5000, loss: 16.602169
 >> iter 6000, loss: 16.598193
 >> iter 7000, loss: 16.539947
 >> iter 8000, loss: 16.231813
 >> iter 9000, loss: 12.714383
 >> iter 10000, loss: 7.797288
   Number of active neurons: 6
 >> iter 11000, loss: 3.915467
 >> iter 12000, loss: 1.679959
 >> iter 13000, loss: 0.995453
 >> iter 14000, loss: 0.718287
 >> iter 15000, loss: 0.831559
 >> iter 16000, loss: 0.717647
 >> iter 17000, loss: 0.500590
 >> iter 18000, loss: 0.445733
 >> iter 19000, loss: 0.394803
 >> iter 20000, loss: 0.355229
   Number of active neurons: 6
 >> iter 21000, loss: 0.392531
 >> iter 22000, loss: 0.687031
 >> iter 23000, loss: 0.470063
 >> iter 24000, loss: 0.236600
 >> iter 25000, loss: 0.370874
 >> iter 26000, loss: 0.235007
 >> iter 27000, loss: 0.595410
 >> iter 28000, loss: 0.580048
 >> iter 29000, loss: 0.408195
 >> iter 30000, loss: 0.479373
   Number of active neurons: 6
 >> iter 31000, loss: 0.414835
 >> iter 32000, loss: 0.456000
 >> iter 33000, loss: 0.533202
 >> iter 34000, loss: 0.307032
 >> iter 35000, loss: 0.335908
 >> iter 36000, loss: 0.289706
 >> iter 37000, loss: 0.243745
 >> iter 38000, loss: 0.239462
 >> iter 39000, loss: 0.273218
 >> iter 40000, loss: 0.236860
   Number of active neurons: 6
 >> iter 41000, loss: 0.382710
 >> iter 42000, loss: 0.288090
 >> iter 43000, loss: 0.414829
 >> iter 44000, loss: 0.622269
 >> iter 45000, loss: 0.419119
 >> iter 46000, loss: 0.237744
 >> iter 47000, loss: 0.425635
 >> iter 48000, loss: 0.438668
 >> iter 49000, loss: 0.472040
 >> iter 50000, loss: 0.526945
   Number of active neurons: 5
 >> iter 51000, loss: 0.420396
 >> iter 52000, loss: 0.458202
 >> iter 53000, loss: 0.325671
 >> iter 54000, loss: 0.310714
 >> iter 55000, loss: 0.247752
 >> iter 56000, loss: 0.241343
 >> iter 57000, loss: 0.374619
 >> iter 58000, loss: 0.178700
 >> iter 59000, loss: 0.171081
 >> iter 60000, loss: 0.203580
   Number of active neurons: 5
 >> iter 61000, loss: 0.288978
 >> iter 62000, loss: 0.353480
 >> iter 63000, loss: 0.407423
 >> iter 64000, loss: 0.277947
 >> iter 65000, loss: 0.294705
 >> iter 66000, loss: 0.297509
 >> iter 67000, loss: 0.344197
 >> iter 68000, loss: 0.196989
 >> iter 69000, loss: 0.439503
 >> iter 70000, loss: 0.397100
   Number of active neurons: 4
 >> iter 71000, loss: 0.290228
 >> iter 72000, loss: 0.201473
 >> iter 73000, loss: 0.220072
 >> iter 74000, loss: 0.221070
 >> iter 75000, loss: 0.275711
 >> iter 76000, loss: 0.192339
 >> iter 77000, loss: 0.370479
 >> iter 78000, loss: 0.313770
 >> iter 79000, loss: 0.244698
 >> iter 80000, loss: 0.335399
   Number of active neurons: 4
 >> iter 81000, loss: 0.170196
 >> iter 82000, loss: 0.166215
 >> iter 83000, loss: 0.183793
 >> iter 84000, loss: 0.129907
 >> iter 85000, loss: 0.123996
 >> iter 86000, loss: 0.105341
 >> iter 87000, loss: 0.165916
 >> iter 88000, loss: 0.202123
 >> iter 89000, loss: 0.121356
 >> iter 90000, loss: 0.210878
   Number of active neurons: 3
 >> iter 91000, loss: 0.188914
 >> iter 92000, loss: 0.189780
 >> iter 93000, loss: 0.220499
 >> iter 94000, loss: 0.219584
 >> iter 95000, loss: 0.192401
 >> iter 96000, loss: 0.201205
 >> iter 97000, loss: 0.117659
 >> iter 98000, loss: 0.155820
 >> iter 99000, loss: 0.209708
 >> iter 100000, loss: 0.233694
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.711218
 >> iter 2000, loss: 9.218084
 >> iter 3000, loss: 4.136632
 >> iter 4000, loss: 2.124995
 >> iter 5000, loss: 0.981146
 >> iter 6000, loss: 0.562958
 >> iter 7000, loss: 0.767601
 >> iter 8000, loss: 0.417425
 >> iter 9000, loss: 0.449826
 >> iter 10000, loss: 0.487445
   Number of active neurons: 3
 >> iter 11000, loss: 0.298727
 >> iter 12000, loss: 0.242744
 >> iter 13000, loss: 0.392620
 >> iter 14000, loss: 0.266776
 >> iter 15000, loss: 0.195249
 >> iter 16000, loss: 0.349861
 >> iter 17000, loss: 0.191444
 >> iter 18000, loss: 0.170980
 >> iter 19000, loss: 0.112168
 >> iter 20000, loss: 0.158549
   Number of active neurons: 3
 >> iter 21000, loss: 0.189926
 >> iter 22000, loss: 0.206018
 >> iter 23000, loss: 0.202707
 >> iter 24000, loss: 0.304591
 >> iter 25000, loss: 0.357177
 >> iter 26000, loss: 0.367407
 >> iter 27000, loss: 0.349638
 >> iter 28000, loss: 0.419697
 >> iter 29000, loss: 0.474649
 >> iter 30000, loss: 0.442698
   Number of active neurons: 3
 >> iter 31000, loss: 0.289975
 >> iter 32000, loss: 0.335341
 >> iter 33000, loss: 0.330440
 >> iter 34000, loss: 0.416195
 >> iter 35000, loss: 0.294548
 >> iter 36000, loss: 0.321613
 >> iter 37000, loss: 0.242005
 >> iter 38000, loss: 0.175734
 >> iter 39000, loss: 0.236670
 >> iter 40000, loss: 0.333717
   Number of active neurons: 3
 >> iter 41000, loss: 0.263099
 >> iter 42000, loss: 0.263509
 >> iter 43000, loss: 0.314642
 >> iter 44000, loss: 0.282962
 >> iter 45000, loss: 0.337430
 >> iter 46000, loss: 0.356707
 >> iter 47000, loss: 0.221475
 >> iter 48000, loss: 0.158759
 >> iter 49000, loss: 0.219925
 >> iter 50000, loss: 0.321674
   Number of active neurons: 3
 >> iter 51000, loss: 0.293597
 >> iter 52000, loss: 0.194625
 >> iter 53000, loss: 0.397389
 >> iter 54000, loss: 0.314759
 >> iter 55000, loss: 0.202444
 >> iter 56000, loss: 0.477771
 >> iter 57000, loss: 0.456123
 >> iter 58000, loss: 0.313359
 >> iter 59000, loss: 0.324997
 >> iter 60000, loss: 0.217273
   Number of active neurons: 3
 >> iter 61000, loss: 0.221431
 >> iter 62000, loss: 0.158008
 >> iter 63000, loss: 0.158302
 >> iter 64000, loss: 0.204407
 >> iter 65000, loss: 0.116955
 >> iter 66000, loss: 0.238268
 >> iter 67000, loss: 0.227545
 >> iter 68000, loss: 0.225892
 >> iter 69000, loss: 0.170944
 >> iter 70000, loss: 0.158945
   Number of active neurons: 3
 >> iter 71000, loss: 0.191563
 >> iter 72000, loss: 0.227574
 >> iter 73000, loss: 0.240393
 >> iter 74000, loss: 0.273677
 >> iter 75000, loss: 0.207198
 >> iter 76000, loss: 0.194414
 >> iter 77000, loss: 0.190020
 >> iter 78000, loss: 0.188646
 >> iter 79000, loss: 0.289961
 >> iter 80000, loss: 0.284617
   Number of active neurons: 3
 >> iter 81000, loss: 0.307056
 >> iter 82000, loss: 0.163415
 >> iter 83000, loss: 0.144830
 >> iter 84000, loss: 0.106575
 >> iter 85000, loss: 0.101557
 >> iter 86000, loss: 0.070177
 >> iter 87000, loss: 0.243666
 >> iter 88000, loss: 0.230425
 >> iter 89000, loss: 0.209904
 >> iter 90000, loss: 0.232237
   Number of active neurons: 3
 >> iter 91000, loss: 0.269107
 >> iter 92000, loss: 0.185587
 >> iter 93000, loss: 0.151783
 >> iter 94000, loss: 0.309703
 >> iter 95000, loss: 0.277766
 >> iter 96000, loss: 0.241672
 >> iter 97000, loss: 0.135051
 >> iter 98000, loss: 0.231607
 >> iter 99000, loss: 0.162514
 >> iter 100000, loss: 0.174502
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.353992
 >> iter 2000, loss: 10.391061
 >> iter 3000, loss: 5.102667
 >> iter 4000, loss: 2.779957
 >> iter 5000, loss: 1.606659
 >> iter 6000, loss: 1.077498
 >> iter 7000, loss: 0.778682
 >> iter 8000, loss: 0.554310
 >> iter 9000, loss: 0.465347
 >> iter 10000, loss: 0.500503
   Number of active neurons: 6
 >> iter 11000, loss: 0.404359
 >> iter 12000, loss: 0.498393
 >> iter 13000, loss: 0.430651
 >> iter 14000, loss: 0.467707
 >> iter 15000, loss: 0.456185
 >> iter 16000, loss: 0.353433
 >> iter 17000, loss: 0.566416
 >> iter 18000, loss: 0.372075
 >> iter 19000, loss: 0.295553
 >> iter 20000, loss: 0.617366
   Number of active neurons: 6
 >> iter 21000, loss: 0.450997
 >> iter 22000, loss: 0.403050
 >> iter 23000, loss: 0.451612
 >> iter 24000, loss: 0.556988
 >> iter 25000, loss: 0.500833
 >> iter 26000, loss: 0.591587
 >> iter 27000, loss: 0.648070
 >> iter 28000, loss: 0.451359
 >> iter 29000, loss: 0.541994
 >> iter 30000, loss: 0.607491
   Number of active neurons: 6
 >> iter 31000, loss: 0.477878
 >> iter 32000, loss: 0.328901
 >> iter 33000, loss: 0.487017
 >> iter 34000, loss: 0.426554
 >> iter 35000, loss: 0.315970
 >> iter 36000, loss: 0.369373
 >> iter 37000, loss: 0.439659
 >> iter 38000, loss: 0.533454
 >> iter 39000, loss: 0.612647
 >> iter 40000, loss: 0.582616
   Number of active neurons: 6
 >> iter 41000, loss: 0.476714
 >> iter 42000, loss: 0.394551
 >> iter 43000, loss: 0.691585
 >> iter 44000, loss: 0.541020
 >> iter 45000, loss: 0.433597
 >> iter 46000, loss: 0.480679
 >> iter 47000, loss: 0.603267
 >> iter 48000, loss: 0.679370
 >> iter 49000, loss: 0.547921
 >> iter 50000, loss: 0.479345
   Number of active neurons: 6
 >> iter 51000, loss: 0.481805
 >> iter 52000, loss: 0.395634
 >> iter 53000, loss: 0.333708
 >> iter 54000, loss: 0.381833
 >> iter 55000, loss: 0.331341
 >> iter 56000, loss: 0.268765
 >> iter 57000, loss: 0.346616
 >> iter 58000, loss: 0.334163
 >> iter 59000, loss: 0.571331
 >> iter 60000, loss: 0.473649
   Number of active neurons: 6
 >> iter 61000, loss: 0.504222
 >> iter 62000, loss: 0.518198
 >> iter 63000, loss: 0.668654
 >> iter 64000, loss: 0.611181
 >> iter 65000, loss: 0.285114
 >> iter 66000, loss: 0.424205
 >> iter 67000, loss: 0.343130
 >> iter 68000, loss: 0.344579
 >> iter 69000, loss: 0.435510
 >> iter 70000, loss: 0.426341
   Number of active neurons: 6
 >> iter 71000, loss: 0.315662
 >> iter 72000, loss: 0.388562
 >> iter 73000, loss: 0.524696
 >> iter 74000, loss: 0.291814
 >> iter 75000, loss: 0.252012
 >> iter 76000, loss: 0.542144
 >> iter 77000, loss: 0.427616
 >> iter 78000, loss: 0.556619
 >> iter 79000, loss: 0.393460
 >> iter 80000, loss: 0.560719
   Number of active neurons: 6
 >> iter 81000, loss: 0.427434
 >> iter 82000, loss: 0.482803
 >> iter 83000, loss: 0.377422
 >> iter 84000, loss: 0.397256
 >> iter 85000, loss: 0.304020
 >> iter 86000, loss: 0.527355
 >> iter 87000, loss: 0.329838
 >> iter 88000, loss: 0.235011
 >> iter 89000, loss: 0.370811
 >> iter 90000, loss: 0.362904
   Number of active neurons: 6
 >> iter 91000, loss: 0.357109
 >> iter 92000, loss: 0.255280
 >> iter 93000, loss: 0.424969
 >> iter 94000, loss: 0.452914
 >> iter 95000, loss: 0.500031
 >> iter 96000, loss: 0.431432
 >> iter 97000, loss: 0.301617
 >> iter 98000, loss: 0.427003
 >> iter 99000, loss: 0.296349
 >> iter 100000, loss: 0.372815
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.716315
 >> iter 2000, loss: 11.501290
 >> iter 3000, loss: 6.568028
 >> iter 4000, loss: 3.199785
 >> iter 5000, loss: 1.494187
 >> iter 6000, loss: 0.749288
 >> iter 7000, loss: 0.648987
 >> iter 8000, loss: 0.685810
 >> iter 9000, loss: 0.558372
 >> iter 10000, loss: 0.375780
   Number of active neurons: 5
 >> iter 11000, loss: 0.209681
 >> iter 12000, loss: 0.254738
 >> iter 13000, loss: 0.450368
 >> iter 14000, loss: 0.321808
 >> iter 15000, loss: 0.229426
 >> iter 16000, loss: 0.315682
 >> iter 17000, loss: 0.308984
 >> iter 18000, loss: 0.294975
 >> iter 19000, loss: 0.423346
 >> iter 20000, loss: 0.468353
   Number of active neurons: 4
 >> iter 21000, loss: 0.404227
 >> iter 22000, loss: 0.406244
 >> iter 23000, loss: 0.313560
 >> iter 24000, loss: 0.380488
 >> iter 25000, loss: 0.272467
 >> iter 26000, loss: 0.322165
 >> iter 27000, loss: 0.282716
 >> iter 28000, loss: 0.493244
 >> iter 29000, loss: 0.264204
 >> iter 30000, loss: 0.487876
   Number of active neurons: 4
 >> iter 31000, loss: 0.224865
 >> iter 32000, loss: 0.317476
 >> iter 33000, loss: 0.226508
 >> iter 34000, loss: 0.167664
 >> iter 35000, loss: 0.161374
 >> iter 36000, loss: 0.256263
 >> iter 37000, loss: 0.280405
 >> iter 38000, loss: 0.211667
 >> iter 39000, loss: 0.214736
 >> iter 40000, loss: 0.187097
   Number of active neurons: 4
 >> iter 41000, loss: 0.354477
 >> iter 42000, loss: 0.284939
 >> iter 43000, loss: 0.267441
 >> iter 44000, loss: 0.425266
 >> iter 45000, loss: 0.355384
 >> iter 46000, loss: 0.312951
 >> iter 47000, loss: 0.251480
 >> iter 48000, loss: 0.234033
 >> iter 49000, loss: 0.281725
 >> iter 50000, loss: 0.238225
   Number of active neurons: 4
 >> iter 51000, loss: 0.266085
 >> iter 52000, loss: 0.344590
 >> iter 53000, loss: 0.266577
 >> iter 54000, loss: 0.128120
 >> iter 55000, loss: 0.187338
 >> iter 56000, loss: 0.311349
 >> iter 57000, loss: 0.333144
 >> iter 58000, loss: 0.270508
 >> iter 59000, loss: 0.415488
 >> iter 60000, loss: 0.347270
   Number of active neurons: 3
 >> iter 61000, loss: 0.351323
 >> iter 62000, loss: 0.366581
 >> iter 63000, loss: 0.368813
 >> iter 64000, loss: 0.270041
 >> iter 65000, loss: 0.221018
 >> iter 66000, loss: 0.274043
 >> iter 67000, loss: 0.360405
 >> iter 68000, loss: 0.380237
 >> iter 69000, loss: 0.241974
 >> iter 70000, loss: 0.260420
   Number of active neurons: 3
 >> iter 71000, loss: 0.239219
 >> iter 72000, loss: 0.368009
 >> iter 73000, loss: 0.188426
 >> iter 74000, loss: 0.405850
 >> iter 75000, loss: 0.309514
 >> iter 76000, loss: 0.227036
 >> iter 77000, loss: 0.293618
 >> iter 78000, loss: 0.146758
 >> iter 79000, loss: 0.126810
 >> iter 80000, loss: 0.218572
   Number of active neurons: 3
 >> iter 81000, loss: 0.308830
 >> iter 82000, loss: 0.226741
 >> iter 83000, loss: 0.434075
 >> iter 84000, loss: 0.239346
 >> iter 85000, loss: 0.297667
 >> iter 86000, loss: 0.368016
 >> iter 87000, loss: 0.202040
 >> iter 88000, loss: 0.154664
 >> iter 89000, loss: 0.139615
 >> iter 90000, loss: 0.156271
   Number of active neurons: 3
 >> iter 91000, loss: 0.172848
 >> iter 92000, loss: 0.188931
 >> iter 93000, loss: 0.244872
 >> iter 94000, loss: 0.211289
 >> iter 95000, loss: 0.303635
 >> iter 96000, loss: 0.208329
 >> iter 97000, loss: 0.229494
 >> iter 98000, loss: 0.230470
 >> iter 99000, loss: 0.316459
 >> iter 100000, loss: 0.202046
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

