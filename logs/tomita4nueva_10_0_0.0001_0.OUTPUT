 > Problema: tomita4nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.268111
 >> iter 2000, loss: 6.785597
 >> iter 3000, loss: 2.563371
 >> iter 4000, loss: 1.043783
 >> iter 5000, loss: 0.412971
 >> iter 6000, loss: 0.328108
 >> iter 7000, loss: 0.160123
 >> iter 8000, loss: 0.188188
 >> iter 9000, loss: 0.262738
 >> iter 10000, loss: 0.548067
   Number of active neurons: 3
 >> iter 11000, loss: 0.228488
 >> iter 12000, loss: 0.277224
 >> iter 13000, loss: 0.140281
 >> iter 14000, loss: 0.231629
 >> iter 15000, loss: 0.184797
 >> iter 16000, loss: 0.161244
 >> iter 17000, loss: 0.209744
 >> iter 18000, loss: 0.186575
 >> iter 19000, loss: 0.261627
 >> iter 20000, loss: 0.218170
   Number of active neurons: 3
 >> iter 21000, loss: 0.132165
 >> iter 22000, loss: 0.303591
 >> iter 23000, loss: 0.163256
 >> iter 24000, loss: 0.393476
 >> iter 25000, loss: 0.165561
 >> iter 26000, loss: 0.205779
 >> iter 27000, loss: 0.093043
 >> iter 28000, loss: 0.134880
 >> iter 29000, loss: 0.072481
 >> iter 30000, loss: 0.167152
   Number of active neurons: 3
 >> iter 31000, loss: 0.120315
 >> iter 32000, loss: 0.246926
 >> iter 33000, loss: 0.118650
 >> iter 34000, loss: 0.476090
 >> iter 35000, loss: 0.236585
 >> iter 36000, loss: 0.226032
 >> iter 37000, loss: 0.101618
 >> iter 38000, loss: 0.255420
 >> iter 39000, loss: 0.112586
 >> iter 40000, loss: 0.680432
   Number of active neurons: 3
 >> iter 41000, loss: 0.279341
 >> iter 42000, loss: 0.332944
 >> iter 43000, loss: 0.145042
 >> iter 44000, loss: 0.144367
 >> iter 45000, loss: 0.070696
 >> iter 46000, loss: 0.143111
 >> iter 47000, loss: 0.091005
 >> iter 48000, loss: 0.160969
 >> iter 49000, loss: 0.095884
 >> iter 50000, loss: 0.125274
   Number of active neurons: 3
 >> iter 51000, loss: 0.144259
 >> iter 52000, loss: 0.268020
 >> iter 53000, loss: 0.417588
 >> iter 54000, loss: 0.320333
 >> iter 55000, loss: 0.137950
 >> iter 56000, loss: 0.187396
 >> iter 57000, loss: 0.103931
 >> iter 58000, loss: 0.214386
 >> iter 59000, loss: 0.160517
 >> iter 60000, loss: 0.223918
   Number of active neurons: 3
 >> iter 61000, loss: 0.172693
 >> iter 62000, loss: 0.177155
 >> iter 63000, loss: 0.104292
 >> iter 64000, loss: 0.353894
 >> iter 65000, loss: 0.150171
 >> iter 66000, loss: 0.274533
 >> iter 67000, loss: 0.119624
 >> iter 68000, loss: 0.069313
 >> iter 69000, loss: 0.142310
 >> iter 70000, loss: 0.285528
   Number of active neurons: 3
 >> iter 71000, loss: 0.124797
 >> iter 72000, loss: 0.226925
 >> iter 73000, loss: 0.151095
 >> iter 74000, loss: 0.187233
 >> iter 75000, loss: 0.172221
 >> iter 76000, loss: 0.166204
 >> iter 77000, loss: 0.167264
 >> iter 78000, loss: 0.206468
 >> iter 79000, loss: 0.155714
 >> iter 80000, loss: 0.161447
   Number of active neurons: 3
 >> iter 81000, loss: 0.151475
 >> iter 82000, loss: 0.141108
 >> iter 83000, loss: 0.068059
 >> iter 84000, loss: 0.159148
 >> iter 85000, loss: 0.194211
 >> iter 86000, loss: 0.294061
 >> iter 87000, loss: 0.128025
 >> iter 88000, loss: 0.243792
 >> iter 89000, loss: 0.109272
 >> iter 90000, loss: 0.306664
   Number of active neurons: 3
 >> iter 91000, loss: 0.131090
 >> iter 92000, loss: 0.229964
 >> iter 93000, loss: 0.101807
 >> iter 94000, loss: 0.225213
 >> iter 95000, loss: 0.122050
 >> iter 96000, loss: 0.553230
 >> iter 97000, loss: 0.227626
 >> iter 98000, loss: 0.378427
 >> iter 99000, loss: 0.297928
 >> iter 100000, loss: 0.291954
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.783556
 >> iter 2000, loss: 7.852329
 >> iter 3000, loss: 2.974934
 >> iter 4000, loss: 1.132310
 >> iter 5000, loss: 0.459552
 >> iter 6000, loss: 0.196395
 >> iter 7000, loss: 0.115328
 >> iter 8000, loss: 0.262943
 >> iter 9000, loss: 0.228898
 >> iter 10000, loss: 0.326325
   Number of active neurons: 3
 >> iter 11000, loss: 0.213763
 >> iter 12000, loss: 0.232817
 >> iter 13000, loss: 0.363586
 >> iter 14000, loss: 0.599774
 >> iter 15000, loss: 0.539036
 >> iter 16000, loss: 0.301729
 >> iter 17000, loss: 0.168471
 >> iter 18000, loss: 0.161567
 >> iter 19000, loss: 0.099737
 >> iter 20000, loss: 0.323217
   Number of active neurons: 3
 >> iter 21000, loss: 0.231706
 >> iter 22000, loss: 0.444981
 >> iter 23000, loss: 0.446530
 >> iter 24000, loss: 0.305670
 >> iter 25000, loss: 0.285052
 >> iter 26000, loss: 0.276340
 >> iter 27000, loss: 0.147339
 >> iter 28000, loss: 0.188933
 >> iter 29000, loss: 0.165982
 >> iter 30000, loss: 0.383503
   Number of active neurons: 2
 >> iter 31000, loss: 0.256091
 >> iter 32000, loss: 0.274394
 >> iter 33000, loss: 0.147199
 >> iter 34000, loss: 0.198410
 >> iter 35000, loss: 0.111868
 >> iter 36000, loss: 0.192968
 >> iter 37000, loss: 0.230562
 >> iter 38000, loss: 0.464446
 >> iter 39000, loss: 0.256431
 >> iter 40000, loss: 0.248663
   Number of active neurons: 2
 >> iter 41000, loss: 0.149993
 >> iter 42000, loss: 0.181276
 >> iter 43000, loss: 0.208090
 >> iter 44000, loss: 0.103859
 >> iter 45000, loss: 0.246837
 >> iter 46000, loss: 0.272159
 >> iter 47000, loss: 0.186763
 >> iter 48000, loss: 0.465781
 >> iter 49000, loss: 0.246444
 >> iter 50000, loss: 0.438698
   Number of active neurons: 4
 >> iter 51000, loss: 0.516485
 >> iter 52000, loss: 0.326800
 >> iter 53000, loss: 0.178496
 >> iter 54000, loss: 0.125942
 >> iter 55000, loss: 0.335894
 >> iter 56000, loss: 1.026812
 >> iter 57000, loss: 0.568875
 >> iter 58000, loss: 0.311655
 >> iter 59000, loss: 0.141863
 >> iter 60000, loss: 0.315093
   Number of active neurons: 3
 >> iter 61000, loss: 0.301136
 >> iter 62000, loss: 0.393158
 >> iter 63000, loss: 0.424052
 >> iter 64000, loss: 0.437545
 >> iter 65000, loss: 0.259662
 >> iter 66000, loss: 0.197934
 >> iter 67000, loss: 0.247214
 >> iter 68000, loss: 0.279748
 >> iter 69000, loss: 0.126938
 >> iter 70000, loss: 0.369668
   Number of active neurons: 2
 >> iter 71000, loss: 0.256600
 >> iter 72000, loss: 0.153723
 >> iter 73000, loss: 0.523386
 >> iter 74000, loss: 0.451795
 >> iter 75000, loss: 0.438713
 >> iter 76000, loss: 0.423086
 >> iter 77000, loss: 0.216523
 >> iter 78000, loss: 0.160163
 >> iter 79000, loss: 0.358846
 >> iter 80000, loss: 0.364894
   Number of active neurons: 2
 >> iter 81000, loss: 0.752989
 >> iter 82000, loss: 0.382906
 >> iter 83000, loss: 0.201080
 >> iter 84000, loss: 0.285222
 >> iter 85000, loss: 0.485587
 >> iter 86000, loss: 0.433534
 >> iter 87000, loss: 0.195427
 >> iter 88000, loss: 0.098770
 >> iter 89000, loss: 0.144641
 >> iter 90000, loss: 0.181672
   Number of active neurons: 2
 >> iter 91000, loss: 0.108240
 >> iter 92000, loss: 0.197797
 >> iter 93000, loss: 0.364356
 >> iter 94000, loss: 0.165569
 >> iter 95000, loss: 0.349710
 >> iter 96000, loss: 0.427249
 >> iter 97000, loss: 0.431748
 >> iter 98000, loss: 0.440598
 >> iter 99000, loss: 0.194816
 >> iter 100000, loss: 0.470365
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 20.524757
 >> iter 2000, loss: 18.054294
 >> iter 3000, loss: 17.068468
 >> iter 4000, loss: 16.779382
 >> iter 5000, loss: 16.602176
 >> iter 6000, loss: 16.598210
 >> iter 7000, loss: 16.539955
 >> iter 8000, loss: 16.570997
 >> iter 9000, loss: 16.532193
 >> iter 10000, loss: 16.581952
   Number of active neurons: 0
 >> iter 11000, loss: 16.532528
 >> iter 12000, loss: 16.591992
 >> iter 13000, loss: 16.533423
 >> iter 14000, loss: 16.598222
 >> iter 15000, loss: 16.533579
 >> iter 16000, loss: 16.603690
 >> iter 17000, loss: 16.535606
 >> iter 18000, loss: 16.598738
 >> iter 19000, loss: 16.535945
 >> iter 20000, loss: 16.602369
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 16.535962
 >> iter 22000, loss: 16.597446
 >> iter 23000, loss: 16.533876
 >> iter 24000, loss: 16.596577
 >> iter 25000, loss: 16.530726
 >> iter 26000, loss: 16.602735
 >> iter 27000, loss: 16.531025
 >> iter 28000, loss: 16.595567
 >> iter 29000, loss: 16.535289
 >> iter 30000, loss: 16.598205
   Number of active neurons: 0
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 0
 >> iter 31000, loss: 16.534229
 >> iter 32000, loss: 16.594135
 >> iter 33000, loss: 16.537949
 >> iter 34000, loss: 16.586341
 >> iter 35000, loss: 16.535300
 >> iter 36000, loss: 16.581687
 >> iter 37000, loss: 16.534732
 >> iter 38000, loss: 16.572795
 >> iter 39000, loss: 16.532240
 >> iter 40000, loss: 16.565515
   Number of active neurons: 0
   SHOCK
   Setting new limit to 275000.0 iters...
   Number of active neurons: 0
 >> iter 41000, loss: 16.526951
 >> iter 42000, loss: 16.567551
 >> iter 43000, loss: 16.524121
 >> iter 44000, loss: 16.558044
 >> iter 45000, loss: 16.519591
 >> iter 46000, loss: 16.552835
 >> iter 47000, loss: 16.519598
 >> iter 48000, loss: 16.560108
 >> iter 49000, loss: 16.532470
 >> iter 50000, loss: 16.565404
   Number of active neurons: 0
   SHOCK
   Setting new limit to 287500.0 iters...
   Number of active neurons: 0
 >> iter 51000, loss: 16.533031
 >> iter 52000, loss: 16.560531
 >> iter 53000, loss: 16.528829
 >> iter 54000, loss: 16.559958
 >> iter 55000, loss: 16.532603
 >> iter 56000, loss: 16.550788
 >> iter 57000, loss: 16.533105
 >> iter 58000, loss: 16.541008
 >> iter 59000, loss: 16.532278
 >> iter 60000, loss: 16.544611
   Number of active neurons: 0
   SHOCK
   Setting new limit to 293750.0 iters...
   Number of active neurons: 0
 >> iter 61000, loss: 16.526218
 >> iter 62000, loss: 16.559355
 >> iter 63000, loss: 16.525363
 >> iter 64000, loss: 16.555528
 >> iter 65000, loss: 16.529032
 >> iter 66000, loss: 16.551661
 >> iter 67000, loss: 16.523629
 >> iter 68000, loss: 16.544404
 >> iter 69000, loss: 16.527297
 >> iter 70000, loss: 16.534417
   Number of active neurons: 0
   SHOCK
   Setting new limit to 296875.0 iters...
   Number of active neurons: 0
 >> iter 71000, loss: 16.525160
 >> iter 72000, loss: 16.523889
 >> iter 73000, loss: 16.518677
 >> iter 74000, loss: 16.515665
 >> iter 75000, loss: 16.511401
 >> iter 76000, loss: 16.517521
 >> iter 77000, loss: 16.506099
 >> iter 78000, loss: 16.506633
 >> iter 79000, loss: 16.504422
 >> iter 80000, loss: 16.514463
   Number of active neurons: 0
   SHOCK
   Setting new limit to 298437.5 iters...
   Number of active neurons: 0
 >> iter 81000, loss: 16.507666
 >> iter 82000, loss: 16.526974
 >> iter 83000, loss: 16.521908
 >> iter 84000, loss: 16.519153
 >> iter 85000, loss: 16.528901
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299218.75 iters...
 >> iter 86000, loss: 16.524565
 >> iter 87000, loss: 16.529426
 >> iter 88000, loss: 16.514365
 >> iter 89000, loss: 16.531204
 >> iter 90000, loss: 16.515747
   Number of active neurons: 0
 >> iter 91000, loss: 16.530426
 >> iter 92000, loss: 16.525725
 >> iter 93000, loss: 16.532642
 >> iter 94000, loss: 16.527651
 >> iter 95000, loss: 16.540760
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299609.375 iters...
 >> iter 96000, loss: 16.539041
 >> iter 97000, loss: 16.541463
 >> iter 98000, loss: 16.537331
 >> iter 99000, loss: 16.542144
 >> iter 100000, loss: 16.528743
   Number of active neurons: 0
 >> iter 101000, loss: 16.540538
 >> iter 102000, loss: 16.519505
 >> iter 103000, loss: 16.541796
 >> iter 104000, loss: 16.519129
 >> iter 105000, loss: 16.541221
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299804.6875 iters...
 >> iter 106000, loss: 16.509547
 >> iter 107000, loss: 16.544785
 >> iter 108000, loss: 16.517995
 >> iter 109000, loss: 16.545071
 >> iter 110000, loss: 16.516393
   Number of active neurons: 0
 >> iter 111000, loss: 16.541638
 >> iter 112000, loss: 16.533840
 >> iter 113000, loss: 16.539577
 >> iter 114000, loss: 16.536231
 >> iter 115000, loss: 16.545574
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299902.34375 iters...
 >> iter 116000, loss: 16.540123
 >> iter 117000, loss: 16.543084
 >> iter 118000, loss: 16.532600
 >> iter 119000, loss: 16.546257
 >> iter 120000, loss: 16.531827
   Number of active neurons: 0
 >> iter 121000, loss: 16.551647
 >> iter 122000, loss: 16.523715
 >> iter 123000, loss: 16.553016
 >> iter 124000, loss: 16.523042
 >> iter 125000, loss: 16.551156
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299951.171875 iters...
 >> iter 126000, loss: 16.517397
 >> iter 127000, loss: 16.553474
 >> iter 128000, loss: 16.512548
 >> iter 129000, loss: 16.555626
 >> iter 130000, loss: 16.516487
   Number of active neurons: 0
 >> iter 131000, loss: 16.556222
 >> iter 132000, loss: 16.514808
 >> iter 133000, loss: 16.558732
 >> iter 134000, loss: 16.517148
 >> iter 135000, loss: 16.559598
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299975.585938 iters...
 >> iter 136000, loss: 16.517294
 >> iter 137000, loss: 16.559816
 >> iter 138000, loss: 16.523546
 >> iter 139000, loss: 16.562677
 >> iter 140000, loss: 16.516440
   Number of active neurons: 0
 >> iter 141000, loss: 16.562978
 >> iter 142000, loss: 16.516521
 >> iter 143000, loss: 16.561885
 >> iter 144000, loss: 16.508915
 >> iter 145000, loss: 16.560464
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299987.792969 iters...
 >> iter 146000, loss: 16.510074
 >> iter 147000, loss: 16.556854
 >> iter 148000, loss: 16.519049
 >> iter 149000, loss: 16.552266
 >> iter 150000, loss: 16.512690
   Number of active neurons: 0
 >> iter 151000, loss: 16.547935
 >> iter 152000, loss: 16.519890
 >> iter 153000, loss: 16.541570
 >> iter 154000, loss: 16.513533
 >> iter 155000, loss: 16.534403
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299993.896484 iters...
 >> iter 156000, loss: 16.517175
 >> iter 157000, loss: 16.536250
 >> iter 158000, loss: 16.522635
 >> iter 159000, loss: 16.542717
 >> iter 160000, loss: 16.516297
   Number of active neurons: 0
 >> iter 161000, loss: 16.543278
 >> iter 162000, loss: 16.518605
 >> iter 163000, loss: 16.542422
 >> iter 164000, loss: 16.521287
 >> iter 165000, loss: 16.538819
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299996.948242 iters...
 >> iter 166000, loss: 16.522322
 >> iter 167000, loss: 16.534085
 >> iter 168000, loss: 16.517044
 >> iter 169000, loss: 16.530645
 >> iter 170000, loss: 16.515552
   Number of active neurons: 0
 >> iter 171000, loss: 16.536291
 >> iter 172000, loss: 16.511938
 >> iter 173000, loss: 16.537076
 >> iter 174000, loss: 16.507974
 >> iter 175000, loss: 16.531581
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299998.474121 iters...
 >> iter 176000, loss: 16.500295
 >> iter 177000, loss: 16.523782
 >> iter 178000, loss: 16.506290
 >> iter 179000, loss: 16.515280
 >> iter 180000, loss: 16.505486
   Number of active neurons: 0
 >> iter 181000, loss: 16.521133
 >> iter 182000, loss: 16.497895
 >> iter 183000, loss: 16.516522
 >> iter 184000, loss: 16.500959
 >> iter 185000, loss: 16.511760
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.237061 iters...
 >> iter 186000, loss: 16.509476
 >> iter 187000, loss: 16.502551
 >> iter 188000, loss: 16.502660
 >> iter 189000, loss: 16.501009
 >> iter 190000, loss: 16.509479
   Number of active neurons: 0
 >> iter 191000, loss: 16.497126
 >> iter 192000, loss: 16.504156
 >> iter 193000, loss: 16.501474
 >> iter 194000, loss: 16.505043
 >> iter 195000, loss: 16.495530
 >> iter 196000, loss: 16.504215
 >> iter 197000, loss: 16.508837
 >> iter 198000, loss: 16.501007
 >> iter 199000, loss: 16.508221
 >> iter 200000, loss: 16.502750
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.61853 iters...
   Number of active neurons: 0
 >> iter 201000, loss: 16.506550
 >> iter 202000, loss: 16.507368
 >> iter 203000, loss: 16.498830
 >> iter 204000, loss: 16.507906
 >> iter 205000, loss: 16.489466
 >> iter 206000, loss: 16.505161
 >> iter 207000, loss: 16.497631
 >> iter 208000, loss: 16.507922
 >> iter 209000, loss: 16.510424
 >> iter 210000, loss: 16.502158
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.809265 iters...
   Number of active neurons: 0
 >> iter 211000, loss: 16.520842
 >> iter 212000, loss: 16.499884
 >> iter 213000, loss: 16.522779
 >> iter 214000, loss: 16.502120
 >> iter 215000, loss: 16.531922
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.904633 iters...
 >> iter 216000, loss: 16.497194
 >> iter 217000, loss: 16.528868
 >> iter 218000, loss: 16.508924
 >> iter 219000, loss: 16.521665
 >> iter 220000, loss: 16.512206
   Number of active neurons: 0
 >> iter 221000, loss: 16.519973
 >> iter 222000, loss: 16.516120
 >> iter 223000, loss: 16.525474
 >> iter 224000, loss: 16.515482
 >> iter 225000, loss: 16.525426
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.952316 iters...
 >> iter 226000, loss: 16.510676
 >> iter 227000, loss: 16.525348
 >> iter 228000, loss: 16.504967
 >> iter 229000, loss: 16.529005
 >> iter 230000, loss: 16.514870
   Number of active neurons: 0
 >> iter 231000, loss: 16.530134
 >> iter 232000, loss: 16.522690
 >> iter 233000, loss: 16.528131
 >> iter 234000, loss: 16.518907
 >> iter 235000, loss: 16.525319
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.976158 iters...
 >> iter 236000, loss: 16.518113
 >> iter 237000, loss: 16.520814
 >> iter 238000, loss: 16.518572
 >> iter 239000, loss: 16.513338
 >> iter 240000, loss: 16.521411
   Number of active neurons: 0
 >> iter 241000, loss: 16.520023
 >> iter 242000, loss: 16.522753
 >> iter 243000, loss: 16.512547
 >> iter 244000, loss: 16.524870
 >> iter 245000, loss: 16.523885
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.988079 iters...
 >> iter 246000, loss: 16.528477
 >> iter 247000, loss: 16.527201
 >> iter 248000, loss: 16.526165
 >> iter 249000, loss: 16.532191
 >> iter 250000, loss: 16.525734
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99404 iters...
   Number of active neurons: 0
 >> iter 251000, loss: 16.527590
 >> iter 252000, loss: 16.530560
 >> iter 253000, loss: 16.520892
 >> iter 254000, loss: 16.527766
 >> iter 255000, loss: 16.513414
 >> iter 256000, loss: 16.530123
 >> iter 257000, loss: 16.516378
 >> iter 258000, loss: 16.529824
 >> iter 259000, loss: 16.514720
 >> iter 260000, loss: 16.526494
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99702 iters...
   Number of active neurons: 0
 >> iter 261000, loss: 16.523176
 >> iter 262000, loss: 16.529117
 >> iter 263000, loss: 16.521581
 >> iter 264000, loss: 16.529419
 >> iter 265000, loss: 16.516909
 >> iter 266000, loss: 16.526040
 >> iter 267000, loss: 16.510915
 >> iter 268000, loss: 16.524945
 >> iter 269000, loss: 16.508266
 >> iter 270000, loss: 16.524243
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99851 iters...
   Number of active neurons: 0
 >> iter 271000, loss: 16.513455
 >> iter 272000, loss: 16.528981
 >> iter 273000, loss: 16.505606
 >> iter 274000, loss: 16.531515
 >> iter 275000, loss: 16.498037
 >> iter 276000, loss: 16.532512
 >> iter 277000, loss: 16.489919
 >> iter 278000, loss: 16.529690
 >> iter 279000, loss: 16.497843
 >> iter 280000, loss: 16.525847
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.999255 iters...
   Number of active neurons: 0
 >> iter 281000, loss: 16.498379
 >> iter 282000, loss: 16.523098
 >> iter 283000, loss: 16.489525
 >> iter 284000, loss: 16.529053
 >> iter 285000, loss: 16.480044
 >> iter 286000, loss: 16.537095
 >> iter 287000, loss: 16.484722
 >> iter 288000, loss: 16.536558
 >> iter 289000, loss: 16.476376
 >> iter 290000, loss: 16.533228
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.999627 iters...
   Number of active neurons: 0
 >> iter 291000, loss: 16.476146
 >> iter 292000, loss: 16.534136
 >> iter 293000, loss: 16.486443
 >> iter 294000, loss: 16.529309
 >> iter 295000, loss: 16.477258
 >> iter 296000, loss: 16.535892
 >> iter 297000, loss: 16.476923
 >> iter 298000, loss: 16.531059
 >> iter 299000, loss: 16.467389
 >> iter 300000, loss: 16.525329
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.999814 iters...
   Number of active neurons: 0
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 35.8332833343
   - Test - Long: 87.8906054697
   - Test - Big: 36.2076379236
   - Test - A: 0.0
   - Test - B: 97.0535297647
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.707158
 >> iter 2000, loss: 7.722159
 >> iter 3000, loss: 2.920450
 >> iter 4000, loss: 1.192537
 >> iter 5000, loss: 0.468392
 >> iter 6000, loss: 0.416743
 >> iter 7000, loss: 0.179047
 >> iter 8000, loss: 0.252115
 >> iter 9000, loss: 0.142558
 >> iter 10000, loss: 0.395997
   Number of active neurons: 3
 >> iter 11000, loss: 0.173809
 >> iter 12000, loss: 0.379194
 >> iter 13000, loss: 0.221282
 >> iter 14000, loss: 0.493412
 >> iter 15000, loss: 0.301246
 >> iter 16000, loss: 0.337559
 >> iter 17000, loss: 0.389896
 >> iter 18000, loss: 0.838995
 >> iter 19000, loss: 0.629793
 >> iter 20000, loss: 0.428194
   Number of active neurons: 3
 >> iter 21000, loss: 0.356721
 >> iter 22000, loss: 0.587902
 >> iter 23000, loss: 0.278418
 >> iter 24000, loss: 0.242458
 >> iter 25000, loss: 0.383044
 >> iter 26000, loss: 0.309686
 >> iter 27000, loss: 0.387089
 >> iter 28000, loss: 0.259314
 >> iter 29000, loss: 0.380720
 >> iter 30000, loss: 0.606411
   Number of active neurons: 3
 >> iter 31000, loss: 0.405454
 >> iter 32000, loss: 0.184352
 >> iter 33000, loss: 0.132033
 >> iter 34000, loss: 0.172055
 >> iter 35000, loss: 0.094988
 >> iter 36000, loss: 0.134683
 >> iter 37000, loss: 0.093671
 >> iter 38000, loss: 0.347707
 >> iter 39000, loss: 0.215207
 >> iter 40000, loss: 0.296519
   Number of active neurons: 2
 >> iter 41000, loss: 0.304931
 >> iter 42000, loss: 0.198336
 >> iter 43000, loss: 0.125348
 >> iter 44000, loss: 0.463250
 >> iter 45000, loss: 0.200568
 >> iter 46000, loss: 0.141711
 >> iter 47000, loss: 0.534642
 >> iter 48000, loss: 0.539846
 >> iter 49000, loss: 0.369465
 >> iter 50000, loss: 0.270818
   Number of active neurons: 2
 >> iter 51000, loss: 0.148540
 >> iter 52000, loss: 0.348681
 >> iter 53000, loss: 0.189705
 >> iter 54000, loss: 0.672791
 >> iter 55000, loss: 0.391114
 >> iter 56000, loss: 0.245507
 >> iter 57000, loss: 0.199941
 >> iter 58000, loss: 0.311059
 >> iter 59000, loss: 0.240387
 >> iter 60000, loss: 0.246041
   Number of active neurons: 2
 >> iter 61000, loss: 0.399367
 >> iter 62000, loss: 0.196154
 >> iter 63000, loss: 0.532205
 >> iter 64000, loss: 0.372756
 >> iter 65000, loss: 0.397946
 >> iter 66000, loss: 1.002314
 >> iter 67000, loss: 0.756145
 >> iter 68000, loss: 0.688276
 >> iter 69000, loss: 0.286077
 >> iter 70000, loss: 0.200612
   Number of active neurons: 3
 >> iter 71000, loss: 0.241876
 >> iter 72000, loss: 0.368170
 >> iter 73000, loss: 0.159054
 >> iter 74000, loss: 0.146897
 >> iter 75000, loss: 0.071729
 >> iter 76000, loss: 0.050659
 >> iter 77000, loss: 0.044926
 >> iter 78000, loss: 0.104568
 >> iter 79000, loss: 0.053136
 >> iter 80000, loss: 0.134721
   Number of active neurons: 3
 >> iter 81000, loss: 0.245130
 >> iter 82000, loss: 0.484251
 >> iter 83000, loss: 0.201964
 >> iter 84000, loss: 0.099131
 >> iter 85000, loss: 0.052912
 >> iter 86000, loss: 0.053253
 >> iter 87000, loss: 0.184156
 >> iter 88000, loss: 0.273096
 >> iter 89000, loss: 0.120284
 >> iter 90000, loss: 0.269426
   Number of active neurons: 3
 >> iter 91000, loss: 0.118462
 >> iter 92000, loss: 0.247273
 >> iter 93000, loss: 0.143948
 >> iter 94000, loss: 0.231166
 >> iter 95000, loss: 0.194042
 >> iter 96000, loss: 0.174715
 >> iter 97000, loss: 0.100299
 >> iter 98000, loss: 0.134295
 >> iter 99000, loss: 0.141787
 >> iter 100000, loss: 0.266951
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.585173
 >> iter 2000, loss: 6.611395
 >> iter 3000, loss: 2.747877
 >> iter 4000, loss: 1.259620
 >> iter 5000, loss: 0.511021
 >> iter 6000, loss: 0.369765
 >> iter 7000, loss: 0.180173
 >> iter 8000, loss: 0.171285
 >> iter 9000, loss: 0.121396
 >> iter 10000, loss: 0.585019
   Number of active neurons: 4
 >> iter 11000, loss: 0.258480
 >> iter 12000, loss: 0.234336
 >> iter 13000, loss: 0.166338
 >> iter 14000, loss: 0.174066
 >> iter 15000, loss: 0.082323
 >> iter 16000, loss: 0.199501
 >> iter 17000, loss: 0.108479
 >> iter 18000, loss: 0.133364
 >> iter 19000, loss: 0.087721
 >> iter 20000, loss: 0.127369
   Number of active neurons: 4
 >> iter 21000, loss: 0.085147
 >> iter 22000, loss: 0.277765
 >> iter 23000, loss: 0.234925
 >> iter 24000, loss: 0.254707
 >> iter 25000, loss: 0.112238
 >> iter 26000, loss: 0.434762
 >> iter 27000, loss: 0.182342
 >> iter 28000, loss: 0.118074
 >> iter 29000, loss: 0.156690
 >> iter 30000, loss: 0.085128
   Number of active neurons: 3
 >> iter 31000, loss: 0.269194
 >> iter 32000, loss: 0.241762
 >> iter 33000, loss: 0.108297
 >> iter 34000, loss: 0.272208
 >> iter 35000, loss: 0.118172
 >> iter 36000, loss: 0.233187
 >> iter 37000, loss: 0.103339
 >> iter 38000, loss: 0.548532
 >> iter 39000, loss: 0.225365
 >> iter 40000, loss: 0.107345
   Number of active neurons: 3
 >> iter 41000, loss: 0.055947
 >> iter 42000, loss: 0.348879
 >> iter 43000, loss: 0.149061
 >> iter 44000, loss: 0.239938
 >> iter 45000, loss: 0.106413
 >> iter 46000, loss: 0.212151
 >> iter 47000, loss: 0.211109
 >> iter 48000, loss: 0.105912
 >> iter 49000, loss: 0.079719
 >> iter 50000, loss: 0.658143
   Number of active neurons: 3
 >> iter 51000, loss: 0.356459
 >> iter 52000, loss: 0.261464
 >> iter 53000, loss: 0.124872
 >> iter 54000, loss: 0.086530
 >> iter 55000, loss: 0.606580
 >> iter 56000, loss: 0.403660
 >> iter 57000, loss: 0.172300
 >> iter 58000, loss: 0.342935
 >> iter 59000, loss: 0.232588
 >> iter 60000, loss: 0.175989
   Number of active neurons: 3
 >> iter 61000, loss: 0.084150
 >> iter 62000, loss: 0.270745
 >> iter 63000, loss: 0.264636
 >> iter 64000, loss: 0.357854
 >> iter 65000, loss: 0.204019
 >> iter 66000, loss: 0.252561
 >> iter 67000, loss: 0.132858
 >> iter 68000, loss: 0.475868
 >> iter 69000, loss: 0.338476
 >> iter 70000, loss: 0.244543
   Number of active neurons: 3
 >> iter 71000, loss: 0.187284
 >> iter 72000, loss: 0.186384
 >> iter 73000, loss: 0.113444
 >> iter 74000, loss: 0.130852
 >> iter 75000, loss: 0.206348
 >> iter 76000, loss: 0.826095
 >> iter 77000, loss: 0.331069
 >> iter 78000, loss: 0.241670
 >> iter 79000, loss: 0.107082
 >> iter 80000, loss: 0.335893
   Number of active neurons: 3
 >> iter 81000, loss: 0.142229
 >> iter 82000, loss: 0.211918
 >> iter 83000, loss: 0.112092
 >> iter 84000, loss: 0.349800
 >> iter 85000, loss: 0.149465
 >> iter 86000, loss: 0.090008
 >> iter 87000, loss: 0.049521
 >> iter 88000, loss: 0.055531
 >> iter 89000, loss: 0.060332
 >> iter 90000, loss: 0.233417
   Number of active neurons: 3
 >> iter 91000, loss: 0.187688
 >> iter 92000, loss: 0.165238
 >> iter 93000, loss: 0.134187
 >> iter 94000, loss: 0.193555
 >> iter 95000, loss: 0.176806
 >> iter 96000, loss: 0.194681
 >> iter 97000, loss: 0.230869
 >> iter 98000, loss: 0.127353
 >> iter 99000, loss: 0.233370
 >> iter 100000, loss: 0.215109
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0069999300007
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524751
 >> iter 2000, loss: 18.054289
 >> iter 3000, loss: 17.068466
 >> iter 4000, loss: 16.779388
 >> iter 5000, loss: 16.602178
 >> iter 6000, loss: 16.598218
 >> iter 7000, loss: 16.539958
 >> iter 8000, loss: 16.571003
 >> iter 9000, loss: 16.532196
 >> iter 10000, loss: 16.581959
   Number of active neurons: 0
 >> iter 11000, loss: 16.532531
 >> iter 12000, loss: 16.592002
 >> iter 13000, loss: 16.533427
 >> iter 14000, loss: 16.598229
 >> iter 15000, loss: 16.533582
 >> iter 16000, loss: 16.603697
 >> iter 17000, loss: 16.535610
 >> iter 18000, loss: 16.598742
 >> iter 19000, loss: 16.535947
 >> iter 20000, loss: 16.602373
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 16.535964
 >> iter 22000, loss: 16.597447
 >> iter 23000, loss: 16.533876
 >> iter 24000, loss: 16.596577
 >> iter 25000, loss: 16.530725
 >> iter 26000, loss: 16.602737
 >> iter 27000, loss: 16.531025
 >> iter 28000, loss: 16.595566
 >> iter 29000, loss: 16.535289
 >> iter 30000, loss: 16.598205
   Number of active neurons: 0
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 0
 >> iter 31000, loss: 16.534228
 >> iter 32000, loss: 16.594138
 >> iter 33000, loss: 16.537950
 >> iter 34000, loss: 16.586341
 >> iter 35000, loss: 16.535299
 >> iter 36000, loss: 16.581688
 >> iter 37000, loss: 16.534733
 >> iter 38000, loss: 16.572798
 >> iter 39000, loss: 16.532241
 >> iter 40000, loss: 16.565517
   Number of active neurons: 0
   SHOCK
   Setting new limit to 275000.0 iters...
   Number of active neurons: 0
 >> iter 41000, loss: 16.526952
 >> iter 42000, loss: 16.567554
 >> iter 43000, loss: 16.524123
 >> iter 44000, loss: 16.558048
 >> iter 45000, loss: 16.519593
 >> iter 46000, loss: 16.552836
 >> iter 47000, loss: 16.519598
 >> iter 48000, loss: 16.560110
 >> iter 49000, loss: 16.532471
 >> iter 50000, loss: 16.565402
   Number of active neurons: 0
   SHOCK
   Setting new limit to 287500.0 iters...
   Number of active neurons: 0
 >> iter 51000, loss: 16.533030
 >> iter 52000, loss: 16.560530
 >> iter 53000, loss: 16.528828
 >> iter 54000, loss: 16.559959
 >> iter 55000, loss: 16.532603
 >> iter 56000, loss: 16.550788
 >> iter 57000, loss: 16.533105
 >> iter 58000, loss: 16.541009
 >> iter 59000, loss: 16.532278
 >> iter 60000, loss: 16.544614
   Number of active neurons: 0
   SHOCK
   Setting new limit to 293750.0 iters...
   Number of active neurons: 0
 >> iter 61000, loss: 16.526219
 >> iter 62000, loss: 16.559355
 >> iter 63000, loss: 16.525363
 >> iter 64000, loss: 16.555524
 >> iter 65000, loss: 16.529031
 >> iter 66000, loss: 16.551660
 >> iter 67000, loss: 16.523628
 >> iter 68000, loss: 16.544407
 >> iter 69000, loss: 16.527298
 >> iter 70000, loss: 16.534421
   Number of active neurons: 0
   SHOCK
   Setting new limit to 296875.0 iters...
   Number of active neurons: 0
 >> iter 71000, loss: 16.525162
 >> iter 72000, loss: 16.523891
 >> iter 73000, loss: 16.518678
 >> iter 74000, loss: 16.515666
 >> iter 75000, loss: 16.511401
 >> iter 76000, loss: 16.517520
 >> iter 77000, loss: 16.506099
 >> iter 78000, loss: 16.506631
 >> iter 79000, loss: 16.504422
 >> iter 80000, loss: 16.514459
   Number of active neurons: 0
   SHOCK
   Setting new limit to 298437.5 iters...
   Number of active neurons: 0
 >> iter 81000, loss: 16.507665
 >> iter 82000, loss: 16.526975
 >> iter 83000, loss: 16.521908
 >> iter 84000, loss: 16.519152
 >> iter 85000, loss: 16.528901
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299218.75 iters...
 >> iter 86000, loss: 16.524565
 >> iter 87000, loss: 16.529426
 >> iter 88000, loss: 16.514364
 >> iter 89000, loss: 16.531204
 >> iter 90000, loss: 16.515746
   Number of active neurons: 0
 >> iter 91000, loss: 16.530426
 >> iter 92000, loss: 16.525723
 >> iter 93000, loss: 16.532641
 >> iter 94000, loss: 16.527650
 >> iter 95000, loss: 16.540759
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299609.375 iters...
 >> iter 96000, loss: 16.539041
 >> iter 97000, loss: 16.541462
 >> iter 98000, loss: 16.537332
 >> iter 99000, loss: 16.542145
 >> iter 100000, loss: 16.528739
   Number of active neurons: 0
 >> iter 101000, loss: 16.540536
 >> iter 102000, loss: 16.519506
 >> iter 103000, loss: 16.541797
 >> iter 104000, loss: 16.519128
 >> iter 105000, loss: 16.541221
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299804.6875 iters...
 >> iter 106000, loss: 16.509547
 >> iter 107000, loss: 16.544785
 >> iter 108000, loss: 16.517994
 >> iter 109000, loss: 16.545070
 >> iter 110000, loss: 16.516392
   Number of active neurons: 0
 >> iter 111000, loss: 16.541638
 >> iter 112000, loss: 16.533840
 >> iter 113000, loss: 16.539577
 >> iter 114000, loss: 16.536230
 >> iter 115000, loss: 16.545574
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299902.34375 iters...
 >> iter 116000, loss: 16.540120
 >> iter 117000, loss: 16.543082
 >> iter 118000, loss: 16.532599
 >> iter 119000, loss: 16.546257
 >> iter 120000, loss: 16.531825
   Number of active neurons: 0
 >> iter 121000, loss: 16.551646
 >> iter 122000, loss: 16.523715
 >> iter 123000, loss: 16.553016
 >> iter 124000, loss: 16.523044
 >> iter 125000, loss: 16.551157
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299951.171875 iters...
 >> iter 126000, loss: 16.517396
 >> iter 127000, loss: 16.553474
 >> iter 128000, loss: 16.512548
 >> iter 129000, loss: 16.555626
 >> iter 130000, loss: 16.516488
   Number of active neurons: 0
 >> iter 131000, loss: 16.556223
 >> iter 132000, loss: 16.514805
 >> iter 133000, loss: 16.558731
 >> iter 134000, loss: 16.517146
 >> iter 135000, loss: 16.559598
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299975.585938 iters...
 >> iter 136000, loss: 16.517291
 >> iter 137000, loss: 16.559815
 >> iter 138000, loss: 16.523544
 >> iter 139000, loss: 16.562676
 >> iter 140000, loss: 16.516442
   Number of active neurons: 0
 >> iter 141000, loss: 16.562980
 >> iter 142000, loss: 16.516522
 >> iter 143000, loss: 16.561885
 >> iter 144000, loss: 16.508916
 >> iter 145000, loss: 16.560464
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299987.792969 iters...
 >> iter 146000, loss: 16.510077
 >> iter 147000, loss: 16.556855
 >> iter 148000, loss: 16.519052
 >> iter 149000, loss: 16.552267
 >> iter 150000, loss: 16.512694
   Number of active neurons: 0
 >> iter 151000, loss: 16.547936
 >> iter 152000, loss: 16.519891
 >> iter 153000, loss: 16.541571
 >> iter 154000, loss: 16.513531
 >> iter 155000, loss: 16.534402
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299993.896484 iters...
 >> iter 156000, loss: 16.517176
 >> iter 157000, loss: 16.536250
 >> iter 158000, loss: 16.522636
 >> iter 159000, loss: 16.542717
 >> iter 160000, loss: 16.516294
   Number of active neurons: 0
 >> iter 161000, loss: 16.543278
 >> iter 162000, loss: 16.518605
 >> iter 163000, loss: 16.542422
 >> iter 164000, loss: 16.521283
 >> iter 165000, loss: 16.538818
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299996.948242 iters...
 >> iter 166000, loss: 16.522322
 >> iter 167000, loss: 16.534085
 >> iter 168000, loss: 16.517043
 >> iter 169000, loss: 16.530644
 >> iter 170000, loss: 16.515557
   Number of active neurons: 0
 >> iter 171000, loss: 16.536293
 >> iter 172000, loss: 16.511938
 >> iter 173000, loss: 16.537076
 >> iter 174000, loss: 16.507972
 >> iter 175000, loss: 16.531580
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299998.474121 iters...
 >> iter 176000, loss: 16.500295
 >> iter 177000, loss: 16.523782
 >> iter 178000, loss: 16.506290
 >> iter 179000, loss: 16.515280
 >> iter 180000, loss: 16.505485
   Number of active neurons: 0
 >> iter 181000, loss: 16.521133
 >> iter 182000, loss: 16.497895
 >> iter 183000, loss: 16.516522
 >> iter 184000, loss: 16.500960
 >> iter 185000, loss: 16.511760
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.237061 iters...
 >> iter 186000, loss: 16.509477
 >> iter 187000, loss: 16.502552
 >> iter 188000, loss: 16.502661
 >> iter 189000, loss: 16.501010
 >> iter 190000, loss: 16.509482
   Number of active neurons: 0
 >> iter 191000, loss: 16.497128
 >> iter 192000, loss: 16.504161
 >> iter 193000, loss: 16.501476
 >> iter 194000, loss: 16.505044
 >> iter 195000, loss: 16.495530
 >> iter 196000, loss: 16.504215
 >> iter 197000, loss: 16.508837
 >> iter 198000, loss: 16.501007
 >> iter 199000, loss: 16.508222
 >> iter 200000, loss: 16.502747
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.61853 iters...
   Number of active neurons: 0
 >> iter 201000, loss: 16.506549
 >> iter 202000, loss: 16.507368
 >> iter 203000, loss: 16.498830
 >> iter 204000, loss: 16.507905
 >> iter 205000, loss: 16.489466
 >> iter 206000, loss: 16.505160
 >> iter 207000, loss: 16.497631
 >> iter 208000, loss: 16.507923
 >> iter 209000, loss: 16.510425
 >> iter 210000, loss: 16.502154
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.809265 iters...
   Number of active neurons: 0
 >> iter 211000, loss: 16.520840
 >> iter 212000, loss: 16.499883
 >> iter 213000, loss: 16.522779
 >> iter 214000, loss: 16.502119
 >> iter 215000, loss: 16.531922
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.904633 iters...
 >> iter 216000, loss: 16.497194
 >> iter 217000, loss: 16.528868
 >> iter 218000, loss: 16.508924
 >> iter 219000, loss: 16.521664
 >> iter 220000, loss: 16.512209
   Number of active neurons: 0
 >> iter 221000, loss: 16.519974
 >> iter 222000, loss: 16.516123
 >> iter 223000, loss: 16.525475
 >> iter 224000, loss: 16.515484
 >> iter 225000, loss: 16.525427
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.952316 iters...
 >> iter 226000, loss: 16.510675
 >> iter 227000, loss: 16.525348
 >> iter 228000, loss: 16.504965
 >> iter 229000, loss: 16.529004
 >> iter 230000, loss: 16.514867
   Number of active neurons: 0
 >> iter 231000, loss: 16.530132
 >> iter 232000, loss: 16.522690
 >> iter 233000, loss: 16.528131
 >> iter 234000, loss: 16.518906
 >> iter 235000, loss: 16.525318
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.976158 iters...
 >> iter 236000, loss: 16.518113
 >> iter 237000, loss: 16.520814
 >> iter 238000, loss: 16.518569
 >> iter 239000, loss: 16.513337
 >> iter 240000, loss: 16.521409
   Number of active neurons: 0
 >> iter 241000, loss: 16.520022
 >> iter 242000, loss: 16.522755
 >> iter 243000, loss: 16.512547
 >> iter 244000, loss: 16.524874
 >> iter 245000, loss: 16.523887
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.988079 iters...
 >> iter 246000, loss: 16.528477
 >> iter 247000, loss: 16.527201
 >> iter 248000, loss: 16.526166
 >> iter 249000, loss: 16.532192
 >> iter 250000, loss: 16.525735
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99404 iters...
   Number of active neurons: 0
 >> iter 251000, loss: 16.527590
 >> iter 252000, loss: 16.530562
 >> iter 253000, loss: 16.520892
 >> iter 254000, loss: 16.527769
 >> iter 255000, loss: 16.513416
 >> iter 256000, loss: 16.530124
 >> iter 257000, loss: 16.516379
 >> iter 258000, loss: 16.529822
 >> iter 259000, loss: 16.514719
 >> iter 260000, loss: 16.526493
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99702 iters...
   Number of active neurons: 0
 >> iter 261000, loss: 16.523176
 >> iter 262000, loss: 16.529116
 >> iter 263000, loss: 16.521581
 >> iter 264000, loss: 16.529418
 >> iter 265000, loss: 16.516909
 >> iter 266000, loss: 16.526038
 >> iter 267000, loss: 16.510915
 >> iter 268000, loss: 16.524944
 >> iter 269000, loss: 16.508265
 >> iter 270000, loss: 16.524242
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99851 iters...
   Number of active neurons: 0
 >> iter 271000, loss: 16.513455
 >> iter 272000, loss: 16.528979
 >> iter 273000, loss: 16.505605
 >> iter 274000, loss: 16.531513
 >> iter 275000, loss: 16.498036
 >> iter 276000, loss: 16.532515
 >> iter 277000, loss: 16.489920
 >> iter 278000, loss: 16.529693
 >> iter 279000, loss: 16.497843
 >> iter 280000, loss: 16.525850
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.999255 iters...
   Number of active neurons: 0
 >> iter 281000, loss: 16.498380
 >> iter 282000, loss: 16.523096
 >> iter 283000, loss: 16.489524
 >> iter 284000, loss: 16.529053
 >> iter 285000, loss: 16.480044
 >> iter 286000, loss: 16.537095
 >> iter 287000, loss: 16.484723
 >> iter 288000, loss: 16.536554
 >> iter 289000, loss: 16.476375
 >> iter 290000, loss: 16.533225
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.999627 iters...
   Number of active neurons: 0
 >> iter 291000, loss: 16.476144
 >> iter 292000, loss: 16.534138
 >> iter 293000, loss: 16.486444
 >> iter 294000, loss: 16.529311
 >> iter 295000, loss: 16.477259
 >> iter 296000, loss: 16.535890
 >> iter 297000, loss: 16.476922
 >> iter 298000, loss: 16.531060
 >> iter 299000, loss: 16.467390
 >> iter 300000, loss: 16.525329
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.999814 iters...
   Number of active neurons: 0
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 35.8332833343
   - Test - Long: 87.8906054697
   - Test - Big: 36.2076379236
   - Test - A: 0.0
   - Test - B: 97.0535297647
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.785549
 >> iter 2000, loss: 6.388097
 >> iter 3000, loss: 2.482150
 >> iter 4000, loss: 1.155451
 >> iter 5000, loss: 0.585992
 >> iter 6000, loss: 0.669338
 >> iter 7000, loss: 0.407990
 >> iter 8000, loss: 0.465087
 >> iter 9000, loss: 0.241715
 >> iter 10000, loss: 0.563802
   Number of active neurons: 4
 >> iter 11000, loss: 0.421278
 >> iter 12000, loss: 0.286117
 >> iter 13000, loss: 0.195367
 >> iter 14000, loss: 0.621244
 >> iter 15000, loss: 0.503046
 >> iter 16000, loss: 0.423109
 >> iter 17000, loss: 0.252883
 >> iter 18000, loss: 0.439628
 >> iter 19000, loss: 0.502732
 >> iter 20000, loss: 0.213229
   Number of active neurons: 4
 >> iter 21000, loss: 0.242176
 >> iter 22000, loss: 0.427274
 >> iter 23000, loss: 0.392771
 >> iter 24000, loss: 0.217617
 >> iter 25000, loss: 0.142806
 >> iter 26000, loss: 0.309916
 >> iter 27000, loss: 0.260095
 >> iter 28000, loss: 0.473937
 >> iter 29000, loss: 0.224576
 >> iter 30000, loss: 0.330081
   Number of active neurons: 4
 >> iter 31000, loss: 0.271664
 >> iter 32000, loss: 0.446117
 >> iter 33000, loss: 0.502771
 >> iter 34000, loss: 0.486502
 >> iter 35000, loss: 0.280409
 >> iter 36000, loss: 0.458769
 >> iter 37000, loss: 0.239286
 >> iter 38000, loss: 0.297168
 >> iter 39000, loss: 0.174886
 >> iter 40000, loss: 0.351970
   Number of active neurons: 4
 >> iter 41000, loss: 0.294198
 >> iter 42000, loss: 0.272701
 >> iter 43000, loss: 0.178913
 >> iter 44000, loss: 0.331405
 >> iter 45000, loss: 0.195381
 >> iter 46000, loss: 0.306558
 >> iter 47000, loss: 0.324299
 >> iter 48000, loss: 0.249189
 >> iter 49000, loss: 0.177814
 >> iter 50000, loss: 0.393062
   Number of active neurons: 3
 >> iter 51000, loss: 0.255852
 >> iter 52000, loss: 0.120237
 >> iter 53000, loss: 0.244753
 >> iter 54000, loss: 0.111301
 >> iter 55000, loss: 0.197296
 >> iter 56000, loss: 0.371561
 >> iter 57000, loss: 0.210140
 >> iter 58000, loss: 0.229337
 >> iter 59000, loss: 0.173004
 >> iter 60000, loss: 0.141103
   Number of active neurons: 3
 >> iter 61000, loss: 0.068699
 >> iter 62000, loss: 0.434220
 >> iter 63000, loss: 0.202427
 >> iter 64000, loss: 0.256288
 >> iter 65000, loss: 0.160282
 >> iter 66000, loss: 0.306580
 >> iter 67000, loss: 0.191409
 >> iter 68000, loss: 0.364514
 >> iter 69000, loss: 0.215596
 >> iter 70000, loss: 0.256973
   Number of active neurons: 3
 >> iter 71000, loss: 0.131956
 >> iter 72000, loss: 0.248304
 >> iter 73000, loss: 0.325085
 >> iter 74000, loss: 0.281640
 >> iter 75000, loss: 0.199119
 >> iter 76000, loss: 0.366058
 >> iter 77000, loss: 0.214826
 >> iter 78000, loss: 0.226676
 >> iter 79000, loss: 0.166466
 >> iter 80000, loss: 0.200380
   Number of active neurons: 3
 >> iter 81000, loss: 0.236443
 >> iter 82000, loss: 0.411516
 >> iter 83000, loss: 0.218371
 >> iter 84000, loss: 0.114236
 >> iter 85000, loss: 0.144401
 >> iter 86000, loss: 0.310242
 >> iter 87000, loss: 0.277097
 >> iter 88000, loss: 0.207140
 >> iter 89000, loss: 0.254558
 >> iter 90000, loss: 0.449939
   Number of active neurons: 3
 >> iter 91000, loss: 0.264454
 >> iter 92000, loss: 0.287108
 >> iter 93000, loss: 0.208701
 >> iter 94000, loss: 0.121113
 >> iter 95000, loss: 0.081299
 >> iter 96000, loss: 0.181887
 >> iter 97000, loss: 0.155470
 >> iter 98000, loss: 0.193628
 >> iter 99000, loss: 0.241436
 >> iter 100000, loss: 0.316857
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.369464
 >> iter 2000, loss: 5.868738
 >> iter 3000, loss: 2.189175
 >> iter 4000, loss: 1.354385
 >> iter 5000, loss: 0.541681
 >> iter 6000, loss: 0.304684
 >> iter 7000, loss: 0.275826
 >> iter 8000, loss: 0.292291
 >> iter 9000, loss: 0.177320
 >> iter 10000, loss: 0.126231
   Number of active neurons: 3
 >> iter 11000, loss: 0.130426
 >> iter 12000, loss: 0.158962
 >> iter 13000, loss: 0.153367
 >> iter 14000, loss: 0.179181
 >> iter 15000, loss: 0.130873
 >> iter 16000, loss: 0.198581
 >> iter 17000, loss: 0.127247
 >> iter 18000, loss: 0.499714
 >> iter 19000, loss: 0.210907
 >> iter 20000, loss: 0.154147
   Number of active neurons: 3
 >> iter 21000, loss: 0.122704
 >> iter 22000, loss: 0.342369
 >> iter 23000, loss: 0.163665
 >> iter 24000, loss: 0.292756
 >> iter 25000, loss: 0.422865
 >> iter 26000, loss: 0.418195
 >> iter 27000, loss: 0.240571
 >> iter 28000, loss: 0.164872
 >> iter 29000, loss: 0.122382
 >> iter 30000, loss: 0.345368
   Number of active neurons: 3
 >> iter 31000, loss: 0.329646
 >> iter 32000, loss: 0.411462
 >> iter 33000, loss: 0.210487
 >> iter 34000, loss: 0.360025
 >> iter 35000, loss: 0.326449
 >> iter 36000, loss: 0.145889
 >> iter 37000, loss: 0.156020
 >> iter 38000, loss: 0.179694
 >> iter 39000, loss: 0.174149
 >> iter 40000, loss: 0.188372
   Number of active neurons: 3
 >> iter 41000, loss: 0.228793
 >> iter 42000, loss: 0.397811
 >> iter 43000, loss: 0.232638
 >> iter 44000, loss: 0.320487
 >> iter 45000, loss: 0.219736
 >> iter 46000, loss: 0.190947
 >> iter 47000, loss: 0.116120
 >> iter 48000, loss: 0.161563
 >> iter 49000, loss: 0.171218
 >> iter 50000, loss: 0.116787
   Number of active neurons: 3
 >> iter 51000, loss: 0.159232
 >> iter 52000, loss: 0.272989
 >> iter 53000, loss: 0.279027
 >> iter 54000, loss: 0.231129
 >> iter 55000, loss: 0.197959
 >> iter 56000, loss: 0.127076
 >> iter 57000, loss: 0.130343
 >> iter 58000, loss: 0.307891
 >> iter 59000, loss: 0.206970
 >> iter 60000, loss: 0.100247
   Number of active neurons: 3
 >> iter 61000, loss: 0.267644
 >> iter 62000, loss: 0.230209
 >> iter 63000, loss: 0.182074
 >> iter 64000, loss: 0.157359
 >> iter 65000, loss: 0.246336
 >> iter 66000, loss: 0.321669
 >> iter 67000, loss: 0.275818
 >> iter 68000, loss: 0.420075
 >> iter 69000, loss: 0.195806
 >> iter 70000, loss: 0.173149
   Number of active neurons: 3
 >> iter 71000, loss: 0.436597
 >> iter 72000, loss: 0.427004
 >> iter 73000, loss: 0.305196
 >> iter 74000, loss: 0.167380
 >> iter 75000, loss: 0.143946
 >> iter 76000, loss: 0.236429
 >> iter 77000, loss: 0.371051
 >> iter 78000, loss: 0.203501
 >> iter 79000, loss: 0.216938
 >> iter 80000, loss: 0.228016
   Number of active neurons: 3
 >> iter 81000, loss: 0.240034
 >> iter 82000, loss: 0.401163
 >> iter 83000, loss: 0.174269
 >> iter 84000, loss: 0.404631
 >> iter 85000, loss: 0.268173
 >> iter 86000, loss: 0.326430
 >> iter 87000, loss: 0.154426
 >> iter 88000, loss: 0.388490
 >> iter 89000, loss: 0.297783
 >> iter 90000, loss: 0.308674
   Number of active neurons: 3
 >> iter 91000, loss: 0.200919
 >> iter 92000, loss: 0.133598
 >> iter 93000, loss: 0.276181
 >> iter 94000, loss: 0.231508
 >> iter 95000, loss: 0.343171
 >> iter 96000, loss: 0.278876
 >> iter 97000, loss: 0.165058
 >> iter 98000, loss: 0.113201
 >> iter 99000, loss: 0.143111
 >> iter 100000, loss: 0.357971
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0179996400072
   - Test - Long: 0.0
   - Test - Big: 0.0349996500035
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.643343
 >> iter 2000, loss: 6.184372
 >> iter 3000, loss: 2.322199
 >> iter 4000, loss: 1.064253
 >> iter 5000, loss: 0.481980
 >> iter 6000, loss: 0.334916
 >> iter 7000, loss: 0.580981
 >> iter 8000, loss: 0.346315
 >> iter 9000, loss: 0.176713
 >> iter 10000, loss: 0.764321
   Number of active neurons: 3
 >> iter 11000, loss: 0.324513
 >> iter 12000, loss: 0.141726
 >> iter 13000, loss: 0.447408
 >> iter 14000, loss: 0.192222
 >> iter 15000, loss: 0.314369
 >> iter 16000, loss: 0.209491
 >> iter 17000, loss: 0.260424
 >> iter 18000, loss: 0.231077
 >> iter 19000, loss: 0.129777
 >> iter 20000, loss: 0.267448
   Number of active neurons: 3
 >> iter 21000, loss: 0.182550
 >> iter 22000, loss: 0.438546
 >> iter 23000, loss: 0.388174
 >> iter 24000, loss: 0.415973
 >> iter 25000, loss: 0.196914
 >> iter 26000, loss: 0.473346
 >> iter 27000, loss: 0.286983
 >> iter 28000, loss: 0.347187
 >> iter 29000, loss: 0.207150
 >> iter 30000, loss: 0.133884
   Number of active neurons: 3
 >> iter 31000, loss: 0.168320
 >> iter 32000, loss: 0.292596
 >> iter 33000, loss: 0.211656
 >> iter 34000, loss: 0.296606
 >> iter 35000, loss: 0.148870
 >> iter 36000, loss: 0.333363
 >> iter 37000, loss: 0.531690
 >> iter 38000, loss: 0.355640
 >> iter 39000, loss: 0.219539
 >> iter 40000, loss: 0.221455
   Number of active neurons: 3
 >> iter 41000, loss: 0.131234
 >> iter 42000, loss: 0.201507
 >> iter 43000, loss: 0.459928
 >> iter 44000, loss: 0.307644
 >> iter 45000, loss: 0.264711
 >> iter 46000, loss: 0.299133
 >> iter 47000, loss: 0.161510
 >> iter 48000, loss: 0.211509
 >> iter 49000, loss: 0.165957
 >> iter 50000, loss: 0.149566
   Number of active neurons: 3
 >> iter 51000, loss: 0.163361
 >> iter 52000, loss: 0.143364
 >> iter 53000, loss: 0.221920
 >> iter 54000, loss: 0.202190
 >> iter 55000, loss: 0.166420
 >> iter 56000, loss: 0.191457
 >> iter 57000, loss: 0.236479
 >> iter 58000, loss: 0.109235
 >> iter 59000, loss: 0.157600
 >> iter 60000, loss: 0.080783
   Number of active neurons: 3
 >> iter 61000, loss: 0.177009
 >> iter 62000, loss: 0.234495
 >> iter 63000, loss: 0.175769
 >> iter 64000, loss: 0.129313
 >> iter 65000, loss: 0.113408
 >> iter 66000, loss: 0.224856
 >> iter 67000, loss: 0.140557
 >> iter 68000, loss: 0.192199
 >> iter 69000, loss: 0.226729
 >> iter 70000, loss: 0.287156
   Number of active neurons: 3
 >> iter 71000, loss: 0.236716
 >> iter 72000, loss: 0.209106
 >> iter 73000, loss: 0.369311
 >> iter 74000, loss: 0.346904
 >> iter 75000, loss: 0.169368
 >> iter 76000, loss: 0.272002
 >> iter 77000, loss: 0.148177
 >> iter 78000, loss: 0.132927
 >> iter 79000, loss: 0.180772
 >> iter 80000, loss: 0.438255
   Number of active neurons: 3
 >> iter 81000, loss: 0.465425
 >> iter 82000, loss: 0.424073
 >> iter 83000, loss: 0.237975
 >> iter 84000, loss: 0.281347
 >> iter 85000, loss: 0.195596
 >> iter 86000, loss: 0.578014
 >> iter 87000, loss: 0.298480
 >> iter 88000, loss: 0.327700
 >> iter 89000, loss: 0.190029
 >> iter 90000, loss: 0.365201
   Number of active neurons: 3
 >> iter 91000, loss: 0.218791
 >> iter 92000, loss: 0.355418
 >> iter 93000, loss: 0.191260
 >> iter 94000, loss: 0.260469
 >> iter 95000, loss: 0.184978
 >> iter 96000, loss: 0.207160
 >> iter 97000, loss: 0.154337
 >> iter 98000, loss: 0.567975
 >> iter 99000, loss: 0.364466
 >> iter 100000, loss: 0.269357
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.694636
 >> iter 2000, loss: 6.210579
 >> iter 3000, loss: 2.403623
 >> iter 4000, loss: 0.978355
 >> iter 5000, loss: 0.385390
 >> iter 6000, loss: 0.240159
 >> iter 7000, loss: 0.130457
 >> iter 8000, loss: 0.184670
 >> iter 9000, loss: 0.254557
 >> iter 10000, loss: 0.284508
   Number of active neurons: 2
 >> iter 11000, loss: 0.217224
 >> iter 12000, loss: 0.177486
 >> iter 13000, loss: 0.152411
 >> iter 14000, loss: 0.185371
 >> iter 15000, loss: 0.418929
 >> iter 16000, loss: 0.261880
 >> iter 17000, loss: 0.151910
 >> iter 18000, loss: 0.186162
 >> iter 19000, loss: 0.135184
 >> iter 20000, loss: 0.181480
   Number of active neurons: 2
 >> iter 21000, loss: 0.331796
 >> iter 22000, loss: 0.455222
 >> iter 23000, loss: 0.448343
 >> iter 24000, loss: 0.658774
 >> iter 25000, loss: 0.308445
 >> iter 26000, loss: 0.234556
 >> iter 27000, loss: 0.110947
 >> iter 28000, loss: 0.163368
 >> iter 29000, loss: 0.152859
 >> iter 30000, loss: 0.189468
   Number of active neurons: 2
 >> iter 31000, loss: 0.288033
 >> iter 32000, loss: 0.202688
 >> iter 33000, loss: 0.206256
 >> iter 34000, loss: 0.228623
 >> iter 35000, loss: 0.126360
 >> iter 36000, loss: 0.177108
 >> iter 37000, loss: 0.223333
 >> iter 38000, loss: 0.216070
 >> iter 39000, loss: 0.356709
 >> iter 40000, loss: 0.286355
   Number of active neurons: 2
 >> iter 41000, loss: 0.183066
 >> iter 42000, loss: 0.204833
 >> iter 43000, loss: 0.166014
 >> iter 44000, loss: 0.157270
 >> iter 45000, loss: 0.503757
 >> iter 46000, loss: 0.286783
 >> iter 47000, loss: 0.173336
 >> iter 48000, loss: 0.195391
 >> iter 49000, loss: 0.144145
 >> iter 50000, loss: 0.148015
   Number of active neurons: 2
 >> iter 51000, loss: 0.268595
 >> iter 52000, loss: 0.313285
 >> iter 53000, loss: 0.174569
 >> iter 54000, loss: 0.210944
 >> iter 55000, loss: 0.130245
 >> iter 56000, loss: 0.177066
 >> iter 57000, loss: 0.799932
 >> iter 58000, loss: 0.387239
 >> iter 59000, loss: 0.165419
 >> iter 60000, loss: 0.224669
   Number of active neurons: 2
 >> iter 61000, loss: 0.224574
 >> iter 62000, loss: 0.164961
 >> iter 63000, loss: 0.118014
 >> iter 64000, loss: 0.182080
 >> iter 65000, loss: 0.119011
 >> iter 66000, loss: 0.156135
 >> iter 67000, loss: 0.130505
 >> iter 68000, loss: 0.219753
 >> iter 69000, loss: 0.244070
 >> iter 70000, loss: 0.238505
   Number of active neurons: 2
 >> iter 71000, loss: 0.139917
 >> iter 72000, loss: 0.197371
 >> iter 73000, loss: 0.127001
 >> iter 74000, loss: 0.203312
 >> iter 75000, loss: 0.155311
 >> iter 76000, loss: 0.146141
 >> iter 77000, loss: 0.213621
 >> iter 78000, loss: 0.238313
 >> iter 79000, loss: 0.188875
 >> iter 80000, loss: 0.194702
   Number of active neurons: 2
 >> iter 81000, loss: 0.241678
 >> iter 82000, loss: 0.999039
 >> iter 83000, loss: 0.489311
 >> iter 84000, loss: 0.400475
 >> iter 85000, loss: 0.269712
 >> iter 86000, loss: 0.199528
 >> iter 87000, loss: 0.179179
 >> iter 88000, loss: 0.234437
 >> iter 89000, loss: 0.109524
 >> iter 90000, loss: 0.133552
   Number of active neurons: 2
 >> iter 91000, loss: 0.116061
 >> iter 92000, loss: 0.514991
 >> iter 93000, loss: 0.309333
 >> iter 94000, loss: 0.243272
 >> iter 95000, loss: 0.142876
 >> iter 96000, loss: 0.187270
 >> iter 97000, loss: 0.156333
 >> iter 98000, loss: 0.172743
 >> iter 99000, loss: 0.287405
 >> iter 100000, loss: 0.585537
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.910546
 >> iter 2000, loss: 6.319691
 >> iter 3000, loss: 2.374562
 >> iter 4000, loss: 1.093192
 >> iter 5000, loss: 0.426909
 >> iter 6000, loss: 0.428145
 >> iter 7000, loss: 0.327489
 >> iter 8000, loss: 0.569626
 >> iter 9000, loss: 0.388350
 >> iter 10000, loss: 0.253364
   Number of active neurons: 3
 >> iter 11000, loss: 0.215222
 >> iter 12000, loss: 0.470041
 >> iter 13000, loss: 0.195173
 >> iter 14000, loss: 0.147436
 >> iter 15000, loss: 0.171021
 >> iter 16000, loss: 0.188923
 >> iter 17000, loss: 0.087764
 >> iter 18000, loss: 0.141305
 >> iter 19000, loss: 0.143376
 >> iter 20000, loss: 0.206305
   Number of active neurons: 3
 >> iter 21000, loss: 0.222406
 >> iter 22000, loss: 0.258155
 >> iter 23000, loss: 0.481277
 >> iter 24000, loss: 0.299966
 >> iter 25000, loss: 0.129717
 >> iter 26000, loss: 0.161495
 >> iter 27000, loss: 0.094040
 >> iter 28000, loss: 0.123052
 >> iter 29000, loss: 0.060275
 >> iter 30000, loss: 0.316470
   Number of active neurons: 3
 >> iter 31000, loss: 0.133748
 >> iter 32000, loss: 0.172946
 >> iter 33000, loss: 0.079934
 >> iter 34000, loss: 0.328851
 >> iter 35000, loss: 0.144245
 >> iter 36000, loss: 0.303431
 >> iter 37000, loss: 0.161693
 >> iter 38000, loss: 0.370819
 >> iter 39000, loss: 0.224384
 >> iter 40000, loss: 0.207324
   Number of active neurons: 3
 >> iter 41000, loss: 0.321228
 >> iter 42000, loss: 0.185093
 >> iter 43000, loss: 0.086197
 >> iter 44000, loss: 0.147341
 >> iter 45000, loss: 0.070954
 >> iter 46000, loss: 0.223511
 >> iter 47000, loss: 0.100236
 >> iter 48000, loss: 0.179786
 >> iter 49000, loss: 0.082575
 >> iter 50000, loss: 0.130433
   Number of active neurons: 3
 >> iter 51000, loss: 0.127803
 >> iter 52000, loss: 0.262787
 >> iter 53000, loss: 0.112630
 >> iter 54000, loss: 0.145178
 >> iter 55000, loss: 0.069082
 >> iter 56000, loss: 0.069241
 >> iter 57000, loss: 0.064670
 >> iter 58000, loss: 0.360375
 >> iter 59000, loss: 0.150319
 >> iter 60000, loss: 0.183335
   Number of active neurons: 3
 >> iter 61000, loss: 0.170932
 >> iter 62000, loss: 0.105760
 >> iter 63000, loss: 0.120260
 >> iter 64000, loss: 0.249199
 >> iter 65000, loss: 0.109535
 >> iter 66000, loss: 0.237023
 >> iter 67000, loss: 0.169947
 >> iter 68000, loss: 0.157681
 >> iter 69000, loss: 0.074558
 >> iter 70000, loss: 0.124275
   Number of active neurons: 3
 >> iter 71000, loss: 0.099640
 >> iter 72000, loss: 0.183803
 >> iter 73000, loss: 0.202777
 >> iter 74000, loss: 0.132141
 >> iter 75000, loss: 0.131458
 >> iter 76000, loss: 0.193545
 >> iter 77000, loss: 0.152208
 >> iter 78000, loss: 0.193674
 >> iter 79000, loss: 0.283204
 >> iter 80000, loss: 0.409713
   Number of active neurons: 3
 >> iter 81000, loss: 0.252542
 >> iter 82000, loss: 0.176282
 >> iter 83000, loss: 0.108421
 >> iter 84000, loss: 0.132153
 >> iter 85000, loss: 0.087662
 >> iter 86000, loss: 0.171620
 >> iter 87000, loss: 0.172815
 >> iter 88000, loss: 0.213484
 >> iter 89000, loss: 0.192123
 >> iter 90000, loss: 0.165542
   Number of active neurons: 3
 >> iter 91000, loss: 0.257711
 >> iter 92000, loss: 0.193311
 >> iter 93000, loss: 0.088762
 >> iter 94000, loss: 0.221453
 >> iter 95000, loss: 0.098212
 >> iter 96000, loss: 0.372247
 >> iter 97000, loss: 0.237332
 >> iter 98000, loss: 0.402977
 >> iter 99000, loss: 0.226798
 >> iter 100000, loss: 0.286363
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.00799984000319
   - Test - Long: 0.009999500025
   - Test - Big: 0.0089999100009
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.794351
 >> iter 2000, loss: 7.971389
 >> iter 3000, loss: 2.967435
 >> iter 4000, loss: 1.368182
 >> iter 5000, loss: 0.529436
 >> iter 6000, loss: 0.458667
 >> iter 7000, loss: 0.368004
 >> iter 8000, loss: 0.498468
 >> iter 9000, loss: 0.230881
 >> iter 10000, loss: 0.390230
   Number of active neurons: 4
 >> iter 11000, loss: 0.182819
 >> iter 12000, loss: 0.318247
 >> iter 13000, loss: 0.140690
 >> iter 14000, loss: 0.289982
 >> iter 15000, loss: 0.142721
 >> iter 16000, loss: 0.356257
 >> iter 17000, loss: 0.194540
 >> iter 18000, loss: 0.581795
 >> iter 19000, loss: 0.306715
 >> iter 20000, loss: 0.334293
   Number of active neurons: 3
 >> iter 21000, loss: 0.186997
 >> iter 22000, loss: 0.419806
 >> iter 23000, loss: 0.227605
 >> iter 24000, loss: 0.343209
 >> iter 25000, loss: 0.287624
 >> iter 26000, loss: 0.394348
 >> iter 27000, loss: 0.241343
 >> iter 28000, loss: 0.385757
 >> iter 29000, loss: 0.211576
 >> iter 30000, loss: 0.197597
   Number of active neurons: 3
 >> iter 31000, loss: 0.207899
 >> iter 32000, loss: 0.465147
 >> iter 33000, loss: 0.243833
 >> iter 34000, loss: 0.410959
 >> iter 35000, loss: 0.180309
 >> iter 36000, loss: 0.326061
 >> iter 37000, loss: 0.179604
 >> iter 38000, loss: 0.456368
 >> iter 39000, loss: 0.328483
 >> iter 40000, loss: 0.328730
   Number of active neurons: 3
 >> iter 41000, loss: 0.145065
 >> iter 42000, loss: 0.428831
 >> iter 43000, loss: 0.201076
 >> iter 44000, loss: 0.415643
 >> iter 45000, loss: 0.198208
 >> iter 46000, loss: 0.430196
 >> iter 47000, loss: 0.193888
 >> iter 48000, loss: 0.384172
 >> iter 49000, loss: 0.260425
 >> iter 50000, loss: 0.235043
   Number of active neurons: 3
 >> iter 51000, loss: 0.282627
 >> iter 52000, loss: 0.235908
 >> iter 53000, loss: 0.312364
 >> iter 54000, loss: 0.364152
 >> iter 55000, loss: 0.274756
 >> iter 56000, loss: 0.200904
 >> iter 57000, loss: 0.191814
 >> iter 58000, loss: 0.219911
 >> iter 59000, loss: 0.155026
 >> iter 60000, loss: 0.314070
   Number of active neurons: 3
 >> iter 61000, loss: 0.266551
 >> iter 62000, loss: 0.372423
 >> iter 63000, loss: 0.172011
 >> iter 64000, loss: 0.286923
 >> iter 65000, loss: 0.189536
 >> iter 66000, loss: 0.298499
 >> iter 67000, loss: 0.253446
 >> iter 68000, loss: 0.274921
 >> iter 69000, loss: 0.187437
 >> iter 70000, loss: 0.539076
   Number of active neurons: 3
 >> iter 71000, loss: 0.237327
 >> iter 72000, loss: 0.298923
 >> iter 73000, loss: 0.186657
 >> iter 74000, loss: 0.257199
 >> iter 75000, loss: 0.240477
 >> iter 76000, loss: 0.481526
 >> iter 77000, loss: 0.201915
 >> iter 78000, loss: 0.246060
 >> iter 79000, loss: 0.162768
 >> iter 80000, loss: 0.155464
   Number of active neurons: 3
 >> iter 81000, loss: 0.074952
 >> iter 82000, loss: 0.539992
 >> iter 83000, loss: 0.222997
 >> iter 84000, loss: 0.310336
 >> iter 85000, loss: 0.134295
 >> iter 86000, loss: 0.146884
 >> iter 87000, loss: 0.138470
 >> iter 88000, loss: 0.126145
 >> iter 89000, loss: 0.062011
 >> iter 90000, loss: 0.314339
   Number of active neurons: 3
 >> iter 91000, loss: 0.156540
 >> iter 92000, loss: 0.192817
 >> iter 93000, loss: 0.459060
 >> iter 94000, loss: 0.413203
 >> iter 95000, loss: 0.177355
 >> iter 96000, loss: 0.522148
 >> iter 97000, loss: 0.218389
 >> iter 98000, loss: 0.321709
 >> iter 99000, loss: 0.140270
 >> iter 100000, loss: 0.286724
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.642031
 >> iter 2000, loss: 6.665194
 >> iter 3000, loss: 2.488607
 >> iter 4000, loss: 1.038573
 >> iter 5000, loss: 0.461347
 >> iter 6000, loss: 0.408310
 >> iter 7000, loss: 0.227806
 >> iter 8000, loss: 0.629967
 >> iter 9000, loss: 0.288183
 >> iter 10000, loss: 0.220724
   Number of active neurons: 3
 >> iter 11000, loss: 0.154341
 >> iter 12000, loss: 0.110525
 >> iter 13000, loss: 0.133723
 >> iter 14000, loss: 0.273836
 >> iter 15000, loss: 0.212569
 >> iter 16000, loss: 0.283897
 >> iter 17000, loss: 0.140086
 >> iter 18000, loss: 0.357948
 >> iter 19000, loss: 0.228735
 >> iter 20000, loss: 0.214346
   Number of active neurons: 3
 >> iter 21000, loss: 0.216542
 >> iter 22000, loss: 0.498975
 >> iter 23000, loss: 0.245366
 >> iter 24000, loss: 0.171490
 >> iter 25000, loss: 0.204317
 >> iter 26000, loss: 0.189707
 >> iter 27000, loss: 0.175847
 >> iter 28000, loss: 0.179528
 >> iter 29000, loss: 0.118534
 >> iter 30000, loss: 0.231904
   Number of active neurons: 3
 >> iter 31000, loss: 0.242646
 >> iter 32000, loss: 0.248836
 >> iter 33000, loss: 0.158690
 >> iter 34000, loss: 0.323009
 >> iter 35000, loss: 0.260735
 >> iter 36000, loss: 0.235461
 >> iter 37000, loss: 0.202789
 >> iter 38000, loss: 0.126047
 >> iter 39000, loss: 0.104386
 >> iter 40000, loss: 0.345412
   Number of active neurons: 3
 >> iter 41000, loss: 0.152456
 >> iter 42000, loss: 0.214821
 >> iter 43000, loss: 0.282503
 >> iter 44000, loss: 0.258525
 >> iter 45000, loss: 0.270223
 >> iter 46000, loss: 0.398406
 >> iter 47000, loss: 0.277988
 >> iter 48000, loss: 0.401919
 >> iter 49000, loss: 0.367383
 >> iter 50000, loss: 0.189704
   Number of active neurons: 3
 >> iter 51000, loss: 0.219074
 >> iter 52000, loss: 0.227488
 >> iter 53000, loss: 0.165735
 >> iter 54000, loss: 0.112864
 >> iter 55000, loss: 0.126573
 >> iter 56000, loss: 0.357890
 >> iter 57000, loss: 0.347787
 >> iter 58000, loss: 0.264707
 >> iter 59000, loss: 0.189773
 >> iter 60000, loss: 0.121660
   Number of active neurons: 3
 >> iter 61000, loss: 0.208225
 >> iter 62000, loss: 0.405771
 >> iter 63000, loss: 0.252844
 >> iter 64000, loss: 0.259008
 >> iter 65000, loss: 0.315613
 >> iter 66000, loss: 0.430230
 >> iter 67000, loss: 0.181998
 >> iter 68000, loss: 0.104982
 >> iter 69000, loss: 0.071953
 >> iter 70000, loss: 0.530436
   Number of active neurons: 3
 >> iter 71000, loss: 0.463306
 >> iter 72000, loss: 0.754937
 >> iter 73000, loss: 0.576399
 >> iter 74000, loss: 0.677745
 >> iter 75000, loss: 0.420738
 >> iter 76000, loss: 0.251403
 >> iter 77000, loss: 0.133517
 >> iter 78000, loss: 0.141482
 >> iter 79000, loss: 0.225160
 >> iter 80000, loss: 0.542356
   Number of active neurons: 3
 >> iter 81000, loss: 0.301186
 >> iter 82000, loss: 0.350988
 >> iter 83000, loss: 0.210398
 >> iter 84000, loss: 0.320846
 >> iter 85000, loss: 0.361630
 >> iter 86000, loss: 0.247177
 >> iter 87000, loss: 0.133965
 >> iter 88000, loss: 0.332546
 >> iter 89000, loss: 0.143525
 >> iter 90000, loss: 0.127643
   Number of active neurons: 3
 >> iter 91000, loss: 0.133150
 >> iter 92000, loss: 0.148256
 >> iter 93000, loss: 0.159132
 >> iter 94000, loss: 0.199394
 >> iter 95000, loss: 0.090878
 >> iter 96000, loss: 0.369356
 >> iter 97000, loss: 0.155243
 >> iter 98000, loss: 0.329906
 >> iter 99000, loss: 0.140267
 >> iter 100000, loss: 0.283643
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.643023
 >> iter 2000, loss: 6.501906
 >> iter 3000, loss: 2.421891
 >> iter 4000, loss: 0.913898
 >> iter 5000, loss: 0.397573
 >> iter 6000, loss: 0.778703
 >> iter 7000, loss: 0.320983
 >> iter 8000, loss: 0.393389
 >> iter 9000, loss: 0.177325
 >> iter 10000, loss: 0.159617
   Number of active neurons: 3
 >> iter 11000, loss: 0.135995
 >> iter 12000, loss: 0.203372
 >> iter 13000, loss: 0.138446
 >> iter 14000, loss: 0.333360
 >> iter 15000, loss: 0.184589
 >> iter 16000, loss: 0.143932
 >> iter 17000, loss: 0.220553
 >> iter 18000, loss: 0.337936
 >> iter 19000, loss: 0.168337
 >> iter 20000, loss: 0.151665
   Number of active neurons: 3
 >> iter 21000, loss: 0.131385
 >> iter 22000, loss: 0.235221
 >> iter 23000, loss: 0.181599
 >> iter 24000, loss: 0.283574
 >> iter 25000, loss: 0.222712
 >> iter 26000, loss: 0.347857
 >> iter 27000, loss: 0.209358
 >> iter 28000, loss: 0.099137
 >> iter 29000, loss: 0.264508
 >> iter 30000, loss: 0.149472
   Number of active neurons: 3
 >> iter 31000, loss: 0.088279
 >> iter 32000, loss: 0.181772
 >> iter 33000, loss: 0.270983
 >> iter 34000, loss: 0.493464
 >> iter 35000, loss: 0.264265
 >> iter 36000, loss: 0.182848
 >> iter 37000, loss: 0.152560
 >> iter 38000, loss: 0.261137
 >> iter 39000, loss: 0.383769
 >> iter 40000, loss: 0.418926
   Number of active neurons: 3
 >> iter 41000, loss: 0.198907
 >> iter 42000, loss: 0.296916
 >> iter 43000, loss: 0.322265
 >> iter 44000, loss: 0.203430
 >> iter 45000, loss: 0.169913
 >> iter 46000, loss: 0.219291
 >> iter 47000, loss: 0.190355
 >> iter 48000, loss: 0.204431
 >> iter 49000, loss: 0.101517
 >> iter 50000, loss: 0.279318
   Number of active neurons: 3
 >> iter 51000, loss: 0.156279
 >> iter 52000, loss: 0.334016
 >> iter 53000, loss: 0.189261
 >> iter 54000, loss: 0.213710
 >> iter 55000, loss: 0.237896
 >> iter 56000, loss: 0.390882
 >> iter 57000, loss: 0.263820
 >> iter 58000, loss: 0.140192
 >> iter 59000, loss: 0.315726
 >> iter 60000, loss: 0.249184
   Number of active neurons: 3
 >> iter 61000, loss: 0.245260
 >> iter 62000, loss: 0.128039
 >> iter 63000, loss: 0.293364
 >> iter 64000, loss: 0.334509
 >> iter 65000, loss: 0.187789
 >> iter 66000, loss: 0.118301
 >> iter 67000, loss: 0.124781
 >> iter 68000, loss: 0.178166
 >> iter 69000, loss: 0.100607
 >> iter 70000, loss: 0.961777
   Number of active neurons: 3
 >> iter 71000, loss: 0.501849
 >> iter 72000, loss: 0.425693
 >> iter 73000, loss: 0.180012
 >> iter 74000, loss: 0.201488
 >> iter 75000, loss: 0.107650
 >> iter 76000, loss: 0.259876
 >> iter 77000, loss: 0.190658
 >> iter 78000, loss: 0.116819
 >> iter 79000, loss: 0.285555
 >> iter 80000, loss: 0.208570
   Number of active neurons: 3
 >> iter 81000, loss: 0.138555
 >> iter 82000, loss: 0.525286
 >> iter 83000, loss: 0.514676
 >> iter 84000, loss: 0.318197
 >> iter 85000, loss: 0.201036
 >> iter 86000, loss: 0.211518
 >> iter 87000, loss: 0.237317
 >> iter 88000, loss: 0.162200
 >> iter 89000, loss: 0.332177
 >> iter 90000, loss: 0.176190
   Number of active neurons: 3
 >> iter 91000, loss: 0.144162
 >> iter 92000, loss: 0.173337
 >> iter 93000, loss: 0.267603
 >> iter 94000, loss: 0.122577
 >> iter 95000, loss: 0.331666
 >> iter 96000, loss: 0.182973
 >> iter 97000, loss: 0.286632
 >> iter 98000, loss: 0.203921
 >> iter 99000, loss: 0.125709
 >> iter 100000, loss: 0.282274
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0039999200016
   - Test - Long: 0.0
   - Test - Big: 0.0559994400056
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.908822
 >> iter 2000, loss: 6.730946
 >> iter 3000, loss: 2.583397
 >> iter 4000, loss: 1.112384
 >> iter 5000, loss: 0.474788
 >> iter 6000, loss: 0.490511
 >> iter 7000, loss: 0.204424
 >> iter 8000, loss: 0.440197
 >> iter 9000, loss: 0.258069
 >> iter 10000, loss: 0.248702
   Number of active neurons: 3
 >> iter 11000, loss: 0.175725
 >> iter 12000, loss: 0.226445
 >> iter 13000, loss: 0.154894
 >> iter 14000, loss: 0.206170
 >> iter 15000, loss: 0.117073
 >> iter 16000, loss: 0.441686
 >> iter 17000, loss: 0.188475
 >> iter 18000, loss: 0.417758
 >> iter 19000, loss: 0.185227
 >> iter 20000, loss: 0.299883
   Number of active neurons: 3
 >> iter 21000, loss: 0.152306
 >> iter 22000, loss: 0.373055
 >> iter 23000, loss: 0.179303
 >> iter 24000, loss: 0.363706
 >> iter 25000, loss: 0.155390
 >> iter 26000, loss: 0.463797
 >> iter 27000, loss: 0.254646
 >> iter 28000, loss: 0.224316
 >> iter 29000, loss: 0.101575
 >> iter 30000, loss: 0.654025
   Number of active neurons: 3
 >> iter 31000, loss: 0.267476
 >> iter 32000, loss: 0.136664
 >> iter 33000, loss: 0.067288
 >> iter 34000, loss: 0.265244
 >> iter 35000, loss: 0.115992
 >> iter 36000, loss: 0.131044
 >> iter 37000, loss: 0.077181
 >> iter 38000, loss: 0.122572
 >> iter 39000, loss: 0.061110
 >> iter 40000, loss: 0.203729
   Number of active neurons: 3
 >> iter 41000, loss: 0.091706
 >> iter 42000, loss: 0.315970
 >> iter 43000, loss: 0.135048
 >> iter 44000, loss: 0.258898
 >> iter 45000, loss: 0.179793
 >> iter 46000, loss: 0.205145
 >> iter 47000, loss: 0.094203
 >> iter 48000, loss: 0.411042
 >> iter 49000, loss: 0.194070
 >> iter 50000, loss: 0.200034
   Number of active neurons: 3
 >> iter 51000, loss: 0.113273
 >> iter 52000, loss: 0.137285
 >> iter 53000, loss: 0.088766
 >> iter 54000, loss: 0.217116
 >> iter 55000, loss: 0.180331
 >> iter 56000, loss: 0.199588
 >> iter 57000, loss: 0.277379
 >> iter 58000, loss: 0.219383
 >> iter 59000, loss: 0.174506
 >> iter 60000, loss: 0.354341
   Number of active neurons: 3
 >> iter 61000, loss: 0.194768
 >> iter 62000, loss: 0.196135
 >> iter 63000, loss: 0.090114
 >> iter 64000, loss: 0.167451
 >> iter 65000, loss: 0.077977
 >> iter 66000, loss: 0.165248
 >> iter 67000, loss: 0.258269
 >> iter 68000, loss: 0.149133
 >> iter 69000, loss: 0.157461
 >> iter 70000, loss: 0.143793
   Number of active neurons: 3
 >> iter 71000, loss: 0.093144
 >> iter 72000, loss: 0.193965
 >> iter 73000, loss: 0.186185
 >> iter 74000, loss: 0.287981
 >> iter 75000, loss: 0.207699
 >> iter 76000, loss: 0.197689
 >> iter 77000, loss: 0.091262
 >> iter 78000, loss: 0.233752
 >> iter 79000, loss: 0.158643
 >> iter 80000, loss: 0.160175
   Number of active neurons: 3
 >> iter 81000, loss: 0.075775
 >> iter 82000, loss: 0.162160
 >> iter 83000, loss: 0.196351
 >> iter 84000, loss: 0.353587
 >> iter 85000, loss: 0.152632
 >> iter 86000, loss: 0.287530
 >> iter 87000, loss: 0.265935
 >> iter 88000, loss: 0.214965
 >> iter 89000, loss: 0.197480
 >> iter 90000, loss: 0.197784
   Number of active neurons: 3
 >> iter 91000, loss: 0.153513
 >> iter 92000, loss: 0.164689
 >> iter 93000, loss: 0.077383
 >> iter 94000, loss: 0.146905
 >> iter 95000, loss: 0.128562
 >> iter 96000, loss: 0.129049
 >> iter 97000, loss: 0.063719
 >> iter 98000, loss: 0.156333
 >> iter 99000, loss: 0.164895
 >> iter 100000, loss: 0.264506
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0019999600008
   - Test - Long: 0.0
   - Test - Big: 0.0079999200008
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.801859
 >> iter 2000, loss: 6.803937
 >> iter 3000, loss: 2.543850
 >> iter 4000, loss: 1.316702
 >> iter 5000, loss: 0.539705
 >> iter 6000, loss: 0.867099
 >> iter 7000, loss: 0.379516
 >> iter 8000, loss: 1.060586
 >> iter 9000, loss: 0.521427
 >> iter 10000, loss: 0.325402
   Number of active neurons: 5
 >> iter 11000, loss: 0.187507
 >> iter 12000, loss: 0.645739
 >> iter 13000, loss: 0.289312
 >> iter 14000, loss: 0.287451
 >> iter 15000, loss: 0.128206
 >> iter 16000, loss: 0.468041
 >> iter 17000, loss: 0.236045
 >> iter 18000, loss: 0.283640
 >> iter 19000, loss: 0.182114
 >> iter 20000, loss: 0.596027
   Number of active neurons: 3
 >> iter 21000, loss: 0.305357
 >> iter 22000, loss: 0.139306
 >> iter 23000, loss: 0.140224
 >> iter 24000, loss: 0.174192
 >> iter 25000, loss: 0.174279
 >> iter 26000, loss: 0.455155
 >> iter 27000, loss: 0.193137
 >> iter 28000, loss: 0.160267
 >> iter 29000, loss: 0.238498
 >> iter 30000, loss: 0.397970
   Number of active neurons: 3
 >> iter 31000, loss: 0.169050
 >> iter 32000, loss: 0.321623
 >> iter 33000, loss: 0.138141
 >> iter 34000, loss: 0.132760
 >> iter 35000, loss: 0.077137
 >> iter 36000, loss: 0.461823
 >> iter 37000, loss: 0.189598
 >> iter 38000, loss: 0.212653
 >> iter 39000, loss: 0.100848
 >> iter 40000, loss: 0.283969
   Number of active neurons: 3
 >> iter 41000, loss: 0.153692
 >> iter 42000, loss: 0.106294
 >> iter 43000, loss: 0.284162
 >> iter 44000, loss: 0.255418
 >> iter 45000, loss: 0.114256
 >> iter 46000, loss: 0.241917
 >> iter 47000, loss: 0.107138
 >> iter 48000, loss: 0.088342
 >> iter 49000, loss: 0.155035
 >> iter 50000, loss: 0.141950
   Number of active neurons: 3
 >> iter 51000, loss: 0.186379
 >> iter 52000, loss: 0.196399
 >> iter 53000, loss: 0.090434
 >> iter 54000, loss: 0.273921
 >> iter 55000, loss: 0.119000
 >> iter 56000, loss: 0.135077
 >> iter 57000, loss: 0.193740
 >> iter 58000, loss: 0.403395
 >> iter 59000, loss: 0.169824
 >> iter 60000, loss: 0.157503
   Number of active neurons: 3
 >> iter 61000, loss: 0.129904
 >> iter 62000, loss: 0.232750
 >> iter 63000, loss: 0.145478
 >> iter 64000, loss: 0.155750
 >> iter 65000, loss: 0.094517
 >> iter 66000, loss: 0.434990
 >> iter 67000, loss: 0.177965
 >> iter 68000, loss: 0.241339
 >> iter 69000, loss: 0.166007
 >> iter 70000, loss: 0.397102
   Number of active neurons: 3
 >> iter 71000, loss: 0.168254
 >> iter 72000, loss: 0.155383
 >> iter 73000, loss: 0.097442
 >> iter 74000, loss: 0.228124
 >> iter 75000, loss: 0.101173
 >> iter 76000, loss: 0.275440
 >> iter 77000, loss: 0.132417
 >> iter 78000, loss: 0.431812
 >> iter 79000, loss: 0.178805
 >> iter 80000, loss: 0.086435
   Number of active neurons: 3
 >> iter 81000, loss: 0.047182
 >> iter 82000, loss: 0.170995
 >> iter 83000, loss: 0.077901
 >> iter 84000, loss: 0.347953
 >> iter 85000, loss: 0.146167
 >> iter 86000, loss: 0.220837
 >> iter 87000, loss: 0.098404
 >> iter 88000, loss: 0.196538
 >> iter 89000, loss: 0.179423
 >> iter 90000, loss: 0.285427
   Number of active neurons: 3
 >> iter 91000, loss: 0.206050
 >> iter 92000, loss: 0.174828
 >> iter 93000, loss: 0.151409
 >> iter 94000, loss: 0.163593
 >> iter 95000, loss: 0.099068
 >> iter 96000, loss: 0.171866
 >> iter 97000, loss: 0.264730
 >> iter 98000, loss: 0.129405
 >> iter 99000, loss: 0.144813
 >> iter 100000, loss: 0.105417
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.209780
 >> iter 2000, loss: 7.295572
 >> iter 3000, loss: 2.781400
 >> iter 4000, loss: 1.058770
 >> iter 5000, loss: 0.426083
 >> iter 6000, loss: 0.180005
 >> iter 7000, loss: 0.115472
 >> iter 8000, loss: 0.063282
 >> iter 9000, loss: 0.076213
 >> iter 10000, loss: 0.057666
   Number of active neurons: 2
 >> iter 11000, loss: 0.092503
 >> iter 12000, loss: 0.053288
 >> iter 13000, loss: 0.086251
 >> iter 14000, loss: 0.051148
 >> iter 15000, loss: 0.093227
 >> iter 16000, loss: 0.504508
 >> iter 17000, loss: 0.462850
 >> iter 18000, loss: 0.252302
 >> iter 19000, loss: 0.219091
 >> iter 20000, loss: 0.145442
   Number of active neurons: 2
 >> iter 21000, loss: 0.139630
 >> iter 22000, loss: 0.145085
 >> iter 23000, loss: 0.149768
 >> iter 24000, loss: 0.219590
 >> iter 25000, loss: 0.234617
 >> iter 26000, loss: 0.181518
 >> iter 27000, loss: 0.191924
 >> iter 28000, loss: 0.162617
 >> iter 29000, loss: 0.169975
 >> iter 30000, loss: 0.088097
   Number of active neurons: 2
 >> iter 31000, loss: 0.104590
 >> iter 32000, loss: 0.093882
 >> iter 33000, loss: 0.072203
 >> iter 34000, loss: 0.201976
 >> iter 35000, loss: 0.100458
 >> iter 36000, loss: 0.161735
 >> iter 37000, loss: 0.180115
 >> iter 38000, loss: 0.214793
 >> iter 39000, loss: 0.177588
 >> iter 40000, loss: 0.198977
   Number of active neurons: 2
 >> iter 41000, loss: 0.130083
 >> iter 42000, loss: 0.142202
 >> iter 43000, loss: 0.177280
 >> iter 44000, loss: 0.219109
 >> iter 45000, loss: 0.101908
 >> iter 46000, loss: 0.171891
 >> iter 47000, loss: 0.425053
 >> iter 48000, loss: 0.360994
 >> iter 49000, loss: 0.325646
 >> iter 50000, loss: 0.243083
   Number of active neurons: 2
 >> iter 51000, loss: 0.144598
 >> iter 52000, loss: 0.176299
 >> iter 53000, loss: 0.353008
 >> iter 54000, loss: 0.318853
 >> iter 55000, loss: 0.278511
 >> iter 56000, loss: 0.204791
 >> iter 57000, loss: 0.110516
 >> iter 58000, loss: 0.179597
 >> iter 59000, loss: 0.299100
 >> iter 60000, loss: 0.265443
   Number of active neurons: 2
 >> iter 61000, loss: 0.136613
 >> iter 62000, loss: 0.168589
 >> iter 63000, loss: 0.196697
 >> iter 64000, loss: 0.220305
 >> iter 65000, loss: 0.169039
 >> iter 66000, loss: 0.629115
 >> iter 67000, loss: 0.297032
 >> iter 68000, loss: 0.298555
 >> iter 69000, loss: 0.151609
 >> iter 70000, loss: 0.090608
   Number of active neurons: 2
 >> iter 71000, loss: 0.194844
 >> iter 72000, loss: 0.100904
 >> iter 73000, loss: 0.103779
 >> iter 74000, loss: 0.128587
 >> iter 75000, loss: 0.155430
 >> iter 76000, loss: 0.195084
 >> iter 77000, loss: 0.359108
 >> iter 78000, loss: 0.230338
 >> iter 79000, loss: 0.197192
 >> iter 80000, loss: 0.175858
   Number of active neurons: 2
 >> iter 81000, loss: 0.119610
 >> iter 82000, loss: 0.170983
 >> iter 83000, loss: 0.117306
 >> iter 84000, loss: 0.162422
 >> iter 85000, loss: 0.113854
 >> iter 86000, loss: 0.111755
 >> iter 87000, loss: 0.157014
 >> iter 88000, loss: 0.157348
 >> iter 89000, loss: 0.318181
 >> iter 90000, loss: 0.296030
   Number of active neurons: 2
 >> iter 91000, loss: 0.353300
 >> iter 92000, loss: 0.251380
 >> iter 93000, loss: 0.145871
 >> iter 94000, loss: 0.176507
 >> iter 95000, loss: 0.183901
 >> iter 96000, loss: 0.188249
 >> iter 97000, loss: 0.282712
 >> iter 98000, loss: 0.251447
 >> iter 99000, loss: 0.230305
 >> iter 100000, loss: 0.207115
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.781001
 >> iter 2000, loss: 6.740845
 >> iter 3000, loss: 2.757727
 >> iter 4000, loss: 1.145656
 >> iter 5000, loss: 0.651030
 >> iter 6000, loss: 0.310771
 >> iter 7000, loss: 0.408959
 >> iter 8000, loss: 0.223047
 >> iter 9000, loss: 0.271560
 >> iter 10000, loss: 0.298323
   Number of active neurons: 5
 >> iter 11000, loss: 0.204999
 >> iter 12000, loss: 0.163386
 >> iter 13000, loss: 0.164204
 >> iter 14000, loss: 0.402965
 >> iter 15000, loss: 0.189097
 >> iter 16000, loss: 0.351335
 >> iter 17000, loss: 0.150044
 >> iter 18000, loss: 0.324802
 >> iter 19000, loss: 0.213793
 >> iter 20000, loss: 0.236209
   Number of active neurons: 4
 >> iter 21000, loss: 0.120926
 >> iter 22000, loss: 0.258339
 >> iter 23000, loss: 0.299571
 >> iter 24000, loss: 0.304676
 >> iter 25000, loss: 0.218415
 >> iter 26000, loss: 0.266340
 >> iter 27000, loss: 0.214041
 >> iter 28000, loss: 0.225825
 >> iter 29000, loss: 0.211869
 >> iter 30000, loss: 0.280551
   Number of active neurons: 4
 >> iter 31000, loss: 0.323653
 >> iter 32000, loss: 0.428341
 >> iter 33000, loss: 0.204313
 >> iter 34000, loss: 0.412684
 >> iter 35000, loss: 0.213110
 >> iter 36000, loss: 0.209682
 >> iter 37000, loss: 0.121973
 >> iter 38000, loss: 0.324825
 >> iter 39000, loss: 0.283475
 >> iter 40000, loss: 0.312417
   Number of active neurons: 4
 >> iter 41000, loss: 0.229258
 >> iter 42000, loss: 0.274857
 >> iter 43000, loss: 0.152844
 >> iter 44000, loss: 0.360477
 >> iter 45000, loss: 0.158722
 >> iter 46000, loss: 0.304552
 >> iter 47000, loss: 0.161917
 >> iter 48000, loss: 0.141332
 >> iter 49000, loss: 0.070586
 >> iter 50000, loss: 0.109879
   Number of active neurons: 4
 >> iter 51000, loss: 0.057460
 >> iter 52000, loss: 0.203800
 >> iter 53000, loss: 0.227913
 >> iter 54000, loss: 0.315374
 >> iter 55000, loss: 0.185611
 >> iter 56000, loss: 0.285771
 >> iter 57000, loss: 0.159255
 >> iter 58000, loss: 0.381854
 >> iter 59000, loss: 0.162816
 >> iter 60000, loss: 0.160823
   Number of active neurons: 4
 >> iter 61000, loss: 0.077095
 >> iter 62000, loss: 0.207143
 >> iter 63000, loss: 0.190262
 >> iter 64000, loss: 0.147912
 >> iter 65000, loss: 0.282273
 >> iter 66000, loss: 0.148902
 >> iter 67000, loss: 0.141682
 >> iter 68000, loss: 0.156011
 >> iter 69000, loss: 0.075469
 >> iter 70000, loss: 0.209907
   Number of active neurons: 3
 >> iter 71000, loss: 0.218407
 >> iter 72000, loss: 0.107811
 >> iter 73000, loss: 0.276882
 >> iter 74000, loss: 0.218604
 >> iter 75000, loss: 0.127540
 >> iter 76000, loss: 0.087488
 >> iter 77000, loss: 0.269377
 >> iter 78000, loss: 0.221931
 >> iter 79000, loss: 0.186049
 >> iter 80000, loss: 0.213170
   Number of active neurons: 3
 >> iter 81000, loss: 0.214253
 >> iter 82000, loss: 0.220929
 >> iter 83000, loss: 0.220902
 >> iter 84000, loss: 0.225335
 >> iter 85000, loss: 0.103459
 >> iter 86000, loss: 0.156022
 >> iter 87000, loss: 0.102118
 >> iter 88000, loss: 0.167464
 >> iter 89000, loss: 0.239327
 >> iter 90000, loss: 0.137876
   Number of active neurons: 3
 >> iter 91000, loss: 0.183371
 >> iter 92000, loss: 0.313726
 >> iter 93000, loss: 0.135963
 >> iter 94000, loss: 0.199606
 >> iter 95000, loss: 0.091780
 >> iter 96000, loss: 0.213985
 >> iter 97000, loss: 0.161180
 >> iter 98000, loss: 0.250122
 >> iter 99000, loss: 0.196053
 >> iter 100000, loss: 0.214707
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.753953
 >> iter 2000, loss: 6.836851
 >> iter 3000, loss: 2.543444
 >> iter 4000, loss: 1.161250
 >> iter 5000, loss: 0.598470
 >> iter 6000, loss: 0.580065
 >> iter 7000, loss: 0.400840
 >> iter 8000, loss: 0.397764
 >> iter 9000, loss: 0.569123
 >> iter 10000, loss: 0.345430
   Number of active neurons: 5
 >> iter 11000, loss: 0.239412
 >> iter 12000, loss: 0.431029
 >> iter 13000, loss: 0.260020
 >> iter 14000, loss: 0.491539
 >> iter 15000, loss: 0.261262
 >> iter 16000, loss: 0.235622
 >> iter 17000, loss: 0.203998
 >> iter 18000, loss: 0.273753
 >> iter 19000, loss: 0.218536
 >> iter 20000, loss: 0.213153
   Number of active neurons: 4
 >> iter 21000, loss: 0.220441
 >> iter 22000, loss: 0.215975
 >> iter 23000, loss: 0.199969
 >> iter 24000, loss: 0.449797
 >> iter 25000, loss: 0.285367
 >> iter 26000, loss: 0.409666
 >> iter 27000, loss: 0.395112
 >> iter 28000, loss: 0.274765
 >> iter 29000, loss: 0.219240
 >> iter 30000, loss: 0.535792
   Number of active neurons: 4
 >> iter 31000, loss: 0.289090
 >> iter 32000, loss: 0.246616
 >> iter 33000, loss: 0.217327
 >> iter 34000, loss: 0.202407
 >> iter 35000, loss: 0.236678
 >> iter 36000, loss: 0.216752
 >> iter 37000, loss: 0.239474
 >> iter 38000, loss: 0.241485
 >> iter 39000, loss: 0.173542
 >> iter 40000, loss: 0.263603
   Number of active neurons: 4
 >> iter 41000, loss: 0.132025
 >> iter 42000, loss: 0.500523
 >> iter 43000, loss: 0.235671
 >> iter 44000, loss: 0.281801
 >> iter 45000, loss: 0.432047
 >> iter 46000, loss: 0.195634
 >> iter 47000, loss: 0.205584
 >> iter 48000, loss: 0.277536
 >> iter 49000, loss: 0.185220
 >> iter 50000, loss: 0.252945
   Number of active neurons: 4
 >> iter 51000, loss: 0.114082
 >> iter 52000, loss: 0.287530
 >> iter 53000, loss: 0.265317
 >> iter 54000, loss: 0.640473
 >> iter 55000, loss: 0.270277
 >> iter 56000, loss: 0.284671
 >> iter 57000, loss: 0.488719
 >> iter 58000, loss: 0.305411
 >> iter 59000, loss: 0.237753
 >> iter 60000, loss: 0.336802
   Number of active neurons: 4
 >> iter 61000, loss: 0.331276
 >> iter 62000, loss: 0.294335
 >> iter 63000, loss: 0.269745
 >> iter 64000, loss: 0.297051
 >> iter 65000, loss: 0.219256
 >> iter 66000, loss: 0.212535
 >> iter 67000, loss: 0.412250
 >> iter 68000, loss: 0.336857
 >> iter 69000, loss: 0.318588
 >> iter 70000, loss: 0.310077
   Number of active neurons: 4
 >> iter 71000, loss: 0.205917
 >> iter 72000, loss: 0.205457
 >> iter 73000, loss: 0.200482
 >> iter 74000, loss: 0.209823
 >> iter 75000, loss: 0.249050
 >> iter 76000, loss: 0.121505
 >> iter 77000, loss: 0.177268
 >> iter 78000, loss: 0.229763
 >> iter 79000, loss: 0.365035
 >> iter 80000, loss: 0.164339
   Number of active neurons: 4
 >> iter 81000, loss: 0.153475
 >> iter 82000, loss: 0.198065
 >> iter 83000, loss: 0.117654
 >> iter 84000, loss: 0.386780
 >> iter 85000, loss: 0.181895
 >> iter 86000, loss: 0.216062
 >> iter 87000, loss: 0.139130
 >> iter 88000, loss: 0.290699
 >> iter 89000, loss: 0.270794
 >> iter 90000, loss: 0.367137
   Number of active neurons: 4
 >> iter 91000, loss: 0.192279
 >> iter 92000, loss: 0.403610
 >> iter 93000, loss: 0.186696
 >> iter 94000, loss: 0.292437
 >> iter 95000, loss: 0.172873
 >> iter 96000, loss: 0.266193
 >> iter 97000, loss: 0.189461
 >> iter 98000, loss: 0.247686
 >> iter 99000, loss: 0.230065
 >> iter 100000, loss: 0.221323
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.935867
 >> iter 2000, loss: 8.748129
 >> iter 3000, loss: 3.985859
 >> iter 4000, loss: 1.701265
 >> iter 5000, loss: 0.781129
 >> iter 6000, loss: 0.523048
 >> iter 7000, loss: 0.275016
 >> iter 8000, loss: 0.213993
 >> iter 9000, loss: 0.198573
 >> iter 10000, loss: 0.342798
   Number of active neurons: 4
 >> iter 11000, loss: 0.227549
 >> iter 12000, loss: 0.216397
 >> iter 13000, loss: 0.142726
 >> iter 14000, loss: 0.169413
 >> iter 15000, loss: 0.116307
 >> iter 16000, loss: 0.277750
 >> iter 17000, loss: 0.124526
 >> iter 18000, loss: 0.333995
 >> iter 19000, loss: 0.147447
 >> iter 20000, loss: 0.327705
   Number of active neurons: 3
 >> iter 21000, loss: 0.189798
 >> iter 22000, loss: 0.411555
 >> iter 23000, loss: 0.199172
 >> iter 24000, loss: 0.610963
 >> iter 25000, loss: 0.385124
 >> iter 26000, loss: 0.416506
 >> iter 27000, loss: 0.229036
 >> iter 28000, loss: 0.411633
 >> iter 29000, loss: 0.257293
 >> iter 30000, loss: 0.203293
   Number of active neurons: 4
 >> iter 31000, loss: 0.164118
 >> iter 32000, loss: 0.176791
 >> iter 33000, loss: 0.102519
 >> iter 34000, loss: 0.302896
 >> iter 35000, loss: 0.153571
 >> iter 36000, loss: 0.452935
 >> iter 37000, loss: 0.190623
 >> iter 38000, loss: 0.439174
 >> iter 39000, loss: 0.200087
 >> iter 40000, loss: 0.204751
   Number of active neurons: 3
 >> iter 41000, loss: 0.152527
 >> iter 42000, loss: 0.264822
 >> iter 43000, loss: 0.216504
 >> iter 44000, loss: 0.311834
 >> iter 45000, loss: 0.162615
 >> iter 46000, loss: 0.086623
 >> iter 47000, loss: 0.161431
 >> iter 48000, loss: 0.238930
 >> iter 49000, loss: 0.194700
 >> iter 50000, loss: 0.626212
   Number of active neurons: 3
 >> iter 51000, loss: 0.281915
 >> iter 52000, loss: 0.400514
 >> iter 53000, loss: 0.341963
 >> iter 54000, loss: 0.550945
 >> iter 55000, loss: 0.245599
 >> iter 56000, loss: 0.237085
 >> iter 57000, loss: 0.170165
 >> iter 58000, loss: 0.151358
 >> iter 59000, loss: 0.162353
 >> iter 60000, loss: 0.245193
   Number of active neurons: 3
 >> iter 61000, loss: 0.158018
 >> iter 62000, loss: 0.352245
 >> iter 63000, loss: 0.200421
 >> iter 64000, loss: 0.323322
 >> iter 65000, loss: 0.288264
 >> iter 66000, loss: 0.338727
 >> iter 67000, loss: 0.291590
 >> iter 68000, loss: 0.469292
 >> iter 69000, loss: 0.219867
 >> iter 70000, loss: 0.268755
   Number of active neurons: 3
 >> iter 71000, loss: 0.263496
 >> iter 72000, loss: 0.334115
 >> iter 73000, loss: 0.232278
 >> iter 74000, loss: 0.111298
 >> iter 75000, loss: 0.148118
 >> iter 76000, loss: 0.242387
 >> iter 77000, loss: 0.202813
 >> iter 78000, loss: 0.240431
 >> iter 79000, loss: 0.264171
 >> iter 80000, loss: 0.249460
   Number of active neurons: 3
 >> iter 81000, loss: 0.127587
 >> iter 82000, loss: 0.215083
 >> iter 83000, loss: 0.387342
 >> iter 84000, loss: 0.372527
 >> iter 85000, loss: 0.279002
 >> iter 86000, loss: 0.305324
 >> iter 87000, loss: 0.189968
 >> iter 88000, loss: 0.272369
 >> iter 89000, loss: 0.395372
 >> iter 90000, loss: 0.195689
   Number of active neurons: 3
 >> iter 91000, loss: 0.294814
 >> iter 92000, loss: 0.320906
 >> iter 93000, loss: 0.348760
 >> iter 94000, loss: 0.267535
 >> iter 95000, loss: 0.168527
 >> iter 96000, loss: 0.403108
 >> iter 97000, loss: 0.280571
 >> iter 98000, loss: 0.406421
 >> iter 99000, loss: 0.215410
 >> iter 100000, loss: 0.184401
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.00799984000319
   - Test - Long: 0.0849957502125
   - Test - Big: 0.0089999100009
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

