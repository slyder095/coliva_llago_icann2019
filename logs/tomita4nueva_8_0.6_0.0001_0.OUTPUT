 > Problema: tomita4nueva
 > Args:
   - Hidden size: 8
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.451690
 >> iter 2000, loss: 8.158757
 >> iter 3000, loss: 3.600636
 >> iter 4000, loss: 1.775734
 >> iter 5000, loss: 1.057256
 >> iter 6000, loss: 0.673300
 >> iter 7000, loss: 0.593243
 >> iter 8000, loss: 0.644122
 >> iter 9000, loss: 0.656125
 >> iter 10000, loss: 0.626831
   Number of active neurons: 5
 >> iter 11000, loss: 0.466871
 >> iter 12000, loss: 0.535761
 >> iter 13000, loss: 0.481803
 >> iter 14000, loss: 0.424769
 >> iter 15000, loss: 0.468162
 >> iter 16000, loss: 0.337156
 >> iter 17000, loss: 0.365807
 >> iter 18000, loss: 0.452510
 >> iter 19000, loss: 0.606173
 >> iter 20000, loss: 0.354022
   Number of active neurons: 5
 >> iter 21000, loss: 0.412429
 >> iter 22000, loss: 0.389956
 >> iter 23000, loss: 0.601790
 >> iter 24000, loss: 0.469772
 >> iter 25000, loss: 0.371719
 >> iter 26000, loss: 0.568293
 >> iter 27000, loss: 0.457438
 >> iter 28000, loss: 0.342750
 >> iter 29000, loss: 0.396375
 >> iter 30000, loss: 0.400816
   Number of active neurons: 5
 >> iter 31000, loss: 0.307476
 >> iter 32000, loss: 0.401128
 >> iter 33000, loss: 0.406343
 >> iter 34000, loss: 0.421520
 >> iter 35000, loss: 0.594174
 >> iter 36000, loss: 0.574091
 >> iter 37000, loss: 0.351949
 >> iter 38000, loss: 0.442032
 >> iter 39000, loss: 0.589529
 >> iter 40000, loss: 0.622795
   Number of active neurons: 5
 >> iter 41000, loss: 0.428846
 >> iter 42000, loss: 0.388711
 >> iter 43000, loss: 0.739569
 >> iter 44000, loss: 0.475386
 >> iter 45000, loss: 0.355579
 >> iter 46000, loss: 0.378032
 >> iter 47000, loss: 0.285716
 >> iter 48000, loss: 0.265008
 >> iter 49000, loss: 0.410554
 >> iter 50000, loss: 0.464477
   Number of active neurons: 5
 >> iter 51000, loss: 0.499788
 >> iter 52000, loss: 0.383223
 >> iter 53000, loss: 0.505386
 >> iter 54000, loss: 0.706487
 >> iter 55000, loss: 0.591583
 >> iter 56000, loss: 0.460219
 >> iter 57000, loss: 0.399890
 >> iter 58000, loss: 0.394927
 >> iter 59000, loss: 0.212174
 >> iter 60000, loss: 0.322737
   Number of active neurons: 5
 >> iter 61000, loss: 0.308527
 >> iter 62000, loss: 0.270479
 >> iter 63000, loss: 0.316845
 >> iter 64000, loss: 0.319528
 >> iter 65000, loss: 0.508940
 >> iter 66000, loss: 0.352870
 >> iter 67000, loss: 0.276924
 >> iter 68000, loss: 0.565615
 >> iter 69000, loss: 0.595854
 >> iter 70000, loss: 0.509306
   Number of active neurons: 5
 >> iter 71000, loss: 0.441550
 >> iter 72000, loss: 0.511184
 >> iter 73000, loss: 0.553218
 >> iter 74000, loss: 0.436866
 >> iter 75000, loss: 0.345162
 >> iter 76000, loss: 0.439890
 >> iter 77000, loss: 0.475060
 >> iter 78000, loss: 0.607821
 >> iter 79000, loss: 0.361005
 >> iter 80000, loss: 0.366786
   Number of active neurons: 5
 >> iter 81000, loss: 0.655561
 >> iter 82000, loss: 0.397927
 >> iter 83000, loss: 0.431585
 >> iter 84000, loss: 0.314649
 >> iter 85000, loss: 0.261682
 >> iter 86000, loss: 0.553686
 >> iter 87000, loss: 0.474750
 >> iter 88000, loss: 0.290591
 >> iter 89000, loss: 0.332318
 >> iter 90000, loss: 0.290891
   Number of active neurons: 4
 >> iter 91000, loss: 0.421385
 >> iter 92000, loss: 0.245836
 >> iter 93000, loss: 0.356005
 >> iter 94000, loss: 0.190084
 >> iter 95000, loss: 0.247461
 >> iter 96000, loss: 0.207443
 >> iter 97000, loss: 0.406658
 >> iter 98000, loss: 0.341836
 >> iter 99000, loss: 0.177387
 >> iter 100000, loss: 0.179261
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.482392
 >> iter 2000, loss: 9.935043
 >> iter 3000, loss: 4.485433
 >> iter 4000, loss: 2.149129
 >> iter 5000, loss: 1.017457
 >> iter 6000, loss: 0.750352
 >> iter 7000, loss: 0.547828
 >> iter 8000, loss: 0.357317
 >> iter 9000, loss: 0.518757
 >> iter 10000, loss: 0.376199
   Number of active neurons: 4
 >> iter 11000, loss: 0.359772
 >> iter 12000, loss: 0.414323
 >> iter 13000, loss: 0.238709
 >> iter 14000, loss: 0.322344
 >> iter 15000, loss: 0.346029
 >> iter 16000, loss: 0.273092
 >> iter 17000, loss: 0.389195
 >> iter 18000, loss: 0.252445
 >> iter 19000, loss: 0.252069
 >> iter 20000, loss: 0.287106
   Number of active neurons: 4
 >> iter 21000, loss: 0.140929
 >> iter 22000, loss: 0.139409
 >> iter 23000, loss: 0.117575
 >> iter 24000, loss: 0.331435
 >> iter 25000, loss: 0.295965
 >> iter 26000, loss: 0.206124
 >> iter 27000, loss: 0.216809
 >> iter 28000, loss: 0.178179
 >> iter 29000, loss: 0.223387
 >> iter 30000, loss: 0.388133
   Number of active neurons: 3
 >> iter 31000, loss: 0.195106
 >> iter 32000, loss: 0.117271
 >> iter 33000, loss: 0.108050
 >> iter 34000, loss: 0.125401
 >> iter 35000, loss: 0.166682
 >> iter 36000, loss: 0.304545
 >> iter 37000, loss: 0.304961
 >> iter 38000, loss: 0.285901
 >> iter 39000, loss: 0.281585
 >> iter 40000, loss: 0.188614
   Number of active neurons: 3
 >> iter 41000, loss: 0.255959
 >> iter 42000, loss: 0.232826
 >> iter 43000, loss: 0.244272
 >> iter 44000, loss: 0.318410
 >> iter 45000, loss: 0.183764
 >> iter 46000, loss: 0.228397
 >> iter 47000, loss: 0.214682
 >> iter 48000, loss: 0.439108
 >> iter 49000, loss: 0.416933
 >> iter 50000, loss: 0.205770
   Number of active neurons: 3
 >> iter 51000, loss: 0.174302
 >> iter 52000, loss: 0.123544
 >> iter 53000, loss: 0.130850
 >> iter 54000, loss: 0.166711
 >> iter 55000, loss: 0.286949
 >> iter 56000, loss: 0.281581
 >> iter 57000, loss: 0.158730
 >> iter 58000, loss: 0.229396
 >> iter 59000, loss: 0.294658
 >> iter 60000, loss: 0.190889
   Number of active neurons: 3
 >> iter 61000, loss: 0.150494
 >> iter 62000, loss: 0.253272
 >> iter 63000, loss: 0.366244
 >> iter 64000, loss: 0.409543
 >> iter 65000, loss: 0.413155
 >> iter 66000, loss: 0.323757
 >> iter 67000, loss: 0.261628
 >> iter 68000, loss: 0.291668
 >> iter 69000, loss: 0.322076
 >> iter 70000, loss: 0.453941
   Number of active neurons: 3
 >> iter 71000, loss: 0.248291
 >> iter 72000, loss: 0.256671
 >> iter 73000, loss: 0.266141
 >> iter 74000, loss: 0.266990
 >> iter 75000, loss: 0.304619
 >> iter 76000, loss: 0.263066
 >> iter 77000, loss: 0.262221
 >> iter 78000, loss: 0.127682
 >> iter 79000, loss: 0.156711
 >> iter 80000, loss: 0.344365
   Number of active neurons: 3
 >> iter 81000, loss: 0.313209
 >> iter 82000, loss: 0.217788
 >> iter 83000, loss: 0.145380
 >> iter 84000, loss: 0.079281
 >> iter 85000, loss: 0.201686
 >> iter 86000, loss: 0.199770
 >> iter 87000, loss: 0.302346
 >> iter 88000, loss: 0.307184
 >> iter 89000, loss: 0.311053
 >> iter 90000, loss: 0.190121
   Number of active neurons: 3
 >> iter 91000, loss: 0.125848
 >> iter 92000, loss: 0.143403
 >> iter 93000, loss: 0.172947
 >> iter 94000, loss: 0.161416
 >> iter 95000, loss: 0.229070
 >> iter 96000, loss: 0.161834
 >> iter 97000, loss: 0.291973
 >> iter 98000, loss: 0.139309
 >> iter 99000, loss: 0.177179
 >> iter 100000, loss: 0.199424
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.681435
 >> iter 2000, loss: 11.142559
 >> iter 3000, loss: 5.141138
 >> iter 4000, loss: 2.487933
 >> iter 5000, loss: 1.298098
 >> iter 6000, loss: 0.703411
 >> iter 7000, loss: 0.849287
 >> iter 8000, loss: 0.531004
 >> iter 9000, loss: 0.430918
 >> iter 10000, loss: 0.297309
   Number of active neurons: 4
 >> iter 11000, loss: 0.427132
 >> iter 12000, loss: 0.405183
 >> iter 13000, loss: 0.525898
 >> iter 14000, loss: 0.407978
 >> iter 15000, loss: 0.442254
 >> iter 16000, loss: 0.217422
 >> iter 17000, loss: 0.377901
 >> iter 18000, loss: 0.247025
 >> iter 19000, loss: 0.348027
 >> iter 20000, loss: 0.308432
   Number of active neurons: 4
 >> iter 21000, loss: 0.265552
 >> iter 22000, loss: 0.343276
 >> iter 23000, loss: 0.429517
 >> iter 24000, loss: 0.228933
 >> iter 25000, loss: 0.284784
 >> iter 26000, loss: 0.221927
 >> iter 27000, loss: 0.330970
 >> iter 28000, loss: 0.375672
 >> iter 29000, loss: 0.266467
 >> iter 30000, loss: 0.327333
   Number of active neurons: 3
 >> iter 31000, loss: 0.283143
 >> iter 32000, loss: 0.195774
 >> iter 33000, loss: 0.228741
 >> iter 34000, loss: 0.219609
 >> iter 35000, loss: 0.282325
 >> iter 36000, loss: 0.203905
 >> iter 37000, loss: 0.229037
 >> iter 38000, loss: 0.189429
 >> iter 39000, loss: 0.301237
 >> iter 40000, loss: 0.217587
   Number of active neurons: 3
 >> iter 41000, loss: 0.266127
 >> iter 42000, loss: 0.327110
 >> iter 43000, loss: 0.292181
 >> iter 44000, loss: 0.328958
 >> iter 45000, loss: 0.175995
 >> iter 46000, loss: 0.552985
 >> iter 47000, loss: 0.298948
 >> iter 48000, loss: 0.186194
 >> iter 49000, loss: 0.261275
 >> iter 50000, loss: 0.196487
   Number of active neurons: 3
 >> iter 51000, loss: 0.102586
 >> iter 52000, loss: 0.125439
 >> iter 53000, loss: 0.269985
 >> iter 54000, loss: 0.279007
 >> iter 55000, loss: 0.294786
 >> iter 56000, loss: 0.197386
 >> iter 57000, loss: 0.308969
 >> iter 58000, loss: 0.260432
 >> iter 59000, loss: 0.279566
 >> iter 60000, loss: 0.281175
   Number of active neurons: 3
 >> iter 61000, loss: 0.218653
 >> iter 62000, loss: 0.254539
 >> iter 63000, loss: 0.154850
 >> iter 64000, loss: 0.194318
 >> iter 65000, loss: 0.341243
 >> iter 66000, loss: 0.307388
 >> iter 67000, loss: 0.227570
 >> iter 68000, loss: 0.160979
 >> iter 69000, loss: 0.167538
 >> iter 70000, loss: 0.137596
   Number of active neurons: 3
 >> iter 71000, loss: 0.215101
 >> iter 72000, loss: 0.131344
 >> iter 73000, loss: 0.127860
 >> iter 74000, loss: 0.213603
 >> iter 75000, loss: 0.155435
 >> iter 76000, loss: 0.189060
 >> iter 77000, loss: 0.210698
 >> iter 78000, loss: 0.280397
 >> iter 79000, loss: 0.168919
 >> iter 80000, loss: 0.169199
   Number of active neurons: 3
 >> iter 81000, loss: 0.175499
 >> iter 82000, loss: 0.263291
 >> iter 83000, loss: 0.215728
 >> iter 84000, loss: 0.207999
 >> iter 85000, loss: 0.135298
 >> iter 86000, loss: 0.123366
 >> iter 87000, loss: 0.275780
 >> iter 88000, loss: 0.292764
 >> iter 89000, loss: 0.156368
 >> iter 90000, loss: 0.172334
   Number of active neurons: 3
 >> iter 91000, loss: 0.197939
 >> iter 92000, loss: 0.282884
 >> iter 93000, loss: 0.295435
 >> iter 94000, loss: 0.188932
 >> iter 95000, loss: 0.189906
 >> iter 96000, loss: 0.278199
 >> iter 97000, loss: 0.213072
 >> iter 98000, loss: 0.264336
 >> iter 99000, loss: 0.244440
 >> iter 100000, loss: 0.152826
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.639483
 >> iter 2000, loss: 11.412823
 >> iter 3000, loss: 8.606722
 >> iter 4000, loss: 6.205621
 >> iter 5000, loss: 2.889464
 >> iter 6000, loss: 1.308692
 >> iter 7000, loss: 0.771240
 >> iter 8000, loss: 0.532997
 >> iter 9000, loss: 0.369247
 >> iter 10000, loss: 0.315339
   Number of active neurons: 5
 >> iter 11000, loss: 0.318536
 >> iter 12000, loss: 0.329900
 >> iter 13000, loss: 0.286522
 >> iter 14000, loss: 0.292636
 >> iter 15000, loss: 0.150648
 >> iter 16000, loss: 0.165852
 >> iter 17000, loss: 0.223870
 >> iter 18000, loss: 0.503910
 >> iter 19000, loss: 0.269896
 >> iter 20000, loss: 0.194802
   Number of active neurons: 5
 >> iter 21000, loss: 0.239875
 >> iter 22000, loss: 0.188099
 >> iter 23000, loss: 0.340620
 >> iter 24000, loss: 0.394525
 >> iter 25000, loss: 0.299843
 >> iter 26000, loss: 0.216012
 >> iter 27000, loss: 0.182609
 >> iter 28000, loss: 0.201405
 >> iter 29000, loss: 0.296084
 >> iter 30000, loss: 0.214649
   Number of active neurons: 3
 >> iter 31000, loss: 0.364780
 >> iter 32000, loss: 0.360165
 >> iter 33000, loss: 0.183708
 >> iter 34000, loss: 0.264470
 >> iter 35000, loss: 0.162495
 >> iter 36000, loss: 0.174312
 >> iter 37000, loss: 0.245208
 >> iter 38000, loss: 0.177469
 >> iter 39000, loss: 0.200530
 >> iter 40000, loss: 0.219839
   Number of active neurons: 3
 >> iter 41000, loss: 0.140224
 >> iter 42000, loss: 0.244855
 >> iter 43000, loss: 0.199561
 >> iter 44000, loss: 0.360262
 >> iter 45000, loss: 0.174390
 >> iter 46000, loss: 0.325287
 >> iter 47000, loss: 0.387596
 >> iter 48000, loss: 0.212867
 >> iter 49000, loss: 0.137825
 >> iter 50000, loss: 0.299926
   Number of active neurons: 3
 >> iter 51000, loss: 0.237313
 >> iter 52000, loss: 0.402994
 >> iter 53000, loss: 0.297143
 >> iter 54000, loss: 0.400119
 >> iter 55000, loss: 0.380065
 >> iter 56000, loss: 0.302917
 >> iter 57000, loss: 0.309218
 >> iter 58000, loss: 0.365907
 >> iter 59000, loss: 0.238262
 >> iter 60000, loss: 0.171711
   Number of active neurons: 3
 >> iter 61000, loss: 0.175348
 >> iter 62000, loss: 0.137635
 >> iter 63000, loss: 0.241100
 >> iter 64000, loss: 0.274263
 >> iter 65000, loss: 0.211130
 >> iter 66000, loss: 0.215983
 >> iter 67000, loss: 0.211562
 >> iter 68000, loss: 0.145740
 >> iter 69000, loss: 0.181229
 >> iter 70000, loss: 0.106328
   Number of active neurons: 3
 >> iter 71000, loss: 0.178909
 >> iter 72000, loss: 0.313921
 >> iter 73000, loss: 0.193471
 >> iter 74000, loss: 0.354538
 >> iter 75000, loss: 0.257465
 >> iter 76000, loss: 0.176918
 >> iter 77000, loss: 0.214672
 >> iter 78000, loss: 0.101666
 >> iter 79000, loss: 0.283910
 >> iter 80000, loss: 0.303428
   Number of active neurons: 3
 >> iter 81000, loss: 0.264913
 >> iter 82000, loss: 0.273002
 >> iter 83000, loss: 0.189955
 >> iter 84000, loss: 0.275264
 >> iter 85000, loss: 0.137449
 >> iter 86000, loss: 0.223120
 >> iter 87000, loss: 0.297905
 >> iter 88000, loss: 0.303832
 >> iter 89000, loss: 0.307499
 >> iter 90000, loss: 0.413726
   Number of active neurons: 3
 >> iter 91000, loss: 0.438322
 >> iter 92000, loss: 0.361686
 >> iter 93000, loss: 0.425897
 >> iter 94000, loss: 0.264113
 >> iter 95000, loss: 0.183900
 >> iter 96000, loss: 0.109866
 >> iter 97000, loss: 0.233359
 >> iter 98000, loss: 0.208826
 >> iter 99000, loss: 0.298691
 >> iter 100000, loss: 0.407857
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.656391
 >> iter 2000, loss: 10.203590
 >> iter 3000, loss: 4.883751
 >> iter 4000, loss: 2.612557
 >> iter 5000, loss: 1.395521
 >> iter 6000, loss: 1.064219
 >> iter 7000, loss: 0.861685
 >> iter 8000, loss: 0.618805
 >> iter 9000, loss: 0.460761
 >> iter 10000, loss: 0.566933
   Number of active neurons: 8
 >> iter 11000, loss: 0.680926
 >> iter 12000, loss: 0.595862
 >> iter 13000, loss: 0.595835
 >> iter 14000, loss: 0.652302
 >> iter 15000, loss: 0.615609
 >> iter 16000, loss: 0.367130
 >> iter 17000, loss: 0.643046
 >> iter 18000, loss: 0.503135
 >> iter 19000, loss: 0.587207
 >> iter 20000, loss: 0.664465
   Number of active neurons: 6
 >> iter 21000, loss: 0.501388
 >> iter 22000, loss: 0.565449
 >> iter 23000, loss: 0.812985
 >> iter 24000, loss: 0.686649
 >> iter 25000, loss: 0.561277
 >> iter 26000, loss: 0.580635
 >> iter 27000, loss: 0.750259
 >> iter 28000, loss: 0.651295
 >> iter 29000, loss: 0.433313
 >> iter 30000, loss: 0.302775
   Number of active neurons: 7
 >> iter 31000, loss: 0.263759
 >> iter 32000, loss: 0.513331
 >> iter 33000, loss: 0.656177
 >> iter 34000, loss: 0.597327
 >> iter 35000, loss: 0.489792
 >> iter 36000, loss: 0.481628
 >> iter 37000, loss: 0.727284
 >> iter 38000, loss: 0.604882
 >> iter 39000, loss: 0.579997
 >> iter 40000, loss: 0.515860
   Number of active neurons: 8
 >> iter 41000, loss: 0.592549
 >> iter 42000, loss: 0.576278
 >> iter 43000, loss: 0.424619
 >> iter 44000, loss: 0.579011
 >> iter 45000, loss: 0.734962
 >> iter 46000, loss: 0.646953
 >> iter 47000, loss: 0.586002
 >> iter 48000, loss: 0.366538
 >> iter 49000, loss: 0.243859
 >> iter 50000, loss: 0.302475
   Number of active neurons: 7
 >> iter 51000, loss: 0.431712
 >> iter 52000, loss: 0.274579
 >> iter 53000, loss: 0.307277
 >> iter 54000, loss: 0.434152
 >> iter 55000, loss: 0.366206
 >> iter 56000, loss: 0.514343
 >> iter 57000, loss: 0.301127
 >> iter 58000, loss: 0.416887
 >> iter 59000, loss: 0.313392
 >> iter 60000, loss: 0.390098
   Number of active neurons: 8
 >> iter 61000, loss: 0.450902
 >> iter 62000, loss: 0.384238
 >> iter 63000, loss: 0.392598
 >> iter 64000, loss: 0.351892
 >> iter 65000, loss: 0.385848
 >> iter 66000, loss: 0.325860
 >> iter 67000, loss: 0.223655
 >> iter 68000, loss: 0.476486
 >> iter 69000, loss: 0.382228
 >> iter 70000, loss: 0.360455
   Number of active neurons: 8
 >> iter 71000, loss: 0.297620
 >> iter 72000, loss: 0.332109
 >> iter 73000, loss: 0.327348
 >> iter 74000, loss: 0.304594
 >> iter 75000, loss: 0.211433
 >> iter 76000, loss: 0.404144
 >> iter 77000, loss: 0.331694
 >> iter 78000, loss: 0.506037
 >> iter 79000, loss: 0.473172
 >> iter 80000, loss: 0.329081
   Number of active neurons: 8
 >> iter 81000, loss: 0.463121
 >> iter 82000, loss: 0.414431
 >> iter 83000, loss: 0.307475
 >> iter 84000, loss: 0.304356
 >> iter 85000, loss: 0.375920
 >> iter 86000, loss: 0.318625
 >> iter 87000, loss: 0.464848
 >> iter 88000, loss: 0.350424
 >> iter 89000, loss: 0.465232
 >> iter 90000, loss: 0.413601
   Number of active neurons: 8
 >> iter 91000, loss: 0.252861
 >> iter 92000, loss: 0.312497
 >> iter 93000, loss: 0.377624
 >> iter 94000, loss: 0.490854
 >> iter 95000, loss: 0.406905
 >> iter 96000, loss: 0.492235
 >> iter 97000, loss: 0.530239
 >> iter 98000, loss: 0.416283
 >> iter 99000, loss: 0.367989
 >> iter 100000, loss: 0.261434
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.572369
 >> iter 2000, loss: 12.947352
 >> iter 3000, loss: 7.313181
 >> iter 4000, loss: 3.713621
 >> iter 5000, loss: 1.959731
 >> iter 6000, loss: 1.067871
 >> iter 7000, loss: 0.720755
 >> iter 8000, loss: 0.757951
 >> iter 9000, loss: 0.474719
 >> iter 10000, loss: 0.436647
   Number of active neurons: 8
 >> iter 11000, loss: 0.657241
 >> iter 12000, loss: 0.633174
 >> iter 13000, loss: 0.475940
 >> iter 14000, loss: 0.539820
 >> iter 15000, loss: 0.555029
 >> iter 16000, loss: 0.501330
 >> iter 17000, loss: 0.578534
 >> iter 18000, loss: 0.481160
 >> iter 19000, loss: 0.396776
 >> iter 20000, loss: 0.579466
   Number of active neurons: 6
 >> iter 21000, loss: 0.537677
 >> iter 22000, loss: 0.372622
 >> iter 23000, loss: 0.440489
 >> iter 24000, loss: 0.479865
 >> iter 25000, loss: 0.767352
 >> iter 26000, loss: 0.562278
 >> iter 27000, loss: 0.522398
 >> iter 28000, loss: 0.320410
 >> iter 29000, loss: 0.334393
 >> iter 30000, loss: 0.430769
   Number of active neurons: 6
 >> iter 31000, loss: 0.367627
 >> iter 32000, loss: 0.712626
 >> iter 33000, loss: 0.618875
 >> iter 34000, loss: 0.550789
 >> iter 35000, loss: 0.476956
 >> iter 36000, loss: 0.497176
 >> iter 37000, loss: 0.561234
 >> iter 38000, loss: 0.539009
 >> iter 39000, loss: 0.337837
 >> iter 40000, loss: 0.495678
   Number of active neurons: 6
 >> iter 41000, loss: 0.359898
 >> iter 42000, loss: 0.370083
 >> iter 43000, loss: 0.330981
 >> iter 44000, loss: 0.517034
 >> iter 45000, loss: 0.432257
 >> iter 46000, loss: 0.390210
 >> iter 47000, loss: 0.356503
 >> iter 48000, loss: 0.658151
 >> iter 49000, loss: 0.445664
 >> iter 50000, loss: 0.454314
   Number of active neurons: 6
 >> iter 51000, loss: 0.311889
 >> iter 52000, loss: 0.532512
 >> iter 53000, loss: 0.404983
 >> iter 54000, loss: 0.500800
 >> iter 55000, loss: 0.675420
 >> iter 56000, loss: 0.511130
 >> iter 57000, loss: 0.339835
 >> iter 58000, loss: 0.277490
 >> iter 59000, loss: 0.395259
 >> iter 60000, loss: 0.390963
   Number of active neurons: 5
 >> iter 61000, loss: 0.425186
 >> iter 62000, loss: 0.609149
 >> iter 63000, loss: 0.553300
 >> iter 64000, loss: 0.461141
 >> iter 65000, loss: 0.344361
 >> iter 66000, loss: 0.479878
 >> iter 67000, loss: 0.492267
 >> iter 68000, loss: 0.436207
 >> iter 69000, loss: 0.565475
 >> iter 70000, loss: 0.362969
   Number of active neurons: 8
 >> iter 71000, loss: 0.583310
 >> iter 72000, loss: 0.411229
 >> iter 73000, loss: 0.594889
 >> iter 74000, loss: 0.477865
 >> iter 75000, loss: 0.469397
 >> iter 76000, loss: 0.319887
 >> iter 77000, loss: 0.337413
 >> iter 78000, loss: 0.286462
 >> iter 79000, loss: 0.299391
 >> iter 80000, loss: 0.286425
   Number of active neurons: 5
 >> iter 81000, loss: 0.251782
 >> iter 82000, loss: 0.276906
 >> iter 83000, loss: 0.341378
 >> iter 84000, loss: 0.532448
 >> iter 85000, loss: 0.528160
 >> iter 86000, loss: 0.357248
 >> iter 87000, loss: 0.327829
 >> iter 88000, loss: 0.335010
 >> iter 89000, loss: 0.314344
 >> iter 90000, loss: 0.420297
   Number of active neurons: 6
 >> iter 91000, loss: 0.327190
 >> iter 92000, loss: 0.390166
 >> iter 93000, loss: 0.365230
 >> iter 94000, loss: 0.334291
 >> iter 95000, loss: 0.330955
 >> iter 96000, loss: 0.374085
 >> iter 97000, loss: 0.344395
 >> iter 98000, loss: 0.382715
 >> iter 99000, loss: 0.503924
 >> iter 100000, loss: 0.327187
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 18.132590
 >> iter 2000, loss: 9.437630
 >> iter 3000, loss: 4.597904
 >> iter 4000, loss: 1.981298
 >> iter 5000, loss: 0.865389
 >> iter 6000, loss: 0.616356
 >> iter 7000, loss: 0.563372
 >> iter 8000, loss: 0.344348
 >> iter 9000, loss: 0.376913
 >> iter 10000, loss: 0.418502
   Number of active neurons: 6
 >> iter 11000, loss: 0.281214
 >> iter 12000, loss: 0.346553
 >> iter 13000, loss: 0.404280
 >> iter 14000, loss: 0.199749
 >> iter 15000, loss: 0.349474
 >> iter 16000, loss: 0.442077
 >> iter 17000, loss: 0.354676
 >> iter 18000, loss: 0.262672
 >> iter 19000, loss: 0.229424
 >> iter 20000, loss: 0.138943
   Number of active neurons: 5
 >> iter 21000, loss: 0.424398
 >> iter 22000, loss: 0.329931
 >> iter 23000, loss: 0.199193
 >> iter 24000, loss: 0.241227
 >> iter 25000, loss: 0.143753
 >> iter 26000, loss: 0.134387
 >> iter 27000, loss: 0.290893
 >> iter 28000, loss: 0.267033
 >> iter 29000, loss: 0.256286
 >> iter 30000, loss: 0.192849
   Number of active neurons: 4
 >> iter 31000, loss: 0.122652
 >> iter 32000, loss: 0.233097
 >> iter 33000, loss: 0.246175
 >> iter 34000, loss: 0.218956
 >> iter 35000, loss: 0.253062
 >> iter 36000, loss: 0.187191
 >> iter 37000, loss: 0.338857
 >> iter 38000, loss: 0.254693
 >> iter 39000, loss: 0.229464
 >> iter 40000, loss: 0.175365
   Number of active neurons: 3
 >> iter 41000, loss: 0.104625
 >> iter 42000, loss: 0.206689
 >> iter 43000, loss: 0.131621
 >> iter 44000, loss: 0.389799
 >> iter 45000, loss: 0.250945
 >> iter 46000, loss: 0.337661
 >> iter 47000, loss: 0.178131
 >> iter 48000, loss: 0.163517
 >> iter 49000, loss: 0.295358
 >> iter 50000, loss: 0.243232
   Number of active neurons: 3
 >> iter 51000, loss: 0.203461
 >> iter 52000, loss: 0.254576
 >> iter 53000, loss: 0.176216
 >> iter 54000, loss: 0.199041
 >> iter 55000, loss: 0.159553
 >> iter 56000, loss: 0.465705
 >> iter 57000, loss: 0.276736
 >> iter 58000, loss: 0.365273
 >> iter 59000, loss: 0.308856
 >> iter 60000, loss: 0.151915
   Number of active neurons: 3
 >> iter 61000, loss: 0.118166
 >> iter 62000, loss: 0.263650
 >> iter 63000, loss: 0.290416
 >> iter 64000, loss: 0.257110
 >> iter 65000, loss: 0.200724
 >> iter 66000, loss: 0.157313
 >> iter 67000, loss: 0.160774
 >> iter 68000, loss: 0.149552
 >> iter 69000, loss: 0.218040
 >> iter 70000, loss: 0.322051
   Number of active neurons: 3
 >> iter 71000, loss: 0.194785
 >> iter 72000, loss: 0.358777
 >> iter 73000, loss: 0.342628
 >> iter 74000, loss: 0.285742
 >> iter 75000, loss: 0.276147
 >> iter 76000, loss: 0.434874
 >> iter 77000, loss: 0.331312
 >> iter 78000, loss: 0.329225
 >> iter 79000, loss: 0.289921
 >> iter 80000, loss: 0.166807
   Number of active neurons: 3
 >> iter 81000, loss: 0.181318
 >> iter 82000, loss: 0.160145
 >> iter 83000, loss: 0.206758
 >> iter 84000, loss: 0.328286
 >> iter 85000, loss: 0.332464
 >> iter 86000, loss: 0.316034
 >> iter 87000, loss: 0.288851
 >> iter 88000, loss: 0.182562
 >> iter 89000, loss: 0.193500
 >> iter 90000, loss: 0.207166
   Number of active neurons: 3
 >> iter 91000, loss: 0.229510
 >> iter 92000, loss: 0.220122
 >> iter 93000, loss: 0.326815
 >> iter 94000, loss: 0.300082
 >> iter 95000, loss: 0.224998
 >> iter 96000, loss: 0.130170
 >> iter 97000, loss: 0.212464
 >> iter 98000, loss: 0.218573
 >> iter 99000, loss: 0.191227
 >> iter 100000, loss: 0.217162
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.957800
 >> iter 2000, loss: 8.967507
 >> iter 3000, loss: 3.858050
 >> iter 4000, loss: 1.945390
 >> iter 5000, loss: 0.986719
 >> iter 6000, loss: 0.664847
 >> iter 7000, loss: 0.335013
 >> iter 8000, loss: 0.558790
 >> iter 9000, loss: 0.517971
 >> iter 10000, loss: 0.532294
   Number of active neurons: 4
 >> iter 11000, loss: 0.497744
 >> iter 12000, loss: 0.695685
 >> iter 13000, loss: 0.464795
 >> iter 14000, loss: 0.436474
 >> iter 15000, loss: 0.333909
 >> iter 16000, loss: 0.259137
 >> iter 17000, loss: 0.427055
 >> iter 18000, loss: 0.348445
 >> iter 19000, loss: 0.298387
 >> iter 20000, loss: 0.319987
   Number of active neurons: 4
 >> iter 21000, loss: 0.312013
 >> iter 22000, loss: 0.207355
 >> iter 23000, loss: 0.170663
 >> iter 24000, loss: 0.395426
 >> iter 25000, loss: 0.294312
 >> iter 26000, loss: 0.248458
 >> iter 27000, loss: 0.291352
 >> iter 28000, loss: 0.274275
 >> iter 29000, loss: 0.389412
 >> iter 30000, loss: 0.273521
   Number of active neurons: 4
 >> iter 31000, loss: 0.371009
 >> iter 32000, loss: 0.290563
 >> iter 33000, loss: 0.151842
 >> iter 34000, loss: 0.296337
 >> iter 35000, loss: 0.222711
 >> iter 36000, loss: 0.235339
 >> iter 37000, loss: 0.248847
 >> iter 38000, loss: 0.320704
 >> iter 39000, loss: 0.317557
 >> iter 40000, loss: 0.286159
   Number of active neurons: 4
 >> iter 41000, loss: 0.231914
 >> iter 42000, loss: 0.258102
 >> iter 43000, loss: 0.158188
 >> iter 44000, loss: 0.169977
 >> iter 45000, loss: 0.101897
 >> iter 46000, loss: 0.259296
 >> iter 47000, loss: 0.213632
 >> iter 48000, loss: 0.230895
 >> iter 49000, loss: 0.231282
 >> iter 50000, loss: 0.217899
   Number of active neurons: 4
 >> iter 51000, loss: 0.173736
 >> iter 52000, loss: 0.149948
 >> iter 53000, loss: 0.305969
 >> iter 54000, loss: 0.288688
 >> iter 55000, loss: 0.250883
 >> iter 56000, loss: 0.150511
 >> iter 57000, loss: 0.161157
 >> iter 58000, loss: 0.227003
 >> iter 59000, loss: 0.168864
 >> iter 60000, loss: 0.102187
   Number of active neurons: 4
 >> iter 61000, loss: 0.139586
 >> iter 62000, loss: 0.143079
 >> iter 63000, loss: 0.196577
 >> iter 64000, loss: 0.136851
 >> iter 65000, loss: 0.196904
 >> iter 66000, loss: 0.205488
 >> iter 67000, loss: 0.255836
 >> iter 68000, loss: 0.444255
 >> iter 69000, loss: 0.243724
 >> iter 70000, loss: 0.273559
   Number of active neurons: 4
 >> iter 71000, loss: 0.278527
 >> iter 72000, loss: 0.420851
 >> iter 73000, loss: 0.249299
 >> iter 74000, loss: 0.244814
 >> iter 75000, loss: 0.136946
 >> iter 76000, loss: 0.340109
 >> iter 77000, loss: 0.290336
 >> iter 78000, loss: 0.334896
 >> iter 79000, loss: 0.383456
 >> iter 80000, loss: 0.274597
   Number of active neurons: 4
 >> iter 81000, loss: 0.358673
 >> iter 82000, loss: 0.286435
 >> iter 83000, loss: 0.260607
 >> iter 84000, loss: 0.203608
 >> iter 85000, loss: 0.187864
 >> iter 86000, loss: 0.152003
 >> iter 87000, loss: 0.141851
 >> iter 88000, loss: 0.121548
 >> iter 89000, loss: 0.301261
 >> iter 90000, loss: 0.225820
   Number of active neurons: 4
 >> iter 91000, loss: 0.233388
 >> iter 92000, loss: 0.324686
 >> iter 93000, loss: 0.253266
 >> iter 94000, loss: 0.360294
 >> iter 95000, loss: 0.354731
 >> iter 96000, loss: 0.299132
 >> iter 97000, loss: 0.226955
 >> iter 98000, loss: 0.199336
 >> iter 99000, loss: 0.189060
 >> iter 100000, loss: 0.283356
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.763701
 >> iter 2000, loss: 11.625138
 >> iter 3000, loss: 6.470750
 >> iter 4000, loss: 3.087959
 >> iter 5000, loss: 1.971054
 >> iter 6000, loss: 1.228738
 >> iter 7000, loss: 1.067914
 >> iter 8000, loss: 0.838331
 >> iter 9000, loss: 0.687923
 >> iter 10000, loss: 0.667539
   Number of active neurons: 7
 >> iter 11000, loss: 0.502739
 >> iter 12000, loss: 0.516110
 >> iter 13000, loss: 0.430148
 >> iter 14000, loss: 0.556143
 >> iter 15000, loss: 0.657902
 >> iter 16000, loss: 0.558853
 >> iter 17000, loss: 0.703379
 >> iter 18000, loss: 0.719173
 >> iter 19000, loss: 0.443034
 >> iter 20000, loss: 0.474545
   Number of active neurons: 8
 >> iter 21000, loss: 0.390695
 >> iter 22000, loss: 0.497911
 >> iter 23000, loss: 0.463702
 >> iter 24000, loss: 0.352620
 >> iter 25000, loss: 0.375575
 >> iter 26000, loss: 0.332428
 >> iter 27000, loss: 0.379230
 >> iter 28000, loss: 0.460799
 >> iter 29000, loss: 0.508744
 >> iter 30000, loss: 0.539663
   Number of active neurons: 8
 >> iter 31000, loss: 0.568731
 >> iter 32000, loss: 0.508951
 >> iter 33000, loss: 0.470667
 >> iter 34000, loss: 0.585359
 >> iter 35000, loss: 0.611432
 >> iter 36000, loss: 0.497609
 >> iter 37000, loss: 0.293086
 >> iter 38000, loss: 0.552250
 >> iter 39000, loss: 0.637804
 >> iter 40000, loss: 0.380648
   Number of active neurons: 8
 >> iter 41000, loss: 0.385320
 >> iter 42000, loss: 0.426932
 >> iter 43000, loss: 0.460323
 >> iter 44000, loss: 0.498643
 >> iter 45000, loss: 0.421241
 >> iter 46000, loss: 0.656406
 >> iter 47000, loss: 0.575775
 >> iter 48000, loss: 0.457342
 >> iter 49000, loss: 0.408389
 >> iter 50000, loss: 0.305569
   Number of active neurons: 8
 >> iter 51000, loss: 0.352881
 >> iter 52000, loss: 0.262205
 >> iter 53000, loss: 0.349032
 >> iter 54000, loss: 0.484068
 >> iter 55000, loss: 0.541695
 >> iter 56000, loss: 0.322971
 >> iter 57000, loss: 0.599084
 >> iter 58000, loss: 0.434138
 >> iter 59000, loss: 0.610154
 >> iter 60000, loss: 0.409511
   Number of active neurons: 8
 >> iter 61000, loss: 0.344232
 >> iter 62000, loss: 0.453176
 >> iter 63000, loss: 0.447503
 >> iter 64000, loss: 0.360324
 >> iter 65000, loss: 0.507913
 >> iter 66000, loss: 0.359483
 >> iter 67000, loss: 0.350661
 >> iter 68000, loss: 0.329102
 >> iter 69000, loss: 0.491697
 >> iter 70000, loss: 0.319864
   Number of active neurons: 8
 >> iter 71000, loss: 0.288343
 >> iter 72000, loss: 0.187413
 >> iter 73000, loss: 0.106071
 >> iter 74000, loss: 0.148890
 >> iter 75000, loss: 0.298225
 >> iter 76000, loss: 0.432512
 >> iter 77000, loss: 0.343368
 >> iter 78000, loss: 0.337077
 >> iter 79000, loss: 0.673991
 >> iter 80000, loss: 0.765747
   Number of active neurons: 8
 >> iter 81000, loss: 0.555782
 >> iter 82000, loss: 0.491711
 >> iter 83000, loss: 0.537543
 >> iter 84000, loss: 0.517046
 >> iter 85000, loss: 0.337740
 >> iter 86000, loss: 0.584230
 >> iter 87000, loss: 0.437074
 >> iter 88000, loss: 0.465001
 >> iter 89000, loss: 0.320201
 >> iter 90000, loss: 0.381354
   Number of active neurons: 8
 >> iter 91000, loss: 0.415063
 >> iter 92000, loss: 0.328527
 >> iter 93000, loss: 0.602712
 >> iter 94000, loss: 0.662315
 >> iter 95000, loss: 0.400888
 >> iter 96000, loss: 0.442843
 >> iter 97000, loss: 0.325070
 >> iter 98000, loss: 0.442384
 >> iter 99000, loss: 0.495602
 >> iter 100000, loss: 0.609969
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.515464
 >> iter 2000, loss: 8.594998
 >> iter 3000, loss: 3.988804
 >> iter 4000, loss: 1.805891
 >> iter 5000, loss: 0.979063
 >> iter 6000, loss: 0.548029
 >> iter 7000, loss: 0.569522
 >> iter 8000, loss: 0.491601
 >> iter 9000, loss: 0.399908
 >> iter 10000, loss: 0.272279
   Number of active neurons: 3
 >> iter 11000, loss: 0.573288
 >> iter 12000, loss: 0.487816
 >> iter 13000, loss: 0.421100
 >> iter 14000, loss: 0.281593
 >> iter 15000, loss: 0.216701
 >> iter 16000, loss: 0.264305
 >> iter 17000, loss: 0.211970
 >> iter 18000, loss: 0.269188
 >> iter 19000, loss: 0.334828
 >> iter 20000, loss: 0.361651
   Number of active neurons: 3
 >> iter 21000, loss: 0.310714
 >> iter 22000, loss: 0.333838
 >> iter 23000, loss: 0.464540
 >> iter 24000, loss: 0.431640
 >> iter 25000, loss: 0.444681
 >> iter 26000, loss: 0.301945
 >> iter 27000, loss: 0.222800
 >> iter 28000, loss: 0.443775
 >> iter 29000, loss: 0.378609
 >> iter 30000, loss: 0.223979
   Number of active neurons: 3
 >> iter 31000, loss: 0.257199
 >> iter 32000, loss: 0.330777
 >> iter 33000, loss: 0.387280
 >> iter 34000, loss: 0.284410
 >> iter 35000, loss: 0.221598
 >> iter 36000, loss: 0.317220
 >> iter 37000, loss: 0.361467
 >> iter 38000, loss: 0.305189
 >> iter 39000, loss: 0.297696
 >> iter 40000, loss: 0.171814
   Number of active neurons: 3
 >> iter 41000, loss: 0.276699
 >> iter 42000, loss: 0.333285
 >> iter 43000, loss: 0.220363
 >> iter 44000, loss: 0.285036
 >> iter 45000, loss: 0.313640
 >> iter 46000, loss: 0.455939
 >> iter 47000, loss: 0.430256
 >> iter 48000, loss: 0.388200
 >> iter 49000, loss: 0.335107
 >> iter 50000, loss: 0.269034
   Number of active neurons: 3
 >> iter 51000, loss: 0.451585
 >> iter 52000, loss: 0.282751
 >> iter 53000, loss: 0.218355
 >> iter 54000, loss: 0.261446
 >> iter 55000, loss: 0.157080
 >> iter 56000, loss: 0.241610
 >> iter 57000, loss: 0.392218
 >> iter 58000, loss: 0.352819
 >> iter 59000, loss: 0.349719
 >> iter 60000, loss: 0.243101
   Number of active neurons: 3
 >> iter 61000, loss: 0.351330
 >> iter 62000, loss: 0.344474
 >> iter 63000, loss: 0.333439
 >> iter 64000, loss: 0.268095
 >> iter 65000, loss: 0.564915
 >> iter 66000, loss: 0.551246
 >> iter 67000, loss: 0.446437
 >> iter 68000, loss: 0.492446
 >> iter 69000, loss: 0.438317
 >> iter 70000, loss: 0.248062
   Number of active neurons: 3
 >> iter 71000, loss: 0.283823
 >> iter 72000, loss: 0.324480
 >> iter 73000, loss: 0.319034
 >> iter 74000, loss: 0.327920
 >> iter 75000, loss: 0.306580
 >> iter 76000, loss: 0.233941
 >> iter 77000, loss: 0.173687
 >> iter 78000, loss: 0.169555
 >> iter 79000, loss: 0.222937
 >> iter 80000, loss: 0.160631
   Number of active neurons: 3
 >> iter 81000, loss: 0.269034
 >> iter 82000, loss: 0.334323
 >> iter 83000, loss: 0.263537
 >> iter 84000, loss: 0.373178
 >> iter 85000, loss: 0.309866
 >> iter 86000, loss: 0.229613
 >> iter 87000, loss: 0.292619
 >> iter 88000, loss: 0.213252
 >> iter 89000, loss: 0.284673
 >> iter 90000, loss: 0.236341
   Number of active neurons: 3
 >> iter 91000, loss: 0.215003
 >> iter 92000, loss: 0.344030
 >> iter 93000, loss: 0.253978
 >> iter 94000, loss: 0.287444
 >> iter 95000, loss: 0.260279
 >> iter 96000, loss: 0.237756
 >> iter 97000, loss: 0.232334
 >> iter 98000, loss: 0.371974
 >> iter 99000, loss: 0.280070
 >> iter 100000, loss: 0.186376
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.061137
 >> iter 2000, loss: 11.002430
 >> iter 3000, loss: 6.085465
 >> iter 4000, loss: 3.133994
 >> iter 5000, loss: 2.058684
 >> iter 6000, loss: 1.359928
 >> iter 7000, loss: 1.393452
 >> iter 8000, loss: 1.030134
 >> iter 9000, loss: 0.697751
 >> iter 10000, loss: 0.725271
   Number of active neurons: 8
 >> iter 11000, loss: 0.500996
 >> iter 12000, loss: 0.603391
 >> iter 13000, loss: 0.617955
 >> iter 14000, loss: 0.890800
 >> iter 15000, loss: 0.644367
 >> iter 16000, loss: 0.643419
 >> iter 17000, loss: 0.548382
 >> iter 18000, loss: 0.569202
 >> iter 19000, loss: 0.523385
 >> iter 20000, loss: 0.538027
   Number of active neurons: 8
 >> iter 21000, loss: 0.445505
 >> iter 22000, loss: 0.393083
 >> iter 23000, loss: 0.303528
 >> iter 24000, loss: 0.291879
 >> iter 25000, loss: 0.319507
 >> iter 26000, loss: 0.601538
 >> iter 27000, loss: 0.499768
 >> iter 28000, loss: 0.450123
 >> iter 29000, loss: 0.367436
 >> iter 30000, loss: 0.622173
   Number of active neurons: 6
 >> iter 31000, loss: 0.380249
 >> iter 32000, loss: 0.290687
 >> iter 33000, loss: 0.404871
 >> iter 34000, loss: 0.455057
 >> iter 35000, loss: 0.509723
 >> iter 36000, loss: 0.500019
 >> iter 37000, loss: 0.496233
 >> iter 38000, loss: 0.348647
 >> iter 39000, loss: 0.286797
 >> iter 40000, loss: 0.424753
   Number of active neurons: 8
 >> iter 41000, loss: 0.475366
 >> iter 42000, loss: 0.386609
 >> iter 43000, loss: 0.673354
 >> iter 44000, loss: 0.498062
 >> iter 45000, loss: 0.468628
 >> iter 46000, loss: 0.377765
 >> iter 47000, loss: 0.282110
 >> iter 48000, loss: 0.288945
 >> iter 49000, loss: 0.374687
 >> iter 50000, loss: 0.368410
   Number of active neurons: 8
 >> iter 51000, loss: 0.362577
 >> iter 52000, loss: 0.193758
 >> iter 53000, loss: 0.291699
 >> iter 54000, loss: 0.232460
 >> iter 55000, loss: 0.450821
 >> iter 56000, loss: 0.344905
 >> iter 57000, loss: 0.295599
 >> iter 58000, loss: 0.419861
 >> iter 59000, loss: 0.410536
 >> iter 60000, loss: 0.393866
   Number of active neurons: 7
 >> iter 61000, loss: 0.320049
 >> iter 62000, loss: 0.398003
 >> iter 63000, loss: 0.543126
 >> iter 64000, loss: 0.399248
 >> iter 65000, loss: 0.428559
 >> iter 66000, loss: 0.349064
 >> iter 67000, loss: 0.239355
 >> iter 68000, loss: 0.346084
 >> iter 69000, loss: 0.230527
 >> iter 70000, loss: 0.607769
   Number of active neurons: 8
 >> iter 71000, loss: 0.553246
 >> iter 72000, loss: 0.501817
 >> iter 73000, loss: 0.272019
 >> iter 74000, loss: 0.367737
 >> iter 75000, loss: 0.500680
 >> iter 76000, loss: 0.588933
 >> iter 77000, loss: 0.494614
 >> iter 78000, loss: 0.374767
 >> iter 79000, loss: 0.179809
 >> iter 80000, loss: 0.381151
   Number of active neurons: 8
 >> iter 81000, loss: 0.413865
 >> iter 82000, loss: 0.496382
 >> iter 83000, loss: 0.394596
 >> iter 84000, loss: 0.394959
 >> iter 85000, loss: 0.334889
 >> iter 86000, loss: 0.390106
 >> iter 87000, loss: 0.408050
 >> iter 88000, loss: 0.491064
 >> iter 89000, loss: 0.349768
 >> iter 90000, loss: 0.227892
   Number of active neurons: 8
 >> iter 91000, loss: 0.234740
 >> iter 92000, loss: 0.355356
 >> iter 93000, loss: 0.425027
 >> iter 94000, loss: 0.298880
 >> iter 95000, loss: 0.372406
 >> iter 96000, loss: 0.258902
 >> iter 97000, loss: 0.216823
 >> iter 98000, loss: 0.303362
 >> iter 99000, loss: 0.233857
 >> iter 100000, loss: 0.290004
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.428463
 >> iter 2000, loss: 8.957477
 >> iter 3000, loss: 4.294010
 >> iter 4000, loss: 2.351041
 >> iter 5000, loss: 1.357711
 >> iter 6000, loss: 1.202157
 >> iter 7000, loss: 0.850375
 >> iter 8000, loss: 0.750403
 >> iter 9000, loss: 0.593785
 >> iter 10000, loss: 0.509201
   Number of active neurons: 5
 >> iter 11000, loss: 0.427261
 >> iter 12000, loss: 0.518275
 >> iter 13000, loss: 0.442446
 >> iter 14000, loss: 0.525088
 >> iter 15000, loss: 0.532651
 >> iter 16000, loss: 0.487939
 >> iter 17000, loss: 0.548064
 >> iter 18000, loss: 0.569435
 >> iter 19000, loss: 0.455297
 >> iter 20000, loss: 0.656072
   Number of active neurons: 4
 >> iter 21000, loss: 0.697790
 >> iter 22000, loss: 0.457938
 >> iter 23000, loss: 0.416263
 >> iter 24000, loss: 0.602848
 >> iter 25000, loss: 0.592269
 >> iter 26000, loss: 0.459925
 >> iter 27000, loss: 0.443052
 >> iter 28000, loss: 0.462917
 >> iter 29000, loss: 0.436439
 >> iter 30000, loss: 0.482798
   Number of active neurons: 4
 >> iter 31000, loss: 0.556470
 >> iter 32000, loss: 0.503426
 >> iter 33000, loss: 0.442872
 >> iter 34000, loss: 0.686546
 >> iter 35000, loss: 0.461375
 >> iter 36000, loss: 0.244182
 >> iter 37000, loss: 0.437757
 >> iter 38000, loss: 0.354220
 >> iter 39000, loss: 0.276065
 >> iter 40000, loss: 0.433217
   Number of active neurons: 3
 >> iter 41000, loss: 0.568182
 >> iter 42000, loss: 0.618918
 >> iter 43000, loss: 0.503541
 >> iter 44000, loss: 0.506829
 >> iter 45000, loss: 0.402012
 >> iter 46000, loss: 0.394052
 >> iter 47000, loss: 0.442606
 >> iter 48000, loss: 0.281134
 >> iter 49000, loss: 0.553200
 >> iter 50000, loss: 0.783340
   Number of active neurons: 3
 >> iter 51000, loss: 0.524859
 >> iter 52000, loss: 0.510086
 >> iter 53000, loss: 0.470315
 >> iter 54000, loss: 0.444717
 >> iter 55000, loss: 0.366574
 >> iter 56000, loss: 0.253859
 >> iter 57000, loss: 0.405488
 >> iter 58000, loss: 0.470535
 >> iter 59000, loss: 0.435120
 >> iter 60000, loss: 0.335286
   Number of active neurons: 3
 >> iter 61000, loss: 0.483581
 >> iter 62000, loss: 0.502275
 >> iter 63000, loss: 0.477698
 >> iter 64000, loss: 0.458416
 >> iter 65000, loss: 0.420555
 >> iter 66000, loss: 0.436859
 >> iter 67000, loss: 0.611530
 >> iter 68000, loss: 0.575878
 >> iter 69000, loss: 0.600861
 >> iter 70000, loss: 0.557458
   Number of active neurons: 3
 >> iter 71000, loss: 0.532111
 >> iter 72000, loss: 0.577879
 >> iter 73000, loss: 0.469053
 >> iter 74000, loss: 0.342553
 >> iter 75000, loss: 0.258868
 >> iter 76000, loss: 0.437473
 >> iter 77000, loss: 0.497188
 >> iter 78000, loss: 0.479050
 >> iter 79000, loss: 0.404125
 >> iter 80000, loss: 0.647780
   Number of active neurons: 3
 >> iter 81000, loss: 0.479058
 >> iter 82000, loss: 0.608815
 >> iter 83000, loss: 0.630889
 >> iter 84000, loss: 0.588256
 >> iter 85000, loss: 0.365485
 >> iter 86000, loss: 0.474514
 >> iter 87000, loss: 0.549492
 >> iter 88000, loss: 0.325553
 >> iter 89000, loss: 0.236153
 >> iter 90000, loss: 0.590760
   Number of active neurons: 3
 >> iter 91000, loss: 0.489300
 >> iter 92000, loss: 0.603945
 >> iter 93000, loss: 0.595390
 >> iter 94000, loss: 0.605287
 >> iter 95000, loss: 0.342543
 >> iter 96000, loss: 0.466541
 >> iter 97000, loss: 0.478102
 >> iter 98000, loss: 0.487167
 >> iter 99000, loss: 0.481990
 >> iter 100000, loss: 0.438666
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.318617
 >> iter 2000, loss: 10.823592
 >> iter 3000, loss: 5.430085
 >> iter 4000, loss: 2.881204
 >> iter 5000, loss: 1.632570
 >> iter 6000, loss: 1.199783
 >> iter 7000, loss: 0.887318
 >> iter 8000, loss: 0.753137
 >> iter 9000, loss: 0.611970
 >> iter 10000, loss: 0.620130
   Number of active neurons: 8
 >> iter 11000, loss: 0.596507
 >> iter 12000, loss: 0.640530
 >> iter 13000, loss: 0.420324
 >> iter 14000, loss: 0.526434
 >> iter 15000, loss: 0.647215
 >> iter 16000, loss: 0.433194
 >> iter 17000, loss: 0.526973
 >> iter 18000, loss: 0.678026
 >> iter 19000, loss: 0.528169
 >> iter 20000, loss: 0.479101
   Number of active neurons: 8
 >> iter 21000, loss: 0.537078
 >> iter 22000, loss: 0.433196
 >> iter 23000, loss: 0.560385
 >> iter 24000, loss: 0.490427
 >> iter 25000, loss: 0.443436
 >> iter 26000, loss: 0.564686
 >> iter 27000, loss: 0.422454
 >> iter 28000, loss: 0.556435
 >> iter 29000, loss: 0.335948
 >> iter 30000, loss: 0.672450
   Number of active neurons: 8
 >> iter 31000, loss: 0.496870
 >> iter 32000, loss: 0.593145
 >> iter 33000, loss: 0.737817
 >> iter 34000, loss: 0.466377
 >> iter 35000, loss: 0.542384
 >> iter 36000, loss: 0.536592
 >> iter 37000, loss: 0.463447
 >> iter 38000, loss: 0.284157
 >> iter 39000, loss: 0.460723
 >> iter 40000, loss: 0.512217
   Number of active neurons: 8
 >> iter 41000, loss: 0.568473
 >> iter 42000, loss: 0.435824
 >> iter 43000, loss: 0.594026
 >> iter 44000, loss: 0.502912
 >> iter 45000, loss: 0.575304
 >> iter 46000, loss: 0.475497
 >> iter 47000, loss: 0.350471
 >> iter 48000, loss: 0.609832
 >> iter 49000, loss: 0.595263
 >> iter 50000, loss: 0.536928
   Number of active neurons: 8
 >> iter 51000, loss: 0.519612
 >> iter 52000, loss: 0.534234
 >> iter 53000, loss: 0.633948
 >> iter 54000, loss: 0.816925
 >> iter 55000, loss: 0.488284
 >> iter 56000, loss: 0.484473
 >> iter 57000, loss: 0.361181
 >> iter 58000, loss: 0.588020
 >> iter 59000, loss: 0.496410
 >> iter 60000, loss: 0.545677
   Number of active neurons: 7
 >> iter 61000, loss: 0.745600
 >> iter 62000, loss: 0.568472
 >> iter 63000, loss: 0.398381
 >> iter 64000, loss: 0.428522
 >> iter 65000, loss: 0.430116
 >> iter 66000, loss: 0.325503
 >> iter 67000, loss: 0.521429
 >> iter 68000, loss: 0.368356
 >> iter 69000, loss: 0.307826
 >> iter 70000, loss: 0.332957
   Number of active neurons: 8
 >> iter 71000, loss: 0.454659
 >> iter 72000, loss: 0.446196
 >> iter 73000, loss: 0.497165
 >> iter 74000, loss: 0.403543
 >> iter 75000, loss: 0.512538
 >> iter 76000, loss: 0.362069
 >> iter 77000, loss: 0.354458
 >> iter 78000, loss: 0.342088
 >> iter 79000, loss: 0.254346
 >> iter 80000, loss: 0.293019
   Number of active neurons: 8
 >> iter 81000, loss: 0.586630
 >> iter 82000, loss: 0.639935
 >> iter 83000, loss: 0.419498
 >> iter 84000, loss: 0.415574
 >> iter 85000, loss: 0.355014
 >> iter 86000, loss: 0.328637
 >> iter 87000, loss: 0.325039
 >> iter 88000, loss: 0.443059
 >> iter 89000, loss: 0.258155
 >> iter 90000, loss: 0.338423
   Number of active neurons: 8
 >> iter 91000, loss: 0.206045
 >> iter 92000, loss: 0.400224
 >> iter 93000, loss: 0.299899
 >> iter 94000, loss: 0.362777
 >> iter 95000, loss: 0.380362
 >> iter 96000, loss: 0.490074
 >> iter 97000, loss: 0.410463
 >> iter 98000, loss: 0.426112
 >> iter 99000, loss: 0.429636
 >> iter 100000, loss: 0.307667
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.442464
 >> iter 2000, loss: 9.288435
 >> iter 3000, loss: 4.511693
 >> iter 4000, loss: 2.562082
 >> iter 5000, loss: 1.562881
 >> iter 6000, loss: 0.966343
 >> iter 7000, loss: 0.617788
 >> iter 8000, loss: 0.491109
 >> iter 9000, loss: 0.597593
 >> iter 10000, loss: 0.501911
   Number of active neurons: 5
 >> iter 11000, loss: 0.508320
 >> iter 12000, loss: 0.755937
 >> iter 13000, loss: 0.555193
 >> iter 14000, loss: 0.527271
 >> iter 15000, loss: 0.570750
 >> iter 16000, loss: 0.683285
 >> iter 17000, loss: 0.390055
 >> iter 18000, loss: 0.485399
 >> iter 19000, loss: 0.412338
 >> iter 20000, loss: 0.580090
   Number of active neurons: 5
 >> iter 21000, loss: 0.565642
 >> iter 22000, loss: 0.519008
 >> iter 23000, loss: 0.431402
 >> iter 24000, loss: 0.500080
 >> iter 25000, loss: 0.327036
 >> iter 26000, loss: 0.354243
 >> iter 27000, loss: 0.373289
 >> iter 28000, loss: 0.338116
 >> iter 29000, loss: 0.306839
 >> iter 30000, loss: 0.561313
   Number of active neurons: 5
 >> iter 31000, loss: 0.545325
 >> iter 32000, loss: 0.424873
 >> iter 33000, loss: 0.335035
 >> iter 34000, loss: 0.337719
 >> iter 35000, loss: 0.448459
 >> iter 36000, loss: 0.429445
 >> iter 37000, loss: 0.496675
 >> iter 38000, loss: 0.456888
 >> iter 39000, loss: 0.710125
 >> iter 40000, loss: 0.587462
   Number of active neurons: 5
 >> iter 41000, loss: 0.667730
 >> iter 42000, loss: 0.492774
 >> iter 43000, loss: 0.414129
 >> iter 44000, loss: 0.496894
 >> iter 45000, loss: 0.544789
 >> iter 46000, loss: 0.372471
 >> iter 47000, loss: 0.297835
 >> iter 48000, loss: 0.416311
 >> iter 49000, loss: 0.619905
 >> iter 50000, loss: 0.423360
   Number of active neurons: 5
 >> iter 51000, loss: 0.293087
 >> iter 52000, loss: 0.473854
 >> iter 53000, loss: 0.338351
 >> iter 54000, loss: 0.333088
 >> iter 55000, loss: 0.565933
 >> iter 56000, loss: 0.574860
 >> iter 57000, loss: 0.496519
 >> iter 58000, loss: 0.431870
 >> iter 59000, loss: 0.395002
 >> iter 60000, loss: 0.673370
   Number of active neurons: 5
 >> iter 61000, loss: 0.548262
 >> iter 62000, loss: 0.747560
 >> iter 63000, loss: 0.540022
 >> iter 64000, loss: 0.508928
 >> iter 65000, loss: 0.356567
 >> iter 66000, loss: 0.331102
 >> iter 67000, loss: 0.429271
 >> iter 68000, loss: 0.404091
 >> iter 69000, loss: 0.483279
 >> iter 70000, loss: 0.478530
   Number of active neurons: 5
 >> iter 71000, loss: 0.628064
 >> iter 72000, loss: 0.580608
 >> iter 73000, loss: 0.572412
 >> iter 74000, loss: 0.448220
 >> iter 75000, loss: 0.633009
 >> iter 76000, loss: 0.464431
 >> iter 77000, loss: 0.520858
 >> iter 78000, loss: 0.528654
 >> iter 79000, loss: 0.354978
 >> iter 80000, loss: 0.398942
   Number of active neurons: 5
 >> iter 81000, loss: 0.494363
 >> iter 82000, loss: 0.429629
 >> iter 83000, loss: 0.321114
 >> iter 84000, loss: 0.431528
 >> iter 85000, loss: 0.299573
 >> iter 86000, loss: 0.749235
 >> iter 87000, loss: 0.433013
 >> iter 88000, loss: 0.405750
 >> iter 89000, loss: 0.534026
 >> iter 90000, loss: 0.390887
   Number of active neurons: 4
 >> iter 91000, loss: 0.418217
 >> iter 92000, loss: 0.411132
 >> iter 93000, loss: 0.350352
 >> iter 94000, loss: 0.602068
 >> iter 95000, loss: 0.453903
 >> iter 96000, loss: 0.446638
 >> iter 97000, loss: 0.638291
 >> iter 98000, loss: 0.560212
 >> iter 99000, loss: 0.544880
 >> iter 100000, loss: 0.478620
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.746853
 >> iter 2000, loss: 7.824109
 >> iter 3000, loss: 3.270846
 >> iter 4000, loss: 1.730601
 >> iter 5000, loss: 1.309950
 >> iter 6000, loss: 0.916429
 >> iter 7000, loss: 0.504392
 >> iter 8000, loss: 0.420938
 >> iter 9000, loss: 0.353779
 >> iter 10000, loss: 0.291749
   Number of active neurons: 5
 >> iter 11000, loss: 0.301571
 >> iter 12000, loss: 0.284361
 >> iter 13000, loss: 0.260529
 >> iter 14000, loss: 0.221300
 >> iter 15000, loss: 0.368297
 >> iter 16000, loss: 0.404425
 >> iter 17000, loss: 0.216751
 >> iter 18000, loss: 0.164372
 >> iter 19000, loss: 0.406634
 >> iter 20000, loss: 0.534322
   Number of active neurons: 5
 >> iter 21000, loss: 0.313274
 >> iter 22000, loss: 0.343791
 >> iter 23000, loss: 0.244974
 >> iter 24000, loss: 0.291791
 >> iter 25000, loss: 0.234607
 >> iter 26000, loss: 0.213766
 >> iter 27000, loss: 0.262773
 >> iter 28000, loss: 0.266005
 >> iter 29000, loss: 0.252647
 >> iter 30000, loss: 0.256309
   Number of active neurons: 4
 >> iter 31000, loss: 0.472147
 >> iter 32000, loss: 0.383555
 >> iter 33000, loss: 0.463941
 >> iter 34000, loss: 0.280149
 >> iter 35000, loss: 0.282543
 >> iter 36000, loss: 0.322137
 >> iter 37000, loss: 0.374355
 >> iter 38000, loss: 0.213699
 >> iter 39000, loss: 0.232587
 >> iter 40000, loss: 0.399505
   Number of active neurons: 4
 >> iter 41000, loss: 0.256119
 >> iter 42000, loss: 0.133875
 >> iter 43000, loss: 0.163408
 >> iter 44000, loss: 0.177184
 >> iter 45000, loss: 0.232231
 >> iter 46000, loss: 0.286669
 >> iter 47000, loss: 0.206734
 >> iter 48000, loss: 0.158273
 >> iter 49000, loss: 0.254535
 >> iter 50000, loss: 0.178660
   Number of active neurons: 3
 >> iter 51000, loss: 0.306332
 >> iter 52000, loss: 0.207009
 >> iter 53000, loss: 0.229080
 >> iter 54000, loss: 0.426979
 >> iter 55000, loss: 0.238279
 >> iter 56000, loss: 0.199654
 >> iter 57000, loss: 0.213684
 >> iter 58000, loss: 0.401324
 >> iter 59000, loss: 0.318696
 >> iter 60000, loss: 0.247935
   Number of active neurons: 3
 >> iter 61000, loss: 0.124208
 >> iter 62000, loss: 0.259010
 >> iter 63000, loss: 0.247228
 >> iter 64000, loss: 0.233285
 >> iter 65000, loss: 0.158183
 >> iter 66000, loss: 0.256525
 >> iter 67000, loss: 0.166250
 >> iter 68000, loss: 0.350418
 >> iter 69000, loss: 0.256001
 >> iter 70000, loss: 0.307239
   Number of active neurons: 3
 >> iter 71000, loss: 0.208728
 >> iter 72000, loss: 0.283992
 >> iter 73000, loss: 0.264085
 >> iter 74000, loss: 0.362471
 >> iter 75000, loss: 0.288338
 >> iter 76000, loss: 0.218077
 >> iter 77000, loss: 0.166571
 >> iter 78000, loss: 0.137013
 >> iter 79000, loss: 0.144223
 >> iter 80000, loss: 0.168855
   Number of active neurons: 3
 >> iter 81000, loss: 0.166999
 >> iter 82000, loss: 0.290687
 >> iter 83000, loss: 0.241351
 >> iter 84000, loss: 0.274142
 >> iter 85000, loss: 0.239393
 >> iter 86000, loss: 0.301520
 >> iter 87000, loss: 0.209012
 >> iter 88000, loss: 0.171635
 >> iter 89000, loss: 0.141665
 >> iter 90000, loss: 0.203831
   Number of active neurons: 3
 >> iter 91000, loss: 0.300667
 >> iter 92000, loss: 0.336720
 >> iter 93000, loss: 0.289473
 >> iter 94000, loss: 0.168475
 >> iter 95000, loss: 0.156461
 >> iter 96000, loss: 0.216295
 >> iter 97000, loss: 0.390999
 >> iter 98000, loss: 0.385476
 >> iter 99000, loss: 0.449330
 >> iter 100000, loss: 0.316769
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.979748
 >> iter 2000, loss: 8.628059
 >> iter 3000, loss: 4.116666
 >> iter 4000, loss: 1.944887
 >> iter 5000, loss: 0.997249
 >> iter 6000, loss: 0.683775
 >> iter 7000, loss: 0.572842
 >> iter 8000, loss: 0.535999
 >> iter 9000, loss: 0.366488
 >> iter 10000, loss: 0.583049
   Number of active neurons: 4
 >> iter 11000, loss: 0.487309
 >> iter 12000, loss: 0.418560
 >> iter 13000, loss: 0.487894
 >> iter 14000, loss: 0.434010
 >> iter 15000, loss: 0.321019
 >> iter 16000, loss: 0.266091
 >> iter 17000, loss: 0.387029
 >> iter 18000, loss: 0.285839
 >> iter 19000, loss: 0.304985
 >> iter 20000, loss: 0.279461
   Number of active neurons: 4
 >> iter 21000, loss: 0.363337
 >> iter 22000, loss: 0.317719
 >> iter 23000, loss: 0.326814
 >> iter 24000, loss: 0.249919
 >> iter 25000, loss: 0.369075
 >> iter 26000, loss: 0.347745
 >> iter 27000, loss: 0.296879
 >> iter 28000, loss: 0.256844
 >> iter 29000, loss: 0.261407
 >> iter 30000, loss: 0.250363
   Number of active neurons: 4
 >> iter 31000, loss: 0.314530
 >> iter 32000, loss: 0.253968
 >> iter 33000, loss: 0.488784
 >> iter 34000, loss: 0.276169
 >> iter 35000, loss: 0.274533
 >> iter 36000, loss: 0.334750
 >> iter 37000, loss: 0.270044
 >> iter 38000, loss: 0.253537
 >> iter 39000, loss: 0.224712
 >> iter 40000, loss: 0.209296
   Number of active neurons: 3
 >> iter 41000, loss: 0.140447
 >> iter 42000, loss: 0.422230
 >> iter 43000, loss: 0.306019
 >> iter 44000, loss: 0.398083
 >> iter 45000, loss: 0.434664
 >> iter 46000, loss: 0.478006
 >> iter 47000, loss: 0.490728
 >> iter 48000, loss: 0.341747
 >> iter 49000, loss: 0.211661
 >> iter 50000, loss: 0.250565
   Number of active neurons: 3
 >> iter 51000, loss: 0.263533
 >> iter 52000, loss: 0.330846
 >> iter 53000, loss: 0.283574
 >> iter 54000, loss: 0.202335
 >> iter 55000, loss: 0.219781
 >> iter 56000, loss: 0.248871
 >> iter 57000, loss: 0.339072
 >> iter 58000, loss: 0.158224
 >> iter 59000, loss: 0.137446
 >> iter 60000, loss: 0.138372
   Number of active neurons: 3
 >> iter 61000, loss: 0.416894
 >> iter 62000, loss: 0.280300
 >> iter 63000, loss: 0.433267
 >> iter 64000, loss: 0.298183
 >> iter 65000, loss: 0.189409
 >> iter 66000, loss: 0.291702
 >> iter 67000, loss: 0.262154
 >> iter 68000, loss: 0.287129
 >> iter 69000, loss: 0.285724
 >> iter 70000, loss: 0.186938
   Number of active neurons: 3
 >> iter 71000, loss: 0.273482
 >> iter 72000, loss: 0.566785
 >> iter 73000, loss: 0.288545
 >> iter 74000, loss: 0.255261
 >> iter 75000, loss: 0.318917
 >> iter 76000, loss: 0.273764
 >> iter 77000, loss: 0.323422
 >> iter 78000, loss: 0.392990
 >> iter 79000, loss: 0.181545
 >> iter 80000, loss: 0.224096
   Number of active neurons: 3
 >> iter 81000, loss: 0.228332
 >> iter 82000, loss: 0.308943
 >> iter 83000, loss: 0.266075
 >> iter 84000, loss: 0.283493
 >> iter 85000, loss: 0.334115
 >> iter 86000, loss: 0.246528
 >> iter 87000, loss: 0.171449
 >> iter 88000, loss: 0.231929
 >> iter 89000, loss: 0.202607
 >> iter 90000, loss: 0.296588
   Number of active neurons: 3
 >> iter 91000, loss: 0.214956
 >> iter 92000, loss: 0.237371
 >> iter 93000, loss: 0.186071
 >> iter 94000, loss: 0.312622
 >> iter 95000, loss: 0.290408
 >> iter 96000, loss: 0.203954
 >> iter 97000, loss: 0.207994
 >> iter 98000, loss: 0.191214
 >> iter 99000, loss: 0.380231
 >> iter 100000, loss: 0.460786
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.868627
 >> iter 2000, loss: 9.959862
 >> iter 3000, loss: 4.563202
 >> iter 4000, loss: 2.232691
 >> iter 5000, loss: 1.067104
 >> iter 6000, loss: 0.816466
 >> iter 7000, loss: 0.498169
 >> iter 8000, loss: 0.422364
 >> iter 9000, loss: 0.337965
 >> iter 10000, loss: 0.363806
   Number of active neurons: 5
 >> iter 11000, loss: 0.286532
 >> iter 12000, loss: 0.299560
 >> iter 13000, loss: 0.251874
 >> iter 14000, loss: 0.330919
 >> iter 15000, loss: 0.301526
 >> iter 16000, loss: 0.256501
 >> iter 17000, loss: 0.392131
 >> iter 18000, loss: 0.413901
 >> iter 19000, loss: 0.228920
 >> iter 20000, loss: 0.302616
   Number of active neurons: 5
 >> iter 21000, loss: 0.238381
 >> iter 22000, loss: 0.200563
 >> iter 23000, loss: 0.448945
 >> iter 24000, loss: 0.230318
 >> iter 25000, loss: 0.267211
 >> iter 26000, loss: 0.257334
 >> iter 27000, loss: 0.238575
 >> iter 28000, loss: 0.210920
 >> iter 29000, loss: 0.350806
 >> iter 30000, loss: 0.290064
   Number of active neurons: 4
 >> iter 31000, loss: 0.242503
 >> iter 32000, loss: 0.303083
 >> iter 33000, loss: 0.186489
 >> iter 34000, loss: 0.189208
 >> iter 35000, loss: 0.418757
 >> iter 36000, loss: 0.340867
 >> iter 37000, loss: 0.365771
 >> iter 38000, loss: 0.257042
 >> iter 39000, loss: 0.194811
 >> iter 40000, loss: 0.110446
   Number of active neurons: 4
 >> iter 41000, loss: 0.210061
 >> iter 42000, loss: 0.241404
 >> iter 43000, loss: 0.207665
 >> iter 44000, loss: 0.178276
 >> iter 45000, loss: 0.178946
 >> iter 46000, loss: 0.246225
 >> iter 47000, loss: 0.574471
 >> iter 48000, loss: 0.496648
 >> iter 49000, loss: 0.324139
 >> iter 50000, loss: 0.265508
   Number of active neurons: 3
 >> iter 51000, loss: 0.243132
 >> iter 52000, loss: 0.235250
 >> iter 53000, loss: 0.246711
 >> iter 54000, loss: 0.251972
 >> iter 55000, loss: 0.412134
 >> iter 56000, loss: 0.203013
 >> iter 57000, loss: 0.240314
 >> iter 58000, loss: 0.213880
 >> iter 59000, loss: 0.174319
 >> iter 60000, loss: 0.418908
   Number of active neurons: 3
 >> iter 61000, loss: 0.189175
 >> iter 62000, loss: 0.327032
 >> iter 63000, loss: 0.221897
 >> iter 64000, loss: 0.302958
 >> iter 65000, loss: 0.211449
 >> iter 66000, loss: 0.204275
 >> iter 67000, loss: 0.119541
 >> iter 68000, loss: 0.206774
 >> iter 69000, loss: 0.179710
 >> iter 70000, loss: 0.278725
   Number of active neurons: 3
 >> iter 71000, loss: 0.289821
 >> iter 72000, loss: 0.220954
 >> iter 73000, loss: 0.209744
 >> iter 74000, loss: 0.151362
 >> iter 75000, loss: 0.232618
 >> iter 76000, loss: 0.164063
 >> iter 77000, loss: 0.185810
 >> iter 78000, loss: 0.204393
 >> iter 79000, loss: 0.251387
 >> iter 80000, loss: 0.552871
   Number of active neurons: 3
 >> iter 81000, loss: 0.334879
 >> iter 82000, loss: 0.469515
 >> iter 83000, loss: 0.232392
 >> iter 84000, loss: 0.116402
 >> iter 85000, loss: 0.177776
 >> iter 86000, loss: 0.229222
 >> iter 87000, loss: 0.178514
 >> iter 88000, loss: 0.318693
 >> iter 89000, loss: 0.233573
 >> iter 90000, loss: 0.256121
   Number of active neurons: 3
 >> iter 91000, loss: 0.203918
 >> iter 92000, loss: 0.178765
 >> iter 93000, loss: 0.156936
 >> iter 94000, loss: 0.383074
 >> iter 95000, loss: 0.392175
 >> iter 96000, loss: 0.511519
 >> iter 97000, loss: 0.341729
 >> iter 98000, loss: 0.207327
 >> iter 99000, loss: 0.263903
 >> iter 100000, loss: 0.204791
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.675668
 >> iter 2000, loss: 9.271446
 >> iter 3000, loss: 4.442558
 >> iter 4000, loss: 2.209890
 >> iter 5000, loss: 0.962906
 >> iter 6000, loss: 0.596658
 >> iter 7000, loss: 0.404896
 >> iter 8000, loss: 0.486192
 >> iter 9000, loss: 0.582499
 >> iter 10000, loss: 0.355771
   Number of active neurons: 6
 >> iter 11000, loss: 0.294821
 >> iter 12000, loss: 0.263008
 >> iter 13000, loss: 0.522607
 >> iter 14000, loss: 0.424695
 >> iter 15000, loss: 0.503246
 >> iter 16000, loss: 0.363355
 >> iter 17000, loss: 0.280414
 >> iter 18000, loss: 0.387034
 >> iter 19000, loss: 0.233761
 >> iter 20000, loss: 0.151864
   Number of active neurons: 4
 >> iter 21000, loss: 0.236491
 >> iter 22000, loss: 0.326535
 >> iter 23000, loss: 0.264226
 >> iter 24000, loss: 0.154793
 >> iter 25000, loss: 0.178372
 >> iter 26000, loss: 0.304461
 >> iter 27000, loss: 0.300313
 >> iter 28000, loss: 0.196100
 >> iter 29000, loss: 0.340502
 >> iter 30000, loss: 0.237526
   Number of active neurons: 4
 >> iter 31000, loss: 0.160952
 >> iter 32000, loss: 0.236730
 >> iter 33000, loss: 0.354754
 >> iter 34000, loss: 0.346651
 >> iter 35000, loss: 0.189808
 >> iter 36000, loss: 0.287316
 >> iter 37000, loss: 0.279309
 >> iter 38000, loss: 0.293756
 >> iter 39000, loss: 0.221733
 >> iter 40000, loss: 0.220523
   Number of active neurons: 4
 >> iter 41000, loss: 0.156505
 >> iter 42000, loss: 0.292787
 >> iter 43000, loss: 0.157467
 >> iter 44000, loss: 0.212669
 >> iter 45000, loss: 0.275614
 >> iter 46000, loss: 0.186447
 >> iter 47000, loss: 0.174409
 >> iter 48000, loss: 0.329449
 >> iter 49000, loss: 0.235280
 >> iter 50000, loss: 0.194081
   Number of active neurons: 4
 >> iter 51000, loss: 0.186481
 >> iter 52000, loss: 0.159400
 >> iter 53000, loss: 0.102295
 >> iter 54000, loss: 0.423092
 >> iter 55000, loss: 0.471444
 >> iter 56000, loss: 0.249170
 >> iter 57000, loss: 0.329603
 >> iter 58000, loss: 0.363649
 >> iter 59000, loss: 0.331329
 >> iter 60000, loss: 0.166985
   Number of active neurons: 4
 >> iter 61000, loss: 0.119003
 >> iter 62000, loss: 0.299796
 >> iter 63000, loss: 0.212868
 >> iter 64000, loss: 0.215948
 >> iter 65000, loss: 0.201112
 >> iter 66000, loss: 0.155470
 >> iter 67000, loss: 0.191203
 >> iter 68000, loss: 0.305557
 >> iter 69000, loss: 0.229547
 >> iter 70000, loss: 0.420451
   Number of active neurons: 4
 >> iter 71000, loss: 0.242711
 >> iter 72000, loss: 0.181569
 >> iter 73000, loss: 0.123749
 >> iter 74000, loss: 0.190477
 >> iter 75000, loss: 0.215412
 >> iter 76000, loss: 0.227189
 >> iter 77000, loss: 0.173578
 >> iter 78000, loss: 0.200615
 >> iter 79000, loss: 0.234908
 >> iter 80000, loss: 0.327127
   Number of active neurons: 4
 >> iter 81000, loss: 0.297007
 >> iter 82000, loss: 0.250800
 >> iter 83000, loss: 0.286603
 >> iter 84000, loss: 0.239953
 >> iter 85000, loss: 0.270753
 >> iter 86000, loss: 0.222265
 >> iter 87000, loss: 0.269569
 >> iter 88000, loss: 0.352232
 >> iter 89000, loss: 0.333467
 >> iter 90000, loss: 0.351606
   Number of active neurons: 4
 >> iter 91000, loss: 0.275615
 >> iter 92000, loss: 0.260842
 >> iter 93000, loss: 0.457456
 >> iter 94000, loss: 0.330762
 >> iter 95000, loss: 0.195559
 >> iter 96000, loss: 0.241008
 >> iter 97000, loss: 0.152287
 >> iter 98000, loss: 0.191923
 >> iter 99000, loss: 0.142783
 >> iter 100000, loss: 0.126996
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.305063
 >> iter 2000, loss: 9.908934
 >> iter 3000, loss: 4.463466
 >> iter 4000, loss: 2.254154
 >> iter 5000, loss: 1.412349
 >> iter 6000, loss: 0.704981
 >> iter 7000, loss: 0.732590
 >> iter 8000, loss: 0.533153
 >> iter 9000, loss: 0.312125
 >> iter 10000, loss: 0.313980
   Number of active neurons: 7
 >> iter 11000, loss: 0.284828
 >> iter 12000, loss: 0.285367
 >> iter 13000, loss: 0.267344
 >> iter 14000, loss: 0.257854
 >> iter 15000, loss: 0.470592
 >> iter 16000, loss: 0.527752
 >> iter 17000, loss: 0.307065
 >> iter 18000, loss: 0.273888
 >> iter 19000, loss: 0.265679
 >> iter 20000, loss: 0.328648
   Number of active neurons: 6
 >> iter 21000, loss: 0.335635
 >> iter 22000, loss: 0.297282
 >> iter 23000, loss: 0.233843
 >> iter 24000, loss: 0.397139
 >> iter 25000, loss: 0.261192
 >> iter 26000, loss: 0.176504
 >> iter 27000, loss: 0.184057
 >> iter 28000, loss: 0.150874
 >> iter 29000, loss: 0.247280
 >> iter 30000, loss: 0.230218
   Number of active neurons: 5
 >> iter 31000, loss: 0.312036
 >> iter 32000, loss: 0.265594
 >> iter 33000, loss: 0.286539
 >> iter 34000, loss: 0.239851
 >> iter 35000, loss: 0.202719
 >> iter 36000, loss: 0.284569
 >> iter 37000, loss: 0.331420
 >> iter 38000, loss: 0.231606
 >> iter 39000, loss: 0.186804
 >> iter 40000, loss: 0.244135
   Number of active neurons: 4
 >> iter 41000, loss: 0.289868
 >> iter 42000, loss: 0.286596
 >> iter 43000, loss: 0.312770
 >> iter 44000, loss: 0.223322
 >> iter 45000, loss: 0.297037
 >> iter 46000, loss: 0.342937
 >> iter 47000, loss: 0.309489
 >> iter 48000, loss: 0.323219
 >> iter 49000, loss: 0.208050
 >> iter 50000, loss: 0.158070
   Number of active neurons: 4
 >> iter 51000, loss: 0.149041
 >> iter 52000, loss: 0.303831
 >> iter 53000, loss: 0.239219
 >> iter 54000, loss: 0.218338
 >> iter 55000, loss: 0.185690
 >> iter 56000, loss: 0.099662
 >> iter 57000, loss: 0.113617
 >> iter 58000, loss: 0.215000
 >> iter 59000, loss: 0.202637
 >> iter 60000, loss: 0.251295
   Number of active neurons: 4
 >> iter 61000, loss: 0.318816
 >> iter 62000, loss: 0.331214
 >> iter 63000, loss: 0.217906
 >> iter 64000, loss: 0.146985
 >> iter 65000, loss: 0.384282
 >> iter 66000, loss: 0.218778
 >> iter 67000, loss: 0.165474
 >> iter 68000, loss: 0.202108
 >> iter 69000, loss: 0.340346
 >> iter 70000, loss: 0.204179
   Number of active neurons: 4
 >> iter 71000, loss: 0.220727
 >> iter 72000, loss: 0.114864
 >> iter 73000, loss: 0.259991
 >> iter 74000, loss: 0.167105
 >> iter 75000, loss: 0.152752
 >> iter 76000, loss: 0.092342
 >> iter 77000, loss: 0.413966
 >> iter 78000, loss: 0.527231
 >> iter 79000, loss: 0.295366
 >> iter 80000, loss: 0.248910
   Number of active neurons: 4
 >> iter 81000, loss: 0.253045
 >> iter 82000, loss: 0.258532
 >> iter 83000, loss: 0.309011
 >> iter 84000, loss: 0.238514
 >> iter 85000, loss: 0.184883
 >> iter 86000, loss: 0.224761
 >> iter 87000, loss: 0.245309
 >> iter 88000, loss: 0.235438
 >> iter 89000, loss: 0.253654
 >> iter 90000, loss: 0.368582
   Number of active neurons: 4
 >> iter 91000, loss: 0.261079
 >> iter 92000, loss: 0.375645
 >> iter 93000, loss: 0.288165
 >> iter 94000, loss: 0.180385
 >> iter 95000, loss: 0.163653
 >> iter 96000, loss: 0.103596
 >> iter 97000, loss: 0.331860
 >> iter 98000, loss: 0.303265
 >> iter 99000, loss: 0.291744
 >> iter 100000, loss: 0.344591
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.794635
 >> iter 2000, loss: 10.163800
 >> iter 3000, loss: 4.729968
 >> iter 4000, loss: 2.331803
 >> iter 5000, loss: 1.397397
 >> iter 6000, loss: 0.866493
 >> iter 7000, loss: 0.619893
 >> iter 8000, loss: 0.519868
 >> iter 9000, loss: 0.476322
 >> iter 10000, loss: 0.306057
   Number of active neurons: 5
 >> iter 11000, loss: 0.269325
 >> iter 12000, loss: 0.299457
 >> iter 13000, loss: 0.270177
 >> iter 14000, loss: 0.311194
 >> iter 15000, loss: 0.376023
 >> iter 16000, loss: 0.297230
 >> iter 17000, loss: 0.291069
 >> iter 18000, loss: 0.490048
 >> iter 19000, loss: 0.312001
 >> iter 20000, loss: 0.440600
   Number of active neurons: 5
 >> iter 21000, loss: 0.281162
 >> iter 22000, loss: 0.375751
 >> iter 23000, loss: 0.446110
 >> iter 24000, loss: 0.438136
 >> iter 25000, loss: 0.414415
 >> iter 26000, loss: 0.354284
 >> iter 27000, loss: 0.237910
 >> iter 28000, loss: 0.357102
 >> iter 29000, loss: 0.299157
 >> iter 30000, loss: 0.398812
   Number of active neurons: 4
 >> iter 31000, loss: 0.325716
 >> iter 32000, loss: 0.558456
 >> iter 33000, loss: 0.325998
 >> iter 34000, loss: 0.415144
 >> iter 35000, loss: 0.474804
 >> iter 36000, loss: 0.292173
 >> iter 37000, loss: 0.167829
 >> iter 38000, loss: 0.166136
 >> iter 39000, loss: 0.227130
 >> iter 40000, loss: 0.278971
   Number of active neurons: 3
 >> iter 41000, loss: 0.259280
 >> iter 42000, loss: 0.159409
 >> iter 43000, loss: 0.154691
 >> iter 44000, loss: 0.364081
 >> iter 45000, loss: 0.350420
 >> iter 46000, loss: 0.231662
 >> iter 47000, loss: 0.379845
 >> iter 48000, loss: 0.332856
 >> iter 49000, loss: 0.253908
 >> iter 50000, loss: 0.225094
   Number of active neurons: 3
 >> iter 51000, loss: 0.224525
 >> iter 52000, loss: 0.201459
 >> iter 53000, loss: 0.387445
 >> iter 54000, loss: 0.587550
 >> iter 55000, loss: 0.475151
 >> iter 56000, loss: 0.378080
 >> iter 57000, loss: 0.379941
 >> iter 58000, loss: 0.313967
 >> iter 59000, loss: 0.264248
 >> iter 60000, loss: 0.256659
   Number of active neurons: 3
 >> iter 61000, loss: 0.152879
 >> iter 62000, loss: 0.241516
 >> iter 63000, loss: 0.210795
 >> iter 64000, loss: 0.185707
 >> iter 65000, loss: 0.102210
 >> iter 66000, loss: 0.123363
 >> iter 67000, loss: 0.366750
 >> iter 68000, loss: 0.376504
 >> iter 69000, loss: 0.327992
 >> iter 70000, loss: 0.279186
   Number of active neurons: 3
 >> iter 71000, loss: 0.247139
 >> iter 72000, loss: 0.261824
 >> iter 73000, loss: 0.192770
 >> iter 74000, loss: 0.216409
 >> iter 75000, loss: 0.258233
 >> iter 76000, loss: 0.275304
 >> iter 77000, loss: 0.307595
 >> iter 78000, loss: 0.182954
 >> iter 79000, loss: 0.147956
 >> iter 80000, loss: 0.295472
   Number of active neurons: 3
 >> iter 81000, loss: 0.168816
 >> iter 82000, loss: 0.256369
 >> iter 83000, loss: 0.245803
 >> iter 84000, loss: 0.244961
 >> iter 85000, loss: 0.147881
 >> iter 86000, loss: 0.247513
 >> iter 87000, loss: 0.210029
 >> iter 88000, loss: 0.227139
 >> iter 89000, loss: 0.200139
 >> iter 90000, loss: 0.220003
   Number of active neurons: 3
 >> iter 91000, loss: 0.231325
 >> iter 92000, loss: 0.179324
 >> iter 93000, loss: 0.183607
 >> iter 94000, loss: 0.306351
 >> iter 95000, loss: 0.225997
 >> iter 96000, loss: 0.287422
 >> iter 97000, loss: 0.422512
 >> iter 98000, loss: 0.239240
 >> iter 99000, loss: 0.184705
 >> iter 100000, loss: 0.361481
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

