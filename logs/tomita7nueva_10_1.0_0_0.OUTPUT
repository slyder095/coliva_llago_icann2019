 > Problema: tomita7nueva
 > Args:
   - Hidden size: 10
   - Noise level: 1.0
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.045279
 >> iter 2000, loss: 10.577593
 >> iter 3000, loss: 7.675292
 >> iter 4000, loss: 6.071771
 >> iter 5000, loss: 4.210841
 >> iter 6000, loss: 2.559235
 >> iter 7000, loss: 1.517953
 >> iter 8000, loss: 0.937708
 >> iter 9000, loss: 0.691636
 >> iter 10000, loss: 0.508007
   Number of active neurons: 10
 >> iter 11000, loss: 0.477891
 >> iter 12000, loss: 0.263263
 >> iter 13000, loss: 0.297135
 >> iter 14000, loss: 0.280286
 >> iter 15000, loss: 0.285095
 >> iter 16000, loss: 0.241311
 >> iter 17000, loss: 0.134144
 >> iter 18000, loss: 0.168620
 >> iter 19000, loss: 0.299144
 >> iter 20000, loss: 0.237243
   Number of active neurons: 10
 >> iter 21000, loss: 0.141823
 >> iter 22000, loss: 0.130545
 >> iter 23000, loss: 0.184921
 >> iter 24000, loss: 0.189816
 >> iter 25000, loss: 0.136361
 >> iter 26000, loss: 0.238660
 >> iter 27000, loss: 0.108809
 >> iter 28000, loss: 0.138695
 >> iter 29000, loss: 0.155343
 >> iter 30000, loss: 0.108048
   Number of active neurons: 10
 >> iter 31000, loss: 0.075770
 >> iter 32000, loss: 0.105635
 >> iter 33000, loss: 0.157337
 >> iter 34000, loss: 0.197123
 >> iter 35000, loss: 0.201060
 >> iter 36000, loss: 0.085988
 >> iter 37000, loss: 0.064498
 >> iter 38000, loss: 0.074317
 >> iter 39000, loss: 0.140373
 >> iter 40000, loss: 0.143472
   Number of active neurons: 10
 >> iter 41000, loss: 0.179121
 >> iter 42000, loss: 0.090020
 >> iter 43000, loss: 0.074910
 >> iter 44000, loss: 0.057427
 >> iter 45000, loss: 0.145938
 >> iter 46000, loss: 0.159576
 >> iter 47000, loss: 0.075476
 >> iter 48000, loss: 0.047917
 >> iter 49000, loss: 0.043707
 >> iter 50000, loss: 0.057387
   Number of active neurons: 10
 >> iter 51000, loss: 0.103863
 >> iter 52000, loss: 0.081342
 >> iter 53000, loss: 0.103758
 >> iter 54000, loss: 0.082565
 >> iter 55000, loss: 0.100488
 >> iter 56000, loss: 0.132579
 >> iter 57000, loss: 0.241028
 >> iter 58000, loss: 0.113887
 >> iter 59000, loss: 0.081449
 >> iter 60000, loss: 0.036707
   Number of active neurons: 10
 >> iter 61000, loss: 0.043389
 >> iter 62000, loss: 0.067763
 >> iter 63000, loss: 0.204765
 >> iter 64000, loss: 0.164865
 >> iter 65000, loss: 0.146313
 >> iter 66000, loss: 0.083723
 >> iter 67000, loss: 0.059486
 >> iter 68000, loss: 0.036614
 >> iter 69000, loss: 0.048632
 >> iter 70000, loss: 0.039776
   Number of active neurons: 10
 >> iter 71000, loss: 0.019819
 >> iter 72000, loss: 0.012108
 >> iter 73000, loss: 0.010556
 >> iter 74000, loss: 0.069427
 >> iter 75000, loss: 0.042220
 >> iter 76000, loss: 0.019494
 >> iter 77000, loss: 0.050617
 >> iter 78000, loss: 0.076703
 >> iter 79000, loss: 0.083704
 >> iter 80000, loss: 0.043069
   Number of active neurons: 10
 >> iter 81000, loss: 0.041178
 >> iter 82000, loss: 0.042666
 >> iter 83000, loss: 0.033130
 >> iter 84000, loss: 0.037072
 >> iter 85000, loss: 0.062096
 >> iter 86000, loss: 0.062313
 >> iter 87000, loss: 0.044412
 >> iter 88000, loss: 0.023631
 >> iter 89000, loss: 0.061740
 >> iter 90000, loss: 0.103481
   Number of active neurons: 10
 >> iter 91000, loss: 0.043620
 >> iter 92000, loss: 0.020711
 >> iter 93000, loss: 0.011105
 >> iter 94000, loss: 0.009737
 >> iter 95000, loss: 0.020155
 >> iter 96000, loss: 0.031283
 >> iter 97000, loss: 0.040878
 >> iter 98000, loss: 0.039680
 >> iter 99000, loss: 0.036498
 >> iter 100000, loss: 0.017889
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 18.109712
 >> iter 2000, loss: 10.707289
 >> iter 3000, loss: 7.760326
 >> iter 4000, loss: 5.338688
 >> iter 5000, loss: 3.633676
 >> iter 6000, loss: 2.311128
 >> iter 7000, loss: 1.336151
 >> iter 8000, loss: 0.914936
 >> iter 9000, loss: 0.700201
 >> iter 10000, loss: 0.540400
   Number of active neurons: 10
 >> iter 11000, loss: 0.389315
 >> iter 12000, loss: 0.451814
 >> iter 13000, loss: 0.535072
 >> iter 14000, loss: 0.312756
 >> iter 15000, loss: 0.258908
 >> iter 16000, loss: 0.197256
 >> iter 17000, loss: 0.194524
 >> iter 18000, loss: 0.156152
 >> iter 19000, loss: 0.311113
 >> iter 20000, loss: 0.168576
   Number of active neurons: 10
 >> iter 21000, loss: 0.170090
 >> iter 22000, loss: 0.192286
 >> iter 23000, loss: 0.201737
 >> iter 24000, loss: 0.125962
 >> iter 25000, loss: 0.162775
 >> iter 26000, loss: 0.120275
 >> iter 27000, loss: 0.199290
 >> iter 28000, loss: 0.241704
 >> iter 29000, loss: 0.177879
 >> iter 30000, loss: 0.114774
   Number of active neurons: 10
 >> iter 31000, loss: 0.134426
 >> iter 32000, loss: 0.100598
 >> iter 33000, loss: 0.168736
 >> iter 34000, loss: 0.175754
 >> iter 35000, loss: 0.113726
 >> iter 36000, loss: 0.131938
 >> iter 37000, loss: 0.079609
 >> iter 38000, loss: 0.120923
 >> iter 39000, loss: 0.100317
 >> iter 40000, loss: 0.058760
   Number of active neurons: 10
 >> iter 41000, loss: 0.129040
 >> iter 42000, loss: 0.130684
 >> iter 43000, loss: 0.095215
 >> iter 44000, loss: 0.091172
 >> iter 45000, loss: 0.091389
 >> iter 46000, loss: 0.095310
 >> iter 47000, loss: 0.055330
 >> iter 48000, loss: 0.030333
 >> iter 49000, loss: 0.018417
 >> iter 50000, loss: 0.039994
   Number of active neurons: 10
 >> iter 51000, loss: 0.082149
 >> iter 52000, loss: 0.046555
 >> iter 53000, loss: 0.081413
 >> iter 54000, loss: 0.056965
 >> iter 55000, loss: 0.089395
 >> iter 56000, loss: 0.104375
 >> iter 57000, loss: 0.056335
 >> iter 58000, loss: 0.086100
 >> iter 59000, loss: 0.056889
 >> iter 60000, loss: 0.056517
   Number of active neurons: 10
 >> iter 61000, loss: 0.083706
 >> iter 62000, loss: 0.076125
 >> iter 63000, loss: 0.096915
 >> iter 64000, loss: 0.124725
 >> iter 65000, loss: 0.090741
 >> iter 66000, loss: 0.092679
 >> iter 67000, loss: 0.184603
 >> iter 68000, loss: 0.113863
 >> iter 69000, loss: 0.082079
 >> iter 70000, loss: 0.136061
   Number of active neurons: 10
 >> iter 71000, loss: 0.104501
 >> iter 72000, loss: 0.047405
 >> iter 73000, loss: 0.093059
 >> iter 74000, loss: 0.054202
 >> iter 75000, loss: 0.083277
 >> iter 76000, loss: 0.116031
 >> iter 77000, loss: 0.090825
 >> iter 78000, loss: 0.043751
 >> iter 79000, loss: 0.047767
 >> iter 80000, loss: 0.070540
   Number of active neurons: 10
 >> iter 81000, loss: 0.047577
 >> iter 82000, loss: 0.023442
 >> iter 83000, loss: 0.048869
 >> iter 84000, loss: 0.027256
 >> iter 85000, loss: 0.014166
 >> iter 86000, loss: 0.008250
 >> iter 87000, loss: 0.008547
 >> iter 88000, loss: 0.011679
 >> iter 89000, loss: 0.006878
 >> iter 90000, loss: 0.031929
   Number of active neurons: 10
 >> iter 91000, loss: 0.054822
 >> iter 92000, loss: 0.023104
 >> iter 93000, loss: 0.010583
 >> iter 94000, loss: 0.005697
 >> iter 95000, loss: 0.055701
 >> iter 96000, loss: 0.079414
 >> iter 97000, loss: 0.071303
 >> iter 98000, loss: 0.066805
 >> iter 99000, loss: 0.063407
 >> iter 100000, loss: 0.042360
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.132872
 >> iter 2000, loss: 10.352874
 >> iter 3000, loss: 7.672312
 >> iter 4000, loss: 6.230698
 >> iter 5000, loss: 5.179128
 >> iter 6000, loss: 3.873214
 >> iter 7000, loss: 2.759830
 >> iter 8000, loss: 1.802699
 >> iter 9000, loss: 1.178649
 >> iter 10000, loss: 0.827310
   Number of active neurons: 10
 >> iter 11000, loss: 0.689320
 >> iter 12000, loss: 0.551424
 >> iter 13000, loss: 0.423803
 >> iter 14000, loss: 0.349854
 >> iter 15000, loss: 0.349358
 >> iter 16000, loss: 0.344721
 >> iter 17000, loss: 0.277926
 >> iter 18000, loss: 0.246163
 >> iter 19000, loss: 0.277562
 >> iter 20000, loss: 0.278042
   Number of active neurons: 10
 >> iter 21000, loss: 0.206741
 >> iter 22000, loss: 0.170475
 >> iter 23000, loss: 0.190332
 >> iter 24000, loss: 0.217135
 >> iter 25000, loss: 0.155224
 >> iter 26000, loss: 0.162921
 >> iter 27000, loss: 0.153694
 >> iter 28000, loss: 0.090610
 >> iter 29000, loss: 0.108331
 >> iter 30000, loss: 0.130117
   Number of active neurons: 10
 >> iter 31000, loss: 0.176290
 >> iter 32000, loss: 0.156830
 >> iter 33000, loss: 0.133312
 >> iter 34000, loss: 0.119011
 >> iter 35000, loss: 0.128782
 >> iter 36000, loss: 0.122157
 >> iter 37000, loss: 0.075144
 >> iter 38000, loss: 0.091033
 >> iter 39000, loss: 0.071355
 >> iter 40000, loss: 0.058942
   Number of active neurons: 10
 >> iter 41000, loss: 0.065999
 >> iter 42000, loss: 0.078328
 >> iter 43000, loss: 0.098349
 >> iter 44000, loss: 0.112541
 >> iter 45000, loss: 0.087023
 >> iter 46000, loss: 0.053568
 >> iter 47000, loss: 0.067048
 >> iter 48000, loss: 0.112988
 >> iter 49000, loss: 0.135828
 >> iter 50000, loss: 0.136585
   Number of active neurons: 10
 >> iter 51000, loss: 0.135674
 >> iter 52000, loss: 0.074101
 >> iter 53000, loss: 0.037673
 >> iter 54000, loss: 0.068330
 >> iter 55000, loss: 0.029809
 >> iter 56000, loss: 0.142033
 >> iter 57000, loss: 0.107060
 >> iter 58000, loss: 0.054980
 >> iter 59000, loss: 0.050945
 >> iter 60000, loss: 0.080612
   Number of active neurons: 10
 >> iter 61000, loss: 0.107337
 >> iter 62000, loss: 0.075136
 >> iter 63000, loss: 0.068130
 >> iter 64000, loss: 0.058738
 >> iter 65000, loss: 0.040930
 >> iter 66000, loss: 0.036029
 >> iter 67000, loss: 0.054063
 >> iter 68000, loss: 0.051448
 >> iter 69000, loss: 0.022177
 >> iter 70000, loss: 0.063708
   Number of active neurons: 10
 >> iter 71000, loss: 0.035508
 >> iter 72000, loss: 0.037410
 >> iter 73000, loss: 0.041752
 >> iter 74000, loss: 0.058131
 >> iter 75000, loss: 0.024882
 >> iter 76000, loss: 0.011908
 >> iter 77000, loss: 0.066669
 >> iter 78000, loss: 0.027620
 >> iter 79000, loss: 0.036339
 >> iter 80000, loss: 0.063716
   Number of active neurons: 10
 >> iter 81000, loss: 0.077901
 >> iter 82000, loss: 0.066469
 >> iter 83000, loss: 0.063240
 >> iter 84000, loss: 0.053142
 >> iter 85000, loss: 0.044486
 >> iter 86000, loss: 0.028682
 >> iter 87000, loss: 0.047540
 >> iter 88000, loss: 0.026241
 >> iter 89000, loss: 0.038853
 >> iter 90000, loss: 0.017534
   Number of active neurons: 10
 >> iter 91000, loss: 0.012455
 >> iter 92000, loss: 0.024635
 >> iter 93000, loss: 0.076301
 >> iter 94000, loss: 0.089149
 >> iter 95000, loss: 0.067259
 >> iter 96000, loss: 0.043349
 >> iter 97000, loss: 0.019218
 >> iter 98000, loss: 0.009834
 >> iter 99000, loss: 0.037637
 >> iter 100000, loss: 0.030924
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 17.111176
 >> iter 2000, loss: 10.500865
 >> iter 3000, loss: 7.733795
 >> iter 4000, loss: 6.214300
 >> iter 5000, loss: 5.383193
 >> iter 6000, loss: 4.309171
 >> iter 7000, loss: 3.194878
 >> iter 8000, loss: 2.072030
 >> iter 9000, loss: 1.569949
 >> iter 10000, loss: 1.076573
   Number of active neurons: 10
 >> iter 11000, loss: 0.859035
 >> iter 12000, loss: 0.580161
 >> iter 13000, loss: 0.500036
 >> iter 14000, loss: 0.492761
 >> iter 15000, loss: 0.350800
 >> iter 16000, loss: 0.386276
 >> iter 17000, loss: 0.286230
 >> iter 18000, loss: 0.241463
 >> iter 19000, loss: 0.153324
 >> iter 20000, loss: 0.100981
   Number of active neurons: 10
 >> iter 21000, loss: 0.240687
 >> iter 22000, loss: 0.238612
 >> iter 23000, loss: 0.216482
 >> iter 24000, loss: 0.196282
 >> iter 25000, loss: 0.134370
 >> iter 26000, loss: 0.098659
 >> iter 27000, loss: 0.137690
 >> iter 28000, loss: 0.138860
 >> iter 29000, loss: 0.157649
 >> iter 30000, loss: 0.099867
   Number of active neurons: 10
 >> iter 31000, loss: 0.088805
 >> iter 32000, loss: 0.058621
 >> iter 33000, loss: 0.132448
 >> iter 34000, loss: 0.131898
 >> iter 35000, loss: 0.142052
 >> iter 36000, loss: 0.120932
 >> iter 37000, loss: 0.178009
 >> iter 38000, loss: 0.118224
 >> iter 39000, loss: 0.077801
 >> iter 40000, loss: 0.131596
   Number of active neurons: 10
 >> iter 41000, loss: 0.059526
 >> iter 42000, loss: 0.067175
 >> iter 43000, loss: 0.064278
 >> iter 44000, loss: 0.040864
 >> iter 45000, loss: 0.062853
 >> iter 46000, loss: 0.046819
 >> iter 47000, loss: 0.049768
 >> iter 48000, loss: 0.062380
 >> iter 49000, loss: 0.043240
 >> iter 50000, loss: 0.019942
   Number of active neurons: 10
 >> iter 51000, loss: 0.078854
 >> iter 52000, loss: 0.061473
 >> iter 53000, loss: 0.055144
 >> iter 54000, loss: 0.043065
 >> iter 55000, loss: 0.058458
 >> iter 56000, loss: 0.113485
 >> iter 57000, loss: 0.067640
 >> iter 58000, loss: 0.034199
 >> iter 59000, loss: 0.084731
 >> iter 60000, loss: 0.046904
   Number of active neurons: 10
 >> iter 61000, loss: 0.051074
 >> iter 62000, loss: 0.053203
 >> iter 63000, loss: 0.068712
 >> iter 64000, loss: 0.051680
 >> iter 65000, loss: 0.022918
 >> iter 66000, loss: 0.011555
 >> iter 67000, loss: 0.019170
 >> iter 68000, loss: 0.011127
 >> iter 69000, loss: 0.085344
 >> iter 70000, loss: 0.063723
   Number of active neurons: 10
 >> iter 71000, loss: 0.059705
 >> iter 72000, loss: 0.068956
 >> iter 73000, loss: 0.035250
 >> iter 74000, loss: 0.057485
 >> iter 75000, loss: 0.024691
 >> iter 76000, loss: 0.075457
 >> iter 77000, loss: 0.030786
 >> iter 78000, loss: 0.048254
 >> iter 79000, loss: 0.052068
 >> iter 80000, loss: 0.059103
   Number of active neurons: 10
 >> iter 81000, loss: 0.056468
 >> iter 82000, loss: 0.087465
 >> iter 83000, loss: 0.036481
 >> iter 84000, loss: 0.016853
 >> iter 85000, loss: 0.035444
 >> iter 86000, loss: 0.053707
 >> iter 87000, loss: 0.022715
 >> iter 88000, loss: 0.011234
 >> iter 89000, loss: 0.020858
 >> iter 90000, loss: 0.058297
   Number of active neurons: 10
 >> iter 91000, loss: 0.033249
 >> iter 92000, loss: 0.014430
 >> iter 93000, loss: 0.034799
 >> iter 94000, loss: 0.068007
 >> iter 95000, loss: 0.031271
 >> iter 96000, loss: 0.021790
 >> iter 97000, loss: 0.010464
 >> iter 98000, loss: 0.009111
 >> iter 99000, loss: 0.007443
 >> iter 100000, loss: 0.046679
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455157
   Number of active neurons: 0
 >> iter 1000, loss: 16.742601
 >> iter 2000, loss: 10.310939
 >> iter 3000, loss: 7.574636
 >> iter 4000, loss: 5.878081
 >> iter 5000, loss: 4.939923
 >> iter 6000, loss: 3.511108
 >> iter 7000, loss: 2.140366
 >> iter 8000, loss: 1.332811
 >> iter 9000, loss: 0.877131
 >> iter 10000, loss: 0.682269
   Number of active neurons: 10
 >> iter 11000, loss: 0.467371
 >> iter 12000, loss: 0.391053
 >> iter 13000, loss: 0.245605
 >> iter 14000, loss: 0.221155
 >> iter 15000, loss: 0.318353
 >> iter 16000, loss: 0.230323
 >> iter 17000, loss: 0.129549
 >> iter 18000, loss: 0.091964
 >> iter 19000, loss: 0.083479
 >> iter 20000, loss: 0.163292
   Number of active neurons: 10
 >> iter 21000, loss: 0.167718
 >> iter 22000, loss: 0.098894
 >> iter 23000, loss: 0.057737
 >> iter 24000, loss: 0.098168
 >> iter 25000, loss: 0.093402
 >> iter 26000, loss: 0.089615
 >> iter 27000, loss: 0.130693
 >> iter 28000, loss: 0.090949
 >> iter 29000, loss: 0.076330
 >> iter 30000, loss: 0.086702
   Number of active neurons: 10
 >> iter 31000, loss: 0.152106
 >> iter 32000, loss: 0.118615
 >> iter 33000, loss: 0.084299
 >> iter 34000, loss: 0.041350
 >> iter 35000, loss: 0.146979
 >> iter 36000, loss: 0.293825
 >> iter 37000, loss: 0.144414
 >> iter 38000, loss: 0.196898
 >> iter 39000, loss: 0.198667
 >> iter 40000, loss: 0.173538
   Number of active neurons: 10
 >> iter 41000, loss: 0.111349
 >> iter 42000, loss: 0.077647
 >> iter 43000, loss: 0.067265
 >> iter 44000, loss: 0.044733
 >> iter 45000, loss: 0.042221
 >> iter 46000, loss: 0.024367
 >> iter 47000, loss: 0.033040
 >> iter 48000, loss: 0.145122
 >> iter 49000, loss: 0.059112
 >> iter 50000, loss: 0.082135
   Number of active neurons: 10
 >> iter 51000, loss: 0.082879
 >> iter 52000, loss: 0.035511
 >> iter 53000, loss: 0.017761
 >> iter 54000, loss: 0.029141
 >> iter 55000, loss: 0.026955
 >> iter 56000, loss: 0.013929
 >> iter 57000, loss: 0.008793
 >> iter 58000, loss: 0.008278
 >> iter 59000, loss: 0.005828
 >> iter 60000, loss: 0.041109
   Number of active neurons: 10
 >> iter 61000, loss: 0.062048
 >> iter 62000, loss: 0.035177
 >> iter 63000, loss: 0.081556
 >> iter 64000, loss: 0.033890
 >> iter 65000, loss: 0.015378
 >> iter 66000, loss: 0.070243
 >> iter 67000, loss: 0.072989
 >> iter 68000, loss: 0.048686
 >> iter 69000, loss: 0.021253
 >> iter 70000, loss: 0.011187
   Number of active neurons: 10
 >> iter 71000, loss: 0.007752
 >> iter 72000, loss: 0.005653
 >> iter 73000, loss: 0.023853
 >> iter 74000, loss: 0.026294
 >> iter 75000, loss: 0.013288
 >> iter 76000, loss: 0.015536
 >> iter 77000, loss: 0.064870
 >> iter 78000, loss: 0.027572
 >> iter 79000, loss: 0.038990
 >> iter 80000, loss: 0.021097
   Number of active neurons: 10
 >> iter 81000, loss: 0.010773
 >> iter 82000, loss: 0.057544
 >> iter 83000, loss: 0.078174
 >> iter 84000, loss: 0.031574
 >> iter 85000, loss: 0.053126
 >> iter 86000, loss: 0.039653
 >> iter 87000, loss: 0.043599
 >> iter 88000, loss: 0.077815
 >> iter 89000, loss: 0.046515
 >> iter 90000, loss: 0.019943
   Number of active neurons: 10
 >> iter 91000, loss: 0.051858
 >> iter 92000, loss: 0.022225
 >> iter 93000, loss: 0.011127
 >> iter 94000, loss: 0.006473
 >> iter 95000, loss: 0.005616
 >> iter 96000, loss: 0.003914
 >> iter 97000, loss: 0.003224
 >> iter 98000, loss: 0.004201
 >> iter 99000, loss: 0.003466
 >> iter 100000, loss: 0.014003
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.099679
 >> iter 2000, loss: 10.264125
 >> iter 3000, loss: 7.461221
 >> iter 4000, loss: 6.112761
 >> iter 5000, loss: 5.195612
 >> iter 6000, loss: 4.147353
 >> iter 7000, loss: 3.525717
 >> iter 8000, loss: 2.724436
 >> iter 9000, loss: 1.854536
 >> iter 10000, loss: 1.697863
   Number of active neurons: 10
 >> iter 11000, loss: 1.407068
 >> iter 12000, loss: 1.217032
 >> iter 13000, loss: 1.111369
 >> iter 14000, loss: 0.893858
 >> iter 15000, loss: 0.885862
 >> iter 16000, loss: 0.800381
 >> iter 17000, loss: 0.659296
 >> iter 18000, loss: 0.755101
 >> iter 19000, loss: 0.717979
 >> iter 20000, loss: 0.545792
   Number of active neurons: 10
 >> iter 21000, loss: 0.474344
 >> iter 22000, loss: 0.395858
 >> iter 23000, loss: 0.479195
 >> iter 24000, loss: 0.436357
 >> iter 25000, loss: 0.328656
 >> iter 26000, loss: 0.341943
 >> iter 27000, loss: 0.328391
 >> iter 28000, loss: 0.359436
 >> iter 29000, loss: 0.426698
 >> iter 30000, loss: 0.496091
   Number of active neurons: 10
 >> iter 31000, loss: 0.441176
 >> iter 32000, loss: 0.335435
 >> iter 33000, loss: 0.479954
 >> iter 34000, loss: 0.436462
 >> iter 35000, loss: 0.356897
 >> iter 36000, loss: 0.407298
 >> iter 37000, loss: 0.337523
 >> iter 38000, loss: 0.259371
 >> iter 39000, loss: 0.219995
 >> iter 40000, loss: 0.253357
   Number of active neurons: 10
 >> iter 41000, loss: 0.293224
 >> iter 42000, loss: 0.225881
 >> iter 43000, loss: 0.280453
 >> iter 44000, loss: 0.244164
 >> iter 45000, loss: 0.208933
 >> iter 46000, loss: 0.246113
 >> iter 47000, loss: 0.142071
 >> iter 48000, loss: 0.255450
 >> iter 49000, loss: 0.197031
 >> iter 50000, loss: 0.281683
   Number of active neurons: 10
 >> iter 51000, loss: 0.217558
 >> iter 52000, loss: 0.243565
 >> iter 53000, loss: 0.166511
 >> iter 54000, loss: 0.211004
 >> iter 55000, loss: 0.168749
 >> iter 56000, loss: 0.130882
 >> iter 57000, loss: 0.160903
 >> iter 58000, loss: 0.254033
 >> iter 59000, loss: 0.227635
 >> iter 60000, loss: 0.245295
   Number of active neurons: 10
 >> iter 61000, loss: 0.186829
 >> iter 62000, loss: 0.262674
 >> iter 63000, loss: 0.232825
 >> iter 64000, loss: 0.199385
 >> iter 65000, loss: 0.271148
 >> iter 66000, loss: 0.278627
 >> iter 67000, loss: 0.237193
 >> iter 68000, loss: 0.178230
 >> iter 69000, loss: 0.111859
 >> iter 70000, loss: 0.158565
   Number of active neurons: 10
 >> iter 71000, loss: 0.119019
 >> iter 72000, loss: 0.109231
 >> iter 73000, loss: 0.124777
 >> iter 74000, loss: 0.082564
 >> iter 75000, loss: 0.143073
 >> iter 76000, loss: 0.088471
 >> iter 77000, loss: 0.070980
 >> iter 78000, loss: 0.073874
 >> iter 79000, loss: 0.103626
 >> iter 80000, loss: 0.183839
   Number of active neurons: 10
 >> iter 81000, loss: 0.097443
 >> iter 82000, loss: 0.134137
 >> iter 83000, loss: 0.138794
 >> iter 84000, loss: 0.074752
 >> iter 85000, loss: 0.124434
 >> iter 86000, loss: 0.092997
 >> iter 87000, loss: 0.085831
 >> iter 88000, loss: 0.183786
 >> iter 89000, loss: 0.218838
 >> iter 90000, loss: 0.195735
   Number of active neurons: 10
 >> iter 91000, loss: 0.125511
 >> iter 92000, loss: 0.138668
 >> iter 93000, loss: 0.093704
 >> iter 94000, loss: 0.143794
 >> iter 95000, loss: 0.147919
 >> iter 96000, loss: 0.086547
 >> iter 97000, loss: 0.108125
 >> iter 98000, loss: 0.122988
 >> iter 99000, loss: 0.120286
 >> iter 100000, loss: 0.138133
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.038876
 >> iter 2000, loss: 10.336736
 >> iter 3000, loss: 7.571658
 >> iter 4000, loss: 6.146101
 >> iter 5000, loss: 5.285679
 >> iter 6000, loss: 4.529388
 >> iter 7000, loss: 4.235095
 >> iter 8000, loss: 3.494985
 >> iter 9000, loss: 3.058544
 >> iter 10000, loss: 2.506017
   Number of active neurons: 10
 >> iter 11000, loss: 2.178010
 >> iter 12000, loss: 2.098704
 >> iter 13000, loss: 1.990517
 >> iter 14000, loss: 1.641339
 >> iter 15000, loss: 1.498139
 >> iter 16000, loss: 1.134882
 >> iter 17000, loss: 1.027310
 >> iter 18000, loss: 0.799585
 >> iter 19000, loss: 0.720533
 >> iter 20000, loss: 0.915223
   Number of active neurons: 10
 >> iter 21000, loss: 0.741228
 >> iter 22000, loss: 0.586225
 >> iter 23000, loss: 0.664721
 >> iter 24000, loss: 0.644107
 >> iter 25000, loss: 0.565087
 >> iter 26000, loss: 0.746421
 >> iter 27000, loss: 0.707709
 >> iter 28000, loss: 0.507783
 >> iter 29000, loss: 0.670090
 >> iter 30000, loss: 0.624154
   Number of active neurons: 10
 >> iter 31000, loss: 0.570681
 >> iter 32000, loss: 0.414158
 >> iter 33000, loss: 0.412137
 >> iter 34000, loss: 0.349127
 >> iter 35000, loss: 0.279112
 >> iter 36000, loss: 0.807461
 >> iter 37000, loss: 0.681543
 >> iter 38000, loss: 0.634413
 >> iter 39000, loss: 0.424629
 >> iter 40000, loss: 0.433267
   Number of active neurons: 10
 >> iter 41000, loss: 0.309076
 >> iter 42000, loss: 0.350192
 >> iter 43000, loss: 0.290568
 >> iter 44000, loss: 0.315192
 >> iter 45000, loss: 0.281655
 >> iter 46000, loss: 0.343520
 >> iter 47000, loss: 0.275938
 >> iter 48000, loss: 0.258438
 >> iter 49000, loss: 0.262692
 >> iter 50000, loss: 0.198508
   Number of active neurons: 10
 >> iter 51000, loss: 0.158893
 >> iter 52000, loss: 0.330801
 >> iter 53000, loss: 0.274236
 >> iter 54000, loss: 0.180627
 >> iter 55000, loss: 0.126165
 >> iter 56000, loss: 0.086976
 >> iter 57000, loss: 0.092979
 >> iter 58000, loss: 0.117453
 >> iter 59000, loss: 0.108188
 >> iter 60000, loss: 0.218409
   Number of active neurons: 10
 >> iter 61000, loss: 0.151548
 >> iter 62000, loss: 0.248413
 >> iter 63000, loss: 0.127886
 >> iter 64000, loss: 0.121413
 >> iter 65000, loss: 0.094011
 >> iter 66000, loss: 0.401023
 >> iter 67000, loss: 0.267422
 >> iter 68000, loss: 0.210333
 >> iter 69000, loss: 0.203740
 >> iter 70000, loss: 0.178669
   Number of active neurons: 10
 >> iter 71000, loss: 0.255245
 >> iter 72000, loss: 0.301724
 >> iter 73000, loss: 0.221500
 >> iter 74000, loss: 0.213147
 >> iter 75000, loss: 0.130424
 >> iter 76000, loss: 0.102739
 >> iter 77000, loss: 0.194658
 >> iter 78000, loss: 0.099436
 >> iter 79000, loss: 0.222006
 >> iter 80000, loss: 0.211773
   Number of active neurons: 10
 >> iter 81000, loss: 0.143055
 >> iter 82000, loss: 0.091167
 >> iter 83000, loss: 0.210848
 >> iter 84000, loss: 0.213746
 >> iter 85000, loss: 0.180775
 >> iter 86000, loss: 0.240955
 >> iter 87000, loss: 0.217698
 >> iter 88000, loss: 0.145431
 >> iter 89000, loss: 0.151509
 >> iter 90000, loss: 0.136097
   Number of active neurons: 10
 >> iter 91000, loss: 0.162191
 >> iter 92000, loss: 0.129586
 >> iter 93000, loss: 0.123025
 >> iter 94000, loss: 0.253998
 >> iter 95000, loss: 0.158698
 >> iter 96000, loss: 0.076039
 >> iter 97000, loss: 0.088393
 >> iter 98000, loss: 0.092438
 >> iter 99000, loss: 0.142116
 >> iter 100000, loss: 0.181184
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.039849
 >> iter 2000, loss: 10.363769
 >> iter 3000, loss: 7.317399
 >> iter 4000, loss: 5.471057
 >> iter 5000, loss: 4.281104
 >> iter 6000, loss: 3.202248
 >> iter 7000, loss: 2.205122
 >> iter 8000, loss: 1.478398
 >> iter 9000, loss: 1.214584
 >> iter 10000, loss: 0.947349
   Number of active neurons: 10
 >> iter 11000, loss: 0.760801
 >> iter 12000, loss: 0.688751
 >> iter 13000, loss: 0.575674
 >> iter 14000, loss: 0.493831
 >> iter 15000, loss: 0.515047
 >> iter 16000, loss: 0.498770
 >> iter 17000, loss: 0.567850
 >> iter 18000, loss: 0.444353
 >> iter 19000, loss: 0.299893
 >> iter 20000, loss: 0.198885
   Number of active neurons: 10
 >> iter 21000, loss: 0.315025
 >> iter 22000, loss: 0.479457
 >> iter 23000, loss: 0.425269
 >> iter 24000, loss: 0.407183
 >> iter 25000, loss: 0.314461
 >> iter 26000, loss: 0.317262
 >> iter 27000, loss: 0.263273
 >> iter 28000, loss: 0.317700
 >> iter 29000, loss: 0.289729
 >> iter 30000, loss: 0.219087
   Number of active neurons: 10
 >> iter 31000, loss: 0.186881
 >> iter 32000, loss: 0.199113
 >> iter 33000, loss: 0.145216
 >> iter 34000, loss: 0.243674
 >> iter 35000, loss: 0.192137
 >> iter 36000, loss: 0.134591
 >> iter 37000, loss: 0.219611
 >> iter 38000, loss: 0.187363
 >> iter 39000, loss: 0.198799
 >> iter 40000, loss: 0.122804
   Number of active neurons: 10
 >> iter 41000, loss: 0.141513
 >> iter 42000, loss: 0.151825
 >> iter 43000, loss: 0.100993
 >> iter 44000, loss: 0.209604
 >> iter 45000, loss: 0.311445
 >> iter 46000, loss: 0.276143
 >> iter 47000, loss: 0.151318
 >> iter 48000, loss: 0.148581
 >> iter 49000, loss: 0.120055
 >> iter 50000, loss: 0.134257
   Number of active neurons: 10
 >> iter 51000, loss: 0.163387
 >> iter 52000, loss: 0.143146
 >> iter 53000, loss: 0.127464
 >> iter 54000, loss: 0.104456
 >> iter 55000, loss: 0.143664
 >> iter 56000, loss: 0.082815
 >> iter 57000, loss: 0.193469
 >> iter 58000, loss: 0.124857
 >> iter 59000, loss: 0.099926
 >> iter 60000, loss: 0.133477
   Number of active neurons: 10
 >> iter 61000, loss: 0.121317
 >> iter 62000, loss: 0.236790
 >> iter 63000, loss: 0.157335
 >> iter 64000, loss: 0.073812
 >> iter 65000, loss: 0.064513
 >> iter 66000, loss: 0.055469
 >> iter 67000, loss: 0.055976
 >> iter 68000, loss: 0.059991
 >> iter 69000, loss: 0.061336
 >> iter 70000, loss: 0.028196
   Number of active neurons: 10
 >> iter 71000, loss: 0.110674
 >> iter 72000, loss: 0.108046
 >> iter 73000, loss: 0.093677
 >> iter 74000, loss: 0.067379
 >> iter 75000, loss: 0.043193
 >> iter 76000, loss: 0.067157
 >> iter 77000, loss: 0.033023
 >> iter 78000, loss: 0.025213
 >> iter 79000, loss: 0.066158
 >> iter 80000, loss: 0.087249
   Number of active neurons: 10
 >> iter 81000, loss: 0.057038
 >> iter 82000, loss: 0.059073
 >> iter 83000, loss: 0.057394
 >> iter 84000, loss: 0.032112
 >> iter 85000, loss: 0.039540
 >> iter 86000, loss: 0.022351
 >> iter 87000, loss: 0.053167
 >> iter 88000, loss: 0.058824
 >> iter 89000, loss: 0.038553
 >> iter 90000, loss: 0.060522
   Number of active neurons: 10
 >> iter 91000, loss: 0.093205
 >> iter 92000, loss: 0.069312
 >> iter 93000, loss: 0.030999
 >> iter 94000, loss: 0.016232
 >> iter 95000, loss: 0.015373
 >> iter 96000, loss: 0.051008
 >> iter 97000, loss: 0.022537
 >> iter 98000, loss: 0.028404
 >> iter 99000, loss: 0.031349
 >> iter 100000, loss: 0.052330
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 16.907595
 >> iter 2000, loss: 10.095649
 >> iter 3000, loss: 6.099811
 >> iter 4000, loss: 3.680330
 >> iter 5000, loss: 2.275586
 >> iter 6000, loss: 1.498695
 >> iter 7000, loss: 0.894457
 >> iter 8000, loss: 0.758297
 >> iter 9000, loss: 0.573292
 >> iter 10000, loss: 0.384879
   Number of active neurons: 10
 >> iter 11000, loss: 0.461083
 >> iter 12000, loss: 0.431669
 >> iter 13000, loss: 0.322162
 >> iter 14000, loss: 0.342327
 >> iter 15000, loss: 0.406888
 >> iter 16000, loss: 0.263853
 >> iter 17000, loss: 0.258051
 >> iter 18000, loss: 0.236883
 >> iter 19000, loss: 0.184345
 >> iter 20000, loss: 0.153115
   Number of active neurons: 10
 >> iter 21000, loss: 0.127162
 >> iter 22000, loss: 0.099088
 >> iter 23000, loss: 0.135846
 >> iter 24000, loss: 0.123263
 >> iter 25000, loss: 0.066339
 >> iter 26000, loss: 0.063990
 >> iter 27000, loss: 0.119877
 >> iter 28000, loss: 0.076735
 >> iter 29000, loss: 0.053163
 >> iter 30000, loss: 0.073394
   Number of active neurons: 10
 >> iter 31000, loss: 0.141377
 >> iter 32000, loss: 0.063986
 >> iter 33000, loss: 0.099187
 >> iter 34000, loss: 0.054196
 >> iter 35000, loss: 0.038345
 >> iter 36000, loss: 0.075143
 >> iter 37000, loss: 0.103475
 >> iter 38000, loss: 0.094707
 >> iter 39000, loss: 0.097974
 >> iter 40000, loss: 0.085975
   Number of active neurons: 10
 >> iter 41000, loss: 0.082970
 >> iter 42000, loss: 0.052336
 >> iter 43000, loss: 0.058407
 >> iter 44000, loss: 0.037616
 >> iter 45000, loss: 0.034498
 >> iter 46000, loss: 0.060598
 >> iter 47000, loss: 0.055765
 >> iter 48000, loss: 0.025142
 >> iter 49000, loss: 0.035600
 >> iter 50000, loss: 0.082207
   Number of active neurons: 10
 >> iter 51000, loss: 0.042698
 >> iter 52000, loss: 0.028280
 >> iter 53000, loss: 0.021660
 >> iter 54000, loss: 0.071120
 >> iter 55000, loss: 0.030493
 >> iter 56000, loss: 0.057940
 >> iter 57000, loss: 0.106408
 >> iter 58000, loss: 0.061854
 >> iter 59000, loss: 0.049702
 >> iter 60000, loss: 0.023701
   Number of active neurons: 10
 >> iter 61000, loss: 0.024795
 >> iter 62000, loss: 0.079928
 >> iter 63000, loss: 0.055296
 >> iter 64000, loss: 0.042711
 >> iter 65000, loss: 0.051319
 >> iter 66000, loss: 0.066989
 >> iter 67000, loss: 0.046649
 >> iter 68000, loss: 0.021039
 >> iter 69000, loss: 0.037325
 >> iter 70000, loss: 0.017740
   Number of active neurons: 10
 >> iter 71000, loss: 0.010606
 >> iter 72000, loss: 0.007611
 >> iter 73000, loss: 0.006010
 >> iter 74000, loss: 0.060253
 >> iter 75000, loss: 0.040687
 >> iter 76000, loss: 0.018999
 >> iter 77000, loss: 0.025433
 >> iter 78000, loss: 0.034177
 >> iter 79000, loss: 0.058266
 >> iter 80000, loss: 0.037555
   Number of active neurons: 10
 >> iter 81000, loss: 0.022965
 >> iter 82000, loss: 0.091508
 >> iter 83000, loss: 0.037605
 >> iter 84000, loss: 0.027958
 >> iter 85000, loss: 0.014277
 >> iter 86000, loss: 0.018630
 >> iter 87000, loss: 0.011205
 >> iter 88000, loss: 0.006823
 >> iter 89000, loss: 0.004933
 >> iter 90000, loss: 0.004234
   Number of active neurons: 10
 >> iter 91000, loss: 0.005345
 >> iter 92000, loss: 0.026329
 >> iter 93000, loss: 0.035995
 >> iter 94000, loss: 0.069484
 >> iter 95000, loss: 0.036582
 >> iter 96000, loss: 0.015821
 >> iter 97000, loss: 0.051777
 >> iter 98000, loss: 0.025861
 >> iter 99000, loss: 0.064061
 >> iter 100000, loss: 0.028513
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.762300
 >> iter 2000, loss: 10.270084
 >> iter 3000, loss: 7.581071
 >> iter 4000, loss: 5.005946
 >> iter 5000, loss: 2.904041
 >> iter 6000, loss: 1.447419
 >> iter 7000, loss: 0.880428
 >> iter 8000, loss: 0.682718
 >> iter 9000, loss: 0.419034
 >> iter 10000, loss: 0.295672
   Number of active neurons: 10
 >> iter 11000, loss: 0.325084
 >> iter 12000, loss: 0.242670
 >> iter 13000, loss: 0.225123
 >> iter 14000, loss: 0.152167
 >> iter 15000, loss: 0.194590
 >> iter 16000, loss: 0.170053
 >> iter 17000, loss: 0.163293
 >> iter 18000, loss: 0.109870
 >> iter 19000, loss: 0.170164
 >> iter 20000, loss: 0.109395
   Number of active neurons: 10
 >> iter 21000, loss: 0.068044
 >> iter 22000, loss: 0.130761
 >> iter 23000, loss: 0.066862
 >> iter 24000, loss: 0.098122
 >> iter 25000, loss: 0.047068
 >> iter 26000, loss: 0.069605
 >> iter 27000, loss: 0.059757
 >> iter 28000, loss: 0.032788
 >> iter 29000, loss: 0.043695
 >> iter 30000, loss: 0.025281
   Number of active neurons: 10
 >> iter 31000, loss: 0.071743
 >> iter 32000, loss: 0.050974
 >> iter 33000, loss: 0.101423
 >> iter 34000, loss: 0.094708
 >> iter 35000, loss: 0.154580
 >> iter 36000, loss: 0.127106
 >> iter 37000, loss: 0.104187
 >> iter 38000, loss: 0.064525
 >> iter 39000, loss: 0.042687
 >> iter 40000, loss: 0.030373
   Number of active neurons: 10
 >> iter 41000, loss: 0.074935
 >> iter 42000, loss: 0.057880
 >> iter 43000, loss: 0.067735
 >> iter 44000, loss: 0.030924
 >> iter 45000, loss: 0.082906
 >> iter 46000, loss: 0.035994
 >> iter 47000, loss: 0.017242
 >> iter 48000, loss: 0.009326
 >> iter 49000, loss: 0.070515
 >> iter 50000, loss: 0.040053
   Number of active neurons: 10
 >> iter 51000, loss: 0.057927
 >> iter 52000, loss: 0.077145
 >> iter 53000, loss: 0.032907
 >> iter 54000, loss: 0.053212
 >> iter 55000, loss: 0.032114
 >> iter 56000, loss: 0.015934
 >> iter 57000, loss: 0.020175
 >> iter 58000, loss: 0.032237
 >> iter 59000, loss: 0.015731
 >> iter 60000, loss: 0.014921
   Number of active neurons: 10
 >> iter 61000, loss: 0.011275
 >> iter 62000, loss: 0.013328
 >> iter 63000, loss: 0.015224
 >> iter 64000, loss: 0.007935
 >> iter 65000, loss: 0.025759
 >> iter 66000, loss: 0.026612
 >> iter 67000, loss: 0.037142
 >> iter 68000, loss: 0.017755
 >> iter 69000, loss: 0.095987
 >> iter 70000, loss: 0.038738
   Number of active neurons: 10
 >> iter 71000, loss: 0.021041
 >> iter 72000, loss: 0.010243
 >> iter 73000, loss: 0.040525
 >> iter 74000, loss: 0.042977
 >> iter 75000, loss: 0.028030
 >> iter 76000, loss: 0.039975
 >> iter 77000, loss: 0.017925
 >> iter 78000, loss: 0.027399
 >> iter 79000, loss: 0.030567
 >> iter 80000, loss: 0.027659
   Number of active neurons: 10
 >> iter 81000, loss: 0.020162
 >> iter 82000, loss: 0.033651
 >> iter 83000, loss: 0.014736
 >> iter 84000, loss: 0.017405
 >> iter 85000, loss: 0.009813
 >> iter 86000, loss: 0.014306
 >> iter 87000, loss: 0.020519
 >> iter 88000, loss: 0.009745
 >> iter 89000, loss: 0.015684
 >> iter 90000, loss: 0.007652
   Number of active neurons: 10
 >> iter 91000, loss: 0.024113
 >> iter 92000, loss: 0.022745
 >> iter 93000, loss: 0.009925
 >> iter 94000, loss: 0.005658
 >> iter 95000, loss: 0.033644
 >> iter 96000, loss: 0.023541
 >> iter 97000, loss: 0.053670
 >> iter 98000, loss: 0.022294
 >> iter 99000, loss: 0.011113
 >> iter 100000, loss: 0.031390
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 17.163101
 >> iter 2000, loss: 10.475016
 >> iter 3000, loss: 7.805061
 >> iter 4000, loss: 6.360641
 >> iter 5000, loss: 4.902418
 >> iter 6000, loss: 3.265712
 >> iter 7000, loss: 1.944513
 >> iter 8000, loss: 1.363502
 >> iter 9000, loss: 0.898390
 >> iter 10000, loss: 0.608517
   Number of active neurons: 10
 >> iter 11000, loss: 0.393630
 >> iter 12000, loss: 0.427260
 >> iter 13000, loss: 0.408072
 >> iter 14000, loss: 0.370540
 >> iter 15000, loss: 0.373218
 >> iter 16000, loss: 0.298767
 >> iter 17000, loss: 0.285720
 >> iter 18000, loss: 0.194157
 >> iter 19000, loss: 0.224812
 >> iter 20000, loss: 0.186893
   Number of active neurons: 10
 >> iter 21000, loss: 0.254983
 >> iter 22000, loss: 0.203093
 >> iter 23000, loss: 0.192831
 >> iter 24000, loss: 0.237728
 >> iter 25000, loss: 0.156675
 >> iter 26000, loss: 0.172469
 >> iter 27000, loss: 0.139282
 >> iter 28000, loss: 0.106933
 >> iter 29000, loss: 0.120894
 >> iter 30000, loss: 0.128765
   Number of active neurons: 10
 >> iter 31000, loss: 0.174131
 >> iter 32000, loss: 0.091446
 >> iter 33000, loss: 0.247725
 >> iter 34000, loss: 0.125475
 >> iter 35000, loss: 0.135786
 >> iter 36000, loss: 0.169132
 >> iter 37000, loss: 0.092230
 >> iter 38000, loss: 0.063294
 >> iter 39000, loss: 0.074657
 >> iter 40000, loss: 0.055690
   Number of active neurons: 10
 >> iter 41000, loss: 0.114700
 >> iter 42000, loss: 0.071078
 >> iter 43000, loss: 0.051544
 >> iter 44000, loss: 0.038506
 >> iter 45000, loss: 0.117310
 >> iter 46000, loss: 0.084244
 >> iter 47000, loss: 0.101560
 >> iter 48000, loss: 0.062814
 >> iter 49000, loss: 0.106251
 >> iter 50000, loss: 0.052749
   Number of active neurons: 10
 >> iter 51000, loss: 0.024761
 >> iter 52000, loss: 0.085166
 >> iter 53000, loss: 0.080258
 >> iter 54000, loss: 0.064405
 >> iter 55000, loss: 0.080837
 >> iter 56000, loss: 0.046676
 >> iter 57000, loss: 0.028918
 >> iter 58000, loss: 0.031190
 >> iter 59000, loss: 0.015315
 >> iter 60000, loss: 0.009824
   Number of active neurons: 10
 >> iter 61000, loss: 0.027363
 >> iter 62000, loss: 0.018355
 >> iter 63000, loss: 0.044872
 >> iter 64000, loss: 0.043736
 >> iter 65000, loss: 0.033817
 >> iter 66000, loss: 0.067570
 >> iter 67000, loss: 0.089130
 >> iter 68000, loss: 0.037992
 >> iter 69000, loss: 0.043235
 >> iter 70000, loss: 0.023642
   Number of active neurons: 10
 >> iter 71000, loss: 0.039478
 >> iter 72000, loss: 0.059640
 >> iter 73000, loss: 0.102520
 >> iter 74000, loss: 0.044753
 >> iter 75000, loss: 0.019926
 >> iter 76000, loss: 0.023571
 >> iter 77000, loss: 0.013324
 >> iter 78000, loss: 0.024587
 >> iter 79000, loss: 0.074434
 >> iter 80000, loss: 0.037886
   Number of active neurons: 10
 >> iter 81000, loss: 0.091672
 >> iter 82000, loss: 0.036988
 >> iter 83000, loss: 0.016214
 >> iter 84000, loss: 0.031286
 >> iter 85000, loss: 0.038712
 >> iter 86000, loss: 0.152790
 >> iter 87000, loss: 0.110784
 >> iter 88000, loss: 0.097327
 >> iter 89000, loss: 0.049182
 >> iter 90000, loss: 0.044122
   Number of active neurons: 10
 >> iter 91000, loss: 0.073483
 >> iter 92000, loss: 0.053041
 >> iter 93000, loss: 0.073803
 >> iter 94000, loss: 0.083282
 >> iter 95000, loss: 0.049731
 >> iter 96000, loss: 0.021622
 >> iter 97000, loss: 0.015815
 >> iter 98000, loss: 0.008393
 >> iter 99000, loss: 0.008297
 >> iter 100000, loss: 0.005070
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.111198
 >> iter 2000, loss: 10.174719
 >> iter 3000, loss: 6.658625
 >> iter 4000, loss: 3.866890
 >> iter 5000, loss: 2.094770
 >> iter 6000, loss: 1.173437
 >> iter 7000, loss: 0.828516
 >> iter 8000, loss: 0.681797
 >> iter 9000, loss: 0.662453
 >> iter 10000, loss: 0.484521
   Number of active neurons: 10
 >> iter 11000, loss: 0.321109
 >> iter 12000, loss: 0.193843
 >> iter 13000, loss: 0.287730
 >> iter 14000, loss: 0.294853
 >> iter 15000, loss: 0.245741
 >> iter 16000, loss: 0.296906
 >> iter 17000, loss: 0.336788
 >> iter 18000, loss: 0.224310
 >> iter 19000, loss: 0.206298
 >> iter 20000, loss: 0.136166
   Number of active neurons: 10
 >> iter 21000, loss: 0.155806
 >> iter 22000, loss: 0.122091
 >> iter 23000, loss: 0.110379
 >> iter 24000, loss: 0.147944
 >> iter 25000, loss: 0.144964
 >> iter 26000, loss: 0.300571
 >> iter 27000, loss: 0.201006
 >> iter 28000, loss: 0.149924
 >> iter 29000, loss: 0.300494
 >> iter 30000, loss: 0.252144
   Number of active neurons: 10
 >> iter 31000, loss: 0.195458
 >> iter 32000, loss: 0.212869
 >> iter 33000, loss: 0.167611
 >> iter 34000, loss: 0.105088
 >> iter 35000, loss: 0.093947
 >> iter 36000, loss: 0.091398
 >> iter 37000, loss: 0.149833
 >> iter 38000, loss: 0.109064
 >> iter 39000, loss: 0.162587
 >> iter 40000, loss: 0.142749
   Number of active neurons: 10
 >> iter 41000, loss: 0.095539
 >> iter 42000, loss: 0.074336
 >> iter 43000, loss: 0.091157
 >> iter 44000, loss: 0.123180
 >> iter 45000, loss: 0.058418
 >> iter 46000, loss: 0.029992
 >> iter 47000, loss: 0.044783
 >> iter 48000, loss: 0.042212
 >> iter 49000, loss: 0.029862
 >> iter 50000, loss: 0.029441
   Number of active neurons: 10
 >> iter 51000, loss: 0.047584
 >> iter 52000, loss: 0.044552
 >> iter 53000, loss: 0.032851
 >> iter 54000, loss: 0.018540
 >> iter 55000, loss: 0.045879
 >> iter 56000, loss: 0.022299
 >> iter 57000, loss: 0.062006
 >> iter 58000, loss: 0.087677
 >> iter 59000, loss: 0.084245
 >> iter 60000, loss: 0.082715
   Number of active neurons: 10
 >> iter 61000, loss: 0.056371
 >> iter 62000, loss: 0.025661
 >> iter 63000, loss: 0.062775
 >> iter 64000, loss: 0.076389
 >> iter 65000, loss: 0.033729
 >> iter 66000, loss: 0.022991
 >> iter 67000, loss: 0.038276
 >> iter 68000, loss: 0.050226
 >> iter 69000, loss: 0.022743
 >> iter 70000, loss: 0.035792
   Number of active neurons: 10
 >> iter 71000, loss: 0.016510
 >> iter 72000, loss: 0.016623
 >> iter 73000, loss: 0.082605
 >> iter 74000, loss: 0.035495
 >> iter 75000, loss: 0.016466
 >> iter 76000, loss: 0.036250
 >> iter 77000, loss: 0.017480
 >> iter 78000, loss: 0.009440
 >> iter 79000, loss: 0.014831
 >> iter 80000, loss: 0.024762
   Number of active neurons: 10
 >> iter 81000, loss: 0.013587
 >> iter 82000, loss: 0.009502
 >> iter 83000, loss: 0.014651
 >> iter 84000, loss: 0.027556
 >> iter 85000, loss: 0.065513
 >> iter 86000, loss: 0.037426
 >> iter 87000, loss: 0.018235
 >> iter 88000, loss: 0.015286
 >> iter 89000, loss: 0.011086
 >> iter 90000, loss: 0.006379
   Number of active neurons: 10
 >> iter 91000, loss: 0.007248
 >> iter 92000, loss: 0.052628
 >> iter 93000, loss: 0.086514
 >> iter 94000, loss: 0.035303
 >> iter 95000, loss: 0.015660
 >> iter 96000, loss: 0.011720
 >> iter 97000, loss: 0.009486
 >> iter 98000, loss: 0.010211
 >> iter 99000, loss: 0.007325
 >> iter 100000, loss: 0.004862
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455179
   Number of active neurons: 0
 >> iter 1000, loss: 16.812255
 >> iter 2000, loss: 10.248553
 >> iter 3000, loss: 7.590515
 >> iter 4000, loss: 6.162816
 >> iter 5000, loss: 5.441368
 >> iter 6000, loss: 4.046438
 >> iter 7000, loss: 2.317433
 >> iter 8000, loss: 1.405556
 >> iter 9000, loss: 0.905457
 >> iter 10000, loss: 0.712338
   Number of active neurons: 10
 >> iter 11000, loss: 0.535045
 >> iter 12000, loss: 0.285846
 >> iter 13000, loss: 0.233127
 >> iter 14000, loss: 0.159060
 >> iter 15000, loss: 0.172334
 >> iter 16000, loss: 0.134240
 >> iter 17000, loss: 0.090678
 >> iter 18000, loss: 0.074489
 >> iter 19000, loss: 0.135949
 >> iter 20000, loss: 0.083687
   Number of active neurons: 10
 >> iter 21000, loss: 0.045265
 >> iter 22000, loss: 0.062716
 >> iter 23000, loss: 0.058008
 >> iter 24000, loss: 0.052530
 >> iter 25000, loss: 0.027360
 >> iter 26000, loss: 0.039422
 >> iter 27000, loss: 0.022110
 >> iter 28000, loss: 0.117921
 >> iter 29000, loss: 0.103125
 >> iter 30000, loss: 0.121919
   Number of active neurons: 10
 >> iter 31000, loss: 0.082918
 >> iter 32000, loss: 0.069612
 >> iter 33000, loss: 0.116218
 >> iter 34000, loss: 0.052522
 >> iter 35000, loss: 0.058229
 >> iter 36000, loss: 0.071352
 >> iter 37000, loss: 0.039512
 >> iter 38000, loss: 0.028253
 >> iter 39000, loss: 0.067765
 >> iter 40000, loss: 0.054079
   Number of active neurons: 10
 >> iter 41000, loss: 0.074919
 >> iter 42000, loss: 0.059234
 >> iter 43000, loss: 0.026561
 >> iter 44000, loss: 0.014035
 >> iter 45000, loss: 0.052507
 >> iter 46000, loss: 0.026302
 >> iter 47000, loss: 0.047858
 >> iter 48000, loss: 0.022628
 >> iter 49000, loss: 0.013413
 >> iter 50000, loss: 0.023591
   Number of active neurons: 10
 >> iter 51000, loss: 0.037134
 >> iter 52000, loss: 0.035574
 >> iter 53000, loss: 0.040160
 >> iter 54000, loss: 0.072245
 >> iter 55000, loss: 0.054653
 >> iter 56000, loss: 0.039186
 >> iter 57000, loss: 0.022152
 >> iter 58000, loss: 0.036277
 >> iter 59000, loss: 0.016700
 >> iter 60000, loss: 0.009240
   Number of active neurons: 10
 >> iter 61000, loss: 0.008922
 >> iter 62000, loss: 0.007527
 >> iter 63000, loss: 0.006746
 >> iter 64000, loss: 0.005862
 >> iter 65000, loss: 0.004108
 >> iter 66000, loss: 0.016824
 >> iter 67000, loss: 0.008304
 >> iter 68000, loss: 0.017008
 >> iter 69000, loss: 0.019568
 >> iter 70000, loss: 0.020314
   Number of active neurons: 10
 >> iter 71000, loss: 0.023609
 >> iter 72000, loss: 0.011157
 >> iter 73000, loss: 0.014480
 >> iter 74000, loss: 0.013117
 >> iter 75000, loss: 0.011602
 >> iter 76000, loss: 0.033071
 >> iter 77000, loss: 0.014308
 >> iter 78000, loss: 0.034454
 >> iter 79000, loss: 0.027894
 >> iter 80000, loss: 0.013378
   Number of active neurons: 10
 >> iter 81000, loss: 0.048680
 >> iter 82000, loss: 0.029208
 >> iter 83000, loss: 0.012843
 >> iter 84000, loss: 0.006640
 >> iter 85000, loss: 0.004192
 >> iter 86000, loss: 0.003263
 >> iter 87000, loss: 0.122139
 >> iter 88000, loss: 0.056645
 >> iter 89000, loss: 0.023647
 >> iter 90000, loss: 0.016885
   Number of active neurons: 10
 >> iter 91000, loss: 0.008247
 >> iter 92000, loss: 0.024455
 >> iter 93000, loss: 0.021309
 >> iter 94000, loss: 0.011792
 >> iter 95000, loss: 0.026160
 >> iter 96000, loss: 0.011755
 >> iter 97000, loss: 0.006261
 >> iter 98000, loss: 0.004297
 >> iter 99000, loss: 0.003279
 >> iter 100000, loss: 0.012434
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.958664
 >> iter 2000, loss: 10.364862
 >> iter 3000, loss: 7.704699
 >> iter 4000, loss: 6.161414
 >> iter 5000, loss: 5.204623
 >> iter 6000, loss: 3.685464
 >> iter 7000, loss: 2.114916
 >> iter 8000, loss: 1.229334
 >> iter 9000, loss: 0.883927
 >> iter 10000, loss: 0.636838
   Number of active neurons: 10
 >> iter 11000, loss: 0.458034
 >> iter 12000, loss: 0.386427
 >> iter 13000, loss: 0.298386
 >> iter 14000, loss: 0.192051
 >> iter 15000, loss: 0.287627
 >> iter 16000, loss: 0.241135
 >> iter 17000, loss: 0.210805
 >> iter 18000, loss: 0.184000
 >> iter 19000, loss: 0.151145
 >> iter 20000, loss: 0.069557
   Number of active neurons: 10
 >> iter 21000, loss: 0.066868
 >> iter 22000, loss: 0.085501
 >> iter 23000, loss: 0.066094
 >> iter 24000, loss: 0.129141
 >> iter 25000, loss: 0.138117
 >> iter 26000, loss: 0.113641
 >> iter 27000, loss: 0.060756
 >> iter 28000, loss: 0.111385
 >> iter 29000, loss: 0.082188
 >> iter 30000, loss: 0.078378
   Number of active neurons: 10
 >> iter 31000, loss: 0.061769
 >> iter 32000, loss: 0.035827
 >> iter 33000, loss: 0.047714
 >> iter 34000, loss: 0.034626
 >> iter 35000, loss: 0.035626
 >> iter 36000, loss: 0.028236
 >> iter 37000, loss: 0.016897
 >> iter 38000, loss: 0.038032
 >> iter 39000, loss: 0.028086
 >> iter 40000, loss: 0.047704
   Number of active neurons: 10
 >> iter 41000, loss: 0.070868
 >> iter 42000, loss: 0.044416
 >> iter 43000, loss: 0.020292
 >> iter 44000, loss: 0.012344
 >> iter 45000, loss: 0.042332
 >> iter 46000, loss: 0.058627
 >> iter 47000, loss: 0.067937
 >> iter 48000, loss: 0.038886
 >> iter 49000, loss: 0.033541
 >> iter 50000, loss: 0.015910
   Number of active neurons: 10
 >> iter 51000, loss: 0.039837
 >> iter 52000, loss: 0.056513
 >> iter 53000, loss: 0.068536
 >> iter 54000, loss: 0.045354
 >> iter 55000, loss: 0.023198
 >> iter 56000, loss: 0.066332
 >> iter 57000, loss: 0.027708
 >> iter 58000, loss: 0.065745
 >> iter 59000, loss: 0.070535
 >> iter 60000, loss: 0.050881
   Number of active neurons: 10
 >> iter 61000, loss: 0.077428
 >> iter 62000, loss: 0.094880
 >> iter 63000, loss: 0.043192
 >> iter 64000, loss: 0.076052
 >> iter 65000, loss: 0.046152
 >> iter 66000, loss: 0.031966
 >> iter 67000, loss: 0.018349
 >> iter 68000, loss: 0.028576
 >> iter 69000, loss: 0.013934
 >> iter 70000, loss: 0.032209
   Number of active neurons: 10
 >> iter 71000, loss: 0.015556
 >> iter 72000, loss: 0.019251
 >> iter 73000, loss: 0.012261
 >> iter 74000, loss: 0.057401
 >> iter 75000, loss: 0.045131
 >> iter 76000, loss: 0.044730
 >> iter 77000, loss: 0.107290
 >> iter 78000, loss: 0.054260
 >> iter 79000, loss: 0.077815
 >> iter 80000, loss: 0.033277
   Number of active neurons: 10
 >> iter 81000, loss: 0.019832
 >> iter 82000, loss: 0.010309
 >> iter 83000, loss: 0.024842
 >> iter 84000, loss: 0.011972
 >> iter 85000, loss: 0.017242
 >> iter 86000, loss: 0.033586
 >> iter 87000, loss: 0.038090
 >> iter 88000, loss: 0.051876
 >> iter 89000, loss: 0.022904
 >> iter 90000, loss: 0.031266
   Number of active neurons: 10
 >> iter 91000, loss: 0.085706
 >> iter 92000, loss: 0.104257
 >> iter 93000, loss: 0.081919
 >> iter 94000, loss: 0.035421
 >> iter 95000, loss: 0.020692
 >> iter 96000, loss: 0.042035
 >> iter 97000, loss: 0.018140
 >> iter 98000, loss: 0.009164
 >> iter 99000, loss: 0.005613
 >> iter 100000, loss: 0.005921
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.279201
 >> iter 2000, loss: 10.342406
 >> iter 3000, loss: 7.421245
 >> iter 4000, loss: 5.347124
 >> iter 5000, loss: 3.468584
 >> iter 6000, loss: 2.379316
 >> iter 7000, loss: 1.500917
 >> iter 8000, loss: 0.984632
 >> iter 9000, loss: 0.698021
 >> iter 10000, loss: 0.639081
   Number of active neurons: 10
 >> iter 11000, loss: 0.408890
 >> iter 12000, loss: 0.507087
 >> iter 13000, loss: 0.330888
 >> iter 14000, loss: 0.379445
 >> iter 15000, loss: 0.318730
 >> iter 16000, loss: 0.320550
 >> iter 17000, loss: 0.298918
 >> iter 18000, loss: 0.374358
 >> iter 19000, loss: 0.293287
 >> iter 20000, loss: 0.262068
   Number of active neurons: 10
 >> iter 21000, loss: 0.362216
 >> iter 22000, loss: 0.358328
 >> iter 23000, loss: 0.332656
 >> iter 24000, loss: 0.232748
 >> iter 25000, loss: 0.176747
 >> iter 26000, loss: 0.236250
 >> iter 27000, loss: 0.228604
 >> iter 28000, loss: 0.217251
 >> iter 29000, loss: 0.126817
 >> iter 30000, loss: 0.108492
   Number of active neurons: 10
 >> iter 31000, loss: 0.173351
 >> iter 32000, loss: 0.173270
 >> iter 33000, loss: 0.138159
 >> iter 34000, loss: 0.151708
 >> iter 35000, loss: 0.079972
 >> iter 36000, loss: 0.077702
 >> iter 37000, loss: 0.075034
 >> iter 38000, loss: 0.103468
 >> iter 39000, loss: 0.180886
 >> iter 40000, loss: 0.118373
   Number of active neurons: 10
 >> iter 41000, loss: 0.143552
 >> iter 42000, loss: 0.157279
 >> iter 43000, loss: 0.082000
 >> iter 44000, loss: 0.138278
 >> iter 45000, loss: 0.089956
 >> iter 46000, loss: 0.052683
 >> iter 47000, loss: 0.043564
 >> iter 48000, loss: 0.071549
 >> iter 49000, loss: 0.056654
 >> iter 50000, loss: 0.041419
   Number of active neurons: 10
 >> iter 51000, loss: 0.026629
 >> iter 52000, loss: 0.055306
 >> iter 53000, loss: 0.049000
 >> iter 54000, loss: 0.115555
 >> iter 55000, loss: 0.101567
 >> iter 56000, loss: 0.070601
 >> iter 57000, loss: 0.067746
 >> iter 58000, loss: 0.204531
 >> iter 59000, loss: 0.133156
 >> iter 60000, loss: 0.098481
   Number of active neurons: 10
 >> iter 61000, loss: 0.043172
 >> iter 62000, loss: 0.095565
 >> iter 63000, loss: 0.079560
 >> iter 64000, loss: 0.075823
 >> iter 65000, loss: 0.033836
 >> iter 66000, loss: 0.017147
 >> iter 67000, loss: 0.071842
 >> iter 68000, loss: 0.052761
 >> iter 69000, loss: 0.056293
 >> iter 70000, loss: 0.079712
   Number of active neurons: 10
 >> iter 71000, loss: 0.058932
 >> iter 72000, loss: 0.130148
 >> iter 73000, loss: 0.118777
 >> iter 74000, loss: 0.062474
 >> iter 75000, loss: 0.061398
 >> iter 76000, loss: 0.064104
 >> iter 77000, loss: 0.088446
 >> iter 78000, loss: 0.039521
 >> iter 79000, loss: 0.107945
 >> iter 80000, loss: 0.050682
   Number of active neurons: 10
 >> iter 81000, loss: 0.036496
 >> iter 82000, loss: 0.020358
 >> iter 83000, loss: 0.025784
 >> iter 84000, loss: 0.107977
 >> iter 85000, loss: 0.120323
 >> iter 86000, loss: 0.075424
 >> iter 87000, loss: 0.074989
 >> iter 88000, loss: 0.050676
 >> iter 89000, loss: 0.023215
 >> iter 90000, loss: 0.026066
   Number of active neurons: 10
 >> iter 91000, loss: 0.023851
 >> iter 92000, loss: 0.011765
 >> iter 93000, loss: 0.016953
 >> iter 94000, loss: 0.029914
 >> iter 95000, loss: 0.062985
 >> iter 96000, loss: 0.055926
 >> iter 97000, loss: 0.024516
 >> iter 98000, loss: 0.157668
 >> iter 99000, loss: 0.092917
 >> iter 100000, loss: 0.038451
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 17.285060
 >> iter 2000, loss: 10.611094
 >> iter 3000, loss: 7.482741
 >> iter 4000, loss: 5.349888
 >> iter 5000, loss: 3.534898
 >> iter 6000, loss: 2.132238
 >> iter 7000, loss: 1.302322
 >> iter 8000, loss: 0.738127
 >> iter 9000, loss: 0.402924
 >> iter 10000, loss: 0.318802
   Number of active neurons: 10
 >> iter 11000, loss: 0.254847
 >> iter 12000, loss: 0.274094
 >> iter 13000, loss: 0.260001
 >> iter 14000, loss: 0.247850
 >> iter 15000, loss: 0.172567
 >> iter 16000, loss: 0.182210
 >> iter 17000, loss: 0.129010
 >> iter 18000, loss: 0.124025
 >> iter 19000, loss: 0.190170
 >> iter 20000, loss: 0.135540
   Number of active neurons: 10
 >> iter 21000, loss: 0.081442
 >> iter 22000, loss: 0.158036
 >> iter 23000, loss: 0.083395
 >> iter 24000, loss: 0.130805
 >> iter 25000, loss: 0.084030
 >> iter 26000, loss: 0.069380
 >> iter 27000, loss: 0.043017
 >> iter 28000, loss: 0.064101
 >> iter 29000, loss: 0.071447
 >> iter 30000, loss: 0.104881
   Number of active neurons: 10
 >> iter 31000, loss: 0.099267
 >> iter 32000, loss: 0.056472
 >> iter 33000, loss: 0.036280
 >> iter 34000, loss: 0.154707
 >> iter 35000, loss: 0.135767
 >> iter 36000, loss: 0.145825
 >> iter 37000, loss: 0.139393
 >> iter 38000, loss: 0.074777
 >> iter 39000, loss: 0.110389
 >> iter 40000, loss: 0.110175
   Number of active neurons: 10
 >> iter 41000, loss: 0.064006
 >> iter 42000, loss: 0.033449
 >> iter 43000, loss: 0.051000
 >> iter 44000, loss: 0.030981
 >> iter 45000, loss: 0.027281
 >> iter 46000, loss: 0.014276
 >> iter 47000, loss: 0.009289
 >> iter 48000, loss: 0.035435
 >> iter 49000, loss: 0.016742
 >> iter 50000, loss: 0.009754
   Number of active neurons: 10
 >> iter 51000, loss: 0.020680
 >> iter 52000, loss: 0.012915
 >> iter 53000, loss: 0.021219
 >> iter 54000, loss: 0.032386
 >> iter 55000, loss: 0.015410
 >> iter 56000, loss: 0.008318
 >> iter 57000, loss: 0.016166
 >> iter 58000, loss: 0.008534
 >> iter 59000, loss: 0.029863
 >> iter 60000, loss: 0.013713
   Number of active neurons: 10
 >> iter 61000, loss: 0.022027
 >> iter 62000, loss: 0.010736
 >> iter 63000, loss: 0.054661
 >> iter 64000, loss: 0.022421
 >> iter 65000, loss: 0.010723
 >> iter 66000, loss: 0.006135
 >> iter 67000, loss: 0.004030
 >> iter 68000, loss: 0.003148
 >> iter 69000, loss: 0.003698
 >> iter 70000, loss: 0.017548
   Number of active neurons: 10
 >> iter 71000, loss: 0.018324
 >> iter 72000, loss: 0.031909
 >> iter 73000, loss: 0.015688
 >> iter 74000, loss: 0.007723
 >> iter 75000, loss: 0.020913
 >> iter 76000, loss: 0.022521
 >> iter 77000, loss: 0.012551
 >> iter 78000, loss: 0.019530
 >> iter 79000, loss: 0.029105
 >> iter 80000, loss: 0.019997
   Number of active neurons: 10
 >> iter 81000, loss: 0.021734
 >> iter 82000, loss: 0.096065
 >> iter 83000, loss: 0.093313
 >> iter 84000, loss: 0.060222
 >> iter 85000, loss: 0.037971
 >> iter 86000, loss: 0.017344
 >> iter 87000, loss: 0.016513
 >> iter 88000, loss: 0.008610
 >> iter 89000, loss: 0.005310
 >> iter 90000, loss: 0.020124
   Number of active neurons: 10
 >> iter 91000, loss: 0.010192
 >> iter 92000, loss: 0.006880
 >> iter 93000, loss: 0.004419
 >> iter 94000, loss: 0.003458
 >> iter 95000, loss: 0.004024
 >> iter 96000, loss: 0.005239
 >> iter 97000, loss: 0.029198
 >> iter 98000, loss: 0.012324
 >> iter 99000, loss: 0.017697
 >> iter 100000, loss: 0.049385
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.819895
 >> iter 2000, loss: 10.141577
 >> iter 3000, loss: 7.643362
 >> iter 4000, loss: 6.337876
 >> iter 5000, loss: 5.274380
 >> iter 6000, loss: 3.732580
 >> iter 7000, loss: 2.477414
 >> iter 8000, loss: 1.397116
 >> iter 9000, loss: 1.118688
 >> iter 10000, loss: 0.759940
   Number of active neurons: 10
 >> iter 11000, loss: 0.668825
 >> iter 12000, loss: 0.537472
 >> iter 13000, loss: 0.493469
 >> iter 14000, loss: 0.432218
 >> iter 15000, loss: 0.357415
 >> iter 16000, loss: 0.458612
 >> iter 17000, loss: 0.388833
 >> iter 18000, loss: 0.189574
 >> iter 19000, loss: 0.291335
 >> iter 20000, loss: 0.253373
   Number of active neurons: 10
 >> iter 21000, loss: 0.176696
 >> iter 22000, loss: 0.108952
 >> iter 23000, loss: 0.219118
 >> iter 24000, loss: 0.340169
 >> iter 25000, loss: 0.315563
 >> iter 26000, loss: 0.147979
 >> iter 27000, loss: 0.122041
 >> iter 28000, loss: 0.077853
 >> iter 29000, loss: 0.095124
 >> iter 30000, loss: 0.059101
   Number of active neurons: 10
 >> iter 31000, loss: 0.101461
 >> iter 32000, loss: 0.084144
 >> iter 33000, loss: 0.119958
 >> iter 34000, loss: 0.139674
 >> iter 35000, loss: 0.140054
 >> iter 36000, loss: 0.115682
 >> iter 37000, loss: 0.098545
 >> iter 38000, loss: 0.064876
 >> iter 39000, loss: 0.067209
 >> iter 40000, loss: 0.094380
   Number of active neurons: 10
 >> iter 41000, loss: 0.063325
 >> iter 42000, loss: 0.104157
 >> iter 43000, loss: 0.067231
 >> iter 44000, loss: 0.077317
 >> iter 45000, loss: 0.060664
 >> iter 46000, loss: 0.070487
 >> iter 47000, loss: 0.123572
 >> iter 48000, loss: 0.102712
 >> iter 49000, loss: 0.080184
 >> iter 50000, loss: 0.036306
   Number of active neurons: 10
 >> iter 51000, loss: 0.106317
 >> iter 52000, loss: 0.073998
 >> iter 53000, loss: 0.083190
 >> iter 54000, loss: 0.043076
 >> iter 55000, loss: 0.113047
 >> iter 56000, loss: 0.077952
 >> iter 57000, loss: 0.050731
 >> iter 58000, loss: 0.117501
 >> iter 59000, loss: 0.142366
 >> iter 60000, loss: 0.079507
   Number of active neurons: 10
 >> iter 61000, loss: 0.041176
 >> iter 62000, loss: 0.103175
 >> iter 63000, loss: 0.053009
 >> iter 64000, loss: 0.038682
 >> iter 65000, loss: 0.085585
 >> iter 66000, loss: 0.042826
 >> iter 67000, loss: 0.135045
 >> iter 68000, loss: 0.088632
 >> iter 69000, loss: 0.133904
 >> iter 70000, loss: 0.055631
   Number of active neurons: 10
 >> iter 71000, loss: 0.053661
 >> iter 72000, loss: 0.033107
 >> iter 73000, loss: 0.015582
 >> iter 74000, loss: 0.046925
 >> iter 75000, loss: 0.022847
 >> iter 76000, loss: 0.019506
 >> iter 77000, loss: 0.036590
 >> iter 78000, loss: 0.030216
 >> iter 79000, loss: 0.028805
 >> iter 80000, loss: 0.028564
   Number of active neurons: 10
 >> iter 81000, loss: 0.028124
 >> iter 82000, loss: 0.013124
 >> iter 83000, loss: 0.008020
 >> iter 84000, loss: 0.010411
 >> iter 85000, loss: 0.009033
 >> iter 86000, loss: 0.020323
 >> iter 87000, loss: 0.012973
 >> iter 88000, loss: 0.101028
 >> iter 89000, loss: 0.120983
 >> iter 90000, loss: 0.071086
   Number of active neurons: 10
 >> iter 91000, loss: 0.052374
 >> iter 92000, loss: 0.060134
 >> iter 93000, loss: 0.026061
 >> iter 94000, loss: 0.045541
 >> iter 95000, loss: 0.019833
 >> iter 96000, loss: 0.075371
 >> iter 97000, loss: 0.086330
 >> iter 98000, loss: 0.035330
 >> iter 99000, loss: 0.015857
 >> iter 100000, loss: 0.082622
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.003103
 >> iter 2000, loss: 10.346652
 >> iter 3000, loss: 7.629985
 >> iter 4000, loss: 6.078234
 >> iter 5000, loss: 5.483944
 >> iter 6000, loss: 4.400208
 >> iter 7000, loss: 3.119697
 >> iter 8000, loss: 2.043592
 >> iter 9000, loss: 1.466000
 >> iter 10000, loss: 0.836700
   Number of active neurons: 10
 >> iter 11000, loss: 0.658434
 >> iter 12000, loss: 0.497352
 >> iter 13000, loss: 0.610469
 >> iter 14000, loss: 0.525319
 >> iter 15000, loss: 0.536917
 >> iter 16000, loss: 0.367022
 >> iter 17000, loss: 0.276478
 >> iter 18000, loss: 0.210876
 >> iter 19000, loss: 0.359272
 >> iter 20000, loss: 0.340565
   Number of active neurons: 10
 >> iter 21000, loss: 0.260821
 >> iter 22000, loss: 0.193435
 >> iter 23000, loss: 0.165017
 >> iter 24000, loss: 0.165495
 >> iter 25000, loss: 0.131354
 >> iter 26000, loss: 0.100908
 >> iter 27000, loss: 0.226458
 >> iter 28000, loss: 0.125261
 >> iter 29000, loss: 0.084556
 >> iter 30000, loss: 0.135707
   Number of active neurons: 10
 >> iter 31000, loss: 0.106697
 >> iter 32000, loss: 0.131472
 >> iter 33000, loss: 0.097828
 >> iter 34000, loss: 0.126763
 >> iter 35000, loss: 0.098959
 >> iter 36000, loss: 0.095116
 >> iter 37000, loss: 0.077755
 >> iter 38000, loss: 0.051577
 >> iter 39000, loss: 0.064742
 >> iter 40000, loss: 0.108914
   Number of active neurons: 10
 >> iter 41000, loss: 0.065822
 >> iter 42000, loss: 0.029353
 >> iter 43000, loss: 0.035273
 >> iter 44000, loss: 0.028572
 >> iter 45000, loss: 0.027980
 >> iter 46000, loss: 0.048457
 >> iter 47000, loss: 0.077746
 >> iter 48000, loss: 0.051904
 >> iter 49000, loss: 0.058392
 >> iter 50000, loss: 0.101249
   Number of active neurons: 10
 >> iter 51000, loss: 0.112044
 >> iter 52000, loss: 0.098387
 >> iter 53000, loss: 0.067138
 >> iter 54000, loss: 0.035413
 >> iter 55000, loss: 0.047455
 >> iter 56000, loss: 0.047347
 >> iter 57000, loss: 0.045857
 >> iter 58000, loss: 0.033939
 >> iter 59000, loss: 0.020789
 >> iter 60000, loss: 0.010766
   Number of active neurons: 10
 >> iter 61000, loss: 0.012271
 >> iter 62000, loss: 0.045444
 >> iter 63000, loss: 0.116537
 >> iter 64000, loss: 0.148822
 >> iter 65000, loss: 0.111737
 >> iter 66000, loss: 0.048739
 >> iter 67000, loss: 0.039279
 >> iter 68000, loss: 0.038814
 >> iter 69000, loss: 0.059079
 >> iter 70000, loss: 0.031063
   Number of active neurons: 10
 >> iter 71000, loss: 0.027650
 >> iter 72000, loss: 0.054835
 >> iter 73000, loss: 0.023125
 >> iter 74000, loss: 0.033715
 >> iter 75000, loss: 0.046723
 >> iter 76000, loss: 0.020245
 >> iter 77000, loss: 0.049238
 >> iter 78000, loss: 0.061453
 >> iter 79000, loss: 0.080497
 >> iter 80000, loss: 0.038402
   Number of active neurons: 10
 >> iter 81000, loss: 0.026933
 >> iter 82000, loss: 0.012688
 >> iter 83000, loss: 0.032769
 >> iter 84000, loss: 0.095451
 >> iter 85000, loss: 0.097412
 >> iter 86000, loss: 0.102800
 >> iter 87000, loss: 0.083195
 >> iter 88000, loss: 0.066779
 >> iter 89000, loss: 0.091244
 >> iter 90000, loss: 0.103099
   Number of active neurons: 10
 >> iter 91000, loss: 0.073416
 >> iter 92000, loss: 0.062945
 >> iter 93000, loss: 0.087851
 >> iter 94000, loss: 0.036388
 >> iter 95000, loss: 0.043375
 >> iter 96000, loss: 0.044789
 >> iter 97000, loss: 0.054500
 >> iter 98000, loss: 0.074093
 >> iter 99000, loss: 0.074359
 >> iter 100000, loss: 0.032158
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.088398
 >> iter 2000, loss: 10.445850
 >> iter 3000, loss: 7.541458
 >> iter 4000, loss: 6.152440
 >> iter 5000, loss: 5.199997
 >> iter 6000, loss: 4.120463
 >> iter 7000, loss: 3.081629
 >> iter 8000, loss: 2.325172
 >> iter 9000, loss: 1.928207
 >> iter 10000, loss: 1.448027
   Number of active neurons: 10
 >> iter 11000, loss: 1.311025
 >> iter 12000, loss: 1.296589
 >> iter 13000, loss: 1.059366
 >> iter 14000, loss: 1.094800
 >> iter 15000, loss: 1.037563
 >> iter 16000, loss: 1.027600
 >> iter 17000, loss: 0.627641
 >> iter 18000, loss: 0.816097
 >> iter 19000, loss: 0.890178
 >> iter 20000, loss: 0.776327
   Number of active neurons: 10
 >> iter 21000, loss: 0.700109
 >> iter 22000, loss: 0.641421
 >> iter 23000, loss: 0.558848
 >> iter 24000, loss: 0.557741
 >> iter 25000, loss: 0.503513
 >> iter 26000, loss: 0.515550
 >> iter 27000, loss: 0.430304
 >> iter 28000, loss: 0.445926
 >> iter 29000, loss: 0.423384
 >> iter 30000, loss: 0.412996
   Number of active neurons: 10
 >> iter 31000, loss: 0.384022
 >> iter 32000, loss: 0.337131
 >> iter 33000, loss: 0.298784
 >> iter 34000, loss: 0.342505
 >> iter 35000, loss: 0.360952
 >> iter 36000, loss: 0.438462
 >> iter 37000, loss: 0.436942
 >> iter 38000, loss: 0.369659
 >> iter 39000, loss: 0.345149
 >> iter 40000, loss: 0.282330
   Number of active neurons: 10
 >> iter 41000, loss: 0.300733
 >> iter 42000, loss: 0.377156
 >> iter 43000, loss: 0.262972
 >> iter 44000, loss: 0.230881
 >> iter 45000, loss: 0.236389
 >> iter 46000, loss: 0.270265
 >> iter 47000, loss: 0.230121
 >> iter 48000, loss: 0.144232
 >> iter 49000, loss: 0.243723
 >> iter 50000, loss: 0.224161
   Number of active neurons: 10
 >> iter 51000, loss: 0.241863
 >> iter 52000, loss: 0.249460
 >> iter 53000, loss: 0.148916
 >> iter 54000, loss: 0.271417
 >> iter 55000, loss: 0.222346
 >> iter 56000, loss: 0.239761
 >> iter 57000, loss: 0.149288
 >> iter 58000, loss: 0.283308
 >> iter 59000, loss: 0.289175
 >> iter 60000, loss: 0.191633
   Number of active neurons: 10
 >> iter 61000, loss: 0.241359
 >> iter 62000, loss: 0.200219
 >> iter 63000, loss: 0.202616
 >> iter 64000, loss: 0.115553
 >> iter 65000, loss: 0.140146
 >> iter 66000, loss: 0.134128
 >> iter 67000, loss: 0.131678
 >> iter 68000, loss: 0.129109
 >> iter 69000, loss: 0.227325
 >> iter 70000, loss: 0.217155
   Number of active neurons: 10
 >> iter 71000, loss: 0.176039
 >> iter 72000, loss: 0.166959
 >> iter 73000, loss: 0.146754
 >> iter 74000, loss: 0.203131
 >> iter 75000, loss: 0.147715
 >> iter 76000, loss: 0.079273
 >> iter 77000, loss: 0.091591
 >> iter 78000, loss: 0.051090
 >> iter 79000, loss: 0.052035
 >> iter 80000, loss: 0.055210
   Number of active neurons: 10
 >> iter 81000, loss: 0.033732
 >> iter 82000, loss: 0.086439
 >> iter 83000, loss: 0.038093
 >> iter 84000, loss: 0.115831
 >> iter 85000, loss: 0.126084
 >> iter 86000, loss: 0.152415
 >> iter 87000, loss: 0.195333
 >> iter 88000, loss: 0.241132
 >> iter 89000, loss: 0.098257
 >> iter 90000, loss: 0.141403
   Number of active neurons: 10
 >> iter 91000, loss: 0.078882
 >> iter 92000, loss: 0.082145
 >> iter 93000, loss: 0.118131
 >> iter 94000, loss: 0.118492
 >> iter 95000, loss: 0.130794
 >> iter 96000, loss: 0.097443
 >> iter 97000, loss: 0.060067
 >> iter 98000, loss: 0.085970
 >> iter 99000, loss: 0.078073
 >> iter 100000, loss: 0.063180
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.823701
 >> iter 2000, loss: 10.176479
 >> iter 3000, loss: 7.357967
 >> iter 4000, loss: 5.518528
 >> iter 5000, loss: 3.898628
 >> iter 6000, loss: 3.047651
 >> iter 7000, loss: 2.468015
 >> iter 8000, loss: 1.900360
 >> iter 9000, loss: 1.729396
 >> iter 10000, loss: 1.438277
   Number of active neurons: 10
 >> iter 11000, loss: 1.241924
 >> iter 12000, loss: 0.935821
 >> iter 13000, loss: 0.755147
 >> iter 14000, loss: 0.838238
 >> iter 15000, loss: 0.614739
 >> iter 16000, loss: 0.520835
 >> iter 17000, loss: 0.542056
 >> iter 18000, loss: 0.516796
 >> iter 19000, loss: 0.380277
 >> iter 20000, loss: 0.378705
   Number of active neurons: 10
 >> iter 21000, loss: 0.472343
 >> iter 22000, loss: 0.313463
 >> iter 23000, loss: 0.251009
 >> iter 24000, loss: 0.150259
 >> iter 25000, loss: 0.297818
 >> iter 26000, loss: 0.235452
 >> iter 27000, loss: 0.238143
 >> iter 28000, loss: 0.244298
 >> iter 29000, loss: 0.204741
 >> iter 30000, loss: 0.097029
   Number of active neurons: 10
 >> iter 31000, loss: 0.080288
 >> iter 32000, loss: 0.082616
 >> iter 33000, loss: 0.095975
 >> iter 34000, loss: 0.166933
 >> iter 35000, loss: 0.265560
 >> iter 36000, loss: 0.231308
 >> iter 37000, loss: 0.183072
 >> iter 38000, loss: 0.124778
 >> iter 39000, loss: 0.105385
 >> iter 40000, loss: 0.127346
   Number of active neurons: 10
 >> iter 41000, loss: 0.156551
 >> iter 42000, loss: 0.117866
 >> iter 43000, loss: 0.075868
 >> iter 44000, loss: 0.105251
 >> iter 45000, loss: 0.100096
 >> iter 46000, loss: 0.083728
 >> iter 47000, loss: 0.045951
 >> iter 48000, loss: 0.030917
 >> iter 49000, loss: 0.026130
 >> iter 50000, loss: 0.111797
   Number of active neurons: 10
 >> iter 51000, loss: 0.099901
 >> iter 52000, loss: 0.163348
 >> iter 53000, loss: 0.119553
 >> iter 54000, loss: 0.050720
 >> iter 55000, loss: 0.129188
 >> iter 56000, loss: 0.082271
 >> iter 57000, loss: 0.042739
 >> iter 58000, loss: 0.086444
 >> iter 59000, loss: 0.131329
 >> iter 60000, loss: 0.138231
   Number of active neurons: 10
 >> iter 61000, loss: 0.058829
 >> iter 62000, loss: 0.026413
 >> iter 63000, loss: 0.019979
 >> iter 64000, loss: 0.072395
 >> iter 65000, loss: 0.083260
 >> iter 66000, loss: 0.107870
 >> iter 67000, loss: 0.132342
 >> iter 68000, loss: 0.090952
 >> iter 69000, loss: 0.075182
 >> iter 70000, loss: 0.056811
   Number of active neurons: 10
 >> iter 71000, loss: 0.025659
 >> iter 72000, loss: 0.057541
 >> iter 73000, loss: 0.029251
 >> iter 74000, loss: 0.112781
 >> iter 75000, loss: 0.064560
 >> iter 76000, loss: 0.110085
 >> iter 77000, loss: 0.071542
 >> iter 78000, loss: 0.033790
 >> iter 79000, loss: 0.047133
 >> iter 80000, loss: 0.040142
   Number of active neurons: 10
 >> iter 81000, loss: 0.072077
 >> iter 82000, loss: 0.037566
 >> iter 83000, loss: 0.043751
 >> iter 84000, loss: 0.019694
 >> iter 85000, loss: 0.010495
 >> iter 86000, loss: 0.057971
 >> iter 87000, loss: 0.052540
 >> iter 88000, loss: 0.023636
 >> iter 89000, loss: 0.089184
 >> iter 90000, loss: 0.044875
   Number of active neurons: 10
 >> iter 91000, loss: 0.048642
 >> iter 92000, loss: 0.056909
 >> iter 93000, loss: 0.057680
 >> iter 94000, loss: 0.070721
 >> iter 95000, loss: 0.067746
 >> iter 96000, loss: 0.050255
 >> iter 97000, loss: 0.022129
 >> iter 98000, loss: 0.027776
 >> iter 99000, loss: 0.090159
 >> iter 100000, loss: 0.051851
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

