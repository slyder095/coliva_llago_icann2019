 > Problema: tomita7nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.9
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 16.927312
 >> iter 2000, loss: 10.520696
 >> iter 3000, loss: 7.824634
 >> iter 4000, loss: 5.961601
 >> iter 5000, loss: 3.706030
 >> iter 6000, loss: 2.049319
 >> iter 7000, loss: 1.264764
 >> iter 8000, loss: 0.737197
 >> iter 9000, loss: 0.645592
 >> iter 10000, loss: 0.492218
   Number of active neurons: 10
 >> iter 11000, loss: 0.470626
 >> iter 12000, loss: 0.392432
 >> iter 13000, loss: 0.313379
 >> iter 14000, loss: 0.233263
 >> iter 15000, loss: 0.272212
 >> iter 16000, loss: 0.160847
 >> iter 17000, loss: 0.193533
 >> iter 18000, loss: 0.201029
 >> iter 19000, loss: 0.246415
 >> iter 20000, loss: 0.192567
   Number of active neurons: 10
 >> iter 21000, loss: 0.098996
 >> iter 22000, loss: 0.075485
 >> iter 23000, loss: 0.097460
 >> iter 24000, loss: 0.137545
 >> iter 25000, loss: 0.144072
 >> iter 26000, loss: 0.087088
 >> iter 27000, loss: 0.079090
 >> iter 28000, loss: 0.113707
 >> iter 29000, loss: 0.110546
 >> iter 30000, loss: 0.107819
   Number of active neurons: 10
 >> iter 31000, loss: 0.137989
 >> iter 32000, loss: 0.138477
 >> iter 33000, loss: 0.132396
 >> iter 34000, loss: 0.107471
 >> iter 35000, loss: 0.114641
 >> iter 36000, loss: 0.071077
 >> iter 37000, loss: 0.093978
 >> iter 38000, loss: 0.068997
 >> iter 39000, loss: 0.109627
 >> iter 40000, loss: 0.057041
   Number of active neurons: 10
 >> iter 41000, loss: 0.049564
 >> iter 42000, loss: 0.029295
 >> iter 43000, loss: 0.050997
 >> iter 44000, loss: 0.031808
 >> iter 45000, loss: 0.015789
 >> iter 46000, loss: 0.038503
 >> iter 47000, loss: 0.025286
 >> iter 48000, loss: 0.032337
 >> iter 49000, loss: 0.028066
 >> iter 50000, loss: 0.025483
   Number of active neurons: 10
 >> iter 51000, loss: 0.071660
 >> iter 52000, loss: 0.039173
 >> iter 53000, loss: 0.018418
 >> iter 54000, loss: 0.041423
 >> iter 55000, loss: 0.018910
 >> iter 56000, loss: 0.068392
 >> iter 57000, loss: 0.046327
 >> iter 58000, loss: 0.043561
 >> iter 59000, loss: 0.118387
 >> iter 60000, loss: 0.061897
   Number of active neurons: 10
 >> iter 61000, loss: 0.045315
 >> iter 62000, loss: 0.020588
 >> iter 63000, loss: 0.026743
 >> iter 64000, loss: 0.023811
 >> iter 65000, loss: 0.024809
 >> iter 66000, loss: 0.029236
 >> iter 67000, loss: 0.067209
 >> iter 68000, loss: 0.032406
 >> iter 69000, loss: 0.088200
 >> iter 70000, loss: 0.083364
   Number of active neurons: 10
 >> iter 71000, loss: 0.087199
 >> iter 72000, loss: 0.036227
 >> iter 73000, loss: 0.029478
 >> iter 74000, loss: 0.014548
 >> iter 75000, loss: 0.026562
 >> iter 76000, loss: 0.013946
 >> iter 77000, loss: 0.042533
 >> iter 78000, loss: 0.018440
 >> iter 79000, loss: 0.010473
 >> iter 80000, loss: 0.005793
   Number of active neurons: 10
 >> iter 81000, loss: 0.038021
 >> iter 82000, loss: 0.032910
 >> iter 83000, loss: 0.014645
 >> iter 84000, loss: 0.009531
 >> iter 85000, loss: 0.013713
 >> iter 86000, loss: 0.007248
 >> iter 87000, loss: 0.004221
 >> iter 88000, loss: 0.016288
 >> iter 89000, loss: 0.014148
 >> iter 90000, loss: 0.043278
   Number of active neurons: 10
 >> iter 91000, loss: 0.041662
 >> iter 92000, loss: 0.023352
 >> iter 93000, loss: 0.038990
 >> iter 94000, loss: 0.017071
 >> iter 95000, loss: 0.007856
 >> iter 96000, loss: 0.005288
 >> iter 97000, loss: 0.023211
 >> iter 98000, loss: 0.073771
 >> iter 99000, loss: 0.028825
 >> iter 100000, loss: 0.012172
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.696100
 >> iter 2000, loss: 10.041871
 >> iter 3000, loss: 7.014793
 >> iter 4000, loss: 4.984651
 >> iter 5000, loss: 3.676512
 >> iter 6000, loss: 2.583572
 >> iter 7000, loss: 1.693617
 >> iter 8000, loss: 1.293782
 >> iter 9000, loss: 1.028587
 >> iter 10000, loss: 1.060461
   Number of active neurons: 10
 >> iter 11000, loss: 0.782436
 >> iter 12000, loss: 0.629152
 >> iter 13000, loss: 0.566171
 >> iter 14000, loss: 0.739263
 >> iter 15000, loss: 0.668331
 >> iter 16000, loss: 0.641527
 >> iter 17000, loss: 0.542386
 >> iter 18000, loss: 0.426489
 >> iter 19000, loss: 0.445952
 >> iter 20000, loss: 0.430839
   Number of active neurons: 10
 >> iter 21000, loss: 0.394258
 >> iter 22000, loss: 0.410163
 >> iter 23000, loss: 0.485480
 >> iter 24000, loss: 0.262317
 >> iter 25000, loss: 0.232913
 >> iter 26000, loss: 0.182382
 >> iter 27000, loss: 0.219805
 >> iter 28000, loss: 0.244816
 >> iter 29000, loss: 0.321463
 >> iter 30000, loss: 0.240112
   Number of active neurons: 10
 >> iter 31000, loss: 0.315485
 >> iter 32000, loss: 0.224477
 >> iter 33000, loss: 0.181004
 >> iter 34000, loss: 0.164298
 >> iter 35000, loss: 0.234174
 >> iter 36000, loss: 0.256717
 >> iter 37000, loss: 0.244086
 >> iter 38000, loss: 0.209772
 >> iter 39000, loss: 0.293942
 >> iter 40000, loss: 0.298936
   Number of active neurons: 10
 >> iter 41000, loss: 0.248530
 >> iter 42000, loss: 0.179077
 >> iter 43000, loss: 0.125776
 >> iter 44000, loss: 0.198488
 >> iter 45000, loss: 0.127156
 >> iter 46000, loss: 0.158328
 >> iter 47000, loss: 0.121127
 >> iter 48000, loss: 0.068175
 >> iter 49000, loss: 0.110415
 >> iter 50000, loss: 0.166275
   Number of active neurons: 10
 >> iter 51000, loss: 0.166539
 >> iter 52000, loss: 0.217708
 >> iter 53000, loss: 0.209629
 >> iter 54000, loss: 0.170197
 >> iter 55000, loss: 0.149462
 >> iter 56000, loss: 0.186054
 >> iter 57000, loss: 0.173320
 >> iter 58000, loss: 0.171708
 >> iter 59000, loss: 0.120096
 >> iter 60000, loss: 0.070120
   Number of active neurons: 10
 >> iter 61000, loss: 0.048538
 >> iter 62000, loss: 0.113124
 >> iter 63000, loss: 0.085198
 >> iter 64000, loss: 0.166033
 >> iter 65000, loss: 0.164445
 >> iter 66000, loss: 0.102533
 >> iter 67000, loss: 0.117128
 >> iter 68000, loss: 0.125938
 >> iter 69000, loss: 0.060608
 >> iter 70000, loss: 0.069146
   Number of active neurons: 10
 >> iter 71000, loss: 0.032520
 >> iter 72000, loss: 0.133347
 >> iter 73000, loss: 0.114873
 >> iter 74000, loss: 0.075886
 >> iter 75000, loss: 0.081121
 >> iter 76000, loss: 0.189725
 >> iter 77000, loss: 0.206288
 >> iter 78000, loss: 0.113694
 >> iter 79000, loss: 0.064393
 >> iter 80000, loss: 0.081329
   Number of active neurons: 10
 >> iter 81000, loss: 0.085799
 >> iter 82000, loss: 0.089738
 >> iter 83000, loss: 0.071760
 >> iter 84000, loss: 0.125055
 >> iter 85000, loss: 0.141193
 >> iter 86000, loss: 0.059355
 >> iter 87000, loss: 0.046657
 >> iter 88000, loss: 0.046436
 >> iter 89000, loss: 0.058096
 >> iter 90000, loss: 0.086553
   Number of active neurons: 10
 >> iter 91000, loss: 0.062629
 >> iter 92000, loss: 0.074050
 >> iter 93000, loss: 0.041742
 >> iter 94000, loss: 0.057033
 >> iter 95000, loss: 0.093133
 >> iter 96000, loss: 0.069839
 >> iter 97000, loss: 0.086446
 >> iter 98000, loss: 0.067573
 >> iter 99000, loss: 0.037279
 >> iter 100000, loss: 0.134861
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 17.071322
 >> iter 2000, loss: 10.139643
 >> iter 3000, loss: 6.138366
 >> iter 4000, loss: 3.322777
 >> iter 5000, loss: 1.832453
 >> iter 6000, loss: 1.193062
 >> iter 7000, loss: 0.685686
 >> iter 8000, loss: 0.546258
 >> iter 9000, loss: 0.377874
 >> iter 10000, loss: 0.409341
   Number of active neurons: 10
 >> iter 11000, loss: 0.326392
 >> iter 12000, loss: 0.222474
 >> iter 13000, loss: 0.224025
 >> iter 14000, loss: 0.165048
 >> iter 15000, loss: 0.150054
 >> iter 16000, loss: 0.211972
 >> iter 17000, loss: 0.237258
 >> iter 18000, loss: 0.218105
 >> iter 19000, loss: 0.144974
 >> iter 20000, loss: 0.318804
   Number of active neurons: 10
 >> iter 21000, loss: 0.308870
 >> iter 22000, loss: 0.204926
 >> iter 23000, loss: 0.198668
 >> iter 24000, loss: 0.105664
 >> iter 25000, loss: 0.095508
 >> iter 26000, loss: 0.150961
 >> iter 27000, loss: 0.112016
 >> iter 28000, loss: 0.162711
 >> iter 29000, loss: 0.156039
 >> iter 30000, loss: 0.071775
   Number of active neurons: 10
 >> iter 31000, loss: 0.036287
 >> iter 32000, loss: 0.135070
 >> iter 33000, loss: 0.058369
 >> iter 34000, loss: 0.077314
 >> iter 35000, loss: 0.099204
 >> iter 36000, loss: 0.098860
 >> iter 37000, loss: 0.067091
 >> iter 38000, loss: 0.121132
 >> iter 39000, loss: 0.079409
 >> iter 40000, loss: 0.035129
   Number of active neurons: 10
 >> iter 41000, loss: 0.023908
 >> iter 42000, loss: 0.051492
 >> iter 43000, loss: 0.040247
 >> iter 44000, loss: 0.108828
 >> iter 45000, loss: 0.089228
 >> iter 46000, loss: 0.040143
 >> iter 47000, loss: 0.040146
 >> iter 48000, loss: 0.034506
 >> iter 49000, loss: 0.123439
 >> iter 50000, loss: 0.124528
   Number of active neurons: 10
 >> iter 51000, loss: 0.101087
 >> iter 52000, loss: 0.045896
 >> iter 53000, loss: 0.042872
 >> iter 54000, loss: 0.066308
 >> iter 55000, loss: 0.029192
 >> iter 56000, loss: 0.026218
 >> iter 57000, loss: 0.013838
 >> iter 58000, loss: 0.019848
 >> iter 59000, loss: 0.018996
 >> iter 60000, loss: 0.026029
   Number of active neurons: 10
 >> iter 61000, loss: 0.027416
 >> iter 62000, loss: 0.016629
 >> iter 63000, loss: 0.064784
 >> iter 64000, loss: 0.054145
 >> iter 65000, loss: 0.096049
 >> iter 66000, loss: 0.056213
 >> iter 67000, loss: 0.046854
 >> iter 68000, loss: 0.079446
 >> iter 69000, loss: 0.099044
 >> iter 70000, loss: 0.098471
   Number of active neurons: 10
 >> iter 71000, loss: 0.079341
 >> iter 72000, loss: 0.046403
 >> iter 73000, loss: 0.022885
 >> iter 74000, loss: 0.097883
 >> iter 75000, loss: 0.072576
 >> iter 76000, loss: 0.073694
 >> iter 77000, loss: 0.031544
 >> iter 78000, loss: 0.117204
 >> iter 79000, loss: 0.106238
 >> iter 80000, loss: 0.052389
   Number of active neurons: 10
 >> iter 81000, loss: 0.049622
 >> iter 82000, loss: 0.055328
 >> iter 83000, loss: 0.040871
 >> iter 84000, loss: 0.093995
 >> iter 85000, loss: 0.052839
 >> iter 86000, loss: 0.070991
 >> iter 87000, loss: 0.036753
 >> iter 88000, loss: 0.020703
 >> iter 89000, loss: 0.033777
 >> iter 90000, loss: 0.015820
   Number of active neurons: 10
 >> iter 91000, loss: 0.009160
 >> iter 92000, loss: 0.020577
 >> iter 93000, loss: 0.095321
 >> iter 94000, loss: 0.106102
 >> iter 95000, loss: 0.048018
 >> iter 96000, loss: 0.044376
 >> iter 97000, loss: 0.040328
 >> iter 98000, loss: 0.033088
 >> iter 99000, loss: 0.018864
 >> iter 100000, loss: 0.051008
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.571291
 >> iter 2000, loss: 9.795576
 >> iter 3000, loss: 6.755157
 >> iter 4000, loss: 4.965228
 >> iter 5000, loss: 3.012439
 >> iter 6000, loss: 1.577998
 >> iter 7000, loss: 0.882551
 >> iter 8000, loss: 0.687975
 >> iter 9000, loss: 0.542757
 >> iter 10000, loss: 0.344454
   Number of active neurons: 10
 >> iter 11000, loss: 0.327955
 >> iter 12000, loss: 0.252292
 >> iter 13000, loss: 0.190251
 >> iter 14000, loss: 0.182291
 >> iter 15000, loss: 0.109855
 >> iter 16000, loss: 0.135196
 >> iter 17000, loss: 0.138312
 >> iter 18000, loss: 0.126427
 >> iter 19000, loss: 0.176011
 >> iter 20000, loss: 0.113742
   Number of active neurons: 10
 >> iter 21000, loss: 0.142079
 >> iter 22000, loss: 0.131556
 >> iter 23000, loss: 0.083707
 >> iter 24000, loss: 0.146322
 >> iter 25000, loss: 0.102260
 >> iter 26000, loss: 0.166005
 >> iter 27000, loss: 0.087107
 >> iter 28000, loss: 0.054237
 >> iter 29000, loss: 0.029928
 >> iter 30000, loss: 0.108776
   Number of active neurons: 10
 >> iter 31000, loss: 0.061680
 >> iter 32000, loss: 0.075543
 >> iter 33000, loss: 0.034190
 >> iter 34000, loss: 0.068353
 >> iter 35000, loss: 0.031700
 >> iter 36000, loss: 0.032002
 >> iter 37000, loss: 0.103109
 >> iter 38000, loss: 0.140952
 >> iter 39000, loss: 0.139633
 >> iter 40000, loss: 0.102139
   Number of active neurons: 10
 >> iter 41000, loss: 0.105221
 >> iter 42000, loss: 0.149616
 >> iter 43000, loss: 0.064433
 >> iter 44000, loss: 0.052191
 >> iter 45000, loss: 0.058663
 >> iter 46000, loss: 0.040782
 >> iter 47000, loss: 0.032052
 >> iter 48000, loss: 0.016352
 >> iter 49000, loss: 0.010322
 >> iter 50000, loss: 0.012247
   Number of active neurons: 10
 >> iter 51000, loss: 0.024273
 >> iter 52000, loss: 0.012722
 >> iter 53000, loss: 0.008757
 >> iter 54000, loss: 0.020920
 >> iter 55000, loss: 0.035701
 >> iter 56000, loss: 0.017985
 >> iter 57000, loss: 0.023166
 >> iter 58000, loss: 0.015391
 >> iter 59000, loss: 0.047404
 >> iter 60000, loss: 0.049868
   Number of active neurons: 10
 >> iter 61000, loss: 0.091228
 >> iter 62000, loss: 0.099160
 >> iter 63000, loss: 0.134088
 >> iter 64000, loss: 0.075502
 >> iter 65000, loss: 0.076132
 >> iter 66000, loss: 0.063649
 >> iter 67000, loss: 0.044712
 >> iter 68000, loss: 0.082045
 >> iter 69000, loss: 0.034609
 >> iter 70000, loss: 0.061554
   Number of active neurons: 10
 >> iter 71000, loss: 0.027515
 >> iter 72000, loss: 0.013631
 >> iter 73000, loss: 0.008103
 >> iter 74000, loss: 0.010198
 >> iter 75000, loss: 0.006686
 >> iter 76000, loss: 0.025141
 >> iter 77000, loss: 0.045144
 >> iter 78000, loss: 0.026223
 >> iter 79000, loss: 0.026933
 >> iter 80000, loss: 0.013806
   Number of active neurons: 10
 >> iter 81000, loss: 0.026793
 >> iter 82000, loss: 0.019767
 >> iter 83000, loss: 0.010498
 >> iter 84000, loss: 0.030408
 >> iter 85000, loss: 0.018828
 >> iter 86000, loss: 0.048957
 >> iter 87000, loss: 0.060830
 >> iter 88000, loss: 0.095715
 >> iter 89000, loss: 0.078294
 >> iter 90000, loss: 0.055870
   Number of active neurons: 10
 >> iter 91000, loss: 0.058516
 >> iter 92000, loss: 0.025127
 >> iter 93000, loss: 0.019057
 >> iter 94000, loss: 0.034964
 >> iter 95000, loss: 0.015915
 >> iter 96000, loss: 0.015245
 >> iter 97000, loss: 0.021587
 >> iter 98000, loss: 0.040727
 >> iter 99000, loss: 0.018692
 >> iter 100000, loss: 0.009162
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.022688
 >> iter 2000, loss: 9.930754
 >> iter 3000, loss: 6.392676
 >> iter 4000, loss: 3.366928
 >> iter 5000, loss: 1.928596
 >> iter 6000, loss: 1.318054
 >> iter 7000, loss: 0.907413
 >> iter 8000, loss: 0.738416
 >> iter 9000, loss: 0.537408
 >> iter 10000, loss: 0.357757
   Number of active neurons: 10
 >> iter 11000, loss: 0.282845
 >> iter 12000, loss: 0.249657
 >> iter 13000, loss: 0.307074
 >> iter 14000, loss: 0.305070
 >> iter 15000, loss: 0.250510
 >> iter 16000, loss: 0.228811
 >> iter 17000, loss: 0.177622
 >> iter 18000, loss: 0.100536
 >> iter 19000, loss: 0.101723
 >> iter 20000, loss: 0.163915
   Number of active neurons: 10
 >> iter 21000, loss: 0.099822
 >> iter 22000, loss: 0.210372
 >> iter 23000, loss: 0.180737
 >> iter 24000, loss: 0.143292
 >> iter 25000, loss: 0.092945
 >> iter 26000, loss: 0.074780
 >> iter 27000, loss: 0.107117
 >> iter 28000, loss: 0.119883
 >> iter 29000, loss: 0.085784
 >> iter 30000, loss: 0.059882
   Number of active neurons: 10
 >> iter 31000, loss: 0.032315
 >> iter 32000, loss: 0.088760
 >> iter 33000, loss: 0.058827
 >> iter 34000, loss: 0.087185
 >> iter 35000, loss: 0.065952
 >> iter 36000, loss: 0.088822
 >> iter 37000, loss: 0.039762
 >> iter 38000, loss: 0.047979
 >> iter 39000, loss: 0.058765
 >> iter 40000, loss: 0.098765
   Number of active neurons: 10
 >> iter 41000, loss: 0.053810
 >> iter 42000, loss: 0.034734
 >> iter 43000, loss: 0.025587
 >> iter 44000, loss: 0.036227
 >> iter 45000, loss: 0.092234
 >> iter 46000, loss: 0.053753
 >> iter 47000, loss: 0.035744
 >> iter 48000, loss: 0.018357
 >> iter 49000, loss: 0.011210
 >> iter 50000, loss: 0.008371
   Number of active neurons: 10
 >> iter 51000, loss: 0.046976
 >> iter 52000, loss: 0.020826
 >> iter 53000, loss: 0.083365
 >> iter 54000, loss: 0.083329
 >> iter 55000, loss: 0.045575
 >> iter 56000, loss: 0.021074
 >> iter 57000, loss: 0.013281
 >> iter 58000, loss: 0.078328
 >> iter 59000, loss: 0.032440
 >> iter 60000, loss: 0.049192
   Number of active neurons: 10
 >> iter 61000, loss: 0.118609
 >> iter 62000, loss: 0.099185
 >> iter 63000, loss: 0.105059
 >> iter 64000, loss: 0.046630
 >> iter 65000, loss: 0.023836
 >> iter 66000, loss: 0.045562
 >> iter 67000, loss: 0.040047
 >> iter 68000, loss: 0.018421
 >> iter 69000, loss: 0.016111
 >> iter 70000, loss: 0.140293
   Number of active neurons: 10
 >> iter 71000, loss: 0.057454
 >> iter 72000, loss: 0.065242
 >> iter 73000, loss: 0.031405
 >> iter 74000, loss: 0.040202
 >> iter 75000, loss: 0.026037
 >> iter 76000, loss: 0.041570
 >> iter 77000, loss: 0.047279
 >> iter 78000, loss: 0.020497
 >> iter 79000, loss: 0.010502
 >> iter 80000, loss: 0.041741
   Number of active neurons: 10
 >> iter 81000, loss: 0.024291
 >> iter 82000, loss: 0.045944
 >> iter 83000, loss: 0.106058
 >> iter 84000, loss: 0.064285
 >> iter 85000, loss: 0.035638
 >> iter 86000, loss: 0.018527
 >> iter 87000, loss: 0.037617
 >> iter 88000, loss: 0.016741
 >> iter 89000, loss: 0.018161
 >> iter 90000, loss: 0.026270
   Number of active neurons: 10
 >> iter 91000, loss: 0.016091
 >> iter 92000, loss: 0.009422
 >> iter 93000, loss: 0.007587
 >> iter 94000, loss: 0.004992
 >> iter 95000, loss: 0.019052
 >> iter 96000, loss: 0.009056
 >> iter 97000, loss: 0.062220
 >> iter 98000, loss: 0.032138
 >> iter 99000, loss: 0.046099
 >> iter 100000, loss: 0.034689
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.869908
 >> iter 2000, loss: 10.117587
 >> iter 3000, loss: 7.515658
 >> iter 4000, loss: 6.246798
 >> iter 5000, loss: 5.354357
 >> iter 6000, loss: 4.062211
 >> iter 7000, loss: 3.305945
 >> iter 8000, loss: 2.795744
 >> iter 9000, loss: 2.143152
 >> iter 10000, loss: 1.455264
   Number of active neurons: 10
 >> iter 11000, loss: 1.439031
 >> iter 12000, loss: 1.238560
 >> iter 13000, loss: 1.076290
 >> iter 14000, loss: 0.883572
 >> iter 15000, loss: 0.660612
 >> iter 16000, loss: 0.533789
 >> iter 17000, loss: 0.529330
 >> iter 18000, loss: 0.484234
 >> iter 19000, loss: 0.453531
 >> iter 20000, loss: 0.587240
   Number of active neurons: 10
 >> iter 21000, loss: 0.672484
 >> iter 22000, loss: 0.521765
 >> iter 23000, loss: 0.390281
 >> iter 24000, loss: 0.351955
 >> iter 25000, loss: 0.177438
 >> iter 26000, loss: 0.271052
 >> iter 27000, loss: 0.208171
 >> iter 28000, loss: 0.173357
 >> iter 29000, loss: 0.155038
 >> iter 30000, loss: 0.150056
   Number of active neurons: 10
 >> iter 31000, loss: 0.272737
 >> iter 32000, loss: 0.263425
 >> iter 33000, loss: 0.218795
 >> iter 34000, loss: 0.217217
 >> iter 35000, loss: 0.202292
 >> iter 36000, loss: 0.466854
 >> iter 37000, loss: 0.320830
 >> iter 38000, loss: 0.265712
 >> iter 39000, loss: 0.322626
 >> iter 40000, loss: 0.310740
   Number of active neurons: 10
 >> iter 41000, loss: 0.230554
 >> iter 42000, loss: 0.199365
 >> iter 43000, loss: 0.238848
 >> iter 44000, loss: 0.160223
 >> iter 45000, loss: 0.180486
 >> iter 46000, loss: 0.103295
 >> iter 47000, loss: 0.133582
 >> iter 48000, loss: 0.159772
 >> iter 49000, loss: 0.146231
 >> iter 50000, loss: 0.230607
   Number of active neurons: 10
 >> iter 51000, loss: 0.183879
 >> iter 52000, loss: 0.150906
 >> iter 53000, loss: 0.203655
 >> iter 54000, loss: 0.187473
 >> iter 55000, loss: 0.088514
 >> iter 56000, loss: 0.059567
 >> iter 57000, loss: 0.047697
 >> iter 58000, loss: 0.112405
 >> iter 59000, loss: 0.166623
 >> iter 60000, loss: 0.181818
   Number of active neurons: 10
 >> iter 61000, loss: 0.088168
 >> iter 62000, loss: 0.096560
 >> iter 63000, loss: 0.123831
 >> iter 64000, loss: 0.069729
 >> iter 65000, loss: 0.138449
 >> iter 66000, loss: 0.122942
 >> iter 67000, loss: 0.103054
 >> iter 68000, loss: 0.152807
 >> iter 69000, loss: 0.092752
 >> iter 70000, loss: 0.059820
   Number of active neurons: 10
 >> iter 71000, loss: 0.058247
 >> iter 72000, loss: 0.067423
 >> iter 73000, loss: 0.074737
 >> iter 74000, loss: 0.055762
 >> iter 75000, loss: 0.154176
 >> iter 76000, loss: 0.160036
 >> iter 77000, loss: 0.201415
 >> iter 78000, loss: 0.189981
 >> iter 79000, loss: 0.123460
 >> iter 80000, loss: 0.150815
   Number of active neurons: 10
 >> iter 81000, loss: 0.103340
 >> iter 82000, loss: 0.141266
 >> iter 83000, loss: 0.092678
 >> iter 84000, loss: 0.053709
 >> iter 85000, loss: 0.036543
 >> iter 86000, loss: 0.117300
 >> iter 87000, loss: 0.091588
 >> iter 88000, loss: 0.087975
 >> iter 89000, loss: 0.089872
 >> iter 90000, loss: 0.113091
   Number of active neurons: 10
 >> iter 91000, loss: 0.169606
 >> iter 92000, loss: 0.179154
 >> iter 93000, loss: 0.122005
 >> iter 94000, loss: 0.076490
 >> iter 95000, loss: 0.099592
 >> iter 96000, loss: 0.091075
 >> iter 97000, loss: 0.131521
 >> iter 98000, loss: 0.057479
 >> iter 99000, loss: 0.046791
 >> iter 100000, loss: 0.036995
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.004244
 >> iter 2000, loss: 10.385221
 >> iter 3000, loss: 7.565578
 >> iter 4000, loss: 6.134788
 >> iter 5000, loss: 5.364246
 >> iter 6000, loss: 4.429266
 >> iter 7000, loss: 3.863012
 >> iter 8000, loss: 2.241819
 >> iter 9000, loss: 1.262181
 >> iter 10000, loss: 0.830366
   Number of active neurons: 10
 >> iter 11000, loss: 0.500592
 >> iter 12000, loss: 0.408659
 >> iter 13000, loss: 0.307530
 >> iter 14000, loss: 0.212286
 >> iter 15000, loss: 0.239853
 >> iter 16000, loss: 0.128778
 >> iter 17000, loss: 0.094379
 >> iter 18000, loss: 0.140652
 >> iter 19000, loss: 0.150252
 >> iter 20000, loss: 0.097597
   Number of active neurons: 10
 >> iter 21000, loss: 0.100473
 >> iter 22000, loss: 0.128021
 >> iter 23000, loss: 0.144331
 >> iter 24000, loss: 0.079342
 >> iter 25000, loss: 0.111280
 >> iter 26000, loss: 0.051259
 >> iter 27000, loss: 0.071498
 >> iter 28000, loss: 0.043358
 >> iter 29000, loss: 0.034965
 >> iter 30000, loss: 0.019358
   Number of active neurons: 10
 >> iter 31000, loss: 0.016313
 >> iter 32000, loss: 0.012753
 >> iter 33000, loss: 0.027280
 >> iter 34000, loss: 0.030393
 >> iter 35000, loss: 0.022968
 >> iter 36000, loss: 0.063622
 >> iter 37000, loss: 0.054812
 >> iter 38000, loss: 0.030611
 >> iter 39000, loss: 0.021747
 >> iter 40000, loss: 0.012237
   Number of active neurons: 10
 >> iter 41000, loss: 0.008295
 >> iter 42000, loss: 0.025672
 >> iter 43000, loss: 0.056321
 >> iter 44000, loss: 0.039674
 >> iter 45000, loss: 0.017511
 >> iter 46000, loss: 0.008814
 >> iter 47000, loss: 0.031249
 >> iter 48000, loss: 0.044584
 >> iter 49000, loss: 0.051923
 >> iter 50000, loss: 0.040988
   Number of active neurons: 10
 >> iter 51000, loss: 0.057235
 >> iter 52000, loss: 0.120320
 >> iter 53000, loss: 0.061585
 >> iter 54000, loss: 0.060481
 >> iter 55000, loss: 0.043883
 >> iter 56000, loss: 0.018708
 >> iter 57000, loss: 0.042225
 >> iter 58000, loss: 0.018596
 >> iter 59000, loss: 0.093094
 >> iter 60000, loss: 0.052510
   Number of active neurons: 10
 >> iter 61000, loss: 0.022175
 >> iter 62000, loss: 0.029359
 >> iter 63000, loss: 0.017194
 >> iter 64000, loss: 0.034099
 >> iter 65000, loss: 0.016178
 >> iter 66000, loss: 0.008380
 >> iter 67000, loss: 0.029142
 >> iter 68000, loss: 0.012978
 >> iter 69000, loss: 0.009220
 >> iter 70000, loss: 0.014415
   Number of active neurons: 10
 >> iter 71000, loss: 0.041492
 >> iter 72000, loss: 0.056904
 >> iter 73000, loss: 0.023101
 >> iter 74000, loss: 0.010572
 >> iter 75000, loss: 0.028948
 >> iter 76000, loss: 0.054923
 >> iter 77000, loss: 0.022265
 >> iter 78000, loss: 0.067717
 >> iter 79000, loss: 0.028720
 >> iter 80000, loss: 0.012922
   Number of active neurons: 10
 >> iter 81000, loss: 0.008199
 >> iter 82000, loss: 0.015242
 >> iter 83000, loss: 0.027082
 >> iter 84000, loss: 0.022023
 >> iter 85000, loss: 0.023909
 >> iter 86000, loss: 0.010654
 >> iter 87000, loss: 0.017238
 >> iter 88000, loss: 0.025619
 >> iter 89000, loss: 0.012920
 >> iter 90000, loss: 0.075381
   Number of active neurons: 10
 >> iter 91000, loss: 0.033812
 >> iter 92000, loss: 0.023689
 >> iter 93000, loss: 0.010371
 >> iter 94000, loss: 0.032165
 >> iter 95000, loss: 0.025175
 >> iter 96000, loss: 0.025231
 >> iter 97000, loss: 0.037976
 >> iter 98000, loss: 0.017620
 >> iter 99000, loss: 0.008385
 >> iter 100000, loss: 0.015942
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.972607
 >> iter 2000, loss: 10.317948
 >> iter 3000, loss: 7.670759
 >> iter 4000, loss: 5.264894
 >> iter 5000, loss: 3.016067
 >> iter 6000, loss: 1.391707
 >> iter 7000, loss: 0.913791
 >> iter 8000, loss: 0.536148
 >> iter 9000, loss: 0.380865
 >> iter 10000, loss: 0.289597
   Number of active neurons: 10
 >> iter 11000, loss: 0.217695
 >> iter 12000, loss: 0.123809
 >> iter 13000, loss: 0.114318
 >> iter 14000, loss: 0.151053
 >> iter 15000, loss: 0.129426
 >> iter 16000, loss: 0.151019
 >> iter 17000, loss: 0.100968
 >> iter 18000, loss: 0.090485
 >> iter 19000, loss: 0.108995
 >> iter 20000, loss: 0.115965
   Number of active neurons: 10
 >> iter 21000, loss: 0.075948
 >> iter 22000, loss: 0.102258
 >> iter 23000, loss: 0.074834
 >> iter 24000, loss: 0.037420
 >> iter 25000, loss: 0.065622
 >> iter 26000, loss: 0.064758
 >> iter 27000, loss: 0.129417
 >> iter 28000, loss: 0.093386
 >> iter 29000, loss: 0.060873
 >> iter 30000, loss: 0.030712
   Number of active neurons: 10
 >> iter 31000, loss: 0.016303
 >> iter 32000, loss: 0.043525
 >> iter 33000, loss: 0.042227
 >> iter 34000, loss: 0.055194
 >> iter 35000, loss: 0.094392
 >> iter 36000, loss: 0.109254
 >> iter 37000, loss: 0.049995
 >> iter 38000, loss: 0.027251
 >> iter 39000, loss: 0.036755
 >> iter 40000, loss: 0.017663
   Number of active neurons: 10
 >> iter 41000, loss: 0.010559
 >> iter 42000, loss: 0.047973
 >> iter 43000, loss: 0.062240
 >> iter 44000, loss: 0.098359
 >> iter 45000, loss: 0.090683
 >> iter 46000, loss: 0.039312
 >> iter 47000, loss: 0.123260
 >> iter 48000, loss: 0.117542
 >> iter 49000, loss: 0.069795
 >> iter 50000, loss: 0.041092
   Number of active neurons: 10
 >> iter 51000, loss: 0.028485
 >> iter 52000, loss: 0.014832
 >> iter 53000, loss: 0.013234
 >> iter 54000, loss: 0.008217
 >> iter 55000, loss: 0.006539
 >> iter 56000, loss: 0.005388
 >> iter 57000, loss: 0.011902
 >> iter 58000, loss: 0.020003
 >> iter 59000, loss: 0.088130
 >> iter 60000, loss: 0.058582
   Number of active neurons: 10
 >> iter 61000, loss: 0.046706
 >> iter 62000, loss: 0.052444
 >> iter 63000, loss: 0.022670
 >> iter 64000, loss: 0.011651
 >> iter 65000, loss: 0.018608
 >> iter 66000, loss: 0.158968
 >> iter 67000, loss: 0.093771
 >> iter 68000, loss: 0.078069
 >> iter 69000, loss: 0.037667
 >> iter 70000, loss: 0.017147
   Number of active neurons: 10
 >> iter 71000, loss: 0.034513
 >> iter 72000, loss: 0.034853
 >> iter 73000, loss: 0.016802
 >> iter 74000, loss: 0.031354
 >> iter 75000, loss: 0.073598
 >> iter 76000, loss: 0.044650
 >> iter 77000, loss: 0.024447
 >> iter 78000, loss: 0.095198
 >> iter 79000, loss: 0.039104
 >> iter 80000, loss: 0.017072
   Number of active neurons: 10
 >> iter 81000, loss: 0.035296
 >> iter 82000, loss: 0.015402
 >> iter 83000, loss: 0.122390
 >> iter 84000, loss: 0.070999
 >> iter 85000, loss: 0.031673
 >> iter 86000, loss: 0.067488
 >> iter 87000, loss: 0.029378
 >> iter 88000, loss: 0.044074
 >> iter 89000, loss: 0.043084
 >> iter 90000, loss: 0.020644
   Number of active neurons: 10
 >> iter 91000, loss: 0.032228
 >> iter 92000, loss: 0.029894
 >> iter 93000, loss: 0.013605
 >> iter 94000, loss: 0.035294
 >> iter 95000, loss: 0.034276
 >> iter 96000, loss: 0.067478
 >> iter 97000, loss: 0.085426
 >> iter 98000, loss: 0.051391
 >> iter 99000, loss: 0.024672
 >> iter 100000, loss: 0.011947
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.679260
 >> iter 2000, loss: 10.141388
 >> iter 3000, loss: 7.224389
 >> iter 4000, loss: 5.488148
 >> iter 5000, loss: 3.897426
 >> iter 6000, loss: 2.360171
 >> iter 7000, loss: 1.429846
 >> iter 8000, loss: 0.972487
 >> iter 9000, loss: 0.726407
 >> iter 10000, loss: 0.615213
   Number of active neurons: 10
 >> iter 11000, loss: 0.451454
 >> iter 12000, loss: 0.370202
 >> iter 13000, loss: 0.282629
 >> iter 14000, loss: 0.223820
 >> iter 15000, loss: 0.230854
 >> iter 16000, loss: 0.212240
 >> iter 17000, loss: 0.238879
 >> iter 18000, loss: 0.284888
 >> iter 19000, loss: 0.222184
 >> iter 20000, loss: 0.229199
   Number of active neurons: 10
 >> iter 21000, loss: 0.174081
 >> iter 22000, loss: 0.226813
 >> iter 23000, loss: 0.270208
 >> iter 24000, loss: 0.279161
 >> iter 25000, loss: 0.198112
 >> iter 26000, loss: 0.259768
 >> iter 27000, loss: 0.157535
 >> iter 28000, loss: 0.178205
 >> iter 29000, loss: 0.172718
 >> iter 30000, loss: 0.094902
   Number of active neurons: 10
 >> iter 31000, loss: 0.097564
 >> iter 32000, loss: 0.067433
 >> iter 33000, loss: 0.116310
 >> iter 34000, loss: 0.134868
 >> iter 35000, loss: 0.077083
 >> iter 36000, loss: 0.036209
 >> iter 37000, loss: 0.065071
 >> iter 38000, loss: 0.105554
 >> iter 39000, loss: 0.131367
 >> iter 40000, loss: 0.098350
   Number of active neurons: 10
 >> iter 41000, loss: 0.114591
 >> iter 42000, loss: 0.078831
 >> iter 43000, loss: 0.099150
 >> iter 44000, loss: 0.105917
 >> iter 45000, loss: 0.096428
 >> iter 46000, loss: 0.109140
 >> iter 47000, loss: 0.110230
 >> iter 48000, loss: 0.067311
 >> iter 49000, loss: 0.044390
 >> iter 50000, loss: 0.051641
   Number of active neurons: 10
 >> iter 51000, loss: 0.065956
 >> iter 52000, loss: 0.047434
 >> iter 53000, loss: 0.030336
 >> iter 54000, loss: 0.034869
 >> iter 55000, loss: 0.105535
 >> iter 56000, loss: 0.071535
 >> iter 57000, loss: 0.094174
 >> iter 58000, loss: 0.044328
 >> iter 59000, loss: 0.123357
 >> iter 60000, loss: 0.265650
   Number of active neurons: 10
 >> iter 61000, loss: 0.147192
 >> iter 62000, loss: 0.125271
 >> iter 63000, loss: 0.082213
 >> iter 64000, loss: 0.128197
 >> iter 65000, loss: 0.092686
 >> iter 66000, loss: 0.099223
 >> iter 67000, loss: 0.054757
 >> iter 68000, loss: 0.039702
 >> iter 69000, loss: 0.020465
 >> iter 70000, loss: 0.077468
   Number of active neurons: 10
 >> iter 71000, loss: 0.034163
 >> iter 72000, loss: 0.055501
 >> iter 73000, loss: 0.025876
 >> iter 74000, loss: 0.015608
 >> iter 75000, loss: 0.027578
 >> iter 76000, loss: 0.056483
 >> iter 77000, loss: 0.048490
 >> iter 78000, loss: 0.033844
 >> iter 79000, loss: 0.043114
 >> iter 80000, loss: 0.081711
   Number of active neurons: 10
 >> iter 81000, loss: 0.091267
 >> iter 82000, loss: 0.039090
 >> iter 83000, loss: 0.061480
 >> iter 84000, loss: 0.039055
 >> iter 85000, loss: 0.033325
 >> iter 86000, loss: 0.051968
 >> iter 87000, loss: 0.022805
 >> iter 88000, loss: 0.051505
 >> iter 89000, loss: 0.041183
 >> iter 90000, loss: 0.027377
   Number of active neurons: 10
 >> iter 91000, loss: 0.032806
 >> iter 92000, loss: 0.125848
 >> iter 93000, loss: 0.086211
 >> iter 94000, loss: 0.043150
 >> iter 95000, loss: 0.044872
 >> iter 96000, loss: 0.035408
 >> iter 97000, loss: 0.066614
 >> iter 98000, loss: 0.060173
 >> iter 99000, loss: 0.040772
 >> iter 100000, loss: 0.066609
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.894962
 >> iter 2000, loss: 10.153199
 >> iter 3000, loss: 7.360598
 >> iter 4000, loss: 5.480090
 >> iter 5000, loss: 3.973203
 >> iter 6000, loss: 2.267390
 >> iter 7000, loss: 1.639810
 >> iter 8000, loss: 1.107100
 >> iter 9000, loss: 0.927926
 >> iter 10000, loss: 0.681837
   Number of active neurons: 10
 >> iter 11000, loss: 0.638995
 >> iter 12000, loss: 0.518100
 >> iter 13000, loss: 0.586132
 >> iter 14000, loss: 0.468155
 >> iter 15000, loss: 0.277127
 >> iter 16000, loss: 0.200235
 >> iter 17000, loss: 0.189183
 >> iter 18000, loss: 0.251033
 >> iter 19000, loss: 0.140897
 >> iter 20000, loss: 0.136605
   Number of active neurons: 10
 >> iter 21000, loss: 0.160670
 >> iter 22000, loss: 0.186220
 >> iter 23000, loss: 0.190228
 >> iter 24000, loss: 0.150069
 >> iter 25000, loss: 0.104294
 >> iter 26000, loss: 0.067224
 >> iter 27000, loss: 0.047588
 >> iter 28000, loss: 0.069566
 >> iter 29000, loss: 0.072150
 >> iter 30000, loss: 0.129460
   Number of active neurons: 10
 >> iter 31000, loss: 0.146020
 >> iter 32000, loss: 0.088932
 >> iter 33000, loss: 0.194403
 >> iter 34000, loss: 0.150981
 >> iter 35000, loss: 0.172405
 >> iter 36000, loss: 0.230029
 >> iter 37000, loss: 0.127905
 >> iter 38000, loss: 0.150931
 >> iter 39000, loss: 0.094365
 >> iter 40000, loss: 0.069596
   Number of active neurons: 10
 >> iter 41000, loss: 0.043932
 >> iter 42000, loss: 0.047003
 >> iter 43000, loss: 0.053049
 >> iter 44000, loss: 0.051704
 >> iter 45000, loss: 0.027357
 >> iter 46000, loss: 0.024898
 >> iter 47000, loss: 0.099182
 >> iter 48000, loss: 0.099424
 >> iter 49000, loss: 0.043657
 >> iter 50000, loss: 0.074381
   Number of active neurons: 10
 >> iter 51000, loss: 0.034522
 >> iter 52000, loss: 0.033857
 >> iter 53000, loss: 0.022762
 >> iter 54000, loss: 0.028124
 >> iter 55000, loss: 0.069418
 >> iter 56000, loss: 0.035136
 >> iter 57000, loss: 0.069356
 >> iter 58000, loss: 0.061554
 >> iter 59000, loss: 0.083135
 >> iter 60000, loss: 0.039861
   Number of active neurons: 10
 >> iter 61000, loss: 0.020142
 >> iter 62000, loss: 0.012367
 >> iter 63000, loss: 0.035536
 >> iter 64000, loss: 0.057496
 >> iter 65000, loss: 0.031220
 >> iter 66000, loss: 0.034522
 >> iter 67000, loss: 0.016736
 >> iter 68000, loss: 0.010335
 >> iter 69000, loss: 0.014321
 >> iter 70000, loss: 0.047771
   Number of active neurons: 10
 >> iter 71000, loss: 0.053693
 >> iter 72000, loss: 0.114144
 >> iter 73000, loss: 0.091962
 >> iter 74000, loss: 0.039842
 >> iter 75000, loss: 0.032453
 >> iter 76000, loss: 0.016055
 >> iter 77000, loss: 0.010116
 >> iter 78000, loss: 0.007204
 >> iter 79000, loss: 0.006699
 >> iter 80000, loss: 0.023500
   Number of active neurons: 10
 >> iter 81000, loss: 0.018890
 >> iter 82000, loss: 0.011159
 >> iter 83000, loss: 0.104255
 >> iter 84000, loss: 0.043899
 >> iter 85000, loss: 0.033420
 >> iter 86000, loss: 0.024451
 >> iter 87000, loss: 0.012243
 >> iter 88000, loss: 0.012631
 >> iter 89000, loss: 0.018455
 >> iter 90000, loss: 0.037436
   Number of active neurons: 10
 >> iter 91000, loss: 0.053328
 >> iter 92000, loss: 0.023370
 >> iter 93000, loss: 0.014698
 >> iter 94000, loss: 0.007887
 >> iter 95000, loss: 0.085746
 >> iter 96000, loss: 0.093115
 >> iter 97000, loss: 0.067661
 >> iter 98000, loss: 0.054190
 >> iter 99000, loss: 0.033562
 >> iter 100000, loss: 0.022440
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.824272
 >> iter 2000, loss: 10.276417
 >> iter 3000, loss: 7.541411
 >> iter 4000, loss: 5.887525
 >> iter 5000, loss: 4.839130
 >> iter 6000, loss: 3.121645
 >> iter 7000, loss: 1.867031
 >> iter 8000, loss: 1.210591
 >> iter 9000, loss: 0.733596
 >> iter 10000, loss: 0.562860
   Number of active neurons: 10
 >> iter 11000, loss: 0.425813
 >> iter 12000, loss: 0.430541
 >> iter 13000, loss: 0.328193
 >> iter 14000, loss: 0.411734
 >> iter 15000, loss: 0.269725
 >> iter 16000, loss: 0.254876
 >> iter 17000, loss: 0.443896
 >> iter 18000, loss: 0.385954
 >> iter 19000, loss: 0.282051
 >> iter 20000, loss: 0.221258
   Number of active neurons: 10
 >> iter 21000, loss: 0.207607
 >> iter 22000, loss: 0.151169
 >> iter 23000, loss: 0.180539
 >> iter 24000, loss: 0.112537
 >> iter 25000, loss: 0.214923
 >> iter 26000, loss: 0.189699
 >> iter 27000, loss: 0.082224
 >> iter 28000, loss: 0.042163
 >> iter 29000, loss: 0.094863
 >> iter 30000, loss: 0.074673
   Number of active neurons: 10
 >> iter 31000, loss: 0.097259
 >> iter 32000, loss: 0.061269
 >> iter 33000, loss: 0.051645
 >> iter 34000, loss: 0.028447
 >> iter 35000, loss: 0.078216
 >> iter 36000, loss: 0.035270
 >> iter 37000, loss: 0.051209
 >> iter 38000, loss: 0.025073
 >> iter 39000, loss: 0.067090
 >> iter 40000, loss: 0.160079
   Number of active neurons: 10
 >> iter 41000, loss: 0.072551
 >> iter 42000, loss: 0.092569
 >> iter 43000, loss: 0.052910
 >> iter 44000, loss: 0.126580
 >> iter 45000, loss: 0.084513
 >> iter 46000, loss: 0.036476
 >> iter 47000, loss: 0.018595
 >> iter 48000, loss: 0.027825
 >> iter 49000, loss: 0.101905
 >> iter 50000, loss: 0.073834
   Number of active neurons: 10
 >> iter 51000, loss: 0.112238
 >> iter 52000, loss: 0.060148
 >> iter 53000, loss: 0.028252
 >> iter 54000, loss: 0.029661
 >> iter 55000, loss: 0.049594
 >> iter 56000, loss: 0.036610
 >> iter 57000, loss: 0.020431
 >> iter 58000, loss: 0.060734
 >> iter 59000, loss: 0.109593
 >> iter 60000, loss: 0.087195
   Number of active neurons: 10
 >> iter 61000, loss: 0.099402
 >> iter 62000, loss: 0.050490
 >> iter 63000, loss: 0.026727
 >> iter 64000, loss: 0.045457
 >> iter 65000, loss: 0.041400
 >> iter 66000, loss: 0.034716
 >> iter 67000, loss: 0.111911
 >> iter 68000, loss: 0.095157
 >> iter 69000, loss: 0.040395
 >> iter 70000, loss: 0.022887
   Number of active neurons: 10
 >> iter 71000, loss: 0.027428
 >> iter 72000, loss: 0.014012
 >> iter 73000, loss: 0.038616
 >> iter 74000, loss: 0.018441
 >> iter 75000, loss: 0.010022
 >> iter 76000, loss: 0.006512
 >> iter 77000, loss: 0.021970
 >> iter 78000, loss: 0.011623
 >> iter 79000, loss: 0.010893
 >> iter 80000, loss: 0.006635
   Number of active neurons: 10
 >> iter 81000, loss: 0.006029
 >> iter 82000, loss: 0.004412
 >> iter 83000, loss: 0.007108
 >> iter 84000, loss: 0.046010
 >> iter 85000, loss: 0.019284
 >> iter 86000, loss: 0.009085
 >> iter 87000, loss: 0.005337
 >> iter 88000, loss: 0.003783
 >> iter 89000, loss: 0.031524
 >> iter 90000, loss: 0.023625
   Number of active neurons: 10
 >> iter 91000, loss: 0.011033
 >> iter 92000, loss: 0.005843
 >> iter 93000, loss: 0.003869
 >> iter 94000, loss: 0.002993
 >> iter 95000, loss: 0.019010
 >> iter 96000, loss: 0.009442
 >> iter 97000, loss: 0.005135
 >> iter 98000, loss: 0.025776
 >> iter 99000, loss: 0.028033
 >> iter 100000, loss: 0.031441
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 17.507981
 >> iter 2000, loss: 10.549144
 >> iter 3000, loss: 7.448077
 >> iter 4000, loss: 5.430017
 >> iter 5000, loss: 3.216854
 >> iter 6000, loss: 1.630848
 >> iter 7000, loss: 0.971409
 >> iter 8000, loss: 0.677079
 >> iter 9000, loss: 0.391783
 >> iter 10000, loss: 0.380897
   Number of active neurons: 10
 >> iter 11000, loss: 0.315116
 >> iter 12000, loss: 0.241144
 >> iter 13000, loss: 0.320518
 >> iter 14000, loss: 0.202262
 >> iter 15000, loss: 0.220677
 >> iter 16000, loss: 0.219632
 >> iter 17000, loss: 0.244081
 >> iter 18000, loss: 0.177326
 >> iter 19000, loss: 0.143903
 >> iter 20000, loss: 0.172528
   Number of active neurons: 10
 >> iter 21000, loss: 0.107220
 >> iter 22000, loss: 0.098907
 >> iter 23000, loss: 0.046560
 >> iter 24000, loss: 0.049020
 >> iter 25000, loss: 0.082429
 >> iter 26000, loss: 0.069746
 >> iter 27000, loss: 0.067653
 >> iter 28000, loss: 0.089488
 >> iter 29000, loss: 0.044108
 >> iter 30000, loss: 0.046059
   Number of active neurons: 10
 >> iter 31000, loss: 0.077445
 >> iter 32000, loss: 0.061368
 >> iter 33000, loss: 0.027801
 >> iter 34000, loss: 0.022140
 >> iter 35000, loss: 0.011788
 >> iter 36000, loss: 0.061200
 >> iter 37000, loss: 0.087267
 >> iter 38000, loss: 0.111390
 >> iter 39000, loss: 0.063887
 >> iter 40000, loss: 0.134264
   Number of active neurons: 10
 >> iter 41000, loss: 0.058825
 >> iter 42000, loss: 0.041746
 >> iter 43000, loss: 0.034967
 >> iter 44000, loss: 0.098226
 >> iter 45000, loss: 0.070847
 >> iter 46000, loss: 0.067171
 >> iter 47000, loss: 0.119644
 >> iter 48000, loss: 0.078628
 >> iter 49000, loss: 0.062205
 >> iter 50000, loss: 0.082657
   Number of active neurons: 10
 >> iter 51000, loss: 0.035286
 >> iter 52000, loss: 0.016261
 >> iter 53000, loss: 0.032495
 >> iter 54000, loss: 0.031794
 >> iter 55000, loss: 0.030900
 >> iter 56000, loss: 0.084276
 >> iter 57000, loss: 0.105064
 >> iter 58000, loss: 0.044321
 >> iter 59000, loss: 0.041140
 >> iter 60000, loss: 0.097223
   Number of active neurons: 10
 >> iter 61000, loss: 0.053154
 >> iter 62000, loss: 0.063012
 >> iter 63000, loss: 0.054145
 >> iter 64000, loss: 0.023962
 >> iter 65000, loss: 0.017388
 >> iter 66000, loss: 0.015442
 >> iter 67000, loss: 0.009590
 >> iter 68000, loss: 0.083865
 >> iter 69000, loss: 0.035343
 >> iter 70000, loss: 0.015516
   Number of active neurons: 10
 >> iter 71000, loss: 0.008250
 >> iter 72000, loss: 0.005308
 >> iter 73000, loss: 0.010152
 >> iter 74000, loss: 0.044135
 >> iter 75000, loss: 0.018669
 >> iter 76000, loss: 0.050246
 >> iter 77000, loss: 0.042695
 >> iter 78000, loss: 0.063822
 >> iter 79000, loss: 0.069886
 >> iter 80000, loss: 0.032245
   Number of active neurons: 10
 >> iter 81000, loss: 0.014876
 >> iter 82000, loss: 0.037873
 >> iter 83000, loss: 0.083965
 >> iter 84000, loss: 0.157879
 >> iter 85000, loss: 0.062468
 >> iter 86000, loss: 0.026333
 >> iter 87000, loss: 0.027171
 >> iter 88000, loss: 0.027708
 >> iter 89000, loss: 0.023758
 >> iter 90000, loss: 0.011309
   Number of active neurons: 10
 >> iter 91000, loss: 0.014782
 >> iter 92000, loss: 0.075825
 >> iter 93000, loss: 0.030185
 >> iter 94000, loss: 0.013562
 >> iter 95000, loss: 0.007309
 >> iter 96000, loss: 0.004450
 >> iter 97000, loss: 0.028124
 >> iter 98000, loss: 0.046254
 >> iter 99000, loss: 0.103185
 >> iter 100000, loss: 0.045016
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.892839
 >> iter 2000, loss: 10.320918
 >> iter 3000, loss: 7.676527
 >> iter 4000, loss: 5.899374
 >> iter 5000, loss: 4.174120
 >> iter 6000, loss: 2.387494
 >> iter 7000, loss: 1.597230
 >> iter 8000, loss: 1.040081
 >> iter 9000, loss: 0.789407
 >> iter 10000, loss: 0.561804
   Number of active neurons: 10
 >> iter 11000, loss: 0.431101
 >> iter 12000, loss: 0.294549
 >> iter 13000, loss: 0.239492
 >> iter 14000, loss: 0.230897
 >> iter 15000, loss: 0.306674
 >> iter 16000, loss: 0.251531
 >> iter 17000, loss: 0.179154
 >> iter 18000, loss: 0.226785
 >> iter 19000, loss: 0.235052
 >> iter 20000, loss: 0.231191
   Number of active neurons: 10
 >> iter 21000, loss: 0.140185
 >> iter 22000, loss: 0.257661
 >> iter 23000, loss: 0.217518
 >> iter 24000, loss: 0.289751
 >> iter 25000, loss: 0.147007
 >> iter 26000, loss: 0.120142
 >> iter 27000, loss: 0.127332
 >> iter 28000, loss: 0.120268
 >> iter 29000, loss: 0.086164
 >> iter 30000, loss: 0.091508
   Number of active neurons: 10
 >> iter 31000, loss: 0.043783
 >> iter 32000, loss: 0.063942
 >> iter 33000, loss: 0.084085
 >> iter 34000, loss: 0.075206
 >> iter 35000, loss: 0.069924
 >> iter 36000, loss: 0.109522
 >> iter 37000, loss: 0.209807
 >> iter 38000, loss: 0.105494
 >> iter 39000, loss: 0.072329
 >> iter 40000, loss: 0.032948
   Number of active neurons: 10
 >> iter 41000, loss: 0.026544
 >> iter 42000, loss: 0.079365
 >> iter 43000, loss: 0.091446
 >> iter 44000, loss: 0.094099
 >> iter 45000, loss: 0.042089
 >> iter 46000, loss: 0.026242
 >> iter 47000, loss: 0.079307
 >> iter 48000, loss: 0.070177
 >> iter 49000, loss: 0.057823
 >> iter 50000, loss: 0.042103
   Number of active neurons: 10
 >> iter 51000, loss: 0.019557
 >> iter 52000, loss: 0.029603
 >> iter 53000, loss: 0.038746
 >> iter 54000, loss: 0.075156
 >> iter 55000, loss: 0.045335
 >> iter 56000, loss: 0.028577
 >> iter 57000, loss: 0.047360
 >> iter 58000, loss: 0.022758
 >> iter 59000, loss: 0.030570
 >> iter 60000, loss: 0.014045
   Number of active neurons: 10
 >> iter 61000, loss: 0.019636
 >> iter 62000, loss: 0.073547
 >> iter 63000, loss: 0.038075
 >> iter 64000, loss: 0.017047
 >> iter 65000, loss: 0.039102
 >> iter 66000, loss: 0.020870
 >> iter 67000, loss: 0.050316
 >> iter 68000, loss: 0.027068
 >> iter 69000, loss: 0.012627
 >> iter 70000, loss: 0.015896
   Number of active neurons: 10
 >> iter 71000, loss: 0.018154
 >> iter 72000, loss: 0.012594
 >> iter 73000, loss: 0.006920
 >> iter 74000, loss: 0.005582
 >> iter 75000, loss: 0.003847
 >> iter 76000, loss: 0.031971
 >> iter 77000, loss: 0.069141
 >> iter 78000, loss: 0.048380
 >> iter 79000, loss: 0.021652
 >> iter 80000, loss: 0.010400
   Number of active neurons: 10
 >> iter 81000, loss: 0.058968
 >> iter 82000, loss: 0.042270
 >> iter 83000, loss: 0.020287
 >> iter 84000, loss: 0.027894
 >> iter 85000, loss: 0.023587
 >> iter 86000, loss: 0.057464
 >> iter 87000, loss: 0.024453
 >> iter 88000, loss: 0.048225
 >> iter 89000, loss: 0.044264
 >> iter 90000, loss: 0.080138
   Number of active neurons: 10
 >> iter 91000, loss: 0.062796
 >> iter 92000, loss: 0.070208
 >> iter 93000, loss: 0.057343
 >> iter 94000, loss: 0.031502
 >> iter 95000, loss: 0.030738
 >> iter 96000, loss: 0.013880
 >> iter 97000, loss: 0.024505
 >> iter 98000, loss: 0.011553
 >> iter 99000, loss: 0.008984
 >> iter 100000, loss: 0.005281
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.098280
 >> iter 2000, loss: 10.268794
 >> iter 3000, loss: 7.497963
 >> iter 4000, loss: 5.510524
 >> iter 5000, loss: 3.695517
 >> iter 6000, loss: 1.966215
 >> iter 7000, loss: 1.202835
 >> iter 8000, loss: 0.581530
 >> iter 9000, loss: 0.422287
 >> iter 10000, loss: 0.488900
   Number of active neurons: 10
 >> iter 11000, loss: 0.369992
 >> iter 12000, loss: 0.288871
 >> iter 13000, loss: 0.244074
 >> iter 14000, loss: 0.185394
 >> iter 15000, loss: 0.208659
 >> iter 16000, loss: 0.126626
 >> iter 17000, loss: 0.210639
 >> iter 18000, loss: 0.117317
 >> iter 19000, loss: 0.094717
 >> iter 20000, loss: 0.070946
   Number of active neurons: 10
 >> iter 21000, loss: 0.053016
 >> iter 22000, loss: 0.114753
 >> iter 23000, loss: 0.121933
 >> iter 24000, loss: 0.111439
 >> iter 25000, loss: 0.074937
 >> iter 26000, loss: 0.063938
 >> iter 27000, loss: 0.077878
 >> iter 28000, loss: 0.116278
 >> iter 29000, loss: 0.099275
 >> iter 30000, loss: 0.049661
   Number of active neurons: 10
 >> iter 31000, loss: 0.073914
 >> iter 32000, loss: 0.066243
 >> iter 33000, loss: 0.092450
 >> iter 34000, loss: 0.049515
 >> iter 35000, loss: 0.047275
 >> iter 36000, loss: 0.064927
 >> iter 37000, loss: 0.101588
 >> iter 38000, loss: 0.063030
 >> iter 39000, loss: 0.044166
 >> iter 40000, loss: 0.032448
   Number of active neurons: 10
 >> iter 41000, loss: 0.015989
 >> iter 42000, loss: 0.024809
 >> iter 43000, loss: 0.060728
 >> iter 44000, loss: 0.061729
 >> iter 45000, loss: 0.068933
 >> iter 46000, loss: 0.029335
 >> iter 47000, loss: 0.070783
 >> iter 48000, loss: 0.037479
 >> iter 49000, loss: 0.018988
 >> iter 50000, loss: 0.021597
   Number of active neurons: 10
 >> iter 51000, loss: 0.027675
 >> iter 52000, loss: 0.021907
 >> iter 53000, loss: 0.020704
 >> iter 54000, loss: 0.033745
 >> iter 55000, loss: 0.015216
 >> iter 56000, loss: 0.008269
 >> iter 57000, loss: 0.005499
 >> iter 58000, loss: 0.004289
 >> iter 59000, loss: 0.004156
 >> iter 60000, loss: 0.003266
   Number of active neurons: 10
 >> iter 61000, loss: 0.022799
 >> iter 62000, loss: 0.011015
 >> iter 63000, loss: 0.060960
 >> iter 64000, loss: 0.064356
 >> iter 65000, loss: 0.050126
 >> iter 66000, loss: 0.118953
 >> iter 67000, loss: 0.050989
 >> iter 68000, loss: 0.062170
 >> iter 69000, loss: 0.046860
 >> iter 70000, loss: 0.059623
   Number of active neurons: 10
 >> iter 71000, loss: 0.052112
 >> iter 72000, loss: 0.022516
 >> iter 73000, loss: 0.049090
 >> iter 74000, loss: 0.035523
 >> iter 75000, loss: 0.037461
 >> iter 76000, loss: 0.020461
 >> iter 77000, loss: 0.032768
 >> iter 78000, loss: 0.031860
 >> iter 79000, loss: 0.014908
 >> iter 80000, loss: 0.031391
   Number of active neurons: 10
 >> iter 81000, loss: 0.035584
 >> iter 82000, loss: 0.019766
 >> iter 83000, loss: 0.010992
 >> iter 84000, loss: 0.008300
 >> iter 85000, loss: 0.009266
 >> iter 86000, loss: 0.008648
 >> iter 87000, loss: 0.015887
 >> iter 88000, loss: 0.007940
 >> iter 89000, loss: 0.055764
 >> iter 90000, loss: 0.027351
   Number of active neurons: 10
 >> iter 91000, loss: 0.013195
 >> iter 92000, loss: 0.006398
 >> iter 93000, loss: 0.012764
 >> iter 94000, loss: 0.006150
 >> iter 95000, loss: 0.003601
 >> iter 96000, loss: 0.002594
 >> iter 97000, loss: 0.029512
 >> iter 98000, loss: 0.012100
 >> iter 99000, loss: 0.017523
 >> iter 100000, loss: 0.007625
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.245379
 >> iter 2000, loss: 11.077595
 >> iter 3000, loss: 7.923422
 >> iter 4000, loss: 5.902962
 >> iter 5000, loss: 3.760227
 >> iter 6000, loss: 2.580710
 >> iter 7000, loss: 1.438517
 >> iter 8000, loss: 0.960763
 >> iter 9000, loss: 0.865538
 >> iter 10000, loss: 0.798060
   Number of active neurons: 10
 >> iter 11000, loss: 0.462316
 >> iter 12000, loss: 0.425770
 >> iter 13000, loss: 0.598464
 >> iter 14000, loss: 0.495237
 >> iter 15000, loss: 0.274523
 >> iter 16000, loss: 0.290882
 >> iter 17000, loss: 0.238591
 >> iter 18000, loss: 0.225979
 >> iter 19000, loss: 0.140495
 >> iter 20000, loss: 0.127413
   Number of active neurons: 10
 >> iter 21000, loss: 0.235529
 >> iter 22000, loss: 0.188040
 >> iter 23000, loss: 0.238555
 >> iter 24000, loss: 0.130962
 >> iter 25000, loss: 0.098771
 >> iter 26000, loss: 0.099103
 >> iter 27000, loss: 0.101582
 >> iter 28000, loss: 0.079191
 >> iter 29000, loss: 0.151454
 >> iter 30000, loss: 0.127783
   Number of active neurons: 10
 >> iter 31000, loss: 0.096840
 >> iter 32000, loss: 0.064217
 >> iter 33000, loss: 0.063663
 >> iter 34000, loss: 0.046286
 >> iter 35000, loss: 0.105544
 >> iter 36000, loss: 0.115994
 >> iter 37000, loss: 0.077027
 >> iter 38000, loss: 0.163339
 >> iter 39000, loss: 0.117856
 >> iter 40000, loss: 0.142994
   Number of active neurons: 10
 >> iter 41000, loss: 0.128904
 >> iter 42000, loss: 0.077714
 >> iter 43000, loss: 0.100977
 >> iter 44000, loss: 0.049739
 >> iter 45000, loss: 0.081085
 >> iter 46000, loss: 0.110625
 >> iter 47000, loss: 0.125967
 >> iter 48000, loss: 0.071448
 >> iter 49000, loss: 0.131033
 >> iter 50000, loss: 0.140399
   Number of active neurons: 10
 >> iter 51000, loss: 0.065017
 >> iter 52000, loss: 0.050719
 >> iter 53000, loss: 0.034751
 >> iter 54000, loss: 0.043469
 >> iter 55000, loss: 0.087404
 >> iter 56000, loss: 0.052321
 >> iter 57000, loss: 0.092396
 >> iter 58000, loss: 0.054110
 >> iter 59000, loss: 0.064196
 >> iter 60000, loss: 0.028036
   Number of active neurons: 10
 >> iter 61000, loss: 0.090192
 >> iter 62000, loss: 0.110331
 >> iter 63000, loss: 0.062752
 >> iter 64000, loss: 0.044679
 >> iter 65000, loss: 0.035793
 >> iter 66000, loss: 0.052052
 >> iter 67000, loss: 0.022919
 >> iter 68000, loss: 0.022809
 >> iter 69000, loss: 0.037415
 >> iter 70000, loss: 0.033177
   Number of active neurons: 10
 >> iter 71000, loss: 0.049837
 >> iter 72000, loss: 0.047174
 >> iter 73000, loss: 0.059629
 >> iter 74000, loss: 0.056618
 >> iter 75000, loss: 0.041359
 >> iter 76000, loss: 0.018584
 >> iter 77000, loss: 0.074453
 >> iter 78000, loss: 0.031119
 >> iter 79000, loss: 0.022363
 >> iter 80000, loss: 0.037205
   Number of active neurons: 10
 >> iter 81000, loss: 0.031487
 >> iter 82000, loss: 0.046452
 >> iter 83000, loss: 0.026346
 >> iter 84000, loss: 0.103583
 >> iter 85000, loss: 0.062950
 >> iter 86000, loss: 0.026696
 >> iter 87000, loss: 0.092871
 >> iter 88000, loss: 0.054676
 >> iter 89000, loss: 0.070001
 >> iter 90000, loss: 0.160232
   Number of active neurons: 10
 >> iter 91000, loss: 0.112632
 >> iter 92000, loss: 0.095952
 >> iter 93000, loss: 0.054766
 >> iter 94000, loss: 0.024964
 >> iter 95000, loss: 0.013638
 >> iter 96000, loss: 0.043611
 >> iter 97000, loss: 0.045988
 >> iter 98000, loss: 0.053804
 >> iter 99000, loss: 0.065887
 >> iter 100000, loss: 0.070985
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.341336
 >> iter 2000, loss: 10.421072
 >> iter 3000, loss: 6.009377
 >> iter 4000, loss: 3.072253
 >> iter 5000, loss: 1.638530
 >> iter 6000, loss: 1.047536
 >> iter 7000, loss: 0.785748
 >> iter 8000, loss: 0.635709
 >> iter 9000, loss: 0.416794
 >> iter 10000, loss: 0.413497
   Number of active neurons: 10
 >> iter 11000, loss: 0.336134
 >> iter 12000, loss: 0.248984
 >> iter 13000, loss: 0.234067
 >> iter 14000, loss: 0.268127
 >> iter 15000, loss: 0.217806
 >> iter 16000, loss: 0.255048
 >> iter 17000, loss: 0.264729
 >> iter 18000, loss: 0.245612
 >> iter 19000, loss: 0.152449
 >> iter 20000, loss: 0.132498
   Number of active neurons: 10
 >> iter 21000, loss: 0.275295
 >> iter 22000, loss: 0.139176
 >> iter 23000, loss: 0.118570
 >> iter 24000, loss: 0.189922
 >> iter 25000, loss: 0.195146
 >> iter 26000, loss: 0.278553
 >> iter 27000, loss: 0.299369
 >> iter 28000, loss: 0.190387
 >> iter 29000, loss: 0.117004
 >> iter 30000, loss: 0.102276
   Number of active neurons: 10
 >> iter 31000, loss: 0.123420
 >> iter 32000, loss: 0.126340
 >> iter 33000, loss: 0.128993
 >> iter 34000, loss: 0.094241
 >> iter 35000, loss: 0.114793
 >> iter 36000, loss: 0.095640
 >> iter 37000, loss: 0.059838
 >> iter 38000, loss: 0.037667
 >> iter 39000, loss: 0.073311
 >> iter 40000, loss: 0.110147
   Number of active neurons: 10
 >> iter 41000, loss: 0.112488
 >> iter 42000, loss: 0.137804
 >> iter 43000, loss: 0.077038
 >> iter 44000, loss: 0.083984
 >> iter 45000, loss: 0.071923
 >> iter 46000, loss: 0.044903
 >> iter 47000, loss: 0.157512
 >> iter 48000, loss: 0.109629
 >> iter 49000, loss: 0.048597
 >> iter 50000, loss: 0.061476
   Number of active neurons: 10
 >> iter 51000, loss: 0.029031
 >> iter 52000, loss: 0.043385
 >> iter 53000, loss: 0.029660
 >> iter 54000, loss: 0.095186
 >> iter 55000, loss: 0.052470
 >> iter 56000, loss: 0.053463
 >> iter 57000, loss: 0.024625
 >> iter 58000, loss: 0.065195
 >> iter 59000, loss: 0.062252
 >> iter 60000, loss: 0.069287
   Number of active neurons: 10
 >> iter 61000, loss: 0.043374
 >> iter 62000, loss: 0.073329
 >> iter 63000, loss: 0.077872
 >> iter 64000, loss: 0.065652
 >> iter 65000, loss: 0.033542
 >> iter 66000, loss: 0.033549
 >> iter 67000, loss: 0.016746
 >> iter 68000, loss: 0.020297
 >> iter 69000, loss: 0.023971
 >> iter 70000, loss: 0.012319
   Number of active neurons: 10
 >> iter 71000, loss: 0.042559
 >> iter 72000, loss: 0.052121
 >> iter 73000, loss: 0.025233
 >> iter 74000, loss: 0.049070
 >> iter 75000, loss: 0.028522
 >> iter 76000, loss: 0.075117
 >> iter 77000, loss: 0.060091
 >> iter 78000, loss: 0.063809
 >> iter 79000, loss: 0.086377
 >> iter 80000, loss: 0.047112
   Number of active neurons: 10
 >> iter 81000, loss: 0.068452
 >> iter 82000, loss: 0.074992
 >> iter 83000, loss: 0.032762
 >> iter 84000, loss: 0.016390
 >> iter 85000, loss: 0.020463
 >> iter 86000, loss: 0.010993
 >> iter 87000, loss: 0.007216
 >> iter 88000, loss: 0.034247
 >> iter 89000, loss: 0.042279
 >> iter 90000, loss: 0.050812
   Number of active neurons: 10
 >> iter 91000, loss: 0.067698
 >> iter 92000, loss: 0.030115
 >> iter 93000, loss: 0.023382
 >> iter 94000, loss: 0.046966
 >> iter 95000, loss: 0.036931
 >> iter 96000, loss: 0.035220
 >> iter 97000, loss: 0.024317
 >> iter 98000, loss: 0.019256
 >> iter 99000, loss: 0.012207
 >> iter 100000, loss: 0.062286
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.948690
 >> iter 2000, loss: 10.409165
 >> iter 3000, loss: 7.501536
 >> iter 4000, loss: 5.892013
 >> iter 5000, loss: 4.558451
 >> iter 6000, loss: 2.625032
 >> iter 7000, loss: 1.550067
 >> iter 8000, loss: 0.916469
 >> iter 9000, loss: 0.632191
 >> iter 10000, loss: 0.398641
   Number of active neurons: 10
 >> iter 11000, loss: 0.271649
 >> iter 12000, loss: 0.259031
 >> iter 13000, loss: 0.145759
 >> iter 14000, loss: 0.213204
 >> iter 15000, loss: 0.172557
 >> iter 16000, loss: 0.203021
 >> iter 17000, loss: 0.114993
 >> iter 18000, loss: 0.117993
 >> iter 19000, loss: 0.087171
 >> iter 20000, loss: 0.105576
   Number of active neurons: 10
 >> iter 21000, loss: 0.055674
 >> iter 22000, loss: 0.147851
 >> iter 23000, loss: 0.124003
 >> iter 24000, loss: 0.132052
 >> iter 25000, loss: 0.108723
 >> iter 26000, loss: 0.185650
 >> iter 27000, loss: 0.146570
 >> iter 28000, loss: 0.135779
 >> iter 29000, loss: 0.076320
 >> iter 30000, loss: 0.164789
   Number of active neurons: 10
 >> iter 31000, loss: 0.098568
 >> iter 32000, loss: 0.103819
 >> iter 33000, loss: 0.078147
 >> iter 34000, loss: 0.034788
 >> iter 35000, loss: 0.053411
 >> iter 36000, loss: 0.086947
 >> iter 37000, loss: 0.038533
 >> iter 38000, loss: 0.027565
 >> iter 39000, loss: 0.018493
 >> iter 40000, loss: 0.010601
   Number of active neurons: 10
 >> iter 41000, loss: 0.029610
 >> iter 42000, loss: 0.016292
 >> iter 43000, loss: 0.042234
 >> iter 44000, loss: 0.020147
 >> iter 45000, loss: 0.012177
 >> iter 46000, loss: 0.011122
 >> iter 47000, loss: 0.059096
 >> iter 48000, loss: 0.101559
 >> iter 49000, loss: 0.055889
 >> iter 50000, loss: 0.037069
   Number of active neurons: 10
 >> iter 51000, loss: 0.020953
 >> iter 52000, loss: 0.049882
 >> iter 53000, loss: 0.026206
 >> iter 54000, loss: 0.012403
 >> iter 55000, loss: 0.116922
 >> iter 56000, loss: 0.058886
 >> iter 57000, loss: 0.042800
 >> iter 58000, loss: 0.019047
 >> iter 59000, loss: 0.050352
 >> iter 60000, loss: 0.064169
   Number of active neurons: 10
 >> iter 61000, loss: 0.048214
 >> iter 62000, loss: 0.041316
 >> iter 63000, loss: 0.039167
 >> iter 64000, loss: 0.018853
 >> iter 65000, loss: 0.093443
 >> iter 66000, loss: 0.040067
 >> iter 67000, loss: 0.018845
 >> iter 68000, loss: 0.058540
 >> iter 69000, loss: 0.035956
 >> iter 70000, loss: 0.040521
   Number of active neurons: 10
 >> iter 71000, loss: 0.018956
 >> iter 72000, loss: 0.009325
 >> iter 73000, loss: 0.029816
 >> iter 74000, loss: 0.024423
 >> iter 75000, loss: 0.014493
 >> iter 76000, loss: 0.033164
 >> iter 77000, loss: 0.017796
 >> iter 78000, loss: 0.023638
 >> iter 79000, loss: 0.011457
 >> iter 80000, loss: 0.006366
   Number of active neurons: 10
 >> iter 81000, loss: 0.039026
 >> iter 82000, loss: 0.026669
 >> iter 83000, loss: 0.121773
 >> iter 84000, loss: 0.047282
 >> iter 85000, loss: 0.019840
 >> iter 86000, loss: 0.013461
 >> iter 87000, loss: 0.040313
 >> iter 88000, loss: 0.017103
 >> iter 89000, loss: 0.056738
 >> iter 90000, loss: 0.023055
   Number of active neurons: 10
 >> iter 91000, loss: 0.026257
 >> iter 92000, loss: 0.046660
 >> iter 93000, loss: 0.075922
 >> iter 94000, loss: 0.031357
 >> iter 95000, loss: 0.027909
 >> iter 96000, loss: 0.012410
 >> iter 97000, loss: 0.006724
 >> iter 98000, loss: 0.035901
 >> iter 99000, loss: 0.019350
 >> iter 100000, loss: 0.035753
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.722095
 >> iter 2000, loss: 11.182638
 >> iter 3000, loss: 7.967186
 >> iter 4000, loss: 5.898980
 >> iter 5000, loss: 4.695027
 >> iter 6000, loss: 3.743238
 >> iter 7000, loss: 3.255910
 >> iter 8000, loss: 2.582964
 >> iter 9000, loss: 2.195539
 >> iter 10000, loss: 1.536919
   Number of active neurons: 10
 >> iter 11000, loss: 0.981719
 >> iter 12000, loss: 0.884430
 >> iter 13000, loss: 0.831900
 >> iter 14000, loss: 0.704245
 >> iter 15000, loss: 0.696314
 >> iter 16000, loss: 0.436209
 >> iter 17000, loss: 0.292022
 >> iter 18000, loss: 0.315522
 >> iter 19000, loss: 0.286748
 >> iter 20000, loss: 0.189907
   Number of active neurons: 10
 >> iter 21000, loss: 0.275719
 >> iter 22000, loss: 0.265237
 >> iter 23000, loss: 0.223122
 >> iter 24000, loss: 0.162492
 >> iter 25000, loss: 0.145651
 >> iter 26000, loss: 0.199259
 >> iter 27000, loss: 0.112876
 >> iter 28000, loss: 0.108654
 >> iter 29000, loss: 0.072148
 >> iter 30000, loss: 0.085283
   Number of active neurons: 10
 >> iter 31000, loss: 0.098507
 >> iter 32000, loss: 0.145893
 >> iter 33000, loss: 0.118102
 >> iter 34000, loss: 0.137422
 >> iter 35000, loss: 0.067824
 >> iter 36000, loss: 0.030856
 >> iter 37000, loss: 0.067443
 >> iter 38000, loss: 0.153577
 >> iter 39000, loss: 0.097799
 >> iter 40000, loss: 0.099509
   Number of active neurons: 10
 >> iter 41000, loss: 0.066847
 >> iter 42000, loss: 0.044926
 >> iter 43000, loss: 0.050429
 >> iter 44000, loss: 0.143774
 >> iter 45000, loss: 0.122791
 >> iter 46000, loss: 0.240329
 >> iter 47000, loss: 0.163729
 >> iter 48000, loss: 0.142211
 >> iter 49000, loss: 0.075396
 >> iter 50000, loss: 0.096093
   Number of active neurons: 10
 >> iter 51000, loss: 0.076024
 >> iter 52000, loss: 0.035720
 >> iter 53000, loss: 0.031005
 >> iter 54000, loss: 0.058679
 >> iter 55000, loss: 0.076770
 >> iter 56000, loss: 0.087873
 >> iter 57000, loss: 0.078338
 >> iter 58000, loss: 0.140433
 >> iter 59000, loss: 0.124439
 >> iter 60000, loss: 0.065795
   Number of active neurons: 10
 >> iter 61000, loss: 0.069272
 >> iter 62000, loss: 0.068336
 >> iter 63000, loss: 0.030024
 >> iter 64000, loss: 0.030274
 >> iter 65000, loss: 0.035241
 >> iter 66000, loss: 0.030720
 >> iter 67000, loss: 0.015168
 >> iter 68000, loss: 0.033232
 >> iter 69000, loss: 0.016865
 >> iter 70000, loss: 0.008933
   Number of active neurons: 10
 >> iter 71000, loss: 0.023321
 >> iter 72000, loss: 0.011026
 >> iter 73000, loss: 0.028708
 >> iter 74000, loss: 0.049592
 >> iter 75000, loss: 0.024672
 >> iter 76000, loss: 0.029831
 >> iter 77000, loss: 0.013840
 >> iter 78000, loss: 0.033313
 >> iter 79000, loss: 0.036041
 >> iter 80000, loss: 0.026999
   Number of active neurons: 10
 >> iter 81000, loss: 0.081666
 >> iter 82000, loss: 0.032889
 >> iter 83000, loss: 0.043090
 >> iter 84000, loss: 0.055896
 >> iter 85000, loss: 0.041453
 >> iter 86000, loss: 0.020101
 >> iter 87000, loss: 0.009956
 >> iter 88000, loss: 0.014724
 >> iter 89000, loss: 0.008188
 >> iter 90000, loss: 0.005710
   Number of active neurons: 10
 >> iter 91000, loss: 0.016962
 >> iter 92000, loss: 0.020482
 >> iter 93000, loss: 0.093708
 >> iter 94000, loss: 0.084590
 >> iter 95000, loss: 0.036497
 >> iter 96000, loss: 0.032418
 >> iter 97000, loss: 0.027813
 >> iter 98000, loss: 0.039652
 >> iter 99000, loss: 0.045118
 >> iter 100000, loss: 0.059638
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.828048
 >> iter 2000, loss: 10.171303
 >> iter 3000, loss: 7.582974
 >> iter 4000, loss: 5.785922
 >> iter 5000, loss: 3.911295
 >> iter 6000, loss: 2.213328
 >> iter 7000, loss: 1.215685
 >> iter 8000, loss: 0.665431
 >> iter 9000, loss: 0.569355
 >> iter 10000, loss: 0.290174
   Number of active neurons: 10
 >> iter 11000, loss: 0.237556
 >> iter 12000, loss: 0.272334
 >> iter 13000, loss: 0.311834
 >> iter 14000, loss: 0.284625
 >> iter 15000, loss: 0.187278
 >> iter 16000, loss: 0.178893
 >> iter 17000, loss: 0.093909
 >> iter 18000, loss: 0.075557
 >> iter 19000, loss: 0.061385
 >> iter 20000, loss: 0.095742
   Number of active neurons: 10
 >> iter 21000, loss: 0.120801
 >> iter 22000, loss: 0.087072
 >> iter 23000, loss: 0.129761
 >> iter 24000, loss: 0.146618
 >> iter 25000, loss: 0.110370
 >> iter 26000, loss: 0.082331
 >> iter 27000, loss: 0.040959
 >> iter 28000, loss: 0.141271
 >> iter 29000, loss: 0.140455
 >> iter 30000, loss: 0.115841
   Number of active neurons: 10
 >> iter 31000, loss: 0.056211
 >> iter 32000, loss: 0.077036
 >> iter 33000, loss: 0.055923
 >> iter 34000, loss: 0.056057
 >> iter 35000, loss: 0.053564
 >> iter 36000, loss: 0.025980
 >> iter 37000, loss: 0.030897
 >> iter 38000, loss: 0.046810
 >> iter 39000, loss: 0.034846
 >> iter 40000, loss: 0.017832
   Number of active neurons: 10
 >> iter 41000, loss: 0.010079
 >> iter 42000, loss: 0.006522
 >> iter 43000, loss: 0.013390
 >> iter 44000, loss: 0.015441
 >> iter 45000, loss: 0.008833
 >> iter 46000, loss: 0.047531
 >> iter 47000, loss: 0.020913
 >> iter 48000, loss: 0.032193
 >> iter 49000, loss: 0.058937
 >> iter 50000, loss: 0.039585
   Number of active neurons: 10
 >> iter 51000, loss: 0.018465
 >> iter 52000, loss: 0.024557
 >> iter 53000, loss: 0.017787
 >> iter 54000, loss: 0.009893
 >> iter 55000, loss: 0.005759
 >> iter 56000, loss: 0.003847
 >> iter 57000, loss: 0.005252
 >> iter 58000, loss: 0.013612
 >> iter 59000, loss: 0.008899
 >> iter 60000, loss: 0.005198
   Number of active neurons: 10
 >> iter 61000, loss: 0.003238
 >> iter 62000, loss: 0.003172
 >> iter 63000, loss: 0.045616
 >> iter 64000, loss: 0.112254
 >> iter 65000, loss: 0.044881
 >> iter 66000, loss: 0.022954
 >> iter 67000, loss: 0.020283
 >> iter 68000, loss: 0.015762
 >> iter 69000, loss: 0.017623
 >> iter 70000, loss: 0.025459
   Number of active neurons: 10
 >> iter 71000, loss: 0.023119
 >> iter 72000, loss: 0.017141
 >> iter 73000, loss: 0.008306
 >> iter 74000, loss: 0.004930
 >> iter 75000, loss: 0.041764
 >> iter 76000, loss: 0.017085
 >> iter 77000, loss: 0.007588
 >> iter 78000, loss: 0.003956
 >> iter 79000, loss: 0.025946
 >> iter 80000, loss: 0.042896
   Number of active neurons: 10
 >> iter 81000, loss: 0.049846
 >> iter 82000, loss: 0.052110
 >> iter 83000, loss: 0.068322
 >> iter 84000, loss: 0.052706
 >> iter 85000, loss: 0.054525
 >> iter 86000, loss: 0.034044
 >> iter 87000, loss: 0.100430
 >> iter 88000, loss: 0.082031
 >> iter 89000, loss: 0.034331
 >> iter 90000, loss: 0.020130
   Number of active neurons: 10
 >> iter 91000, loss: 0.023392
 >> iter 92000, loss: 0.029553
 >> iter 93000, loss: 0.059297
 >> iter 94000, loss: 0.058145
 >> iter 95000, loss: 0.041144
 >> iter 96000, loss: 0.018192
 >> iter 97000, loss: 0.021384
 >> iter 98000, loss: 0.009762
 >> iter 99000, loss: 0.024100
 >> iter 100000, loss: 0.021051
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.923880
 >> iter 2000, loss: 10.232891
 >> iter 3000, loss: 7.542660
 >> iter 4000, loss: 5.508857
 >> iter 5000, loss: 3.409574
 >> iter 6000, loss: 1.631798
 >> iter 7000, loss: 0.829523
 >> iter 8000, loss: 0.575363
 >> iter 9000, loss: 0.373269
 >> iter 10000, loss: 0.236574
   Number of active neurons: 10
 >> iter 11000, loss: 0.220010
 >> iter 12000, loss: 0.165874
 >> iter 13000, loss: 0.141055
 >> iter 14000, loss: 0.085812
 >> iter 15000, loss: 0.171235
 >> iter 16000, loss: 0.121558
 >> iter 17000, loss: 0.105140
 >> iter 18000, loss: 0.135349
 >> iter 19000, loss: 0.124488
 >> iter 20000, loss: 0.058143
   Number of active neurons: 10
 >> iter 21000, loss: 0.088441
 >> iter 22000, loss: 0.047099
 >> iter 23000, loss: 0.164396
 >> iter 24000, loss: 0.108443
 >> iter 25000, loss: 0.105886
 >> iter 26000, loss: 0.133534
 >> iter 27000, loss: 0.098974
 >> iter 28000, loss: 0.068862
 >> iter 29000, loss: 0.079386
 >> iter 30000, loss: 0.044573
   Number of active neurons: 10
 >> iter 31000, loss: 0.081102
 >> iter 32000, loss: 0.086812
 >> iter 33000, loss: 0.057888
 >> iter 34000, loss: 0.079276
 >> iter 35000, loss: 0.043041
 >> iter 36000, loss: 0.027636
 >> iter 37000, loss: 0.040898
 >> iter 38000, loss: 0.037390
 >> iter 39000, loss: 0.019469
 >> iter 40000, loss: 0.012453
   Number of active neurons: 10
 >> iter 41000, loss: 0.039467
 >> iter 42000, loss: 0.021960
 >> iter 43000, loss: 0.028224
 >> iter 44000, loss: 0.018726
 >> iter 45000, loss: 0.069579
 >> iter 46000, loss: 0.033749
 >> iter 47000, loss: 0.027505
 >> iter 48000, loss: 0.020897
 >> iter 49000, loss: 0.011198
 >> iter 50000, loss: 0.014086
   Number of active neurons: 10
 >> iter 51000, loss: 0.055423
 >> iter 52000, loss: 0.024566
 >> iter 53000, loss: 0.054914
 >> iter 54000, loss: 0.036101
 >> iter 55000, loss: 0.068075
 >> iter 56000, loss: 0.042699
 >> iter 57000, loss: 0.020411
 >> iter 58000, loss: 0.027084
 >> iter 59000, loss: 0.038344
 >> iter 60000, loss: 0.047157
   Number of active neurons: 10
 >> iter 61000, loss: 0.020714
 >> iter 62000, loss: 0.010968
 >> iter 63000, loss: 0.006988
 >> iter 64000, loss: 0.005433
 >> iter 65000, loss: 0.025814
 >> iter 66000, loss: 0.012212
 >> iter 67000, loss: 0.009621
 >> iter 68000, loss: 0.024876
 >> iter 69000, loss: 0.022695
 >> iter 70000, loss: 0.034441
   Number of active neurons: 10
 >> iter 71000, loss: 0.064359
 >> iter 72000, loss: 0.072319
 >> iter 73000, loss: 0.052868
 >> iter 74000, loss: 0.028759
 >> iter 75000, loss: 0.026089
 >> iter 76000, loss: 0.016540
 >> iter 77000, loss: 0.008721
 >> iter 78000, loss: 0.005555
 >> iter 79000, loss: 0.004378
 >> iter 80000, loss: 0.004347
   Number of active neurons: 10
 >> iter 81000, loss: 0.007624
 >> iter 82000, loss: 0.004782
 >> iter 83000, loss: 0.003789
 >> iter 84000, loss: 0.003873
 >> iter 85000, loss: 0.003061
 >> iter 86000, loss: 0.010583
 >> iter 87000, loss: 0.005771
 >> iter 88000, loss: 0.003761
 >> iter 89000, loss: 0.003158
 >> iter 90000, loss: 0.002990
   Number of active neurons: 10
 >> iter 91000, loss: 0.013292
 >> iter 92000, loss: 0.038266
 >> iter 93000, loss: 0.086214
 >> iter 94000, loss: 0.081271
 >> iter 95000, loss: 0.038069
 >> iter 96000, loss: 0.015962
 >> iter 97000, loss: 0.021908
 >> iter 98000, loss: 0.009857
 >> iter 99000, loss: 0.044854
 >> iter 100000, loss: 0.018937
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

