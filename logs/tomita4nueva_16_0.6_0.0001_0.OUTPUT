 > Problema: tomita4nueva
 > Args:
   - Hidden size: 16
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.115073
 >> iter 2000, loss: 9.783612
 >> iter 3000, loss: 4.255334
 >> iter 4000, loss: 1.768934
 >> iter 5000, loss: 0.959723
 >> iter 6000, loss: 0.608220
 >> iter 7000, loss: 0.401551
 >> iter 8000, loss: 0.243637
 >> iter 9000, loss: 0.309329
 >> iter 10000, loss: 0.246534
   Number of active neurons: 4
 >> iter 11000, loss: 0.220075
 >> iter 12000, loss: 0.238379
 >> iter 13000, loss: 0.196665
 >> iter 14000, loss: 0.102599
 >> iter 15000, loss: 0.215261
 >> iter 16000, loss: 0.259676
 >> iter 17000, loss: 0.432545
 >> iter 18000, loss: 0.308448
 >> iter 19000, loss: 0.286734
 >> iter 20000, loss: 0.287955
   Number of active neurons: 3
 >> iter 21000, loss: 0.322874
 >> iter 22000, loss: 0.288047
 >> iter 23000, loss: 0.221611
 >> iter 24000, loss: 0.154231
 >> iter 25000, loss: 0.209633
 >> iter 26000, loss: 0.172869
 >> iter 27000, loss: 0.151148
 >> iter 28000, loss: 0.247438
 >> iter 29000, loss: 0.277773
 >> iter 30000, loss: 0.199115
   Number of active neurons: 3
 >> iter 31000, loss: 0.242432
 >> iter 32000, loss: 0.267466
 >> iter 33000, loss: 0.231622
 >> iter 34000, loss: 0.337745
 >> iter 35000, loss: 0.205744
 >> iter 36000, loss: 0.143527
 >> iter 37000, loss: 0.129094
 >> iter 38000, loss: 0.081334
 >> iter 39000, loss: 0.326472
 >> iter 40000, loss: 0.491959
   Number of active neurons: 3
 >> iter 41000, loss: 0.252484
 >> iter 42000, loss: 0.394070
 >> iter 43000, loss: 0.328194
 >> iter 44000, loss: 0.311969
 >> iter 45000, loss: 0.161820
 >> iter 46000, loss: 0.470784
 >> iter 47000, loss: 0.377174
 >> iter 48000, loss: 0.303570
 >> iter 49000, loss: 0.185701
 >> iter 50000, loss: 0.277548
   Number of active neurons: 3
 >> iter 51000, loss: 0.186461
 >> iter 52000, loss: 0.289505
 >> iter 53000, loss: 0.163766
 >> iter 54000, loss: 0.184629
 >> iter 55000, loss: 0.180988
 >> iter 56000, loss: 0.247681
 >> iter 57000, loss: 0.143955
 >> iter 58000, loss: 0.233250
 >> iter 59000, loss: 0.198553
 >> iter 60000, loss: 0.119922
   Number of active neurons: 3
 >> iter 61000, loss: 0.179686
 >> iter 62000, loss: 0.297498
 >> iter 63000, loss: 0.225698
 >> iter 64000, loss: 0.129572
 >> iter 65000, loss: 0.194830
 >> iter 66000, loss: 0.236970
 >> iter 67000, loss: 0.340406
 >> iter 68000, loss: 0.201370
 >> iter 69000, loss: 0.210672
 >> iter 70000, loss: 0.183114
   Number of active neurons: 3
 >> iter 71000, loss: 0.249209
 >> iter 72000, loss: 0.309345
 >> iter 73000, loss: 0.324757
 >> iter 74000, loss: 0.340219
 >> iter 75000, loss: 0.220205
 >> iter 76000, loss: 0.113174
 >> iter 77000, loss: 0.226089
 >> iter 78000, loss: 0.283574
 >> iter 79000, loss: 0.161660
 >> iter 80000, loss: 0.227559
   Number of active neurons: 3
 >> iter 81000, loss: 0.282442
 >> iter 82000, loss: 0.302933
 >> iter 83000, loss: 0.169505
 >> iter 84000, loss: 0.124665
 >> iter 85000, loss: 0.086415
 >> iter 86000, loss: 0.136646
 >> iter 87000, loss: 0.111426
 >> iter 88000, loss: 0.075479
 >> iter 89000, loss: 0.169408
 >> iter 90000, loss: 0.215229
   Number of active neurons: 3
 >> iter 91000, loss: 0.176125
 >> iter 92000, loss: 0.230192
 >> iter 93000, loss: 0.371029
 >> iter 94000, loss: 0.361323
 >> iter 95000, loss: 0.173062
 >> iter 96000, loss: 0.205081
 >> iter 97000, loss: 0.188191
 >> iter 98000, loss: 0.138936
 >> iter 99000, loss: 0.156583
 >> iter 100000, loss: 0.135594
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.397586
 >> iter 2000, loss: 8.510440
 >> iter 3000, loss: 3.632978
 >> iter 4000, loss: 1.710371
 >> iter 5000, loss: 0.867639
 >> iter 6000, loss: 0.672207
 >> iter 7000, loss: 0.579634
 >> iter 8000, loss: 0.457488
 >> iter 9000, loss: 0.369559
 >> iter 10000, loss: 0.558151
   Number of active neurons: 8
 >> iter 11000, loss: 0.516854
 >> iter 12000, loss: 0.539724
 >> iter 13000, loss: 0.382223
 >> iter 14000, loss: 0.463140
 >> iter 15000, loss: 0.436940
 >> iter 16000, loss: 0.382847
 >> iter 17000, loss: 0.314358
 >> iter 18000, loss: 0.468543
 >> iter 19000, loss: 0.368141
 >> iter 20000, loss: 0.285817
   Number of active neurons: 7
 >> iter 21000, loss: 0.292646
 >> iter 22000, loss: 0.355727
 >> iter 23000, loss: 0.488128
 >> iter 24000, loss: 0.449504
 >> iter 25000, loss: 0.292002
 >> iter 26000, loss: 0.203765
 >> iter 27000, loss: 0.169375
 >> iter 28000, loss: 0.273435
 >> iter 29000, loss: 0.144780
 >> iter 30000, loss: 0.095952
   Number of active neurons: 4
 >> iter 31000, loss: 0.433517
 >> iter 32000, loss: 0.214777
 >> iter 33000, loss: 0.142879
 >> iter 34000, loss: 0.368262
 >> iter 35000, loss: 0.366552
 >> iter 36000, loss: 0.469863
 >> iter 37000, loss: 0.503770
 >> iter 38000, loss: 0.354030
 >> iter 39000, loss: 0.431019
 >> iter 40000, loss: 0.319778
   Number of active neurons: 4
 >> iter 41000, loss: 0.408242
 >> iter 42000, loss: 0.351859
 >> iter 43000, loss: 0.262892
 >> iter 44000, loss: 0.316922
 >> iter 45000, loss: 0.305469
 >> iter 46000, loss: 0.291877
 >> iter 47000, loss: 0.383050
 >> iter 48000, loss: 0.285138
 >> iter 49000, loss: 0.318416
 >> iter 50000, loss: 0.242748
   Number of active neurons: 3
 >> iter 51000, loss: 0.170468
 >> iter 52000, loss: 0.241574
 >> iter 53000, loss: 0.344017
 >> iter 54000, loss: 0.296131
 >> iter 55000, loss: 0.364829
 >> iter 56000, loss: 0.325921
 >> iter 57000, loss: 0.271673
 >> iter 58000, loss: 0.375566
 >> iter 59000, loss: 0.256861
 >> iter 60000, loss: 0.210803
   Number of active neurons: 3
 >> iter 61000, loss: 0.361747
 >> iter 62000, loss: 0.263455
 >> iter 63000, loss: 0.431040
 >> iter 64000, loss: 0.263971
 >> iter 65000, loss: 0.209328
 >> iter 66000, loss: 0.324155
 >> iter 67000, loss: 0.220413
 >> iter 68000, loss: 0.161419
 >> iter 69000, loss: 0.264284
 >> iter 70000, loss: 0.348052
   Number of active neurons: 3
 >> iter 71000, loss: 0.366853
 >> iter 72000, loss: 0.247384
 >> iter 73000, loss: 0.213009
 >> iter 74000, loss: 0.179809
 >> iter 75000, loss: 0.301440
 >> iter 76000, loss: 0.160829
 >> iter 77000, loss: 0.109401
 >> iter 78000, loss: 0.362414
 >> iter 79000, loss: 0.210640
 >> iter 80000, loss: 0.269523
   Number of active neurons: 3
 >> iter 81000, loss: 0.224530
 >> iter 82000, loss: 0.178166
 >> iter 83000, loss: 0.223441
 >> iter 84000, loss: 0.189674
 >> iter 85000, loss: 0.224047
 >> iter 86000, loss: 0.198613
 >> iter 87000, loss: 0.294413
 >> iter 88000, loss: 0.267506
 >> iter 89000, loss: 0.239719
 >> iter 90000, loss: 0.148274
   Number of active neurons: 3
 >> iter 91000, loss: 0.259406
 >> iter 92000, loss: 0.239723
 >> iter 93000, loss: 0.186536
 >> iter 94000, loss: 0.215722
 >> iter 95000, loss: 0.314625
 >> iter 96000, loss: 0.350516
 >> iter 97000, loss: 0.218897
 >> iter 98000, loss: 0.288735
 >> iter 99000, loss: 0.209552
 >> iter 100000, loss: 0.151750
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.612594
 >> iter 2000, loss: 8.525123
 >> iter 3000, loss: 4.026779
 >> iter 4000, loss: 1.660242
 >> iter 5000, loss: 0.966590
 >> iter 6000, loss: 0.554909
 >> iter 7000, loss: 0.456561
 >> iter 8000, loss: 0.369781
 >> iter 9000, loss: 0.375377
 >> iter 10000, loss: 0.311327
   Number of active neurons: 5
 >> iter 11000, loss: 0.377108
 >> iter 12000, loss: 0.303270
 >> iter 13000, loss: 0.484859
 >> iter 14000, loss: 0.379160
 >> iter 15000, loss: 0.389551
 >> iter 16000, loss: 0.370032
 >> iter 17000, loss: 0.286704
 >> iter 18000, loss: 0.200901
 >> iter 19000, loss: 0.303436
 >> iter 20000, loss: 0.534690
   Number of active neurons: 5
 >> iter 21000, loss: 0.524082
 >> iter 22000, loss: 0.341140
 >> iter 23000, loss: 0.340325
 >> iter 24000, loss: 0.212515
 >> iter 25000, loss: 0.251983
 >> iter 26000, loss: 0.222234
 >> iter 27000, loss: 0.276427
 >> iter 28000, loss: 0.385266
 >> iter 29000, loss: 0.205295
 >> iter 30000, loss: 0.121222
   Number of active neurons: 4
 >> iter 31000, loss: 0.264538
 >> iter 32000, loss: 0.157890
 >> iter 33000, loss: 0.247146
 >> iter 34000, loss: 0.403141
 >> iter 35000, loss: 0.230636
 >> iter 36000, loss: 0.221827
 >> iter 37000, loss: 0.198672
 >> iter 38000, loss: 0.419767
 >> iter 39000, loss: 0.379184
 >> iter 40000, loss: 0.220543
   Number of active neurons: 4
 >> iter 41000, loss: 0.281189
 >> iter 42000, loss: 0.221149
 >> iter 43000, loss: 0.239352
 >> iter 44000, loss: 0.236982
 >> iter 45000, loss: 0.198212
 >> iter 46000, loss: 0.251486
 >> iter 47000, loss: 0.511269
 >> iter 48000, loss: 0.309295
 >> iter 49000, loss: 0.157516
 >> iter 50000, loss: 0.213036
   Number of active neurons: 4
 >> iter 51000, loss: 0.279569
 >> iter 52000, loss: 0.184752
 >> iter 53000, loss: 0.180460
 >> iter 54000, loss: 0.251568
 >> iter 55000, loss: 0.234883
 >> iter 56000, loss: 0.169476
 >> iter 57000, loss: 0.297263
 >> iter 58000, loss: 0.304589
 >> iter 59000, loss: 0.221537
 >> iter 60000, loss: 0.194607
   Number of active neurons: 4
 >> iter 61000, loss: 0.194846
 >> iter 62000, loss: 0.153232
 >> iter 63000, loss: 0.335488
 >> iter 64000, loss: 0.235441
 >> iter 65000, loss: 0.203729
 >> iter 66000, loss: 0.253655
 >> iter 67000, loss: 0.202875
 >> iter 68000, loss: 0.116472
 >> iter 69000, loss: 0.154225
 >> iter 70000, loss: 0.202424
   Number of active neurons: 4
 >> iter 71000, loss: 0.195647
 >> iter 72000, loss: 0.165065
 >> iter 73000, loss: 0.198801
 >> iter 74000, loss: 0.259788
 >> iter 75000, loss: 0.313883
 >> iter 76000, loss: 0.151857
 >> iter 77000, loss: 0.295684
 >> iter 78000, loss: 0.323745
 >> iter 79000, loss: 0.162930
 >> iter 80000, loss: 0.220673
   Number of active neurons: 4
 >> iter 81000, loss: 0.293729
 >> iter 82000, loss: 0.213746
 >> iter 83000, loss: 0.221815
 >> iter 84000, loss: 0.276697
 >> iter 85000, loss: 0.181830
 >> iter 86000, loss: 0.151412
 >> iter 87000, loss: 0.369356
 >> iter 88000, loss: 0.270351
 >> iter 89000, loss: 0.271527
 >> iter 90000, loss: 0.205805
   Number of active neurons: 3
 >> iter 91000, loss: 0.193770
 >> iter 92000, loss: 0.171986
 >> iter 93000, loss: 0.173601
 >> iter 94000, loss: 0.142571
 >> iter 95000, loss: 0.192921
 >> iter 96000, loss: 0.199954
 >> iter 97000, loss: 0.143390
 >> iter 98000, loss: 0.329826
 >> iter 99000, loss: 0.358142
 >> iter 100000, loss: 0.345702
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455178
   Number of active neurons: 0
 >> iter 1000, loss: 17.687684
 >> iter 2000, loss: 8.350169
 >> iter 3000, loss: 3.704265
 >> iter 4000, loss: 1.814513
 >> iter 5000, loss: 0.896109
 >> iter 6000, loss: 0.501516
 >> iter 7000, loss: 0.376974
 >> iter 8000, loss: 0.204671
 >> iter 9000, loss: 0.363995
 >> iter 10000, loss: 0.372375
   Number of active neurons: 4
 >> iter 11000, loss: 0.341681
 >> iter 12000, loss: 0.243307
 >> iter 13000, loss: 0.323482
 >> iter 14000, loss: 0.359207
 >> iter 15000, loss: 0.320451
 >> iter 16000, loss: 0.347764
 >> iter 17000, loss: 0.433187
 >> iter 18000, loss: 0.339573
 >> iter 19000, loss: 0.272098
 >> iter 20000, loss: 0.272555
   Number of active neurons: 4
 >> iter 21000, loss: 0.241443
 >> iter 22000, loss: 0.416915
 >> iter 23000, loss: 0.310987
 >> iter 24000, loss: 0.349276
 >> iter 25000, loss: 0.244615
 >> iter 26000, loss: 0.203613
 >> iter 27000, loss: 0.207201
 >> iter 28000, loss: 0.312075
 >> iter 29000, loss: 0.227065
 >> iter 30000, loss: 0.189937
   Number of active neurons: 3
 >> iter 31000, loss: 0.188796
 >> iter 32000, loss: 0.326301
 >> iter 33000, loss: 0.352058
 >> iter 34000, loss: 0.319582
 >> iter 35000, loss: 0.346983
 >> iter 36000, loss: 0.308257
 >> iter 37000, loss: 0.363861
 >> iter 38000, loss: 0.396797
 >> iter 39000, loss: 0.476503
 >> iter 40000, loss: 0.248661
   Number of active neurons: 3
 >> iter 41000, loss: 0.293176
 >> iter 42000, loss: 0.275154
 >> iter 43000, loss: 0.251670
 >> iter 44000, loss: 0.267244
 >> iter 45000, loss: 0.308282
 >> iter 46000, loss: 0.287518
 >> iter 47000, loss: 0.360970
 >> iter 48000, loss: 0.284306
 >> iter 49000, loss: 0.343514
 >> iter 50000, loss: 0.156935
   Number of active neurons: 3
 >> iter 51000, loss: 0.264143
 >> iter 52000, loss: 0.303553
 >> iter 53000, loss: 0.450316
 >> iter 54000, loss: 0.277994
 >> iter 55000, loss: 0.272318
 >> iter 56000, loss: 0.276241
 >> iter 57000, loss: 0.383319
 >> iter 58000, loss: 0.376640
 >> iter 59000, loss: 0.300117
 >> iter 60000, loss: 0.305210
   Number of active neurons: 3
 >> iter 61000, loss: 0.245158
 >> iter 62000, loss: 0.195966
 >> iter 63000, loss: 0.230325
 >> iter 64000, loss: 0.475921
 >> iter 65000, loss: 0.389990
 >> iter 66000, loss: 0.289352
 >> iter 67000, loss: 0.186058
 >> iter 68000, loss: 0.171381
 >> iter 69000, loss: 0.195649
 >> iter 70000, loss: 0.110327
   Number of active neurons: 3
 >> iter 71000, loss: 0.163012
 >> iter 72000, loss: 0.156714
 >> iter 73000, loss: 0.308348
 >> iter 74000, loss: 0.270379
 >> iter 75000, loss: 0.290402
 >> iter 76000, loss: 0.179869
 >> iter 77000, loss: 0.281936
 >> iter 78000, loss: 0.218281
 >> iter 79000, loss: 0.272144
 >> iter 80000, loss: 0.267790
   Number of active neurons: 3
 >> iter 81000, loss: 0.242283
 >> iter 82000, loss: 0.176374
 >> iter 83000, loss: 0.155750
 >> iter 84000, loss: 0.221516
 >> iter 85000, loss: 0.158203
 >> iter 86000, loss: 0.394800
 >> iter 87000, loss: 0.292906
 >> iter 88000, loss: 0.205247
 >> iter 89000, loss: 0.276615
 >> iter 90000, loss: 0.379662
   Number of active neurons: 3
 >> iter 91000, loss: 0.174355
 >> iter 92000, loss: 0.350769
 >> iter 93000, loss: 0.293513
 >> iter 94000, loss: 0.157452
 >> iter 95000, loss: 0.317655
 >> iter 96000, loss: 0.322198
 >> iter 97000, loss: 0.215986
 >> iter 98000, loss: 0.150718
 >> iter 99000, loss: 0.173954
 >> iter 100000, loss: 0.148687
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.279494
 >> iter 2000, loss: 8.725788
 >> iter 3000, loss: 3.881710
 >> iter 4000, loss: 1.879696
 >> iter 5000, loss: 1.062735
 >> iter 6000, loss: 0.695294
 >> iter 7000, loss: 0.678300
 >> iter 8000, loss: 0.429598
 >> iter 9000, loss: 0.340039
 >> iter 10000, loss: 0.345593
   Number of active neurons: 4
 >> iter 11000, loss: 0.346700
 >> iter 12000, loss: 0.484820
 >> iter 13000, loss: 0.390041
 >> iter 14000, loss: 0.429307
 >> iter 15000, loss: 0.529533
 >> iter 16000, loss: 0.359753
 >> iter 17000, loss: 0.255762
 >> iter 18000, loss: 0.248270
 >> iter 19000, loss: 0.280431
 >> iter 20000, loss: 0.260576
   Number of active neurons: 4
 >> iter 21000, loss: 0.188971
 >> iter 22000, loss: 0.224319
 >> iter 23000, loss: 0.387598
 >> iter 24000, loss: 0.239397
 >> iter 25000, loss: 0.212678
 >> iter 26000, loss: 0.355820
 >> iter 27000, loss: 0.363234
 >> iter 28000, loss: 0.224062
 >> iter 29000, loss: 0.244687
 >> iter 30000, loss: 0.186198
   Number of active neurons: 4
 >> iter 31000, loss: 0.324138
 >> iter 32000, loss: 0.383498
 >> iter 33000, loss: 0.437651
 >> iter 34000, loss: 0.259763
 >> iter 35000, loss: 0.398429
 >> iter 36000, loss: 0.409186
 >> iter 37000, loss: 0.333490
 >> iter 38000, loss: 0.288629
 >> iter 39000, loss: 0.288579
 >> iter 40000, loss: 0.259630
   Number of active neurons: 3
 >> iter 41000, loss: 0.319141
 >> iter 42000, loss: 0.355614
 >> iter 43000, loss: 0.260607
 >> iter 44000, loss: 0.146557
 >> iter 45000, loss: 0.134841
 >> iter 46000, loss: 0.148185
 >> iter 47000, loss: 0.152757
 >> iter 48000, loss: 0.192219
 >> iter 49000, loss: 0.386842
 >> iter 50000, loss: 0.206117
   Number of active neurons: 3
 >> iter 51000, loss: 0.354016
 >> iter 52000, loss: 0.376158
 >> iter 53000, loss: 0.291283
 >> iter 54000, loss: 0.367798
 >> iter 55000, loss: 0.292240
 >> iter 56000, loss: 0.193292
 >> iter 57000, loss: 0.135977
 >> iter 58000, loss: 0.181380
 >> iter 59000, loss: 0.280117
 >> iter 60000, loss: 0.316842
   Number of active neurons: 3
 >> iter 61000, loss: 0.366714
 >> iter 62000, loss: 0.179799
 >> iter 63000, loss: 0.461859
 >> iter 64000, loss: 0.265570
 >> iter 65000, loss: 0.227587
 >> iter 66000, loss: 0.129659
 >> iter 67000, loss: 0.144258
 >> iter 68000, loss: 0.407331
 >> iter 69000, loss: 0.299701
 >> iter 70000, loss: 0.311834
   Number of active neurons: 3
 >> iter 71000, loss: 0.442481
 >> iter 72000, loss: 0.255609
 >> iter 73000, loss: 0.376861
 >> iter 74000, loss: 0.306145
 >> iter 75000, loss: 0.350213
 >> iter 76000, loss: 0.270467
 >> iter 77000, loss: 0.378804
 >> iter 78000, loss: 0.330581
 >> iter 79000, loss: 0.292808
 >> iter 80000, loss: 0.303437
   Number of active neurons: 3
 >> iter 81000, loss: 0.302348
 >> iter 82000, loss: 0.272485
 >> iter 83000, loss: 0.375217
 >> iter 84000, loss: 0.174128
 >> iter 85000, loss: 0.272505
 >> iter 86000, loss: 0.221784
 >> iter 87000, loss: 0.233126
 >> iter 88000, loss: 0.243359
 >> iter 89000, loss: 0.205732
 >> iter 90000, loss: 0.193366
   Number of active neurons: 3
 >> iter 91000, loss: 0.136219
 >> iter 92000, loss: 0.413937
 >> iter 93000, loss: 0.196119
 >> iter 94000, loss: 0.191412
 >> iter 95000, loss: 0.120159
 >> iter 96000, loss: 0.244306
 >> iter 97000, loss: 0.209453
 >> iter 98000, loss: 0.189877
 >> iter 99000, loss: 0.245082
 >> iter 100000, loss: 0.251547
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.636302
 >> iter 2000, loss: 8.608211
 >> iter 3000, loss: 3.675361
 >> iter 4000, loss: 1.854663
 >> iter 5000, loss: 1.495393
 >> iter 6000, loss: 0.864145
 >> iter 7000, loss: 1.048241
 >> iter 8000, loss: 0.763476
 >> iter 9000, loss: 0.688840
 >> iter 10000, loss: 0.608403
   Number of active neurons: 6
 >> iter 11000, loss: 0.618228
 >> iter 12000, loss: 0.614109
 >> iter 13000, loss: 0.405790
 >> iter 14000, loss: 0.464835
 >> iter 15000, loss: 0.649036
 >> iter 16000, loss: 0.665622
 >> iter 17000, loss: 0.523047
 >> iter 18000, loss: 0.597308
 >> iter 19000, loss: 0.547352
 >> iter 20000, loss: 0.459036
   Number of active neurons: 5
 >> iter 21000, loss: 0.467136
 >> iter 22000, loss: 0.415927
 >> iter 23000, loss: 0.448193
 >> iter 24000, loss: 0.495787
 >> iter 25000, loss: 0.457239
 >> iter 26000, loss: 0.479183
 >> iter 27000, loss: 0.496042
 >> iter 28000, loss: 0.540557
 >> iter 29000, loss: 0.460259
 >> iter 30000, loss: 0.379117
   Number of active neurons: 5
 >> iter 31000, loss: 0.423992
 >> iter 32000, loss: 0.217238
 >> iter 33000, loss: 0.238764
 >> iter 34000, loss: 0.407672
 >> iter 35000, loss: 0.384972
 >> iter 36000, loss: 0.267597
 >> iter 37000, loss: 0.555858
 >> iter 38000, loss: 0.586066
 >> iter 39000, loss: 0.607899
 >> iter 40000, loss: 0.468311
   Number of active neurons: 5
 >> iter 41000, loss: 0.400095
 >> iter 42000, loss: 0.383463
 >> iter 43000, loss: 0.486808
 >> iter 44000, loss: 0.427373
 >> iter 45000, loss: 0.448574
 >> iter 46000, loss: 0.510765
 >> iter 47000, loss: 0.484307
 >> iter 48000, loss: 0.306649
 >> iter 49000, loss: 0.473961
 >> iter 50000, loss: 0.391943
   Number of active neurons: 4
 >> iter 51000, loss: 0.407187
 >> iter 52000, loss: 0.342829
 >> iter 53000, loss: 0.422510
 >> iter 54000, loss: 0.355530
 >> iter 55000, loss: 0.164051
 >> iter 56000, loss: 0.485479
 >> iter 57000, loss: 0.386080
 >> iter 58000, loss: 0.618514
 >> iter 59000, loss: 0.486906
 >> iter 60000, loss: 0.432905
   Number of active neurons: 4
 >> iter 61000, loss: 0.468652
 >> iter 62000, loss: 0.636117
 >> iter 63000, loss: 0.353121
 >> iter 64000, loss: 0.513391
 >> iter 65000, loss: 0.482009
 >> iter 66000, loss: 0.377330
 >> iter 67000, loss: 0.379877
 >> iter 68000, loss: 0.460732
 >> iter 69000, loss: 0.350403
 >> iter 70000, loss: 0.346402
   Number of active neurons: 4
 >> iter 71000, loss: 0.387115
 >> iter 72000, loss: 0.450872
 >> iter 73000, loss: 0.357200
 >> iter 74000, loss: 0.353070
 >> iter 75000, loss: 0.490071
 >> iter 76000, loss: 0.367208
 >> iter 77000, loss: 0.505425
 >> iter 78000, loss: 0.430364
 >> iter 79000, loss: 0.430549
 >> iter 80000, loss: 0.507315
   Number of active neurons: 4
 >> iter 81000, loss: 0.327823
 >> iter 82000, loss: 0.405957
 >> iter 83000, loss: 0.504037
 >> iter 84000, loss: 0.409862
 >> iter 85000, loss: 0.495123
 >> iter 86000, loss: 0.756778
 >> iter 87000, loss: 0.484266
 >> iter 88000, loss: 0.729264
 >> iter 89000, loss: 0.472329
 >> iter 90000, loss: 0.301096
   Number of active neurons: 4
 >> iter 91000, loss: 0.241589
 >> iter 92000, loss: 0.329308
 >> iter 93000, loss: 0.391029
 >> iter 94000, loss: 0.294108
 >> iter 95000, loss: 0.510358
 >> iter 96000, loss: 0.288563
 >> iter 97000, loss: 0.486324
 >> iter 98000, loss: 0.430012
 >> iter 99000, loss: 0.294623
 >> iter 100000, loss: 0.540536
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 17.598786
 >> iter 2000, loss: 9.446160
 >> iter 3000, loss: 4.290419
 >> iter 4000, loss: 2.216458
 >> iter 5000, loss: 1.171655
 >> iter 6000, loss: 0.758590
 >> iter 7000, loss: 0.735276
 >> iter 8000, loss: 0.401642
 >> iter 9000, loss: 0.586160
 >> iter 10000, loss: 0.471915
   Number of active neurons: 6
 >> iter 11000, loss: 0.423011
 >> iter 12000, loss: 0.401378
 >> iter 13000, loss: 0.498298
 >> iter 14000, loss: 0.378017
 >> iter 15000, loss: 0.379044
 >> iter 16000, loss: 0.421517
 >> iter 17000, loss: 0.502998
 >> iter 18000, loss: 0.452052
 >> iter 19000, loss: 0.562195
 >> iter 20000, loss: 0.666437
   Number of active neurons: 6
 >> iter 21000, loss: 0.524555
 >> iter 22000, loss: 0.468398
 >> iter 23000, loss: 0.392779
 >> iter 24000, loss: 0.226907
 >> iter 25000, loss: 0.243471
 >> iter 26000, loss: 0.373995
 >> iter 27000, loss: 0.355971
 >> iter 28000, loss: 0.299196
 >> iter 29000, loss: 0.403189
 >> iter 30000, loss: 0.277005
   Number of active neurons: 6
 >> iter 31000, loss: 0.319598
 >> iter 32000, loss: 0.484845
 >> iter 33000, loss: 0.481200
 >> iter 34000, loss: 0.366210
 >> iter 35000, loss: 0.203097
 >> iter 36000, loss: 0.257893
 >> iter 37000, loss: 0.179086
 >> iter 38000, loss: 0.247323
 >> iter 39000, loss: 0.493674
 >> iter 40000, loss: 0.330052
   Number of active neurons: 6
 >> iter 41000, loss: 0.204429
 >> iter 42000, loss: 0.242690
 >> iter 43000, loss: 0.235739
 >> iter 44000, loss: 0.195695
 >> iter 45000, loss: 0.260752
 >> iter 46000, loss: 0.166208
 >> iter 47000, loss: 0.234597
 >> iter 48000, loss: 0.248655
 >> iter 49000, loss: 0.352119
 >> iter 50000, loss: 0.276063
   Number of active neurons: 4
 >> iter 51000, loss: 0.201313
 >> iter 52000, loss: 0.157074
 >> iter 53000, loss: 0.243427
 >> iter 54000, loss: 0.265224
 >> iter 55000, loss: 0.288003
 >> iter 56000, loss: 0.424555
 >> iter 57000, loss: 0.279587
 >> iter 58000, loss: 0.298018
 >> iter 59000, loss: 0.191914
 >> iter 60000, loss: 0.359403
   Number of active neurons: 4
 >> iter 61000, loss: 0.464283
 >> iter 62000, loss: 0.317454
 >> iter 63000, loss: 0.347510
 >> iter 64000, loss: 0.420768
 >> iter 65000, loss: 0.321796
 >> iter 66000, loss: 0.455501
 >> iter 67000, loss: 0.373814
 >> iter 68000, loss: 0.417577
 >> iter 69000, loss: 0.255871
 >> iter 70000, loss: 0.317905
   Number of active neurons: 3
 >> iter 71000, loss: 0.172837
 >> iter 72000, loss: 0.239155
 >> iter 73000, loss: 0.344811
 >> iter 74000, loss: 0.357190
 >> iter 75000, loss: 0.171498
 >> iter 76000, loss: 0.137690
 >> iter 77000, loss: 0.138683
 >> iter 78000, loss: 0.298335
 >> iter 79000, loss: 0.361156
 >> iter 80000, loss: 0.315087
   Number of active neurons: 3
 >> iter 81000, loss: 0.329680
 >> iter 82000, loss: 0.186625
 >> iter 83000, loss: 0.124140
 >> iter 84000, loss: 0.346942
 >> iter 85000, loss: 0.260255
 >> iter 86000, loss: 0.147291
 >> iter 87000, loss: 0.182999
 >> iter 88000, loss: 0.167487
 >> iter 89000, loss: 0.274238
 >> iter 90000, loss: 0.233867
   Number of active neurons: 3
 >> iter 91000, loss: 0.223992
 >> iter 92000, loss: 0.327475
 >> iter 93000, loss: 0.263903
 >> iter 94000, loss: 0.393103
 >> iter 95000, loss: 0.229683
 >> iter 96000, loss: 0.215099
 >> iter 97000, loss: 0.383669
 >> iter 98000, loss: 0.372927
 >> iter 99000, loss: 0.231726
 >> iter 100000, loss: 0.332400
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.217179
 >> iter 2000, loss: 9.789028
 >> iter 3000, loss: 4.866431
 >> iter 4000, loss: 2.372208
 >> iter 5000, loss: 1.461768
 >> iter 6000, loss: 1.006419
 >> iter 7000, loss: 0.726003
 >> iter 8000, loss: 0.649951
 >> iter 9000, loss: 0.578800
 >> iter 10000, loss: 0.513352
   Number of active neurons: 8
 >> iter 11000, loss: 0.334733
 >> iter 12000, loss: 0.506072
 >> iter 13000, loss: 0.616519
 >> iter 14000, loss: 0.571787
 >> iter 15000, loss: 0.546641
 >> iter 16000, loss: 0.525701
 >> iter 17000, loss: 0.412332
 >> iter 18000, loss: 0.517130
 >> iter 19000, loss: 0.437397
 >> iter 20000, loss: 0.749554
   Number of active neurons: 5
 >> iter 21000, loss: 0.628070
 >> iter 22000, loss: 0.541707
 >> iter 23000, loss: 0.385031
 >> iter 24000, loss: 0.440059
 >> iter 25000, loss: 0.528442
 >> iter 26000, loss: 0.519872
 >> iter 27000, loss: 0.413392
 >> iter 28000, loss: 0.518601
 >> iter 29000, loss: 0.712460
 >> iter 30000, loss: 0.386387
   Number of active neurons: 5
 >> iter 31000, loss: 0.498687
 >> iter 32000, loss: 0.563205
 >> iter 33000, loss: 0.461203
 >> iter 34000, loss: 0.531965
 >> iter 35000, loss: 0.336029
 >> iter 36000, loss: 0.464303
 >> iter 37000, loss: 0.593116
 >> iter 38000, loss: 0.633399
 >> iter 39000, loss: 0.539148
 >> iter 40000, loss: 0.629862
   Number of active neurons: 5
 >> iter 41000, loss: 0.555641
 >> iter 42000, loss: 0.416486
 >> iter 43000, loss: 0.561714
 >> iter 44000, loss: 0.751063
 >> iter 45000, loss: 0.959003
 >> iter 46000, loss: 0.580125
 >> iter 47000, loss: 0.496251
 >> iter 48000, loss: 0.493253
 >> iter 49000, loss: 0.530276
 >> iter 50000, loss: 0.593045
   Number of active neurons: 5
 >> iter 51000, loss: 0.521149
 >> iter 52000, loss: 0.370459
 >> iter 53000, loss: 0.479250
 >> iter 54000, loss: 0.609994
 >> iter 55000, loss: 0.510975
 >> iter 56000, loss: 0.443326
 >> iter 57000, loss: 0.358244
 >> iter 58000, loss: 0.373966
 >> iter 59000, loss: 0.249814
 >> iter 60000, loss: 0.480668
   Number of active neurons: 5
 >> iter 61000, loss: 0.432451
 >> iter 62000, loss: 0.335377
 >> iter 63000, loss: 0.390821
 >> iter 64000, loss: 0.453341
 >> iter 65000, loss: 0.615172
 >> iter 66000, loss: 0.709278
 >> iter 67000, loss: 0.529564
 >> iter 68000, loss: 0.561428
 >> iter 69000, loss: 0.457133
 >> iter 70000, loss: 0.305771
   Number of active neurons: 4
 >> iter 71000, loss: 0.197896
 >> iter 72000, loss: 0.369317
 >> iter 73000, loss: 0.525416
 >> iter 74000, loss: 0.601050
 >> iter 75000, loss: 0.433617
 >> iter 76000, loss: 0.558482
 >> iter 77000, loss: 0.368867
 >> iter 78000, loss: 0.319465
 >> iter 79000, loss: 0.375334
 >> iter 80000, loss: 0.424194
   Number of active neurons: 4
 >> iter 81000, loss: 0.466523
 >> iter 82000, loss: 0.330331
 >> iter 83000, loss: 0.423684
 >> iter 84000, loss: 0.427173
 >> iter 85000, loss: 0.421373
 >> iter 86000, loss: 0.409514
 >> iter 87000, loss: 0.327786
 >> iter 88000, loss: 0.340534
 >> iter 89000, loss: 0.273800
 >> iter 90000, loss: 0.471646
   Number of active neurons: 4
 >> iter 91000, loss: 0.556942
 >> iter 92000, loss: 0.398997
 >> iter 93000, loss: 0.425596
 >> iter 94000, loss: 0.505719
 >> iter 95000, loss: 0.456713
 >> iter 96000, loss: 0.403579
 >> iter 97000, loss: 0.566329
 >> iter 98000, loss: 0.474759
 >> iter 99000, loss: 0.675753
 >> iter 100000, loss: 0.558287
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.602601
 >> iter 2000, loss: 8.401389
 >> iter 3000, loss: 3.641179
 >> iter 4000, loss: 1.885343
 >> iter 5000, loss: 1.084916
 >> iter 6000, loss: 0.692071
 >> iter 7000, loss: 0.419526
 >> iter 8000, loss: 0.382041
 >> iter 9000, loss: 0.265522
 >> iter 10000, loss: 0.501862
   Number of active neurons: 5
 >> iter 11000, loss: 0.479991
 >> iter 12000, loss: 0.350601
 >> iter 13000, loss: 0.442148
 >> iter 14000, loss: 0.340018
 >> iter 15000, loss: 0.291098
 >> iter 16000, loss: 0.257801
 >> iter 17000, loss: 0.367913
 >> iter 18000, loss: 0.355376
 >> iter 19000, loss: 0.388281
 >> iter 20000, loss: 0.298102
   Number of active neurons: 5
 >> iter 21000, loss: 0.411529
 >> iter 22000, loss: 0.353666
 >> iter 23000, loss: 0.254265
 >> iter 24000, loss: 0.277298
 >> iter 25000, loss: 0.455529
 >> iter 26000, loss: 0.345001
 >> iter 27000, loss: 0.175182
 >> iter 28000, loss: 0.236181
 >> iter 29000, loss: 0.531779
 >> iter 30000, loss: 0.389848
   Number of active neurons: 5
 >> iter 31000, loss: 0.245338
 >> iter 32000, loss: 0.256528
 >> iter 33000, loss: 0.298618
 >> iter 34000, loss: 0.266539
 >> iter 35000, loss: 0.270157
 >> iter 36000, loss: 0.300555
 >> iter 37000, loss: 0.272380
 >> iter 38000, loss: 0.231226
 >> iter 39000, loss: 0.316768
 >> iter 40000, loss: 0.297899
   Number of active neurons: 4
 >> iter 41000, loss: 0.254298
 >> iter 42000, loss: 0.266266
 >> iter 43000, loss: 0.365022
 >> iter 44000, loss: 0.436266
 >> iter 45000, loss: 0.384503
 >> iter 46000, loss: 0.319946
 >> iter 47000, loss: 0.286214
 >> iter 48000, loss: 0.248347
 >> iter 49000, loss: 0.375918
 >> iter 50000, loss: 0.426491
   Number of active neurons: 4
 >> iter 51000, loss: 0.202037
 >> iter 52000, loss: 0.320823
 >> iter 53000, loss: 0.467357
 >> iter 54000, loss: 0.363107
 >> iter 55000, loss: 0.601322
 >> iter 56000, loss: 0.336139
 >> iter 57000, loss: 0.329680
 >> iter 58000, loss: 0.285617
 >> iter 59000, loss: 0.276420
 >> iter 60000, loss: 0.437345
   Number of active neurons: 4
 >> iter 61000, loss: 0.292976
 >> iter 62000, loss: 0.363079
 >> iter 63000, loss: 0.274499
 >> iter 64000, loss: 0.277625
 >> iter 65000, loss: 0.321234
 >> iter 66000, loss: 0.206144
 >> iter 67000, loss: 0.270636
 >> iter 68000, loss: 0.333637
 >> iter 69000, loss: 0.178563
 >> iter 70000, loss: 0.253635
   Number of active neurons: 4
 >> iter 71000, loss: 0.466982
 >> iter 72000, loss: 0.449714
 >> iter 73000, loss: 0.277085
 >> iter 74000, loss: 0.315621
 >> iter 75000, loss: 0.239308
 >> iter 76000, loss: 0.291521
 >> iter 77000, loss: 0.226361
 >> iter 78000, loss: 0.359977
 >> iter 79000, loss: 0.375540
 >> iter 80000, loss: 0.447746
   Number of active neurons: 4
 >> iter 81000, loss: 0.278775
 >> iter 82000, loss: 0.189218
 >> iter 83000, loss: 0.235367
 >> iter 84000, loss: 0.284188
 >> iter 85000, loss: 0.433683
 >> iter 86000, loss: 0.247184
 >> iter 87000, loss: 0.299188
 >> iter 88000, loss: 0.375867
 >> iter 89000, loss: 0.230703
 >> iter 90000, loss: 0.230805
   Number of active neurons: 4
 >> iter 91000, loss: 0.241742
 >> iter 92000, loss: 0.308549
 >> iter 93000, loss: 0.239914
 >> iter 94000, loss: 0.198904
 >> iter 95000, loss: 0.275645
 >> iter 96000, loss: 0.183589
 >> iter 97000, loss: 0.197775
 >> iter 98000, loss: 0.206043
 >> iter 99000, loss: 0.121427
 >> iter 100000, loss: 0.177570
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.695519
 >> iter 2000, loss: 8.183056
 >> iter 3000, loss: 3.899975
 >> iter 4000, loss: 2.064920
 >> iter 5000, loss: 1.008468
 >> iter 6000, loss: 0.636242
 >> iter 7000, loss: 0.522663
 >> iter 8000, loss: 0.326837
 >> iter 9000, loss: 0.324870
 >> iter 10000, loss: 0.280195
   Number of active neurons: 3
 >> iter 11000, loss: 0.376403
 >> iter 12000, loss: 0.388189
 >> iter 13000, loss: 0.506037
 >> iter 14000, loss: 0.270581
 >> iter 15000, loss: 0.195372
 >> iter 16000, loss: 0.422561
 >> iter 17000, loss: 0.352223
 >> iter 18000, loss: 0.367746
 >> iter 19000, loss: 0.294990
 >> iter 20000, loss: 0.221284
   Number of active neurons: 3
 >> iter 21000, loss: 0.206497
 >> iter 22000, loss: 0.238385
 >> iter 23000, loss: 0.320278
 >> iter 24000, loss: 0.286455
 >> iter 25000, loss: 0.186919
 >> iter 26000, loss: 0.356475
 >> iter 27000, loss: 0.229926
 >> iter 28000, loss: 0.227359
 >> iter 29000, loss: 0.200164
 >> iter 30000, loss: 0.443595
   Number of active neurons: 3
 >> iter 31000, loss: 0.282848
 >> iter 32000, loss: 0.379821
 >> iter 33000, loss: 0.263986
 >> iter 34000, loss: 0.261840
 >> iter 35000, loss: 0.521744
 >> iter 36000, loss: 0.252483
 >> iter 37000, loss: 0.225368
 >> iter 38000, loss: 0.377516
 >> iter 39000, loss: 0.339725
 >> iter 40000, loss: 0.322587
   Number of active neurons: 3
 >> iter 41000, loss: 0.299432
 >> iter 42000, loss: 0.196430
 >> iter 43000, loss: 0.292719
 >> iter 44000, loss: 0.304170
 >> iter 45000, loss: 0.231044
 >> iter 46000, loss: 0.144837
 >> iter 47000, loss: 0.184078
 >> iter 48000, loss: 0.224835
 >> iter 49000, loss: 0.265115
 >> iter 50000, loss: 0.274684
   Number of active neurons: 3
 >> iter 51000, loss: 0.242486
 >> iter 52000, loss: 0.487315
 >> iter 53000, loss: 0.249208
 >> iter 54000, loss: 0.285788
 >> iter 55000, loss: 0.329156
 >> iter 56000, loss: 0.308339
 >> iter 57000, loss: 0.343240
 >> iter 58000, loss: 0.319272
 >> iter 59000, loss: 0.359063
 >> iter 60000, loss: 0.398587
   Number of active neurons: 3
 >> iter 61000, loss: 0.243686
 >> iter 62000, loss: 0.211144
 >> iter 63000, loss: 0.383315
 >> iter 64000, loss: 0.252377
 >> iter 65000, loss: 0.258237
 >> iter 66000, loss: 0.272845
 >> iter 67000, loss: 0.187779
 >> iter 68000, loss: 0.242729
 >> iter 69000, loss: 0.341758
 >> iter 70000, loss: 0.175934
   Number of active neurons: 3
 >> iter 71000, loss: 0.354686
 >> iter 72000, loss: 0.337031
 >> iter 73000, loss: 0.192018
 >> iter 74000, loss: 0.139881
 >> iter 75000, loss: 0.170866
 >> iter 76000, loss: 0.269147
 >> iter 77000, loss: 0.292492
 >> iter 78000, loss: 0.359369
 >> iter 79000, loss: 0.333265
 >> iter 80000, loss: 0.237179
   Number of active neurons: 3
 >> iter 81000, loss: 0.394598
 >> iter 82000, loss: 0.530076
 >> iter 83000, loss: 0.301301
 >> iter 84000, loss: 0.284104
 >> iter 85000, loss: 0.316877
 >> iter 86000, loss: 0.276858
 >> iter 87000, loss: 0.206987
 >> iter 88000, loss: 0.231294
 >> iter 89000, loss: 0.184745
 >> iter 90000, loss: 0.131386
   Number of active neurons: 3
 >> iter 91000, loss: 0.114405
 >> iter 92000, loss: 0.149263
 >> iter 93000, loss: 0.346144
 >> iter 94000, loss: 0.288726
 >> iter 95000, loss: 0.218213
 >> iter 96000, loss: 0.341533
 >> iter 97000, loss: 0.338741
 >> iter 98000, loss: 0.376928
 >> iter 99000, loss: 0.270302
 >> iter 100000, loss: 0.203450
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.787507
 >> iter 2000, loss: 8.523260
 >> iter 3000, loss: 3.849584
 >> iter 4000, loss: 1.949771
 >> iter 5000, loss: 1.070761
 >> iter 6000, loss: 0.562321
 >> iter 7000, loss: 0.336219
 >> iter 8000, loss: 0.388595
 >> iter 9000, loss: 0.394906
 >> iter 10000, loss: 0.450754
   Number of active neurons: 5
 >> iter 11000, loss: 0.299569
 >> iter 12000, loss: 0.193270
 >> iter 13000, loss: 0.118556
 >> iter 14000, loss: 0.349033
 >> iter 15000, loss: 0.301504
 >> iter 16000, loss: 0.291486
 >> iter 17000, loss: 0.237194
 >> iter 18000, loss: 0.208384
 >> iter 19000, loss: 0.449035
 >> iter 20000, loss: 0.412067
   Number of active neurons: 4
 >> iter 21000, loss: 0.281598
 >> iter 22000, loss: 0.249423
 >> iter 23000, loss: 0.301826
 >> iter 24000, loss: 0.169228
 >> iter 25000, loss: 0.268935
 >> iter 26000, loss: 0.177593
 >> iter 27000, loss: 0.324747
 >> iter 28000, loss: 0.290289
 >> iter 29000, loss: 0.234547
 >> iter 30000, loss: 0.190888
   Number of active neurons: 4
 >> iter 31000, loss: 0.274521
 >> iter 32000, loss: 0.265714
 >> iter 33000, loss: 0.336668
 >> iter 34000, loss: 0.213243
 >> iter 35000, loss: 0.294714
 >> iter 36000, loss: 0.289485
 >> iter 37000, loss: 0.146737
 >> iter 38000, loss: 0.164895
 >> iter 39000, loss: 0.210244
 >> iter 40000, loss: 0.447570
   Number of active neurons: 4
 >> iter 41000, loss: 0.378558
 >> iter 42000, loss: 0.177121
 >> iter 43000, loss: 0.273029
 >> iter 44000, loss: 0.355747
 >> iter 45000, loss: 0.292871
 >> iter 46000, loss: 0.186240
 >> iter 47000, loss: 0.220544
 >> iter 48000, loss: 0.191576
 >> iter 49000, loss: 0.144299
 >> iter 50000, loss: 0.426932
   Number of active neurons: 4
 >> iter 51000, loss: 0.275252
 >> iter 52000, loss: 0.309971
 >> iter 53000, loss: 0.218510
 >> iter 54000, loss: 0.215362
 >> iter 55000, loss: 0.259420
 >> iter 56000, loss: 0.298600
 >> iter 57000, loss: 0.298358
 >> iter 58000, loss: 0.226281
 >> iter 59000, loss: 0.191833
 >> iter 60000, loss: 0.196719
   Number of active neurons: 4
 >> iter 61000, loss: 0.258241
 >> iter 62000, loss: 0.300079
 >> iter 63000, loss: 0.428149
 >> iter 64000, loss: 0.243522
 >> iter 65000, loss: 0.341697
 >> iter 66000, loss: 0.184550
 >> iter 67000, loss: 0.244610
 >> iter 68000, loss: 0.318183
 >> iter 69000, loss: 0.201023
 >> iter 70000, loss: 0.313919
   Number of active neurons: 4
 >> iter 71000, loss: 0.184292
 >> iter 72000, loss: 0.316890
 >> iter 73000, loss: 0.290120
 >> iter 74000, loss: 0.173830
 >> iter 75000, loss: 0.183671
 >> iter 76000, loss: 0.132380
 >> iter 77000, loss: 0.323478
 >> iter 78000, loss: 0.465345
 >> iter 79000, loss: 0.289719
 >> iter 80000, loss: 0.255341
   Number of active neurons: 4
 >> iter 81000, loss: 0.229962
 >> iter 82000, loss: 0.212479
 >> iter 83000, loss: 0.167677
 >> iter 84000, loss: 0.166851
 >> iter 85000, loss: 0.266290
 >> iter 86000, loss: 0.152881
 >> iter 87000, loss: 0.191851
 >> iter 88000, loss: 0.178983
 >> iter 89000, loss: 0.136440
 >> iter 90000, loss: 0.081014
   Number of active neurons: 3
 >> iter 91000, loss: 0.223372
 >> iter 92000, loss: 0.469036
 >> iter 93000, loss: 0.298680
 >> iter 94000, loss: 0.153773
 >> iter 95000, loss: 0.166390
 >> iter 96000, loss: 0.281293
 >> iter 97000, loss: 0.360844
 >> iter 98000, loss: 0.220749
 >> iter 99000, loss: 0.379959
 >> iter 100000, loss: 0.178600
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.544617
 >> iter 2000, loss: 8.560597
 >> iter 3000, loss: 3.794126
 >> iter 4000, loss: 1.996292
 >> iter 5000, loss: 0.941212
 >> iter 6000, loss: 0.637081
 >> iter 7000, loss: 0.511255
 >> iter 8000, loss: 0.487641
 >> iter 9000, loss: 0.345258
 >> iter 10000, loss: 0.351778
   Number of active neurons: 5
 >> iter 11000, loss: 0.295377
 >> iter 12000, loss: 0.254471
 >> iter 13000, loss: 0.206229
 >> iter 14000, loss: 0.225406
 >> iter 15000, loss: 0.153584
 >> iter 16000, loss: 0.247863
 >> iter 17000, loss: 0.205787
 >> iter 18000, loss: 0.249528
 >> iter 19000, loss: 0.189289
 >> iter 20000, loss: 0.475145
   Number of active neurons: 5
 >> iter 21000, loss: 0.297611
 >> iter 22000, loss: 0.376153
 >> iter 23000, loss: 0.280019
 >> iter 24000, loss: 0.456820
 >> iter 25000, loss: 0.376177
 >> iter 26000, loss: 0.365515
 >> iter 27000, loss: 0.438633
 >> iter 28000, loss: 0.277739
 >> iter 29000, loss: 0.430931
 >> iter 30000, loss: 0.494104
   Number of active neurons: 3
 >> iter 31000, loss: 0.466020
 >> iter 32000, loss: 0.341532
 >> iter 33000, loss: 0.349638
 >> iter 34000, loss: 0.510590
 >> iter 35000, loss: 0.502188
 >> iter 36000, loss: 0.293642
 >> iter 37000, loss: 0.152509
 >> iter 38000, loss: 0.325496
 >> iter 39000, loss: 0.331045
 >> iter 40000, loss: 0.293369
   Number of active neurons: 3
 >> iter 41000, loss: 0.442983
 >> iter 42000, loss: 0.318012
 >> iter 43000, loss: 0.277887
 >> iter 44000, loss: 0.388194
 >> iter 45000, loss: 0.302205
 >> iter 46000, loss: 0.178355
 >> iter 47000, loss: 0.199293
 >> iter 48000, loss: 0.264979
 >> iter 49000, loss: 0.563989
 >> iter 50000, loss: 0.322222
   Number of active neurons: 3
 >> iter 51000, loss: 0.349117
 >> iter 52000, loss: 0.258202
 >> iter 53000, loss: 0.170125
 >> iter 54000, loss: 0.128645
 >> iter 55000, loss: 0.321454
 >> iter 56000, loss: 0.210978
 >> iter 57000, loss: 0.192002
 >> iter 58000, loss: 0.214039
 >> iter 59000, loss: 0.275217
 >> iter 60000, loss: 0.214926
   Number of active neurons: 3
 >> iter 61000, loss: 0.190707
 >> iter 62000, loss: 0.176519
 >> iter 63000, loss: 0.096524
 >> iter 64000, loss: 0.182947
 >> iter 65000, loss: 0.173523
 >> iter 66000, loss: 0.200809
 >> iter 67000, loss: 0.237714
 >> iter 68000, loss: 0.289794
 >> iter 69000, loss: 0.460377
 >> iter 70000, loss: 0.363522
   Number of active neurons: 3
 >> iter 71000, loss: 0.292937
 >> iter 72000, loss: 0.250735
 >> iter 73000, loss: 0.405453
 >> iter 74000, loss: 0.424941
 >> iter 75000, loss: 0.382915
 >> iter 76000, loss: 0.228446
 >> iter 77000, loss: 0.191256
 >> iter 78000, loss: 0.306376
 >> iter 79000, loss: 0.169810
 >> iter 80000, loss: 0.226792
   Number of active neurons: 3
 >> iter 81000, loss: 0.237276
 >> iter 82000, loss: 0.265187
 >> iter 83000, loss: 0.166419
 >> iter 84000, loss: 0.306891
 >> iter 85000, loss: 0.186331
 >> iter 86000, loss: 0.148156
 >> iter 87000, loss: 0.270769
 >> iter 88000, loss: 0.343121
 >> iter 89000, loss: 0.349888
 >> iter 90000, loss: 0.255932
   Number of active neurons: 3
 >> iter 91000, loss: 0.150757
 >> iter 92000, loss: 0.250972
 >> iter 93000, loss: 0.184332
 >> iter 94000, loss: 0.194797
 >> iter 95000, loss: 0.137773
 >> iter 96000, loss: 0.120992
 >> iter 97000, loss: 0.137567
 >> iter 98000, loss: 0.111071
 >> iter 99000, loss: 0.288814
 >> iter 100000, loss: 0.177561
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.449009
 >> iter 2000, loss: 10.314597
 >> iter 3000, loss: 4.851364
 >> iter 4000, loss: 2.271445
 >> iter 5000, loss: 1.199796
 >> iter 6000, loss: 0.781623
 >> iter 7000, loss: 0.551546
 >> iter 8000, loss: 0.483384
 >> iter 9000, loss: 0.608668
 >> iter 10000, loss: 0.472981
   Number of active neurons: 7
 >> iter 11000, loss: 0.439576
 >> iter 12000, loss: 0.349087
 >> iter 13000, loss: 0.331455
 >> iter 14000, loss: 0.274178
 >> iter 15000, loss: 0.295835
 >> iter 16000, loss: 0.385044
 >> iter 17000, loss: 0.242104
 >> iter 18000, loss: 0.250185
 >> iter 19000, loss: 0.384782
 >> iter 20000, loss: 0.430608
   Number of active neurons: 6
 >> iter 21000, loss: 0.307173
 >> iter 22000, loss: 0.460553
 >> iter 23000, loss: 0.379410
 >> iter 24000, loss: 0.330932
 >> iter 25000, loss: 0.410389
 >> iter 26000, loss: 0.369350
 >> iter 27000, loss: 0.589305
 >> iter 28000, loss: 0.328568
 >> iter 29000, loss: 0.656975
 >> iter 30000, loss: 0.417542
   Number of active neurons: 6
 >> iter 31000, loss: 0.273233
 >> iter 32000, loss: 0.400512
 >> iter 33000, loss: 0.350811
 >> iter 34000, loss: 0.309267
 >> iter 35000, loss: 0.383605
 >> iter 36000, loss: 0.348287
 >> iter 37000, loss: 0.395766
 >> iter 38000, loss: 0.377454
 >> iter 39000, loss: 0.352638
 >> iter 40000, loss: 0.217543
   Number of active neurons: 5
 >> iter 41000, loss: 0.212189
 >> iter 42000, loss: 0.304273
 >> iter 43000, loss: 0.344081
 >> iter 44000, loss: 0.191746
 >> iter 45000, loss: 0.318808
 >> iter 46000, loss: 0.316719
 >> iter 47000, loss: 0.211271
 >> iter 48000, loss: 0.231605
 >> iter 49000, loss: 0.339062
 >> iter 50000, loss: 0.388300
   Number of active neurons: 5
 >> iter 51000, loss: 0.261272
 >> iter 52000, loss: 0.268440
 >> iter 53000, loss: 0.307979
 >> iter 54000, loss: 0.219241
 >> iter 55000, loss: 0.467771
 >> iter 56000, loss: 0.233133
 >> iter 57000, loss: 0.321060
 >> iter 58000, loss: 0.256014
 >> iter 59000, loss: 0.362424
 >> iter 60000, loss: 0.377920
   Number of active neurons: 4
 >> iter 61000, loss: 0.453182
 >> iter 62000, loss: 0.428260
 >> iter 63000, loss: 0.378042
 >> iter 64000, loss: 0.380970
 >> iter 65000, loss: 0.225714
 >> iter 66000, loss: 0.213367
 >> iter 67000, loss: 0.177999
 >> iter 68000, loss: 0.298164
 >> iter 69000, loss: 0.287199
 >> iter 70000, loss: 0.268591
   Number of active neurons: 4
 >> iter 71000, loss: 0.308526
 >> iter 72000, loss: 0.300184
 >> iter 73000, loss: 0.333527
 >> iter 74000, loss: 0.291358
 >> iter 75000, loss: 0.552882
 >> iter 76000, loss: 0.350706
 >> iter 77000, loss: 0.243551
 >> iter 78000, loss: 0.537201
 >> iter 79000, loss: 0.357462
 >> iter 80000, loss: 0.279674
   Number of active neurons: 4
 >> iter 81000, loss: 0.298339
 >> iter 82000, loss: 0.398329
 >> iter 83000, loss: 0.381673
 >> iter 84000, loss: 0.363308
 >> iter 85000, loss: 0.351157
 >> iter 86000, loss: 0.538334
 >> iter 87000, loss: 0.301490
 >> iter 88000, loss: 0.200342
 >> iter 89000, loss: 0.196866
 >> iter 90000, loss: 0.166246
   Number of active neurons: 4
 >> iter 91000, loss: 0.181901
 >> iter 92000, loss: 0.301062
 >> iter 93000, loss: 0.270452
 >> iter 94000, loss: 0.179341
 >> iter 95000, loss: 0.332841
 >> iter 96000, loss: 0.360300
 >> iter 97000, loss: 0.257870
 >> iter 98000, loss: 0.146699
 >> iter 99000, loss: 0.220015
 >> iter 100000, loss: 0.240474
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.906178
 >> iter 2000, loss: 8.995337
 >> iter 3000, loss: 4.208157
 >> iter 4000, loss: 2.003541
 >> iter 5000, loss: 1.292165
 >> iter 6000, loss: 0.922532
 >> iter 7000, loss: 0.681969
 >> iter 8000, loss: 0.749767
 >> iter 9000, loss: 0.400281
 >> iter 10000, loss: 0.230511
   Number of active neurons: 4
 >> iter 11000, loss: 0.150272
 >> iter 12000, loss: 0.312227
 >> iter 13000, loss: 0.271622
 >> iter 14000, loss: 0.211061
 >> iter 15000, loss: 0.318654
 >> iter 16000, loss: 0.342101
 >> iter 17000, loss: 0.192759
 >> iter 18000, loss: 0.192464
 >> iter 19000, loss: 0.277598
 >> iter 20000, loss: 0.313540
   Number of active neurons: 3
 >> iter 21000, loss: 0.230363
 >> iter 22000, loss: 0.343427
 >> iter 23000, loss: 0.379436
 >> iter 24000, loss: 0.397888
 >> iter 25000, loss: 0.246605
 >> iter 26000, loss: 0.289617
 >> iter 27000, loss: 0.430868
 >> iter 28000, loss: 0.273208
 >> iter 29000, loss: 0.157380
 >> iter 30000, loss: 0.197294
   Number of active neurons: 3
 >> iter 31000, loss: 0.215425
 >> iter 32000, loss: 0.320324
 >> iter 33000, loss: 0.242926
 >> iter 34000, loss: 0.146624
 >> iter 35000, loss: 0.226244
 >> iter 36000, loss: 0.396354
 >> iter 37000, loss: 0.241380
 >> iter 38000, loss: 0.162163
 >> iter 39000, loss: 0.115148
 >> iter 40000, loss: 0.376890
   Number of active neurons: 3
 >> iter 41000, loss: 0.237223
 >> iter 42000, loss: 0.264178
 >> iter 43000, loss: 0.415224
 >> iter 44000, loss: 0.238337
 >> iter 45000, loss: 0.266726
 >> iter 46000, loss: 0.226280
 >> iter 47000, loss: 0.330439
 >> iter 48000, loss: 0.200360
 >> iter 49000, loss: 0.250538
 >> iter 50000, loss: 0.298677
   Number of active neurons: 3
 >> iter 51000, loss: 0.253631
 >> iter 52000, loss: 0.239592
 >> iter 53000, loss: 0.288206
 >> iter 54000, loss: 0.223095
 >> iter 55000, loss: 0.302220
 >> iter 56000, loss: 0.181084
 >> iter 57000, loss: 0.165689
 >> iter 58000, loss: 0.212649
 >> iter 59000, loss: 0.267104
 >> iter 60000, loss: 0.227704
   Number of active neurons: 3
 >> iter 61000, loss: 0.342463
 >> iter 62000, loss: 0.340287
 >> iter 63000, loss: 0.302812
 >> iter 64000, loss: 0.298158
 >> iter 65000, loss: 0.324759
 >> iter 66000, loss: 0.317026
 >> iter 67000, loss: 0.478054
 >> iter 68000, loss: 0.298868
 >> iter 69000, loss: 0.318580
 >> iter 70000, loss: 0.331344
   Number of active neurons: 3
 >> iter 71000, loss: 0.246334
 >> iter 72000, loss: 0.311904
 >> iter 73000, loss: 0.230922
 >> iter 74000, loss: 0.131846
 >> iter 75000, loss: 0.387997
 >> iter 76000, loss: 0.293555
 >> iter 77000, loss: 0.158124
 >> iter 78000, loss: 0.231336
 >> iter 79000, loss: 0.305318
 >> iter 80000, loss: 0.283935
   Number of active neurons: 3
 >> iter 81000, loss: 0.178602
 >> iter 82000, loss: 0.180520
 >> iter 83000, loss: 0.229339
 >> iter 84000, loss: 0.170340
 >> iter 85000, loss: 0.196909
 >> iter 86000, loss: 0.441240
 >> iter 87000, loss: 0.258236
 >> iter 88000, loss: 0.137228
 >> iter 89000, loss: 0.129411
 >> iter 90000, loss: 0.176493
   Number of active neurons: 3
 >> iter 91000, loss: 0.260769
 >> iter 92000, loss: 0.232097
 >> iter 93000, loss: 0.270321
 >> iter 94000, loss: 0.221654
 >> iter 95000, loss: 0.257884
 >> iter 96000, loss: 0.226566
 >> iter 97000, loss: 0.257173
 >> iter 98000, loss: 0.241669
 >> iter 99000, loss: 0.246669
 >> iter 100000, loss: 0.145863
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.742099
 >> iter 2000, loss: 9.082185
 >> iter 3000, loss: 4.176391
 >> iter 4000, loss: 2.007243
 >> iter 5000, loss: 1.044558
 >> iter 6000, loss: 0.527651
 >> iter 7000, loss: 0.350533
 >> iter 8000, loss: 0.297898
 >> iter 9000, loss: 0.462958
 >> iter 10000, loss: 0.371168
   Number of active neurons: 3
 >> iter 11000, loss: 0.271244
 >> iter 12000, loss: 0.322872
 >> iter 13000, loss: 0.359140
 >> iter 14000, loss: 0.251869
 >> iter 15000, loss: 0.266148
 >> iter 16000, loss: 0.254133
 >> iter 17000, loss: 0.280491
 >> iter 18000, loss: 0.294047
 >> iter 19000, loss: 0.239638
 >> iter 20000, loss: 0.236775
   Number of active neurons: 3
 >> iter 21000, loss: 0.638755
 >> iter 22000, loss: 0.408947
 >> iter 23000, loss: 0.401735
 >> iter 24000, loss: 0.325006
 >> iter 25000, loss: 0.382432
 >> iter 26000, loss: 0.297148
 >> iter 27000, loss: 0.320811
 >> iter 28000, loss: 0.183826
 >> iter 29000, loss: 0.186935
 >> iter 30000, loss: 0.195238
   Number of active neurons: 3
 >> iter 31000, loss: 0.214323
 >> iter 32000, loss: 0.141437
 >> iter 33000, loss: 0.162403
 >> iter 34000, loss: 0.253278
 >> iter 35000, loss: 0.327726
 >> iter 36000, loss: 0.301841
 >> iter 37000, loss: 0.340194
 >> iter 38000, loss: 0.222870
 >> iter 39000, loss: 0.267525
 >> iter 40000, loss: 0.310443
   Number of active neurons: 3
 >> iter 41000, loss: 0.393556
 >> iter 42000, loss: 0.348608
 >> iter 43000, loss: 0.302404
 >> iter 44000, loss: 0.331102
 >> iter 45000, loss: 0.411630
 >> iter 46000, loss: 0.396193
 >> iter 47000, loss: 0.530549
 >> iter 48000, loss: 0.291585
 >> iter 49000, loss: 0.251199
 >> iter 50000, loss: 0.329805
   Number of active neurons: 3
 >> iter 51000, loss: 0.391616
 >> iter 52000, loss: 0.452003
 >> iter 53000, loss: 0.421282
 >> iter 54000, loss: 0.256980
 >> iter 55000, loss: 0.291965
 >> iter 56000, loss: 0.167815
 >> iter 57000, loss: 0.136223
 >> iter 58000, loss: 0.257054
 >> iter 59000, loss: 0.314293
 >> iter 60000, loss: 0.267714
   Number of active neurons: 3
 >> iter 61000, loss: 0.228243
 >> iter 62000, loss: 0.172606
 >> iter 63000, loss: 0.441644
 >> iter 64000, loss: 0.317539
 >> iter 65000, loss: 0.233498
 >> iter 66000, loss: 0.347795
 >> iter 67000, loss: 0.349408
 >> iter 68000, loss: 0.261231
 >> iter 69000, loss: 0.284443
 >> iter 70000, loss: 0.311048
   Number of active neurons: 3
 >> iter 71000, loss: 0.168903
 >> iter 72000, loss: 0.146141
 >> iter 73000, loss: 0.164994
 >> iter 74000, loss: 0.175912
 >> iter 75000, loss: 0.257026
 >> iter 76000, loss: 0.253125
 >> iter 77000, loss: 0.198279
 >> iter 78000, loss: 0.120996
 >> iter 79000, loss: 0.174138
 >> iter 80000, loss: 0.239097
   Number of active neurons: 3
 >> iter 81000, loss: 0.210334
 >> iter 82000, loss: 0.343867
 >> iter 83000, loss: 0.179546
 >> iter 84000, loss: 0.302914
 >> iter 85000, loss: 0.208021
 >> iter 86000, loss: 0.155650
 >> iter 87000, loss: 0.189043
 >> iter 88000, loss: 0.249101
 >> iter 89000, loss: 0.353362
 >> iter 90000, loss: 0.320606
   Number of active neurons: 3
 >> iter 91000, loss: 0.217574
 >> iter 92000, loss: 0.371285
 >> iter 93000, loss: 0.219107
 >> iter 94000, loss: 0.323929
 >> iter 95000, loss: 0.341681
 >> iter 96000, loss: 0.213645
 >> iter 97000, loss: 0.208128
 >> iter 98000, loss: 0.338563
 >> iter 99000, loss: 0.288145
 >> iter 100000, loss: 0.244512
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.755093
 >> iter 2000, loss: 9.694893
 >> iter 3000, loss: 4.904117
 >> iter 4000, loss: 2.735683
 >> iter 5000, loss: 1.663555
 >> iter 6000, loss: 0.956501
 >> iter 7000, loss: 0.525351
 >> iter 8000, loss: 0.375626
 >> iter 9000, loss: 0.498204
 >> iter 10000, loss: 0.318410
   Number of active neurons: 3
 >> iter 11000, loss: 0.429929
 >> iter 12000, loss: 0.379855
 >> iter 13000, loss: 0.384889
 >> iter 14000, loss: 0.316633
 >> iter 15000, loss: 0.537452
 >> iter 16000, loss: 0.358587
 >> iter 17000, loss: 0.177397
 >> iter 18000, loss: 0.353214
 >> iter 19000, loss: 0.360626
 >> iter 20000, loss: 0.388740
   Number of active neurons: 3
 >> iter 21000, loss: 0.363150
 >> iter 22000, loss: 0.242877
 >> iter 23000, loss: 0.501682
 >> iter 24000, loss: 0.400866
 >> iter 25000, loss: 0.425960
 >> iter 26000, loss: 0.295933
 >> iter 27000, loss: 0.207154
 >> iter 28000, loss: 0.141844
 >> iter 29000, loss: 0.206478
 >> iter 30000, loss: 0.299967
   Number of active neurons: 3
 >> iter 31000, loss: 0.437371
 >> iter 32000, loss: 0.471858
 >> iter 33000, loss: 0.399803
 >> iter 34000, loss: 0.408780
 >> iter 35000, loss: 0.435732
 >> iter 36000, loss: 0.304249
 >> iter 37000, loss: 0.347225
 >> iter 38000, loss: 0.332438
 >> iter 39000, loss: 0.297554
 >> iter 40000, loss: 0.357523
   Number of active neurons: 3
 >> iter 41000, loss: 0.273045
 >> iter 42000, loss: 0.245026
 >> iter 43000, loss: 0.164316
 >> iter 44000, loss: 0.170015
 >> iter 45000, loss: 0.220800
 >> iter 46000, loss: 0.322281
 >> iter 47000, loss: 0.257712
 >> iter 48000, loss: 0.204145
 >> iter 49000, loss: 0.313574
 >> iter 50000, loss: 0.349524
   Number of active neurons: 3
 >> iter 51000, loss: 0.313817
 >> iter 52000, loss: 0.194003
 >> iter 53000, loss: 0.337617
 >> iter 54000, loss: 0.171353
 >> iter 55000, loss: 0.125744
 >> iter 56000, loss: 0.293131
 >> iter 57000, loss: 0.365006
 >> iter 58000, loss: 0.405723
 >> iter 59000, loss: 0.430034
 >> iter 60000, loss: 0.515986
   Number of active neurons: 3
 >> iter 61000, loss: 0.456991
 >> iter 62000, loss: 0.272858
 >> iter 63000, loss: 0.192184
 >> iter 64000, loss: 0.154869
 >> iter 65000, loss: 0.338532
 >> iter 66000, loss: 0.380035
 >> iter 67000, loss: 0.290948
 >> iter 68000, loss: 0.272888
 >> iter 69000, loss: 0.378525
 >> iter 70000, loss: 0.341720
   Number of active neurons: 3
 >> iter 71000, loss: 0.324587
 >> iter 72000, loss: 0.429207
 >> iter 73000, loss: 0.466883
 >> iter 74000, loss: 0.272746
 >> iter 75000, loss: 0.246373
 >> iter 76000, loss: 0.230792
 >> iter 77000, loss: 0.159289
 >> iter 78000, loss: 0.190857
 >> iter 79000, loss: 0.142332
 >> iter 80000, loss: 0.341546
   Number of active neurons: 3
 >> iter 81000, loss: 0.370054
 >> iter 82000, loss: 0.186201
 >> iter 83000, loss: 0.161194
 >> iter 84000, loss: 0.445968
 >> iter 85000, loss: 0.435062
 >> iter 86000, loss: 0.293251
 >> iter 87000, loss: 0.319287
 >> iter 88000, loss: 0.293715
 >> iter 89000, loss: 0.274257
 >> iter 90000, loss: 0.341972
   Number of active neurons: 3
 >> iter 91000, loss: 0.264084
 >> iter 92000, loss: 0.201738
 >> iter 93000, loss: 0.200023
 >> iter 94000, loss: 0.168748
 >> iter 95000, loss: 0.197652
 >> iter 96000, loss: 0.150079
 >> iter 97000, loss: 0.272314
 >> iter 98000, loss: 0.201916
 >> iter 99000, loss: 0.162090
 >> iter 100000, loss: 0.251200
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 17.451548
 >> iter 2000, loss: 9.299672
 >> iter 3000, loss: 4.826083
 >> iter 4000, loss: 2.659142
 >> iter 5000, loss: 1.658308
 >> iter 6000, loss: 1.136194
 >> iter 7000, loss: 0.817204
 >> iter 8000, loss: 0.674766
 >> iter 9000, loss: 0.580768
 >> iter 10000, loss: 0.427781
   Number of active neurons: 3
 >> iter 11000, loss: 0.416655
 >> iter 12000, loss: 0.431137
 >> iter 13000, loss: 0.527075
 >> iter 14000, loss: 0.575495
 >> iter 15000, loss: 0.465700
 >> iter 16000, loss: 0.592534
 >> iter 17000, loss: 0.614322
 >> iter 18000, loss: 0.423093
 >> iter 19000, loss: 0.492945
 >> iter 20000, loss: 0.588386
   Number of active neurons: 3
 >> iter 21000, loss: 0.495734
 >> iter 22000, loss: 0.588983
 >> iter 23000, loss: 0.464295
 >> iter 24000, loss: 0.679603
 >> iter 25000, loss: 0.452539
 >> iter 26000, loss: 0.572635
 >> iter 27000, loss: 0.632579
 >> iter 28000, loss: 0.502873
 >> iter 29000, loss: 0.440079
 >> iter 30000, loss: 0.483211
   Number of active neurons: 3
 >> iter 31000, loss: 0.535750
 >> iter 32000, loss: 0.414017
 >> iter 33000, loss: 0.599751
 >> iter 34000, loss: 0.531646
 >> iter 35000, loss: 0.568659
 >> iter 36000, loss: 0.340290
 >> iter 37000, loss: 0.356308
 >> iter 38000, loss: 0.448040
 >> iter 39000, loss: 0.405107
 >> iter 40000, loss: 0.368180
   Number of active neurons: 3
 >> iter 41000, loss: 0.675341
 >> iter 42000, loss: 0.622623
 >> iter 43000, loss: 0.490174
 >> iter 44000, loss: 0.413879
 >> iter 45000, loss: 0.403243
 >> iter 46000, loss: 0.592093
 >> iter 47000, loss: 0.651694
 >> iter 48000, loss: 0.561401
 >> iter 49000, loss: 0.731965
 >> iter 50000, loss: 0.700830
   Number of active neurons: 3
 >> iter 51000, loss: 0.584230
 >> iter 52000, loss: 0.651798
 >> iter 53000, loss: 0.481488
 >> iter 54000, loss: 0.611058
 >> iter 55000, loss: 0.407725
 >> iter 56000, loss: 0.557808
 >> iter 57000, loss: 0.541698
 >> iter 58000, loss: 0.622531
 >> iter 59000, loss: 0.485497
 >> iter 60000, loss: 0.352009
   Number of active neurons: 3
 >> iter 61000, loss: 0.303110
 >> iter 62000, loss: 0.348405
 >> iter 63000, loss: 0.514875
 >> iter 64000, loss: 0.835324
 >> iter 65000, loss: 0.632336
 >> iter 66000, loss: 0.367927
 >> iter 67000, loss: 0.439317
 >> iter 68000, loss: 0.586081
 >> iter 69000, loss: 0.646554
 >> iter 70000, loss: 0.640755
   Number of active neurons: 3
 >> iter 71000, loss: 0.695668
 >> iter 72000, loss: 0.610624
 >> iter 73000, loss: 0.478009
 >> iter 74000, loss: 0.407376
 >> iter 75000, loss: 0.487173
 >> iter 76000, loss: 0.571869
 >> iter 77000, loss: 0.457918
 >> iter 78000, loss: 0.618016
 >> iter 79000, loss: 0.499314
 >> iter 80000, loss: 0.619243
   Number of active neurons: 3
 >> iter 81000, loss: 0.500699
 >> iter 82000, loss: 0.408078
 >> iter 83000, loss: 0.463252
 >> iter 84000, loss: 0.411261
 >> iter 85000, loss: 0.568536
 >> iter 86000, loss: 0.769650
 >> iter 87000, loss: 0.670917
 >> iter 88000, loss: 0.434495
 >> iter 89000, loss: 0.402415
 >> iter 90000, loss: 0.410587
   Number of active neurons: 3
 >> iter 91000, loss: 0.465515
 >> iter 92000, loss: 0.483635
 >> iter 93000, loss: 0.508442
 >> iter 94000, loss: 0.436494
 >> iter 95000, loss: 0.490437
 >> iter 96000, loss: 0.473665
 >> iter 97000, loss: 0.538737
 >> iter 98000, loss: 0.404907
 >> iter 99000, loss: 0.510636
 >> iter 100000, loss: 0.529505
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.940536
 >> iter 2000, loss: 9.470573
 >> iter 3000, loss: 4.467708
 >> iter 4000, loss: 2.066474
 >> iter 5000, loss: 1.055418
 >> iter 6000, loss: 0.682468
 >> iter 7000, loss: 0.582054
 >> iter 8000, loss: 0.363956
 >> iter 9000, loss: 0.544269
 >> iter 10000, loss: 0.515204
   Number of active neurons: 5
 >> iter 11000, loss: 0.407658
 >> iter 12000, loss: 0.370576
 >> iter 13000, loss: 0.367645
 >> iter 14000, loss: 0.189837
 >> iter 15000, loss: 0.230976
 >> iter 16000, loss: 0.270551
 >> iter 17000, loss: 0.409331
 >> iter 18000, loss: 0.318395
 >> iter 19000, loss: 0.412882
 >> iter 20000, loss: 0.365159
   Number of active neurons: 4
 >> iter 21000, loss: 0.422805
 >> iter 22000, loss: 0.401121
 >> iter 23000, loss: 0.251349
 >> iter 24000, loss: 0.189517
 >> iter 25000, loss: 0.361672
 >> iter 26000, loss: 0.478668
 >> iter 27000, loss: 0.291781
 >> iter 28000, loss: 0.378961
 >> iter 29000, loss: 0.316387
 >> iter 30000, loss: 0.442646
   Number of active neurons: 4
 >> iter 31000, loss: 0.385141
 >> iter 32000, loss: 0.321128
 >> iter 33000, loss: 0.321454
 >> iter 34000, loss: 0.451370
 >> iter 35000, loss: 0.362120
 >> iter 36000, loss: 0.369905
 >> iter 37000, loss: 0.347375
 >> iter 38000, loss: 0.303289
 >> iter 39000, loss: 0.234442
 >> iter 40000, loss: 0.299866
   Number of active neurons: 3
 >> iter 41000, loss: 0.304149
 >> iter 42000, loss: 0.335269
 >> iter 43000, loss: 0.244052
 >> iter 44000, loss: 0.217218
 >> iter 45000, loss: 0.223332
 >> iter 46000, loss: 0.270445
 >> iter 47000, loss: 0.352653
 >> iter 48000, loss: 0.210977
 >> iter 49000, loss: 0.160109
 >> iter 50000, loss: 0.435403
   Number of active neurons: 3
 >> iter 51000, loss: 0.338545
 >> iter 52000, loss: 0.206563
 >> iter 53000, loss: 0.252894
 >> iter 54000, loss: 0.250071
 >> iter 55000, loss: 0.321279
 >> iter 56000, loss: 0.244901
 >> iter 57000, loss: 0.324065
 >> iter 58000, loss: 0.297849
 >> iter 59000, loss: 0.544169
 >> iter 60000, loss: 0.516733
   Number of active neurons: 3
 >> iter 61000, loss: 0.359641
 >> iter 62000, loss: 0.247562
 >> iter 63000, loss: 0.246404
 >> iter 64000, loss: 0.149733
 >> iter 65000, loss: 0.250862
 >> iter 66000, loss: 0.193683
 >> iter 67000, loss: 0.184286
 >> iter 68000, loss: 0.156087
 >> iter 69000, loss: 0.151647
 >> iter 70000, loss: 0.360532
   Number of active neurons: 3
 >> iter 71000, loss: 0.343300
 >> iter 72000, loss: 0.302227
 >> iter 73000, loss: 0.296414
 >> iter 74000, loss: 0.292711
 >> iter 75000, loss: 0.261015
 >> iter 76000, loss: 0.303993
 >> iter 77000, loss: 0.382652
 >> iter 78000, loss: 0.276816
 >> iter 79000, loss: 0.400691
 >> iter 80000, loss: 0.208241
   Number of active neurons: 3
 >> iter 81000, loss: 0.128540
 >> iter 82000, loss: 0.139443
 >> iter 83000, loss: 0.207540
 >> iter 84000, loss: 0.291916
 >> iter 85000, loss: 0.229378
 >> iter 86000, loss: 0.355669
 >> iter 87000, loss: 0.237499
 >> iter 88000, loss: 0.292553
 >> iter 89000, loss: 0.276426
 >> iter 90000, loss: 0.235217
   Number of active neurons: 3
 >> iter 91000, loss: 0.261935
 >> iter 92000, loss: 0.180446
 >> iter 93000, loss: 0.135549
 >> iter 94000, loss: 0.120149
 >> iter 95000, loss: 0.115481
 >> iter 96000, loss: 0.183831
 >> iter 97000, loss: 0.138438
 >> iter 98000, loss: 0.217089
 >> iter 99000, loss: 0.172764
 >> iter 100000, loss: 0.100848
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.804288
 >> iter 2000, loss: 9.258380
 >> iter 3000, loss: 4.264557
 >> iter 4000, loss: 1.918258
 >> iter 5000, loss: 0.971789
 >> iter 6000, loss: 0.631572
 >> iter 7000, loss: 0.460960
 >> iter 8000, loss: 0.794137
 >> iter 9000, loss: 0.577620
 >> iter 10000, loss: 0.397999
   Number of active neurons: 5
 >> iter 11000, loss: 0.459282
 >> iter 12000, loss: 0.357563
 >> iter 13000, loss: 0.438262
 >> iter 14000, loss: 0.314079
 >> iter 15000, loss: 0.221032
 >> iter 16000, loss: 0.348190
 >> iter 17000, loss: 0.320490
 >> iter 18000, loss: 0.620331
 >> iter 19000, loss: 0.547600
 >> iter 20000, loss: 0.388480
   Number of active neurons: 5
 >> iter 21000, loss: 0.306588
 >> iter 22000, loss: 0.584817
 >> iter 23000, loss: 0.425790
 >> iter 24000, loss: 0.373925
 >> iter 25000, loss: 0.334551
 >> iter 26000, loss: 0.220044
 >> iter 27000, loss: 0.426860
 >> iter 28000, loss: 0.440274
 >> iter 29000, loss: 0.336111
 >> iter 30000, loss: 0.297022
   Number of active neurons: 5
 >> iter 31000, loss: 0.241380
 >> iter 32000, loss: 0.199788
 >> iter 33000, loss: 0.336686
 >> iter 34000, loss: 0.420891
 >> iter 35000, loss: 0.411305
 >> iter 36000, loss: 0.431637
 >> iter 37000, loss: 0.496989
 >> iter 38000, loss: 0.333730
 >> iter 39000, loss: 0.252992
 >> iter 40000, loss: 0.273157
   Number of active neurons: 5
 >> iter 41000, loss: 0.253876
 >> iter 42000, loss: 0.210301
 >> iter 43000, loss: 0.215775
 >> iter 44000, loss: 0.387778
 >> iter 45000, loss: 0.315450
 >> iter 46000, loss: 0.718204
 >> iter 47000, loss: 0.485435
 >> iter 48000, loss: 0.325877
 >> iter 49000, loss: 0.299506
 >> iter 50000, loss: 0.363825
   Number of active neurons: 4
 >> iter 51000, loss: 0.325380
 >> iter 52000, loss: 0.251505
 >> iter 53000, loss: 0.256998
 >> iter 54000, loss: 0.245233
 >> iter 55000, loss: 0.301954
 >> iter 56000, loss: 0.206897
 >> iter 57000, loss: 0.148382
 >> iter 58000, loss: 0.160239
 >> iter 59000, loss: 0.148582
 >> iter 60000, loss: 0.540849
   Number of active neurons: 4
 >> iter 61000, loss: 0.391561
 >> iter 62000, loss: 0.334547
 >> iter 63000, loss: 0.358252
 >> iter 64000, loss: 0.251920
 >> iter 65000, loss: 0.185897
 >> iter 66000, loss: 0.211044
 >> iter 67000, loss: 0.392207
 >> iter 68000, loss: 0.245236
 >> iter 69000, loss: 0.305722
 >> iter 70000, loss: 0.304195
   Number of active neurons: 4
 >> iter 71000, loss: 0.163278
 >> iter 72000, loss: 0.201515
 >> iter 73000, loss: 0.129348
 >> iter 74000, loss: 0.286469
 >> iter 75000, loss: 0.324186
 >> iter 76000, loss: 0.232189
 >> iter 77000, loss: 0.179634
 >> iter 78000, loss: 0.397431
 >> iter 79000, loss: 0.368466
 >> iter 80000, loss: 0.270877
   Number of active neurons: 4
 >> iter 81000, loss: 0.265743
 >> iter 82000, loss: 0.251239
 >> iter 83000, loss: 0.305338
 >> iter 84000, loss: 0.342326
 >> iter 85000, loss: 0.184476
 >> iter 86000, loss: 0.178980
 >> iter 87000, loss: 0.393005
 >> iter 88000, loss: 0.237969
 >> iter 89000, loss: 0.259033
 >> iter 90000, loss: 0.262262
   Number of active neurons: 3
 >> iter 91000, loss: 0.339226
 >> iter 92000, loss: 0.291439
 >> iter 93000, loss: 0.208594
 >> iter 94000, loss: 0.243423
 >> iter 95000, loss: 0.236772
 >> iter 96000, loss: 0.143083
 >> iter 97000, loss: 0.329243
 >> iter 98000, loss: 0.249342
 >> iter 99000, loss: 0.233773
 >> iter 100000, loss: 0.139846
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.541105
 >> iter 2000, loss: 8.492275
 >> iter 3000, loss: 4.138659
 >> iter 4000, loss: 2.172323
 >> iter 5000, loss: 1.196664
 >> iter 6000, loss: 0.603890
 >> iter 7000, loss: 0.419962
 >> iter 8000, loss: 0.472492
 >> iter 9000, loss: 0.434213
 >> iter 10000, loss: 0.315739
   Number of active neurons: 3
 >> iter 11000, loss: 0.301721
 >> iter 12000, loss: 0.428582
 >> iter 13000, loss: 0.513396
 >> iter 14000, loss: 0.331725
 >> iter 15000, loss: 0.281799
 >> iter 16000, loss: 0.216204
 >> iter 17000, loss: 0.324784
 >> iter 18000, loss: 0.179885
 >> iter 19000, loss: 0.187512
 >> iter 20000, loss: 0.364458
   Number of active neurons: 3
 >> iter 21000, loss: 0.330795
 >> iter 22000, loss: 0.226796
 >> iter 23000, loss: 0.316156
 >> iter 24000, loss: 0.219816
 >> iter 25000, loss: 0.362733
 >> iter 26000, loss: 0.294184
 >> iter 27000, loss: 0.234693
 >> iter 28000, loss: 0.411506
 >> iter 29000, loss: 0.404877
 >> iter 30000, loss: 0.223460
   Number of active neurons: 3
 >> iter 31000, loss: 0.312365
 >> iter 32000, loss: 0.403446
 >> iter 33000, loss: 0.390456
 >> iter 34000, loss: 0.319053
 >> iter 35000, loss: 0.204466
 >> iter 36000, loss: 0.351810
 >> iter 37000, loss: 0.286985
 >> iter 38000, loss: 0.166118
 >> iter 39000, loss: 0.158713
 >> iter 40000, loss: 0.183774
   Number of active neurons: 3
 >> iter 41000, loss: 0.130549
 >> iter 42000, loss: 0.075902
 >> iter 43000, loss: 0.430010
 >> iter 44000, loss: 0.268255
 >> iter 45000, loss: 0.388445
 >> iter 46000, loss: 0.329190
 >> iter 47000, loss: 0.187819
 >> iter 48000, loss: 0.227790
 >> iter 49000, loss: 0.157827
 >> iter 50000, loss: 0.188351
   Number of active neurons: 3
 >> iter 51000, loss: 0.242592
 >> iter 52000, loss: 0.284890
 >> iter 53000, loss: 0.225675
 >> iter 54000, loss: 0.355047
 >> iter 55000, loss: 0.270747
 >> iter 56000, loss: 0.171961
 >> iter 57000, loss: 0.137987
 >> iter 58000, loss: 0.544601
 >> iter 59000, loss: 0.356921
 >> iter 60000, loss: 0.389764
   Number of active neurons: 3
 >> iter 61000, loss: 0.185206
 >> iter 62000, loss: 0.277482
 >> iter 63000, loss: 0.221006
 >> iter 64000, loss: 0.188731
 >> iter 65000, loss: 0.275507
 >> iter 66000, loss: 0.171387
 >> iter 67000, loss: 0.209945
 >> iter 68000, loss: 0.209192
 >> iter 69000, loss: 0.253495
 >> iter 70000, loss: 0.236799
   Number of active neurons: 3
 >> iter 71000, loss: 0.250599
 >> iter 72000, loss: 0.178269
 >> iter 73000, loss: 0.111452
 >> iter 74000, loss: 0.235797
 >> iter 75000, loss: 0.150827
 >> iter 76000, loss: 0.183507
 >> iter 77000, loss: 0.187693
 >> iter 78000, loss: 0.247751
 >> iter 79000, loss: 0.184131
 >> iter 80000, loss: 0.145590
   Number of active neurons: 3
 >> iter 81000, loss: 0.235760
 >> iter 82000, loss: 0.382341
 >> iter 83000, loss: 0.338990
 >> iter 84000, loss: 0.211756
 >> iter 85000, loss: 0.232036
 >> iter 86000, loss: 0.183204
 >> iter 87000, loss: 0.119260
 >> iter 88000, loss: 0.244737
 >> iter 89000, loss: 0.479640
 >> iter 90000, loss: 0.386084
   Number of active neurons: 3
 >> iter 91000, loss: 0.333423
 >> iter 92000, loss: 0.226737
 >> iter 93000, loss: 0.231506
 >> iter 94000, loss: 0.321027
 >> iter 95000, loss: 0.228118
 >> iter 96000, loss: 0.340021
 >> iter 97000, loss: 0.232912
 >> iter 98000, loss: 0.378666
 >> iter 99000, loss: 0.180923
 >> iter 100000, loss: 0.231715
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

