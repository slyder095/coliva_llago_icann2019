 > Problema: tomita1nueva
 > Args:
   - Hidden size: 4
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.987934
 >> iter 2000, loss: 4.093693
 >> iter 3000, loss: 1.529141
 >> iter 4000, loss: 0.581184
 >> iter 5000, loss: 0.236206
 >> iter 6000, loss: 0.102862
 >> iter 7000, loss: 0.052937
 >> iter 8000, loss: 0.035423
 >> iter 9000, loss: 0.031916
 >> iter 10000, loss: 0.029256
   Number of active neurons: 3
 >> iter 11000, loss: 0.043718
 >> iter 12000, loss: 0.036468
 >> iter 13000, loss: 0.030914
 >> iter 14000, loss: 0.026596
 >> iter 15000, loss: 0.025498
 >> iter 16000, loss: 0.021905
 >> iter 17000, loss: 0.024663
 >> iter 18000, loss: 0.027085
 >> iter 19000, loss: 0.025549
 >> iter 20000, loss: 0.029077
   Number of active neurons: 2
 >> iter 21000, loss: 0.023011
 >> iter 22000, loss: 0.029548
 >> iter 23000, loss: 0.063207
 >> iter 24000, loss: 0.036549
 >> iter 25000, loss: 0.028661
 >> iter 26000, loss: 0.026619
 >> iter 27000, loss: 0.028726
 >> iter 28000, loss: 0.024065
 >> iter 29000, loss: 0.025178
 >> iter 30000, loss: 0.024820
   Number of active neurons: 2
 >> iter 31000, loss: 0.025052
 >> iter 32000, loss: 0.027798
 >> iter 33000, loss: 0.024079
 >> iter 34000, loss: 0.059429
 >> iter 35000, loss: 0.036730
 >> iter 36000, loss: 0.037433
 >> iter 37000, loss: 0.034789
 >> iter 38000, loss: 0.027785
 >> iter 39000, loss: 0.025797
 >> iter 40000, loss: 0.049606
   Number of active neurons: 1
 >> iter 41000, loss: 0.032213
 >> iter 42000, loss: 0.025311
 >> iter 43000, loss: 0.021619
 >> iter 44000, loss: 0.021272
 >> iter 45000, loss: 0.028239
 >> iter 46000, loss: 0.023538
 >> iter 47000, loss: 0.021862
 >> iter 48000, loss: 0.059260
 >> iter 49000, loss: 0.032754
 >> iter 50000, loss: 0.022832
   Number of active neurons: 1
 >> iter 51000, loss: 0.018690
 >> iter 52000, loss: 0.018562
 >> iter 53000, loss: 0.017298
 >> iter 54000, loss: 0.024112
 >> iter 55000, loss: 0.028689
 >> iter 56000, loss: 0.020554
 >> iter 57000, loss: 0.020093
 >> iter 58000, loss: 0.022783
 >> iter 59000, loss: 0.018086
 >> iter 60000, loss: 0.020725
   Number of active neurons: 1
 >> iter 61000, loss: 0.034907
 >> iter 62000, loss: 0.030074
 >> iter 63000, loss: 0.026789
 >> iter 64000, loss: 0.020116
 >> iter 65000, loss: 0.020122
 >> iter 66000, loss: 0.022448
 >> iter 67000, loss: 0.018575
 >> iter 68000, loss: 0.021448
 >> iter 69000, loss: 0.018329
 >> iter 70000, loss: 0.022786
   Number of active neurons: 1
 >> iter 71000, loss: 0.042400
 >> iter 72000, loss: 0.025909
 >> iter 73000, loss: 0.020395
 >> iter 74000, loss: 0.018322
 >> iter 75000, loss: 0.028022
 >> iter 76000, loss: 0.034946
 >> iter 77000, loss: 0.047612
 >> iter 78000, loss: 0.032378
 >> iter 79000, loss: 0.025860
 >> iter 80000, loss: 0.020006
   Number of active neurons: 1
 >> iter 81000, loss: 0.017485
 >> iter 82000, loss: 0.018223
 >> iter 83000, loss: 0.016622
 >> iter 84000, loss: 0.025183
 >> iter 85000, loss: 0.022726
 >> iter 86000, loss: 0.019430
 >> iter 87000, loss: 0.018304
 >> iter 88000, loss: 0.020881
 >> iter 89000, loss: 0.027361
 >> iter 90000, loss: 0.053125
   Number of active neurons: 1
 >> iter 91000, loss: 0.033127
 >> iter 92000, loss: 0.025775
 >> iter 93000, loss: 0.019049
 >> iter 94000, loss: 0.019859
 >> iter 95000, loss: 0.018946
 >> iter 96000, loss: 0.023020
 >> iter 97000, loss: 0.018634
 >> iter 98000, loss: 0.028194
 >> iter 99000, loss: 0.024704
 >> iter 100000, loss: 0.019499
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.038714
 >> iter 2000, loss: 4.101617
 >> iter 3000, loss: 1.533868
 >> iter 4000, loss: 0.588080
 >> iter 5000, loss: 0.234157
 >> iter 6000, loss: 0.104271
 >> iter 7000, loss: 0.061165
 >> iter 8000, loss: 0.038277
 >> iter 9000, loss: 0.044259
 >> iter 10000, loss: 0.047992
   Number of active neurons: 3
 >> iter 11000, loss: 0.034231
 >> iter 12000, loss: 0.029093
 >> iter 13000, loss: 0.027675
 >> iter 14000, loss: 0.025766
 >> iter 15000, loss: 0.026406
 >> iter 16000, loss: 0.033690
 >> iter 17000, loss: 0.031204
 >> iter 18000, loss: 0.024404
 >> iter 19000, loss: 0.027320
 >> iter 20000, loss: 0.021641
   Number of active neurons: 1
 >> iter 21000, loss: 0.018395
 >> iter 22000, loss: 0.027902
 >> iter 23000, loss: 0.030607
 >> iter 24000, loss: 0.022795
 >> iter 25000, loss: 0.018515
 >> iter 26000, loss: 0.037745
 >> iter 27000, loss: 0.025748
 >> iter 28000, loss: 0.025278
 >> iter 29000, loss: 0.020577
 >> iter 30000, loss: 0.017235
   Number of active neurons: 1
 >> iter 31000, loss: 0.018750
 >> iter 32000, loss: 0.016923
 >> iter 33000, loss: 0.017331
 >> iter 34000, loss: 0.017524
 >> iter 35000, loss: 0.022594
 >> iter 36000, loss: 0.020969
 >> iter 37000, loss: 0.021229
 >> iter 38000, loss: 0.019980
 >> iter 39000, loss: 0.016894
 >> iter 40000, loss: 0.015776
   Number of active neurons: 1
 >> iter 41000, loss: 0.023230
 >> iter 42000, loss: 0.034438
 >> iter 43000, loss: 0.028241
 >> iter 44000, loss: 0.025442
 >> iter 45000, loss: 0.024655
 >> iter 46000, loss: 0.032914
 >> iter 47000, loss: 0.023299
 >> iter 48000, loss: 0.019252
 >> iter 49000, loss: 0.018626
 >> iter 50000, loss: 0.017134
   Number of active neurons: 1
 >> iter 51000, loss: 0.017857
 >> iter 52000, loss: 0.021718
 >> iter 53000, loss: 0.018609
 >> iter 54000, loss: 0.017139
 >> iter 55000, loss: 0.024240
 >> iter 56000, loss: 0.034545
 >> iter 57000, loss: 0.027288
 >> iter 58000, loss: 0.021507
 >> iter 59000, loss: 0.019683
 >> iter 60000, loss: 0.016986
   Number of active neurons: 1
 >> iter 61000, loss: 0.021163
 >> iter 62000, loss: 0.022571
 >> iter 63000, loss: 0.024770
 >> iter 64000, loss: 0.031321
 >> iter 65000, loss: 0.022194
 >> iter 66000, loss: 0.027428
 >> iter 67000, loss: 0.021034
 >> iter 68000, loss: 0.029496
 >> iter 69000, loss: 0.022175
 >> iter 70000, loss: 0.027458
   Number of active neurons: 1
 >> iter 71000, loss: 0.021428
 >> iter 72000, loss: 0.019165
 >> iter 73000, loss: 0.020886
 >> iter 74000, loss: 0.020186
 >> iter 75000, loss: 0.024362
 >> iter 76000, loss: 0.023525
 >> iter 77000, loss: 0.023504
 >> iter 78000, loss: 0.018259
 >> iter 79000, loss: 0.024206
 >> iter 80000, loss: 0.071150
   Number of active neurons: 1
 >> iter 81000, loss: 0.039646
 >> iter 82000, loss: 0.028561
 >> iter 83000, loss: 0.027289
 >> iter 84000, loss: 0.021827
 >> iter 85000, loss: 0.019990
 >> iter 86000, loss: 0.022372
 >> iter 87000, loss: 0.022860
 >> iter 88000, loss: 0.020326
 >> iter 89000, loss: 0.020071
 >> iter 90000, loss: 0.017027
   Number of active neurons: 1
 >> iter 91000, loss: 0.016020
 >> iter 92000, loss: 0.016852
 >> iter 93000, loss: 0.016373
 >> iter 94000, loss: 0.017044
 >> iter 95000, loss: 0.019799
 >> iter 96000, loss: 0.020083
 >> iter 97000, loss: 0.019600
 >> iter 98000, loss: 0.021818
 >> iter 99000, loss: 0.017421
 >> iter 100000, loss: 0.016275
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.930804
 >> iter 2000, loss: 4.064384
 >> iter 3000, loss: 1.518550
 >> iter 4000, loss: 0.576272
 >> iter 5000, loss: 0.239776
 >> iter 6000, loss: 0.103123
 >> iter 7000, loss: 0.051709
 >> iter 8000, loss: 0.033944
 >> iter 9000, loss: 0.026118
 >> iter 10000, loss: 0.047758
   Number of active neurons: 2
 >> iter 11000, loss: 0.033741
 >> iter 12000, loss: 0.026067
 >> iter 13000, loss: 0.021828
 >> iter 14000, loss: 0.036397
 >> iter 15000, loss: 0.030103
 >> iter 16000, loss: 0.023679
 >> iter 17000, loss: 0.023133
 >> iter 18000, loss: 0.020027
 >> iter 19000, loss: 0.027532
 >> iter 20000, loss: 0.025422
   Number of active neurons: 2
 >> iter 21000, loss: 0.023682
 >> iter 22000, loss: 0.022346
 >> iter 23000, loss: 0.024413
 >> iter 24000, loss: 0.023221
 >> iter 25000, loss: 0.026978
 >> iter 26000, loss: 0.021955
 >> iter 27000, loss: 0.021316
 >> iter 28000, loss: 0.019725
 >> iter 29000, loss: 0.021214
 >> iter 30000, loss: 0.020446
   Number of active neurons: 2
 >> iter 31000, loss: 0.023891
 >> iter 32000, loss: 0.028032
 >> iter 33000, loss: 0.024397
 >> iter 34000, loss: 0.024621
 >> iter 35000, loss: 0.022080
 >> iter 36000, loss: 0.023380
 >> iter 37000, loss: 0.024209
 >> iter 38000, loss: 0.022777
 >> iter 39000, loss: 0.040263
 >> iter 40000, loss: 0.038556
   Number of active neurons: 2
 >> iter 41000, loss: 0.034518
 >> iter 42000, loss: 0.025903
 >> iter 43000, loss: 0.022861
 >> iter 44000, loss: 0.020548
 >> iter 45000, loss: 0.022409
 >> iter 46000, loss: 0.021483
 >> iter 47000, loss: 0.027145
 >> iter 48000, loss: 0.023806
 >> iter 49000, loss: 0.020931
 >> iter 50000, loss: 0.026880
   Number of active neurons: 2
 >> iter 51000, loss: 0.026225
 >> iter 52000, loss: 0.025861
 >> iter 53000, loss: 0.023705
 >> iter 54000, loss: 0.031329
 >> iter 55000, loss: 0.024813
 >> iter 56000, loss: 0.033351
 >> iter 57000, loss: 0.026208
 >> iter 58000, loss: 0.038787
 >> iter 59000, loss: 0.063645
 >> iter 60000, loss: 0.037741
   Number of active neurons: 2
 >> iter 61000, loss: 0.027443
 >> iter 62000, loss: 0.023384
 >> iter 63000, loss: 0.024768
 >> iter 64000, loss: 0.035564
 >> iter 65000, loss: 0.026956
 >> iter 66000, loss: 0.034403
 >> iter 67000, loss: 0.027187
 >> iter 68000, loss: 0.033692
 >> iter 69000, loss: 0.033662
 >> iter 70000, loss: 0.033657
   Number of active neurons: 2
 >> iter 71000, loss: 0.025032
 >> iter 72000, loss: 0.023650
 >> iter 73000, loss: 0.024049
 >> iter 74000, loss: 0.020743
 >> iter 75000, loss: 0.023606
 >> iter 76000, loss: 0.023718
 >> iter 77000, loss: 0.030762
 >> iter 78000, loss: 0.024162
 >> iter 79000, loss: 0.023734
 >> iter 80000, loss: 0.024921
   Number of active neurons: 2
 >> iter 81000, loss: 0.023322
 >> iter 82000, loss: 0.024574
 >> iter 83000, loss: 0.024905
 >> iter 84000, loss: 0.021602
 >> iter 85000, loss: 0.040721
 >> iter 86000, loss: 0.031120
 >> iter 87000, loss: 0.037378
 >> iter 88000, loss: 0.030498
 >> iter 89000, loss: 0.025491
 >> iter 90000, loss: 0.024914
   Number of active neurons: 1
 >> iter 91000, loss: 0.021762
 >> iter 92000, loss: 0.020720
 >> iter 93000, loss: 0.018265
 >> iter 94000, loss: 0.018029
 >> iter 95000, loss: 0.020859
 >> iter 96000, loss: 0.022406
 >> iter 97000, loss: 0.028885
 >> iter 98000, loss: 0.028539
 >> iter 99000, loss: 0.021673
 >> iter 100000, loss: 0.019171
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.983481
 >> iter 2000, loss: 4.080123
 >> iter 3000, loss: 1.526008
 >> iter 4000, loss: 0.580120
 >> iter 5000, loss: 0.228680
 >> iter 6000, loss: 0.098503
 >> iter 7000, loss: 0.057197
 >> iter 8000, loss: 0.042577
 >> iter 9000, loss: 0.028502
 >> iter 10000, loss: 0.030458
   Number of active neurons: 2
 >> iter 11000, loss: 0.026886
 >> iter 12000, loss: 0.025298
 >> iter 13000, loss: 0.021905
 >> iter 14000, loss: 0.020141
 >> iter 15000, loss: 0.021259
 >> iter 16000, loss: 0.020854
 >> iter 17000, loss: 0.036007
 >> iter 18000, loss: 0.027482
 >> iter 19000, loss: 0.026667
 >> iter 20000, loss: 0.022369
   Number of active neurons: 2
 >> iter 21000, loss: 0.029377
 >> iter 22000, loss: 0.024643
 >> iter 23000, loss: 0.025113
 >> iter 24000, loss: 0.031151
 >> iter 25000, loss: 0.025791
 >> iter 26000, loss: 0.022095
 >> iter 27000, loss: 0.045775
 >> iter 28000, loss: 0.031474
 >> iter 29000, loss: 0.026673
 >> iter 30000, loss: 0.021469
   Number of active neurons: 2
 >> iter 31000, loss: 0.020677
 >> iter 32000, loss: 0.019990
 >> iter 33000, loss: 0.022695
 >> iter 34000, loss: 0.021039
 >> iter 35000, loss: 0.024473
 >> iter 36000, loss: 0.023203
 >> iter 37000, loss: 0.020393
 >> iter 38000, loss: 0.021280
 >> iter 39000, loss: 0.021006
 >> iter 40000, loss: 0.022983
   Number of active neurons: 2
 >> iter 41000, loss: 0.020820
 >> iter 42000, loss: 0.022415
 >> iter 43000, loss: 0.021100
 >> iter 44000, loss: 0.019902
 >> iter 45000, loss: 0.020412
 >> iter 46000, loss: 0.030477
 >> iter 47000, loss: 0.025639
 >> iter 48000, loss: 0.025442
 >> iter 49000, loss: 0.021210
 >> iter 50000, loss: 0.021656
   Number of active neurons: 2
 >> iter 51000, loss: 0.021418
 >> iter 52000, loss: 0.020572
 >> iter 53000, loss: 0.021010
 >> iter 54000, loss: 0.024397
 >> iter 55000, loss: 0.022839
 >> iter 56000, loss: 0.034216
 >> iter 57000, loss: 0.025258
 >> iter 58000, loss: 0.025267
 >> iter 59000, loss: 0.020737
 >> iter 60000, loss: 0.020498
   Number of active neurons: 2
 >> iter 61000, loss: 0.026860
 >> iter 62000, loss: 0.024494
 >> iter 63000, loss: 0.030821
 >> iter 64000, loss: 0.025227
 >> iter 65000, loss: 0.021259
 >> iter 66000, loss: 0.026849
 >> iter 67000, loss: 0.025635
 >> iter 68000, loss: 0.051956
 >> iter 69000, loss: 0.032668
 >> iter 70000, loss: 0.031109
   Number of active neurons: 2
 >> iter 71000, loss: 0.025240
 >> iter 72000, loss: 0.023703
 >> iter 73000, loss: 0.021294
 >> iter 74000, loss: 0.023732
 >> iter 75000, loss: 0.025060
 >> iter 76000, loss: 0.031297
 >> iter 77000, loss: 0.024777
 >> iter 78000, loss: 0.024491
 >> iter 79000, loss: 0.047693
 >> iter 80000, loss: 0.033366
   Number of active neurons: 2
 >> iter 81000, loss: 0.040908
 >> iter 82000, loss: 0.035796
 >> iter 83000, loss: 0.029367
 >> iter 84000, loss: 0.022840
 >> iter 85000, loss: 0.020741
 >> iter 86000, loss: 0.024441
 >> iter 87000, loss: 0.021141
 >> iter 88000, loss: 0.021984
 >> iter 89000, loss: 0.036840
 >> iter 90000, loss: 0.025937
   Number of active neurons: 2
 >> iter 91000, loss: 0.027422
 >> iter 92000, loss: 0.038559
 >> iter 93000, loss: 0.028394
 >> iter 94000, loss: 0.024017
 >> iter 95000, loss: 0.023399
 >> iter 96000, loss: 0.022293
 >> iter 97000, loss: 0.032337
 >> iter 98000, loss: 0.034614
 >> iter 99000, loss: 0.024322
 >> iter 100000, loss: 0.030894
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.968003
 >> iter 2000, loss: 4.067303
 >> iter 3000, loss: 1.523622
 >> iter 4000, loss: 0.583549
 >> iter 5000, loss: 0.231636
 >> iter 6000, loss: 0.103084
 >> iter 7000, loss: 0.054421
 >> iter 8000, loss: 0.035705
 >> iter 9000, loss: 0.027110
 >> iter 10000, loss: 0.025274
   Number of active neurons: 3
 >> iter 11000, loss: 0.024199
 >> iter 12000, loss: 0.034781
 >> iter 13000, loss: 0.032090
 >> iter 14000, loss: 0.027678
 >> iter 15000, loss: 0.030093
 >> iter 16000, loss: 0.035330
 >> iter 17000, loss: 0.034055
 >> iter 18000, loss: 0.038088
 >> iter 19000, loss: 0.030234
 >> iter 20000, loss: 0.027752
   Number of active neurons: 3
 >> iter 21000, loss: 0.024349
 >> iter 22000, loss: 0.025687
 >> iter 23000, loss: 0.024750
 >> iter 24000, loss: 0.022977
 >> iter 25000, loss: 0.024981
 >> iter 26000, loss: 0.028001
 >> iter 27000, loss: 0.031858
 >> iter 28000, loss: 0.026019
 >> iter 29000, loss: 0.035773
 >> iter 30000, loss: 0.030307
   Number of active neurons: 3
 >> iter 31000, loss: 0.024770
 >> iter 32000, loss: 0.023758
 >> iter 33000, loss: 0.027646
 >> iter 34000, loss: 0.022500
 >> iter 35000, loss: 0.025061
 >> iter 36000, loss: 0.030947
 >> iter 37000, loss: 0.028925
 >> iter 38000, loss: 0.025873
 >> iter 39000, loss: 0.023604
 >> iter 40000, loss: 0.021553
   Number of active neurons: 2
 >> iter 41000, loss: 0.021051
 >> iter 42000, loss: 0.022494
 >> iter 43000, loss: 0.021459
 >> iter 44000, loss: 0.024918
 >> iter 45000, loss: 0.022712
 >> iter 46000, loss: 0.033064
 >> iter 47000, loss: 0.025006
 >> iter 48000, loss: 0.037120
 >> iter 49000, loss: 0.027883
 >> iter 50000, loss: 0.024222
   Number of active neurons: 2
 >> iter 51000, loss: 0.021723
 >> iter 52000, loss: 0.032602
 >> iter 53000, loss: 0.028253
 >> iter 54000, loss: 0.025825
 >> iter 55000, loss: 0.022588
 >> iter 56000, loss: 0.020509
 >> iter 57000, loss: 0.025072
 >> iter 58000, loss: 0.021768
 >> iter 59000, loss: 0.020767
 >> iter 60000, loss: 0.023260
   Number of active neurons: 2
 >> iter 61000, loss: 0.021740
 >> iter 62000, loss: 0.020196
 >> iter 63000, loss: 0.022148
 >> iter 64000, loss: 0.022025
 >> iter 65000, loss: 0.020554
 >> iter 66000, loss: 0.021922
 >> iter 67000, loss: 0.021289
 >> iter 68000, loss: 0.019931
 >> iter 69000, loss: 0.022393
 >> iter 70000, loss: 0.021056
   Number of active neurons: 2
 >> iter 71000, loss: 0.026087
 >> iter 72000, loss: 0.025889
 >> iter 73000, loss: 0.023152
 >> iter 74000, loss: 0.022255
 >> iter 75000, loss: 0.030813
 >> iter 76000, loss: 0.023770
 >> iter 77000, loss: 0.021585
 >> iter 78000, loss: 0.021066
 >> iter 79000, loss: 0.021165
 >> iter 80000, loss: 0.026541
   Number of active neurons: 2
 >> iter 81000, loss: 0.023617
 >> iter 82000, loss: 0.026370
 >> iter 83000, loss: 0.024235
 >> iter 84000, loss: 0.021115
 >> iter 85000, loss: 0.023084
 >> iter 86000, loss: 0.024160
 >> iter 87000, loss: 0.031014
 >> iter 88000, loss: 0.035635
 >> iter 89000, loss: 0.026934
 >> iter 90000, loss: 0.026815
   Number of active neurons: 2
 >> iter 91000, loss: 0.022711
 >> iter 92000, loss: 0.021615
 >> iter 93000, loss: 0.022362
 >> iter 94000, loss: 0.020334
 >> iter 95000, loss: 0.022019
 >> iter 96000, loss: 0.021178
 >> iter 97000, loss: 0.026226
 >> iter 98000, loss: 0.025355
 >> iter 99000, loss: 0.023759
 >> iter 100000, loss: 0.039607
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.976155
 >> iter 2000, loss: 4.071404
 >> iter 3000, loss: 1.529748
 >> iter 4000, loss: 0.591189
 >> iter 5000, loss: 0.234042
 >> iter 6000, loss: 0.120668
 >> iter 7000, loss: 0.060894
 >> iter 8000, loss: 0.040485
 >> iter 9000, loss: 0.035160
 >> iter 10000, loss: 0.032682
   Number of active neurons: 3
 >> iter 11000, loss: 0.027642
 >> iter 12000, loss: 0.025730
 >> iter 13000, loss: 0.032444
 >> iter 14000, loss: 0.028914
 >> iter 15000, loss: 0.027437
 >> iter 16000, loss: 0.024236
 >> iter 17000, loss: 0.028448
 >> iter 18000, loss: 0.032090
 >> iter 19000, loss: 0.027669
 >> iter 20000, loss: 0.024366
   Number of active neurons: 3
 >> iter 21000, loss: 0.036882
 >> iter 22000, loss: 0.030997
 >> iter 23000, loss: 0.041684
 >> iter 24000, loss: 0.033791
 >> iter 25000, loss: 0.027958
 >> iter 26000, loss: 0.023190
 >> iter 27000, loss: 0.023869
 >> iter 28000, loss: 0.021488
 >> iter 29000, loss: 0.032264
 >> iter 30000, loss: 0.025547
   Number of active neurons: 2
 >> iter 31000, loss: 0.022892
 >> iter 32000, loss: 0.027077
 >> iter 33000, loss: 0.024078
 >> iter 34000, loss: 0.021776
 >> iter 35000, loss: 0.021660
 >> iter 36000, loss: 0.022329
 >> iter 37000, loss: 0.022130
 >> iter 38000, loss: 0.020499
 >> iter 39000, loss: 0.027494
 >> iter 40000, loss: 0.023463
   Number of active neurons: 2
 >> iter 41000, loss: 0.028846
 >> iter 42000, loss: 0.035731
 >> iter 43000, loss: 0.026440
 >> iter 44000, loss: 0.029429
 >> iter 45000, loss: 0.024267
 >> iter 46000, loss: 0.020898
 >> iter 47000, loss: 0.022076
 >> iter 48000, loss: 0.023646
 >> iter 49000, loss: 0.023338
 >> iter 50000, loss: 0.021205
   Number of active neurons: 2
 >> iter 51000, loss: 0.020657
 >> iter 52000, loss: 0.021265
 >> iter 53000, loss: 0.024549
 >> iter 54000, loss: 0.021152
 >> iter 55000, loss: 0.021091
 >> iter 56000, loss: 0.020018
 >> iter 57000, loss: 0.025932
 >> iter 58000, loss: 0.024477
 >> iter 59000, loss: 0.020600
 >> iter 60000, loss: 0.040379
   Number of active neurons: 1
 >> iter 61000, loss: 0.030895
 >> iter 62000, loss: 0.028073
 >> iter 63000, loss: 0.021574
 >> iter 64000, loss: 0.022250
 >> iter 65000, loss: 0.022333
 >> iter 66000, loss: 0.029660
 >> iter 67000, loss: 0.025380
 >> iter 68000, loss: 0.028196
 >> iter 69000, loss: 0.033054
 >> iter 70000, loss: 0.023712
   Number of active neurons: 1
 >> iter 71000, loss: 0.021867
 >> iter 72000, loss: 0.045969
 >> iter 73000, loss: 0.035138
 >> iter 74000, loss: 0.022862
 >> iter 75000, loss: 0.020889
 >> iter 76000, loss: 0.018379
 >> iter 77000, loss: 0.036056
 >> iter 78000, loss: 0.024654
 >> iter 79000, loss: 0.042335
 >> iter 80000, loss: 0.027676
   Number of active neurons: 1
 >> iter 81000, loss: 0.021882
 >> iter 82000, loss: 0.019354
 >> iter 83000, loss: 0.018316
 >> iter 84000, loss: 0.023089
 >> iter 85000, loss: 0.025032
 >> iter 86000, loss: 0.020707
 >> iter 87000, loss: 0.016964
 >> iter 88000, loss: 0.020169
 >> iter 89000, loss: 0.031802
 >> iter 90000, loss: 0.023773
   Number of active neurons: 1
 >> iter 91000, loss: 0.020190
 >> iter 92000, loss: 0.017691
 >> iter 93000, loss: 0.019356
 >> iter 94000, loss: 0.016829
 >> iter 95000, loss: 0.018458
 >> iter 96000, loss: 0.020744
 >> iter 97000, loss: 0.024010
 >> iter 98000, loss: 0.020708
 >> iter 99000, loss: 0.033828
 >> iter 100000, loss: 0.023032
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.083404
 >> iter 2000, loss: 4.147932
 >> iter 3000, loss: 1.548279
 >> iter 4000, loss: 0.587898
 >> iter 5000, loss: 0.232547
 >> iter 6000, loss: 0.103300
 >> iter 7000, loss: 0.051891
 >> iter 8000, loss: 0.036868
 >> iter 9000, loss: 0.028523
 >> iter 10000, loss: 0.025905
   Number of active neurons: 3
 >> iter 11000, loss: 0.029295
 >> iter 12000, loss: 0.040481
 >> iter 13000, loss: 0.030582
 >> iter 14000, loss: 0.025227
 >> iter 15000, loss: 0.024083
 >> iter 16000, loss: 0.025663
 >> iter 17000, loss: 0.035769
 >> iter 18000, loss: 0.027563
 >> iter 19000, loss: 0.035714
 >> iter 20000, loss: 0.036671
   Number of active neurons: 3
 >> iter 21000, loss: 0.031394
 >> iter 22000, loss: 0.027208
 >> iter 23000, loss: 0.026592
 >> iter 24000, loss: 0.026941
 >> iter 25000, loss: 0.024191
 >> iter 26000, loss: 0.028823
 >> iter 27000, loss: 0.024719
 >> iter 28000, loss: 0.026434
 >> iter 29000, loss: 0.027486
 >> iter 30000, loss: 0.024800
   Number of active neurons: 3
 >> iter 31000, loss: 0.025815
 >> iter 32000, loss: 0.033932
 >> iter 33000, loss: 0.043973
 >> iter 34000, loss: 0.031598
 >> iter 35000, loss: 0.032604
 >> iter 36000, loss: 0.025666
 >> iter 37000, loss: 0.026320
 >> iter 38000, loss: 0.023553
 >> iter 39000, loss: 0.023648
 >> iter 40000, loss: 0.032182
   Number of active neurons: 3
 >> iter 41000, loss: 0.031943
 >> iter 42000, loss: 0.027697
 >> iter 43000, loss: 0.025546
 >> iter 44000, loss: 0.030912
 >> iter 45000, loss: 0.025547
 >> iter 46000, loss: 0.023588
 >> iter 47000, loss: 0.023477
 >> iter 48000, loss: 0.021478
 >> iter 49000, loss: 0.023864
 >> iter 50000, loss: 0.042455
   Number of active neurons: 2
 >> iter 51000, loss: 0.033541
 >> iter 52000, loss: 0.029511
 >> iter 53000, loss: 0.027798
 >> iter 54000, loss: 0.024238
 >> iter 55000, loss: 0.025455
 >> iter 56000, loss: 0.028965
 >> iter 57000, loss: 0.026710
 >> iter 58000, loss: 0.030751
 >> iter 59000, loss: 0.027423
 >> iter 60000, loss: 0.026136
   Number of active neurons: 2
 >> iter 61000, loss: 0.026847
 >> iter 62000, loss: 0.021267
 >> iter 63000, loss: 0.021298
 >> iter 64000, loss: 0.021671
 >> iter 65000, loss: 0.021828
 >> iter 66000, loss: 0.027873
 >> iter 67000, loss: 0.022369
 >> iter 68000, loss: 0.022701
 >> iter 69000, loss: 0.054340
 >> iter 70000, loss: 0.034671
   Number of active neurons: 2
 >> iter 71000, loss: 0.026832
 >> iter 72000, loss: 0.023446
 >> iter 73000, loss: 0.029360
 >> iter 74000, loss: 0.023678
 >> iter 75000, loss: 0.023426
 >> iter 76000, loss: 0.020165
 >> iter 77000, loss: 0.020677
 >> iter 78000, loss: 0.025133
 >> iter 79000, loss: 0.032564
 >> iter 80000, loss: 0.023117
   Number of active neurons: 1
 >> iter 81000, loss: 0.019192
 >> iter 82000, loss: 0.028882
 >> iter 83000, loss: 0.026704
 >> iter 84000, loss: 0.026022
 >> iter 85000, loss: 0.021977
 >> iter 86000, loss: 0.019188
 >> iter 87000, loss: 0.029467
 >> iter 88000, loss: 0.021887
 >> iter 89000, loss: 0.018189
 >> iter 90000, loss: 0.027150
   Number of active neurons: 1
 >> iter 91000, loss: 0.029391
 >> iter 92000, loss: 0.029690
 >> iter 93000, loss: 0.024381
 >> iter 94000, loss: 0.022253
 >> iter 95000, loss: 0.024628
 >> iter 96000, loss: 0.019891
 >> iter 97000, loss: 0.017362
 >> iter 98000, loss: 0.024920
 >> iter 99000, loss: 0.025030
 >> iter 100000, loss: 0.018444
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.065419
 >> iter 2000, loss: 4.107223
 >> iter 3000, loss: 1.567958
 >> iter 4000, loss: 0.595417
 >> iter 5000, loss: 0.237147
 >> iter 6000, loss: 0.106089
 >> iter 7000, loss: 0.091629
 >> iter 8000, loss: 0.047176
 >> iter 9000, loss: 0.042623
 >> iter 10000, loss: 0.028548
   Number of active neurons: 2
 >> iter 11000, loss: 0.024516
 >> iter 12000, loss: 0.025907
 >> iter 13000, loss: 0.022613
 >> iter 14000, loss: 0.021707
 >> iter 15000, loss: 0.022394
 >> iter 16000, loss: 0.033432
 >> iter 17000, loss: 0.028555
 >> iter 18000, loss: 0.027669
 >> iter 19000, loss: 0.025864
 >> iter 20000, loss: 0.022812
   Number of active neurons: 2
 >> iter 21000, loss: 0.038614
 >> iter 22000, loss: 0.029560
 >> iter 23000, loss: 0.023315
 >> iter 24000, loss: 0.024441
 >> iter 25000, loss: 0.020935
 >> iter 26000, loss: 0.020370
 >> iter 27000, loss: 0.031224
 >> iter 28000, loss: 0.023906
 >> iter 29000, loss: 0.021634
 >> iter 30000, loss: 0.020766
   Number of active neurons: 2
 >> iter 31000, loss: 0.024149
 >> iter 32000, loss: 0.025934
 >> iter 33000, loss: 0.023618
 >> iter 34000, loss: 0.023283
 >> iter 35000, loss: 0.022794
 >> iter 36000, loss: 0.029517
 >> iter 37000, loss: 0.024231
 >> iter 38000, loss: 0.032130
 >> iter 39000, loss: 0.026025
 >> iter 40000, loss: 0.022437
   Number of active neurons: 2
 >> iter 41000, loss: 0.028640
 >> iter 42000, loss: 0.024185
 >> iter 43000, loss: 0.021872
 >> iter 44000, loss: 0.019825
 >> iter 45000, loss: 0.029177
 >> iter 46000, loss: 0.022880
 >> iter 47000, loss: 0.026554
 >> iter 48000, loss: 0.023223
 >> iter 49000, loss: 0.020400
 >> iter 50000, loss: 0.019282
   Number of active neurons: 1
 >> iter 51000, loss: 0.020962
 >> iter 52000, loss: 0.018115
 >> iter 53000, loss: 0.039769
 >> iter 54000, loss: 0.029119
 >> iter 55000, loss: 0.033619
 >> iter 56000, loss: 0.025788
 >> iter 57000, loss: 0.020569
 >> iter 58000, loss: 0.018400
 >> iter 59000, loss: 0.020008
 >> iter 60000, loss: 0.036747
   Number of active neurons: 1
 >> iter 61000, loss: 0.024337
 >> iter 62000, loss: 0.020447
 >> iter 63000, loss: 0.018065
 >> iter 64000, loss: 0.019110
 >> iter 65000, loss: 0.016376
 >> iter 66000, loss: 0.017322
 >> iter 67000, loss: 0.033348
 >> iter 68000, loss: 0.022247
 >> iter 69000, loss: 0.022969
 >> iter 70000, loss: 0.019110
   Number of active neurons: 1
 >> iter 71000, loss: 0.016084
 >> iter 72000, loss: 0.016724
 >> iter 73000, loss: 0.017270
 >> iter 74000, loss: 0.019367
 >> iter 75000, loss: 0.020987
 >> iter 76000, loss: 0.022913
 >> iter 77000, loss: 0.035335
 >> iter 78000, loss: 0.033027
 >> iter 79000, loss: 0.036907
 >> iter 80000, loss: 0.026701
   Number of active neurons: 1
 >> iter 81000, loss: 0.025728
 >> iter 82000, loss: 0.021896
 >> iter 83000, loss: 0.032375
 >> iter 84000, loss: 0.024029
 >> iter 85000, loss: 0.019497
 >> iter 86000, loss: 0.018517
 >> iter 87000, loss: 0.018885
 >> iter 88000, loss: 0.017168
 >> iter 89000, loss: 0.021008
 >> iter 90000, loss: 0.020541
   Number of active neurons: 1
 >> iter 91000, loss: 0.023014
 >> iter 92000, loss: 0.018658
 >> iter 93000, loss: 0.019352
 >> iter 94000, loss: 0.024817
 >> iter 95000, loss: 0.023622
 >> iter 96000, loss: 0.022099
 >> iter 97000, loss: 0.021025
 >> iter 98000, loss: 0.019922
 >> iter 99000, loss: 0.018567
 >> iter 100000, loss: 0.017218
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.986857
 >> iter 2000, loss: 4.077383
 >> iter 3000, loss: 1.529920
 >> iter 4000, loss: 0.596531
 >> iter 5000, loss: 0.242108
 >> iter 6000, loss: 0.104034
 >> iter 7000, loss: 0.053623
 >> iter 8000, loss: 0.035549
 >> iter 9000, loss: 0.028117
 >> iter 10000, loss: 0.023133
   Number of active neurons: 2
 >> iter 11000, loss: 0.027564
 >> iter 12000, loss: 0.024111
 >> iter 13000, loss: 0.021173
 >> iter 14000, loss: 0.020580
 >> iter 15000, loss: 0.021487
 >> iter 16000, loss: 0.020179
 >> iter 17000, loss: 0.019847
 >> iter 18000, loss: 0.020735
 >> iter 19000, loss: 0.022775
 >> iter 20000, loss: 0.022388
   Number of active neurons: 2
 >> iter 21000, loss: 0.027247
 >> iter 22000, loss: 0.035350
 >> iter 23000, loss: 0.024921
 >> iter 24000, loss: 0.021403
 >> iter 25000, loss: 0.022298
 >> iter 26000, loss: 0.020137
 >> iter 27000, loss: 0.021744
 >> iter 28000, loss: 0.021504
 >> iter 29000, loss: 0.020821
 >> iter 30000, loss: 0.020682
   Number of active neurons: 2
 >> iter 31000, loss: 0.022079
 >> iter 32000, loss: 0.023618
 >> iter 33000, loss: 0.023073
 >> iter 34000, loss: 0.025044
 >> iter 35000, loss: 0.028104
 >> iter 36000, loss: 0.026292
 >> iter 37000, loss: 0.023574
 >> iter 38000, loss: 0.021056
 >> iter 39000, loss: 0.024682
 >> iter 40000, loss: 0.021409
   Number of active neurons: 2
 >> iter 41000, loss: 0.022678
 >> iter 42000, loss: 0.021690
 >> iter 43000, loss: 0.026387
 >> iter 44000, loss: 0.026544
 >> iter 45000, loss: 0.023002
 >> iter 46000, loss: 0.020901
 >> iter 47000, loss: 0.033754
 >> iter 48000, loss: 0.026464
 >> iter 49000, loss: 0.021371
 >> iter 50000, loss: 0.020623
   Number of active neurons: 2
 >> iter 51000, loss: 0.022293
 >> iter 52000, loss: 0.020815
 >> iter 53000, loss: 0.022596
 >> iter 54000, loss: 0.022373
 >> iter 55000, loss: 0.021382
 >> iter 56000, loss: 0.020919
 >> iter 57000, loss: 0.024923
 >> iter 58000, loss: 0.022485
 >> iter 59000, loss: 0.021508
 >> iter 60000, loss: 0.020174
   Number of active neurons: 2
 >> iter 61000, loss: 0.020049
 >> iter 62000, loss: 0.020632
 >> iter 63000, loss: 0.031682
 >> iter 64000, loss: 0.024854
 >> iter 65000, loss: 0.021201
 >> iter 66000, loss: 0.021131
 >> iter 67000, loss: 0.038473
 >> iter 68000, loss: 0.029600
 >> iter 69000, loss: 0.023396
 >> iter 70000, loss: 0.023700
   Number of active neurons: 2
 >> iter 71000, loss: 0.021885
 >> iter 72000, loss: 0.020442
 >> iter 73000, loss: 0.023172
 >> iter 74000, loss: 0.021970
 >> iter 75000, loss: 0.021308
 >> iter 76000, loss: 0.021409
 >> iter 77000, loss: 0.020574
 >> iter 78000, loss: 0.031441
 >> iter 79000, loss: 0.024193
 >> iter 80000, loss: 0.023519
   Number of active neurons: 2
 >> iter 81000, loss: 0.029881
 >> iter 82000, loss: 0.023083
 >> iter 83000, loss: 0.022224
 >> iter 84000, loss: 0.021276
 >> iter 85000, loss: 0.020301
 >> iter 86000, loss: 0.023007
 >> iter 87000, loss: 0.023375
 >> iter 88000, loss: 0.021110
 >> iter 89000, loss: 0.025585
 >> iter 90000, loss: 0.022045
   Number of active neurons: 2
 >> iter 91000, loss: 0.021354
 >> iter 92000, loss: 0.030615
 >> iter 93000, loss: 0.024021
 >> iter 94000, loss: 0.020906
 >> iter 95000, loss: 0.024663
 >> iter 96000, loss: 0.023553
 >> iter 97000, loss: 0.031400
 >> iter 98000, loss: 0.025587
 >> iter 99000, loss: 0.022916
 >> iter 100000, loss: 0.022989
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.085662
 >> iter 2000, loss: 4.123391
 >> iter 3000, loss: 1.545359
 >> iter 4000, loss: 0.584299
 >> iter 5000, loss: 0.239892
 >> iter 6000, loss: 0.104744
 >> iter 7000, loss: 0.058137
 >> iter 8000, loss: 0.038374
 >> iter 9000, loss: 0.029629
 >> iter 10000, loss: 0.024507
   Number of active neurons: 3
 >> iter 11000, loss: 0.033713
 >> iter 12000, loss: 0.027375
 >> iter 13000, loss: 0.027887
 >> iter 14000, loss: 0.027013
 >> iter 15000, loss: 0.026691
 >> iter 16000, loss: 0.023417
 >> iter 17000, loss: 0.027422
 >> iter 18000, loss: 0.028182
 >> iter 19000, loss: 0.038596
 >> iter 20000, loss: 0.028228
   Number of active neurons: 3
 >> iter 21000, loss: 0.038608
 >> iter 22000, loss: 0.028964
 >> iter 23000, loss: 0.027492
 >> iter 24000, loss: 0.032555
 >> iter 25000, loss: 0.029539
 >> iter 26000, loss: 0.033936
 >> iter 27000, loss: 0.026434
 >> iter 28000, loss: 0.024870
 >> iter 29000, loss: 0.023988
 >> iter 30000, loss: 0.024557
   Number of active neurons: 3
 >> iter 31000, loss: 0.023317
 >> iter 32000, loss: 0.023223
 >> iter 33000, loss: 0.022399
 >> iter 34000, loss: 0.027684
 >> iter 35000, loss: 0.039068
 >> iter 36000, loss: 0.027225
 >> iter 37000, loss: 0.021997
 >> iter 38000, loss: 0.022697
 >> iter 39000, loss: 0.022803
 >> iter 40000, loss: 0.029585
   Number of active neurons: 2
 >> iter 41000, loss: 0.032373
 >> iter 42000, loss: 0.025060
 >> iter 43000, loss: 0.021783
 >> iter 44000, loss: 0.020643
 >> iter 45000, loss: 0.021155
 >> iter 46000, loss: 0.024217
 >> iter 47000, loss: 0.023671
 >> iter 48000, loss: 0.027832
 >> iter 49000, loss: 0.023863
 >> iter 50000, loss: 0.022112
   Number of active neurons: 2
 >> iter 51000, loss: 0.021105
 >> iter 52000, loss: 0.038953
 >> iter 53000, loss: 0.036940
 >> iter 54000, loss: 0.025390
 >> iter 55000, loss: 0.026996
 >> iter 56000, loss: 0.023868
 >> iter 57000, loss: 0.023816
 >> iter 58000, loss: 0.022733
 >> iter 59000, loss: 0.021225
 >> iter 60000, loss: 0.023390
   Number of active neurons: 2
 >> iter 61000, loss: 0.022951
 >> iter 62000, loss: 0.021865
 >> iter 63000, loss: 0.053838
 >> iter 64000, loss: 0.032687
 >> iter 65000, loss: 0.025657
 >> iter 66000, loss: 0.029140
 >> iter 67000, loss: 0.023694
 >> iter 68000, loss: 0.024384
 >> iter 69000, loss: 0.024975
 >> iter 70000, loss: 0.023721
   Number of active neurons: 2
 >> iter 71000, loss: 0.022922
 >> iter 72000, loss: 0.025312
 >> iter 73000, loss: 0.024914
 >> iter 74000, loss: 0.021557
 >> iter 75000, loss: 0.019609
 >> iter 76000, loss: 0.032059
 >> iter 77000, loss: 0.024571
 >> iter 78000, loss: 0.026512
 >> iter 79000, loss: 0.031219
 >> iter 80000, loss: 0.045800
   Number of active neurons: 2
 >> iter 81000, loss: 0.033246
 >> iter 82000, loss: 0.025643
 >> iter 83000, loss: 0.024761
 >> iter 84000, loss: 0.022569
 >> iter 85000, loss: 0.020443
 >> iter 86000, loss: 0.026474
 >> iter 87000, loss: 0.027781
 >> iter 88000, loss: 0.029724
 >> iter 89000, loss: 0.023681
 >> iter 90000, loss: 0.020586
   Number of active neurons: 1
 >> iter 91000, loss: 0.019544
 >> iter 92000, loss: 0.033362
 >> iter 93000, loss: 0.023128
 >> iter 94000, loss: 0.023578
 >> iter 95000, loss: 0.020989
 >> iter 96000, loss: 0.018376
 >> iter 97000, loss: 0.018693
 >> iter 98000, loss: 0.023041
 >> iter 99000, loss: 0.028030
 >> iter 100000, loss: 0.022076
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.949120
 >> iter 2000, loss: 4.067997
 >> iter 3000, loss: 1.517211
 >> iter 4000, loss: 0.601954
 >> iter 5000, loss: 0.246672
 >> iter 6000, loss: 0.107762
 >> iter 7000, loss: 0.057434
 >> iter 8000, loss: 0.042362
 >> iter 9000, loss: 0.031989
 >> iter 10000, loss: 0.031466
   Number of active neurons: 2
 >> iter 11000, loss: 0.034610
 >> iter 12000, loss: 0.027475
 >> iter 13000, loss: 0.022962
 >> iter 14000, loss: 0.024541
 >> iter 15000, loss: 0.025531
 >> iter 16000, loss: 0.021214
 >> iter 17000, loss: 0.021313
 >> iter 18000, loss: 0.039762
 >> iter 19000, loss: 0.058260
 >> iter 20000, loss: 0.036772
   Number of active neurons: 2
 >> iter 21000, loss: 0.027452
 >> iter 22000, loss: 0.024501
 >> iter 23000, loss: 0.022817
 >> iter 24000, loss: 0.022342
 >> iter 25000, loss: 0.024874
 >> iter 26000, loss: 0.022619
 >> iter 27000, loss: 0.024301
 >> iter 28000, loss: 0.022987
 >> iter 29000, loss: 0.021169
 >> iter 30000, loss: 0.020764
   Number of active neurons: 2
 >> iter 31000, loss: 0.028757
 >> iter 32000, loss: 0.023161
 >> iter 33000, loss: 0.029953
 >> iter 34000, loss: 0.022656
 >> iter 35000, loss: 0.023057
 >> iter 36000, loss: 0.021211
 >> iter 37000, loss: 0.022143
 >> iter 38000, loss: 0.037213
 >> iter 39000, loss: 0.026832
 >> iter 40000, loss: 0.026213
   Number of active neurons: 2
 >> iter 41000, loss: 0.024796
 >> iter 42000, loss: 0.024773
 >> iter 43000, loss: 0.021552
 >> iter 44000, loss: 0.020041
 >> iter 45000, loss: 0.027622
 >> iter 46000, loss: 0.023027
 >> iter 47000, loss: 0.020011
 >> iter 48000, loss: 0.024487
 >> iter 49000, loss: 0.024254
 >> iter 50000, loss: 0.027425
   Number of active neurons: 2
 >> iter 51000, loss: 0.035505
 >> iter 52000, loss: 0.032634
 >> iter 53000, loss: 0.066411
 >> iter 54000, loss: 0.046428
 >> iter 55000, loss: 0.033860
 >> iter 56000, loss: 0.025028
 >> iter 57000, loss: 0.023290
 >> iter 58000, loss: 0.021255
 >> iter 59000, loss: 0.024776
 >> iter 60000, loss: 0.026042
   Number of active neurons: 2
 >> iter 61000, loss: 0.021370
 >> iter 62000, loss: 0.022986
 >> iter 63000, loss: 0.021554
 >> iter 64000, loss: 0.027120
 >> iter 65000, loss: 0.026881
 >> iter 66000, loss: 0.029086
 >> iter 67000, loss: 0.025777
 >> iter 68000, loss: 0.022354
 >> iter 69000, loss: 0.029090
 >> iter 70000, loss: 0.023902
   Number of active neurons: 2
 >> iter 71000, loss: 0.023063
 >> iter 72000, loss: 0.020147
 >> iter 73000, loss: 0.022103
 >> iter 74000, loss: 0.022693
 >> iter 75000, loss: 0.024286
 >> iter 76000, loss: 0.022776
 >> iter 77000, loss: 0.023109
 >> iter 78000, loss: 0.022081
 >> iter 79000, loss: 0.021577
 >> iter 80000, loss: 0.019380
   Number of active neurons: 2
 >> iter 81000, loss: 0.030506
 >> iter 82000, loss: 0.023810
 >> iter 83000, loss: 0.021486
 >> iter 84000, loss: 0.033615
 >> iter 85000, loss: 0.027254
 >> iter 86000, loss: 0.022624
 >> iter 87000, loss: 0.023255
 >> iter 88000, loss: 0.020800
 >> iter 89000, loss: 0.027871
 >> iter 90000, loss: 0.025938
   Number of active neurons: 1
 >> iter 91000, loss: 0.022530
 >> iter 92000, loss: 0.018696
 >> iter 93000, loss: 0.019160
 >> iter 94000, loss: 0.017809
 >> iter 95000, loss: 0.025844
 >> iter 96000, loss: 0.024548
 >> iter 97000, loss: 0.021625
 >> iter 98000, loss: 0.018778
 >> iter 99000, loss: 0.016648
 >> iter 100000, loss: 0.017752
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.146416
 >> iter 2000, loss: 4.139468
 >> iter 3000, loss: 1.543397
 >> iter 4000, loss: 0.592519
 >> iter 5000, loss: 0.235732
 >> iter 6000, loss: 0.113336
 >> iter 7000, loss: 0.058179
 >> iter 8000, loss: 0.036230
 >> iter 9000, loss: 0.051766
 >> iter 10000, loss: 0.035134
   Number of active neurons: 3
 >> iter 11000, loss: 0.032665
 >> iter 12000, loss: 0.025879
 >> iter 13000, loss: 0.030579
 >> iter 14000, loss: 0.024652
 >> iter 15000, loss: 0.023050
 >> iter 16000, loss: 0.021974
 >> iter 17000, loss: 0.034824
 >> iter 18000, loss: 0.032642
 >> iter 19000, loss: 0.028456
 >> iter 20000, loss: 0.026680
   Number of active neurons: 2
 >> iter 21000, loss: 0.035552
 >> iter 22000, loss: 0.032997
 >> iter 23000, loss: 0.028115
 >> iter 24000, loss: 0.030901
 >> iter 25000, loss: 0.027196
 >> iter 26000, loss: 0.024860
 >> iter 27000, loss: 0.026838
 >> iter 28000, loss: 0.032570
 >> iter 29000, loss: 0.030149
 >> iter 30000, loss: 0.028737
   Number of active neurons: 2
 >> iter 31000, loss: 0.027422
 >> iter 32000, loss: 0.025381
 >> iter 33000, loss: 0.028187
 >> iter 34000, loss: 0.040947
 >> iter 35000, loss: 0.027824
 >> iter 36000, loss: 0.026325
 >> iter 37000, loss: 0.023647
 >> iter 38000, loss: 0.030791
 >> iter 39000, loss: 0.029334
 >> iter 40000, loss: 0.028108
   Number of active neurons: 1
 >> iter 41000, loss: 0.022517
 >> iter 42000, loss: 0.020245
 >> iter 43000, loss: 0.021189
 >> iter 44000, loss: 0.019726
 >> iter 45000, loss: 0.017329
 >> iter 46000, loss: 0.020740
 >> iter 47000, loss: 0.019317
 >> iter 48000, loss: 0.018506
 >> iter 49000, loss: 0.027128
 >> iter 50000, loss: 0.020443
   Number of active neurons: 1
 >> iter 51000, loss: 0.021080
 >> iter 52000, loss: 0.030861
 >> iter 53000, loss: 0.021710
 >> iter 54000, loss: 0.021904
 >> iter 55000, loss: 0.019321
 >> iter 56000, loss: 0.018228
 >> iter 57000, loss: 0.018350
 >> iter 58000, loss: 0.018335
 >> iter 59000, loss: 0.019728
 >> iter 60000, loss: 0.019059
   Number of active neurons: 1
 >> iter 61000, loss: 0.023828
 >> iter 62000, loss: 0.020910
 >> iter 63000, loss: 0.020687
 >> iter 64000, loss: 0.017810
 >> iter 65000, loss: 0.027270
 >> iter 66000, loss: 0.034372
 >> iter 67000, loss: 0.027346
 >> iter 68000, loss: 0.020380
 >> iter 69000, loss: 0.028140
 >> iter 70000, loss: 0.025326
   Number of active neurons: 1
 >> iter 71000, loss: 0.022370
 >> iter 72000, loss: 0.022117
 >> iter 73000, loss: 0.020681
 >> iter 74000, loss: 0.040563
 >> iter 75000, loss: 0.027779
 >> iter 76000, loss: 0.021060
 >> iter 77000, loss: 0.019004
 >> iter 78000, loss: 0.025563
 >> iter 79000, loss: 0.019464
 >> iter 80000, loss: 0.026307
   Number of active neurons: 1
 >> iter 81000, loss: 0.032133
 >> iter 82000, loss: 0.029781
 >> iter 83000, loss: 0.026379
 >> iter 84000, loss: 0.025071
 >> iter 85000, loss: 0.037017
 >> iter 86000, loss: 0.042503
 >> iter 87000, loss: 0.029335
 >> iter 88000, loss: 0.026423
 >> iter 89000, loss: 0.033269
 >> iter 90000, loss: 0.022906
   Number of active neurons: 1
 >> iter 91000, loss: 0.022151
 >> iter 92000, loss: 0.017650
 >> iter 93000, loss: 0.019151
 >> iter 94000, loss: 0.019072
 >> iter 95000, loss: 0.017579
 >> iter 96000, loss: 0.016664
 >> iter 97000, loss: 0.031759
 >> iter 98000, loss: 0.023106
 >> iter 99000, loss: 0.020251
 >> iter 100000, loss: 0.021540
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.956410
 >> iter 2000, loss: 4.065629
 >> iter 3000, loss: 1.531822
 >> iter 4000, loss: 0.581376
 >> iter 5000, loss: 0.232583
 >> iter 6000, loss: 0.106877
 >> iter 7000, loss: 0.059055
 >> iter 8000, loss: 0.038943
 >> iter 9000, loss: 0.039237
 >> iter 10000, loss: 0.029206
   Number of active neurons: 2
 >> iter 11000, loss: 0.024267
 >> iter 12000, loss: 0.027072
 >> iter 13000, loss: 0.023825
 >> iter 14000, loss: 0.030389
 >> iter 15000, loss: 0.030158
 >> iter 16000, loss: 0.028047
 >> iter 17000, loss: 0.024882
 >> iter 18000, loss: 0.024264
 >> iter 19000, loss: 0.022577
 >> iter 20000, loss: 0.021947
   Number of active neurons: 2
 >> iter 21000, loss: 0.024609
 >> iter 22000, loss: 0.024034
 >> iter 23000, loss: 0.023264
 >> iter 24000, loss: 0.023865
 >> iter 25000, loss: 0.021891
 >> iter 26000, loss: 0.019822
 >> iter 27000, loss: 0.020001
 >> iter 28000, loss: 0.027032
 >> iter 29000, loss: 0.024756
 >> iter 30000, loss: 0.025172
   Number of active neurons: 2
 >> iter 31000, loss: 0.024039
 >> iter 32000, loss: 0.023951
 >> iter 33000, loss: 0.023105
 >> iter 34000, loss: 0.025585
 >> iter 35000, loss: 0.026003
 >> iter 36000, loss: 0.025766
 >> iter 37000, loss: 0.024281
 >> iter 38000, loss: 0.019991
 >> iter 39000, loss: 0.024076
 >> iter 40000, loss: 0.019486
   Number of active neurons: 1
 >> iter 41000, loss: 0.043940
 >> iter 42000, loss: 0.036116
 >> iter 43000, loss: 0.027645
 >> iter 44000, loss: 0.021356
 >> iter 45000, loss: 0.018277
 >> iter 46000, loss: 0.029600
 >> iter 47000, loss: 0.023742
 >> iter 48000, loss: 0.027455
 >> iter 49000, loss: 0.025142
 >> iter 50000, loss: 0.018730
   Number of active neurons: 1
 >> iter 51000, loss: 0.023015
 >> iter 52000, loss: 0.017818
 >> iter 53000, loss: 0.016560
 >> iter 54000, loss: 0.022480
 >> iter 55000, loss: 0.022083
 >> iter 56000, loss: 0.022399
 >> iter 57000, loss: 0.021038
 >> iter 58000, loss: 0.018425
 >> iter 59000, loss: 0.029574
 >> iter 60000, loss: 0.022817
   Number of active neurons: 1
 >> iter 61000, loss: 0.030638
 >> iter 62000, loss: 0.020748
 >> iter 63000, loss: 0.033730
 >> iter 64000, loss: 0.023400
 >> iter 65000, loss: 0.021064
 >> iter 66000, loss: 0.017772
 >> iter 67000, loss: 0.018487
 >> iter 68000, loss: 0.017409
 >> iter 69000, loss: 0.052418
 >> iter 70000, loss: 0.033518
   Number of active neurons: 1
 >> iter 71000, loss: 0.025958
 >> iter 72000, loss: 0.021899
 >> iter 73000, loss: 0.027530
 >> iter 74000, loss: 0.034203
 >> iter 75000, loss: 0.024894
 >> iter 76000, loss: 0.028483
 >> iter 77000, loss: 0.023021
 >> iter 78000, loss: 0.036999
 >> iter 79000, loss: 0.024408
 >> iter 80000, loss: 0.020474
   Number of active neurons: 1
 >> iter 81000, loss: 0.017962
 >> iter 82000, loss: 0.018930
 >> iter 83000, loss: 0.018570
 >> iter 84000, loss: 0.016269
 >> iter 85000, loss: 0.015867
 >> iter 86000, loss: 0.019131
 >> iter 87000, loss: 0.017030
 >> iter 88000, loss: 0.019008
 >> iter 89000, loss: 0.019583
 >> iter 90000, loss: 0.021440
   Number of active neurons: 1
 >> iter 91000, loss: 0.018179
 >> iter 92000, loss: 0.016757
 >> iter 93000, loss: 0.016429
 >> iter 94000, loss: 0.036506
 >> iter 95000, loss: 0.049506
 >> iter 96000, loss: 0.032907
 >> iter 97000, loss: 0.027168
 >> iter 98000, loss: 0.020867
 >> iter 99000, loss: 0.018462
 >> iter 100000, loss: 0.021016
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.959730
 >> iter 2000, loss: 4.063982
 >> iter 3000, loss: 1.523147
 >> iter 4000, loss: 0.586611
 >> iter 5000, loss: 0.233364
 >> iter 6000, loss: 0.102303
 >> iter 7000, loss: 0.072369
 >> iter 8000, loss: 0.045614
 >> iter 9000, loss: 0.031931
 >> iter 10000, loss: 0.034141
   Number of active neurons: 3
 >> iter 11000, loss: 0.025713
 >> iter 12000, loss: 0.023128
 >> iter 13000, loss: 0.025434
 >> iter 14000, loss: 0.024418
 >> iter 15000, loss: 0.023838
 >> iter 16000, loss: 0.026105
 >> iter 17000, loss: 0.025885
 >> iter 18000, loss: 0.028629
 >> iter 19000, loss: 0.026613
 >> iter 20000, loss: 0.031171
   Number of active neurons: 3
 >> iter 21000, loss: 0.026403
 >> iter 22000, loss: 0.022722
 >> iter 23000, loss: 0.025159
 >> iter 24000, loss: 0.025621
 >> iter 25000, loss: 0.029244
 >> iter 26000, loss: 0.027096
 >> iter 27000, loss: 0.024305
 >> iter 28000, loss: 0.023438
 >> iter 29000, loss: 0.024349
 >> iter 30000, loss: 0.024579
   Number of active neurons: 3
 >> iter 31000, loss: 0.023227
 >> iter 32000, loss: 0.023698
 >> iter 33000, loss: 0.036434
 >> iter 34000, loss: 0.029351
 >> iter 35000, loss: 0.028922
 >> iter 36000, loss: 0.025850
 >> iter 37000, loss: 0.024074
 >> iter 38000, loss: 0.023327
 >> iter 39000, loss: 0.024665
 >> iter 40000, loss: 0.036898
   Number of active neurons: 3
 >> iter 41000, loss: 0.028442
 >> iter 42000, loss: 0.023756
 >> iter 43000, loss: 0.025751
 >> iter 44000, loss: 0.025056
 >> iter 45000, loss: 0.022860
 >> iter 46000, loss: 0.023599
 >> iter 47000, loss: 0.021805
 >> iter 48000, loss: 0.022069
 >> iter 49000, loss: 0.053384
 >> iter 50000, loss: 0.031649
   Number of active neurons: 2
 >> iter 51000, loss: 0.027046
 >> iter 52000, loss: 0.023727
 >> iter 53000, loss: 0.021088
 >> iter 54000, loss: 0.021427
 >> iter 55000, loss: 0.022130
 >> iter 56000, loss: 0.025171
 >> iter 57000, loss: 0.024401
 >> iter 58000, loss: 0.025502
 >> iter 59000, loss: 0.033740
 >> iter 60000, loss: 0.025627
   Number of active neurons: 2
 >> iter 61000, loss: 0.024812
 >> iter 62000, loss: 0.025227
 >> iter 63000, loss: 0.029098
 >> iter 64000, loss: 0.024681
 >> iter 65000, loss: 0.023000
 >> iter 66000, loss: 0.020902
 >> iter 67000, loss: 0.020425
 >> iter 68000, loss: 0.029359
 >> iter 69000, loss: 0.022558
 >> iter 70000, loss: 0.020672
   Number of active neurons: 2
 >> iter 71000, loss: 0.020169
 >> iter 72000, loss: 0.028419
 >> iter 73000, loss: 0.026661
 >> iter 74000, loss: 0.024447
 >> iter 75000, loss: 0.031355
 >> iter 76000, loss: 0.025684
 >> iter 77000, loss: 0.021721
 >> iter 78000, loss: 0.020662
 >> iter 79000, loss: 0.021530
 >> iter 80000, loss: 0.019811
   Number of active neurons: 2
 >> iter 81000, loss: 0.020657
 >> iter 82000, loss: 0.022834
 >> iter 83000, loss: 0.022152
 >> iter 84000, loss: 0.021936
 >> iter 85000, loss: 0.021460
 >> iter 86000, loss: 0.023447
 >> iter 87000, loss: 0.039332
 >> iter 88000, loss: 0.027873
 >> iter 89000, loss: 0.026068
 >> iter 90000, loss: 0.022632
   Number of active neurons: 2
 >> iter 91000, loss: 0.029145
 >> iter 92000, loss: 0.026374
 >> iter 93000, loss: 0.023429
 >> iter 94000, loss: 0.020281
 >> iter 95000, loss: 0.025750
 >> iter 96000, loss: 0.022884
 >> iter 97000, loss: 0.023428
 >> iter 98000, loss: 0.023406
 >> iter 99000, loss: 0.022804
 >> iter 100000, loss: 0.024563
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.003120
 >> iter 2000, loss: 4.096661
 >> iter 3000, loss: 1.562904
 >> iter 4000, loss: 0.596039
 >> iter 5000, loss: 0.251536
 >> iter 6000, loss: 0.106671
 >> iter 7000, loss: 0.058640
 >> iter 8000, loss: 0.034030
 >> iter 9000, loss: 0.028161
 >> iter 10000, loss: 0.023889
   Number of active neurons: 2
 >> iter 11000, loss: 0.022742
 >> iter 12000, loss: 0.027608
 >> iter 13000, loss: 0.044145
 >> iter 14000, loss: 0.039404
 >> iter 15000, loss: 0.027509
 >> iter 16000, loss: 0.030998
 >> iter 17000, loss: 0.025370
 >> iter 18000, loss: 0.023324
 >> iter 19000, loss: 0.025885
 >> iter 20000, loss: 0.022073
   Number of active neurons: 2
 >> iter 21000, loss: 0.019943
 >> iter 22000, loss: 0.022100
 >> iter 23000, loss: 0.034112
 >> iter 24000, loss: 0.030976
 >> iter 25000, loss: 0.025340
 >> iter 26000, loss: 0.022971
 >> iter 27000, loss: 0.022087
 >> iter 28000, loss: 0.021900
 >> iter 29000, loss: 0.021739
 >> iter 30000, loss: 0.041317
   Number of active neurons: 2
 >> iter 31000, loss: 0.030580
 >> iter 32000, loss: 0.029528
 >> iter 33000, loss: 0.029201
 >> iter 34000, loss: 0.025193
 >> iter 35000, loss: 0.026257
 >> iter 36000, loss: 0.021534
 >> iter 37000, loss: 0.020192
 >> iter 38000, loss: 0.021570
 >> iter 39000, loss: 0.020282
 >> iter 40000, loss: 0.022009
   Number of active neurons: 2
 >> iter 41000, loss: 0.023907
 >> iter 42000, loss: 0.033944
 >> iter 43000, loss: 0.026060
 >> iter 44000, loss: 0.022765
 >> iter 45000, loss: 0.027001
 >> iter 46000, loss: 0.021828
 >> iter 47000, loss: 0.021896
 >> iter 48000, loss: 0.023262
 >> iter 49000, loss: 0.027519
 >> iter 50000, loss: 0.026808
   Number of active neurons: 2
 >> iter 51000, loss: 0.024397
 >> iter 52000, loss: 0.031289
 >> iter 53000, loss: 0.023700
 >> iter 54000, loss: 0.021067
 >> iter 55000, loss: 0.020461
 >> iter 56000, loss: 0.034310
 >> iter 57000, loss: 0.028951
 >> iter 58000, loss: 0.025826
 >> iter 59000, loss: 0.021713
 >> iter 60000, loss: 0.024378
   Number of active neurons: 2
 >> iter 61000, loss: 0.021925
 >> iter 62000, loss: 0.023716
 >> iter 63000, loss: 0.020641
 >> iter 64000, loss: 0.030471
 >> iter 65000, loss: 0.023490
 >> iter 66000, loss: 0.024074
 >> iter 67000, loss: 0.036452
 >> iter 68000, loss: 0.031422
 >> iter 69000, loss: 0.031055
 >> iter 70000, loss: 0.043531
   Number of active neurons: 2
 >> iter 71000, loss: 0.040062
 >> iter 72000, loss: 0.033831
 >> iter 73000, loss: 0.050177
 >> iter 74000, loss: 0.032600
 >> iter 75000, loss: 0.027824
 >> iter 76000, loss: 0.023857
 >> iter 77000, loss: 0.023581
 >> iter 78000, loss: 0.021357
 >> iter 79000, loss: 0.020089
 >> iter 80000, loss: 0.022904
   Number of active neurons: 1
 >> iter 81000, loss: 0.021838
 >> iter 82000, loss: 0.023060
 >> iter 83000, loss: 0.035309
 >> iter 84000, loss: 0.029190
 >> iter 85000, loss: 0.029349
 >> iter 86000, loss: 0.022703
 >> iter 87000, loss: 0.022754
 >> iter 88000, loss: 0.020454
 >> iter 89000, loss: 0.026433
 >> iter 90000, loss: 0.020180
   Number of active neurons: 1
 >> iter 91000, loss: 0.021257
 >> iter 92000, loss: 0.019611
 >> iter 93000, loss: 0.021330
 >> iter 94000, loss: 0.019285
 >> iter 95000, loss: 0.017688
 >> iter 96000, loss: 0.015283
 >> iter 97000, loss: 0.020839
 >> iter 98000, loss: 0.021269
 >> iter 99000, loss: 0.018780
 >> iter 100000, loss: 0.021844
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.012697
 >> iter 2000, loss: 4.101775
 >> iter 3000, loss: 1.549406
 >> iter 4000, loss: 0.590516
 >> iter 5000, loss: 0.254707
 >> iter 6000, loss: 0.114114
 >> iter 7000, loss: 0.056391
 >> iter 8000, loss: 0.037284
 >> iter 9000, loss: 0.029166
 >> iter 10000, loss: 0.030556
   Number of active neurons: 3
 >> iter 11000, loss: 0.029435
 >> iter 12000, loss: 0.029617
 >> iter 13000, loss: 0.025574
 >> iter 14000, loss: 0.026653
 >> iter 15000, loss: 0.024414
 >> iter 16000, loss: 0.026562
 >> iter 17000, loss: 0.029654
 >> iter 18000, loss: 0.025148
 >> iter 19000, loss: 0.024997
 >> iter 20000, loss: 0.023482
   Number of active neurons: 3
 >> iter 21000, loss: 0.037129
 >> iter 22000, loss: 0.029525
 >> iter 23000, loss: 0.025784
 >> iter 24000, loss: 0.030874
 >> iter 25000, loss: 0.028770
 >> iter 26000, loss: 0.026955
 >> iter 27000, loss: 0.026032
 >> iter 28000, loss: 0.029838
 >> iter 29000, loss: 0.026557
 >> iter 30000, loss: 0.029767
   Number of active neurons: 2
 >> iter 31000, loss: 0.023886
 >> iter 32000, loss: 0.021837
 >> iter 33000, loss: 0.022184
 >> iter 34000, loss: 0.019535
 >> iter 35000, loss: 0.020983
 >> iter 36000, loss: 0.020328
 >> iter 37000, loss: 0.019797
 >> iter 38000, loss: 0.021886
 >> iter 39000, loss: 0.022629
 >> iter 40000, loss: 0.022629
   Number of active neurons: 1
 >> iter 41000, loss: 0.018552
 >> iter 42000, loss: 0.030439
 >> iter 43000, loss: 0.022622
 >> iter 44000, loss: 0.043380
 >> iter 45000, loss: 0.027526
 >> iter 46000, loss: 0.031243
 >> iter 47000, loss: 0.022163
 >> iter 48000, loss: 0.022199
 >> iter 49000, loss: 0.022528
 >> iter 50000, loss: 0.018423
   Number of active neurons: 1
 >> iter 51000, loss: 0.020390
 >> iter 52000, loss: 0.016773
 >> iter 53000, loss: 0.041704
 >> iter 54000, loss: 0.026224
 >> iter 55000, loss: 0.024324
 >> iter 56000, loss: 0.018555
 >> iter 57000, loss: 0.019241
 >> iter 58000, loss: 0.022313
 >> iter 59000, loss: 0.019911
 >> iter 60000, loss: 0.021879
   Number of active neurons: 1
 >> iter 61000, loss: 0.018271
 >> iter 62000, loss: 0.032730
 >> iter 63000, loss: 0.021939
 >> iter 64000, loss: 0.018433
 >> iter 65000, loss: 0.018824
 >> iter 66000, loss: 0.030741
 >> iter 67000, loss: 0.026759
 >> iter 68000, loss: 0.026779
 >> iter 69000, loss: 0.020429
 >> iter 70000, loss: 0.021305
   Number of active neurons: 1
 >> iter 71000, loss: 0.018903
 >> iter 72000, loss: 0.022953
 >> iter 73000, loss: 0.020287
 >> iter 74000, loss: 0.018151
 >> iter 75000, loss: 0.016205
 >> iter 76000, loss: 0.018273
 >> iter 77000, loss: 0.030936
 >> iter 78000, loss: 0.024037
 >> iter 79000, loss: 0.027035
 >> iter 80000, loss: 0.035357
   Number of active neurons: 1
 >> iter 81000, loss: 0.031578
 >> iter 82000, loss: 0.022198
 >> iter 83000, loss: 0.019697
 >> iter 84000, loss: 0.017793
 >> iter 85000, loss: 0.018154
 >> iter 86000, loss: 0.019777
 >> iter 87000, loss: 0.016522
 >> iter 88000, loss: 0.017176
 >> iter 89000, loss: 0.018502
 >> iter 90000, loss: 0.016810
   Number of active neurons: 1
 >> iter 91000, loss: 0.042481
 >> iter 92000, loss: 0.039886
 >> iter 93000, loss: 0.034786
 >> iter 94000, loss: 0.025419
 >> iter 95000, loss: 0.020019
 >> iter 96000, loss: 0.024227
 >> iter 97000, loss: 0.038598
 >> iter 98000, loss: 0.024410
 >> iter 99000, loss: 0.020641
 >> iter 100000, loss: 0.017886
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.907880
 >> iter 2000, loss: 4.049949
 >> iter 3000, loss: 1.516296
 >> iter 4000, loss: 0.579427
 >> iter 5000, loss: 0.232939
 >> iter 6000, loss: 0.101639
 >> iter 7000, loss: 0.053142
 >> iter 8000, loss: 0.054028
 >> iter 9000, loss: 0.035802
 >> iter 10000, loss: 0.027214
   Number of active neurons: 3
 >> iter 11000, loss: 0.027436
 >> iter 12000, loss: 0.027158
 >> iter 13000, loss: 0.024376
 >> iter 14000, loss: 0.026610
 >> iter 15000, loss: 0.026525
 >> iter 16000, loss: 0.032753
 >> iter 17000, loss: 0.028560
 >> iter 18000, loss: 0.024199
 >> iter 19000, loss: 0.031682
 >> iter 20000, loss: 0.027382
   Number of active neurons: 3
 >> iter 21000, loss: 0.028046
 >> iter 22000, loss: 0.024945
 >> iter 23000, loss: 0.023344
 >> iter 24000, loss: 0.025864
 >> iter 25000, loss: 0.027569
 >> iter 26000, loss: 0.026095
 >> iter 27000, loss: 0.023497
 >> iter 28000, loss: 0.025756
 >> iter 29000, loss: 0.023340
 >> iter 30000, loss: 0.023203
   Number of active neurons: 2
 >> iter 31000, loss: 0.042232
 >> iter 32000, loss: 0.030873
 >> iter 33000, loss: 0.024469
 >> iter 34000, loss: 0.027695
 >> iter 35000, loss: 0.025882
 >> iter 36000, loss: 0.022509
 >> iter 37000, loss: 0.025710
 >> iter 38000, loss: 0.026271
 >> iter 39000, loss: 0.026107
 >> iter 40000, loss: 0.024499
   Number of active neurons: 2
 >> iter 41000, loss: 0.023403
 >> iter 42000, loss: 0.024258
 >> iter 43000, loss: 0.025134
 >> iter 44000, loss: 0.021879
 >> iter 45000, loss: 0.019628
 >> iter 46000, loss: 0.020396
 >> iter 47000, loss: 0.023892
 >> iter 48000, loss: 0.020806
 >> iter 49000, loss: 0.028430
 >> iter 50000, loss: 0.023699
   Number of active neurons: 2
 >> iter 51000, loss: 0.030742
 >> iter 52000, loss: 0.026707
 >> iter 53000, loss: 0.024878
 >> iter 54000, loss: 0.027372
 >> iter 55000, loss: 0.023402
 >> iter 56000, loss: 0.022407
 >> iter 57000, loss: 0.020452
 >> iter 58000, loss: 0.020314
 >> iter 59000, loss: 0.027158
 >> iter 60000, loss: 0.025768
   Number of active neurons: 2
 >> iter 61000, loss: 0.025788
 >> iter 62000, loss: 0.029700
 >> iter 63000, loss: 0.023948
 >> iter 64000, loss: 0.022852
 >> iter 65000, loss: 0.021168
 >> iter 66000, loss: 0.021012
 >> iter 67000, loss: 0.021562
 >> iter 68000, loss: 0.025064
 >> iter 69000, loss: 0.023480
 >> iter 70000, loss: 0.022885
   Number of active neurons: 2
 >> iter 71000, loss: 0.020875
 >> iter 72000, loss: 0.023610
 >> iter 73000, loss: 0.025601
 >> iter 74000, loss: 0.021609
 >> iter 75000, loss: 0.020476
 >> iter 76000, loss: 0.020946
 >> iter 77000, loss: 0.020298
 >> iter 78000, loss: 0.025016
 >> iter 79000, loss: 0.037784
 >> iter 80000, loss: 0.055416
   Number of active neurons: 1
 >> iter 81000, loss: 0.035682
 >> iter 82000, loss: 0.026730
 >> iter 83000, loss: 0.032324
 >> iter 84000, loss: 0.023181
 >> iter 85000, loss: 0.022995
 >> iter 86000, loss: 0.024537
 >> iter 87000, loss: 0.023253
 >> iter 88000, loss: 0.023285
 >> iter 89000, loss: 0.025226
 >> iter 90000, loss: 0.020395
   Number of active neurons: 1
 >> iter 91000, loss: 0.019221
 >> iter 92000, loss: 0.021164
 >> iter 93000, loss: 0.019517
 >> iter 94000, loss: 0.018702
 >> iter 95000, loss: 0.017185
 >> iter 96000, loss: 0.017471
 >> iter 97000, loss: 0.018310
 >> iter 98000, loss: 0.019994
 >> iter 99000, loss: 0.016514
 >> iter 100000, loss: 0.016804
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.064478
 >> iter 2000, loss: 4.115957
 >> iter 3000, loss: 1.539194
 >> iter 4000, loss: 0.587041
 >> iter 5000, loss: 0.232117
 >> iter 6000, loss: 0.103204
 >> iter 7000, loss: 0.052158
 >> iter 8000, loss: 0.037168
 >> iter 9000, loss: 0.031314
 >> iter 10000, loss: 0.025846
   Number of active neurons: 2
 >> iter 11000, loss: 0.030330
 >> iter 12000, loss: 0.032831
 >> iter 13000, loss: 0.027060
 >> iter 14000, loss: 0.029602
 >> iter 15000, loss: 0.024595
 >> iter 16000, loss: 0.028165
 >> iter 17000, loss: 0.026428
 >> iter 18000, loss: 0.022314
 >> iter 19000, loss: 0.026164
 >> iter 20000, loss: 0.026169
   Number of active neurons: 2
 >> iter 21000, loss: 0.031064
 >> iter 22000, loss: 0.028743
 >> iter 23000, loss: 0.027598
 >> iter 24000, loss: 0.022422
 >> iter 25000, loss: 0.022179
 >> iter 26000, loss: 0.024552
 >> iter 27000, loss: 0.024855
 >> iter 28000, loss: 0.023167
 >> iter 29000, loss: 0.021578
 >> iter 30000, loss: 0.028121
   Number of active neurons: 2
 >> iter 31000, loss: 0.023120
 >> iter 32000, loss: 0.024304
 >> iter 33000, loss: 0.022542
 >> iter 34000, loss: 0.024030
 >> iter 35000, loss: 0.021596
 >> iter 36000, loss: 0.022296
 >> iter 37000, loss: 0.022196
 >> iter 38000, loss: 0.024399
 >> iter 39000, loss: 0.027958
 >> iter 40000, loss: 0.024831
   Number of active neurons: 1
 >> iter 41000, loss: 0.020694
 >> iter 42000, loss: 0.019224
 >> iter 43000, loss: 0.020478
 >> iter 44000, loss: 0.019206
 >> iter 45000, loss: 0.020183
 >> iter 46000, loss: 0.021237
 >> iter 47000, loss: 0.020859
 >> iter 48000, loss: 0.019185
 >> iter 49000, loss: 0.020770
 >> iter 50000, loss: 0.019648
   Number of active neurons: 1
 >> iter 51000, loss: 0.017851
 >> iter 52000, loss: 0.017279
 >> iter 53000, loss: 0.021156
 >> iter 54000, loss: 0.017073
 >> iter 55000, loss: 0.026320
 >> iter 56000, loss: 0.019602
 >> iter 57000, loss: 0.025777
 >> iter 58000, loss: 0.049893
 >> iter 59000, loss: 0.029405
 >> iter 60000, loss: 0.028308
   Number of active neurons: 1
 >> iter 61000, loss: 0.023257
 >> iter 62000, loss: 0.021177
 >> iter 63000, loss: 0.027801
 >> iter 64000, loss: 0.022531
 >> iter 65000, loss: 0.020430
 >> iter 66000, loss: 0.046880
 >> iter 67000, loss: 0.028220
 >> iter 68000, loss: 0.025925
 >> iter 69000, loss: 0.021598
 >> iter 70000, loss: 0.018572
   Number of active neurons: 1
 >> iter 71000, loss: 0.016853
 >> iter 72000, loss: 0.018566
 >> iter 73000, loss: 0.022361
 >> iter 74000, loss: 0.033093
 >> iter 75000, loss: 0.022899
 >> iter 76000, loss: 0.024122
 >> iter 77000, loss: 0.023081
 >> iter 78000, loss: 0.027236
 >> iter 79000, loss: 0.019892
 >> iter 80000, loss: 0.029054
   Number of active neurons: 1
 >> iter 81000, loss: 0.021316
 >> iter 82000, loss: 0.017395
 >> iter 83000, loss: 0.022752
 >> iter 84000, loss: 0.020030
 >> iter 85000, loss: 0.021100
 >> iter 86000, loss: 0.028114
 >> iter 87000, loss: 0.022975
 >> iter 88000, loss: 0.017477
 >> iter 89000, loss: 0.016534
 >> iter 90000, loss: 0.021595
   Number of active neurons: 1
 >> iter 91000, loss: 0.026018
 >> iter 92000, loss: 0.020692
 >> iter 93000, loss: 0.019809
 >> iter 94000, loss: 0.017129
 >> iter 95000, loss: 0.020194
 >> iter 96000, loss: 0.022407
 >> iter 97000, loss: 0.020773
 >> iter 98000, loss: 0.033194
 >> iter 99000, loss: 0.022696
 >> iter 100000, loss: 0.020472
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.946038
 >> iter 2000, loss: 4.060957
 >> iter 3000, loss: 1.516342
 >> iter 4000, loss: 0.577902
 >> iter 5000, loss: 0.229012
 >> iter 6000, loss: 0.101083
 >> iter 7000, loss: 0.075510
 >> iter 8000, loss: 0.049569
 >> iter 9000, loss: 0.034327
 >> iter 10000, loss: 0.031637
   Number of active neurons: 3
 >> iter 11000, loss: 0.033400
 >> iter 12000, loss: 0.028385
 >> iter 13000, loss: 0.031925
 >> iter 14000, loss: 0.029750
 >> iter 15000, loss: 0.024463
 >> iter 16000, loss: 0.022253
 >> iter 17000, loss: 0.064171
 >> iter 18000, loss: 0.044943
 >> iter 19000, loss: 0.035806
 >> iter 20000, loss: 0.028583
   Number of active neurons: 3
 >> iter 21000, loss: 0.027171
 >> iter 22000, loss: 0.025779
 >> iter 23000, loss: 0.025593
 >> iter 24000, loss: 0.038893
 >> iter 25000, loss: 0.030707
 >> iter 26000, loss: 0.029202
 >> iter 27000, loss: 0.030487
 >> iter 28000, loss: 0.026102
 >> iter 29000, loss: 0.023615
 >> iter 30000, loss: 0.020188
   Number of active neurons: 2
 >> iter 31000, loss: 0.020373
 >> iter 32000, loss: 0.024281
 >> iter 33000, loss: 0.021625
 >> iter 34000, loss: 0.020042
 >> iter 35000, loss: 0.026976
 >> iter 36000, loss: 0.024119
 >> iter 37000, loss: 0.022745
 >> iter 38000, loss: 0.029401
 >> iter 39000, loss: 0.025868
 >> iter 40000, loss: 0.028306
   Number of active neurons: 2
 >> iter 41000, loss: 0.022813
 >> iter 42000, loss: 0.021236
 >> iter 43000, loss: 0.024748
 >> iter 44000, loss: 0.021022
 >> iter 45000, loss: 0.021095
 >> iter 46000, loss: 0.020535
 >> iter 47000, loss: 0.020286
 >> iter 48000, loss: 0.020842
 >> iter 49000, loss: 0.019410
 >> iter 50000, loss: 0.021543
   Number of active neurons: 2
 >> iter 51000, loss: 0.022015
 >> iter 52000, loss: 0.024310
 >> iter 53000, loss: 0.025309
 >> iter 54000, loss: 0.025471
 >> iter 55000, loss: 0.025202
 >> iter 56000, loss: 0.022401
 >> iter 57000, loss: 0.021045
 >> iter 58000, loss: 0.022827
 >> iter 59000, loss: 0.031116
 >> iter 60000, loss: 0.024255
   Number of active neurons: 2
 >> iter 61000, loss: 0.024640
 >> iter 62000, loss: 0.024216
 >> iter 63000, loss: 0.020460
 >> iter 64000, loss: 0.022361
 >> iter 65000, loss: 0.021378
 >> iter 66000, loss: 0.021985
 >> iter 67000, loss: 0.022775
 >> iter 68000, loss: 0.020789
 >> iter 69000, loss: 0.022130
 >> iter 70000, loss: 0.022561
   Number of active neurons: 2
 >> iter 71000, loss: 0.034262
 >> iter 72000, loss: 0.024948
 >> iter 73000, loss: 0.026699
 >> iter 74000, loss: 0.027068
 >> iter 75000, loss: 0.021640
 >> iter 76000, loss: 0.037032
 >> iter 77000, loss: 0.029716
 >> iter 78000, loss: 0.024781
 >> iter 79000, loss: 0.027089
 >> iter 80000, loss: 0.026426
   Number of active neurons: 2
 >> iter 81000, loss: 0.023019
 >> iter 82000, loss: 0.023118
 >> iter 83000, loss: 0.022035
 >> iter 84000, loss: 0.030227
 >> iter 85000, loss: 0.037300
 >> iter 86000, loss: 0.025779
 >> iter 87000, loss: 0.023790
 >> iter 88000, loss: 0.025849
 >> iter 89000, loss: 0.025984
 >> iter 90000, loss: 0.032384
   Number of active neurons: 2
 >> iter 91000, loss: 0.028513
 >> iter 92000, loss: 0.024663
 >> iter 93000, loss: 0.021241
 >> iter 94000, loss: 0.025071
 >> iter 95000, loss: 0.024604
 >> iter 96000, loss: 0.022804
 >> iter 97000, loss: 0.025790
 >> iter 98000, loss: 0.022524
 >> iter 99000, loss: 0.024166
 >> iter 100000, loss: 0.021679
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.932122
 >> iter 2000, loss: 4.066469
 >> iter 3000, loss: 1.518128
 >> iter 4000, loss: 0.584353
 >> iter 5000, loss: 0.240353
 >> iter 6000, loss: 0.105886
 >> iter 7000, loss: 0.055234
 >> iter 8000, loss: 0.036578
 >> iter 9000, loss: 0.041514
 >> iter 10000, loss: 0.028288
   Number of active neurons: 3
 >> iter 11000, loss: 0.026089
 >> iter 12000, loss: 0.027531
 >> iter 13000, loss: 0.026649
 >> iter 14000, loss: 0.023885
 >> iter 15000, loss: 0.022354
 >> iter 16000, loss: 0.022750
 >> iter 17000, loss: 0.033220
 >> iter 18000, loss: 0.027454
 >> iter 19000, loss: 0.025125
 >> iter 20000, loss: 0.025694
   Number of active neurons: 3
 >> iter 21000, loss: 0.025076
 >> iter 22000, loss: 0.023689
 >> iter 23000, loss: 0.035720
 >> iter 24000, loss: 0.028567
 >> iter 25000, loss: 0.028104
 >> iter 26000, loss: 0.026936
 >> iter 27000, loss: 0.023126
 >> iter 28000, loss: 0.022507
 >> iter 29000, loss: 0.022696
 >> iter 30000, loss: 0.022622
   Number of active neurons: 2
 >> iter 31000, loss: 0.026122
 >> iter 32000, loss: 0.021639
 >> iter 33000, loss: 0.023614
 >> iter 34000, loss: 0.020609
 >> iter 35000, loss: 0.020384
 >> iter 36000, loss: 0.021562
 >> iter 37000, loss: 0.025130
 >> iter 38000, loss: 0.040378
 >> iter 39000, loss: 0.028950
 >> iter 40000, loss: 0.026782
   Number of active neurons: 1
 >> iter 41000, loss: 0.026585
 >> iter 42000, loss: 0.022320
 >> iter 43000, loss: 0.022540
 >> iter 44000, loss: 0.030482
 >> iter 45000, loss: 0.035664
 >> iter 46000, loss: 0.028574
 >> iter 47000, loss: 0.022353
 >> iter 48000, loss: 0.020508
 >> iter 49000, loss: 0.019266
 >> iter 50000, loss: 0.018398
   Number of active neurons: 1
 >> iter 51000, loss: 0.038460
 >> iter 52000, loss: 0.033026
 >> iter 53000, loss: 0.022704
 >> iter 54000, loss: 0.019855
 >> iter 55000, loss: 0.021131
 >> iter 56000, loss: 0.018342
 >> iter 57000, loss: 0.017411
 >> iter 58000, loss: 0.025801
 >> iter 59000, loss: 0.022222
 >> iter 60000, loss: 0.020615
   Number of active neurons: 1
 >> iter 61000, loss: 0.022725
 >> iter 62000, loss: 0.021374
 >> iter 63000, loss: 0.019946
 >> iter 64000, loss: 0.018678
 >> iter 65000, loss: 0.017544
 >> iter 66000, loss: 0.016161
 >> iter 67000, loss: 0.017379
 >> iter 68000, loss: 0.017985
 >> iter 69000, loss: 0.039549
 >> iter 70000, loss: 0.028270
   Number of active neurons: 1
 >> iter 71000, loss: 0.020763
 >> iter 72000, loss: 0.017774
 >> iter 73000, loss: 0.021087
 >> iter 74000, loss: 0.018901
 >> iter 75000, loss: 0.023816
 >> iter 76000, loss: 0.020788
 >> iter 77000, loss: 0.018482
 >> iter 78000, loss: 0.040475
 >> iter 79000, loss: 0.031176
 >> iter 80000, loss: 0.025748
   Number of active neurons: 1
 >> iter 81000, loss: 0.019625
 >> iter 82000, loss: 0.017559
 >> iter 83000, loss: 0.019005
 >> iter 84000, loss: 0.024632
 >> iter 85000, loss: 0.021966
 >> iter 86000, loss: 0.020176
 >> iter 87000, loss: 0.018206
 >> iter 88000, loss: 0.020609
 >> iter 89000, loss: 0.018006
 >> iter 90000, loss: 0.020856
   Number of active neurons: 1
 >> iter 91000, loss: 0.030513
 >> iter 92000, loss: 0.020790
 >> iter 93000, loss: 0.017342
 >> iter 94000, loss: 0.039617
 >> iter 95000, loss: 0.027987
 >> iter 96000, loss: 0.026278
 >> iter 97000, loss: 0.022629
 >> iter 98000, loss: 0.018253
 >> iter 99000, loss: 0.016605
 >> iter 100000, loss: 0.029355
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

