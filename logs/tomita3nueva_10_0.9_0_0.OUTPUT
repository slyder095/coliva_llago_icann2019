 > Problema: tomita3nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.9
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455161
   Number of active neurons: 0
 >> iter 1000, loss: 19.037806
 >> iter 2000, loss: 12.582087
 >> iter 3000, loss: 6.326574
 >> iter 4000, loss: 3.187701
 >> iter 5000, loss: 1.631411
 >> iter 6000, loss: 0.879841
 >> iter 7000, loss: 0.457560
 >> iter 8000, loss: 0.259048
 >> iter 9000, loss: 0.278912
 >> iter 10000, loss: 0.436563
   Number of active neurons: 10
 >> iter 11000, loss: 0.342041
 >> iter 12000, loss: 0.216496
 >> iter 13000, loss: 0.126030
 >> iter 14000, loss: 0.251881
 >> iter 15000, loss: 0.148277
 >> iter 16000, loss: 0.134382
 >> iter 17000, loss: 0.079479
 >> iter 18000, loss: 0.089873
 >> iter 19000, loss: 0.083759
 >> iter 20000, loss: 0.049628
   Number of active neurons: 10
 >> iter 21000, loss: 0.107916
 >> iter 22000, loss: 0.128543
 >> iter 23000, loss: 0.055477
 >> iter 24000, loss: 0.059503
 >> iter 25000, loss: 0.033761
 >> iter 26000, loss: 0.084906
 >> iter 27000, loss: 0.037137
 >> iter 28000, loss: 0.081291
 >> iter 29000, loss: 0.099191
 >> iter 30000, loss: 0.042537
   Number of active neurons: 10
 >> iter 31000, loss: 0.022111
 >> iter 32000, loss: 0.043166
 >> iter 33000, loss: 0.036022
 >> iter 34000, loss: 0.026514
 >> iter 35000, loss: 0.015735
 >> iter 36000, loss: 0.011181
 >> iter 37000, loss: 0.010083
 >> iter 38000, loss: 0.287138
 >> iter 39000, loss: 0.245998
 >> iter 40000, loss: 0.097706
   Number of active neurons: 10
 >> iter 41000, loss: 0.098719
 >> iter 42000, loss: 0.043501
 >> iter 43000, loss: 0.027065
 >> iter 44000, loss: 0.127842
 >> iter 45000, loss: 0.053391
 >> iter 46000, loss: 0.026466
 >> iter 47000, loss: 0.013504
 >> iter 48000, loss: 0.046849
 >> iter 49000, loss: 0.021217
 >> iter 50000, loss: 0.139355
   Number of active neurons: 10
 >> iter 51000, loss: 0.113183
 >> iter 52000, loss: 0.046190
 >> iter 53000, loss: 0.056272
 >> iter 54000, loss: 0.063793
 >> iter 55000, loss: 0.028626
 >> iter 56000, loss: 0.022947
 >> iter 57000, loss: 0.019460
 >> iter 58000, loss: 0.011058
 >> iter 59000, loss: 0.007455
 >> iter 60000, loss: 0.010482
   Number of active neurons: 10
 >> iter 61000, loss: 0.006850
 >> iter 62000, loss: 0.005378
 >> iter 63000, loss: 0.014140
 >> iter 64000, loss: 0.008116
 >> iter 65000, loss: 0.094889
 >> iter 66000, loss: 0.052695
 >> iter 67000, loss: 0.044531
 >> iter 68000, loss: 0.043924
 >> iter 69000, loss: 0.029704
 >> iter 70000, loss: 0.013244
   Number of active neurons: 10
 >> iter 71000, loss: 0.019732
 >> iter 72000, loss: 0.096804
 >> iter 73000, loss: 0.038883
 >> iter 74000, loss: 0.017714
 >> iter 75000, loss: 0.008923
 >> iter 76000, loss: 0.005588
 >> iter 77000, loss: 0.007824
 >> iter 78000, loss: 0.019691
 >> iter 79000, loss: 0.009395
 >> iter 80000, loss: 0.038284
   Number of active neurons: 10
 >> iter 81000, loss: 0.030119
 >> iter 82000, loss: 0.034803
 >> iter 83000, loss: 0.018336
 >> iter 84000, loss: 0.014326
 >> iter 85000, loss: 0.010571
 >> iter 86000, loss: 0.008718
 >> iter 87000, loss: 0.006816
 >> iter 88000, loss: 0.120939
 >> iter 89000, loss: 0.048261
 >> iter 90000, loss: 0.020089
   Number of active neurons: 10
 >> iter 91000, loss: 0.129459
 >> iter 92000, loss: 0.050677
 >> iter 93000, loss: 0.026367
 >> iter 94000, loss: 0.039539
 >> iter 95000, loss: 0.057203
 >> iter 96000, loss: 0.050445
 >> iter 97000, loss: 0.025897
 >> iter 98000, loss: 0.013671
 >> iter 99000, loss: 0.010017
 >> iter 100000, loss: 0.006010
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.066143
 >> iter 2000, loss: 12.353978
 >> iter 3000, loss: 6.283832
 >> iter 4000, loss: 3.117974
 >> iter 5000, loss: 1.636852
 >> iter 6000, loss: 0.876602
 >> iter 7000, loss: 0.566163
 >> iter 8000, loss: 0.419677
 >> iter 9000, loss: 0.321391
 >> iter 10000, loss: 0.184224
   Number of active neurons: 10
 >> iter 11000, loss: 0.111322
 >> iter 12000, loss: 0.120155
 >> iter 13000, loss: 0.147840
 >> iter 14000, loss: 0.140505
 >> iter 15000, loss: 0.216529
 >> iter 16000, loss: 0.113399
 >> iter 17000, loss: 0.067499
 >> iter 18000, loss: 0.053111
 >> iter 19000, loss: 0.046554
 >> iter 20000, loss: 0.074182
   Number of active neurons: 10
 >> iter 21000, loss: 0.117573
 >> iter 22000, loss: 0.053585
 >> iter 23000, loss: 0.072474
 >> iter 24000, loss: 0.033623
 >> iter 25000, loss: 0.026340
 >> iter 26000, loss: 0.017233
 >> iter 27000, loss: 0.075899
 >> iter 28000, loss: 0.058533
 >> iter 29000, loss: 0.029593
 >> iter 30000, loss: 0.038619
   Number of active neurons: 10
 >> iter 31000, loss: 0.134798
 >> iter 32000, loss: 0.058060
 >> iter 33000, loss: 0.047815
 >> iter 34000, loss: 0.024974
 >> iter 35000, loss: 0.041319
 >> iter 36000, loss: 0.042131
 >> iter 37000, loss: 0.035960
 >> iter 38000, loss: 0.033119
 >> iter 39000, loss: 0.017538
 >> iter 40000, loss: 0.023537
   Number of active neurons: 10
 >> iter 41000, loss: 0.015407
 >> iter 42000, loss: 0.114332
 >> iter 43000, loss: 0.052450
 >> iter 44000, loss: 0.022066
 >> iter 45000, loss: 0.011105
 >> iter 46000, loss: 0.072142
 >> iter 47000, loss: 0.076736
 >> iter 48000, loss: 0.050361
 >> iter 49000, loss: 0.109951
 >> iter 50000, loss: 0.072180
   Number of active neurons: 10
 >> iter 51000, loss: 0.074695
 >> iter 52000, loss: 0.074908
 >> iter 53000, loss: 0.086849
 >> iter 54000, loss: 0.094010
 >> iter 55000, loss: 0.046775
 >> iter 56000, loss: 0.020827
 >> iter 57000, loss: 0.080164
 >> iter 58000, loss: 0.048392
 >> iter 59000, loss: 0.048842
 >> iter 60000, loss: 0.069469
   Number of active neurons: 10
 >> iter 61000, loss: 0.042213
 >> iter 62000, loss: 0.065963
 >> iter 63000, loss: 0.150742
 >> iter 64000, loss: 0.065139
 >> iter 65000, loss: 0.028450
 >> iter 66000, loss: 0.069098
 >> iter 67000, loss: 0.041258
 >> iter 68000, loss: 0.018539
 >> iter 69000, loss: 0.047446
 >> iter 70000, loss: 0.023655
   Number of active neurons: 10
 >> iter 71000, loss: 0.051224
 >> iter 72000, loss: 0.021903
 >> iter 73000, loss: 0.011829
 >> iter 74000, loss: 0.060001
 >> iter 75000, loss: 0.025196
 >> iter 76000, loss: 0.012166
 >> iter 77000, loss: 0.016844
 >> iter 78000, loss: 0.019545
 >> iter 79000, loss: 0.009706
 >> iter 80000, loss: 0.084996
   Number of active neurons: 10
 >> iter 81000, loss: 0.034720
 >> iter 82000, loss: 0.053130
 >> iter 83000, loss: 0.037759
 >> iter 84000, loss: 0.027215
 >> iter 85000, loss: 0.065464
 >> iter 86000, loss: 0.031524
 >> iter 87000, loss: 0.015036
 >> iter 88000, loss: 0.040103
 >> iter 89000, loss: 0.101377
 >> iter 90000, loss: 0.041195
   Number of active neurons: 10
 >> iter 91000, loss: 0.018224
 >> iter 92000, loss: 0.012915
 >> iter 93000, loss: 0.056750
 >> iter 94000, loss: 0.023472
 >> iter 95000, loss: 0.081373
 >> iter 96000, loss: 0.123183
 >> iter 97000, loss: 0.071762
 >> iter 98000, loss: 0.030085
 >> iter 99000, loss: 0.015232
 >> iter 100000, loss: 0.010432
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.280883
 >> iter 2000, loss: 12.897173
 >> iter 3000, loss: 7.263879
 >> iter 4000, loss: 4.276146
 >> iter 5000, loss: 2.224156
 >> iter 6000, loss: 1.171299
 >> iter 7000, loss: 0.702873
 >> iter 8000, loss: 0.484925
 >> iter 9000, loss: 0.329134
 >> iter 10000, loss: 0.214627
   Number of active neurons: 10
 >> iter 11000, loss: 0.270649
 >> iter 12000, loss: 0.218275
 >> iter 13000, loss: 0.305670
 >> iter 14000, loss: 0.159119
 >> iter 15000, loss: 0.147071
 >> iter 16000, loss: 0.179171
 >> iter 17000, loss: 0.183382
 >> iter 18000, loss: 0.113324
 >> iter 19000, loss: 0.081988
 >> iter 20000, loss: 0.151644
   Number of active neurons: 10
 >> iter 21000, loss: 0.150472
 >> iter 22000, loss: 0.116802
 >> iter 23000, loss: 0.076288
 >> iter 24000, loss: 0.096453
 >> iter 25000, loss: 0.086589
 >> iter 26000, loss: 0.049226
 >> iter 27000, loss: 0.052433
 >> iter 28000, loss: 0.032512
 >> iter 29000, loss: 0.024245
 >> iter 30000, loss: 0.030327
   Number of active neurons: 10
 >> iter 31000, loss: 0.049201
 >> iter 32000, loss: 0.190252
 >> iter 33000, loss: 0.095695
 >> iter 34000, loss: 0.043053
 >> iter 35000, loss: 0.051277
 >> iter 36000, loss: 0.023239
 >> iter 37000, loss: 0.034364
 >> iter 38000, loss: 0.021693
 >> iter 39000, loss: 0.046857
 >> iter 40000, loss: 0.021439
   Number of active neurons: 10
 >> iter 41000, loss: 0.014464
 >> iter 42000, loss: 0.008495
 >> iter 43000, loss: 0.010470
 >> iter 44000, loss: 0.006862
 >> iter 45000, loss: 0.011131
 >> iter 46000, loss: 0.021031
 >> iter 47000, loss: 0.010878
 >> iter 48000, loss: 0.006567
 >> iter 49000, loss: 0.025569
 >> iter 50000, loss: 0.013556
   Number of active neurons: 10
 >> iter 51000, loss: 0.018869
 >> iter 52000, loss: 0.110700
 >> iter 53000, loss: 0.043876
 >> iter 54000, loss: 0.090742
 >> iter 55000, loss: 0.054836
 >> iter 56000, loss: 0.023303
 >> iter 57000, loss: 0.011510
 >> iter 58000, loss: 0.008019
 >> iter 59000, loss: 0.030505
 >> iter 60000, loss: 0.021336
   Number of active neurons: 10
 >> iter 61000, loss: 0.197368
 >> iter 62000, loss: 0.077415
 >> iter 63000, loss: 0.030888
 >> iter 64000, loss: 0.031440
 >> iter 65000, loss: 0.013996
 >> iter 66000, loss: 0.009916
 >> iter 67000, loss: 0.005842
 >> iter 68000, loss: 0.013530
 >> iter 69000, loss: 0.007213
 >> iter 70000, loss: 0.004980
   Number of active neurons: 10
 >> iter 71000, loss: 0.003482
 >> iter 72000, loss: 0.003376
 >> iter 73000, loss: 0.004706
 >> iter 74000, loss: 0.012994
 >> iter 75000, loss: 0.006333
 >> iter 76000, loss: 0.133519
 >> iter 77000, loss: 0.051887
 >> iter 78000, loss: 0.022711
 >> iter 79000, loss: 0.010356
 >> iter 80000, loss: 0.051933
   Number of active neurons: 10
 >> iter 81000, loss: 0.021286
 >> iter 82000, loss: 0.147609
 >> iter 83000, loss: 0.120951
 >> iter 84000, loss: 0.048212
 >> iter 85000, loss: 0.020231
 >> iter 86000, loss: 0.009640
 >> iter 87000, loss: 0.061329
 >> iter 88000, loss: 0.034118
 >> iter 89000, loss: 0.103989
 >> iter 90000, loss: 0.041149
   Number of active neurons: 10
 >> iter 91000, loss: 0.020446
 >> iter 92000, loss: 0.009591
 >> iter 93000, loss: 0.006673
 >> iter 94000, loss: 0.004637
 >> iter 95000, loss: 0.003346
 >> iter 96000, loss: 0.002826
 >> iter 97000, loss: 0.005744
 >> iter 98000, loss: 0.038488
 >> iter 99000, loss: 0.062246
 >> iter 100000, loss: 0.025692
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.052549
 >> iter 2000, loss: 13.026193
 >> iter 3000, loss: 7.799472
 >> iter 4000, loss: 3.650563
 >> iter 5000, loss: 1.830704
 >> iter 6000, loss: 1.046589
 >> iter 7000, loss: 0.626272
 >> iter 8000, loss: 0.438544
 >> iter 9000, loss: 0.208056
 >> iter 10000, loss: 0.130521
   Number of active neurons: 10
 >> iter 11000, loss: 0.071059
 >> iter 12000, loss: 0.168844
 >> iter 13000, loss: 0.079950
 >> iter 14000, loss: 0.082460
 >> iter 15000, loss: 0.249615
 >> iter 16000, loss: 0.207691
 >> iter 17000, loss: 0.095824
 >> iter 18000, loss: 0.092545
 >> iter 19000, loss: 0.047333
 >> iter 20000, loss: 0.026018
   Number of active neurons: 10
 >> iter 21000, loss: 0.031495
 >> iter 22000, loss: 0.017975
 >> iter 23000, loss: 0.044406
 >> iter 24000, loss: 0.033567
 >> iter 25000, loss: 0.034938
 >> iter 26000, loss: 0.019292
 >> iter 27000, loss: 0.052695
 >> iter 28000, loss: 0.131876
 >> iter 29000, loss: 0.067948
 >> iter 30000, loss: 0.157256
   Number of active neurons: 10
 >> iter 31000, loss: 0.066313
 >> iter 32000, loss: 0.027852
 >> iter 33000, loss: 0.045707
 >> iter 34000, loss: 0.030695
 >> iter 35000, loss: 0.039712
 >> iter 36000, loss: 0.019661
 >> iter 37000, loss: 0.010449
 >> iter 38000, loss: 0.007312
 >> iter 39000, loss: 0.005840
 >> iter 40000, loss: 0.008358
   Number of active neurons: 10
 >> iter 41000, loss: 0.005575
 >> iter 42000, loss: 0.081514
 >> iter 43000, loss: 0.210327
 >> iter 44000, loss: 0.087649
 >> iter 45000, loss: 0.035186
 >> iter 46000, loss: 0.015471
 >> iter 47000, loss: 0.008031
 >> iter 48000, loss: 0.008443
 >> iter 49000, loss: 0.007855
 >> iter 50000, loss: 0.005425
   Number of active neurons: 10
 >> iter 51000, loss: 0.003915
 >> iter 52000, loss: 0.052288
 >> iter 53000, loss: 0.021074
 >> iter 54000, loss: 0.009446
 >> iter 55000, loss: 0.005404
 >> iter 56000, loss: 0.003391
 >> iter 57000, loss: 0.040240
 >> iter 58000, loss: 0.016356
 >> iter 59000, loss: 0.007747
 >> iter 60000, loss: 0.016458
   Number of active neurons: 10
 >> iter 61000, loss: 0.007835
 >> iter 62000, loss: 0.043257
 >> iter 63000, loss: 0.021810
 >> iter 64000, loss: 0.009744
 >> iter 65000, loss: 0.005051
 >> iter 66000, loss: 0.003914
 >> iter 67000, loss: 0.037790
 >> iter 68000, loss: 0.015453
 >> iter 69000, loss: 0.051617
 >> iter 70000, loss: 0.020512
   Number of active neurons: 10
 >> iter 71000, loss: 0.009111
 >> iter 72000, loss: 0.006101
 >> iter 73000, loss: 0.004003
 >> iter 74000, loss: 0.005980
 >> iter 75000, loss: 0.003607
 >> iter 76000, loss: 0.003293
 >> iter 77000, loss: 0.048452
 >> iter 78000, loss: 0.063351
 >> iter 79000, loss: 0.029666
 >> iter 80000, loss: 0.043629
   Number of active neurons: 10
 >> iter 81000, loss: 0.017373
 >> iter 82000, loss: 0.050687
 >> iter 83000, loss: 0.020289
 >> iter 84000, loss: 0.009911
 >> iter 85000, loss: 0.004977
 >> iter 86000, loss: 0.003320
 >> iter 87000, loss: 0.002628
 >> iter 88000, loss: 0.002182
 >> iter 89000, loss: 0.002478
 >> iter 90000, loss: 0.002671
   Number of active neurons: 10
 >> iter 91000, loss: 0.002895
 >> iter 92000, loss: 0.002118
 >> iter 93000, loss: 0.047075
 >> iter 94000, loss: 0.079360
 >> iter 95000, loss: 0.030742
 >> iter 96000, loss: 0.045477
 >> iter 97000, loss: 0.018254
 >> iter 98000, loss: 0.008235
 >> iter 99000, loss: 0.004257
 >> iter 100000, loss: 0.105400
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.284726
 >> iter 2000, loss: 12.966998
 >> iter 3000, loss: 7.019809
 >> iter 4000, loss: 3.393207
 >> iter 5000, loss: 1.760573
 >> iter 6000, loss: 0.767576
 >> iter 7000, loss: 0.399226
 >> iter 8000, loss: 0.215108
 >> iter 9000, loss: 0.351974
 >> iter 10000, loss: 0.225359
   Number of active neurons: 10
 >> iter 11000, loss: 0.305903
 >> iter 12000, loss: 0.169130
 >> iter 13000, loss: 0.227527
 >> iter 14000, loss: 0.180158
 >> iter 15000, loss: 0.151330
 >> iter 16000, loss: 0.195986
 >> iter 17000, loss: 0.153112
 >> iter 18000, loss: 0.077748
 >> iter 19000, loss: 0.202058
 >> iter 20000, loss: 0.084471
   Number of active neurons: 10
 >> iter 21000, loss: 0.081550
 >> iter 22000, loss: 0.251548
 >> iter 23000, loss: 0.133055
 >> iter 24000, loss: 0.113447
 >> iter 25000, loss: 0.070015
 >> iter 26000, loss: 0.067722
 >> iter 27000, loss: 0.075765
 >> iter 28000, loss: 0.036650
 >> iter 29000, loss: 0.059544
 >> iter 30000, loss: 0.035539
   Number of active neurons: 10
 >> iter 31000, loss: 0.024623
 >> iter 32000, loss: 0.028345
 >> iter 33000, loss: 0.026742
 >> iter 34000, loss: 0.025588
 >> iter 35000, loss: 0.013063
 >> iter 36000, loss: 0.008763
 >> iter 37000, loss: 0.077642
 >> iter 38000, loss: 0.046847
 >> iter 39000, loss: 0.077528
 >> iter 40000, loss: 0.080585
   Number of active neurons: 10
 >> iter 41000, loss: 0.033930
 >> iter 42000, loss: 0.020984
 >> iter 43000, loss: 0.011957
 >> iter 44000, loss: 0.007384
 >> iter 45000, loss: 0.007058
 >> iter 46000, loss: 0.005954
 >> iter 47000, loss: 0.008653
 >> iter 48000, loss: 0.033264
 >> iter 49000, loss: 0.024328
 >> iter 50000, loss: 0.011225
   Number of active neurons: 10
 >> iter 51000, loss: 0.006820
 >> iter 52000, loss: 0.052623
 >> iter 53000, loss: 0.022384
 >> iter 54000, loss: 0.027814
 >> iter 55000, loss: 0.012485
 >> iter 56000, loss: 0.006735
 >> iter 57000, loss: 0.005397
 >> iter 58000, loss: 0.003998
 >> iter 59000, loss: 0.008323
 >> iter 60000, loss: 0.004772
   Number of active neurons: 10
 >> iter 61000, loss: 0.003454
 >> iter 62000, loss: 0.002772
 >> iter 63000, loss: 0.002420
 >> iter 64000, loss: 0.003485
 >> iter 65000, loss: 0.006844
 >> iter 66000, loss: 0.004092
 >> iter 67000, loss: 0.004733
 >> iter 68000, loss: 0.003022
 >> iter 69000, loss: 0.002470
 >> iter 70000, loss: 0.002557
   Number of active neurons: 10
 >> iter 71000, loss: 0.002168
 >> iter 72000, loss: 0.008281
 >> iter 73000, loss: 0.005420
 >> iter 74000, loss: 0.024366
 >> iter 75000, loss: 0.023722
 >> iter 76000, loss: 0.026200
 >> iter 77000, loss: 0.060374
 >> iter 78000, loss: 0.041948
 >> iter 79000, loss: 0.017100
 >> iter 80000, loss: 0.011548
   Number of active neurons: 10
 >> iter 81000, loss: 0.024868
 >> iter 82000, loss: 0.016966
 >> iter 83000, loss: 0.007805
 >> iter 84000, loss: 0.006872
 >> iter 85000, loss: 0.003847
 >> iter 86000, loss: 0.002665
 >> iter 87000, loss: 0.002001
 >> iter 88000, loss: 0.002129
 >> iter 89000, loss: 0.002596
 >> iter 90000, loss: 0.001887
   Number of active neurons: 10
 >> iter 91000, loss: 0.006416
 >> iter 92000, loss: 0.004686
 >> iter 93000, loss: 0.002622
 >> iter 94000, loss: 0.002876
 >> iter 95000, loss: 0.028402
 >> iter 96000, loss: 0.011312
 >> iter 97000, loss: 0.005108
 >> iter 98000, loss: 0.017846
 >> iter 99000, loss: 0.008202
 >> iter 100000, loss: 0.006123
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 19.504840
 >> iter 2000, loss: 13.196491
 >> iter 3000, loss: 6.735065
 >> iter 4000, loss: 3.538986
 >> iter 5000, loss: 1.891194
 >> iter 6000, loss: 1.178688
 >> iter 7000, loss: 0.804160
 >> iter 8000, loss: 0.715297
 >> iter 9000, loss: 0.425417
 >> iter 10000, loss: 0.251734
   Number of active neurons: 10
 >> iter 11000, loss: 0.393147
 >> iter 12000, loss: 0.216783
 >> iter 13000, loss: 0.278713
 >> iter 14000, loss: 0.129333
 >> iter 15000, loss: 0.086742
 >> iter 16000, loss: 0.120770
 >> iter 17000, loss: 0.078450
 >> iter 18000, loss: 0.114318
 >> iter 19000, loss: 0.174377
 >> iter 20000, loss: 0.110172
   Number of active neurons: 10
 >> iter 21000, loss: 0.079681
 >> iter 22000, loss: 0.042423
 >> iter 23000, loss: 0.136177
 >> iter 24000, loss: 0.057702
 >> iter 25000, loss: 0.128246
 >> iter 26000, loss: 0.102670
 >> iter 27000, loss: 0.052056
 >> iter 28000, loss: 0.087923
 >> iter 29000, loss: 0.090483
 >> iter 30000, loss: 0.039757
   Number of active neurons: 10
 >> iter 31000, loss: 0.111246
 >> iter 32000, loss: 0.117203
 >> iter 33000, loss: 0.068216
 >> iter 34000, loss: 0.032893
 >> iter 35000, loss: 0.107513
 >> iter 36000, loss: 0.064444
 >> iter 37000, loss: 0.049321
 >> iter 38000, loss: 0.042186
 >> iter 39000, loss: 0.025938
 >> iter 40000, loss: 0.026836
   Number of active neurons: 10
 >> iter 41000, loss: 0.016552
 >> iter 42000, loss: 0.065019
 >> iter 43000, loss: 0.045513
 >> iter 44000, loss: 0.021815
 >> iter 45000, loss: 0.012354
 >> iter 46000, loss: 0.025335
 >> iter 47000, loss: 0.013812
 >> iter 48000, loss: 0.022084
 >> iter 49000, loss: 0.057732
 >> iter 50000, loss: 0.028614
   Number of active neurons: 10
 >> iter 51000, loss: 0.012884
 >> iter 52000, loss: 0.007657
 >> iter 53000, loss: 0.005531
 >> iter 54000, loss: 0.022575
 >> iter 55000, loss: 0.010488
 >> iter 56000, loss: 0.030577
 >> iter 57000, loss: 0.013328
 >> iter 58000, loss: 0.006908
 >> iter 59000, loss: 0.004965
 >> iter 60000, loss: 0.010319
   Number of active neurons: 10
 >> iter 61000, loss: 0.021448
 >> iter 62000, loss: 0.116470
 >> iter 63000, loss: 0.052871
 >> iter 64000, loss: 0.023738
 >> iter 65000, loss: 0.065747
 >> iter 66000, loss: 0.027372
 >> iter 67000, loss: 0.012065
 >> iter 68000, loss: 0.006340
 >> iter 69000, loss: 0.013749
 >> iter 70000, loss: 0.015963
   Number of active neurons: 10
 >> iter 71000, loss: 0.008759
 >> iter 72000, loss: 0.006672
 >> iter 73000, loss: 0.024114
 >> iter 74000, loss: 0.010486
 >> iter 75000, loss: 0.012135
 >> iter 76000, loss: 0.012990
 >> iter 77000, loss: 0.009977
 >> iter 78000, loss: 0.036329
 >> iter 79000, loss: 0.014797
 >> iter 80000, loss: 0.008480
   Number of active neurons: 10
 >> iter 81000, loss: 0.019210
 >> iter 82000, loss: 0.012329
 >> iter 83000, loss: 0.028153
 >> iter 84000, loss: 0.013099
 >> iter 85000, loss: 0.006987
 >> iter 86000, loss: 0.005175
 >> iter 87000, loss: 0.003583
 >> iter 88000, loss: 0.004564
 >> iter 89000, loss: 0.025108
 >> iter 90000, loss: 0.010449
   Number of active neurons: 10
 >> iter 91000, loss: 0.042263
 >> iter 92000, loss: 0.016790
 >> iter 93000, loss: 0.049623
 >> iter 94000, loss: 0.019834
 >> iter 95000, loss: 0.009048
 >> iter 96000, loss: 0.033908
 >> iter 97000, loss: 0.014460
 >> iter 98000, loss: 0.006364
 >> iter 99000, loss: 0.022973
 >> iter 100000, loss: 0.046714
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.245417
 >> iter 2000, loss: 12.717340
 >> iter 3000, loss: 6.178466
 >> iter 4000, loss: 2.821334
 >> iter 5000, loss: 1.216738
 >> iter 6000, loss: 0.774071
 >> iter 7000, loss: 0.510817
 >> iter 8000, loss: 0.397076
 >> iter 9000, loss: 0.271277
 >> iter 10000, loss: 0.171565
   Number of active neurons: 10
 >> iter 11000, loss: 0.361978
 >> iter 12000, loss: 0.255554
 >> iter 13000, loss: 0.228080
 >> iter 14000, loss: 0.272324
 >> iter 15000, loss: 0.140139
 >> iter 16000, loss: 0.123708
 >> iter 17000, loss: 0.200461
 >> iter 18000, loss: 0.145584
 >> iter 19000, loss: 0.075894
 >> iter 20000, loss: 0.079498
   Number of active neurons: 10
 >> iter 21000, loss: 0.089739
 >> iter 22000, loss: 0.120801
 >> iter 23000, loss: 0.148213
 >> iter 24000, loss: 0.068571
 >> iter 25000, loss: 0.033645
 >> iter 26000, loss: 0.018298
 >> iter 27000, loss: 0.016688
 >> iter 28000, loss: 0.024266
 >> iter 29000, loss: 0.113580
 >> iter 30000, loss: 0.046584
   Number of active neurons: 10
 >> iter 31000, loss: 0.033707
 >> iter 32000, loss: 0.050863
 >> iter 33000, loss: 0.031983
 >> iter 34000, loss: 0.050294
 >> iter 35000, loss: 0.022182
 >> iter 36000, loss: 0.011210
 >> iter 37000, loss: 0.076818
 >> iter 38000, loss: 0.055096
 >> iter 39000, loss: 0.023995
 >> iter 40000, loss: 0.017780
   Number of active neurons: 10
 >> iter 41000, loss: 0.010415
 >> iter 42000, loss: 0.035981
 >> iter 43000, loss: 0.017420
 >> iter 44000, loss: 0.081880
 >> iter 45000, loss: 0.036113
 >> iter 46000, loss: 0.016602
 >> iter 47000, loss: 0.008575
 >> iter 48000, loss: 0.006344
 >> iter 49000, loss: 0.011439
 >> iter 50000, loss: 0.013305
   Number of active neurons: 10
 >> iter 51000, loss: 0.009639
 >> iter 52000, loss: 0.094481
 >> iter 53000, loss: 0.038535
 >> iter 54000, loss: 0.016697
 >> iter 55000, loss: 0.008363
 >> iter 56000, loss: 0.005270
 >> iter 57000, loss: 0.003871
 >> iter 58000, loss: 0.003472
 >> iter 59000, loss: 0.002914
 >> iter 60000, loss: 0.002616
   Number of active neurons: 10
 >> iter 61000, loss: 0.091788
 >> iter 62000, loss: 0.035825
 >> iter 63000, loss: 0.016139
 >> iter 64000, loss: 0.069104
 >> iter 65000, loss: 0.177786
 >> iter 66000, loss: 0.069153
 >> iter 67000, loss: 0.027668
 >> iter 68000, loss: 0.012175
 >> iter 69000, loss: 0.040262
 >> iter 70000, loss: 0.017213
   Number of active neurons: 10
 >> iter 71000, loss: 0.008249
 >> iter 72000, loss: 0.018410
 >> iter 73000, loss: 0.009540
 >> iter 74000, loss: 0.005970
 >> iter 75000, loss: 0.003895
 >> iter 76000, loss: 0.003376
 >> iter 77000, loss: 0.002630
 >> iter 78000, loss: 0.002571
 >> iter 79000, loss: 0.002490
 >> iter 80000, loss: 0.002326
   Number of active neurons: 10
 >> iter 81000, loss: 0.002229
 >> iter 82000, loss: 0.002186
 >> iter 83000, loss: 0.102357
 >> iter 84000, loss: 0.039473
 >> iter 85000, loss: 0.016157
 >> iter 86000, loss: 0.035538
 >> iter 87000, loss: 0.016501
 >> iter 88000, loss: 0.012856
 >> iter 89000, loss: 0.015782
 >> iter 90000, loss: 0.065505
   Number of active neurons: 10
 >> iter 91000, loss: 0.076912
 >> iter 92000, loss: 0.030721
 >> iter 93000, loss: 0.013118
 >> iter 94000, loss: 0.006608
 >> iter 95000, loss: 0.005810
 >> iter 96000, loss: 0.005632
 >> iter 97000, loss: 0.003600
 >> iter 98000, loss: 0.002925
 >> iter 99000, loss: 0.002794
 >> iter 100000, loss: 0.003804
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.332752
 >> iter 2000, loss: 13.718604
 >> iter 3000, loss: 7.402680
 >> iter 4000, loss: 3.676309
 >> iter 5000, loss: 1.781555
 >> iter 6000, loss: 0.924592
 >> iter 7000, loss: 0.530007
 >> iter 8000, loss: 0.395110
 >> iter 9000, loss: 0.231967
 >> iter 10000, loss: 0.252505
   Number of active neurons: 10
 >> iter 11000, loss: 0.171125
 >> iter 12000, loss: 0.348678
 >> iter 13000, loss: 0.185224
 >> iter 14000, loss: 0.184820
 >> iter 15000, loss: 0.104841
 >> iter 16000, loss: 0.080549
 >> iter 17000, loss: 0.235673
 >> iter 18000, loss: 0.100481
 >> iter 19000, loss: 0.045226
 >> iter 20000, loss: 0.035458
   Number of active neurons: 10
 >> iter 21000, loss: 0.036168
 >> iter 22000, loss: 0.058243
 >> iter 23000, loss: 0.067561
 >> iter 24000, loss: 0.030821
 >> iter 25000, loss: 0.018777
 >> iter 26000, loss: 0.175450
 >> iter 27000, loss: 0.163937
 >> iter 28000, loss: 0.083797
 >> iter 29000, loss: 0.104324
 >> iter 30000, loss: 0.131002
   Number of active neurons: 10
 >> iter 31000, loss: 0.113878
 >> iter 32000, loss: 0.064523
 >> iter 33000, loss: 0.033405
 >> iter 34000, loss: 0.073528
 >> iter 35000, loss: 0.034625
 >> iter 36000, loss: 0.023276
 >> iter 37000, loss: 0.016329
 >> iter 38000, loss: 0.009900
 >> iter 39000, loss: 0.009835
 >> iter 40000, loss: 0.008581
   Number of active neurons: 10
 >> iter 41000, loss: 0.010459
 >> iter 42000, loss: 0.010281
 >> iter 43000, loss: 0.073628
 >> iter 44000, loss: 0.034644
 >> iter 45000, loss: 0.055780
 >> iter 46000, loss: 0.074798
 >> iter 47000, loss: 0.040309
 >> iter 48000, loss: 0.019301
 >> iter 49000, loss: 0.050045
 >> iter 50000, loss: 0.023100
   Number of active neurons: 10
 >> iter 51000, loss: 0.011049
 >> iter 52000, loss: 0.009542
 >> iter 53000, loss: 0.064295
 >> iter 54000, loss: 0.115846
 >> iter 55000, loss: 0.053083
 >> iter 56000, loss: 0.022526
 >> iter 57000, loss: 0.031945
 >> iter 58000, loss: 0.029532
 >> iter 59000, loss: 0.013523
 >> iter 60000, loss: 0.158342
   Number of active neurons: 10
 >> iter 61000, loss: 0.079416
 >> iter 62000, loss: 0.033414
 >> iter 63000, loss: 0.036444
 >> iter 64000, loss: 0.047568
 >> iter 65000, loss: 0.065067
 >> iter 66000, loss: 0.050529
 >> iter 67000, loss: 0.031993
 >> iter 68000, loss: 0.039769
 >> iter 69000, loss: 0.019175
 >> iter 70000, loss: 0.010186
   Number of active neurons: 10
 >> iter 71000, loss: 0.045962
 >> iter 72000, loss: 0.020773
 >> iter 73000, loss: 0.064952
 >> iter 74000, loss: 0.027770
 >> iter 75000, loss: 0.013304
 >> iter 76000, loss: 0.007598
 >> iter 77000, loss: 0.036408
 >> iter 78000, loss: 0.015702
 >> iter 79000, loss: 0.087648
 >> iter 80000, loss: 0.034550
   Number of active neurons: 10
 >> iter 81000, loss: 0.024566
 >> iter 82000, loss: 0.046257
 >> iter 83000, loss: 0.024649
 >> iter 84000, loss: 0.011936
 >> iter 85000, loss: 0.105692
 >> iter 86000, loss: 0.061517
 >> iter 87000, loss: 0.033794
 >> iter 88000, loss: 0.078476
 >> iter 89000, loss: 0.032091
 >> iter 90000, loss: 0.034517
   Number of active neurons: 10
 >> iter 91000, loss: 0.065617
 >> iter 92000, loss: 0.184370
 >> iter 93000, loss: 0.077278
 >> iter 94000, loss: 0.031998
 >> iter 95000, loss: 0.038147
 >> iter 96000, loss: 0.099453
 >> iter 97000, loss: 0.147572
 >> iter 98000, loss: 0.136566
 >> iter 99000, loss: 0.055390
 >> iter 100000, loss: 0.069210
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 19.110690
 >> iter 2000, loss: 12.649678
 >> iter 3000, loss: 6.586419
 >> iter 4000, loss: 3.178455
 >> iter 5000, loss: 1.705701
 >> iter 6000, loss: 1.077657
 >> iter 7000, loss: 0.517510
 >> iter 8000, loss: 0.453964
 >> iter 9000, loss: 0.315317
 >> iter 10000, loss: 0.152592
   Number of active neurons: 10
 >> iter 11000, loss: 0.143552
 >> iter 12000, loss: 0.121912
 >> iter 13000, loss: 0.145146
 >> iter 14000, loss: 0.235412
 >> iter 15000, loss: 0.122335
 >> iter 16000, loss: 0.192499
 >> iter 17000, loss: 0.081136
 >> iter 18000, loss: 0.101040
 >> iter 19000, loss: 0.045287
 >> iter 20000, loss: 0.030905
   Number of active neurons: 10
 >> iter 21000, loss: 0.020471
 >> iter 22000, loss: 0.024862
 >> iter 23000, loss: 0.015185
 >> iter 24000, loss: 0.053170
 >> iter 25000, loss: 0.051019
 >> iter 26000, loss: 0.023331
 >> iter 27000, loss: 0.020581
 >> iter 28000, loss: 0.050918
 >> iter 29000, loss: 0.024039
 >> iter 30000, loss: 0.043398
   Number of active neurons: 10
 >> iter 31000, loss: 0.020146
 >> iter 32000, loss: 0.010940
 >> iter 33000, loss: 0.017013
 >> iter 34000, loss: 0.039533
 >> iter 35000, loss: 0.082327
 >> iter 36000, loss: 0.245705
 >> iter 37000, loss: 0.096528
 >> iter 38000, loss: 0.040129
 >> iter 39000, loss: 0.045140
 >> iter 40000, loss: 0.049171
   Number of active neurons: 10
 >> iter 41000, loss: 0.046366
 >> iter 42000, loss: 0.023599
 >> iter 43000, loss: 0.011631
 >> iter 44000, loss: 0.007774
 >> iter 45000, loss: 0.061396
 >> iter 46000, loss: 0.038100
 >> iter 47000, loss: 0.027190
 >> iter 48000, loss: 0.012552
 >> iter 49000, loss: 0.006747
 >> iter 50000, loss: 0.032570
   Number of active neurons: 10
 >> iter 51000, loss: 0.014792
 >> iter 52000, loss: 0.007998
 >> iter 53000, loss: 0.005655
 >> iter 54000, loss: 0.005817
 >> iter 55000, loss: 0.025468
 >> iter 56000, loss: 0.012140
 >> iter 57000, loss: 0.006057
 >> iter 58000, loss: 0.005247
 >> iter 59000, loss: 0.004035
 >> iter 60000, loss: 0.033550
   Number of active neurons: 10
 >> iter 61000, loss: 0.014159
 >> iter 62000, loss: 0.006912
 >> iter 63000, loss: 0.004213
 >> iter 64000, loss: 0.003034
 >> iter 65000, loss: 0.002562
 >> iter 66000, loss: 0.018588
 >> iter 67000, loss: 0.084722
 >> iter 68000, loss: 0.033397
 >> iter 69000, loss: 0.015443
 >> iter 70000, loss: 0.011380
   Number of active neurons: 10
 >> iter 71000, loss: 0.005493
 >> iter 72000, loss: 0.003233
 >> iter 73000, loss: 0.002615
 >> iter 74000, loss: 0.003788
 >> iter 75000, loss: 0.005714
 >> iter 76000, loss: 0.003313
 >> iter 77000, loss: 0.025622
 >> iter 78000, loss: 0.012248
 >> iter 79000, loss: 0.006332
 >> iter 80000, loss: 0.035788
   Number of active neurons: 10
 >> iter 81000, loss: 0.037038
 >> iter 82000, loss: 0.047651
 >> iter 83000, loss: 0.029556
 >> iter 84000, loss: 0.012534
 >> iter 85000, loss: 0.005776
 >> iter 86000, loss: 0.040202
 >> iter 87000, loss: 0.016644
 >> iter 88000, loss: 0.007933
 >> iter 89000, loss: 0.004030
 >> iter 90000, loss: 0.004064
   Number of active neurons: 10
 >> iter 91000, loss: 0.002632
 >> iter 92000, loss: 0.002241
 >> iter 93000, loss: 0.002243
 >> iter 94000, loss: 0.002038
 >> iter 95000, loss: 0.001665
 >> iter 96000, loss: 0.004961
 >> iter 97000, loss: 0.003406
 >> iter 98000, loss: 0.019799
 >> iter 99000, loss: 0.051966
 >> iter 100000, loss: 0.034830
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.176495
 >> iter 2000, loss: 13.475783
 >> iter 3000, loss: 7.997861
 >> iter 4000, loss: 4.174659
 >> iter 5000, loss: 2.203486
 >> iter 6000, loss: 1.222451
 >> iter 7000, loss: 0.876727
 >> iter 8000, loss: 0.561063
 >> iter 9000, loss: 0.369421
 >> iter 10000, loss: 0.335114
   Number of active neurons: 10
 >> iter 11000, loss: 0.341211
 >> iter 12000, loss: 0.333403
 >> iter 13000, loss: 0.394615
 >> iter 14000, loss: 0.245108
 >> iter 15000, loss: 0.206419
 >> iter 16000, loss: 0.175727
 >> iter 17000, loss: 0.166355
 >> iter 18000, loss: 0.110089
 >> iter 19000, loss: 0.112292
 >> iter 20000, loss: 0.106799
   Number of active neurons: 10
 >> iter 21000, loss: 0.142311
 >> iter 22000, loss: 0.130683
 >> iter 23000, loss: 0.166854
 >> iter 24000, loss: 0.084369
 >> iter 25000, loss: 0.096602
 >> iter 26000, loss: 0.071380
 >> iter 27000, loss: 0.081786
 >> iter 28000, loss: 0.102326
 >> iter 29000, loss: 0.050867
 >> iter 30000, loss: 0.029517
   Number of active neurons: 10
 >> iter 31000, loss: 0.108172
 >> iter 32000, loss: 0.120735
 >> iter 33000, loss: 0.135383
 >> iter 34000, loss: 0.071917
 >> iter 35000, loss: 0.032468
 >> iter 36000, loss: 0.026107
 >> iter 37000, loss: 0.073616
 >> iter 38000, loss: 0.051574
 >> iter 39000, loss: 0.030109
 >> iter 40000, loss: 0.016100
   Number of active neurons: 10
 >> iter 41000, loss: 0.010866
 >> iter 42000, loss: 0.008099
 >> iter 43000, loss: 0.006502
 >> iter 44000, loss: 0.076210
 >> iter 45000, loss: 0.138294
 >> iter 46000, loss: 0.075283
 >> iter 47000, loss: 0.053786
 >> iter 48000, loss: 0.050553
 >> iter 49000, loss: 0.023329
 >> iter 50000, loss: 0.024278
   Number of active neurons: 10
 >> iter 51000, loss: 0.054982
 >> iter 52000, loss: 0.054116
 >> iter 53000, loss: 0.029570
 >> iter 54000, loss: 0.022280
 >> iter 55000, loss: 0.019000
 >> iter 56000, loss: 0.047888
 >> iter 57000, loss: 0.106400
 >> iter 58000, loss: 0.052057
 >> iter 59000, loss: 0.032303
 >> iter 60000, loss: 0.037175
   Number of active neurons: 10
 >> iter 61000, loss: 0.175686
 >> iter 62000, loss: 0.077159
 >> iter 63000, loss: 0.035108
 >> iter 64000, loss: 0.019012
 >> iter 65000, loss: 0.016630
 >> iter 66000, loss: 0.087074
 >> iter 67000, loss: 0.064670
 >> iter 68000, loss: 0.050448
 >> iter 69000, loss: 0.106435
 >> iter 70000, loss: 0.122871
   Number of active neurons: 10
 >> iter 71000, loss: 0.054334
 >> iter 72000, loss: 0.045933
 >> iter 73000, loss: 0.020659
 >> iter 74000, loss: 0.041454
 >> iter 75000, loss: 0.081406
 >> iter 76000, loss: 0.038047
 >> iter 77000, loss: 0.017146
 >> iter 78000, loss: 0.051560
 >> iter 79000, loss: 0.025521
 >> iter 80000, loss: 0.012413
   Number of active neurons: 10
 >> iter 81000, loss: 0.049075
 >> iter 82000, loss: 0.032836
 >> iter 83000, loss: 0.014957
 >> iter 84000, loss: 0.007991
 >> iter 85000, loss: 0.058986
 >> iter 86000, loss: 0.024223
 >> iter 87000, loss: 0.011613
 >> iter 88000, loss: 0.007565
 >> iter 89000, loss: 0.010216
 >> iter 90000, loss: 0.006078
   Number of active neurons: 10
 >> iter 91000, loss: 0.015027
 >> iter 92000, loss: 0.009970
 >> iter 93000, loss: 0.006202
 >> iter 94000, loss: 0.064876
 >> iter 95000, loss: 0.026793
 >> iter 96000, loss: 0.012001
 >> iter 97000, loss: 0.016148
 >> iter 98000, loss: 0.011468
 >> iter 99000, loss: 0.066478
 >> iter 100000, loss: 0.026288
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 19.252767
 >> iter 2000, loss: 13.540456
 >> iter 3000, loss: 7.680580
 >> iter 4000, loss: 3.903342
 >> iter 5000, loss: 2.059121
 >> iter 6000, loss: 1.150945
 >> iter 7000, loss: 0.664070
 >> iter 8000, loss: 0.431613
 >> iter 9000, loss: 0.542378
 >> iter 10000, loss: 0.383505
   Number of active neurons: 10
 >> iter 11000, loss: 0.192313
 >> iter 12000, loss: 0.305909
 >> iter 13000, loss: 0.339817
 >> iter 14000, loss: 0.213915
 >> iter 15000, loss: 0.122250
 >> iter 16000, loss: 0.166350
 >> iter 17000, loss: 0.077407
 >> iter 18000, loss: 0.045849
 >> iter 19000, loss: 0.074824
 >> iter 20000, loss: 0.081993
   Number of active neurons: 10
 >> iter 21000, loss: 0.128489
 >> iter 22000, loss: 0.240236
 >> iter 23000, loss: 0.115992
 >> iter 24000, loss: 0.054270
 >> iter 25000, loss: 0.029584
 >> iter 26000, loss: 0.025327
 >> iter 27000, loss: 0.034718
 >> iter 28000, loss: 0.109334
 >> iter 29000, loss: 0.101142
 >> iter 30000, loss: 0.046202
   Number of active neurons: 10
 >> iter 31000, loss: 0.023839
 >> iter 32000, loss: 0.030479
 >> iter 33000, loss: 0.025287
 >> iter 34000, loss: 0.030724
 >> iter 35000, loss: 0.084896
 >> iter 36000, loss: 0.041539
 >> iter 37000, loss: 0.022889
 >> iter 38000, loss: 0.014624
 >> iter 39000, loss: 0.024542
 >> iter 40000, loss: 0.017477
   Number of active neurons: 10
 >> iter 41000, loss: 0.011091
 >> iter 42000, loss: 0.010547
 >> iter 43000, loss: 0.135393
 >> iter 44000, loss: 0.054025
 >> iter 45000, loss: 0.128928
 >> iter 46000, loss: 0.052711
 >> iter 47000, loss: 0.024023
 >> iter 48000, loss: 0.012930
 >> iter 49000, loss: 0.041300
 >> iter 50000, loss: 0.019203
   Number of active neurons: 10
 >> iter 51000, loss: 0.013517
 >> iter 52000, loss: 0.010764
 >> iter 53000, loss: 0.007393
 >> iter 54000, loss: 0.014539
 >> iter 55000, loss: 0.095854
 >> iter 56000, loss: 0.091350
 >> iter 57000, loss: 0.046537
 >> iter 58000, loss: 0.033537
 >> iter 59000, loss: 0.053297
 >> iter 60000, loss: 0.185531
   Number of active neurons: 10
 >> iter 61000, loss: 0.074173
 >> iter 62000, loss: 0.130883
 >> iter 63000, loss: 0.067375
 >> iter 64000, loss: 0.144822
 >> iter 65000, loss: 0.082922
 >> iter 66000, loss: 0.035348
 >> iter 67000, loss: 0.016537
 >> iter 68000, loss: 0.021751
 >> iter 69000, loss: 0.014863
 >> iter 70000, loss: 0.008975
   Number of active neurons: 10
 >> iter 71000, loss: 0.036970
 >> iter 72000, loss: 0.019252
 >> iter 73000, loss: 0.010522
 >> iter 74000, loss: 0.008590
 >> iter 75000, loss: 0.010067
 >> iter 76000, loss: 0.006770
 >> iter 77000, loss: 0.048863
 >> iter 78000, loss: 0.021098
 >> iter 79000, loss: 0.010599
 >> iter 80000, loss: 0.057236
   Number of active neurons: 10
 >> iter 81000, loss: 0.173185
 >> iter 82000, loss: 0.212975
 >> iter 83000, loss: 0.084521
 >> iter 84000, loss: 0.150942
 >> iter 85000, loss: 0.061460
 >> iter 86000, loss: 0.026852
 >> iter 87000, loss: 0.012893
 >> iter 88000, loss: 0.007694
 >> iter 89000, loss: 0.005607
 >> iter 90000, loss: 0.004600
   Number of active neurons: 10
 >> iter 91000, loss: 0.004192
 >> iter 92000, loss: 0.005011
 >> iter 93000, loss: 0.037520
 >> iter 94000, loss: 0.045585
 >> iter 95000, loss: 0.019225
 >> iter 96000, loss: 0.036865
 >> iter 97000, loss: 0.016398
 >> iter 98000, loss: 0.008533
 >> iter 99000, loss: 0.008596
 >> iter 100000, loss: 0.151890
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.241172
 >> iter 2000, loss: 12.634323
 >> iter 3000, loss: 6.536442
 >> iter 4000, loss: 3.021296
 >> iter 5000, loss: 1.632332
 >> iter 6000, loss: 0.948274
 >> iter 7000, loss: 0.696706
 >> iter 8000, loss: 0.472724
 >> iter 9000, loss: 0.595988
 >> iter 10000, loss: 0.266866
   Number of active neurons: 10
 >> iter 11000, loss: 0.207225
 >> iter 12000, loss: 0.170542
 >> iter 13000, loss: 0.076864
 >> iter 14000, loss: 0.040061
 >> iter 15000, loss: 0.099649
 >> iter 16000, loss: 0.051409
 >> iter 17000, loss: 0.082321
 >> iter 18000, loss: 0.086254
 >> iter 19000, loss: 0.080339
 >> iter 20000, loss: 0.079013
   Number of active neurons: 10
 >> iter 21000, loss: 0.049465
 >> iter 22000, loss: 0.061602
 >> iter 23000, loss: 0.111857
 >> iter 24000, loss: 0.084079
 >> iter 25000, loss: 0.063305
 >> iter 26000, loss: 0.080281
 >> iter 27000, loss: 0.068055
 >> iter 28000, loss: 0.281072
 >> iter 29000, loss: 0.203554
 >> iter 30000, loss: 0.105779
   Number of active neurons: 10
 >> iter 31000, loss: 0.049511
 >> iter 32000, loss: 0.046123
 >> iter 33000, loss: 0.057874
 >> iter 34000, loss: 0.116119
 >> iter 35000, loss: 0.049598
 >> iter 36000, loss: 0.109753
 >> iter 37000, loss: 0.052831
 >> iter 38000, loss: 0.024754
 >> iter 39000, loss: 0.012633
 >> iter 40000, loss: 0.009191
   Number of active neurons: 10
 >> iter 41000, loss: 0.111585
 >> iter 42000, loss: 0.047818
 >> iter 43000, loss: 0.025804
 >> iter 44000, loss: 0.014065
 >> iter 45000, loss: 0.007872
 >> iter 46000, loss: 0.005130
 >> iter 47000, loss: 0.004407
 >> iter 48000, loss: 0.008040
 >> iter 49000, loss: 0.024728
 >> iter 50000, loss: 0.011212
   Number of active neurons: 10
 >> iter 51000, loss: 0.042194
 >> iter 52000, loss: 0.076491
 >> iter 53000, loss: 0.135861
 >> iter 54000, loss: 0.069876
 >> iter 55000, loss: 0.031396
 >> iter 56000, loss: 0.013951
 >> iter 57000, loss: 0.007303
 >> iter 58000, loss: 0.005679
 >> iter 59000, loss: 0.004422
 >> iter 60000, loss: 0.004154
   Number of active neurons: 10
 >> iter 61000, loss: 0.019781
 >> iter 62000, loss: 0.022038
 >> iter 63000, loss: 0.009864
 >> iter 64000, loss: 0.030062
 >> iter 65000, loss: 0.053953
 >> iter 66000, loss: 0.022071
 >> iter 67000, loss: 0.009855
 >> iter 68000, loss: 0.017629
 >> iter 69000, loss: 0.008470
 >> iter 70000, loss: 0.009043
   Number of active neurons: 10
 >> iter 71000, loss: 0.005275
 >> iter 72000, loss: 0.016929
 >> iter 73000, loss: 0.010207
 >> iter 74000, loss: 0.005622
 >> iter 75000, loss: 0.004208
 >> iter 76000, loss: 0.003408
 >> iter 77000, loss: 0.002429
 >> iter 78000, loss: 0.002546
 >> iter 79000, loss: 0.002071
 >> iter 80000, loss: 0.005523
   Number of active neurons: 10
 >> iter 81000, loss: 0.002984
 >> iter 82000, loss: 0.011256
 >> iter 83000, loss: 0.025646
 >> iter 84000, loss: 0.010578
 >> iter 85000, loss: 0.006579
 >> iter 86000, loss: 0.016827
 >> iter 87000, loss: 0.007213
 >> iter 88000, loss: 0.005230
 >> iter 89000, loss: 0.149188
 >> iter 90000, loss: 0.057271
   Number of active neurons: 10
 >> iter 91000, loss: 0.022419
 >> iter 92000, loss: 0.009561
 >> iter 93000, loss: 0.009955
 >> iter 94000, loss: 0.004775
 >> iter 95000, loss: 0.094201
 >> iter 96000, loss: 0.044918
 >> iter 97000, loss: 0.017876
 >> iter 98000, loss: 0.007798
 >> iter 99000, loss: 0.008178
 >> iter 100000, loss: 0.005992
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 19.276750
 >> iter 2000, loss: 12.938680
 >> iter 3000, loss: 6.665754
 >> iter 4000, loss: 2.990977
 >> iter 5000, loss: 1.405394
 >> iter 6000, loss: 0.993042
 >> iter 7000, loss: 0.575218
 >> iter 8000, loss: 0.497450
 >> iter 9000, loss: 0.374110
 >> iter 10000, loss: 0.196878
   Number of active neurons: 10
 >> iter 11000, loss: 0.137440
 >> iter 12000, loss: 0.103443
 >> iter 13000, loss: 0.155478
 >> iter 14000, loss: 0.083853
 >> iter 15000, loss: 0.064871
 >> iter 16000, loss: 0.037378
 >> iter 17000, loss: 0.143103
 >> iter 18000, loss: 0.061023
 >> iter 19000, loss: 0.108355
 >> iter 20000, loss: 0.158849
   Number of active neurons: 10
 >> iter 21000, loss: 0.078209
 >> iter 22000, loss: 0.044121
 >> iter 23000, loss: 0.072006
 >> iter 24000, loss: 0.040724
 >> iter 25000, loss: 0.020113
 >> iter 26000, loss: 0.012551
 >> iter 27000, loss: 0.030479
 >> iter 28000, loss: 0.072720
 >> iter 29000, loss: 0.178002
 >> iter 30000, loss: 0.073039
   Number of active neurons: 10
 >> iter 31000, loss: 0.045459
 >> iter 32000, loss: 0.021468
 >> iter 33000, loss: 0.182518
 >> iter 34000, loss: 0.078850
 >> iter 35000, loss: 0.034436
 >> iter 36000, loss: 0.016995
 >> iter 37000, loss: 0.012278
 >> iter 38000, loss: 0.008052
 >> iter 39000, loss: 0.091777
 >> iter 40000, loss: 0.037931
   Number of active neurons: 10
 >> iter 41000, loss: 0.017834
 >> iter 42000, loss: 0.010140
 >> iter 43000, loss: 0.006451
 >> iter 44000, loss: 0.005321
 >> iter 45000, loss: 0.093887
 >> iter 46000, loss: 0.038071
 >> iter 47000, loss: 0.083318
 >> iter 48000, loss: 0.033955
 >> iter 49000, loss: 0.036469
 >> iter 50000, loss: 0.016573
   Number of active neurons: 10
 >> iter 51000, loss: 0.041639
 >> iter 52000, loss: 0.021537
 >> iter 53000, loss: 0.011346
 >> iter 54000, loss: 0.006772
 >> iter 55000, loss: 0.017569
 >> iter 56000, loss: 0.012196
 >> iter 57000, loss: 0.019608
 >> iter 58000, loss: 0.009866
 >> iter 59000, loss: 0.017276
 >> iter 60000, loss: 0.009491
   Number of active neurons: 10
 >> iter 61000, loss: 0.005749
 >> iter 62000, loss: 0.004047
 >> iter 63000, loss: 0.021755
 >> iter 64000, loss: 0.009666
 >> iter 65000, loss: 0.011117
 >> iter 66000, loss: 0.010583
 >> iter 67000, loss: 0.007682
 >> iter 68000, loss: 0.004816
 >> iter 69000, loss: 0.029082
 >> iter 70000, loss: 0.014322
   Number of active neurons: 10
 >> iter 71000, loss: 0.026539
 >> iter 72000, loss: 0.011325
 >> iter 73000, loss: 0.048194
 >> iter 74000, loss: 0.036048
 >> iter 75000, loss: 0.040824
 >> iter 76000, loss: 0.016986
 >> iter 77000, loss: 0.017470
 >> iter 78000, loss: 0.008008
 >> iter 79000, loss: 0.070538
 >> iter 80000, loss: 0.048561
   Number of active neurons: 10
 >> iter 81000, loss: 0.024010
 >> iter 82000, loss: 0.012074
 >> iter 83000, loss: 0.006462
 >> iter 84000, loss: 0.004549
 >> iter 85000, loss: 0.007244
 >> iter 86000, loss: 0.004489
 >> iter 87000, loss: 0.003250
 >> iter 88000, loss: 0.005776
 >> iter 89000, loss: 0.003927
 >> iter 90000, loss: 0.013668
   Number of active neurons: 10
 >> iter 91000, loss: 0.006628
 >> iter 92000, loss: 0.004703
 >> iter 93000, loss: 0.003143
 >> iter 94000, loss: 0.005915
 >> iter 95000, loss: 0.004640
 >> iter 96000, loss: 0.002863
 >> iter 97000, loss: 0.002187
 >> iter 98000, loss: 0.002209
 >> iter 99000, loss: 0.003139
 >> iter 100000, loss: 0.002217
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.275835
 >> iter 2000, loss: 13.368913
 >> iter 3000, loss: 7.015786
 >> iter 4000, loss: 3.329600
 >> iter 5000, loss: 1.524854
 >> iter 6000, loss: 0.895102
 >> iter 7000, loss: 0.730662
 >> iter 8000, loss: 0.419199
 >> iter 9000, loss: 0.190202
 >> iter 10000, loss: 0.111932
   Number of active neurons: 10
 >> iter 11000, loss: 0.165145
 >> iter 12000, loss: 0.210999
 >> iter 13000, loss: 0.118415
 >> iter 14000, loss: 0.199786
 >> iter 15000, loss: 0.151763
 >> iter 16000, loss: 0.143056
 >> iter 17000, loss: 0.147739
 >> iter 18000, loss: 0.088039
 >> iter 19000, loss: 0.329803
 >> iter 20000, loss: 0.198418
   Number of active neurons: 10
 >> iter 21000, loss: 0.152529
 >> iter 22000, loss: 0.100190
 >> iter 23000, loss: 0.087707
 >> iter 24000, loss: 0.050767
 >> iter 25000, loss: 0.046513
 >> iter 26000, loss: 0.107140
 >> iter 27000, loss: 0.047131
 >> iter 28000, loss: 0.077490
 >> iter 29000, loss: 0.164125
 >> iter 30000, loss: 0.117426
   Number of active neurons: 10
 >> iter 31000, loss: 0.112046
 >> iter 32000, loss: 0.113473
 >> iter 33000, loss: 0.061814
 >> iter 34000, loss: 0.116216
 >> iter 35000, loss: 0.056323
 >> iter 36000, loss: 0.025489
 >> iter 37000, loss: 0.014363
 >> iter 38000, loss: 0.011202
 >> iter 39000, loss: 0.027544
 >> iter 40000, loss: 0.075324
   Number of active neurons: 10
 >> iter 41000, loss: 0.032439
 >> iter 42000, loss: 0.018322
 >> iter 43000, loss: 0.012083
 >> iter 44000, loss: 0.042716
 >> iter 45000, loss: 0.109113
 >> iter 46000, loss: 0.113273
 >> iter 47000, loss: 0.063492
 >> iter 48000, loss: 0.063176
 >> iter 49000, loss: 0.067819
 >> iter 50000, loss: 0.029979
   Number of active neurons: 10
 >> iter 51000, loss: 0.023133
 >> iter 52000, loss: 0.011943
 >> iter 53000, loss: 0.078816
 >> iter 54000, loss: 0.032871
 >> iter 55000, loss: 0.020135
 >> iter 56000, loss: 0.019563
 >> iter 57000, loss: 0.041228
 >> iter 58000, loss: 0.065675
 >> iter 59000, loss: 0.033454
 >> iter 60000, loss: 0.015852
   Number of active neurons: 10
 >> iter 61000, loss: 0.041584
 >> iter 62000, loss: 0.089217
 >> iter 63000, loss: 0.059292
 >> iter 64000, loss: 0.025077
 >> iter 65000, loss: 0.036741
 >> iter 66000, loss: 0.016635
 >> iter 67000, loss: 0.036942
 >> iter 68000, loss: 0.033093
 >> iter 69000, loss: 0.062617
 >> iter 70000, loss: 0.026055
   Number of active neurons: 10
 >> iter 71000, loss: 0.016845
 >> iter 72000, loss: 0.017565
 >> iter 73000, loss: 0.016535
 >> iter 74000, loss: 0.008406
 >> iter 75000, loss: 0.015738
 >> iter 76000, loss: 0.008559
 >> iter 77000, loss: 0.005893
 >> iter 78000, loss: 0.004104
 >> iter 79000, loss: 0.003916
 >> iter 80000, loss: 0.003237
   Number of active neurons: 10
 >> iter 81000, loss: 0.003332
 >> iter 82000, loss: 0.007286
 >> iter 83000, loss: 0.008489
 >> iter 84000, loss: 0.065934
 >> iter 85000, loss: 0.050734
 >> iter 86000, loss: 0.020957
 >> iter 87000, loss: 0.012880
 >> iter 88000, loss: 0.008574
 >> iter 89000, loss: 0.004972
 >> iter 90000, loss: 0.003296
   Number of active neurons: 10
 >> iter 91000, loss: 0.003271
 >> iter 92000, loss: 0.004585
 >> iter 93000, loss: 0.003072
 >> iter 94000, loss: 0.002480
 >> iter 95000, loss: 0.002537
 >> iter 96000, loss: 0.009471
 >> iter 97000, loss: 0.004774
 >> iter 98000, loss: 0.066478
 >> iter 99000, loss: 0.052771
 >> iter 100000, loss: 0.022079
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.161722
 >> iter 2000, loss: 12.157789
 >> iter 3000, loss: 6.007304
 >> iter 4000, loss: 2.708724
 >> iter 5000, loss: 1.479667
 >> iter 6000, loss: 0.766526
 >> iter 7000, loss: 0.466969
 >> iter 8000, loss: 0.277008
 >> iter 9000, loss: 0.212893
 >> iter 10000, loss: 0.105020
   Number of active neurons: 10
 >> iter 11000, loss: 0.052004
 >> iter 12000, loss: 0.037213
 >> iter 13000, loss: 0.057621
 >> iter 14000, loss: 0.113484
 >> iter 15000, loss: 0.109326
 >> iter 16000, loss: 0.310077
 >> iter 17000, loss: 0.126203
 >> iter 18000, loss: 0.120125
 >> iter 19000, loss: 0.139769
 >> iter 20000, loss: 0.111339
   Number of active neurons: 10
 >> iter 21000, loss: 0.244649
 >> iter 22000, loss: 0.114675
 >> iter 23000, loss: 0.191860
 >> iter 24000, loss: 0.176032
 >> iter 25000, loss: 0.132496
 >> iter 26000, loss: 0.064050
 >> iter 27000, loss: 0.054227
 >> iter 28000, loss: 0.026352
 >> iter 29000, loss: 0.016509
 >> iter 30000, loss: 0.016774
   Number of active neurons: 10
 >> iter 31000, loss: 0.082545
 >> iter 32000, loss: 0.046469
 >> iter 33000, loss: 0.039044
 >> iter 34000, loss: 0.018598
 >> iter 35000, loss: 0.013034
 >> iter 36000, loss: 0.013352
 >> iter 37000, loss: 0.042643
 >> iter 38000, loss: 0.050967
 >> iter 39000, loss: 0.024865
 >> iter 40000, loss: 0.012402
   Number of active neurons: 10
 >> iter 41000, loss: 0.017118
 >> iter 42000, loss: 0.012903
 >> iter 43000, loss: 0.006918
 >> iter 44000, loss: 0.004798
 >> iter 45000, loss: 0.015594
 >> iter 46000, loss: 0.018878
 >> iter 47000, loss: 0.009536
 >> iter 48000, loss: 0.005478
 >> iter 49000, loss: 0.013285
 >> iter 50000, loss: 0.006818
   Number of active neurons: 10
 >> iter 51000, loss: 0.005391
 >> iter 52000, loss: 0.004654
 >> iter 53000, loss: 0.085198
 >> iter 54000, loss: 0.037330
 >> iter 55000, loss: 0.016085
 >> iter 56000, loss: 0.028522
 >> iter 57000, loss: 0.018867
 >> iter 58000, loss: 0.023421
 >> iter 59000, loss: 0.011785
 >> iter 60000, loss: 0.005988
   Number of active neurons: 10
 >> iter 61000, loss: 0.004061
 >> iter 62000, loss: 0.003435
 >> iter 63000, loss: 0.112150
 >> iter 64000, loss: 0.046537
 >> iter 65000, loss: 0.019283
 >> iter 66000, loss: 0.009948
 >> iter 67000, loss: 0.005254
 >> iter 68000, loss: 0.010572
 >> iter 69000, loss: 0.011319
 >> iter 70000, loss: 0.005673
   Number of active neurons: 10
 >> iter 71000, loss: 0.003282
 >> iter 72000, loss: 0.002420
 >> iter 73000, loss: 0.016734
 >> iter 74000, loss: 0.007950
 >> iter 75000, loss: 0.005330
 >> iter 76000, loss: 0.003192
 >> iter 77000, loss: 0.003533
 >> iter 78000, loss: 0.031424
 >> iter 79000, loss: 0.013355
 >> iter 80000, loss: 0.073872
   Number of active neurons: 10
 >> iter 81000, loss: 0.028908
 >> iter 82000, loss: 0.056579
 >> iter 83000, loss: 0.023343
 >> iter 84000, loss: 0.012832
 >> iter 85000, loss: 0.017722
 >> iter 86000, loss: 0.008286
 >> iter 87000, loss: 0.009166
 >> iter 88000, loss: 0.004815
 >> iter 89000, loss: 0.003007
 >> iter 90000, loss: 0.003809
   Number of active neurons: 10
 >> iter 91000, loss: 0.010024
 >> iter 92000, loss: 0.004973
 >> iter 93000, loss: 0.002888
 >> iter 94000, loss: 0.002377
 >> iter 95000, loss: 0.016221
 >> iter 96000, loss: 0.087919
 >> iter 97000, loss: 0.078034
 >> iter 98000, loss: 0.031266
 >> iter 99000, loss: 0.012989
 >> iter 100000, loss: 0.006251
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.072600
 >> iter 2000, loss: 13.494648
 >> iter 3000, loss: 7.611145
 >> iter 4000, loss: 3.658957
 >> iter 5000, loss: 1.705078
 >> iter 6000, loss: 1.008923
 >> iter 7000, loss: 0.751287
 >> iter 8000, loss: 0.541595
 >> iter 9000, loss: 0.389691
 >> iter 10000, loss: 0.209802
   Number of active neurons: 10
 >> iter 11000, loss: 0.153177
 >> iter 12000, loss: 0.101357
 >> iter 13000, loss: 0.157985
 >> iter 14000, loss: 0.193898
 >> iter 15000, loss: 0.089921
 >> iter 16000, loss: 0.155886
 >> iter 17000, loss: 0.133817
 >> iter 18000, loss: 0.169945
 >> iter 19000, loss: 0.098010
 >> iter 20000, loss: 0.048915
   Number of active neurons: 10
 >> iter 21000, loss: 0.192622
 >> iter 22000, loss: 0.104827
 >> iter 23000, loss: 0.213526
 >> iter 24000, loss: 0.242894
 >> iter 25000, loss: 0.099717
 >> iter 26000, loss: 0.086004
 >> iter 27000, loss: 0.038620
 >> iter 28000, loss: 0.077782
 >> iter 29000, loss: 0.048659
 >> iter 30000, loss: 0.023186
   Number of active neurons: 10
 >> iter 31000, loss: 0.013626
 >> iter 32000, loss: 0.009718
 >> iter 33000, loss: 0.030469
 >> iter 34000, loss: 0.018079
 >> iter 35000, loss: 0.135567
 >> iter 36000, loss: 0.119870
 >> iter 37000, loss: 0.048518
 >> iter 38000, loss: 0.037482
 >> iter 39000, loss: 0.018745
 >> iter 40000, loss: 0.016032
   Number of active neurons: 10
 >> iter 41000, loss: 0.088753
 >> iter 42000, loss: 0.101276
 >> iter 43000, loss: 0.149432
 >> iter 44000, loss: 0.104152
 >> iter 45000, loss: 0.047679
 >> iter 46000, loss: 0.021374
 >> iter 47000, loss: 0.071028
 >> iter 48000, loss: 0.030659
 >> iter 49000, loss: 0.029166
 >> iter 50000, loss: 0.013456
   Number of active neurons: 10
 >> iter 51000, loss: 0.009112
 >> iter 52000, loss: 0.042608
 >> iter 53000, loss: 0.139060
 >> iter 54000, loss: 0.122837
 >> iter 55000, loss: 0.060321
 >> iter 56000, loss: 0.025945
 >> iter 57000, loss: 0.038799
 >> iter 58000, loss: 0.017690
 >> iter 59000, loss: 0.010602
 >> iter 60000, loss: 0.029179
   Number of active neurons: 10
 >> iter 61000, loss: 0.012989
 >> iter 62000, loss: 0.014022
 >> iter 63000, loss: 0.021065
 >> iter 64000, loss: 0.010409
 >> iter 65000, loss: 0.006345
 >> iter 66000, loss: 0.009905
 >> iter 67000, loss: 0.005615
 >> iter 68000, loss: 0.006253
 >> iter 69000, loss: 0.007644
 >> iter 70000, loss: 0.004702
   Number of active neurons: 10
 >> iter 71000, loss: 0.004101
 >> iter 72000, loss: 0.009522
 >> iter 73000, loss: 0.005762
 >> iter 74000, loss: 0.038980
 >> iter 75000, loss: 0.017414
 >> iter 76000, loss: 0.009231
 >> iter 77000, loss: 0.006995
 >> iter 78000, loss: 0.005452
 >> iter 79000, loss: 0.003476
 >> iter 80000, loss: 0.002647
   Number of active neurons: 10
 >> iter 81000, loss: 0.020495
 >> iter 82000, loss: 0.009010
 >> iter 83000, loss: 0.004517
 >> iter 84000, loss: 0.013170
 >> iter 85000, loss: 0.006345
 >> iter 86000, loss: 0.010187
 >> iter 87000, loss: 0.005635
 >> iter 88000, loss: 0.005689
 >> iter 89000, loss: 0.021344
 >> iter 90000, loss: 0.009484
   Number of active neurons: 10
 >> iter 91000, loss: 0.040541
 >> iter 92000, loss: 0.016893
 >> iter 93000, loss: 0.007623
 >> iter 94000, loss: 0.009563
 >> iter 95000, loss: 0.004590
 >> iter 96000, loss: 0.004773
 >> iter 97000, loss: 0.058421
 >> iter 98000, loss: 0.022716
 >> iter 99000, loss: 0.009459
 >> iter 100000, loss: 0.004664
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.240685
 >> iter 2000, loss: 13.398862
 >> iter 3000, loss: 7.236399
 >> iter 4000, loss: 3.570625
 >> iter 5000, loss: 1.934865
 >> iter 6000, loss: 1.037241
 >> iter 7000, loss: 0.612035
 >> iter 8000, loss: 0.393238
 >> iter 9000, loss: 0.452553
 >> iter 10000, loss: 0.355259
   Number of active neurons: 10
 >> iter 11000, loss: 0.310990
 >> iter 12000, loss: 0.218391
 >> iter 13000, loss: 0.178596
 >> iter 14000, loss: 0.190540
 >> iter 15000, loss: 0.123156
 >> iter 16000, loss: 0.095038
 >> iter 17000, loss: 0.080183
 >> iter 18000, loss: 0.046664
 >> iter 19000, loss: 0.062926
 >> iter 20000, loss: 0.037647
   Number of active neurons: 10
 >> iter 21000, loss: 0.020286
 >> iter 22000, loss: 0.053350
 >> iter 23000, loss: 0.336045
 >> iter 24000, loss: 0.316586
 >> iter 25000, loss: 0.278092
 >> iter 26000, loss: 0.153636
 >> iter 27000, loss: 0.074468
 >> iter 28000, loss: 0.115269
 >> iter 29000, loss: 0.138607
 >> iter 30000, loss: 0.198299
   Number of active neurons: 10
 >> iter 31000, loss: 0.140834
 >> iter 32000, loss: 0.066708
 >> iter 33000, loss: 0.045052
 >> iter 34000, loss: 0.113261
 >> iter 35000, loss: 0.047918
 >> iter 36000, loss: 0.025702
 >> iter 37000, loss: 0.014937
 >> iter 38000, loss: 0.020141
 >> iter 39000, loss: 0.043839
 >> iter 40000, loss: 0.034656
   Number of active neurons: 10
 >> iter 41000, loss: 0.023132
 >> iter 42000, loss: 0.012324
 >> iter 43000, loss: 0.037691
 >> iter 44000, loss: 0.040491
 >> iter 45000, loss: 0.024674
 >> iter 46000, loss: 0.012640
 >> iter 47000, loss: 0.008976
 >> iter 48000, loss: 0.009461
 >> iter 49000, loss: 0.006913
 >> iter 50000, loss: 0.007008
   Number of active neurons: 10
 >> iter 51000, loss: 0.099735
 >> iter 52000, loss: 0.043336
 >> iter 53000, loss: 0.067009
 >> iter 54000, loss: 0.027136
 >> iter 55000, loss: 0.012692
 >> iter 56000, loss: 0.028057
 >> iter 57000, loss: 0.017313
 >> iter 58000, loss: 0.010173
 >> iter 59000, loss: 0.018966
 >> iter 60000, loss: 0.034696
   Number of active neurons: 10
 >> iter 61000, loss: 0.016911
 >> iter 62000, loss: 0.009320
 >> iter 63000, loss: 0.005940
 >> iter 64000, loss: 0.004764
 >> iter 65000, loss: 0.003301
 >> iter 66000, loss: 0.002879
 >> iter 67000, loss: 0.015158
 >> iter 68000, loss: 0.119916
 >> iter 69000, loss: 0.049718
 >> iter 70000, loss: 0.076321
   Number of active neurons: 10
 >> iter 71000, loss: 0.030705
 >> iter 72000, loss: 0.076916
 >> iter 73000, loss: 0.091817
 >> iter 74000, loss: 0.036504
 >> iter 75000, loss: 0.050248
 >> iter 76000, loss: 0.054694
 >> iter 77000, loss: 0.042801
 >> iter 78000, loss: 0.098358
 >> iter 79000, loss: 0.116031
 >> iter 80000, loss: 0.045693
   Number of active neurons: 10
 >> iter 81000, loss: 0.019895
 >> iter 82000, loss: 0.010333
 >> iter 83000, loss: 0.006324
 >> iter 84000, loss: 0.008016
 >> iter 85000, loss: 0.006001
 >> iter 86000, loss: 0.027823
 >> iter 87000, loss: 0.020874
 >> iter 88000, loss: 0.130243
 >> iter 89000, loss: 0.051516
 >> iter 90000, loss: 0.063894
   Number of active neurons: 10
 >> iter 91000, loss: 0.026261
 >> iter 92000, loss: 0.011714
 >> iter 93000, loss: 0.006440
 >> iter 94000, loss: 0.004073
 >> iter 95000, loss: 0.036636
 >> iter 96000, loss: 0.016456
 >> iter 97000, loss: 0.035435
 >> iter 98000, loss: 0.058333
 >> iter 99000, loss: 0.024057
 >> iter 100000, loss: 0.010623
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.031650
 >> iter 2000, loss: 12.817859
 >> iter 3000, loss: 6.674485
 >> iter 4000, loss: 3.135593
 >> iter 5000, loss: 1.534463
 >> iter 6000, loss: 0.917243
 >> iter 7000, loss: 0.558596
 >> iter 8000, loss: 0.286878
 >> iter 9000, loss: 0.216244
 >> iter 10000, loss: 0.254893
   Number of active neurons: 10
 >> iter 11000, loss: 0.177218
 >> iter 12000, loss: 0.261063
 >> iter 13000, loss: 0.287485
 >> iter 14000, loss: 0.136207
 >> iter 15000, loss: 0.118242
 >> iter 16000, loss: 0.085396
 >> iter 17000, loss: 0.085909
 >> iter 18000, loss: 0.075653
 >> iter 19000, loss: 0.059642
 >> iter 20000, loss: 0.037487
   Number of active neurons: 10
 >> iter 21000, loss: 0.091056
 >> iter 22000, loss: 0.044651
 >> iter 23000, loss: 0.061407
 >> iter 24000, loss: 0.039486
 >> iter 25000, loss: 0.092321
 >> iter 26000, loss: 0.094019
 >> iter 27000, loss: 0.041478
 >> iter 28000, loss: 0.021980
 >> iter 29000, loss: 0.023538
 >> iter 30000, loss: 0.021499
   Number of active neurons: 10
 >> iter 31000, loss: 0.046489
 >> iter 32000, loss: 0.021491
 >> iter 33000, loss: 0.012943
 >> iter 34000, loss: 0.016954
 >> iter 35000, loss: 0.039427
 >> iter 36000, loss: 0.026599
 >> iter 37000, loss: 0.045057
 >> iter 38000, loss: 0.112024
 >> iter 39000, loss: 0.098820
 >> iter 40000, loss: 0.064698
   Number of active neurons: 10
 >> iter 41000, loss: 0.027593
 >> iter 42000, loss: 0.022618
 >> iter 43000, loss: 0.027991
 >> iter 44000, loss: 0.013787
 >> iter 45000, loss: 0.013752
 >> iter 46000, loss: 0.007681
 >> iter 47000, loss: 0.091864
 >> iter 48000, loss: 0.067728
 >> iter 49000, loss: 0.040879
 >> iter 50000, loss: 0.091876
   Number of active neurons: 10
 >> iter 51000, loss: 0.037719
 >> iter 52000, loss: 0.122822
 >> iter 53000, loss: 0.051186
 >> iter 54000, loss: 0.109964
 >> iter 55000, loss: 0.044376
 >> iter 56000, loss: 0.019820
 >> iter 57000, loss: 0.042827
 >> iter 58000, loss: 0.026722
 >> iter 59000, loss: 0.064455
 >> iter 60000, loss: 0.026718
   Number of active neurons: 10
 >> iter 61000, loss: 0.012475
 >> iter 62000, loss: 0.007593
 >> iter 63000, loss: 0.007119
 >> iter 64000, loss: 0.145461
 >> iter 65000, loss: 0.056493
 >> iter 66000, loss: 0.024162
 >> iter 67000, loss: 0.011660
 >> iter 68000, loss: 0.008762
 >> iter 69000, loss: 0.005596
 >> iter 70000, loss: 0.006334
   Number of active neurons: 10
 >> iter 71000, loss: 0.006403
 >> iter 72000, loss: 0.004383
 >> iter 73000, loss: 0.004387
 >> iter 74000, loss: 0.051550
 >> iter 75000, loss: 0.021005
 >> iter 76000, loss: 0.020614
 >> iter 77000, loss: 0.009797
 >> iter 78000, loss: 0.005652
 >> iter 79000, loss: 0.096098
 >> iter 80000, loss: 0.086608
   Number of active neurons: 10
 >> iter 81000, loss: 0.034526
 >> iter 82000, loss: 0.022894
 >> iter 83000, loss: 0.010699
 >> iter 84000, loss: 0.005838
 >> iter 85000, loss: 0.005561
 >> iter 86000, loss: 0.004629
 >> iter 87000, loss: 0.067875
 >> iter 88000, loss: 0.028112
 >> iter 89000, loss: 0.012302
 >> iter 90000, loss: 0.006973
   Number of active neurons: 10
 >> iter 91000, loss: 0.004159
 >> iter 92000, loss: 0.002895
 >> iter 93000, loss: 0.053321
 >> iter 94000, loss: 0.033839
 >> iter 95000, loss: 0.041013
 >> iter 96000, loss: 0.021864
 >> iter 97000, loss: 0.010093
 >> iter 98000, loss: 0.037376
 >> iter 99000, loss: 0.015700
 >> iter 100000, loss: 0.007515
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.113069
 >> iter 2000, loss: 13.152488
 >> iter 3000, loss: 8.224439
 >> iter 4000, loss: 4.226361
 >> iter 5000, loss: 2.423841
 >> iter 6000, loss: 1.443452
 >> iter 7000, loss: 1.061801
 >> iter 8000, loss: 0.528887
 >> iter 9000, loss: 0.376262
 >> iter 10000, loss: 0.318416
   Number of active neurons: 10
 >> iter 11000, loss: 0.241513
 >> iter 12000, loss: 0.147431
 >> iter 13000, loss: 0.280510
 >> iter 14000, loss: 0.259927
 >> iter 15000, loss: 0.296829
 >> iter 16000, loss: 0.216191
 >> iter 17000, loss: 0.175273
 >> iter 18000, loss: 0.117251
 >> iter 19000, loss: 0.127814
 >> iter 20000, loss: 0.087096
   Number of active neurons: 10
 >> iter 21000, loss: 0.169992
 >> iter 22000, loss: 0.173155
 >> iter 23000, loss: 0.087027
 >> iter 24000, loss: 0.061562
 >> iter 25000, loss: 0.037897
 >> iter 26000, loss: 0.075165
 >> iter 27000, loss: 0.097373
 >> iter 28000, loss: 0.121707
 >> iter 29000, loss: 0.235590
 >> iter 30000, loss: 0.207752
   Number of active neurons: 10
 >> iter 31000, loss: 0.098005
 >> iter 32000, loss: 0.062813
 >> iter 33000, loss: 0.045335
 >> iter 34000, loss: 0.026452
 >> iter 35000, loss: 0.064753
 >> iter 36000, loss: 0.055234
 >> iter 37000, loss: 0.028768
 >> iter 38000, loss: 0.018380
 >> iter 39000, loss: 0.012361
 >> iter 40000, loss: 0.026491
   Number of active neurons: 10
 >> iter 41000, loss: 0.206307
 >> iter 42000, loss: 0.082913
 >> iter 43000, loss: 0.036651
 >> iter 44000, loss: 0.026616
 >> iter 45000, loss: 0.157471
 >> iter 46000, loss: 0.138594
 >> iter 47000, loss: 0.058929
 >> iter 48000, loss: 0.028994
 >> iter 49000, loss: 0.021331
 >> iter 50000, loss: 0.013694
   Number of active neurons: 10
 >> iter 51000, loss: 0.011654
 >> iter 52000, loss: 0.011364
 >> iter 53000, loss: 0.009670
 >> iter 54000, loss: 0.025346
 >> iter 55000, loss: 0.045638
 >> iter 56000, loss: 0.021573
 >> iter 57000, loss: 0.012342
 >> iter 58000, loss: 0.027966
 >> iter 59000, loss: 0.134346
 >> iter 60000, loss: 0.085070
   Number of active neurons: 10
 >> iter 61000, loss: 0.035796
 >> iter 62000, loss: 0.033766
 >> iter 63000, loss: 0.018241
 >> iter 64000, loss: 0.078039
 >> iter 65000, loss: 0.089377
 >> iter 66000, loss: 0.037353
 >> iter 67000, loss: 0.026427
 >> iter 68000, loss: 0.101223
 >> iter 69000, loss: 0.041498
 >> iter 70000, loss: 0.075299
   Number of active neurons: 10
 >> iter 71000, loss: 0.123929
 >> iter 72000, loss: 0.051318
 >> iter 73000, loss: 0.023794
 >> iter 74000, loss: 0.012163
 >> iter 75000, loss: 0.007569
 >> iter 76000, loss: 0.012339
 >> iter 77000, loss: 0.021569
 >> iter 78000, loss: 0.071995
 >> iter 79000, loss: 0.031513
 >> iter 80000, loss: 0.016322
   Number of active neurons: 10
 >> iter 81000, loss: 0.116722
 >> iter 82000, loss: 0.049464
 >> iter 83000, loss: 0.049443
 >> iter 84000, loss: 0.021870
 >> iter 85000, loss: 0.040786
 >> iter 86000, loss: 0.021621
 >> iter 87000, loss: 0.098120
 >> iter 88000, loss: 0.061057
 >> iter 89000, loss: 0.026310
 >> iter 90000, loss: 0.012541
   Number of active neurons: 10
 >> iter 91000, loss: 0.012465
 >> iter 92000, loss: 0.045963
 >> iter 93000, loss: 0.020260
 >> iter 94000, loss: 0.010193
 >> iter 95000, loss: 0.006062
 >> iter 96000, loss: 0.004708
 >> iter 97000, loss: 0.003882
 >> iter 98000, loss: 0.003561
 >> iter 99000, loss: 0.003482
 >> iter 100000, loss: 0.101194
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.176409
 >> iter 2000, loss: 12.655834
 >> iter 3000, loss: 7.064092
 >> iter 4000, loss: 3.320776
 >> iter 5000, loss: 1.626288
 >> iter 6000, loss: 0.908451
 >> iter 7000, loss: 0.545698
 >> iter 8000, loss: 0.455357
 >> iter 9000, loss: 0.279756
 >> iter 10000, loss: 0.157498
   Number of active neurons: 10
 >> iter 11000, loss: 0.090047
 >> iter 12000, loss: 0.329942
 >> iter 13000, loss: 0.189087
 >> iter 14000, loss: 0.083488
 >> iter 15000, loss: 0.066585
 >> iter 16000, loss: 0.073968
 >> iter 17000, loss: 0.035810
 >> iter 18000, loss: 0.020495
 >> iter 19000, loss: 0.143675
 >> iter 20000, loss: 0.156506
   Number of active neurons: 10
 >> iter 21000, loss: 0.065637
 >> iter 22000, loss: 0.070211
 >> iter 23000, loss: 0.181850
 >> iter 24000, loss: 0.237534
 >> iter 25000, loss: 0.114052
 >> iter 26000, loss: 0.098729
 >> iter 27000, loss: 0.042098
 >> iter 28000, loss: 0.055419
 >> iter 29000, loss: 0.038807
 >> iter 30000, loss: 0.019437
   Number of active neurons: 10
 >> iter 31000, loss: 0.015067
 >> iter 32000, loss: 0.009636
 >> iter 33000, loss: 0.068794
 >> iter 34000, loss: 0.029274
 >> iter 35000, loss: 0.137610
 >> iter 36000, loss: 0.055194
 >> iter 37000, loss: 0.030695
 >> iter 38000, loss: 0.015016
 >> iter 39000, loss: 0.074035
 >> iter 40000, loss: 0.035238
   Number of active neurons: 10
 >> iter 41000, loss: 0.042437
 >> iter 42000, loss: 0.022900
 >> iter 43000, loss: 0.029194
 >> iter 44000, loss: 0.014073
 >> iter 45000, loss: 0.017057
 >> iter 46000, loss: 0.016768
 >> iter 47000, loss: 0.009273
 >> iter 48000, loss: 0.007506
 >> iter 49000, loss: 0.021357
 >> iter 50000, loss: 0.010716
   Number of active neurons: 10
 >> iter 51000, loss: 0.009371
 >> iter 52000, loss: 0.007352
 >> iter 53000, loss: 0.006902
 >> iter 54000, loss: 0.014230
 >> iter 55000, loss: 0.007873
 >> iter 56000, loss: 0.073412
 >> iter 57000, loss: 0.029770
 >> iter 58000, loss: 0.012550
 >> iter 59000, loss: 0.011634
 >> iter 60000, loss: 0.008652
   Number of active neurons: 10
 >> iter 61000, loss: 0.046080
 >> iter 62000, loss: 0.049826
 >> iter 63000, loss: 0.123303
 >> iter 64000, loss: 0.080883
 >> iter 65000, loss: 0.142769
 >> iter 66000, loss: 0.120146
 >> iter 67000, loss: 0.089673
 >> iter 68000, loss: 0.038730
 >> iter 69000, loss: 0.018039
 >> iter 70000, loss: 0.248619
   Number of active neurons: 10
 >> iter 71000, loss: 0.095671
 >> iter 72000, loss: 0.038213
 >> iter 73000, loss: 0.025803
 >> iter 74000, loss: 0.028843
 >> iter 75000, loss: 0.013813
 >> iter 76000, loss: 0.023409
 >> iter 77000, loss: 0.024044
 >> iter 78000, loss: 0.019756
 >> iter 79000, loss: 0.010506
 >> iter 80000, loss: 0.005603
   Number of active neurons: 10
 >> iter 81000, loss: 0.004081
 >> iter 82000, loss: 0.005606
 >> iter 83000, loss: 0.072275
 >> iter 84000, loss: 0.028762
 >> iter 85000, loss: 0.020932
 >> iter 86000, loss: 0.009959
 >> iter 87000, loss: 0.005388
 >> iter 88000, loss: 0.005298
 >> iter 89000, loss: 0.006773
 >> iter 90000, loss: 0.003736
   Number of active neurons: 10
 >> iter 91000, loss: 0.002733
 >> iter 92000, loss: 0.006875
 >> iter 93000, loss: 0.004064
 >> iter 94000, loss: 0.051474
 >> iter 95000, loss: 0.020448
 >> iter 96000, loss: 0.013460
 >> iter 97000, loss: 0.006836
 >> iter 98000, loss: 0.003773
 >> iter 99000, loss: 0.002545
 >> iter 100000, loss: 0.018156
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

