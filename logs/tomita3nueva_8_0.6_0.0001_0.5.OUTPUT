 > Problema: tomita3nueva
 > Args:
   - Hidden size: 8
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.231812
 >> iter 2000, loss: 12.486202
 >> iter 3000, loss: 7.038882
 >> iter 4000, loss: 4.183087
 >> iter 5000, loss: 3.297646
 >> iter 6000, loss: 2.497105
 >> iter 7000, loss: 2.387820
 >> iter 8000, loss: 2.245572
 >> iter 9000, loss: 2.301171
 >> iter 10000, loss: 2.148168
   Number of active neurons: 5
 >> iter 11000, loss: 2.166572
 >> iter 12000, loss: 2.066099
 >> iter 13000, loss: 2.203765
 >> iter 14000, loss: 2.055273
 >> iter 15000, loss: 2.146241
 >> iter 16000, loss: 2.034658
 >> iter 17000, loss: 2.063373
 >> iter 18000, loss: 1.948999
 >> iter 19000, loss: 2.080470
 >> iter 20000, loss: 1.913634
   Number of active neurons: 6
 >> iter 21000, loss: 2.239156
 >> iter 22000, loss: 2.039655
 >> iter 23000, loss: 2.362585
 >> iter 24000, loss: 2.036093
 >> iter 25000, loss: 2.248254
   Number of active neurons: 6
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 26000, loss: 2.697957
 >> iter 27000, loss: 2.399000
 >> iter 28000, loss: 2.000441
 >> iter 29000, loss: 2.079934
 >> iter 30000, loss: 1.990418
   Number of active neurons: 8
 >> iter 31000, loss: 1.473902
 >> iter 32000, loss: 0.843969
 >> iter 33000, loss: 0.725268
 >> iter 34000, loss: 0.609756
 >> iter 35000, loss: 0.448579
 >> iter 36000, loss: 0.569417
 >> iter 37000, loss: 0.619570
 >> iter 38000, loss: 0.457018
 >> iter 39000, loss: 0.471885
 >> iter 40000, loss: 0.465791
   Number of active neurons: 8
 >> iter 41000, loss: 0.608812
 >> iter 42000, loss: 0.567988
 >> iter 43000, loss: 0.522739
 >> iter 44000, loss: 0.640862
 >> iter 45000, loss: 0.451546
 >> iter 46000, loss: 0.364808
 >> iter 47000, loss: 0.451464
 >> iter 48000, loss: 0.440268
 >> iter 49000, loss: 0.517189
 >> iter 50000, loss: 0.484375
   Number of active neurons: 7
 >> iter 51000, loss: 0.621021
 >> iter 52000, loss: 0.540427
 >> iter 53000, loss: 0.502493
 >> iter 54000, loss: 0.408377
 >> iter 55000, loss: 0.552939
 >> iter 56000, loss: 0.541401
 >> iter 57000, loss: 0.439441
 >> iter 58000, loss: 0.507644
 >> iter 59000, loss: 0.673499
 >> iter 60000, loss: 0.437740
   Number of active neurons: 6
 >> iter 61000, loss: 0.379973
 >> iter 62000, loss: 0.526831
 >> iter 63000, loss: 0.703064
 >> iter 64000, loss: 0.706904
 >> iter 65000, loss: 0.588256
 >> iter 66000, loss: 0.639866
 >> iter 67000, loss: 0.825529
 >> iter 68000, loss: 0.506001
 >> iter 69000, loss: 0.497512
 >> iter 70000, loss: 0.689754
   Number of active neurons: 5
 >> iter 71000, loss: 0.546006
 >> iter 72000, loss: 0.721935
 >> iter 73000, loss: 0.677880
 >> iter 74000, loss: 0.504837
 >> iter 75000, loss: 0.536235
 >> iter 76000, loss: 0.438852
 >> iter 77000, loss: 0.756741
 >> iter 78000, loss: 0.647588
 >> iter 79000, loss: 0.468603
 >> iter 80000, loss: 0.411313
   Number of active neurons: 5
 >> iter 81000, loss: 0.642837
 >> iter 82000, loss: 0.742597
 >> iter 83000, loss: 0.566876
 >> iter 84000, loss: 0.468259
 >> iter 85000, loss: 0.456460
 >> iter 86000, loss: 0.544463
 >> iter 87000, loss: 0.551695
 >> iter 88000, loss: 0.520908
 >> iter 89000, loss: 0.527758
 >> iter 90000, loss: 0.486394
   Number of active neurons: 5
 >> iter 91000, loss: 0.525926
 >> iter 92000, loss: 0.520020
 >> iter 93000, loss: 0.552603
 >> iter 94000, loss: 0.478459
 >> iter 95000, loss: 0.517888
 >> iter 96000, loss: 0.419770
 >> iter 97000, loss: 0.459896
 >> iter 98000, loss: 0.553205
 >> iter 99000, loss: 0.636178
 >> iter 100000, loss: 0.701076
   Number of active neurons: 5
 >> iter 101000, loss: 0.646894
 >> iter 102000, loss: 0.560321
 >> iter 103000, loss: 0.509666
 >> iter 104000, loss: 0.495653
 >> iter 105000, loss: 0.470746
 >> iter 106000, loss: 0.576610
 >> iter 107000, loss: 0.460757
 >> iter 108000, loss: 0.323577
 >> iter 109000, loss: 0.491979
 >> iter 110000, loss: 0.494879
   Number of active neurons: 5
 >> iter 111000, loss: 0.534257
 >> iter 112000, loss: 0.378257
 >> iter 113000, loss: 0.686050
 >> iter 114000, loss: 0.586087
 >> iter 115000, loss: 0.618279
 >> iter 116000, loss: 0.503277
 >> iter 117000, loss: 0.561469
 >> iter 118000, loss: 0.605391
 >> iter 119000, loss: 0.527425
 >> iter 120000, loss: 0.535473
   Number of active neurons: 5
 >> iter 121000, loss: 0.595517
 >> iter 122000, loss: 0.605251
 >> iter 123000, loss: 0.727458
 >> iter 124000, loss: 0.494832
 >> iter 125000, loss: 0.612148
 >> iter 126000, loss: 0.517956
 >> iter 127000, loss: 0.452349
 >> iter 128000, loss: 0.579795
 >> iter 129000, loss: 0.486473
 >> iter 130000, loss: 0.504799
   Number of active neurons: 5
 >> iter 131000, loss: 0.639247
 >> iter 132000, loss: 0.576274
 >> iter 133000, loss: 0.609704
 >> iter 134000, loss: 0.473811
 >> iter 135000, loss: 0.562137
 >> iter 136000, loss: 0.498381
 >> iter 137000, loss: 0.401997
 >> iter 138000, loss: 0.507577
 >> iter 139000, loss: 0.696335
 >> iter 140000, loss: 0.541792
   Number of active neurons: 5
 >> iter 141000, loss: 0.664618
 >> iter 142000, loss: 0.585499
 >> iter 143000, loss: 0.610711
 >> iter 144000, loss: 0.901110
 >> iter 145000, loss: 0.726015
 >> iter 146000, loss: 0.634222
 >> iter 147000, loss: 0.575030
 >> iter 148000, loss: 0.504406
 >> iter 149000, loss: 0.500113
 >> iter 150000, loss: 0.331172
   Number of active neurons: 5
 >> iter 151000, loss: 0.657552
 >> iter 152000, loss: 0.492573
 >> iter 153000, loss: 0.519599
 >> iter 154000, loss: 0.376065
 >> iter 155000, loss: 0.415162
 >> iter 156000, loss: 0.430876
 >> iter 157000, loss: 0.651045
 >> iter 158000, loss: 0.589276
 >> iter 159000, loss: 0.606834
 >> iter 160000, loss: 0.621761
   Number of active neurons: 5
 >> iter 161000, loss: 0.572485
 >> iter 162000, loss: 0.562940
 >> iter 163000, loss: 0.627992
 >> iter 164000, loss: 0.632376
 >> iter 165000, loss: 0.572036
 >> iter 166000, loss: 0.594684
 >> iter 167000, loss: 0.460497
 >> iter 168000, loss: 0.439502
 >> iter 169000, loss: 0.540877
 >> iter 170000, loss: 0.623497
   Number of active neurons: 5
 >> iter 171000, loss: 0.606066
 >> iter 172000, loss: 0.731871
 >> iter 173000, loss: 0.488124
 >> iter 174000, loss: 0.457785
 >> iter 175000, loss: 0.580791
 >> iter 176000, loss: 0.484877
 >> iter 177000, loss: 0.529814
 >> iter 178000, loss: 0.377635
 >> iter 179000, loss: 0.445949
 >> iter 180000, loss: 0.486837
   Number of active neurons: 5
 >> iter 181000, loss: 0.635735
 >> iter 182000, loss: 0.430685
 >> iter 183000, loss: 0.466178
 >> iter 184000, loss: 0.470073
 >> iter 185000, loss: 0.533054
 >> iter 186000, loss: 0.490729
 >> iter 187000, loss: 0.650540
 >> iter 188000, loss: 0.621915
 >> iter 189000, loss: 0.571653
 >> iter 190000, loss: 0.530934
   Number of active neurons: 5
 >> iter 191000, loss: 0.534655
 >> iter 192000, loss: 0.454265
 >> iter 193000, loss: 0.735406
 >> iter 194000, loss: 0.549475
 >> iter 195000, loss: 0.599667
 >> iter 196000, loss: 0.553462
 >> iter 197000, loss: 0.520988
 >> iter 198000, loss: 0.618817
 >> iter 199000, loss: 0.464948
 >> iter 200000, loss: 0.511952
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.249748
 >> iter 2000, loss: 13.028959
 >> iter 3000, loss: 8.187842
 >> iter 4000, loss: 4.856161
 >> iter 5000, loss: 2.696516
 >> iter 6000, loss: 1.552832
 >> iter 7000, loss: 1.023560
 >> iter 8000, loss: 0.809075
 >> iter 9000, loss: 0.594750
 >> iter 10000, loss: 0.459993
   Number of active neurons: 6
 >> iter 11000, loss: 0.486066
 >> iter 12000, loss: 0.372893
 >> iter 13000, loss: 0.332109
 >> iter 14000, loss: 0.422075
 >> iter 15000, loss: 0.245305
 >> iter 16000, loss: 0.330769
 >> iter 17000, loss: 0.376873
 >> iter 18000, loss: 0.360378
 >> iter 19000, loss: 0.286732
 >> iter 20000, loss: 0.268656
   Number of active neurons: 6
 >> iter 21000, loss: 0.297578
 >> iter 22000, loss: 0.455866
 >> iter 23000, loss: 0.368758
 >> iter 24000, loss: 0.437421
 >> iter 25000, loss: 0.481291
 >> iter 26000, loss: 0.362589
 >> iter 27000, loss: 0.487724
 >> iter 28000, loss: 0.487575
 >> iter 29000, loss: 0.519367
 >> iter 30000, loss: 0.499517
   Number of active neurons: 6
 >> iter 31000, loss: 0.365820
 >> iter 32000, loss: 0.320099
 >> iter 33000, loss: 0.407922
 >> iter 34000, loss: 0.449123
 >> iter 35000, loss: 0.676955
 >> iter 36000, loss: 0.641956
 >> iter 37000, loss: 0.548061
 >> iter 38000, loss: 0.477956
 >> iter 39000, loss: 0.339449
 >> iter 40000, loss: 0.443429
   Number of active neurons: 6
 >> iter 41000, loss: 0.398689
 >> iter 42000, loss: 0.275751
 >> iter 43000, loss: 0.211643
 >> iter 44000, loss: 0.369215
 >> iter 45000, loss: 0.504963
 >> iter 46000, loss: 0.381787
 >> iter 47000, loss: 0.373409
 >> iter 48000, loss: 0.289848
 >> iter 49000, loss: 0.304829
 >> iter 50000, loss: 0.246540
   Number of active neurons: 5
 >> iter 51000, loss: 0.365400
 >> iter 52000, loss: 0.327999
 >> iter 53000, loss: 0.444457
 >> iter 54000, loss: 0.352793
 >> iter 55000, loss: 0.387816
 >> iter 56000, loss: 0.491496
 >> iter 57000, loss: 0.435279
 >> iter 58000, loss: 0.437000
 >> iter 59000, loss: 0.361547
 >> iter 60000, loss: 0.254796
   Number of active neurons: 5
 >> iter 61000, loss: 0.233222
 >> iter 62000, loss: 0.278159
 >> iter 63000, loss: 0.432385
 >> iter 64000, loss: 0.564408
 >> iter 65000, loss: 0.535008
 >> iter 66000, loss: 0.343169
 >> iter 67000, loss: 0.246146
 >> iter 68000, loss: 0.331096
 >> iter 69000, loss: 0.520797
 >> iter 70000, loss: 0.502167
   Number of active neurons: 5
 >> iter 71000, loss: 0.412834
 >> iter 72000, loss: 0.348304
 >> iter 73000, loss: 0.342952
 >> iter 74000, loss: 0.336334
 >> iter 75000, loss: 0.404683
 >> iter 76000, loss: 0.325636
 >> iter 77000, loss: 0.427740
 >> iter 78000, loss: 0.425889
 >> iter 79000, loss: 0.495135
 >> iter 80000, loss: 0.355900
   Number of active neurons: 4
 >> iter 81000, loss: 0.513275
 >> iter 82000, loss: 0.519295
 >> iter 83000, loss: 0.393376
 >> iter 84000, loss: 0.328965
 >> iter 85000, loss: 0.289565
 >> iter 86000, loss: 0.260552
 >> iter 87000, loss: 0.511495
 >> iter 88000, loss: 0.355027
 >> iter 89000, loss: 0.399130
 >> iter 90000, loss: 0.328109
   Number of active neurons: 4
 >> iter 91000, loss: 0.400874
 >> iter 92000, loss: 0.291530
 >> iter 93000, loss: 0.330583
 >> iter 94000, loss: 0.224811
 >> iter 95000, loss: 0.415353
 >> iter 96000, loss: 0.218531
 >> iter 97000, loss: 0.225203
 >> iter 98000, loss: 0.245219
 >> iter 99000, loss: 0.229607
 >> iter 100000, loss: 0.247195
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 12.6124925005
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.707906
 >> iter 2000, loss: 16.351977
 >> iter 3000, loss: 14.136784
 >> iter 4000, loss: 10.790471
 >> iter 5000, loss: 8.762436
 >> iter 6000, loss: 7.656905
 >> iter 7000, loss: 7.258470
 >> iter 8000, loss: 6.843678
 >> iter 9000, loss: 6.836860
 >> iter 10000, loss: 6.419898
   Number of active neurons: 5
 >> iter 11000, loss: 4.458963
 >> iter 12000, loss: 2.357192
 >> iter 13000, loss: 1.258164
 >> iter 14000, loss: 1.180974
 >> iter 15000, loss: 0.877535
 >> iter 16000, loss: 0.617954
 >> iter 17000, loss: 0.548857
 >> iter 18000, loss: 0.367355
 >> iter 19000, loss: 0.489922
 >> iter 20000, loss: 0.491713
   Number of active neurons: 5
 >> iter 21000, loss: 0.566039
 >> iter 22000, loss: 0.649437
 >> iter 23000, loss: 0.741823
 >> iter 24000, loss: 0.480293
 >> iter 25000, loss: 0.351371
 >> iter 26000, loss: 0.495606
 >> iter 27000, loss: 0.340209
 >> iter 28000, loss: 0.428590
 >> iter 29000, loss: 0.443216
 >> iter 30000, loss: 0.267791
   Number of active neurons: 5
 >> iter 31000, loss: 0.188006
 >> iter 32000, loss: 0.243133
 >> iter 33000, loss: 0.328508
 >> iter 34000, loss: 0.275004
 >> iter 35000, loss: 0.198403
 >> iter 36000, loss: 0.254467
 >> iter 37000, loss: 0.318683
 >> iter 38000, loss: 0.433711
 >> iter 39000, loss: 0.388930
 >> iter 40000, loss: 0.332231
   Number of active neurons: 5
 >> iter 41000, loss: 0.219429
 >> iter 42000, loss: 0.241479
 >> iter 43000, loss: 0.405642
 >> iter 44000, loss: 0.409768
 >> iter 45000, loss: 0.281255
 >> iter 46000, loss: 0.223511
 >> iter 47000, loss: 0.452585
 >> iter 48000, loss: 0.353795
 >> iter 49000, loss: 0.448585
 >> iter 50000, loss: 0.372005
   Number of active neurons: 5
 >> iter 51000, loss: 0.501450
 >> iter 52000, loss: 0.455823
 >> iter 53000, loss: 0.448859
 >> iter 54000, loss: 0.464568
 >> iter 55000, loss: 0.546485
 >> iter 56000, loss: 0.722021
 >> iter 57000, loss: 0.422448
 >> iter 58000, loss: 0.295000
 >> iter 59000, loss: 0.397819
 >> iter 60000, loss: 0.600485
   Number of active neurons: 5
 >> iter 61000, loss: 0.548504
 >> iter 62000, loss: 0.441723
 >> iter 63000, loss: 0.415927
 >> iter 64000, loss: 0.524688
 >> iter 65000, loss: 0.337851
 >> iter 66000, loss: 0.428002
 >> iter 67000, loss: 0.316672
 >> iter 68000, loss: 0.334777
 >> iter 69000, loss: 0.221448
 >> iter 70000, loss: 0.302140
   Number of active neurons: 5
 >> iter 71000, loss: 0.336684
 >> iter 72000, loss: 0.218606
 >> iter 73000, loss: 0.303924
 >> iter 74000, loss: 0.308538
 >> iter 75000, loss: 0.345080
 >> iter 76000, loss: 0.319796
 >> iter 77000, loss: 0.330653
 >> iter 78000, loss: 0.324109
 >> iter 79000, loss: 0.300030
 >> iter 80000, loss: 0.266070
   Number of active neurons: 5
 >> iter 81000, loss: 0.193086
 >> iter 82000, loss: 0.251674
 >> iter 83000, loss: 0.192614
 >> iter 84000, loss: 0.335585
 >> iter 85000, loss: 0.373174
 >> iter 86000, loss: 0.310952
 >> iter 87000, loss: 0.326775
 >> iter 88000, loss: 0.236834
 >> iter 89000, loss: 0.169423
 >> iter 90000, loss: 0.187212
   Number of active neurons: 5
 >> iter 91000, loss: 0.266061
 >> iter 92000, loss: 0.301419
 >> iter 93000, loss: 0.296517
 >> iter 94000, loss: 0.307213
 >> iter 95000, loss: 0.188294
 >> iter 96000, loss: 0.163753
 >> iter 97000, loss: 0.190459
 >> iter 98000, loss: 0.444543
 >> iter 99000, loss: 0.420139
 >> iter 100000, loss: 0.230475
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.051872
 >> iter 2000, loss: 13.205168
 >> iter 3000, loss: 6.813880
 >> iter 4000, loss: 3.143236
 >> iter 5000, loss: 1.379440
 >> iter 6000, loss: 0.943558
 >> iter 7000, loss: 0.535703
 >> iter 8000, loss: 0.529797
 >> iter 9000, loss: 0.495619
 >> iter 10000, loss: 0.406664
   Number of active neurons: 5
 >> iter 11000, loss: 0.308786
 >> iter 12000, loss: 0.414931
 >> iter 13000, loss: 0.380914
 >> iter 14000, loss: 0.507549
 >> iter 15000, loss: 0.371383
 >> iter 16000, loss: 0.346012
 >> iter 17000, loss: 0.370184
 >> iter 18000, loss: 0.336980
 >> iter 19000, loss: 0.266588
 >> iter 20000, loss: 0.385711
   Number of active neurons: 5
 >> iter 21000, loss: 0.339697
 >> iter 22000, loss: 0.270432
 >> iter 23000, loss: 0.223000
 >> iter 24000, loss: 0.300316
 >> iter 25000, loss: 0.484277
 >> iter 26000, loss: 0.386316
 >> iter 27000, loss: 0.415881
 >> iter 28000, loss: 0.407981
 >> iter 29000, loss: 0.335124
 >> iter 30000, loss: 0.242130
   Number of active neurons: 5
 >> iter 31000, loss: 0.357630
 >> iter 32000, loss: 0.380643
 >> iter 33000, loss: 0.291470
 >> iter 34000, loss: 0.427703
 >> iter 35000, loss: 0.576643
 >> iter 36000, loss: 0.514945
 >> iter 37000, loss: 0.470392
 >> iter 38000, loss: 0.422991
 >> iter 39000, loss: 0.408060
 >> iter 40000, loss: 0.329247
   Number of active neurons: 5
 >> iter 41000, loss: 0.282597
 >> iter 42000, loss: 0.236056
 >> iter 43000, loss: 0.378201
 >> iter 44000, loss: 0.363378
 >> iter 45000, loss: 0.397420
 >> iter 46000, loss: 0.379283
 >> iter 47000, loss: 0.322371
 >> iter 48000, loss: 0.290601
 >> iter 49000, loss: 0.375429
 >> iter 50000, loss: 0.461073
   Number of active neurons: 5
 >> iter 51000, loss: 0.473331
 >> iter 52000, loss: 0.363761
 >> iter 53000, loss: 0.384779
 >> iter 54000, loss: 0.270744
 >> iter 55000, loss: 0.355915
 >> iter 56000, loss: 0.531970
 >> iter 57000, loss: 0.392764
 >> iter 58000, loss: 0.301014
 >> iter 59000, loss: 0.353106
 >> iter 60000, loss: 0.505164
   Number of active neurons: 5
 >> iter 61000, loss: 0.464969
 >> iter 62000, loss: 0.348481
 >> iter 63000, loss: 0.376213
 >> iter 64000, loss: 0.522485
 >> iter 65000, loss: 0.403466
 >> iter 66000, loss: 0.346128
 >> iter 67000, loss: 0.280147
 >> iter 68000, loss: 0.249936
 >> iter 69000, loss: 0.323113
 >> iter 70000, loss: 0.312041
   Number of active neurons: 5
 >> iter 71000, loss: 0.280125
 >> iter 72000, loss: 0.285865
 >> iter 73000, loss: 0.237774
 >> iter 74000, loss: 0.361554
 >> iter 75000, loss: 0.423633
 >> iter 76000, loss: 0.387169
 >> iter 77000, loss: 0.563980
 >> iter 78000, loss: 0.467206
 >> iter 79000, loss: 0.337627
 >> iter 80000, loss: 0.442757
   Number of active neurons: 4
 >> iter 81000, loss: 0.311221
 >> iter 82000, loss: 0.437067
 >> iter 83000, loss: 0.521009
 >> iter 84000, loss: 0.472452
 >> iter 85000, loss: 0.303352
 >> iter 86000, loss: 0.345004
 >> iter 87000, loss: 0.335381
 >> iter 88000, loss: 0.365243
 >> iter 89000, loss: 0.335524
 >> iter 90000, loss: 0.305079
   Number of active neurons: 4
 >> iter 91000, loss: 0.379132
 >> iter 92000, loss: 0.364262
 >> iter 93000, loss: 0.414190
 >> iter 94000, loss: 0.448567
 >> iter 95000, loss: 0.324113
 >> iter 96000, loss: 0.394439
 >> iter 97000, loss: 0.297620
 >> iter 98000, loss: 0.269895
 >> iter 99000, loss: 0.342309
 >> iter 100000, loss: 0.309007
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0039999200016
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 13.0257982801
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.421323
 >> iter 2000, loss: 12.247040
 >> iter 3000, loss: 5.945959
 >> iter 4000, loss: 2.672237
 >> iter 5000, loss: 1.334607
 >> iter 6000, loss: 0.647478
 >> iter 7000, loss: 0.325117
 >> iter 8000, loss: 0.217261
 >> iter 9000, loss: 0.445497
 >> iter 10000, loss: 0.278945
   Number of active neurons: 5
 >> iter 11000, loss: 0.235397
 >> iter 12000, loss: 0.227217
 >> iter 13000, loss: 0.172413
 >> iter 14000, loss: 0.211070
 >> iter 15000, loss: 0.236177
 >> iter 16000, loss: 0.233566
 >> iter 17000, loss: 0.265660
 >> iter 18000, loss: 0.287976
 >> iter 19000, loss: 0.219518
 >> iter 20000, loss: 0.271377
   Number of active neurons: 5
 >> iter 21000, loss: 0.226420
 >> iter 22000, loss: 0.305654
 >> iter 23000, loss: 0.194629
 >> iter 24000, loss: 0.305746
 >> iter 25000, loss: 0.221165
 >> iter 26000, loss: 0.170294
 >> iter 27000, loss: 0.273378
 >> iter 28000, loss: 0.544275
 >> iter 29000, loss: 0.367574
 >> iter 30000, loss: 0.292028
   Number of active neurons: 5
 >> iter 31000, loss: 0.258020
 >> iter 32000, loss: 0.178460
 >> iter 33000, loss: 0.331282
 >> iter 34000, loss: 0.366991
 >> iter 35000, loss: 0.282866
 >> iter 36000, loss: 0.221130
 >> iter 37000, loss: 0.208967
 >> iter 38000, loss: 0.327542
 >> iter 39000, loss: 0.306619
 >> iter 40000, loss: 0.197021
   Number of active neurons: 5
 >> iter 41000, loss: 0.244436
 >> iter 42000, loss: 0.179747
 >> iter 43000, loss: 0.304182
 >> iter 44000, loss: 0.257473
 >> iter 45000, loss: 0.235555
 >> iter 46000, loss: 0.318455
 >> iter 47000, loss: 0.351244
 >> iter 48000, loss: 0.281576
 >> iter 49000, loss: 0.365204
 >> iter 50000, loss: 0.270754
   Number of active neurons: 5
 >> iter 51000, loss: 0.330401
 >> iter 52000, loss: 0.185548
 >> iter 53000, loss: 0.293574
 >> iter 54000, loss: 0.225992
 >> iter 55000, loss: 0.172317
 >> iter 56000, loss: 0.136178
 >> iter 57000, loss: 0.445917
 >> iter 58000, loss: 0.248892
 >> iter 59000, loss: 0.175111
 >> iter 60000, loss: 0.156417
   Number of active neurons: 4
 >> iter 61000, loss: 0.238221
 >> iter 62000, loss: 0.310990
 >> iter 63000, loss: 0.233009
 >> iter 64000, loss: 0.273271
 >> iter 65000, loss: 0.157594
 >> iter 66000, loss: 0.251030
 >> iter 67000, loss: 0.183627
 >> iter 68000, loss: 0.185027
 >> iter 69000, loss: 0.157516
 >> iter 70000, loss: 0.167243
   Number of active neurons: 4
 >> iter 71000, loss: 0.210049
 >> iter 72000, loss: 0.242139
 >> iter 73000, loss: 0.178994
 >> iter 74000, loss: 0.177054
 >> iter 75000, loss: 0.155865
 >> iter 76000, loss: 0.226382
 >> iter 77000, loss: 0.148459
 >> iter 78000, loss: 0.168797
 >> iter 79000, loss: 0.125947
 >> iter 80000, loss: 0.279961
   Number of active neurons: 4
 >> iter 81000, loss: 0.265452
 >> iter 82000, loss: 0.230651
 >> iter 83000, loss: 0.203546
 >> iter 84000, loss: 0.191972
 >> iter 85000, loss: 0.346849
 >> iter 86000, loss: 0.341986
 >> iter 87000, loss: 0.264404
 >> iter 88000, loss: 0.258491
 >> iter 89000, loss: 0.177373
 >> iter 90000, loss: 0.155932
   Number of active neurons: 4
 >> iter 91000, loss: 0.293449
 >> iter 92000, loss: 0.213652
 >> iter 93000, loss: 0.170292
 >> iter 94000, loss: 0.306524
 >> iter 95000, loss: 0.290739
 >> iter 96000, loss: 0.336636
 >> iter 97000, loss: 0.215651
 >> iter 98000, loss: 0.191817
 >> iter 99000, loss: 0.213225
 >> iter 100000, loss: 0.290824
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.965913
 >> iter 2000, loss: 11.888557
 >> iter 3000, loss: 5.674899
 >> iter 4000, loss: 2.542138
 >> iter 5000, loss: 1.383721
 >> iter 6000, loss: 0.841729
 >> iter 7000, loss: 0.779094
 >> iter 8000, loss: 0.567516
 >> iter 9000, loss: 0.285248
 >> iter 10000, loss: 0.329789
   Number of active neurons: 4
 >> iter 11000, loss: 0.401533
 >> iter 12000, loss: 0.297207
 >> iter 13000, loss: 0.384145
 >> iter 14000, loss: 0.314260
 >> iter 15000, loss: 0.356482
 >> iter 16000, loss: 0.251210
 >> iter 17000, loss: 0.345531
 >> iter 18000, loss: 0.306955
 >> iter 19000, loss: 0.449253
 >> iter 20000, loss: 0.397156
   Number of active neurons: 4
 >> iter 21000, loss: 0.408307
 >> iter 22000, loss: 0.427304
 >> iter 23000, loss: 0.325148
 >> iter 24000, loss: 0.374694
 >> iter 25000, loss: 0.438560
 >> iter 26000, loss: 0.439481
 >> iter 27000, loss: 0.450036
 >> iter 28000, loss: 0.386585
 >> iter 29000, loss: 0.500453
 >> iter 30000, loss: 0.358472
   Number of active neurons: 4
 >> iter 31000, loss: 0.310770
 >> iter 32000, loss: 0.364148
 >> iter 33000, loss: 0.374601
 >> iter 34000, loss: 0.270705
 >> iter 35000, loss: 0.255340
 >> iter 36000, loss: 0.359803
 >> iter 37000, loss: 0.319318
 >> iter 38000, loss: 0.272726
 >> iter 39000, loss: 0.414659
 >> iter 40000, loss: 0.413659
   Number of active neurons: 4
 >> iter 41000, loss: 0.332468
 >> iter 42000, loss: 0.320613
 >> iter 43000, loss: 0.436983
 >> iter 44000, loss: 0.339189
 >> iter 45000, loss: 0.351700
 >> iter 46000, loss: 0.369160
 >> iter 47000, loss: 0.397171
 >> iter 48000, loss: 0.579225
 >> iter 49000, loss: 0.466328
 >> iter 50000, loss: 0.406750
   Number of active neurons: 4
 >> iter 51000, loss: 0.261507
 >> iter 52000, loss: 0.273225
 >> iter 53000, loss: 0.465053
 >> iter 54000, loss: 0.478148
 >> iter 55000, loss: 0.328998
 >> iter 56000, loss: 0.443601
 >> iter 57000, loss: 0.377973
 >> iter 58000, loss: 0.372928
 >> iter 59000, loss: 0.417467
 >> iter 60000, loss: 0.358379
   Number of active neurons: 4
 >> iter 61000, loss: 0.379843
 >> iter 62000, loss: 0.471690
 >> iter 63000, loss: 0.415244
 >> iter 64000, loss: 0.491312
 >> iter 65000, loss: 0.339421
 >> iter 66000, loss: 0.315247
 >> iter 67000, loss: 0.383192
 >> iter 68000, loss: 0.416113
 >> iter 69000, loss: 0.400886
 >> iter 70000, loss: 0.341761
   Number of active neurons: 4
 >> iter 71000, loss: 0.542822
 >> iter 72000, loss: 0.399359
 >> iter 73000, loss: 0.409668
 >> iter 74000, loss: 0.537078
 >> iter 75000, loss: 0.444306
 >> iter 76000, loss: 0.609987
 >> iter 77000, loss: 0.406091
 >> iter 78000, loss: 0.663134
 >> iter 79000, loss: 0.584208
 >> iter 80000, loss: 0.565588
   Number of active neurons: 4
 >> iter 81000, loss: 0.397158
 >> iter 82000, loss: 0.300458
 >> iter 83000, loss: 0.473602
 >> iter 84000, loss: 0.279627
 >> iter 85000, loss: 0.240929
 >> iter 86000, loss: 0.225311
 >> iter 87000, loss: 0.314568
 >> iter 88000, loss: 0.321279
 >> iter 89000, loss: 0.414674
 >> iter 90000, loss: 0.303844
   Number of active neurons: 4
 >> iter 91000, loss: 0.377997
 >> iter 92000, loss: 0.238734
 >> iter 93000, loss: 0.318297
 >> iter 94000, loss: 0.257263
 >> iter 95000, loss: 0.342164
 >> iter 96000, loss: 0.282742
 >> iter 97000, loss: 0.275983
 >> iter 98000, loss: 0.363384
 >> iter 99000, loss: 0.276302
 >> iter 100000, loss: 0.523427
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 12.2125191654
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.914884
 >> iter 2000, loss: 11.074679
 >> iter 3000, loss: 5.119944
 >> iter 4000, loss: 2.443082
 >> iter 5000, loss: 1.393457
 >> iter 6000, loss: 0.756538
 >> iter 7000, loss: 0.683701
 >> iter 8000, loss: 0.541030
 >> iter 9000, loss: 0.450874
 >> iter 10000, loss: 0.431062
   Number of active neurons: 6
 >> iter 11000, loss: 0.542350
 >> iter 12000, loss: 0.513410
 >> iter 13000, loss: 0.370249
 >> iter 14000, loss: 0.368437
 >> iter 15000, loss: 0.438265
 >> iter 16000, loss: 0.297010
 >> iter 17000, loss: 0.423864
 >> iter 18000, loss: 0.518303
 >> iter 19000, loss: 0.499866
 >> iter 20000, loss: 0.332167
   Number of active neurons: 5
 >> iter 21000, loss: 0.484065
 >> iter 22000, loss: 0.382913
 >> iter 23000, loss: 0.403027
 >> iter 24000, loss: 0.286195
 >> iter 25000, loss: 0.304094
 >> iter 26000, loss: 0.321120
 >> iter 27000, loss: 0.337391
 >> iter 28000, loss: 0.389862
 >> iter 29000, loss: 0.570336
 >> iter 30000, loss: 0.502904
   Number of active neurons: 5
 >> iter 31000, loss: 0.377416
 >> iter 32000, loss: 0.340934
 >> iter 33000, loss: 0.436711
 >> iter 34000, loss: 0.527912
 >> iter 35000, loss: 0.443103
 >> iter 36000, loss: 0.516900
 >> iter 37000, loss: 0.351572
 >> iter 38000, loss: 0.437070
 >> iter 39000, loss: 0.538746
 >> iter 40000, loss: 0.516599
   Number of active neurons: 5
 >> iter 41000, loss: 0.419619
 >> iter 42000, loss: 0.506734
 >> iter 43000, loss: 0.437537
 >> iter 44000, loss: 0.397046
 >> iter 45000, loss: 0.379246
 >> iter 46000, loss: 0.532846
 >> iter 47000, loss: 0.385600
 >> iter 48000, loss: 0.442312
 >> iter 49000, loss: 0.286404
 >> iter 50000, loss: 0.368598
   Number of active neurons: 4
 >> iter 51000, loss: 0.337452
 >> iter 52000, loss: 0.494967
 >> iter 53000, loss: 0.466878
 >> iter 54000, loss: 0.352060
 >> iter 55000, loss: 0.346935
 >> iter 56000, loss: 0.316604
 >> iter 57000, loss: 0.320380
 >> iter 58000, loss: 0.485828
 >> iter 59000, loss: 0.415415
 >> iter 60000, loss: 0.365786
   Number of active neurons: 4
 >> iter 61000, loss: 0.433530
 >> iter 62000, loss: 0.320662
 >> iter 63000, loss: 0.440961
 >> iter 64000, loss: 0.433477
 >> iter 65000, loss: 0.287184
 >> iter 66000, loss: 0.250674
 >> iter 67000, loss: 0.370640
 >> iter 68000, loss: 0.404418
 >> iter 69000, loss: 0.277058
 >> iter 70000, loss: 0.341989
   Number of active neurons: 4
 >> iter 71000, loss: 0.417198
 >> iter 72000, loss: 0.490395
 >> iter 73000, loss: 0.461336
 >> iter 74000, loss: 0.430483
 >> iter 75000, loss: 0.329726
 >> iter 76000, loss: 0.268061
 >> iter 77000, loss: 0.479603
 >> iter 78000, loss: 0.412219
 >> iter 79000, loss: 0.447598
 >> iter 80000, loss: 0.334138
   Number of active neurons: 4
 >> iter 81000, loss: 0.374406
 >> iter 82000, loss: 0.410773
 >> iter 83000, loss: 0.354735
 >> iter 84000, loss: 0.369281
 >> iter 85000, loss: 0.392328
 >> iter 86000, loss: 0.346328
 >> iter 87000, loss: 0.356458
 >> iter 88000, loss: 0.423979
 >> iter 89000, loss: 0.404289
 >> iter 90000, loss: 0.347956
   Number of active neurons: 4
 >> iter 91000, loss: 0.285831
 >> iter 92000, loss: 0.341170
 >> iter 93000, loss: 0.386544
 >> iter 94000, loss: 0.398749
 >> iter 95000, loss: 0.394362
 >> iter 96000, loss: 0.301088
 >> iter 97000, loss: 0.461826
 >> iter 98000, loss: 0.296839
 >> iter 99000, loss: 0.531935
 >> iter 100000, loss: 0.547902
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.909753
 >> iter 2000, loss: 12.940648
 >> iter 3000, loss: 10.205726
 >> iter 4000, loss: 8.790297
 >> iter 5000, loss: 8.449212
 >> iter 6000, loss: 8.217951
 >> iter 7000, loss: 8.194067
 >> iter 8000, loss: 7.962289
 >> iter 9000, loss: 8.016978
 >> iter 10000, loss: 7.827560
   Number of active neurons: 3
 >> iter 11000, loss: 8.009457
 >> iter 12000, loss: 7.812609
 >> iter 13000, loss: 7.679139
 >> iter 14000, loss: 7.139033
 >> iter 15000, loss: 7.014685
 >> iter 16000, loss: 5.346898
 >> iter 17000, loss: 3.146692
 >> iter 18000, loss: 1.567585
 >> iter 19000, loss: 0.902799
 >> iter 20000, loss: 0.446195
   Number of active neurons: 6
 >> iter 21000, loss: 0.334297
 >> iter 22000, loss: 0.378370
 >> iter 23000, loss: 0.366998
 >> iter 24000, loss: 0.343364
 >> iter 25000, loss: 0.378663
 >> iter 26000, loss: 0.348411
 >> iter 27000, loss: 0.292890
 >> iter 28000, loss: 0.300341
 >> iter 29000, loss: 0.332648
 >> iter 30000, loss: 0.368416
   Number of active neurons: 6
 >> iter 31000, loss: 0.322845
 >> iter 32000, loss: 0.267860
 >> iter 33000, loss: 0.368778
 >> iter 34000, loss: 0.454102
 >> iter 35000, loss: 0.504569
 >> iter 36000, loss: 0.639462
 >> iter 37000, loss: 0.417677
 >> iter 38000, loss: 0.408434
 >> iter 39000, loss: 0.361959
 >> iter 40000, loss: 0.408395
   Number of active neurons: 5
 >> iter 41000, loss: 0.347683
 >> iter 42000, loss: 0.400042
 >> iter 43000, loss: 0.417520
 >> iter 44000, loss: 0.373180
 >> iter 45000, loss: 0.538146
 >> iter 46000, loss: 0.441437
 >> iter 47000, loss: 0.487195
 >> iter 48000, loss: 0.429717
 >> iter 49000, loss: 0.474414
 >> iter 50000, loss: 0.428478
   Number of active neurons: 4
 >> iter 51000, loss: 0.368150
 >> iter 52000, loss: 0.365968
 >> iter 53000, loss: 0.387999
 >> iter 54000, loss: 0.329947
 >> iter 55000, loss: 0.406125
 >> iter 56000, loss: 0.406749
 >> iter 57000, loss: 0.393029
 >> iter 58000, loss: 0.461118
 >> iter 59000, loss: 0.404785
 >> iter 60000, loss: 0.315827
   Number of active neurons: 4
 >> iter 61000, loss: 0.388098
 >> iter 62000, loss: 0.390074
 >> iter 63000, loss: 0.421195
 >> iter 64000, loss: 0.443460
 >> iter 65000, loss: 0.483121
 >> iter 66000, loss: 0.385684
 >> iter 67000, loss: 0.400350
 >> iter 68000, loss: 0.372744
 >> iter 69000, loss: 0.336913
 >> iter 70000, loss: 0.305099
   Number of active neurons: 4
 >> iter 71000, loss: 0.508666
 >> iter 72000, loss: 0.399334
 >> iter 73000, loss: 0.540425
 >> iter 74000, loss: 0.524499
 >> iter 75000, loss: 0.420205
 >> iter 76000, loss: 0.373387
 >> iter 77000, loss: 0.441995
 >> iter 78000, loss: 0.374493
 >> iter 79000, loss: 0.322137
 >> iter 80000, loss: 0.447601
   Number of active neurons: 4
 >> iter 81000, loss: 0.564921
 >> iter 82000, loss: 0.337026
 >> iter 83000, loss: 0.369596
 >> iter 84000, loss: 0.335980
 >> iter 85000, loss: 0.368155
 >> iter 86000, loss: 0.327421
 >> iter 87000, loss: 0.388664
 >> iter 88000, loss: 0.498791
 >> iter 89000, loss: 0.511416
 >> iter 90000, loss: 0.479282
   Number of active neurons: 4
 >> iter 91000, loss: 0.352391
 >> iter 92000, loss: 0.470872
 >> iter 93000, loss: 0.395332
 >> iter 94000, loss: 0.341226
 >> iter 95000, loss: 0.362838
 >> iter 96000, loss: 0.226413
 >> iter 97000, loss: 0.349913
 >> iter 98000, loss: 0.312988
 >> iter 99000, loss: 0.225772
 >> iter 100000, loss: 0.341075
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.085976
 >> iter 2000, loss: 12.751800
 >> iter 3000, loss: 9.358831
 >> iter 4000, loss: 7.200916
 >> iter 5000, loss: 6.262565
 >> iter 6000, loss: 4.461101
 >> iter 7000, loss: 2.735948
 >> iter 8000, loss: 1.693266
 >> iter 9000, loss: 0.990467
 >> iter 10000, loss: 0.820533
   Number of active neurons: 6
 >> iter 11000, loss: 0.611140
 >> iter 12000, loss: 0.322968
 >> iter 13000, loss: 0.305073
 >> iter 14000, loss: 0.212872
 >> iter 15000, loss: 0.286447
 >> iter 16000, loss: 0.261125
 >> iter 17000, loss: 0.274449
 >> iter 18000, loss: 0.237140
 >> iter 19000, loss: 0.172927
 >> iter 20000, loss: 0.288453
   Number of active neurons: 6
 >> iter 21000, loss: 0.240609
 >> iter 22000, loss: 0.302308
 >> iter 23000, loss: 0.355566
 >> iter 24000, loss: 0.330410
 >> iter 25000, loss: 0.220175
 >> iter 26000, loss: 0.353713
 >> iter 27000, loss: 0.343136
 >> iter 28000, loss: 0.346214
 >> iter 29000, loss: 0.461158
 >> iter 30000, loss: 0.282280
   Number of active neurons: 6
 >> iter 31000, loss: 0.403291
 >> iter 32000, loss: 0.263848
 >> iter 33000, loss: 0.335537
 >> iter 34000, loss: 0.240101
 >> iter 35000, loss: 0.299091
 >> iter 36000, loss: 0.328968
 >> iter 37000, loss: 0.248561
 >> iter 38000, loss: 0.350397
 >> iter 39000, loss: 0.326061
 >> iter 40000, loss: 0.188958
   Number of active neurons: 6
 >> iter 41000, loss: 0.198798
 >> iter 42000, loss: 0.220922
 >> iter 43000, loss: 0.260790
 >> iter 44000, loss: 0.338455
 >> iter 45000, loss: 0.427777
 >> iter 46000, loss: 0.346451
 >> iter 47000, loss: 0.375341
 >> iter 48000, loss: 0.237356
 >> iter 49000, loss: 0.181201
 >> iter 50000, loss: 0.437987
   Number of active neurons: 6
 >> iter 51000, loss: 0.293627
 >> iter 52000, loss: 0.417165
 >> iter 53000, loss: 0.414904
 >> iter 54000, loss: 0.358359
 >> iter 55000, loss: 0.277416
 >> iter 56000, loss: 0.351173
 >> iter 57000, loss: 0.419012
 >> iter 58000, loss: 0.411446
 >> iter 59000, loss: 0.274746
 >> iter 60000, loss: 0.305088
   Number of active neurons: 6
 >> iter 61000, loss: 0.316016
 >> iter 62000, loss: 0.391941
 >> iter 63000, loss: 0.252917
 >> iter 64000, loss: 0.380968
 >> iter 65000, loss: 0.442220
 >> iter 66000, loss: 0.298775
 >> iter 67000, loss: 0.252769
 >> iter 68000, loss: 0.507918
 >> iter 69000, loss: 0.388954
 >> iter 70000, loss: 0.584676
   Number of active neurons: 6
 >> iter 71000, loss: 0.459456
 >> iter 72000, loss: 0.293359
 >> iter 73000, loss: 0.291532
 >> iter 74000, loss: 0.214671
 >> iter 75000, loss: 0.311550
 >> iter 76000, loss: 0.282871
 >> iter 77000, loss: 0.433641
 >> iter 78000, loss: 0.450009
 >> iter 79000, loss: 0.315187
 >> iter 80000, loss: 0.403487
   Number of active neurons: 5
 >> iter 81000, loss: 0.524675
 >> iter 82000, loss: 0.519922
 >> iter 83000, loss: 0.375100
 >> iter 84000, loss: 0.375323
 >> iter 85000, loss: 0.316696
 >> iter 86000, loss: 0.310593
 >> iter 87000, loss: 0.359939
 >> iter 88000, loss: 0.327697
 >> iter 89000, loss: 0.462628
 >> iter 90000, loss: 0.462320
   Number of active neurons: 5
 >> iter 91000, loss: 0.417978
 >> iter 92000, loss: 0.434229
 >> iter 93000, loss: 0.464607
 >> iter 94000, loss: 0.604811
 >> iter 95000, loss: 0.353744
 >> iter 96000, loss: 0.487747
 >> iter 97000, loss: 0.539478
 >> iter 98000, loss: 0.643075
 >> iter 99000, loss: 0.439411
 >> iter 100000, loss: 0.503683
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 16.2655822945
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.058205
 >> iter 2000, loss: 11.902186
 >> iter 3000, loss: 6.192853
 >> iter 4000, loss: 3.007988
 >> iter 5000, loss: 1.572780
 >> iter 6000, loss: 0.790098
 >> iter 7000, loss: 0.451892
 >> iter 8000, loss: 0.372034
 >> iter 9000, loss: 0.464581
 >> iter 10000, loss: 0.454782
   Number of active neurons: 6
 >> iter 11000, loss: 0.554443
 >> iter 12000, loss: 0.365518
 >> iter 13000, loss: 0.390527
 >> iter 14000, loss: 0.341762
 >> iter 15000, loss: 0.447580
 >> iter 16000, loss: 0.330026
 >> iter 17000, loss: 0.307543
 >> iter 18000, loss: 0.279472
 >> iter 19000, loss: 0.310176
 >> iter 20000, loss: 0.321091
   Number of active neurons: 5
 >> iter 21000, loss: 0.377276
 >> iter 22000, loss: 0.255242
 >> iter 23000, loss: 0.345475
 >> iter 24000, loss: 0.295692
 >> iter 25000, loss: 0.211867
 >> iter 26000, loss: 0.259574
 >> iter 27000, loss: 0.230321
 >> iter 28000, loss: 0.360365
 >> iter 29000, loss: 0.389841
 >> iter 30000, loss: 0.238117
   Number of active neurons: 5
 >> iter 31000, loss: 0.309563
 >> iter 32000, loss: 0.243680
 >> iter 33000, loss: 0.225740
 >> iter 34000, loss: 0.327421
 >> iter 35000, loss: 0.356461
 >> iter 36000, loss: 0.267150
 >> iter 37000, loss: 0.245519
 >> iter 38000, loss: 0.281091
 >> iter 39000, loss: 0.232834
 >> iter 40000, loss: 0.174605
   Number of active neurons: 5
 >> iter 41000, loss: 0.266392
 >> iter 42000, loss: 0.354911
 >> iter 43000, loss: 0.228687
 >> iter 44000, loss: 0.187434
 >> iter 45000, loss: 0.398280
 >> iter 46000, loss: 0.425431
 >> iter 47000, loss: 0.475877
 >> iter 48000, loss: 0.419688
 >> iter 49000, loss: 0.410788
 >> iter 50000, loss: 0.315494
   Number of active neurons: 5
 >> iter 51000, loss: 0.469752
 >> iter 52000, loss: 0.420028
 >> iter 53000, loss: 0.307853
 >> iter 54000, loss: 0.354900
 >> iter 55000, loss: 0.427034
 >> iter 56000, loss: 0.331116
 >> iter 57000, loss: 0.268459
 >> iter 58000, loss: 0.393673
 >> iter 59000, loss: 0.235740
 >> iter 60000, loss: 0.201535
   Number of active neurons: 5
 >> iter 61000, loss: 0.271296
 >> iter 62000, loss: 0.344428
 >> iter 63000, loss: 0.309460
 >> iter 64000, loss: 0.229807
 >> iter 65000, loss: 0.278502
 >> iter 66000, loss: 0.250850
 >> iter 67000, loss: 0.307500
 >> iter 68000, loss: 0.216470
 >> iter 69000, loss: 0.254970
 >> iter 70000, loss: 0.358973
   Number of active neurons: 5
 >> iter 71000, loss: 0.321555
 >> iter 72000, loss: 0.327332
 >> iter 73000, loss: 0.275311
 >> iter 74000, loss: 0.275201
 >> iter 75000, loss: 0.325941
 >> iter 76000, loss: 0.259003
 >> iter 77000, loss: 0.437031
 >> iter 78000, loss: 0.434216
 >> iter 79000, loss: 0.359223
 >> iter 80000, loss: 0.348225
   Number of active neurons: 5
 >> iter 81000, loss: 0.481161
 >> iter 82000, loss: 0.335032
 >> iter 83000, loss: 0.274572
 >> iter 84000, loss: 0.350663
 >> iter 85000, loss: 0.344173
 >> iter 86000, loss: 0.355667
 >> iter 87000, loss: 0.276162
 >> iter 88000, loss: 0.317765
 >> iter 89000, loss: 0.299062
 >> iter 90000, loss: 0.259183
   Number of active neurons: 5
 >> iter 91000, loss: 0.330848
 >> iter 92000, loss: 0.451751
 >> iter 93000, loss: 0.350191
 >> iter 94000, loss: 0.245943
 >> iter 95000, loss: 0.229740
 >> iter 96000, loss: 0.263434
 >> iter 97000, loss: 0.450486
 >> iter 98000, loss: 0.376122
 >> iter 99000, loss: 0.431696
 >> iter 100000, loss: 0.401845
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.044098
 >> iter 2000, loss: 10.184761
 >> iter 3000, loss: 4.555485
 >> iter 4000, loss: 2.138480
 >> iter 5000, loss: 1.089781
 >> iter 6000, loss: 0.513361
 >> iter 7000, loss: 0.440397
 >> iter 8000, loss: 0.290414
 >> iter 9000, loss: 0.276809
 >> iter 10000, loss: 0.212580
   Number of active neurons: 6
 >> iter 11000, loss: 0.264793
 >> iter 12000, loss: 0.254793
 >> iter 13000, loss: 0.346997
 >> iter 14000, loss: 0.293773
 >> iter 15000, loss: 0.408483
 >> iter 16000, loss: 0.338761
 >> iter 17000, loss: 0.281907
 >> iter 18000, loss: 0.265801
 >> iter 19000, loss: 0.267674
 >> iter 20000, loss: 0.382764
   Number of active neurons: 6
 >> iter 21000, loss: 0.348440
 >> iter 22000, loss: 0.246293
 >> iter 23000, loss: 0.228197
 >> iter 24000, loss: 0.208058
 >> iter 25000, loss: 0.347980
 >> iter 26000, loss: 0.224354
 >> iter 27000, loss: 0.192045
 >> iter 28000, loss: 0.245881
 >> iter 29000, loss: 0.420333
 >> iter 30000, loss: 0.312411
   Number of active neurons: 6
 >> iter 31000, loss: 0.250680
 >> iter 32000, loss: 0.253617
 >> iter 33000, loss: 0.157297
 >> iter 34000, loss: 0.125206
 >> iter 35000, loss: 0.544201
 >> iter 36000, loss: 0.331931
 >> iter 37000, loss: 0.253456
 >> iter 38000, loss: 0.360047
 >> iter 39000, loss: 0.316686
 >> iter 40000, loss: 0.188320
   Number of active neurons: 6
 >> iter 41000, loss: 0.205271
 >> iter 42000, loss: 0.307995
 >> iter 43000, loss: 0.308140
 >> iter 44000, loss: 0.248658
 >> iter 45000, loss: 0.189953
 >> iter 46000, loss: 0.458629
 >> iter 47000, loss: 0.309759
 >> iter 48000, loss: 0.300040
 >> iter 49000, loss: 0.361663
 >> iter 50000, loss: 0.356068
   Number of active neurons: 5
 >> iter 51000, loss: 0.243085
 >> iter 52000, loss: 0.329181
 >> iter 53000, loss: 0.285943
 >> iter 54000, loss: 0.294061
 >> iter 55000, loss: 0.229875
 >> iter 56000, loss: 0.193544
 >> iter 57000, loss: 0.212103
 >> iter 58000, loss: 0.159374
 >> iter 59000, loss: 0.179169
 >> iter 60000, loss: 0.241597
   Number of active neurons: 5
 >> iter 61000, loss: 0.167642
 >> iter 62000, loss: 0.180817
 >> iter 63000, loss: 0.200356
 >> iter 64000, loss: 0.359906
 >> iter 65000, loss: 0.265431
 >> iter 66000, loss: 0.207952
 >> iter 67000, loss: 0.306303
 >> iter 68000, loss: 0.297727
 >> iter 69000, loss: 0.320581
 >> iter 70000, loss: 0.307329
   Number of active neurons: 4
 >> iter 71000, loss: 0.228137
 >> iter 72000, loss: 0.332442
 >> iter 73000, loss: 0.207883
 >> iter 74000, loss: 0.267592
 >> iter 75000, loss: 0.240696
 >> iter 76000, loss: 0.429884
 >> iter 77000, loss: 0.379080
 >> iter 78000, loss: 0.218155
 >> iter 79000, loss: 0.315992
 >> iter 80000, loss: 0.283366
   Number of active neurons: 4
 >> iter 81000, loss: 0.220308
 >> iter 82000, loss: 0.189524
 >> iter 83000, loss: 0.203501
 >> iter 84000, loss: 0.214513
 >> iter 85000, loss: 0.199002
 >> iter 86000, loss: 0.169278
 >> iter 87000, loss: 0.303957
 >> iter 88000, loss: 0.368557
 >> iter 89000, loss: 0.254736
 >> iter 90000, loss: 0.290381
   Number of active neurons: 4
 >> iter 91000, loss: 0.537014
 >> iter 92000, loss: 0.467557
 >> iter 93000, loss: 0.322125
 >> iter 94000, loss: 0.297319
 >> iter 95000, loss: 0.177953
 >> iter 96000, loss: 0.153260
 >> iter 97000, loss: 0.153946
 >> iter 98000, loss: 0.193959
 >> iter 99000, loss: 0.223565
 >> iter 100000, loss: 0.147795
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.147657
 >> iter 2000, loss: 14.016415
 >> iter 3000, loss: 8.947800
 >> iter 4000, loss: 4.214622
 >> iter 5000, loss: 1.948011
 >> iter 6000, loss: 0.914581
 >> iter 7000, loss: 0.505838
 >> iter 8000, loss: 0.416416
 >> iter 9000, loss: 0.351005
 >> iter 10000, loss: 0.396492
   Number of active neurons: 6
 >> iter 11000, loss: 0.484525
 >> iter 12000, loss: 0.326253
 >> iter 13000, loss: 0.291725
 >> iter 14000, loss: 0.351644
 >> iter 15000, loss: 0.374381
 >> iter 16000, loss: 0.253109
 >> iter 17000, loss: 0.232336
 >> iter 18000, loss: 0.199920
 >> iter 19000, loss: 0.375771
 >> iter 20000, loss: 0.328915
   Number of active neurons: 6
 >> iter 21000, loss: 0.296200
 >> iter 22000, loss: 0.276520
 >> iter 23000, loss: 0.428332
 >> iter 24000, loss: 0.408814
 >> iter 25000, loss: 0.328509
 >> iter 26000, loss: 0.491440
 >> iter 27000, loss: 0.609568
 >> iter 28000, loss: 0.381277
 >> iter 29000, loss: 0.375144
 >> iter 30000, loss: 0.438344
   Number of active neurons: 6
 >> iter 31000, loss: 0.448892
 >> iter 32000, loss: 0.389423
 >> iter 33000, loss: 0.292094
 >> iter 34000, loss: 0.352859
 >> iter 35000, loss: 0.430646
 >> iter 36000, loss: 0.331649
 >> iter 37000, loss: 0.309839
 >> iter 38000, loss: 0.254487
 >> iter 39000, loss: 0.476350
 >> iter 40000, loss: 0.494977
   Number of active neurons: 6
 >> iter 41000, loss: 0.493068
 >> iter 42000, loss: 0.345756
 >> iter 43000, loss: 0.439495
 >> iter 44000, loss: 0.399257
 >> iter 45000, loss: 0.483978
 >> iter 46000, loss: 0.326740
 >> iter 47000, loss: 0.481026
 >> iter 48000, loss: 0.317755
 >> iter 49000, loss: 0.329758
 >> iter 50000, loss: 0.311690
   Number of active neurons: 6
 >> iter 51000, loss: 0.269494
 >> iter 52000, loss: 0.253343
 >> iter 53000, loss: 0.322796
 >> iter 54000, loss: 0.180103
 >> iter 55000, loss: 0.399244
 >> iter 56000, loss: 0.330868
 >> iter 57000, loss: 0.353445
 >> iter 58000, loss: 0.250417
 >> iter 59000, loss: 0.175966
 >> iter 60000, loss: 0.264808
   Number of active neurons: 6
 >> iter 61000, loss: 0.281883
 >> iter 62000, loss: 0.200211
 >> iter 63000, loss: 0.234572
 >> iter 64000, loss: 0.327297
 >> iter 65000, loss: 0.252464
 >> iter 66000, loss: 0.138765
 >> iter 67000, loss: 0.233791
 >> iter 68000, loss: 0.191197
 >> iter 69000, loss: 0.221680
 >> iter 70000, loss: 0.316834
   Number of active neurons: 6
 >> iter 71000, loss: 0.228777
 >> iter 72000, loss: 0.237973
 >> iter 73000, loss: 0.211475
 >> iter 74000, loss: 0.238975
 >> iter 75000, loss: 0.203971
 >> iter 76000, loss: 0.208750
 >> iter 77000, loss: 0.186592
 >> iter 78000, loss: 0.273253
 >> iter 79000, loss: 0.353650
 >> iter 80000, loss: 0.371594
   Number of active neurons: 5
 >> iter 81000, loss: 0.296424
 >> iter 82000, loss: 0.317571
 >> iter 83000, loss: 0.205373
 >> iter 84000, loss: 0.298521
 >> iter 85000, loss: 0.148151
 >> iter 86000, loss: 0.230282
 >> iter 87000, loss: 0.146069
 >> iter 88000, loss: 0.158727
 >> iter 89000, loss: 0.124922
 >> iter 90000, loss: 0.230242
   Number of active neurons: 5
 >> iter 91000, loss: 0.180700
 >> iter 92000, loss: 0.203087
 >> iter 93000, loss: 0.217663
 >> iter 94000, loss: 0.268104
 >> iter 95000, loss: 0.241147
 >> iter 96000, loss: 0.306727
 >> iter 97000, loss: 0.209783
 >> iter 98000, loss: 0.177918
 >> iter 99000, loss: 0.124689
 >> iter 100000, loss: 0.151547
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.444433
 >> iter 2000, loss: 15.367804
 >> iter 3000, loss: 11.809506
 >> iter 4000, loss: 8.355775
 >> iter 5000, loss: 5.810392
 >> iter 6000, loss: 3.901276
 >> iter 7000, loss: 2.703226
 >> iter 8000, loss: 1.462666
 >> iter 9000, loss: 1.337355
 >> iter 10000, loss: 0.918787
   Number of active neurons: 8
 >> iter 11000, loss: 0.805095
 >> iter 12000, loss: 0.583686
 >> iter 13000, loss: 0.591724
 >> iter 14000, loss: 0.501727
 >> iter 15000, loss: 0.426461
 >> iter 16000, loss: 0.386771
 >> iter 17000, loss: 0.388208
 >> iter 18000, loss: 0.503030
 >> iter 19000, loss: 0.798705
 >> iter 20000, loss: 0.435837
   Number of active neurons: 6
 >> iter 21000, loss: 0.359459
 >> iter 22000, loss: 0.441951
 >> iter 23000, loss: 0.387052
 >> iter 24000, loss: 0.533727
 >> iter 25000, loss: 0.363586
 >> iter 26000, loss: 0.294476
 >> iter 27000, loss: 0.239094
 >> iter 28000, loss: 0.640232
 >> iter 29000, loss: 0.430019
 >> iter 30000, loss: 0.488248
   Number of active neurons: 6
 >> iter 31000, loss: 0.333438
 >> iter 32000, loss: 0.376693
 >> iter 33000, loss: 0.276652
 >> iter 34000, loss: 0.213527
 >> iter 35000, loss: 0.359390
 >> iter 36000, loss: 0.289065
 >> iter 37000, loss: 0.467760
 >> iter 38000, loss: 0.492574
 >> iter 39000, loss: 0.438903
 >> iter 40000, loss: 0.362553
   Number of active neurons: 6
 >> iter 41000, loss: 0.350087
 >> iter 42000, loss: 0.577428
 >> iter 43000, loss: 0.530276
 >> iter 44000, loss: 0.494107
 >> iter 45000, loss: 0.294341
 >> iter 46000, loss: 0.385839
 >> iter 47000, loss: 0.468673
 >> iter 48000, loss: 0.358042
 >> iter 49000, loss: 0.280085
 >> iter 50000, loss: 0.322436
   Number of active neurons: 6
 >> iter 51000, loss: 0.427773
 >> iter 52000, loss: 0.410690
 >> iter 53000, loss: 0.416818
 >> iter 54000, loss: 0.325450
 >> iter 55000, loss: 0.469551
 >> iter 56000, loss: 0.430067
 >> iter 57000, loss: 0.364913
 >> iter 58000, loss: 0.354402
 >> iter 59000, loss: 0.431178
 >> iter 60000, loss: 0.504838
   Number of active neurons: 6
 >> iter 61000, loss: 0.378298
 >> iter 62000, loss: 0.446062
 >> iter 63000, loss: 0.541973
 >> iter 64000, loss: 0.544186
 >> iter 65000, loss: 0.349148
 >> iter 66000, loss: 0.499249
 >> iter 67000, loss: 0.458461
 >> iter 68000, loss: 0.493796
 >> iter 69000, loss: 0.533518
 >> iter 70000, loss: 0.417367
   Number of active neurons: 6
 >> iter 71000, loss: 0.515632
 >> iter 72000, loss: 0.342739
 >> iter 73000, loss: 0.404577
 >> iter 74000, loss: 0.278746
 >> iter 75000, loss: 0.414173
 >> iter 76000, loss: 0.405086
 >> iter 77000, loss: 0.607946
 >> iter 78000, loss: 0.527748
 >> iter 79000, loss: 0.458044
 >> iter 80000, loss: 0.447676
   Number of active neurons: 6
 >> iter 81000, loss: 0.323310
 >> iter 82000, loss: 0.491192
 >> iter 83000, loss: 0.419856
 >> iter 84000, loss: 0.476222
 >> iter 85000, loss: 0.443657
 >> iter 86000, loss: 0.518580
 >> iter 87000, loss: 0.425448
 >> iter 88000, loss: 0.340183
 >> iter 89000, loss: 0.441979
 >> iter 90000, loss: 0.444741
   Number of active neurons: 6
 >> iter 91000, loss: 0.471699
 >> iter 92000, loss: 0.430451
 >> iter 93000, loss: 0.444540
 >> iter 94000, loss: 0.414093
 >> iter 95000, loss: 0.429896
 >> iter 96000, loss: 0.395912
 >> iter 97000, loss: 0.437489
 >> iter 98000, loss: 0.359146
 >> iter 99000, loss: 0.518937
 >> iter 100000, loss: 0.440775
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.204274
 >> iter 2000, loss: 11.245477
 >> iter 3000, loss: 5.376294
 >> iter 4000, loss: 2.829482
 >> iter 5000, loss: 1.827297
 >> iter 6000, loss: 1.186285
 >> iter 7000, loss: 0.857433
 >> iter 8000, loss: 0.729896
 >> iter 9000, loss: 0.555462
 >> iter 10000, loss: 0.727259
   Number of active neurons: 5
 >> iter 11000, loss: 0.711896
 >> iter 12000, loss: 0.526333
 >> iter 13000, loss: 0.486684
 >> iter 14000, loss: 0.509927
 >> iter 15000, loss: 0.393235
 >> iter 16000, loss: 0.458280
 >> iter 17000, loss: 0.374279
 >> iter 18000, loss: 0.427181
 >> iter 19000, loss: 0.531127
 >> iter 20000, loss: 0.585791
   Number of active neurons: 5
 >> iter 21000, loss: 0.510423
 >> iter 22000, loss: 0.467145
 >> iter 23000, loss: 0.535090
 >> iter 24000, loss: 0.390577
 >> iter 25000, loss: 0.501881
 >> iter 26000, loss: 0.376273
 >> iter 27000, loss: 0.406802
 >> iter 28000, loss: 0.538021
 >> iter 29000, loss: 0.511598
 >> iter 30000, loss: 0.565508
   Number of active neurons: 5
 >> iter 31000, loss: 0.526957
 >> iter 32000, loss: 0.451172
 >> iter 33000, loss: 0.492223
 >> iter 34000, loss: 0.536042
 >> iter 35000, loss: 0.647775
 >> iter 36000, loss: 0.449833
 >> iter 37000, loss: 0.587887
 >> iter 38000, loss: 0.857094
 >> iter 39000, loss: 0.587377
 >> iter 40000, loss: 0.584351
   Number of active neurons: 5
 >> iter 41000, loss: 0.425508
 >> iter 42000, loss: 0.383702
 >> iter 43000, loss: 0.310158
 >> iter 44000, loss: 0.419198
 >> iter 45000, loss: 0.325298
 >> iter 46000, loss: 0.269485
 >> iter 47000, loss: 0.398560
 >> iter 48000, loss: 0.429121
 >> iter 49000, loss: 0.400656
 >> iter 50000, loss: 0.400701
   Number of active neurons: 5
 >> iter 51000, loss: 0.531896
 >> iter 52000, loss: 0.464768
 >> iter 53000, loss: 0.421749
 >> iter 54000, loss: 0.456523
 >> iter 55000, loss: 0.345525
 >> iter 56000, loss: 0.400096
 >> iter 57000, loss: 0.549494
 >> iter 58000, loss: 0.423495
 >> iter 59000, loss: 0.440615
 >> iter 60000, loss: 0.530875
   Number of active neurons: 5
 >> iter 61000, loss: 0.541823
 >> iter 62000, loss: 0.561071
 >> iter 63000, loss: 0.498750
 >> iter 64000, loss: 0.534808
 >> iter 65000, loss: 0.447982
 >> iter 66000, loss: 0.469227
 >> iter 67000, loss: 0.441722
 >> iter 68000, loss: 0.332858
 >> iter 69000, loss: 0.575810
 >> iter 70000, loss: 0.294715
   Number of active neurons: 5
 >> iter 71000, loss: 0.420951
 >> iter 72000, loss: 0.442876
 >> iter 73000, loss: 0.497503
 >> iter 74000, loss: 0.460711
 >> iter 75000, loss: 0.347069
 >> iter 76000, loss: 0.427164
 >> iter 77000, loss: 0.288337
 >> iter 78000, loss: 0.461465
 >> iter 79000, loss: 0.468461
 >> iter 80000, loss: 0.346430
   Number of active neurons: 5
 >> iter 81000, loss: 0.373112
 >> iter 82000, loss: 0.357236
 >> iter 83000, loss: 0.488110
 >> iter 84000, loss: 0.485080
 >> iter 85000, loss: 0.501368
 >> iter 86000, loss: 0.467937
 >> iter 87000, loss: 0.432433
 >> iter 88000, loss: 0.465093
 >> iter 89000, loss: 0.585897
 >> iter 90000, loss: 0.463728
   Number of active neurons: 5
 >> iter 91000, loss: 0.496266
 >> iter 92000, loss: 0.355358
 >> iter 93000, loss: 0.320533
 >> iter 94000, loss: 0.442785
 >> iter 95000, loss: 0.496632
 >> iter 96000, loss: 0.504166
 >> iter 97000, loss: 0.399604
 >> iter 98000, loss: 0.415951
 >> iter 99000, loss: 0.368422
 >> iter 100000, loss: 0.292586
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.074219
 >> iter 2000, loss: 12.001279
 >> iter 3000, loss: 6.586531
 >> iter 4000, loss: 3.438569
 >> iter 5000, loss: 2.023594
 >> iter 6000, loss: 1.208392
 >> iter 7000, loss: 0.856659
 >> iter 8000, loss: 0.610594
 >> iter 9000, loss: 0.411504
 >> iter 10000, loss: 0.339111
   Number of active neurons: 5
 >> iter 11000, loss: 0.289582
 >> iter 12000, loss: 0.366812
 >> iter 13000, loss: 0.401398
 >> iter 14000, loss: 0.301385
 >> iter 15000, loss: 0.350650
 >> iter 16000, loss: 0.427086
 >> iter 17000, loss: 0.288780
 >> iter 18000, loss: 0.240978
 >> iter 19000, loss: 0.260929
 >> iter 20000, loss: 0.248969
   Number of active neurons: 4
 >> iter 21000, loss: 0.261228
 >> iter 22000, loss: 0.323283
 >> iter 23000, loss: 0.324187
 >> iter 24000, loss: 0.300861
 >> iter 25000, loss: 0.355008
 >> iter 26000, loss: 0.220408
 >> iter 27000, loss: 0.318208
 >> iter 28000, loss: 0.208862
 >> iter 29000, loss: 0.263655
 >> iter 30000, loss: 0.365388
   Number of active neurons: 4
 >> iter 31000, loss: 0.371097
 >> iter 32000, loss: 0.394922
 >> iter 33000, loss: 0.271497
 >> iter 34000, loss: 0.279799
 >> iter 35000, loss: 0.450521
 >> iter 36000, loss: 0.283761
 >> iter 37000, loss: 0.406339
 >> iter 38000, loss: 0.292547
 >> iter 39000, loss: 0.296422
 >> iter 40000, loss: 0.274204
   Number of active neurons: 4
 >> iter 41000, loss: 0.316895
 >> iter 42000, loss: 0.409005
 >> iter 43000, loss: 0.394454
 >> iter 44000, loss: 0.259892
 >> iter 45000, loss: 0.392512
 >> iter 46000, loss: 0.221763
 >> iter 47000, loss: 0.239009
 >> iter 48000, loss: 0.518153
 >> iter 49000, loss: 0.337814
 >> iter 50000, loss: 0.377936
   Number of active neurons: 4
 >> iter 51000, loss: 0.325672
 >> iter 52000, loss: 0.426192
 >> iter 53000, loss: 0.372651
 >> iter 54000, loss: 0.308546
 >> iter 55000, loss: 0.276756
 >> iter 56000, loss: 0.455060
 >> iter 57000, loss: 0.406724
 >> iter 58000, loss: 0.275463
 >> iter 59000, loss: 0.376841
 >> iter 60000, loss: 0.292150
   Number of active neurons: 4
 >> iter 61000, loss: 0.394130
 >> iter 62000, loss: 0.324445
 >> iter 63000, loss: 0.371105
 >> iter 64000, loss: 0.309935
 >> iter 65000, loss: 0.258510
 >> iter 66000, loss: 0.276115
 >> iter 67000, loss: 0.398800
 >> iter 68000, loss: 0.264118
 >> iter 69000, loss: 0.264948
 >> iter 70000, loss: 0.196292
   Number of active neurons: 4
 >> iter 71000, loss: 0.198533
 >> iter 72000, loss: 0.312903
 >> iter 73000, loss: 0.420025
 >> iter 74000, loss: 0.377182
 >> iter 75000, loss: 0.265844
 >> iter 76000, loss: 0.206040
 >> iter 77000, loss: 0.240450
 >> iter 78000, loss: 0.149825
 >> iter 79000, loss: 0.270157
 >> iter 80000, loss: 0.334057
   Number of active neurons: 4
 >> iter 81000, loss: 0.300726
 >> iter 82000, loss: 0.224829
 >> iter 83000, loss: 0.298685
 >> iter 84000, loss: 0.305961
 >> iter 85000, loss: 0.328825
 >> iter 86000, loss: 0.365510
 >> iter 87000, loss: 0.255340
 >> iter 88000, loss: 0.240836
 >> iter 89000, loss: 0.235880
 >> iter 90000, loss: 0.187872
   Number of active neurons: 4
 >> iter 91000, loss: 0.511157
 >> iter 92000, loss: 0.484950
 >> iter 93000, loss: 0.640796
 >> iter 94000, loss: 0.400220
 >> iter 95000, loss: 0.338226
 >> iter 96000, loss: 0.301608
 >> iter 97000, loss: 0.210720
 >> iter 98000, loss: 0.240020
 >> iter 99000, loss: 0.283846
 >> iter 100000, loss: 0.405225
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 18.953131
 >> iter 2000, loss: 11.232195
 >> iter 3000, loss: 5.446954
 >> iter 4000, loss: 2.593258
 >> iter 5000, loss: 1.699314
 >> iter 6000, loss: 0.869244
 >> iter 7000, loss: 0.611416
 >> iter 8000, loss: 0.406694
 >> iter 9000, loss: 0.486714
 >> iter 10000, loss: 0.423299
   Number of active neurons: 6
 >> iter 11000, loss: 0.358599
 >> iter 12000, loss: 0.494628
 >> iter 13000, loss: 0.502819
 >> iter 14000, loss: 0.507716
 >> iter 15000, loss: 0.425895
 >> iter 16000, loss: 0.346889
 >> iter 17000, loss: 0.542629
 >> iter 18000, loss: 0.357428
 >> iter 19000, loss: 0.521396
 >> iter 20000, loss: 0.453455
   Number of active neurons: 5
 >> iter 21000, loss: 0.356078
 >> iter 22000, loss: 0.384219
 >> iter 23000, loss: 0.503036
 >> iter 24000, loss: 0.497394
 >> iter 25000, loss: 0.464678
 >> iter 26000, loss: 0.415837
 >> iter 27000, loss: 0.523061
 >> iter 28000, loss: 0.446549
 >> iter 29000, loss: 0.509497
 >> iter 30000, loss: 0.628919
   Number of active neurons: 5
 >> iter 31000, loss: 0.581793
 >> iter 32000, loss: 0.593572
 >> iter 33000, loss: 0.462243
 >> iter 34000, loss: 0.344856
 >> iter 35000, loss: 0.340051
 >> iter 36000, loss: 0.353151
 >> iter 37000, loss: 0.404302
 >> iter 38000, loss: 0.398022
 >> iter 39000, loss: 0.222331
 >> iter 40000, loss: 0.398247
   Number of active neurons: 5
 >> iter 41000, loss: 0.537924
 >> iter 42000, loss: 0.478188
 >> iter 43000, loss: 0.411444
 >> iter 44000, loss: 0.310493
 >> iter 45000, loss: 0.375749
 >> iter 46000, loss: 0.405734
 >> iter 47000, loss: 0.394523
 >> iter 48000, loss: 0.392267
 >> iter 49000, loss: 0.543087
 >> iter 50000, loss: 0.420824
   Number of active neurons: 4
 >> iter 51000, loss: 0.374611
 >> iter 52000, loss: 0.315287
 >> iter 53000, loss: 0.307690
 >> iter 54000, loss: 0.397206
 >> iter 55000, loss: 0.367972
 >> iter 56000, loss: 0.336987
 >> iter 57000, loss: 0.402250
 >> iter 58000, loss: 0.209924
 >> iter 59000, loss: 0.407020
 >> iter 60000, loss: 0.441648
   Number of active neurons: 4
 >> iter 61000, loss: 0.438997
 >> iter 62000, loss: 0.293846
 >> iter 63000, loss: 0.212358
 >> iter 64000, loss: 0.313902
 >> iter 65000, loss: 0.385277
 >> iter 66000, loss: 0.505979
 >> iter 67000, loss: 0.463059
 >> iter 68000, loss: 0.428639
 >> iter 69000, loss: 0.297751
 >> iter 70000, loss: 0.200780
   Number of active neurons: 4
 >> iter 71000, loss: 0.218092
 >> iter 72000, loss: 0.396991
 >> iter 73000, loss: 0.495818
 >> iter 74000, loss: 0.474884
 >> iter 75000, loss: 0.357045
 >> iter 76000, loss: 0.190701
 >> iter 77000, loss: 0.323265
 >> iter 78000, loss: 0.270351
 >> iter 79000, loss: 0.361712
 >> iter 80000, loss: 0.332392
   Number of active neurons: 4
 >> iter 81000, loss: 0.437714
 >> iter 82000, loss: 0.413222
 >> iter 83000, loss: 0.447621
 >> iter 84000, loss: 0.418178
 >> iter 85000, loss: 0.535677
 >> iter 86000, loss: 0.419110
 >> iter 87000, loss: 0.326125
 >> iter 88000, loss: 0.368833
 >> iter 89000, loss: 0.302118
 >> iter 90000, loss: 0.323718
   Number of active neurons: 4
 >> iter 91000, loss: 0.387009
 >> iter 92000, loss: 0.380694
 >> iter 93000, loss: 0.445022
 >> iter 94000, loss: 0.398785
 >> iter 95000, loss: 0.637450
 >> iter 96000, loss: 0.535112
 >> iter 97000, loss: 0.383105
 >> iter 98000, loss: 0.319215
 >> iter 99000, loss: 0.403848
 >> iter 100000, loss: 0.360410
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 19.0920605293
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.319870
 >> iter 2000, loss: 11.511194
 >> iter 3000, loss: 5.388667
 >> iter 4000, loss: 2.439920
 >> iter 5000, loss: 1.264669
 >> iter 6000, loss: 0.911151
 >> iter 7000, loss: 0.530150
 >> iter 8000, loss: 0.420626
 >> iter 9000, loss: 0.365811
 >> iter 10000, loss: 0.357943
   Number of active neurons: 7
 >> iter 11000, loss: 0.385012
 >> iter 12000, loss: 0.277001
 >> iter 13000, loss: 0.205769
 >> iter 14000, loss: 0.336112
 >> iter 15000, loss: 0.424665
 >> iter 16000, loss: 0.415865
 >> iter 17000, loss: 0.528826
 >> iter 18000, loss: 0.365857
 >> iter 19000, loss: 0.293389
 >> iter 20000, loss: 0.250135
   Number of active neurons: 7
 >> iter 21000, loss: 0.300325
 >> iter 22000, loss: 0.272441
 >> iter 23000, loss: 0.355668
 >> iter 24000, loss: 0.287242
 >> iter 25000, loss: 0.376045
 >> iter 26000, loss: 0.343579
 >> iter 27000, loss: 0.300927
 >> iter 28000, loss: 0.250684
 >> iter 29000, loss: 0.324854
 >> iter 30000, loss: 0.365625
   Number of active neurons: 7
 >> iter 31000, loss: 0.253730
 >> iter 32000, loss: 0.256638
 >> iter 33000, loss: 0.321975
 >> iter 34000, loss: 0.441287
 >> iter 35000, loss: 0.269039
 >> iter 36000, loss: 0.251132
 >> iter 37000, loss: 0.210417
 >> iter 38000, loss: 0.320101
 >> iter 39000, loss: 0.245265
 >> iter 40000, loss: 0.206543
   Number of active neurons: 7
 >> iter 41000, loss: 0.230988
 >> iter 42000, loss: 0.233311
 >> iter 43000, loss: 0.159115
 >> iter 44000, loss: 0.284008
 >> iter 45000, loss: 0.418469
 >> iter 46000, loss: 0.402815
 >> iter 47000, loss: 0.312991
 >> iter 48000, loss: 0.336833
 >> iter 49000, loss: 0.267966
 >> iter 50000, loss: 0.243008
   Number of active neurons: 6
 >> iter 51000, loss: 0.228591
 >> iter 52000, loss: 0.242447
 >> iter 53000, loss: 0.176360
 >> iter 54000, loss: 0.307714
 >> iter 55000, loss: 0.189672
 >> iter 56000, loss: 0.214205
 >> iter 57000, loss: 0.241704
 >> iter 58000, loss: 0.186373
 >> iter 59000, loss: 0.304078
 >> iter 60000, loss: 0.221905
   Number of active neurons: 6
 >> iter 61000, loss: 0.296588
 >> iter 62000, loss: 0.225298
 >> iter 63000, loss: 0.387478
 >> iter 64000, loss: 0.218575
 >> iter 65000, loss: 0.150843
 >> iter 66000, loss: 0.144270
 >> iter 67000, loss: 0.189912
 >> iter 68000, loss: 0.213076
 >> iter 69000, loss: 0.302979
 >> iter 70000, loss: 0.271331
   Number of active neurons: 5
 >> iter 71000, loss: 0.205522
 >> iter 72000, loss: 0.139082
 >> iter 73000, loss: 0.124967
 >> iter 74000, loss: 0.114360
 >> iter 75000, loss: 0.178595
 >> iter 76000, loss: 0.222879
 >> iter 77000, loss: 0.280852
 >> iter 78000, loss: 0.193003
 >> iter 79000, loss: 0.334404
 >> iter 80000, loss: 0.172595
   Number of active neurons: 5
 >> iter 81000, loss: 0.220036
 >> iter 82000, loss: 0.209225
 >> iter 83000, loss: 0.207945
 >> iter 84000, loss: 0.171449
 >> iter 85000, loss: 0.191717
 >> iter 86000, loss: 0.356039
 >> iter 87000, loss: 0.338814
 >> iter 88000, loss: 0.230618
 >> iter 89000, loss: 0.184069
 >> iter 90000, loss: 0.214662
   Number of active neurons: 4
 >> iter 91000, loss: 0.224227
 >> iter 92000, loss: 0.235835
 >> iter 93000, loss: 0.206351
 >> iter 94000, loss: 0.298590
 >> iter 95000, loss: 0.302206
 >> iter 96000, loss: 0.294752
 >> iter 97000, loss: 0.201584
 >> iter 98000, loss: 0.227316
 >> iter 99000, loss: 0.192643
 >> iter 100000, loss: 0.336869
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 19.123645
 >> iter 2000, loss: 13.907545
 >> iter 3000, loss: 11.220477
 >> iter 4000, loss: 7.714860
 >> iter 5000, loss: 4.446673
 >> iter 6000, loss: 2.701892
 >> iter 7000, loss: 1.685482
 >> iter 8000, loss: 1.209564
 >> iter 9000, loss: 1.244360
 >> iter 10000, loss: 1.002809
   Number of active neurons: 7
 >> iter 11000, loss: 1.757768
 >> iter 12000, loss: 1.099612
 >> iter 13000, loss: 0.884573
 >> iter 14000, loss: 0.765706
 >> iter 15000, loss: 0.477052
 >> iter 16000, loss: 0.532172
 >> iter 17000, loss: 0.526367
 >> iter 18000, loss: 0.437412
 >> iter 19000, loss: 0.409369
 >> iter 20000, loss: 0.332147
   Number of active neurons: 7
 >> iter 21000, loss: 0.349037
 >> iter 22000, loss: 0.252131
 >> iter 23000, loss: 0.232648
 >> iter 24000, loss: 0.280238
 >> iter 25000, loss: 0.181321
 >> iter 26000, loss: 0.290136
 >> iter 27000, loss: 0.431921
 >> iter 28000, loss: 0.563720
 >> iter 29000, loss: 0.372017
 >> iter 30000, loss: 0.302335
   Number of active neurons: 7
 >> iter 31000, loss: 0.234377
 >> iter 32000, loss: 0.293235
 >> iter 33000, loss: 0.372212
 >> iter 34000, loss: 0.282681
 >> iter 35000, loss: 0.349787
 >> iter 36000, loss: 0.255902
 >> iter 37000, loss: 0.270645
 >> iter 38000, loss: 0.245681
 >> iter 39000, loss: 0.371418
 >> iter 40000, loss: 0.411416
   Number of active neurons: 7
 >> iter 41000, loss: 0.363509
 >> iter 42000, loss: 0.284103
 >> iter 43000, loss: 0.210104
 >> iter 44000, loss: 0.175001
 >> iter 45000, loss: 0.351835
 >> iter 46000, loss: 0.302459
 >> iter 47000, loss: 0.510406
 >> iter 48000, loss: 0.454897
 >> iter 49000, loss: 0.338396
 >> iter 50000, loss: 0.209924
   Number of active neurons: 7
 >> iter 51000, loss: 0.305093
 >> iter 52000, loss: 0.262890
 >> iter 53000, loss: 0.246116
 >> iter 54000, loss: 0.363419
 >> iter 55000, loss: 0.306292
 >> iter 56000, loss: 0.254551
 >> iter 57000, loss: 0.218143
 >> iter 58000, loss: 0.241279
 >> iter 59000, loss: 0.269498
 >> iter 60000, loss: 0.341862
   Number of active neurons: 7
 >> iter 61000, loss: 0.235260
 >> iter 62000, loss: 0.262663
 >> iter 63000, loss: 0.248011
 >> iter 64000, loss: 0.238604
 >> iter 65000, loss: 0.362220
 >> iter 66000, loss: 0.234317
 >> iter 67000, loss: 0.217039
 >> iter 68000, loss: 0.306481
 >> iter 69000, loss: 0.288600
 >> iter 70000, loss: 0.350928
   Number of active neurons: 5
 >> iter 71000, loss: 0.533479
 >> iter 72000, loss: 0.421600
 >> iter 73000, loss: 0.311877
 >> iter 74000, loss: 0.270924
 >> iter 75000, loss: 0.265784
 >> iter 76000, loss: 0.215509
 >> iter 77000, loss: 0.229146
 >> iter 78000, loss: 0.200207
 >> iter 79000, loss: 0.242709
 >> iter 80000, loss: 0.312434
   Number of active neurons: 5
 >> iter 81000, loss: 0.192907
 >> iter 82000, loss: 0.320060
 >> iter 83000, loss: 0.257967
 >> iter 84000, loss: 0.265166
 >> iter 85000, loss: 0.148238
 >> iter 86000, loss: 0.186985
 >> iter 87000, loss: 0.326011
 >> iter 88000, loss: 0.279247
 >> iter 89000, loss: 0.349545
 >> iter 90000, loss: 0.214619
   Number of active neurons: 5
 >> iter 91000, loss: 0.317773
 >> iter 92000, loss: 0.278123
 >> iter 93000, loss: 0.205705
 >> iter 94000, loss: 0.168184
 >> iter 95000, loss: 0.183652
 >> iter 96000, loss: 0.255706
 >> iter 97000, loss: 0.179497
 >> iter 98000, loss: 0.325766
 >> iter 99000, loss: 0.340948
 >> iter 100000, loss: 0.201252
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.380377
 >> iter 2000, loss: 13.808510
 >> iter 3000, loss: 9.844967
 >> iter 4000, loss: 5.317661
 >> iter 5000, loss: 3.029994
 >> iter 6000, loss: 1.693123
 >> iter 7000, loss: 1.169358
 >> iter 8000, loss: 0.811010
 >> iter 9000, loss: 0.826173
 >> iter 10000, loss: 0.675192
   Number of active neurons: 7
 >> iter 11000, loss: 0.551346
 >> iter 12000, loss: 0.498562
 >> iter 13000, loss: 0.556707
 >> iter 14000, loss: 0.558489
 >> iter 15000, loss: 0.535997
 >> iter 16000, loss: 0.533235
 >> iter 17000, loss: 0.596627
 >> iter 18000, loss: 0.609489
 >> iter 19000, loss: 0.594034
 >> iter 20000, loss: 0.641611
   Number of active neurons: 7
 >> iter 21000, loss: 0.535447
 >> iter 22000, loss: 0.489543
 >> iter 23000, loss: 0.385814
 >> iter 24000, loss: 0.530259
 >> iter 25000, loss: 0.638677
 >> iter 26000, loss: 0.402092
 >> iter 27000, loss: 0.531066
 >> iter 28000, loss: 0.354680
 >> iter 29000, loss: 0.504720
 >> iter 30000, loss: 0.488042
   Number of active neurons: 7
 >> iter 31000, loss: 0.558755
 >> iter 32000, loss: 0.473175
 >> iter 33000, loss: 0.616188
 >> iter 34000, loss: 0.492248
 >> iter 35000, loss: 0.610437
 >> iter 36000, loss: 0.528625
 >> iter 37000, loss: 0.624690
 >> iter 38000, loss: 0.511650
 >> iter 39000, loss: 0.734492
 >> iter 40000, loss: 0.561857
   Number of active neurons: 7
 >> iter 41000, loss: 0.782553
 >> iter 42000, loss: 0.632931
 >> iter 43000, loss: 0.685424
 >> iter 44000, loss: 0.465497
 >> iter 45000, loss: 0.617082
 >> iter 46000, loss: 0.487062
 >> iter 47000, loss: 0.486108
 >> iter 48000, loss: 0.486190
 >> iter 49000, loss: 0.424735
 >> iter 50000, loss: 0.424323
   Number of active neurons: 7
 >> iter 51000, loss: 0.481308
 >> iter 52000, loss: 0.442386
 >> iter 53000, loss: 0.660145
 >> iter 54000, loss: 0.617959
 >> iter 55000, loss: 0.522686
 >> iter 56000, loss: 0.411037
 >> iter 57000, loss: 0.457864
 >> iter 58000, loss: 0.514836
 >> iter 59000, loss: 0.600329
 >> iter 60000, loss: 0.510006
   Number of active neurons: 7
 >> iter 61000, loss: 0.417799
 >> iter 62000, loss: 0.345913
 >> iter 63000, loss: 0.489620
 >> iter 64000, loss: 0.644692
 >> iter 65000, loss: 0.460429
 >> iter 66000, loss: 0.464102
 >> iter 67000, loss: 0.544879
 >> iter 68000, loss: 0.546314
 >> iter 69000, loss: 0.526902
 >> iter 70000, loss: 0.462655
   Number of active neurons: 6
 >> iter 71000, loss: 0.373008
 >> iter 72000, loss: 0.485442
 >> iter 73000, loss: 0.347173
 >> iter 74000, loss: 0.513293
 >> iter 75000, loss: 0.724011
 >> iter 76000, loss: 0.674645
 >> iter 77000, loss: 0.569354
 >> iter 78000, loss: 0.506804
 >> iter 79000, loss: 0.627105
 >> iter 80000, loss: 0.519207
   Number of active neurons: 6
 >> iter 81000, loss: 0.440797
 >> iter 82000, loss: 0.413008
 >> iter 83000, loss: 0.424631
 >> iter 84000, loss: 0.525742
 >> iter 85000, loss: 0.513713
 >> iter 86000, loss: 0.445666
 >> iter 87000, loss: 0.435322
 >> iter 88000, loss: 0.584310
 >> iter 89000, loss: 0.447703
 >> iter 90000, loss: 0.530391
   Number of active neurons: 6
 >> iter 91000, loss: 0.498826
 >> iter 92000, loss: 0.463013
 >> iter 93000, loss: 0.433517
 >> iter 94000, loss: 0.591565
 >> iter 95000, loss: 0.511458
 >> iter 96000, loss: 0.465940
 >> iter 97000, loss: 0.657901
 >> iter 98000, loss: 0.438670
 >> iter 99000, loss: 0.592213
 >> iter 100000, loss: 0.496919
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.228037
 >> iter 2000, loss: 11.841218
 >> iter 3000, loss: 6.469952
 >> iter 4000, loss: 3.368124
 >> iter 5000, loss: 2.003670
 >> iter 6000, loss: 1.242851
 >> iter 7000, loss: 0.863326
 >> iter 8000, loss: 0.576668
 >> iter 9000, loss: 0.669450
 >> iter 10000, loss: 0.582324
   Number of active neurons: 7
 >> iter 11000, loss: 0.467587
 >> iter 12000, loss: 0.464854
 >> iter 13000, loss: 0.602319
 >> iter 14000, loss: 0.711528
 >> iter 15000, loss: 0.799324
 >> iter 16000, loss: 0.840839
 >> iter 17000, loss: 0.680524
 >> iter 18000, loss: 0.447888
 >> iter 19000, loss: 0.489809
 >> iter 20000, loss: 0.408085
   Number of active neurons: 7
 >> iter 21000, loss: 0.591034
 >> iter 22000, loss: 0.415145
 >> iter 23000, loss: 0.587156
 >> iter 24000, loss: 0.479715
 >> iter 25000, loss: 0.565853
 >> iter 26000, loss: 0.446644
 >> iter 27000, loss: 0.449782
 >> iter 28000, loss: 0.465769
 >> iter 29000, loss: 0.604404
 >> iter 30000, loss: 0.432016
   Number of active neurons: 7
 >> iter 31000, loss: 0.413020
 >> iter 32000, loss: 0.405552
 >> iter 33000, loss: 0.419225
 >> iter 34000, loss: 0.483908
 >> iter 35000, loss: 0.516209
 >> iter 36000, loss: 0.588416
 >> iter 37000, loss: 0.445991
 >> iter 38000, loss: 0.406799
 >> iter 39000, loss: 0.555022
 >> iter 40000, loss: 0.501005
   Number of active neurons: 7
 >> iter 41000, loss: 0.392752
 >> iter 42000, loss: 0.239093
 >> iter 43000, loss: 0.215247
 >> iter 44000, loss: 0.283462
 >> iter 45000, loss: 0.476094
 >> iter 46000, loss: 0.454010
 >> iter 47000, loss: 0.461917
 >> iter 48000, loss: 0.358733
 >> iter 49000, loss: 0.466535
 >> iter 50000, loss: 0.386967
   Number of active neurons: 7
 >> iter 51000, loss: 0.604574
 >> iter 52000, loss: 0.460556
 >> iter 53000, loss: 0.476914
 >> iter 54000, loss: 0.415158
 >> iter 55000, loss: 0.386680
 >> iter 56000, loss: 0.308869
 >> iter 57000, loss: 0.344718
 >> iter 58000, loss: 0.308193
 >> iter 59000, loss: 0.320036
 >> iter 60000, loss: 0.543086
   Number of active neurons: 6
 >> iter 61000, loss: 0.494324
 >> iter 62000, loss: 0.405437
 >> iter 63000, loss: 0.383725
 >> iter 64000, loss: 0.369922
 >> iter 65000, loss: 0.444320
 >> iter 66000, loss: 0.399107
 >> iter 67000, loss: 0.302989
 >> iter 68000, loss: 0.232521
 >> iter 69000, loss: 0.338237
 >> iter 70000, loss: 0.456210
   Number of active neurons: 6
 >> iter 71000, loss: 0.415550
 >> iter 72000, loss: 0.306562
 >> iter 73000, loss: 0.340217
 >> iter 74000, loss: 0.433794
 >> iter 75000, loss: 0.505325
 >> iter 76000, loss: 0.425597
 >> iter 77000, loss: 0.391672
 >> iter 78000, loss: 0.497537
 >> iter 79000, loss: 0.357736
 >> iter 80000, loss: 0.241414
   Number of active neurons: 6
 >> iter 81000, loss: 0.408324
 >> iter 82000, loss: 0.365098
 >> iter 83000, loss: 0.402978
 >> iter 84000, loss: 0.360052
 >> iter 85000, loss: 0.324744
 >> iter 86000, loss: 0.323473
 >> iter 87000, loss: 0.332921
 >> iter 88000, loss: 0.538833
 >> iter 89000, loss: 0.450777
 >> iter 90000, loss: 0.436020
   Number of active neurons: 6
 >> iter 91000, loss: 0.344212
 >> iter 92000, loss: 0.246704
 >> iter 93000, loss: 0.246452
 >> iter 94000, loss: 0.211706
 >> iter 95000, loss: 0.400431
 >> iter 96000, loss: 0.423233
 >> iter 97000, loss: 0.551523
 >> iter 98000, loss: 0.463410
 >> iter 99000, loss: 0.446085
 >> iter 100000, loss: 0.390856
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

