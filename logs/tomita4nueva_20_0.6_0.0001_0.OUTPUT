 > Problema: tomita4nueva
 > Args:
   - Hidden size: 20
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.337352
 >> iter 2000, loss: 8.605857
 >> iter 3000, loss: 3.724763
 >> iter 4000, loss: 1.795205
 >> iter 5000, loss: 0.827199
 >> iter 6000, loss: 0.604077
 >> iter 7000, loss: 0.363232
 >> iter 8000, loss: 0.314199
 >> iter 9000, loss: 0.483474
 >> iter 10000, loss: 0.381855
   Number of active neurons: 6
 >> iter 11000, loss: 0.465791
 >> iter 12000, loss: 0.376952
 >> iter 13000, loss: 0.271302
 >> iter 14000, loss: 0.319431
 >> iter 15000, loss: 0.531118
 >> iter 16000, loss: 0.458933
 >> iter 17000, loss: 0.484550
 >> iter 18000, loss: 0.225145
 >> iter 19000, loss: 0.229482
 >> iter 20000, loss: 0.225918
   Number of active neurons: 5
 >> iter 21000, loss: 0.333750
 >> iter 22000, loss: 0.348415
 >> iter 23000, loss: 0.215870
 >> iter 24000, loss: 0.213209
 >> iter 25000, loss: 0.212456
 >> iter 26000, loss: 0.395929
 >> iter 27000, loss: 0.332662
 >> iter 28000, loss: 0.283500
 >> iter 29000, loss: 0.375865
 >> iter 30000, loss: 0.290233
   Number of active neurons: 4
 >> iter 31000, loss: 0.546649
 >> iter 32000, loss: 0.451656
 >> iter 33000, loss: 0.280922
 >> iter 34000, loss: 0.224835
 >> iter 35000, loss: 0.168246
 >> iter 36000, loss: 0.253891
 >> iter 37000, loss: 0.202559
 >> iter 38000, loss: 0.240310
 >> iter 39000, loss: 0.352521
 >> iter 40000, loss: 0.334403
   Number of active neurons: 4
 >> iter 41000, loss: 0.311835
 >> iter 42000, loss: 0.268411
 >> iter 43000, loss: 0.288311
 >> iter 44000, loss: 0.225569
 >> iter 45000, loss: 0.186201
 >> iter 46000, loss: 0.213474
 >> iter 47000, loss: 0.471729
 >> iter 48000, loss: 0.304093
 >> iter 49000, loss: 0.319589
 >> iter 50000, loss: 0.389286
   Number of active neurons: 4
 >> iter 51000, loss: 0.309548
 >> iter 52000, loss: 0.283832
 >> iter 53000, loss: 0.390923
 >> iter 54000, loss: 0.348426
 >> iter 55000, loss: 0.233887
 >> iter 56000, loss: 0.179448
 >> iter 57000, loss: 0.235976
 >> iter 58000, loss: 0.111646
 >> iter 59000, loss: 0.306214
 >> iter 60000, loss: 0.207524
   Number of active neurons: 3
 >> iter 61000, loss: 0.170236
 >> iter 62000, loss: 0.232039
 >> iter 63000, loss: 0.427588
 >> iter 64000, loss: 0.399028
 >> iter 65000, loss: 0.198542
 >> iter 66000, loss: 0.147415
 >> iter 67000, loss: 0.290650
 >> iter 68000, loss: 0.342249
 >> iter 69000, loss: 0.291487
 >> iter 70000, loss: 0.481176
   Number of active neurons: 3
 >> iter 71000, loss: 0.281719
 >> iter 72000, loss: 0.177848
 >> iter 73000, loss: 0.102804
 >> iter 74000, loss: 0.197818
 >> iter 75000, loss: 0.169412
 >> iter 76000, loss: 0.167653
 >> iter 77000, loss: 0.277461
 >> iter 78000, loss: 0.262718
 >> iter 79000, loss: 0.215484
 >> iter 80000, loss: 0.262930
   Number of active neurons: 3
 >> iter 81000, loss: 0.268747
 >> iter 82000, loss: 0.279755
 >> iter 83000, loss: 0.164871
 >> iter 84000, loss: 0.163322
 >> iter 85000, loss: 0.320955
 >> iter 86000, loss: 0.324542
 >> iter 87000, loss: 0.284728
 >> iter 88000, loss: 0.330183
 >> iter 89000, loss: 0.242475
 >> iter 90000, loss: 0.555170
   Number of active neurons: 3
 >> iter 91000, loss: 0.404391
 >> iter 92000, loss: 0.388240
 >> iter 93000, loss: 0.395599
 >> iter 94000, loss: 0.347379
 >> iter 95000, loss: 0.338429
 >> iter 96000, loss: 0.292477
 >> iter 97000, loss: 0.238340
 >> iter 98000, loss: 0.145745
 >> iter 99000, loss: 0.359157
 >> iter 100000, loss: 0.246188
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.671081
 >> iter 2000, loss: 9.094134
 >> iter 3000, loss: 3.988549
 >> iter 4000, loss: 1.994787
 >> iter 5000, loss: 0.911093
 >> iter 6000, loss: 0.703730
 >> iter 7000, loss: 0.491242
 >> iter 8000, loss: 0.482296
 >> iter 9000, loss: 0.279986
 >> iter 10000, loss: 0.429808
   Number of active neurons: 6
 >> iter 11000, loss: 0.577880
 >> iter 12000, loss: 0.325493
 >> iter 13000, loss: 0.339798
 >> iter 14000, loss: 0.468472
 >> iter 15000, loss: 0.327207
 >> iter 16000, loss: 0.414725
 >> iter 17000, loss: 0.395340
 >> iter 18000, loss: 0.559311
 >> iter 19000, loss: 0.398154
 >> iter 20000, loss: 0.306930
   Number of active neurons: 6
 >> iter 21000, loss: 0.459178
 >> iter 22000, loss: 0.671586
 >> iter 23000, loss: 0.454008
 >> iter 24000, loss: 0.330008
 >> iter 25000, loss: 0.219843
 >> iter 26000, loss: 0.337145
 >> iter 27000, loss: 0.381325
 >> iter 28000, loss: 0.356072
 >> iter 29000, loss: 0.295462
 >> iter 30000, loss: 0.578705
   Number of active neurons: 6
 >> iter 31000, loss: 0.437139
 >> iter 32000, loss: 0.540695
 >> iter 33000, loss: 0.391056
 >> iter 34000, loss: 0.363981
 >> iter 35000, loss: 0.496145
 >> iter 36000, loss: 0.699891
 >> iter 37000, loss: 0.459700
 >> iter 38000, loss: 0.308498
 >> iter 39000, loss: 0.241193
 >> iter 40000, loss: 0.308947
   Number of active neurons: 5
 >> iter 41000, loss: 0.250743
 >> iter 42000, loss: 0.352116
 >> iter 43000, loss: 0.256661
 >> iter 44000, loss: 0.274055
 >> iter 45000, loss: 0.260935
 >> iter 46000, loss: 0.200711
 >> iter 47000, loss: 0.182004
 >> iter 48000, loss: 0.248424
 >> iter 49000, loss: 0.336602
 >> iter 50000, loss: 0.267692
   Number of active neurons: 5
 >> iter 51000, loss: 0.355117
 >> iter 52000, loss: 0.356795
 >> iter 53000, loss: 0.221129
 >> iter 54000, loss: 0.244925
 >> iter 55000, loss: 0.223025
 >> iter 56000, loss: 0.227000
 >> iter 57000, loss: 0.427815
 >> iter 58000, loss: 0.430270
 >> iter 59000, loss: 0.332745
 >> iter 60000, loss: 0.287103
   Number of active neurons: 4
 >> iter 61000, loss: 0.326753
 >> iter 62000, loss: 0.232247
 >> iter 63000, loss: 0.291488
 >> iter 64000, loss: 0.344003
 >> iter 65000, loss: 0.259862
 >> iter 66000, loss: 0.370927
 >> iter 67000, loss: 0.345626
 >> iter 68000, loss: 0.184941
 >> iter 69000, loss: 0.375232
 >> iter 70000, loss: 0.303712
   Number of active neurons: 4
 >> iter 71000, loss: 0.279953
 >> iter 72000, loss: 0.362163
 >> iter 73000, loss: 0.177917
 >> iter 74000, loss: 0.157942
 >> iter 75000, loss: 0.185700
 >> iter 76000, loss: 0.323819
 >> iter 77000, loss: 0.285110
 >> iter 78000, loss: 0.309826
 >> iter 79000, loss: 0.276053
 >> iter 80000, loss: 0.315549
   Number of active neurons: 4
 >> iter 81000, loss: 0.242808
 >> iter 82000, loss: 0.171077
 >> iter 83000, loss: 0.175336
 >> iter 84000, loss: 0.179148
 >> iter 85000, loss: 0.226123
 >> iter 86000, loss: 0.160281
 >> iter 87000, loss: 0.201873
 >> iter 88000, loss: 0.357991
 >> iter 89000, loss: 0.330582
 >> iter 90000, loss: 0.219139
   Number of active neurons: 4
 >> iter 91000, loss: 0.299706
 >> iter 92000, loss: 0.233721
 >> iter 93000, loss: 0.456649
 >> iter 94000, loss: 0.332228
 >> iter 95000, loss: 0.210902
 >> iter 96000, loss: 0.291043
 >> iter 97000, loss: 0.159448
 >> iter 98000, loss: 0.101266
 >> iter 99000, loss: 0.225992
 >> iter 100000, loss: 0.214930
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 18.000515
 >> iter 2000, loss: 9.125027
 >> iter 3000, loss: 3.949986
 >> iter 4000, loss: 1.785788
 >> iter 5000, loss: 1.057481
 >> iter 6000, loss: 0.517968
 >> iter 7000, loss: 0.656252
 >> iter 8000, loss: 0.505740
 >> iter 9000, loss: 0.530331
 >> iter 10000, loss: 0.506285
   Number of active neurons: 9
 >> iter 11000, loss: 0.305430
 >> iter 12000, loss: 0.287259
 >> iter 13000, loss: 0.292060
 >> iter 14000, loss: 0.194086
 >> iter 15000, loss: 0.277984
 >> iter 16000, loss: 0.221067
 >> iter 17000, loss: 0.374121
 >> iter 18000, loss: 0.353545
 >> iter 19000, loss: 0.416387
 >> iter 20000, loss: 0.452772
   Number of active neurons: 7
 >> iter 21000, loss: 0.442557
 >> iter 22000, loss: 0.320270
 >> iter 23000, loss: 0.400781
 >> iter 24000, loss: 0.452683
 >> iter 25000, loss: 0.468415
 >> iter 26000, loss: 0.357360
 >> iter 27000, loss: 0.266827
 >> iter 28000, loss: 0.251555
 >> iter 29000, loss: 0.271745
 >> iter 30000, loss: 0.477621
   Number of active neurons: 7
 >> iter 31000, loss: 0.311526
 >> iter 32000, loss: 0.327777
 >> iter 33000, loss: 0.199955
 >> iter 34000, loss: 0.310651
 >> iter 35000, loss: 0.418724
 >> iter 36000, loss: 0.253110
 >> iter 37000, loss: 0.148841
 >> iter 38000, loss: 0.378072
 >> iter 39000, loss: 0.312347
 >> iter 40000, loss: 0.547963
   Number of active neurons: 5
 >> iter 41000, loss: 0.457604
 >> iter 42000, loss: 0.340221
 >> iter 43000, loss: 0.505717
 >> iter 44000, loss: 0.266050
 >> iter 45000, loss: 0.268858
 >> iter 46000, loss: 0.202379
 >> iter 47000, loss: 0.281126
 >> iter 48000, loss: 0.338970
 >> iter 49000, loss: 0.305912
 >> iter 50000, loss: 0.370235
   Number of active neurons: 5
 >> iter 51000, loss: 0.394495
 >> iter 52000, loss: 0.291325
 >> iter 53000, loss: 0.179815
 >> iter 54000, loss: 0.385040
 >> iter 55000, loss: 0.285093
 >> iter 56000, loss: 0.280167
 >> iter 57000, loss: 0.400130
 >> iter 58000, loss: 0.233249
 >> iter 59000, loss: 0.257138
 >> iter 60000, loss: 0.330010
   Number of active neurons: 5
 >> iter 61000, loss: 0.328159
 >> iter 62000, loss: 0.283859
 >> iter 63000, loss: 0.199052
 >> iter 64000, loss: 0.095405
 >> iter 65000, loss: 0.221545
 >> iter 66000, loss: 0.160804
 >> iter 67000, loss: 0.213486
 >> iter 68000, loss: 0.388797
 >> iter 69000, loss: 0.335521
 >> iter 70000, loss: 0.194700
   Number of active neurons: 5
 >> iter 71000, loss: 0.333004
 >> iter 72000, loss: 0.346891
 >> iter 73000, loss: 0.250385
 >> iter 74000, loss: 0.380681
 >> iter 75000, loss: 0.329677
 >> iter 76000, loss: 0.294769
 >> iter 77000, loss: 0.423552
 >> iter 78000, loss: 0.308672
 >> iter 79000, loss: 0.208625
 >> iter 80000, loss: 0.316763
   Number of active neurons: 4
 >> iter 81000, loss: 0.209776
 >> iter 82000, loss: 0.170389
 >> iter 83000, loss: 0.207471
 >> iter 84000, loss: 0.326300
 >> iter 85000, loss: 0.279624
 >> iter 86000, loss: 0.207540
 >> iter 87000, loss: 0.176179
 >> iter 88000, loss: 0.185820
 >> iter 89000, loss: 0.288595
 >> iter 90000, loss: 0.268101
   Number of active neurons: 4
 >> iter 91000, loss: 0.244674
 >> iter 92000, loss: 0.335952
 >> iter 93000, loss: 0.261367
 >> iter 94000, loss: 0.179873
 >> iter 95000, loss: 0.132434
 >> iter 96000, loss: 0.336596
 >> iter 97000, loss: 0.274094
 >> iter 98000, loss: 0.244428
 >> iter 99000, loss: 0.313988
 >> iter 100000, loss: 0.179364
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 17.570276
 >> iter 2000, loss: 8.542555
 >> iter 3000, loss: 3.730012
 >> iter 4000, loss: 2.119642
 >> iter 5000, loss: 1.518489
 >> iter 6000, loss: 0.917673
 >> iter 7000, loss: 0.664640
 >> iter 8000, loss: 0.442748
 >> iter 9000, loss: 0.306808
 >> iter 10000, loss: 0.493754
   Number of active neurons: 5
 >> iter 11000, loss: 0.447832
 >> iter 12000, loss: 0.335594
 >> iter 13000, loss: 0.411689
 >> iter 14000, loss: 0.580862
 >> iter 15000, loss: 0.341772
 >> iter 16000, loss: 0.508982
 >> iter 17000, loss: 0.435237
 >> iter 18000, loss: 0.304353
 >> iter 19000, loss: 0.218408
 >> iter 20000, loss: 0.498414
   Number of active neurons: 4
 >> iter 21000, loss: 0.401836
 >> iter 22000, loss: 0.271026
 >> iter 23000, loss: 0.331936
 >> iter 24000, loss: 0.313632
 >> iter 25000, loss: 0.178416
 >> iter 26000, loss: 0.275382
 >> iter 27000, loss: 0.195152
 >> iter 28000, loss: 0.156719
 >> iter 29000, loss: 0.213811
 >> iter 30000, loss: 0.358540
   Number of active neurons: 3
 >> iter 31000, loss: 0.258738
 >> iter 32000, loss: 0.245988
 >> iter 33000, loss: 0.364845
 >> iter 34000, loss: 0.368929
 >> iter 35000, loss: 0.343427
 >> iter 36000, loss: 0.203014
 >> iter 37000, loss: 0.236269
 >> iter 38000, loss: 0.214139
 >> iter 39000, loss: 0.165782
 >> iter 40000, loss: 0.200582
   Number of active neurons: 3
 >> iter 41000, loss: 0.356674
 >> iter 42000, loss: 0.364026
 >> iter 43000, loss: 0.268405
 >> iter 44000, loss: 0.305722
 >> iter 45000, loss: 0.173942
 >> iter 46000, loss: 0.373972
 >> iter 47000, loss: 0.410603
 >> iter 48000, loss: 0.386708
 >> iter 49000, loss: 0.342365
 >> iter 50000, loss: 0.247257
   Number of active neurons: 3
 >> iter 51000, loss: 0.189839
 >> iter 52000, loss: 0.241107
 >> iter 53000, loss: 0.169314
 >> iter 54000, loss: 0.201617
 >> iter 55000, loss: 0.344957
 >> iter 56000, loss: 0.364535
 >> iter 57000, loss: 0.242448
 >> iter 58000, loss: 0.128146
 >> iter 59000, loss: 0.262296
 >> iter 60000, loss: 0.201287
   Number of active neurons: 3
 >> iter 61000, loss: 0.225279
 >> iter 62000, loss: 0.342734
 >> iter 63000, loss: 0.293117
 >> iter 64000, loss: 0.378969
 >> iter 65000, loss: 0.261016
 >> iter 66000, loss: 0.178391
 >> iter 67000, loss: 0.315094
 >> iter 68000, loss: 0.240066
 >> iter 69000, loss: 0.215658
 >> iter 70000, loss: 0.141294
   Number of active neurons: 3
 >> iter 71000, loss: 0.095214
 >> iter 72000, loss: 0.124876
 >> iter 73000, loss: 0.286972
 >> iter 74000, loss: 0.237494
 >> iter 75000, loss: 0.202263
 >> iter 76000, loss: 0.154515
 >> iter 77000, loss: 0.222921
 >> iter 78000, loss: 0.164317
 >> iter 79000, loss: 0.146799
 >> iter 80000, loss: 0.296864
   Number of active neurons: 3
 >> iter 81000, loss: 0.222118
 >> iter 82000, loss: 0.191580
 >> iter 83000, loss: 0.176782
 >> iter 84000, loss: 0.297304
 >> iter 85000, loss: 0.186422
 >> iter 86000, loss: 0.290206
 >> iter 87000, loss: 0.309250
 >> iter 88000, loss: 0.222012
 >> iter 89000, loss: 0.202213
 >> iter 90000, loss: 0.190798
   Number of active neurons: 3
 >> iter 91000, loss: 0.167079
 >> iter 92000, loss: 0.263819
 >> iter 93000, loss: 0.297989
 >> iter 94000, loss: 0.276461
 >> iter 95000, loss: 0.302799
 >> iter 96000, loss: 0.222757
 >> iter 97000, loss: 0.261943
 >> iter 98000, loss: 0.197615
 >> iter 99000, loss: 0.199112
 >> iter 100000, loss: 0.228030
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.588595
 >> iter 2000, loss: 8.285632
 >> iter 3000, loss: 3.857625
 >> iter 4000, loss: 1.722181
 >> iter 5000, loss: 1.087859
 >> iter 6000, loss: 0.720680
 >> iter 7000, loss: 0.571956
 >> iter 8000, loss: 0.561259
 >> iter 9000, loss: 0.446308
 >> iter 10000, loss: 0.366198
   Number of active neurons: 5
 >> iter 11000, loss: 0.351432
 >> iter 12000, loss: 0.420240
 >> iter 13000, loss: 0.392503
 >> iter 14000, loss: 0.350372
 >> iter 15000, loss: 0.297925
 >> iter 16000, loss: 0.266594
 >> iter 17000, loss: 0.272362
 >> iter 18000, loss: 0.520541
 >> iter 19000, loss: 0.362676
 >> iter 20000, loss: 0.424872
   Number of active neurons: 5
 >> iter 21000, loss: 0.314086
 >> iter 22000, loss: 0.286694
 >> iter 23000, loss: 0.335082
 >> iter 24000, loss: 0.235373
 >> iter 25000, loss: 0.211106
 >> iter 26000, loss: 0.231148
 >> iter 27000, loss: 0.271507
 >> iter 28000, loss: 0.267790
 >> iter 29000, loss: 0.255445
 >> iter 30000, loss: 0.355163
   Number of active neurons: 5
 >> iter 31000, loss: 0.212704
 >> iter 32000, loss: 0.363597
 >> iter 33000, loss: 0.436467
 >> iter 34000, loss: 0.368006
 >> iter 35000, loss: 0.297789
 >> iter 36000, loss: 0.259077
 >> iter 37000, loss: 0.256123
 >> iter 38000, loss: 0.275715
 >> iter 39000, loss: 0.207493
 >> iter 40000, loss: 0.272383
   Number of active neurons: 4
 >> iter 41000, loss: 0.237403
 >> iter 42000, loss: 0.310710
 >> iter 43000, loss: 0.433572
 >> iter 44000, loss: 0.450978
 >> iter 45000, loss: 0.254506
 >> iter 46000, loss: 0.383336
 >> iter 47000, loss: 0.303166
 >> iter 48000, loss: 0.429381
 >> iter 49000, loss: 0.332417
 >> iter 50000, loss: 0.585764
   Number of active neurons: 3
 >> iter 51000, loss: 0.276765
 >> iter 52000, loss: 0.254325
 >> iter 53000, loss: 0.312698
 >> iter 54000, loss: 0.250810
 >> iter 55000, loss: 0.221806
 >> iter 56000, loss: 0.185217
 >> iter 57000, loss: 0.264787
 >> iter 58000, loss: 0.215119
 >> iter 59000, loss: 0.150861
 >> iter 60000, loss: 0.468003
   Number of active neurons: 3
 >> iter 61000, loss: 0.247400
 >> iter 62000, loss: 0.277503
 >> iter 63000, loss: 0.315758
 >> iter 64000, loss: 0.342509
 >> iter 65000, loss: 0.467222
 >> iter 66000, loss: 0.561750
 >> iter 67000, loss: 0.320956
 >> iter 68000, loss: 0.243018
 >> iter 69000, loss: 0.338338
 >> iter 70000, loss: 0.409606
   Number of active neurons: 3
 >> iter 71000, loss: 0.401998
 >> iter 72000, loss: 0.282895
 >> iter 73000, loss: 0.157675
 >> iter 74000, loss: 0.094609
 >> iter 75000, loss: 0.119755
 >> iter 76000, loss: 0.235537
 >> iter 77000, loss: 0.145692
 >> iter 78000, loss: 0.153209
 >> iter 79000, loss: 0.238130
 >> iter 80000, loss: 0.133659
   Number of active neurons: 3
 >> iter 81000, loss: 0.106990
 >> iter 82000, loss: 0.248286
 >> iter 83000, loss: 0.187927
 >> iter 84000, loss: 0.309173
 >> iter 85000, loss: 0.235657
 >> iter 86000, loss: 0.259305
 >> iter 87000, loss: 0.204808
 >> iter 88000, loss: 0.198311
 >> iter 89000, loss: 0.253305
 >> iter 90000, loss: 0.300413
   Number of active neurons: 3
 >> iter 91000, loss: 0.245666
 >> iter 92000, loss: 0.237127
 >> iter 93000, loss: 0.225325
 >> iter 94000, loss: 0.143528
 >> iter 95000, loss: 0.133134
 >> iter 96000, loss: 0.206673
 >> iter 97000, loss: 0.394051
 >> iter 98000, loss: 0.276866
 >> iter 99000, loss: 0.322728
 >> iter 100000, loss: 0.237762
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.767311
 >> iter 2000, loss: 8.333753
 >> iter 3000, loss: 3.633194
 >> iter 4000, loss: 1.604891
 >> iter 5000, loss: 1.119359
 >> iter 6000, loss: 0.803345
 >> iter 7000, loss: 0.479783
 >> iter 8000, loss: 0.525657
 >> iter 9000, loss: 0.505703
 >> iter 10000, loss: 0.373248
   Number of active neurons: 7
 >> iter 11000, loss: 0.887607
 >> iter 12000, loss: 0.688716
 >> iter 13000, loss: 0.453964
 >> iter 14000, loss: 0.358900
 >> iter 15000, loss: 0.184658
 >> iter 16000, loss: 0.313008
 >> iter 17000, loss: 0.325496
 >> iter 18000, loss: 0.285964
 >> iter 19000, loss: 0.322495
 >> iter 20000, loss: 0.264664
   Number of active neurons: 6
 >> iter 21000, loss: 0.287103
 >> iter 22000, loss: 0.192666
 >> iter 23000, loss: 0.239393
 >> iter 24000, loss: 0.245109
 >> iter 25000, loss: 0.165655
 >> iter 26000, loss: 0.148350
 >> iter 27000, loss: 0.297947
 >> iter 28000, loss: 0.247794
 >> iter 29000, loss: 0.168093
 >> iter 30000, loss: 0.195201
   Number of active neurons: 6
 >> iter 31000, loss: 0.199605
 >> iter 32000, loss: 0.441601
 >> iter 33000, loss: 0.369690
 >> iter 34000, loss: 0.264586
 >> iter 35000, loss: 0.176150
 >> iter 36000, loss: 0.301482
 >> iter 37000, loss: 0.410124
 >> iter 38000, loss: 0.278747
 >> iter 39000, loss: 0.161811
 >> iter 40000, loss: 0.132110
   Number of active neurons: 5
 >> iter 41000, loss: 0.225443
 >> iter 42000, loss: 0.207499
 >> iter 43000, loss: 0.105286
 >> iter 44000, loss: 0.377415
 >> iter 45000, loss: 0.182598
 >> iter 46000, loss: 0.183032
 >> iter 47000, loss: 0.215708
 >> iter 48000, loss: 0.202637
 >> iter 49000, loss: 0.189178
 >> iter 50000, loss: 0.151482
   Number of active neurons: 5
 >> iter 51000, loss: 0.287539
 >> iter 52000, loss: 0.138269
 >> iter 53000, loss: 0.295437
 >> iter 54000, loss: 0.155238
 >> iter 55000, loss: 0.400281
 >> iter 56000, loss: 0.329667
 >> iter 57000, loss: 0.254258
 >> iter 58000, loss: 0.248644
 >> iter 59000, loss: 0.309538
 >> iter 60000, loss: 0.470945
   Number of active neurons: 5
 >> iter 61000, loss: 0.346660
 >> iter 62000, loss: 0.340583
 >> iter 63000, loss: 0.176243
 >> iter 64000, loss: 0.168002
 >> iter 65000, loss: 0.475766
 >> iter 66000, loss: 0.286840
 >> iter 67000, loss: 0.275893
 >> iter 68000, loss: 0.278609
 >> iter 69000, loss: 0.195033
 >> iter 70000, loss: 0.288418
   Number of active neurons: 5
 >> iter 71000, loss: 0.286353
 >> iter 72000, loss: 0.235501
 >> iter 73000, loss: 0.248672
 >> iter 74000, loss: 0.207921
 >> iter 75000, loss: 0.284657
 >> iter 76000, loss: 0.203006
 >> iter 77000, loss: 0.276083
 >> iter 78000, loss: 0.257555
 >> iter 79000, loss: 0.295789
 >> iter 80000, loss: 0.388168
   Number of active neurons: 4
 >> iter 81000, loss: 0.406174
 >> iter 82000, loss: 0.271976
 >> iter 83000, loss: 0.175682
 >> iter 84000, loss: 0.282372
 >> iter 85000, loss: 0.201567
 >> iter 86000, loss: 0.159837
 >> iter 87000, loss: 0.217090
 >> iter 88000, loss: 0.302228
 >> iter 89000, loss: 0.259806
 >> iter 90000, loss: 0.242524
   Number of active neurons: 4
 >> iter 91000, loss: 0.321011
 >> iter 92000, loss: 0.459713
 >> iter 93000, loss: 0.455939
 >> iter 94000, loss: 0.262948
 >> iter 95000, loss: 0.244440
 >> iter 96000, loss: 0.145490
 >> iter 97000, loss: 0.108998
 >> iter 98000, loss: 0.167583
 >> iter 99000, loss: 0.179610
 >> iter 100000, loss: 0.329369
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.281205
 >> iter 2000, loss: 10.733718
 >> iter 3000, loss: 5.128807
 >> iter 4000, loss: 2.493613
 >> iter 5000, loss: 1.262279
 >> iter 6000, loss: 0.881636
 >> iter 7000, loss: 0.702676
 >> iter 8000, loss: 0.563026
 >> iter 9000, loss: 0.538251
 >> iter 10000, loss: 0.469866
   Number of active neurons: 6
 >> iter 11000, loss: 0.466256
 >> iter 12000, loss: 0.492556
 >> iter 13000, loss: 0.574118
 >> iter 14000, loss: 0.461223
 >> iter 15000, loss: 0.749438
 >> iter 16000, loss: 0.464661
 >> iter 17000, loss: 0.421183
 >> iter 18000, loss: 0.642094
 >> iter 19000, loss: 0.564209
 >> iter 20000, loss: 0.626769
   Number of active neurons: 5
 >> iter 21000, loss: 0.571169
 >> iter 22000, loss: 0.370539
 >> iter 23000, loss: 0.268339
 >> iter 24000, loss: 0.526644
 >> iter 25000, loss: 0.603145
 >> iter 26000, loss: 0.535340
 >> iter 27000, loss: 0.449394
 >> iter 28000, loss: 0.251554
 >> iter 29000, loss: 0.546968
 >> iter 30000, loss: 0.386728
   Number of active neurons: 5
 >> iter 31000, loss: 0.477520
 >> iter 32000, loss: 0.330864
 >> iter 33000, loss: 0.270766
 >> iter 34000, loss: 0.416388
 >> iter 35000, loss: 0.437293
 >> iter 36000, loss: 0.473698
 >> iter 37000, loss: 0.306698
 >> iter 38000, loss: 0.245928
 >> iter 39000, loss: 0.414396
 >> iter 40000, loss: 0.530948
   Number of active neurons: 5
 >> iter 41000, loss: 0.469932
 >> iter 42000, loss: 0.452952
 >> iter 43000, loss: 0.421279
 >> iter 44000, loss: 0.413979
 >> iter 45000, loss: 0.566927
 >> iter 46000, loss: 0.551051
 >> iter 47000, loss: 0.274995
 >> iter 48000, loss: 0.330309
 >> iter 49000, loss: 0.351710
 >> iter 50000, loss: 0.360924
   Number of active neurons: 5
 >> iter 51000, loss: 0.385720
 >> iter 52000, loss: 0.605359
 >> iter 53000, loss: 0.540958
 >> iter 54000, loss: 0.408488
 >> iter 55000, loss: 0.524231
 >> iter 56000, loss: 0.414453
 >> iter 57000, loss: 0.481098
 >> iter 58000, loss: 0.534311
 >> iter 59000, loss: 0.785767
 >> iter 60000, loss: 0.661490
   Number of active neurons: 5
 >> iter 61000, loss: 0.498017
 >> iter 62000, loss: 0.623720
 >> iter 63000, loss: 0.480841
 >> iter 64000, loss: 0.448596
 >> iter 65000, loss: 0.268456
 >> iter 66000, loss: 0.305747
 >> iter 67000, loss: 0.490165
 >> iter 68000, loss: 0.547734
 >> iter 69000, loss: 0.456997
 >> iter 70000, loss: 0.464296
   Number of active neurons: 5
 >> iter 71000, loss: 0.345957
 >> iter 72000, loss: 0.517552
 >> iter 73000, loss: 0.549198
 >> iter 74000, loss: 0.616148
 >> iter 75000, loss: 0.415912
 >> iter 76000, loss: 0.312886
 >> iter 77000, loss: 0.305391
 >> iter 78000, loss: 0.704290
 >> iter 79000, loss: 0.490811
 >> iter 80000, loss: 0.464086
   Number of active neurons: 5
 >> iter 81000, loss: 0.451740
 >> iter 82000, loss: 0.250052
 >> iter 83000, loss: 0.359343
 >> iter 84000, loss: 0.522882
 >> iter 85000, loss: 0.459314
 >> iter 86000, loss: 0.514748
 >> iter 87000, loss: 0.367944
 >> iter 88000, loss: 0.345899
 >> iter 89000, loss: 0.344762
 >> iter 90000, loss: 0.369106
   Number of active neurons: 5
 >> iter 91000, loss: 0.259911
 >> iter 92000, loss: 0.266431
 >> iter 93000, loss: 0.334338
 >> iter 94000, loss: 0.481610
 >> iter 95000, loss: 0.429147
 >> iter 96000, loss: 0.530252
 >> iter 97000, loss: 0.498218
 >> iter 98000, loss: 0.331243
 >> iter 99000, loss: 0.445119
 >> iter 100000, loss: 0.316080
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.504089
 >> iter 2000, loss: 8.339305
 >> iter 3000, loss: 3.710892
 >> iter 4000, loss: 1.679896
 >> iter 5000, loss: 1.101513
 >> iter 6000, loss: 0.556717
 >> iter 7000, loss: 0.383632
 >> iter 8000, loss: 0.403641
 >> iter 9000, loss: 0.487416
 >> iter 10000, loss: 0.602080
   Number of active neurons: 5
 >> iter 11000, loss: 0.354571
 >> iter 12000, loss: 0.206390
 >> iter 13000, loss: 0.271052
 >> iter 14000, loss: 0.604080
 >> iter 15000, loss: 0.501966
 >> iter 16000, loss: 0.275923
 >> iter 17000, loss: 0.258006
 >> iter 18000, loss: 0.168852
 >> iter 19000, loss: 0.163099
 >> iter 20000, loss: 0.154182
   Number of active neurons: 3
 >> iter 21000, loss: 0.329368
 >> iter 22000, loss: 0.191577
 >> iter 23000, loss: 0.325742
 >> iter 24000, loss: 0.285947
 >> iter 25000, loss: 0.211253
 >> iter 26000, loss: 0.452680
 >> iter 27000, loss: 0.533242
 >> iter 28000, loss: 0.402544
 >> iter 29000, loss: 0.303058
 >> iter 30000, loss: 0.234633
   Number of active neurons: 3
 >> iter 31000, loss: 0.302745
 >> iter 32000, loss: 0.416819
 >> iter 33000, loss: 0.320281
 >> iter 34000, loss: 0.330584
 >> iter 35000, loss: 0.350568
 >> iter 36000, loss: 0.273531
 >> iter 37000, loss: 0.281776
 >> iter 38000, loss: 0.259048
 >> iter 39000, loss: 0.199598
 >> iter 40000, loss: 0.282113
   Number of active neurons: 3
 >> iter 41000, loss: 0.229807
 >> iter 42000, loss: 0.140238
 >> iter 43000, loss: 0.288905
 >> iter 44000, loss: 0.213326
 >> iter 45000, loss: 0.176588
 >> iter 46000, loss: 0.459483
 >> iter 47000, loss: 0.392368
 >> iter 48000, loss: 0.200553
 >> iter 49000, loss: 0.229049
 >> iter 50000, loss: 0.142596
   Number of active neurons: 3
 >> iter 51000, loss: 0.409204
 >> iter 52000, loss: 0.224799
 >> iter 53000, loss: 0.199811
 >> iter 54000, loss: 0.202987
 >> iter 55000, loss: 0.208032
 >> iter 56000, loss: 0.151819
 >> iter 57000, loss: 0.369730
 >> iter 58000, loss: 0.520263
 >> iter 59000, loss: 0.264867
 >> iter 60000, loss: 0.350555
   Number of active neurons: 3
 >> iter 61000, loss: 0.353097
 >> iter 62000, loss: 0.283877
 >> iter 63000, loss: 0.145386
 >> iter 64000, loss: 0.202945
 >> iter 65000, loss: 0.287996
 >> iter 66000, loss: 0.313801
 >> iter 67000, loss: 0.240602
 >> iter 68000, loss: 0.180828
 >> iter 69000, loss: 0.098351
 >> iter 70000, loss: 0.174869
   Number of active neurons: 3
 >> iter 71000, loss: 0.117133
 >> iter 72000, loss: 0.166254
 >> iter 73000, loss: 0.209279
 >> iter 74000, loss: 0.168421
 >> iter 75000, loss: 0.152027
 >> iter 76000, loss: 0.179356
 >> iter 77000, loss: 0.321160
 >> iter 78000, loss: 0.249359
 >> iter 79000, loss: 0.220327
 >> iter 80000, loss: 0.306181
   Number of active neurons: 3
 >> iter 81000, loss: 0.217997
 >> iter 82000, loss: 0.299841
 >> iter 83000, loss: 0.280831
 >> iter 84000, loss: 0.287334
 >> iter 85000, loss: 0.322771
 >> iter 86000, loss: 0.361823
 >> iter 87000, loss: 0.271876
 >> iter 88000, loss: 0.277738
 >> iter 89000, loss: 0.218245
 >> iter 90000, loss: 0.186544
   Number of active neurons: 3
 >> iter 91000, loss: 0.274746
 >> iter 92000, loss: 0.250586
 >> iter 93000, loss: 0.202701
 >> iter 94000, loss: 0.604998
 >> iter 95000, loss: 0.449764
 >> iter 96000, loss: 0.228994
 >> iter 97000, loss: 0.158553
 >> iter 98000, loss: 0.231966
 >> iter 99000, loss: 0.249607
 >> iter 100000, loss: 0.370226
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.575269
 >> iter 2000, loss: 9.235059
 >> iter 3000, loss: 4.461018
 >> iter 4000, loss: 2.167334
 >> iter 5000, loss: 1.239970
 >> iter 6000, loss: 0.813267
 >> iter 7000, loss: 0.534078
 >> iter 8000, loss: 0.398258
 >> iter 9000, loss: 0.712448
 >> iter 10000, loss: 0.495957
   Number of active neurons: 4
 >> iter 11000, loss: 0.336144
 >> iter 12000, loss: 0.294388
 >> iter 13000, loss: 0.319571
 >> iter 14000, loss: 0.395775
 >> iter 15000, loss: 0.217506
 >> iter 16000, loss: 0.300488
 >> iter 17000, loss: 0.238609
 >> iter 18000, loss: 0.231433
 >> iter 19000, loss: 0.242654
 >> iter 20000, loss: 0.325879
   Number of active neurons: 4
 >> iter 21000, loss: 0.441773
 >> iter 22000, loss: 0.448680
 >> iter 23000, loss: 0.246449
 >> iter 24000, loss: 0.160995
 >> iter 25000, loss: 0.242239
 >> iter 26000, loss: 0.252802
 >> iter 27000, loss: 0.209119
 >> iter 28000, loss: 0.247273
 >> iter 29000, loss: 0.371148
 >> iter 30000, loss: 0.334131
   Number of active neurons: 4
 >> iter 31000, loss: 0.238049
 >> iter 32000, loss: 0.249033
 >> iter 33000, loss: 0.243611
 >> iter 34000, loss: 0.264713
 >> iter 35000, loss: 0.405414
 >> iter 36000, loss: 0.288585
 >> iter 37000, loss: 0.260301
 >> iter 38000, loss: 0.271082
 >> iter 39000, loss: 0.344656
 >> iter 40000, loss: 0.556740
   Number of active neurons: 4
 >> iter 41000, loss: 0.409415
 >> iter 42000, loss: 0.375276
 >> iter 43000, loss: 0.452155
 >> iter 44000, loss: 0.483871
 >> iter 45000, loss: 0.249914
 >> iter 46000, loss: 0.241012
 >> iter 47000, loss: 0.156527
 >> iter 48000, loss: 0.191003
 >> iter 49000, loss: 0.293017
 >> iter 50000, loss: 0.274748
   Number of active neurons: 3
 >> iter 51000, loss: 0.296878
 >> iter 52000, loss: 0.166495
 >> iter 53000, loss: 0.100037
 >> iter 54000, loss: 0.145986
 >> iter 55000, loss: 0.147308
 >> iter 56000, loss: 0.242678
 >> iter 57000, loss: 0.252700
 >> iter 58000, loss: 0.428263
 >> iter 59000, loss: 0.349492
 >> iter 60000, loss: 0.524621
   Number of active neurons: 3
 >> iter 61000, loss: 0.268961
 >> iter 62000, loss: 0.163305
 >> iter 63000, loss: 0.213591
 >> iter 64000, loss: 0.425071
 >> iter 65000, loss: 0.242264
 >> iter 66000, loss: 0.283323
 >> iter 67000, loss: 0.171459
 >> iter 68000, loss: 0.168216
 >> iter 69000, loss: 0.229653
 >> iter 70000, loss: 0.148849
   Number of active neurons: 3
 >> iter 71000, loss: 0.239479
 >> iter 72000, loss: 0.129042
 >> iter 73000, loss: 0.157775
 >> iter 74000, loss: 0.294607
 >> iter 75000, loss: 0.152465
 >> iter 76000, loss: 0.137605
 >> iter 77000, loss: 0.199789
 >> iter 78000, loss: 0.219909
 >> iter 79000, loss: 0.308358
 >> iter 80000, loss: 0.377671
   Number of active neurons: 3
 >> iter 81000, loss: 0.257329
 >> iter 82000, loss: 0.271011
 >> iter 83000, loss: 0.221563
 >> iter 84000, loss: 0.258667
 >> iter 85000, loss: 0.302044
 >> iter 86000, loss: 0.355698
 >> iter 87000, loss: 0.439964
 >> iter 88000, loss: 0.234552
 >> iter 89000, loss: 0.121099
 >> iter 90000, loss: 0.149819
   Number of active neurons: 3
 >> iter 91000, loss: 0.196399
 >> iter 92000, loss: 0.358290
 >> iter 93000, loss: 0.212323
 >> iter 94000, loss: 0.263844
 >> iter 95000, loss: 0.222025
 >> iter 96000, loss: 0.278555
 >> iter 97000, loss: 0.209465
 >> iter 98000, loss: 0.325569
 >> iter 99000, loss: 0.283315
 >> iter 100000, loss: 0.315301
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.689012
 >> iter 2000, loss: 9.971334
 >> iter 3000, loss: 5.137915
 >> iter 4000, loss: 2.576086
 >> iter 5000, loss: 1.639237
 >> iter 6000, loss: 1.216091
 >> iter 7000, loss: 0.866715
 >> iter 8000, loss: 0.703103
 >> iter 9000, loss: 0.535946
 >> iter 10000, loss: 0.385071
   Number of active neurons: 5
 >> iter 11000, loss: 0.263205
 >> iter 12000, loss: 0.543295
 >> iter 13000, loss: 0.554857
 >> iter 14000, loss: 0.394695
 >> iter 15000, loss: 0.462398
 >> iter 16000, loss: 0.574886
 >> iter 17000, loss: 0.288584
 >> iter 18000, loss: 0.561725
 >> iter 19000, loss: 0.423322
 >> iter 20000, loss: 0.303103
   Number of active neurons: 5
 >> iter 21000, loss: 0.515528
 >> iter 22000, loss: 0.392223
 >> iter 23000, loss: 0.262397
 >> iter 24000, loss: 0.421574
 >> iter 25000, loss: 0.357439
 >> iter 26000, loss: 0.269421
 >> iter 27000, loss: 0.338294
 >> iter 28000, loss: 0.460868
 >> iter 29000, loss: 0.489699
 >> iter 30000, loss: 0.339420
   Number of active neurons: 5
 >> iter 31000, loss: 0.350426
 >> iter 32000, loss: 0.441430
 >> iter 33000, loss: 0.332729
 >> iter 34000, loss: 0.385503
 >> iter 35000, loss: 0.500209
 >> iter 36000, loss: 0.352670
 >> iter 37000, loss: 0.390656
 >> iter 38000, loss: 0.346318
 >> iter 39000, loss: 0.301743
 >> iter 40000, loss: 0.517267
   Number of active neurons: 5
 >> iter 41000, loss: 0.421186
 >> iter 42000, loss: 0.351738
 >> iter 43000, loss: 0.293397
 >> iter 44000, loss: 0.230028
 >> iter 45000, loss: 0.435916
 >> iter 46000, loss: 0.528548
 >> iter 47000, loss: 0.328350
 >> iter 48000, loss: 0.316446
 >> iter 49000, loss: 0.259711
 >> iter 50000, loss: 0.348573
   Number of active neurons: 4
 >> iter 51000, loss: 0.476914
 >> iter 52000, loss: 0.289849
 >> iter 53000, loss: 0.369314
 >> iter 54000, loss: 0.285341
 >> iter 55000, loss: 0.324941
 >> iter 56000, loss: 0.468323
 >> iter 57000, loss: 0.401131
 >> iter 58000, loss: 0.451294
 >> iter 59000, loss: 0.236489
 >> iter 60000, loss: 0.206435
   Number of active neurons: 4
 >> iter 61000, loss: 0.306227
 >> iter 62000, loss: 0.361078
 >> iter 63000, loss: 0.165360
 >> iter 64000, loss: 0.130089
 >> iter 65000, loss: 0.212367
 >> iter 66000, loss: 0.350511
 >> iter 67000, loss: 0.291980
 >> iter 68000, loss: 0.182182
 >> iter 69000, loss: 0.219785
 >> iter 70000, loss: 0.179347
   Number of active neurons: 4
 >> iter 71000, loss: 0.302027
 >> iter 72000, loss: 0.208769
 >> iter 73000, loss: 0.405633
 >> iter 74000, loss: 0.408541
 >> iter 75000, loss: 0.317841
 >> iter 76000, loss: 0.331000
 >> iter 77000, loss: 0.259215
 >> iter 78000, loss: 0.222044
 >> iter 79000, loss: 0.256385
 >> iter 80000, loss: 0.246647
   Number of active neurons: 4
 >> iter 81000, loss: 0.313331
 >> iter 82000, loss: 0.223983
 >> iter 83000, loss: 0.153585
 >> iter 84000, loss: 0.111487
 >> iter 85000, loss: 0.278153
 >> iter 86000, loss: 0.198598
 >> iter 87000, loss: 0.184737
 >> iter 88000, loss: 0.311432
 >> iter 89000, loss: 0.316868
 >> iter 90000, loss: 0.353186
   Number of active neurons: 3
 >> iter 91000, loss: 0.259011
 >> iter 92000, loss: 0.266519
 >> iter 93000, loss: 0.154549
 >> iter 94000, loss: 0.244519
 >> iter 95000, loss: 0.214739
 >> iter 96000, loss: 0.194634
 >> iter 97000, loss: 0.198898
 >> iter 98000, loss: 0.243089
 >> iter 99000, loss: 0.279636
 >> iter 100000, loss: 0.250658
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.701376
 >> iter 2000, loss: 8.951825
 >> iter 3000, loss: 3.964432
 >> iter 4000, loss: 1.808534
 >> iter 5000, loss: 1.019897
 >> iter 6000, loss: 0.723534
 >> iter 7000, loss: 0.484908
 >> iter 8000, loss: 0.241420
 >> iter 9000, loss: 0.631986
 >> iter 10000, loss: 0.519365
   Number of active neurons: 6
 >> iter 11000, loss: 0.383345
 >> iter 12000, loss: 0.365992
 >> iter 13000, loss: 0.437741
 >> iter 14000, loss: 0.367159
 >> iter 15000, loss: 0.422796
 >> iter 16000, loss: 0.371761
 >> iter 17000, loss: 0.296435
 >> iter 18000, loss: 0.350424
 >> iter 19000, loss: 0.321935
 >> iter 20000, loss: 0.329652
   Number of active neurons: 5
 >> iter 21000, loss: 0.391808
 >> iter 22000, loss: 0.398662
 >> iter 23000, loss: 0.243468
 >> iter 24000, loss: 0.357430
 >> iter 25000, loss: 0.232137
 >> iter 26000, loss: 0.234188
 >> iter 27000, loss: 0.453711
 >> iter 28000, loss: 0.382624
 >> iter 29000, loss: 0.224445
 >> iter 30000, loss: 0.382460
   Number of active neurons: 5
 >> iter 31000, loss: 0.440017
 >> iter 32000, loss: 0.343252
 >> iter 33000, loss: 0.198101
 >> iter 34000, loss: 0.259725
 >> iter 35000, loss: 0.536632
 >> iter 36000, loss: 0.373225
 >> iter 37000, loss: 0.287307
 >> iter 38000, loss: 0.342547
 >> iter 39000, loss: 0.380577
 >> iter 40000, loss: 0.265040
   Number of active neurons: 5
 >> iter 41000, loss: 0.233083
 >> iter 42000, loss: 0.221651
 >> iter 43000, loss: 0.268286
 >> iter 44000, loss: 0.398550
 >> iter 45000, loss: 0.300199
 >> iter 46000, loss: 0.364890
 >> iter 47000, loss: 0.305014
 >> iter 48000, loss: 0.355088
 >> iter 49000, loss: 0.340323
 >> iter 50000, loss: 0.264098
   Number of active neurons: 5
 >> iter 51000, loss: 0.248172
 >> iter 52000, loss: 0.270892
 >> iter 53000, loss: 0.313748
 >> iter 54000, loss: 0.315598
 >> iter 55000, loss: 0.474011
 >> iter 56000, loss: 0.377305
 >> iter 57000, loss: 0.471562
 >> iter 58000, loss: 0.337839
 >> iter 59000, loss: 0.275021
 >> iter 60000, loss: 0.279853
   Number of active neurons: 5
 >> iter 61000, loss: 0.301192
 >> iter 62000, loss: 0.206750
 >> iter 63000, loss: 0.357532
 >> iter 64000, loss: 0.341614
 >> iter 65000, loss: 0.404100
 >> iter 66000, loss: 0.320060
 >> iter 67000, loss: 0.202503
 >> iter 68000, loss: 0.225198
 >> iter 69000, loss: 0.161200
 >> iter 70000, loss: 0.153403
   Number of active neurons: 5
 >> iter 71000, loss: 0.202095
 >> iter 72000, loss: 0.325129
 >> iter 73000, loss: 0.286670
 >> iter 74000, loss: 0.338799
 >> iter 75000, loss: 0.201540
 >> iter 76000, loss: 0.252175
 >> iter 77000, loss: 0.314469
 >> iter 78000, loss: 0.493653
 >> iter 79000, loss: 0.456586
 >> iter 80000, loss: 0.268467
   Number of active neurons: 5
 >> iter 81000, loss: 0.227569
 >> iter 82000, loss: 0.124862
 >> iter 83000, loss: 0.211562
 >> iter 84000, loss: 0.202380
 >> iter 85000, loss: 0.326823
 >> iter 86000, loss: 0.314090
 >> iter 87000, loss: 0.254312
 >> iter 88000, loss: 0.226902
 >> iter 89000, loss: 0.175300
 >> iter 90000, loss: 0.163321
   Number of active neurons: 5
 >> iter 91000, loss: 0.217479
 >> iter 92000, loss: 0.175062
 >> iter 93000, loss: 0.094596
 >> iter 94000, loss: 0.105570
 >> iter 95000, loss: 0.336736
 >> iter 96000, loss: 0.282402
 >> iter 97000, loss: 0.306892
 >> iter 98000, loss: 0.257915
 >> iter 99000, loss: 0.418247
 >> iter 100000, loss: 0.362314
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.211044
 >> iter 2000, loss: 8.728117
 >> iter 3000, loss: 4.087551
 >> iter 4000, loss: 2.192552
 >> iter 5000, loss: 1.574768
 >> iter 6000, loss: 0.790338
 >> iter 7000, loss: 0.479864
 >> iter 8000, loss: 0.350462
 >> iter 9000, loss: 0.409413
 >> iter 10000, loss: 0.452142
   Number of active neurons: 6
 >> iter 11000, loss: 0.332230
 >> iter 12000, loss: 0.595493
 >> iter 13000, loss: 0.463568
 >> iter 14000, loss: 0.361276
 >> iter 15000, loss: 0.367594
 >> iter 16000, loss: 0.411300
 >> iter 17000, loss: 0.272660
 >> iter 18000, loss: 0.356320
 >> iter 19000, loss: 0.270412
 >> iter 20000, loss: 0.298619
   Number of active neurons: 4
 >> iter 21000, loss: 0.273352
 >> iter 22000, loss: 0.297442
 >> iter 23000, loss: 0.378262
 >> iter 24000, loss: 0.440498
 >> iter 25000, loss: 0.487942
 >> iter 26000, loss: 0.383163
 >> iter 27000, loss: 0.286895
 >> iter 28000, loss: 0.212012
 >> iter 29000, loss: 0.386564
 >> iter 30000, loss: 0.473234
   Number of active neurons: 4
 >> iter 31000, loss: 0.237090
 >> iter 32000, loss: 0.199791
 >> iter 33000, loss: 0.342542
 >> iter 34000, loss: 0.257422
 >> iter 35000, loss: 0.242249
 >> iter 36000, loss: 0.273514
 >> iter 37000, loss: 0.202541
 >> iter 38000, loss: 0.221586
 >> iter 39000, loss: 0.211255
 >> iter 40000, loss: 0.282151
   Number of active neurons: 3
 >> iter 41000, loss: 0.319576
 >> iter 42000, loss: 0.181794
 >> iter 43000, loss: 0.273053
 >> iter 44000, loss: 0.207834
 >> iter 45000, loss: 0.569093
 >> iter 46000, loss: 0.299325
 >> iter 47000, loss: 0.211710
 >> iter 48000, loss: 0.253590
 >> iter 49000, loss: 0.389906
 >> iter 50000, loss: 0.392820
   Number of active neurons: 3
 >> iter 51000, loss: 0.446973
 >> iter 52000, loss: 0.433758
 >> iter 53000, loss: 0.252373
 >> iter 54000, loss: 0.274645
 >> iter 55000, loss: 0.239677
 >> iter 56000, loss: 0.445378
 >> iter 57000, loss: 0.320439
 >> iter 58000, loss: 0.229135
 >> iter 59000, loss: 0.330063
 >> iter 60000, loss: 0.472922
   Number of active neurons: 3
 >> iter 61000, loss: 0.449398
 >> iter 62000, loss: 0.288732
 >> iter 63000, loss: 0.381600
 >> iter 64000, loss: 0.297716
 >> iter 65000, loss: 0.249265
 >> iter 66000, loss: 0.296738
 >> iter 67000, loss: 0.262992
 >> iter 68000, loss: 0.298029
 >> iter 69000, loss: 0.296793
 >> iter 70000, loss: 0.229508
   Number of active neurons: 3
 >> iter 71000, loss: 0.223905
 >> iter 72000, loss: 0.293900
 >> iter 73000, loss: 0.436720
 >> iter 74000, loss: 0.334334
 >> iter 75000, loss: 0.272096
 >> iter 76000, loss: 0.442392
 >> iter 77000, loss: 0.307718
 >> iter 78000, loss: 0.168008
 >> iter 79000, loss: 0.142816
 >> iter 80000, loss: 0.184403
   Number of active neurons: 3
 >> iter 81000, loss: 0.131034
 >> iter 82000, loss: 0.268599
 >> iter 83000, loss: 0.228641
 >> iter 84000, loss: 0.314103
 >> iter 85000, loss: 0.174221
 >> iter 86000, loss: 0.198104
 >> iter 87000, loss: 0.400917
 >> iter 88000, loss: 0.224784
 >> iter 89000, loss: 0.306730
 >> iter 90000, loss: 0.420676
   Number of active neurons: 3
 >> iter 91000, loss: 0.392778
 >> iter 92000, loss: 0.431453
 >> iter 93000, loss: 0.225584
 >> iter 94000, loss: 0.171723
 >> iter 95000, loss: 0.228034
 >> iter 96000, loss: 0.136324
 >> iter 97000, loss: 0.203297
 >> iter 98000, loss: 0.383489
 >> iter 99000, loss: 0.275516
 >> iter 100000, loss: 0.225798
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 17.692738
 >> iter 2000, loss: 8.738727
 >> iter 3000, loss: 3.730247
 >> iter 4000, loss: 1.958843
 >> iter 5000, loss: 1.273404
 >> iter 6000, loss: 0.938970
 >> iter 7000, loss: 0.859557
 >> iter 8000, loss: 0.788949
 >> iter 9000, loss: 0.639738
 >> iter 10000, loss: 0.752227
   Number of active neurons: 6
 >> iter 11000, loss: 0.564690
 >> iter 12000, loss: 0.424839
 >> iter 13000, loss: 0.521529
 >> iter 14000, loss: 0.586298
 >> iter 15000, loss: 0.568012
 >> iter 16000, loss: 0.659767
 >> iter 17000, loss: 0.472479
 >> iter 18000, loss: 0.336517
 >> iter 19000, loss: 0.700839
 >> iter 20000, loss: 0.880489
   Number of active neurons: 6
 >> iter 21000, loss: 0.668868
 >> iter 22000, loss: 0.826795
 >> iter 23000, loss: 0.663016
 >> iter 24000, loss: 0.767738
 >> iter 25000, loss: 0.697559
 >> iter 26000, loss: 0.521759
 >> iter 27000, loss: 0.369512
 >> iter 28000, loss: 0.519058
 >> iter 29000, loss: 0.482781
 >> iter 30000, loss: 0.344779
   Number of active neurons: 5
 >> iter 31000, loss: 0.477769
 >> iter 32000, loss: 0.505290
 >> iter 33000, loss: 0.407927
 >> iter 34000, loss: 0.466666
 >> iter 35000, loss: 0.507267
 >> iter 36000, loss: 0.452614
 >> iter 37000, loss: 0.375392
 >> iter 38000, loss: 0.481262
 >> iter 39000, loss: 0.491932
 >> iter 40000, loss: 0.374763
   Number of active neurons: 5
 >> iter 41000, loss: 0.313518
 >> iter 42000, loss: 0.257320
 >> iter 43000, loss: 0.318376
 >> iter 44000, loss: 0.475970
 >> iter 45000, loss: 0.550781
 >> iter 46000, loss: 0.522289
 >> iter 47000, loss: 0.519288
 >> iter 48000, loss: 0.370214
 >> iter 49000, loss: 0.542358
 >> iter 50000, loss: 0.563018
   Number of active neurons: 5
 >> iter 51000, loss: 0.501205
 >> iter 52000, loss: 0.394647
 >> iter 53000, loss: 0.299974
 >> iter 54000, loss: 0.443428
 >> iter 55000, loss: 0.414067
 >> iter 56000, loss: 0.446070
 >> iter 57000, loss: 0.420283
 >> iter 58000, loss: 0.547101
 >> iter 59000, loss: 0.657808
 >> iter 60000, loss: 0.601223
   Number of active neurons: 5
 >> iter 61000, loss: 0.599226
 >> iter 62000, loss: 0.401872
 >> iter 63000, loss: 0.322846
 >> iter 64000, loss: 0.501272
 >> iter 65000, loss: 0.624890
 >> iter 66000, loss: 0.479480
 >> iter 67000, loss: 0.297696
 >> iter 68000, loss: 0.384455
 >> iter 69000, loss: 0.613314
 >> iter 70000, loss: 0.462712
   Number of active neurons: 5
 >> iter 71000, loss: 0.418904
 >> iter 72000, loss: 0.534032
 >> iter 73000, loss: 0.481786
 >> iter 74000, loss: 0.640986
 >> iter 75000, loss: 0.378949
 >> iter 76000, loss: 0.355863
 >> iter 77000, loss: 0.349283
 >> iter 78000, loss: 0.677045
 >> iter 79000, loss: 0.610873
 >> iter 80000, loss: 0.515403
   Number of active neurons: 5
 >> iter 81000, loss: 0.420712
 >> iter 82000, loss: 0.518324
 >> iter 83000, loss: 0.529302
 >> iter 84000, loss: 0.500965
 >> iter 85000, loss: 0.404768
 >> iter 86000, loss: 0.376831
 >> iter 87000, loss: 0.467644
 >> iter 88000, loss: 0.545777
 >> iter 89000, loss: 0.500937
 >> iter 90000, loss: 0.460704
   Number of active neurons: 5
 >> iter 91000, loss: 0.434043
 >> iter 92000, loss: 0.319569
 >> iter 93000, loss: 0.556435
 >> iter 94000, loss: 0.615656
 >> iter 95000, loss: 0.382418
 >> iter 96000, loss: 0.394512
 >> iter 97000, loss: 0.448697
 >> iter 98000, loss: 0.373644
 >> iter 99000, loss: 0.508358
 >> iter 100000, loss: 0.348631
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 18.485752
 >> iter 2000, loss: 10.664987
 >> iter 3000, loss: 4.911084
 >> iter 4000, loss: 2.163793
 >> iter 5000, loss: 1.237508
 >> iter 6000, loss: 0.862135
 >> iter 7000, loss: 1.047150
 >> iter 8000, loss: 0.633619
 >> iter 9000, loss: 0.571422
 >> iter 10000, loss: 0.506823
   Number of active neurons: 7
 >> iter 11000, loss: 0.348558
 >> iter 12000, loss: 0.247641
 >> iter 13000, loss: 0.156930
 >> iter 14000, loss: 0.676722
 >> iter 15000, loss: 0.489602
 >> iter 16000, loss: 0.281265
 >> iter 17000, loss: 0.397147
 >> iter 18000, loss: 0.355214
 >> iter 19000, loss: 0.483494
 >> iter 20000, loss: 0.601587
   Number of active neurons: 6
 >> iter 21000, loss: 0.302378
 >> iter 22000, loss: 0.305387
 >> iter 23000, loss: 0.198320
 >> iter 24000, loss: 0.331586
 >> iter 25000, loss: 0.220773
 >> iter 26000, loss: 0.281967
 >> iter 27000, loss: 0.349253
 >> iter 28000, loss: 0.295877
 >> iter 29000, loss: 0.209254
 >> iter 30000, loss: 0.370508
   Number of active neurons: 5
 >> iter 31000, loss: 0.318074
 >> iter 32000, loss: 0.348994
 >> iter 33000, loss: 0.290979
 >> iter 34000, loss: 0.362552
 >> iter 35000, loss: 0.278420
 >> iter 36000, loss: 0.541085
 >> iter 37000, loss: 0.417845
 >> iter 38000, loss: 0.249693
 >> iter 39000, loss: 0.390171
 >> iter 40000, loss: 0.411041
   Number of active neurons: 5
 >> iter 41000, loss: 0.319551
 >> iter 42000, loss: 0.238463
 >> iter 43000, loss: 0.303138
 >> iter 44000, loss: 0.472621
 >> iter 45000, loss: 0.471678
 >> iter 46000, loss: 0.353453
 >> iter 47000, loss: 0.437545
 >> iter 48000, loss: 0.495411
 >> iter 49000, loss: 0.469084
 >> iter 50000, loss: 0.294823
   Number of active neurons: 4
 >> iter 51000, loss: 0.190041
 >> iter 52000, loss: 0.172989
 >> iter 53000, loss: 0.219072
 >> iter 54000, loss: 0.348500
 >> iter 55000, loss: 0.220660
 >> iter 56000, loss: 0.239498
 >> iter 57000, loss: 0.321195
 >> iter 58000, loss: 0.268605
 >> iter 59000, loss: 0.401692
 >> iter 60000, loss: 0.210500
   Number of active neurons: 3
 >> iter 61000, loss: 0.511490
 >> iter 62000, loss: 0.257033
 >> iter 63000, loss: 0.349626
 >> iter 64000, loss: 0.226518
 >> iter 65000, loss: 0.206615
 >> iter 66000, loss: 0.204601
 >> iter 67000, loss: 0.388207
 >> iter 68000, loss: 0.337953
 >> iter 69000, loss: 0.409608
 >> iter 70000, loss: 0.265378
   Number of active neurons: 3
 >> iter 71000, loss: 0.397854
 >> iter 72000, loss: 0.506717
 >> iter 73000, loss: 0.428297
 >> iter 74000, loss: 0.354841
 >> iter 75000, loss: 0.380513
 >> iter 76000, loss: 0.226976
 >> iter 77000, loss: 0.220516
 >> iter 78000, loss: 0.374386
 >> iter 79000, loss: 0.264416
 >> iter 80000, loss: 0.245692
   Number of active neurons: 3
 >> iter 81000, loss: 0.296915
 >> iter 82000, loss: 0.372087
 >> iter 83000, loss: 0.371364
 >> iter 84000, loss: 0.260121
 >> iter 85000, loss: 0.217270
 >> iter 86000, loss: 0.114996
 >> iter 87000, loss: 0.142468
 >> iter 88000, loss: 0.374915
 >> iter 89000, loss: 0.262967
 >> iter 90000, loss: 0.213622
   Number of active neurons: 3
 >> iter 91000, loss: 0.357479
 >> iter 92000, loss: 0.303152
 >> iter 93000, loss: 0.218538
 >> iter 94000, loss: 0.339932
 >> iter 95000, loss: 0.181593
 >> iter 96000, loss: 0.191233
 >> iter 97000, loss: 0.098932
 >> iter 98000, loss: 0.247187
 >> iter 99000, loss: 0.315944
 >> iter 100000, loss: 0.207528
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.628961
 >> iter 2000, loss: 8.565533
 >> iter 3000, loss: 3.833536
 >> iter 4000, loss: 1.792316
 >> iter 5000, loss: 0.985917
 >> iter 6000, loss: 0.679724
 >> iter 7000, loss: 0.532566
 >> iter 8000, loss: 0.425631
 >> iter 9000, loss: 0.596900
 >> iter 10000, loss: 0.367593
   Number of active neurons: 7
 >> iter 11000, loss: 0.549981
 >> iter 12000, loss: 0.438451
 >> iter 13000, loss: 0.681770
 >> iter 14000, loss: 0.416080
 >> iter 15000, loss: 0.197356
 >> iter 16000, loss: 0.484848
 >> iter 17000, loss: 0.381863
 >> iter 18000, loss: 0.345165
 >> iter 19000, loss: 0.189820
 >> iter 20000, loss: 0.221218
   Number of active neurons: 7
 >> iter 21000, loss: 0.332983
 >> iter 22000, loss: 0.242894
 >> iter 23000, loss: 0.547435
 >> iter 24000, loss: 0.289768
 >> iter 25000, loss: 0.338668
 >> iter 26000, loss: 0.465878
 >> iter 27000, loss: 0.548881
 >> iter 28000, loss: 0.258232
 >> iter 29000, loss: 0.313032
 >> iter 30000, loss: 0.309312
   Number of active neurons: 7
 >> iter 31000, loss: 0.265349
 >> iter 32000, loss: 0.477935
 >> iter 33000, loss: 0.450521
 >> iter 34000, loss: 0.242308
 >> iter 35000, loss: 0.178064
 >> iter 36000, loss: 0.340924
 >> iter 37000, loss: 0.457778
 >> iter 38000, loss: 0.295979
 >> iter 39000, loss: 0.367848
 >> iter 40000, loss: 0.236079
   Number of active neurons: 7
 >> iter 41000, loss: 0.377617
 >> iter 42000, loss: 0.238584
 >> iter 43000, loss: 0.160430
 >> iter 44000, loss: 0.288808
 >> iter 45000, loss: 0.397614
 >> iter 46000, loss: 0.464544
 >> iter 47000, loss: 0.486014
 >> iter 48000, loss: 0.351500
 >> iter 49000, loss: 0.371097
 >> iter 50000, loss: 0.421788
   Number of active neurons: 7
 >> iter 51000, loss: 0.525395
 >> iter 52000, loss: 0.267963
 >> iter 53000, loss: 0.288613
 >> iter 54000, loss: 0.317486
 >> iter 55000, loss: 0.491151
 >> iter 56000, loss: 0.419454
 >> iter 57000, loss: 0.275264
 >> iter 58000, loss: 0.229576
 >> iter 59000, loss: 0.149328
 >> iter 60000, loss: 0.235166
   Number of active neurons: 6
 >> iter 61000, loss: 0.249524
 >> iter 62000, loss: 0.294783
 >> iter 63000, loss: 0.209220
 >> iter 64000, loss: 0.387643
 >> iter 65000, loss: 0.427127
 >> iter 66000, loss: 0.372435
 >> iter 67000, loss: 0.352602
 >> iter 68000, loss: 0.188143
 >> iter 69000, loss: 0.193048
 >> iter 70000, loss: 0.196190
   Number of active neurons: 6
 >> iter 71000, loss: 0.581535
 >> iter 72000, loss: 0.434325
 >> iter 73000, loss: 0.378367
 >> iter 74000, loss: 0.178427
 >> iter 75000, loss: 0.403653
 >> iter 76000, loss: 0.285273
 >> iter 77000, loss: 0.354386
 >> iter 78000, loss: 0.383207
 >> iter 79000, loss: 0.361813
 >> iter 80000, loss: 0.165982
   Number of active neurons: 6
 >> iter 81000, loss: 0.194756
 >> iter 82000, loss: 0.304232
 >> iter 83000, loss: 0.285949
 >> iter 84000, loss: 0.375861
 >> iter 85000, loss: 0.420246
 >> iter 86000, loss: 0.353192
 >> iter 87000, loss: 0.290457
 >> iter 88000, loss: 0.285019
 >> iter 89000, loss: 0.220227
 >> iter 90000, loss: 0.197668
   Number of active neurons: 4
 >> iter 91000, loss: 0.212626
 >> iter 92000, loss: 0.237638
 >> iter 93000, loss: 0.274316
 >> iter 94000, loss: 0.186889
 >> iter 95000, loss: 0.292363
 >> iter 96000, loss: 0.359549
 >> iter 97000, loss: 0.197897
 >> iter 98000, loss: 0.310571
 >> iter 99000, loss: 0.263493
 >> iter 100000, loss: 0.449482
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.048346
 >> iter 2000, loss: 9.337361
 >> iter 3000, loss: 4.312667
 >> iter 4000, loss: 2.094244
 >> iter 5000, loss: 0.936582
 >> iter 6000, loss: 0.555180
 >> iter 7000, loss: 0.551938
 >> iter 8000, loss: 0.377716
 >> iter 9000, loss: 0.303346
 >> iter 10000, loss: 0.447743
   Number of active neurons: 6
 >> iter 11000, loss: 0.436946
 >> iter 12000, loss: 0.458600
 >> iter 13000, loss: 0.558810
 >> iter 14000, loss: 0.298677
 >> iter 15000, loss: 0.329300
 >> iter 16000, loss: 0.348189
 >> iter 17000, loss: 0.287498
 >> iter 18000, loss: 0.251297
 >> iter 19000, loss: 0.481041
 >> iter 20000, loss: 0.381204
   Number of active neurons: 6
 >> iter 21000, loss: 0.368942
 >> iter 22000, loss: 0.321299
 >> iter 23000, loss: 0.312990
 >> iter 24000, loss: 0.316649
 >> iter 25000, loss: 0.449492
 >> iter 26000, loss: 0.494816
 >> iter 27000, loss: 0.346666
 >> iter 28000, loss: 0.466551
 >> iter 29000, loss: 0.462744
 >> iter 30000, loss: 0.344960
   Number of active neurons: 5
 >> iter 31000, loss: 0.369196
 >> iter 32000, loss: 0.222884
 >> iter 33000, loss: 0.303242
 >> iter 34000, loss: 0.329928
 >> iter 35000, loss: 0.273377
 >> iter 36000, loss: 0.324981
 >> iter 37000, loss: 0.281265
 >> iter 38000, loss: 0.456523
 >> iter 39000, loss: 0.410819
 >> iter 40000, loss: 0.315730
   Number of active neurons: 5
 >> iter 41000, loss: 0.416111
 >> iter 42000, loss: 0.339971
 >> iter 43000, loss: 0.228580
 >> iter 44000, loss: 0.164225
 >> iter 45000, loss: 0.282815
 >> iter 46000, loss: 0.266128
 >> iter 47000, loss: 0.232328
 >> iter 48000, loss: 0.260244
 >> iter 49000, loss: 0.267803
 >> iter 50000, loss: 0.275642
   Number of active neurons: 5
 >> iter 51000, loss: 0.290212
 >> iter 52000, loss: 0.260708
 >> iter 53000, loss: 0.373498
 >> iter 54000, loss: 0.235629
 >> iter 55000, loss: 0.205139
 >> iter 56000, loss: 0.336425
 >> iter 57000, loss: 0.356100
 >> iter 58000, loss: 0.230789
 >> iter 59000, loss: 0.342575
 >> iter 60000, loss: 0.387502
   Number of active neurons: 5
 >> iter 61000, loss: 0.315693
 >> iter 62000, loss: 0.319966
 >> iter 63000, loss: 0.257457
 >> iter 64000, loss: 0.278591
 >> iter 65000, loss: 0.211725
 >> iter 66000, loss: 0.305732
 >> iter 67000, loss: 0.292028
 >> iter 68000, loss: 0.253195
 >> iter 69000, loss: 0.282100
 >> iter 70000, loss: 0.405216
   Number of active neurons: 5
 >> iter 71000, loss: 0.344874
 >> iter 72000, loss: 0.368165
 >> iter 73000, loss: 0.245591
 >> iter 74000, loss: 0.376535
 >> iter 75000, loss: 0.413301
 >> iter 76000, loss: 0.414464
 >> iter 77000, loss: 0.321861
 >> iter 78000, loss: 0.280884
 >> iter 79000, loss: 0.231806
 >> iter 80000, loss: 0.125455
   Number of active neurons: 5
 >> iter 81000, loss: 0.326981
 >> iter 82000, loss: 0.297467
 >> iter 83000, loss: 0.213876
 >> iter 84000, loss: 0.263236
 >> iter 85000, loss: 0.153528
 >> iter 86000, loss: 0.209908
 >> iter 87000, loss: 0.286656
 >> iter 88000, loss: 0.206010
 >> iter 89000, loss: 0.149168
 >> iter 90000, loss: 0.149906
   Number of active neurons: 4
 >> iter 91000, loss: 0.118278
 >> iter 92000, loss: 0.128089
 >> iter 93000, loss: 0.159828
 >> iter 94000, loss: 0.277558
 >> iter 95000, loss: 0.346500
 >> iter 96000, loss: 0.223184
 >> iter 97000, loss: 0.210997
 >> iter 98000, loss: 0.205367
 >> iter 99000, loss: 0.170490
 >> iter 100000, loss: 0.144473
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.389823
 >> iter 2000, loss: 8.487751
 >> iter 3000, loss: 3.699639
 >> iter 4000, loss: 1.782884
 >> iter 5000, loss: 0.763056
 >> iter 6000, loss: 0.730959
 >> iter 7000, loss: 0.571316
 >> iter 8000, loss: 0.754239
 >> iter 9000, loss: 0.400744
 >> iter 10000, loss: 0.275136
   Number of active neurons: 5
 >> iter 11000, loss: 0.272410
 >> iter 12000, loss: 0.336176
 >> iter 13000, loss: 0.284418
 >> iter 14000, loss: 0.242623
 >> iter 15000, loss: 0.226166
 >> iter 16000, loss: 0.409121
 >> iter 17000, loss: 0.481774
 >> iter 18000, loss: 0.289139
 >> iter 19000, loss: 0.459953
 >> iter 20000, loss: 0.381269
   Number of active neurons: 5
 >> iter 21000, loss: 0.292864
 >> iter 22000, loss: 0.267442
 >> iter 23000, loss: 0.181255
 >> iter 24000, loss: 0.327802
 >> iter 25000, loss: 0.307398
 >> iter 26000, loss: 0.229519
 >> iter 27000, loss: 0.359162
 >> iter 28000, loss: 0.422683
 >> iter 29000, loss: 0.311432
 >> iter 30000, loss: 0.229277
   Number of active neurons: 5
 >> iter 31000, loss: 0.243890
 >> iter 32000, loss: 0.300890
 >> iter 33000, loss: 0.199111
 >> iter 34000, loss: 0.345570
 >> iter 35000, loss: 0.304406
 >> iter 36000, loss: 0.286532
 >> iter 37000, loss: 0.340899
 >> iter 38000, loss: 0.367264
 >> iter 39000, loss: 0.199288
 >> iter 40000, loss: 0.239645
   Number of active neurons: 4
 >> iter 41000, loss: 0.281533
 >> iter 42000, loss: 0.214075
 >> iter 43000, loss: 0.382149
 >> iter 44000, loss: 0.204313
 >> iter 45000, loss: 0.386476
 >> iter 46000, loss: 0.297815
 >> iter 47000, loss: 0.360692
 >> iter 48000, loss: 0.176773
 >> iter 49000, loss: 0.236129
 >> iter 50000, loss: 0.289715
   Number of active neurons: 4
 >> iter 51000, loss: 0.181685
 >> iter 52000, loss: 0.209626
 >> iter 53000, loss: 0.239993
 >> iter 54000, loss: 0.359720
 >> iter 55000, loss: 0.356222
 >> iter 56000, loss: 0.486134
 >> iter 57000, loss: 0.258113
 >> iter 58000, loss: 0.194768
 >> iter 59000, loss: 0.293829
 >> iter 60000, loss: 0.270902
   Number of active neurons: 4
 >> iter 61000, loss: 0.210769
 >> iter 62000, loss: 0.189485
 >> iter 63000, loss: 0.286085
 >> iter 64000, loss: 0.405337
 >> iter 65000, loss: 0.308453
 >> iter 66000, loss: 0.303304
 >> iter 67000, loss: 0.329713
 >> iter 68000, loss: 0.269510
 >> iter 69000, loss: 0.293171
 >> iter 70000, loss: 0.272912
   Number of active neurons: 4
 >> iter 71000, loss: 0.198509
 >> iter 72000, loss: 0.231866
 >> iter 73000, loss: 0.258913
 >> iter 74000, loss: 0.411245
 >> iter 75000, loss: 0.405121
 >> iter 76000, loss: 0.463277
 >> iter 77000, loss: 0.387330
 >> iter 78000, loss: 0.457246
 >> iter 79000, loss: 0.386744
 >> iter 80000, loss: 0.397253
   Number of active neurons: 4
 >> iter 81000, loss: 0.367322
 >> iter 82000, loss: 0.305779
 >> iter 83000, loss: 0.190687
 >> iter 84000, loss: 0.312527
 >> iter 85000, loss: 0.305538
 >> iter 86000, loss: 0.189211
 >> iter 87000, loss: 0.266993
 >> iter 88000, loss: 0.351671
 >> iter 89000, loss: 0.283441
 >> iter 90000, loss: 0.201022
   Number of active neurons: 4
 >> iter 91000, loss: 0.355442
 >> iter 92000, loss: 0.258271
 >> iter 93000, loss: 0.447742
 >> iter 94000, loss: 0.326824
 >> iter 95000, loss: 0.230087
 >> iter 96000, loss: 0.253314
 >> iter 97000, loss: 0.278147
 >> iter 98000, loss: 0.245171
 >> iter 99000, loss: 0.182013
 >> iter 100000, loss: 0.336950
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 17.807095
 >> iter 2000, loss: 9.266003
 >> iter 3000, loss: 4.351830
 >> iter 4000, loss: 2.032029
 >> iter 5000, loss: 0.844305
 >> iter 6000, loss: 0.625573
 >> iter 7000, loss: 0.525439
 >> iter 8000, loss: 0.389736
 >> iter 9000, loss: 0.541664
 >> iter 10000, loss: 0.380169
   Number of active neurons: 4
 >> iter 11000, loss: 0.409980
 >> iter 12000, loss: 0.525649
 >> iter 13000, loss: 0.516156
 >> iter 14000, loss: 0.355502
 >> iter 15000, loss: 0.269533
 >> iter 16000, loss: 0.374224
 >> iter 17000, loss: 0.255581
 >> iter 18000, loss: 0.326035
 >> iter 19000, loss: 0.213196
 >> iter 20000, loss: 0.405660
   Number of active neurons: 4
 >> iter 21000, loss: 0.259832
 >> iter 22000, loss: 0.395046
 >> iter 23000, loss: 0.514137
 >> iter 24000, loss: 0.237386
 >> iter 25000, loss: 0.260302
 >> iter 26000, loss: 0.312921
 >> iter 27000, loss: 0.502823
 >> iter 28000, loss: 0.379042
 >> iter 29000, loss: 0.244649
 >> iter 30000, loss: 0.209361
   Number of active neurons: 4
 >> iter 31000, loss: 0.193734
 >> iter 32000, loss: 0.248319
 >> iter 33000, loss: 0.292054
 >> iter 34000, loss: 0.429903
 >> iter 35000, loss: 0.457819
 >> iter 36000, loss: 0.314098
 >> iter 37000, loss: 0.343946
 >> iter 38000, loss: 0.324268
 >> iter 39000, loss: 0.279587
 >> iter 40000, loss: 0.227282
   Number of active neurons: 3
 >> iter 41000, loss: 0.305591
 >> iter 42000, loss: 0.208751
 >> iter 43000, loss: 0.178503
 >> iter 44000, loss: 0.225354
 >> iter 45000, loss: 0.168395
 >> iter 46000, loss: 0.261247
 >> iter 47000, loss: 0.306493
 >> iter 48000, loss: 0.335445
 >> iter 49000, loss: 0.272270
 >> iter 50000, loss: 0.338903
   Number of active neurons: 3
 >> iter 51000, loss: 0.389918
 >> iter 52000, loss: 0.308514
 >> iter 53000, loss: 0.305565
 >> iter 54000, loss: 0.339741
 >> iter 55000, loss: 0.557129
 >> iter 56000, loss: 0.429511
 >> iter 57000, loss: 0.235920
 >> iter 58000, loss: 0.193295
 >> iter 59000, loss: 0.288352
 >> iter 60000, loss: 0.498739
   Number of active neurons: 3
 >> iter 61000, loss: 0.422859
 >> iter 62000, loss: 0.436387
 >> iter 63000, loss: 0.429654
 >> iter 64000, loss: 0.297746
 >> iter 65000, loss: 0.178581
 >> iter 66000, loss: 0.180011
 >> iter 67000, loss: 0.336544
 >> iter 68000, loss: 0.232349
 >> iter 69000, loss: 0.411042
 >> iter 70000, loss: 0.213760
   Number of active neurons: 3
 >> iter 71000, loss: 0.179381
 >> iter 72000, loss: 0.214276
 >> iter 73000, loss: 0.212398
 >> iter 74000, loss: 0.237233
 >> iter 75000, loss: 0.189779
 >> iter 76000, loss: 0.369696
 >> iter 77000, loss: 0.418593
 >> iter 78000, loss: 0.295548
 >> iter 79000, loss: 0.371973
 >> iter 80000, loss: 0.371698
   Number of active neurons: 3
 >> iter 81000, loss: 0.240224
 >> iter 82000, loss: 0.467025
 >> iter 83000, loss: 0.464617
 >> iter 84000, loss: 0.263241
 >> iter 85000, loss: 0.399307
 >> iter 86000, loss: 0.211090
 >> iter 87000, loss: 0.324871
 >> iter 88000, loss: 0.280507
 >> iter 89000, loss: 0.226913
 >> iter 90000, loss: 0.210418
   Number of active neurons: 3
 >> iter 91000, loss: 0.264856
 >> iter 92000, loss: 0.143941
 >> iter 93000, loss: 0.168296
 >> iter 94000, loss: 0.189970
 >> iter 95000, loss: 0.104301
 >> iter 96000, loss: 0.287679
 >> iter 97000, loss: 0.217522
 >> iter 98000, loss: 0.309900
 >> iter 99000, loss: 0.270093
 >> iter 100000, loss: 0.223957
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.503571
 >> iter 2000, loss: 8.491051
 >> iter 3000, loss: 4.035122
 >> iter 4000, loss: 2.016142
 >> iter 5000, loss: 1.052423
 >> iter 6000, loss: 0.704457
 >> iter 7000, loss: 0.689990
 >> iter 8000, loss: 0.456962
 >> iter 9000, loss: 0.405652
 >> iter 10000, loss: 0.275729
   Number of active neurons: 7
 >> iter 11000, loss: 0.480452
 >> iter 12000, loss: 0.462395
 >> iter 13000, loss: 0.388409
 >> iter 14000, loss: 0.482499
 >> iter 15000, loss: 0.386288
 >> iter 16000, loss: 0.287784
 >> iter 17000, loss: 0.399408
 >> iter 18000, loss: 0.346218
 >> iter 19000, loss: 0.477548
 >> iter 20000, loss: 0.454215
   Number of active neurons: 4
 >> iter 21000, loss: 0.281060
 >> iter 22000, loss: 0.336862
 >> iter 23000, loss: 0.478646
 >> iter 24000, loss: 0.574197
 >> iter 25000, loss: 0.383779
 >> iter 26000, loss: 0.379416
 >> iter 27000, loss: 0.337795
 >> iter 28000, loss: 0.204645
 >> iter 29000, loss: 0.357507
 >> iter 30000, loss: 0.273819
   Number of active neurons: 4
 >> iter 31000, loss: 0.289445
 >> iter 32000, loss: 0.279836
 >> iter 33000, loss: 0.326540
 >> iter 34000, loss: 0.251061
 >> iter 35000, loss: 0.293425
 >> iter 36000, loss: 0.615800
 >> iter 37000, loss: 0.360170
 >> iter 38000, loss: 0.253084
 >> iter 39000, loss: 0.298630
 >> iter 40000, loss: 0.416567
   Number of active neurons: 4
 >> iter 41000, loss: 0.280130
 >> iter 42000, loss: 0.312755
 >> iter 43000, loss: 0.160995
 >> iter 44000, loss: 0.110563
 >> iter 45000, loss: 0.353736
 >> iter 46000, loss: 0.516263
 >> iter 47000, loss: 0.549471
 >> iter 48000, loss: 0.420949
 >> iter 49000, loss: 0.360860
 >> iter 50000, loss: 0.375673
   Number of active neurons: 4
 >> iter 51000, loss: 0.342123
 >> iter 52000, loss: 0.275759
 >> iter 53000, loss: 0.176463
 >> iter 54000, loss: 0.543829
 >> iter 55000, loss: 0.354281
 >> iter 56000, loss: 0.554337
 >> iter 57000, loss: 0.418955
 >> iter 58000, loss: 0.446358
 >> iter 59000, loss: 0.309771
 >> iter 60000, loss: 0.198497
   Number of active neurons: 4
 >> iter 61000, loss: 0.276621
 >> iter 62000, loss: 0.270994
 >> iter 63000, loss: 0.204356
 >> iter 64000, loss: 0.439282
 >> iter 65000, loss: 0.317300
 >> iter 66000, loss: 0.467914
 >> iter 67000, loss: 0.335960
 >> iter 68000, loss: 0.188062
 >> iter 69000, loss: 0.243852
 >> iter 70000, loss: 0.310901
   Number of active neurons: 4
 >> iter 71000, loss: 0.493538
 >> iter 72000, loss: 0.520242
 >> iter 73000, loss: 0.514964
 >> iter 74000, loss: 0.389495
 >> iter 75000, loss: 0.484417
 >> iter 76000, loss: 0.387944
 >> iter 77000, loss: 0.358479
 >> iter 78000, loss: 0.246617
 >> iter 79000, loss: 0.178401
 >> iter 80000, loss: 0.300220
   Number of active neurons: 4
 >> iter 81000, loss: 0.280166
 >> iter 82000, loss: 0.317969
 >> iter 83000, loss: 0.225979
 >> iter 84000, loss: 0.367557
 >> iter 85000, loss: 0.311715
 >> iter 86000, loss: 0.173556
 >> iter 87000, loss: 0.341860
 >> iter 88000, loss: 0.267751
 >> iter 89000, loss: 0.259973
 >> iter 90000, loss: 0.302890
   Number of active neurons: 4
 >> iter 91000, loss: 0.531968
 >> iter 92000, loss: 0.337697
 >> iter 93000, loss: 0.307010
 >> iter 94000, loss: 0.261883
 >> iter 95000, loss: 0.377715
 >> iter 96000, loss: 0.185837
 >> iter 97000, loss: 0.218383
 >> iter 98000, loss: 0.611136
 >> iter 99000, loss: 0.350557
 >> iter 100000, loss: 0.233240
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.603479
 >> iter 2000, loss: 9.219558
 >> iter 3000, loss: 4.472744
 >> iter 4000, loss: 2.490460
 >> iter 5000, loss: 1.227313
 >> iter 6000, loss: 0.815964
 >> iter 7000, loss: 0.725240
 >> iter 8000, loss: 0.572354
 >> iter 9000, loss: 0.649794
 >> iter 10000, loss: 0.786766
   Number of active neurons: 9
 >> iter 11000, loss: 0.564007
 >> iter 12000, loss: 0.488484
 >> iter 13000, loss: 0.464186
 >> iter 14000, loss: 0.367674
 >> iter 15000, loss: 0.568134
 >> iter 16000, loss: 0.524385
 >> iter 17000, loss: 0.456395
 >> iter 18000, loss: 0.347708
 >> iter 19000, loss: 0.237061
 >> iter 20000, loss: 0.320625
   Number of active neurons: 9
 >> iter 21000, loss: 0.368517
 >> iter 22000, loss: 0.402729
 >> iter 23000, loss: 0.232601
 >> iter 24000, loss: 0.452912
 >> iter 25000, loss: 0.309557
 >> iter 26000, loss: 0.342286
 >> iter 27000, loss: 0.453115
 >> iter 28000, loss: 0.252324
 >> iter 29000, loss: 0.359664
 >> iter 30000, loss: 0.304343
   Number of active neurons: 6
 >> iter 31000, loss: 0.272194
 >> iter 32000, loss: 0.471132
 >> iter 33000, loss: 0.365185
 >> iter 34000, loss: 0.249048
 >> iter 35000, loss: 0.345095
 >> iter 36000, loss: 0.286678
 >> iter 37000, loss: 0.274272
 >> iter 38000, loss: 0.340644
 >> iter 39000, loss: 0.275542
 >> iter 40000, loss: 0.363968
   Number of active neurons: 5
 >> iter 41000, loss: 0.329650
 >> iter 42000, loss: 0.403085
 >> iter 43000, loss: 0.310860
 >> iter 44000, loss: 0.235683
 >> iter 45000, loss: 0.392083
 >> iter 46000, loss: 0.296580
 >> iter 47000, loss: 0.206361
 >> iter 48000, loss: 0.424098
 >> iter 49000, loss: 0.522172
 >> iter 50000, loss: 0.295133
   Number of active neurons: 4
 >> iter 51000, loss: 0.470385
 >> iter 52000, loss: 0.432819
 >> iter 53000, loss: 0.421804
 >> iter 54000, loss: 0.386017
 >> iter 55000, loss: 0.486356
 >> iter 56000, loss: 0.581434
 >> iter 57000, loss: 0.298189
 >> iter 58000, loss: 0.300425
 >> iter 59000, loss: 0.411330
 >> iter 60000, loss: 0.396927
   Number of active neurons: 3
 >> iter 61000, loss: 0.356033
 >> iter 62000, loss: 0.344469
 >> iter 63000, loss: 0.373563
 >> iter 64000, loss: 0.230991
 >> iter 65000, loss: 0.432764
 >> iter 66000, loss: 0.240079
 >> iter 67000, loss: 0.275012
 >> iter 68000, loss: 0.703589
 >> iter 69000, loss: 0.567499
 >> iter 70000, loss: 0.473386
   Number of active neurons: 3
 >> iter 71000, loss: 0.311282
 >> iter 72000, loss: 0.296622
 >> iter 73000, loss: 0.226908
 >> iter 74000, loss: 0.364952
 >> iter 75000, loss: 0.245727
 >> iter 76000, loss: 0.269524
 >> iter 77000, loss: 0.219743
 >> iter 78000, loss: 0.346581
 >> iter 79000, loss: 0.236883
 >> iter 80000, loss: 0.226637
   Number of active neurons: 3
 >> iter 81000, loss: 0.249122
 >> iter 82000, loss: 0.283664
 >> iter 83000, loss: 0.298919
 >> iter 84000, loss: 0.271333
 >> iter 85000, loss: 0.192867
 >> iter 86000, loss: 0.225522
 >> iter 87000, loss: 0.138123
 >> iter 88000, loss: 0.130272
 >> iter 89000, loss: 0.126315
 >> iter 90000, loss: 0.230581
   Number of active neurons: 3
 >> iter 91000, loss: 0.150449
 >> iter 92000, loss: 0.193060
 >> iter 93000, loss: 0.226258
 >> iter 94000, loss: 0.191560
 >> iter 95000, loss: 0.139032
 >> iter 96000, loss: 0.108001
 >> iter 97000, loss: 0.193805
 >> iter 98000, loss: 0.244834
 >> iter 99000, loss: 0.235785
 >> iter 100000, loss: 0.277481
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

