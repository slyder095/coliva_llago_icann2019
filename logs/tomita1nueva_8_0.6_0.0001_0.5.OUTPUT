 > Problema: tomita1nueva
 > Args:
   - Hidden size: 8
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.971286
 >> iter 2000, loss: 4.074268
 >> iter 3000, loss: 1.523578
 >> iter 4000, loss: 0.583939
 >> iter 5000, loss: 0.242167
 >> iter 6000, loss: 0.110213
 >> iter 7000, loss: 0.063958
 >> iter 8000, loss: 0.057808
 >> iter 9000, loss: 0.040679
 >> iter 10000, loss: 0.033566
   Number of active neurons: 4
 >> iter 11000, loss: 0.033721
 >> iter 12000, loss: 0.027950
 >> iter 13000, loss: 0.038807
 >> iter 14000, loss: 0.032099
 >> iter 15000, loss: 0.031573
 >> iter 16000, loss: 0.030924
 >> iter 17000, loss: 0.032826
 >> iter 18000, loss: 0.028805
 >> iter 19000, loss: 0.036013
 >> iter 20000, loss: 0.028413
   Number of active neurons: 4
 >> iter 21000, loss: 0.028112
 >> iter 22000, loss: 0.040415
 >> iter 23000, loss: 0.032451
 >> iter 24000, loss: 0.041267
 >> iter 25000, loss: 0.044655
 >> iter 26000, loss: 0.031984
 >> iter 27000, loss: 0.030394
 >> iter 28000, loss: 0.031793
 >> iter 29000, loss: 0.032979
 >> iter 30000, loss: 0.027920
   Number of active neurons: 4
 >> iter 31000, loss: 0.027577
 >> iter 32000, loss: 0.026342
 >> iter 33000, loss: 0.027739
 >> iter 34000, loss: 0.023778
 >> iter 35000, loss: 0.023670
 >> iter 36000, loss: 0.025206
 >> iter 37000, loss: 0.029243
 >> iter 38000, loss: 0.026369
 >> iter 39000, loss: 0.023391
 >> iter 40000, loss: 0.021826
   Number of active neurons: 2
 >> iter 41000, loss: 0.027312
 >> iter 42000, loss: 0.022461
 >> iter 43000, loss: 0.020106
 >> iter 44000, loss: 0.021489
 >> iter 45000, loss: 0.020263
 >> iter 46000, loss: 0.022725
 >> iter 47000, loss: 0.024563
 >> iter 48000, loss: 0.021919
 >> iter 49000, loss: 0.032301
 >> iter 50000, loss: 0.031128
   Number of active neurons: 2
 >> iter 51000, loss: 0.035311
 >> iter 52000, loss: 0.025096
 >> iter 53000, loss: 0.025104
 >> iter 54000, loss: 0.024106
 >> iter 55000, loss: 0.032015
 >> iter 56000, loss: 0.027264
 >> iter 57000, loss: 0.022744
 >> iter 58000, loss: 0.024918
 >> iter 59000, loss: 0.024958
 >> iter 60000, loss: 0.021584
   Number of active neurons: 2
 >> iter 61000, loss: 0.022656
 >> iter 62000, loss: 0.022049
 >> iter 63000, loss: 0.025408
 >> iter 64000, loss: 0.037159
 >> iter 65000, loss: 0.032728
 >> iter 66000, loss: 0.025145
 >> iter 67000, loss: 0.026496
 >> iter 68000, loss: 0.028730
 >> iter 69000, loss: 0.023670
 >> iter 70000, loss: 0.021097
   Number of active neurons: 2
 >> iter 71000, loss: 0.022772
 >> iter 72000, loss: 0.032281
 >> iter 73000, loss: 0.081442
 >> iter 74000, loss: 0.054231
 >> iter 75000, loss: 0.033046
 >> iter 76000, loss: 0.026813
 >> iter 77000, loss: 0.022146
 >> iter 78000, loss: 0.020667
 >> iter 79000, loss: 0.021452
 >> iter 80000, loss: 0.023883
   Number of active neurons: 2
 >> iter 81000, loss: 0.022069
 >> iter 82000, loss: 0.022442
 >> iter 83000, loss: 0.021538
 >> iter 84000, loss: 0.023132
 >> iter 85000, loss: 0.022144
 >> iter 86000, loss: 0.031158
 >> iter 87000, loss: 0.029827
 >> iter 88000, loss: 0.022699
 >> iter 89000, loss: 0.024358
 >> iter 90000, loss: 0.023897
   Number of active neurons: 1
 >> iter 91000, loss: 0.024048
 >> iter 92000, loss: 0.025304
 >> iter 93000, loss: 0.021696
 >> iter 94000, loss: 0.025361
 >> iter 95000, loss: 0.022124
 >> iter 96000, loss: 0.019582
 >> iter 97000, loss: 0.019436
 >> iter 98000, loss: 0.020941
 >> iter 99000, loss: 0.022954
 >> iter 100000, loss: 0.023681
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.984831
 >> iter 2000, loss: 4.113036
 >> iter 3000, loss: 1.540443
 >> iter 4000, loss: 0.587925
 >> iter 5000, loss: 0.239863
 >> iter 6000, loss: 0.106555
 >> iter 7000, loss: 0.059883
 >> iter 8000, loss: 0.039244
 >> iter 9000, loss: 0.033774
 >> iter 10000, loss: 0.029996
   Number of active neurons: 3
 >> iter 11000, loss: 0.029790
 >> iter 12000, loss: 0.025847
 >> iter 13000, loss: 0.028480
 >> iter 14000, loss: 0.026547
 >> iter 15000, loss: 0.026081
 >> iter 16000, loss: 0.024335
 >> iter 17000, loss: 0.026436
 >> iter 18000, loss: 0.023754
 >> iter 19000, loss: 0.022045
 >> iter 20000, loss: 0.024452
   Number of active neurons: 3
 >> iter 21000, loss: 0.033813
 >> iter 22000, loss: 0.037478
 >> iter 23000, loss: 0.029924
 >> iter 24000, loss: 0.034953
 >> iter 25000, loss: 0.029202
 >> iter 26000, loss: 0.026562
 >> iter 27000, loss: 0.024430
 >> iter 28000, loss: 0.027232
 >> iter 29000, loss: 0.026113
 >> iter 30000, loss: 0.024196
   Number of active neurons: 3
 >> iter 31000, loss: 0.035689
 >> iter 32000, loss: 0.028085
 >> iter 33000, loss: 0.034459
 >> iter 34000, loss: 0.026803
 >> iter 35000, loss: 0.025211
 >> iter 36000, loss: 0.024108
 >> iter 37000, loss: 0.023349
 >> iter 38000, loss: 0.024201
 >> iter 39000, loss: 0.027487
 >> iter 40000, loss: 0.023014
   Number of active neurons: 2
 >> iter 41000, loss: 0.022764
 >> iter 42000, loss: 0.022126
 >> iter 43000, loss: 0.021583
 >> iter 44000, loss: 0.022565
 >> iter 45000, loss: 0.024056
 >> iter 46000, loss: 0.024952
 >> iter 47000, loss: 0.022500
 >> iter 48000, loss: 0.037375
 >> iter 49000, loss: 0.027717
 >> iter 50000, loss: 0.024273
   Number of active neurons: 2
 >> iter 51000, loss: 0.022041
 >> iter 52000, loss: 0.022091
 >> iter 53000, loss: 0.020910
 >> iter 54000, loss: 0.019623
 >> iter 55000, loss: 0.043001
 >> iter 56000, loss: 0.030771
 >> iter 57000, loss: 0.025906
 >> iter 58000, loss: 0.023299
 >> iter 59000, loss: 0.023985
 >> iter 60000, loss: 0.023493
   Number of active neurons: 2
 >> iter 61000, loss: 0.026425
 >> iter 62000, loss: 0.024293
 >> iter 63000, loss: 0.023465
 >> iter 64000, loss: 0.021127
 >> iter 65000, loss: 0.027963
 >> iter 66000, loss: 0.027279
 >> iter 67000, loss: 0.031976
 >> iter 68000, loss: 0.028330
 >> iter 69000, loss: 0.022975
 >> iter 70000, loss: 0.029611
   Number of active neurons: 2
 >> iter 71000, loss: 0.028747
 >> iter 72000, loss: 0.025056
 >> iter 73000, loss: 0.022821
 >> iter 74000, loss: 0.045061
 >> iter 75000, loss: 0.035771
 >> iter 76000, loss: 0.025478
 >> iter 77000, loss: 0.023582
 >> iter 78000, loss: 0.023541
 >> iter 79000, loss: 0.022243
 >> iter 80000, loss: 0.025854
   Number of active neurons: 2
 >> iter 81000, loss: 0.022720
 >> iter 82000, loss: 0.022108
 >> iter 83000, loss: 0.032617
 >> iter 84000, loss: 0.025994
 >> iter 85000, loss: 0.022830
 >> iter 86000, loss: 0.024006
 >> iter 87000, loss: 0.027973
 >> iter 88000, loss: 0.022494
 >> iter 89000, loss: 0.023283
 >> iter 90000, loss: 0.027135
   Number of active neurons: 2
 >> iter 91000, loss: 0.042816
 >> iter 92000, loss: 0.031029
 >> iter 93000, loss: 0.024429
 >> iter 94000, loss: 0.044424
 >> iter 95000, loss: 0.033122
 >> iter 96000, loss: 0.024323
 >> iter 97000, loss: 0.021137
 >> iter 98000, loss: 0.029091
 >> iter 99000, loss: 0.025158
 >> iter 100000, loss: 0.026761
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.947827
 >> iter 2000, loss: 4.083949
 >> iter 3000, loss: 1.541406
 >> iter 4000, loss: 0.589577
 >> iter 5000, loss: 0.242512
 >> iter 6000, loss: 0.108150
 >> iter 7000, loss: 0.061271
 >> iter 8000, loss: 0.039863
 >> iter 9000, loss: 0.030541
 >> iter 10000, loss: 0.026896
   Number of active neurons: 4
 >> iter 11000, loss: 0.041044
 >> iter 12000, loss: 0.030706
 >> iter 13000, loss: 0.029884
 >> iter 14000, loss: 0.026465
 >> iter 15000, loss: 0.025120
 >> iter 16000, loss: 0.027647
 >> iter 17000, loss: 0.026241
 >> iter 18000, loss: 0.024958
 >> iter 19000, loss: 0.030959
 >> iter 20000, loss: 0.032790
   Number of active neurons: 2
 >> iter 21000, loss: 0.025885
 >> iter 22000, loss: 0.028439
 >> iter 23000, loss: 0.027606
 >> iter 24000, loss: 0.031545
 >> iter 25000, loss: 0.025325
 >> iter 26000, loss: 0.023455
 >> iter 27000, loss: 0.022648
 >> iter 28000, loss: 0.022036
 >> iter 29000, loss: 0.021617
 >> iter 30000, loss: 0.030884
   Number of active neurons: 2
 >> iter 31000, loss: 0.025250
 >> iter 32000, loss: 0.023391
 >> iter 33000, loss: 0.022131
 >> iter 34000, loss: 0.041746
 >> iter 35000, loss: 0.028729
 >> iter 36000, loss: 0.037869
 >> iter 37000, loss: 0.029305
 >> iter 38000, loss: 0.024075
 >> iter 39000, loss: 0.036957
 >> iter 40000, loss: 0.029132
   Number of active neurons: 2
 >> iter 41000, loss: 0.027679
 >> iter 42000, loss: 0.036045
 >> iter 43000, loss: 0.026213
 >> iter 44000, loss: 0.025169
 >> iter 45000, loss: 0.022022
 >> iter 46000, loss: 0.026238
 >> iter 47000, loss: 0.022905
 >> iter 48000, loss: 0.037391
 >> iter 49000, loss: 0.026853
 >> iter 50000, loss: 0.024966
   Number of active neurons: 2
 >> iter 51000, loss: 0.023486
 >> iter 52000, loss: 0.023153
 >> iter 53000, loss: 0.023839
 >> iter 54000, loss: 0.020978
 >> iter 55000, loss: 0.033258
 >> iter 56000, loss: 0.030245
 >> iter 57000, loss: 0.025000
 >> iter 58000, loss: 0.036424
 >> iter 59000, loss: 0.025316
 >> iter 60000, loss: 0.021789
   Number of active neurons: 2
 >> iter 61000, loss: 0.023671
 >> iter 62000, loss: 0.022538
 >> iter 63000, loss: 0.021212
 >> iter 64000, loss: 0.033878
 >> iter 65000, loss: 0.027568
 >> iter 66000, loss: 0.027439
 >> iter 67000, loss: 0.023351
 >> iter 68000, loss: 0.042986
 >> iter 69000, loss: 0.028303
 >> iter 70000, loss: 0.027275
   Number of active neurons: 1
 >> iter 71000, loss: 0.021495
 >> iter 72000, loss: 0.018653
 >> iter 73000, loss: 0.028787
 >> iter 74000, loss: 0.022868
 >> iter 75000, loss: 0.020033
 >> iter 76000, loss: 0.020487
 >> iter 77000, loss: 0.017195
 >> iter 78000, loss: 0.017164
 >> iter 79000, loss: 0.019859
 >> iter 80000, loss: 0.031570
   Number of active neurons: 1
 >> iter 81000, loss: 0.027315
 >> iter 82000, loss: 0.022818
 >> iter 83000, loss: 0.017844
 >> iter 84000, loss: 0.017656
 >> iter 85000, loss: 0.020779
 >> iter 86000, loss: 0.028297
 >> iter 87000, loss: 0.024801
 >> iter 88000, loss: 0.029320
 >> iter 89000, loss: 0.021265
 >> iter 90000, loss: 0.017740
   Number of active neurons: 1
 >> iter 91000, loss: 0.017501
 >> iter 92000, loss: 0.017044
 >> iter 93000, loss: 0.017630
 >> iter 94000, loss: 0.020898
 >> iter 95000, loss: 0.020991
 >> iter 96000, loss: 0.025760
 >> iter 97000, loss: 0.024444
 >> iter 98000, loss: 0.021511
 >> iter 99000, loss: 0.018917
 >> iter 100000, loss: 0.019516
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.975115
 >> iter 2000, loss: 4.079170
 >> iter 3000, loss: 1.527993
 >> iter 4000, loss: 0.588427
 >> iter 5000, loss: 0.240104
 >> iter 6000, loss: 0.106470
 >> iter 7000, loss: 0.060691
 >> iter 8000, loss: 0.037799
 >> iter 9000, loss: 0.031730
 >> iter 10000, loss: 0.027624
   Number of active neurons: 3
 >> iter 11000, loss: 0.025611
 >> iter 12000, loss: 0.025135
 >> iter 13000, loss: 0.024414
 >> iter 14000, loss: 0.025111
 >> iter 15000, loss: 0.024488
 >> iter 16000, loss: 0.037810
 >> iter 17000, loss: 0.028330
 >> iter 18000, loss: 0.036494
 >> iter 19000, loss: 0.031352
 >> iter 20000, loss: 0.030575
   Number of active neurons: 3
 >> iter 21000, loss: 0.027937
 >> iter 22000, loss: 0.024336
 >> iter 23000, loss: 0.024393
 >> iter 24000, loss: 0.023613
 >> iter 25000, loss: 0.027629
 >> iter 26000, loss: 0.034803
 >> iter 27000, loss: 0.027163
 >> iter 28000, loss: 0.038462
 >> iter 29000, loss: 0.028631
 >> iter 30000, loss: 0.030610
   Number of active neurons: 3
 >> iter 31000, loss: 0.028878
 >> iter 32000, loss: 0.025534
 >> iter 33000, loss: 0.024712
 >> iter 34000, loss: 0.030864
 >> iter 35000, loss: 0.029022
 >> iter 36000, loss: 0.028341
 >> iter 37000, loss: 0.029333
 >> iter 38000, loss: 0.028777
 >> iter 39000, loss: 0.029093
 >> iter 40000, loss: 0.024620
   Number of active neurons: 2
 >> iter 41000, loss: 0.025388
 >> iter 42000, loss: 0.027335
 >> iter 43000, loss: 0.046540
 >> iter 44000, loss: 0.040085
 >> iter 45000, loss: 0.027618
 >> iter 46000, loss: 0.027967
 >> iter 47000, loss: 0.042965
 >> iter 48000, loss: 0.028099
 >> iter 49000, loss: 0.042219
 >> iter 50000, loss: 0.029026
   Number of active neurons: 2
 >> iter 51000, loss: 0.025178
 >> iter 52000, loss: 0.027293
 >> iter 53000, loss: 0.039313
 >> iter 54000, loss: 0.027408
 >> iter 55000, loss: 0.022743
 >> iter 56000, loss: 0.024340
 >> iter 57000, loss: 0.021716
 >> iter 58000, loss: 0.018246
 >> iter 59000, loss: 0.019481
 >> iter 60000, loss: 0.018040
   Number of active neurons: 1
 >> iter 61000, loss: 0.019577
 >> iter 62000, loss: 0.025742
 >> iter 63000, loss: 0.026028
 >> iter 64000, loss: 0.019142
 >> iter 65000, loss: 0.018145
 >> iter 66000, loss: 0.016847
 >> iter 67000, loss: 0.018085
 >> iter 68000, loss: 0.023561
 >> iter 69000, loss: 0.028839
 >> iter 70000, loss: 0.036858
   Number of active neurons: 1
 >> iter 71000, loss: 0.024070
 >> iter 72000, loss: 0.026946
 >> iter 73000, loss: 0.020720
 >> iter 74000, loss: 0.017105
 >> iter 75000, loss: 0.018623
 >> iter 76000, loss: 0.019850
 >> iter 77000, loss: 0.023103
 >> iter 78000, loss: 0.035557
 >> iter 79000, loss: 0.051113
 >> iter 80000, loss: 0.032387
   Number of active neurons: 1
 >> iter 81000, loss: 0.024015
 >> iter 82000, loss: 0.026184
 >> iter 83000, loss: 0.027013
 >> iter 84000, loss: 0.021797
 >> iter 85000, loss: 0.018416
 >> iter 86000, loss: 0.027266
 >> iter 87000, loss: 0.020235
 >> iter 88000, loss: 0.023437
 >> iter 89000, loss: 0.019404
 >> iter 90000, loss: 0.025244
   Number of active neurons: 1
 >> iter 91000, loss: 0.046132
 >> iter 92000, loss: 0.036601
 >> iter 93000, loss: 0.027385
 >> iter 94000, loss: 0.021147
 >> iter 95000, loss: 0.021246
 >> iter 96000, loss: 0.017516
 >> iter 97000, loss: 0.031807
 >> iter 98000, loss: 0.022127
 >> iter 99000, loss: 0.019788
 >> iter 100000, loss: 0.021444
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.985889
 >> iter 2000, loss: 4.081742
 >> iter 3000, loss: 1.530162
 >> iter 4000, loss: 0.585746
 >> iter 5000, loss: 0.232834
 >> iter 6000, loss: 0.126184
 >> iter 7000, loss: 0.064724
 >> iter 8000, loss: 0.039895
 >> iter 9000, loss: 0.031901
 >> iter 10000, loss: 0.033233
   Number of active neurons: 4
 >> iter 11000, loss: 0.029179
 >> iter 12000, loss: 0.026337
 >> iter 13000, loss: 0.028495
 >> iter 14000, loss: 0.025378
 >> iter 15000, loss: 0.026273
 >> iter 16000, loss: 0.026933
 >> iter 17000, loss: 0.027567
 >> iter 18000, loss: 0.025019
 >> iter 19000, loss: 0.025920
 >> iter 20000, loss: 0.032000
   Number of active neurons: 3
 >> iter 21000, loss: 0.041867
 >> iter 22000, loss: 0.029179
 >> iter 23000, loss: 0.024606
 >> iter 24000, loss: 0.023923
 >> iter 25000, loss: 0.022761
 >> iter 26000, loss: 0.023426
 >> iter 27000, loss: 0.026818
 >> iter 28000, loss: 0.023729
 >> iter 29000, loss: 0.022854
 >> iter 30000, loss: 0.021820
   Number of active neurons: 2
 >> iter 31000, loss: 0.021897
 >> iter 32000, loss: 0.030545
 >> iter 33000, loss: 0.023265
 >> iter 34000, loss: 0.023473
 >> iter 35000, loss: 0.024371
 >> iter 36000, loss: 0.020588
 >> iter 37000, loss: 0.019749
 >> iter 38000, loss: 0.021799
 >> iter 39000, loss: 0.023125
 >> iter 40000, loss: 0.020832
   Number of active neurons: 2
 >> iter 41000, loss: 0.022047
 >> iter 42000, loss: 0.022634
 >> iter 43000, loss: 0.022604
 >> iter 44000, loss: 0.038473
 >> iter 45000, loss: 0.035068
 >> iter 46000, loss: 0.025061
 >> iter 47000, loss: 0.023231
 >> iter 48000, loss: 0.021680
 >> iter 49000, loss: 0.020467
 >> iter 50000, loss: 0.020995
   Number of active neurons: 2
 >> iter 51000, loss: 0.026656
 >> iter 52000, loss: 0.028306
 >> iter 53000, loss: 0.025258
 >> iter 54000, loss: 0.022093
 >> iter 55000, loss: 0.021157
 >> iter 56000, loss: 0.031699
 >> iter 57000, loss: 0.024800
 >> iter 58000, loss: 0.030121
 >> iter 59000, loss: 0.023417
 >> iter 60000, loss: 0.022821
   Number of active neurons: 2
 >> iter 61000, loss: 0.029165
 >> iter 62000, loss: 0.029316
 >> iter 63000, loss: 0.023936
 >> iter 64000, loss: 0.023888
 >> iter 65000, loss: 0.025267
 >> iter 66000, loss: 0.022789
 >> iter 67000, loss: 0.020156
 >> iter 68000, loss: 0.039254
 >> iter 69000, loss: 0.026556
 >> iter 70000, loss: 0.025505
   Number of active neurons: 2
 >> iter 71000, loss: 0.023722
 >> iter 72000, loss: 0.030923
 >> iter 73000, loss: 0.025110
 >> iter 74000, loss: 0.028081
 >> iter 75000, loss: 0.024747
 >> iter 76000, loss: 0.028295
 >> iter 77000, loss: 0.024520
 >> iter 78000, loss: 0.023482
 >> iter 79000, loss: 0.038886
 >> iter 80000, loss: 0.028326
   Number of active neurons: 2
 >> iter 81000, loss: 0.022513
 >> iter 82000, loss: 0.023702
 >> iter 83000, loss: 0.028178
 >> iter 84000, loss: 0.024576
 >> iter 85000, loss: 0.030502
 >> iter 86000, loss: 0.026074
 >> iter 87000, loss: 0.021984
 >> iter 88000, loss: 0.019910
 >> iter 89000, loss: 0.025855
 >> iter 90000, loss: 0.023904
   Number of active neurons: 2
 >> iter 91000, loss: 0.022484
 >> iter 92000, loss: 0.023896
 >> iter 93000, loss: 0.023044
 >> iter 94000, loss: 0.020868
 >> iter 95000, loss: 0.023875
 >> iter 96000, loss: 0.028884
 >> iter 97000, loss: 0.024797
 >> iter 98000, loss: 0.020793
 >> iter 99000, loss: 0.024800
 >> iter 100000, loss: 0.022558
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.987721
 >> iter 2000, loss: 4.086374
 >> iter 3000, loss: 1.531644
 >> iter 4000, loss: 0.587017
 >> iter 5000, loss: 0.246240
 >> iter 6000, loss: 0.107723
 >> iter 7000, loss: 0.058681
 >> iter 8000, loss: 0.047801
 >> iter 9000, loss: 0.033913
 >> iter 10000, loss: 0.031123
   Number of active neurons: 5
 >> iter 11000, loss: 0.035974
 >> iter 12000, loss: 0.051578
 >> iter 13000, loss: 0.036178
 >> iter 14000, loss: 0.032528
 >> iter 15000, loss: 0.029599
 >> iter 16000, loss: 0.026838
 >> iter 17000, loss: 0.029955
 >> iter 18000, loss: 0.026054
 >> iter 19000, loss: 0.028720
 >> iter 20000, loss: 0.030798
   Number of active neurons: 3
 >> iter 21000, loss: 0.026888
 >> iter 22000, loss: 0.033397
 >> iter 23000, loss: 0.026755
 >> iter 24000, loss: 0.041042
 >> iter 25000, loss: 0.033893
 >> iter 26000, loss: 0.028832
 >> iter 27000, loss: 0.027073
 >> iter 28000, loss: 0.026071
 >> iter 29000, loss: 0.025359
 >> iter 30000, loss: 0.029113
   Number of active neurons: 3
 >> iter 31000, loss: 0.024882
 >> iter 32000, loss: 0.022570
 >> iter 33000, loss: 0.022285
 >> iter 34000, loss: 0.031864
 >> iter 35000, loss: 0.028168
 >> iter 36000, loss: 0.026864
 >> iter 37000, loss: 0.029247
 >> iter 38000, loss: 0.027027
 >> iter 39000, loss: 0.023329
 >> iter 40000, loss: 0.026469
   Number of active neurons: 3
 >> iter 41000, loss: 0.024108
 >> iter 42000, loss: 0.035250
 >> iter 43000, loss: 0.048214
 >> iter 44000, loss: 0.037870
 >> iter 45000, loss: 0.029074
 >> iter 46000, loss: 0.031665
 >> iter 47000, loss: 0.029689
 >> iter 48000, loss: 0.025025
 >> iter 49000, loss: 0.028030
 >> iter 50000, loss: 0.031197
   Number of active neurons: 3
 >> iter 51000, loss: 0.028686
 >> iter 52000, loss: 0.043284
 >> iter 53000, loss: 0.034093
 >> iter 54000, loss: 0.027509
 >> iter 55000, loss: 0.025104
 >> iter 56000, loss: 0.076449
 >> iter 57000, loss: 0.054613
 >> iter 58000, loss: 0.040122
 >> iter 59000, loss: 0.040332
 >> iter 60000, loss: 0.033058
   Number of active neurons: 3
 >> iter 61000, loss: 0.061144
 >> iter 62000, loss: 0.043200
 >> iter 63000, loss: 0.030514
 >> iter 64000, loss: 0.025658
 >> iter 65000, loss: 0.029271
 >> iter 66000, loss: 0.023851
 >> iter 67000, loss: 0.023581
 >> iter 68000, loss: 0.020074
 >> iter 69000, loss: 0.021916
 >> iter 70000, loss: 0.021196
   Number of active neurons: 2
 >> iter 71000, loss: 0.020177
 >> iter 72000, loss: 0.021293
 >> iter 73000, loss: 0.023157
 >> iter 74000, loss: 0.036499
 >> iter 75000, loss: 0.031224
 >> iter 76000, loss: 0.039699
 >> iter 77000, loss: 0.043077
 >> iter 78000, loss: 0.032920
 >> iter 79000, loss: 0.042039
 >> iter 80000, loss: 0.030608
   Number of active neurons: 1
 >> iter 81000, loss: 0.022062
 >> iter 82000, loss: 0.036054
 >> iter 83000, loss: 0.025613
 >> iter 84000, loss: 0.020631
 >> iter 85000, loss: 0.018445
 >> iter 86000, loss: 0.019685
 >> iter 87000, loss: 0.018822
 >> iter 88000, loss: 0.020478
 >> iter 89000, loss: 0.020109
 >> iter 90000, loss: 0.045639
   Number of active neurons: 1
 >> iter 91000, loss: 0.028608
 >> iter 92000, loss: 0.022138
 >> iter 93000, loss: 0.019485
 >> iter 94000, loss: 0.022491
 >> iter 95000, loss: 0.019621
 >> iter 96000, loss: 0.018801
 >> iter 97000, loss: 0.034146
 >> iter 98000, loss: 0.022244
 >> iter 99000, loss: 0.019992
 >> iter 100000, loss: 0.018534
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.944690
 >> iter 2000, loss: 4.063858
 >> iter 3000, loss: 1.518867
 >> iter 4000, loss: 0.578117
 >> iter 5000, loss: 0.228366
 >> iter 6000, loss: 0.101785
 >> iter 7000, loss: 0.054525
 >> iter 8000, loss: 0.038636
 >> iter 9000, loss: 0.032606
 >> iter 10000, loss: 0.028526
   Number of active neurons: 3
 >> iter 11000, loss: 0.028330
 >> iter 12000, loss: 0.029316
 >> iter 13000, loss: 0.030974
 >> iter 14000, loss: 0.037858
 >> iter 15000, loss: 0.029024
 >> iter 16000, loss: 0.030451
 >> iter 17000, loss: 0.025848
 >> iter 18000, loss: 0.025223
 >> iter 19000, loss: 0.026528
 >> iter 20000, loss: 0.023339
   Number of active neurons: 2
 >> iter 21000, loss: 0.033335
 >> iter 22000, loss: 0.027822
 >> iter 23000, loss: 0.031678
 >> iter 24000, loss: 0.025914
 >> iter 25000, loss: 0.041064
 >> iter 26000, loss: 0.029230
 >> iter 27000, loss: 0.025567
 >> iter 28000, loss: 0.032899
 >> iter 29000, loss: 0.026259
 >> iter 30000, loss: 0.025929
   Number of active neurons: 2
 >> iter 31000, loss: 0.029417
 >> iter 32000, loss: 0.024347
 >> iter 33000, loss: 0.021399
 >> iter 34000, loss: 0.026153
 >> iter 35000, loss: 0.028855
 >> iter 36000, loss: 0.070547
 >> iter 37000, loss: 0.040762
 >> iter 38000, loss: 0.040259
 >> iter 39000, loss: 0.028675
 >> iter 40000, loss: 0.031484
   Number of active neurons: 2
 >> iter 41000, loss: 0.025808
 >> iter 42000, loss: 0.026714
 >> iter 43000, loss: 0.025528
 >> iter 44000, loss: 0.026584
 >> iter 45000, loss: 0.026788
 >> iter 46000, loss: 0.025731
 >> iter 47000, loss: 0.022136
 >> iter 48000, loss: 0.029032
 >> iter 49000, loss: 0.028083
 >> iter 50000, loss: 0.044690
   Number of active neurons: 2
 >> iter 51000, loss: 0.032342
 >> iter 52000, loss: 0.025202
 >> iter 53000, loss: 0.024610
 >> iter 54000, loss: 0.025459
 >> iter 55000, loss: 0.026921
 >> iter 56000, loss: 0.035321
 >> iter 57000, loss: 0.028089
 >> iter 58000, loss: 0.025352
 >> iter 59000, loss: 0.023130
 >> iter 60000, loss: 0.035120
   Number of active neurons: 1
 >> iter 61000, loss: 0.024258
 >> iter 62000, loss: 0.021511
 >> iter 63000, loss: 0.019120
 >> iter 64000, loss: 0.022218
 >> iter 65000, loss: 0.019916
 >> iter 66000, loss: 0.022794
 >> iter 67000, loss: 0.020658
 >> iter 68000, loss: 0.017578
 >> iter 69000, loss: 0.016452
 >> iter 70000, loss: 0.016792
   Number of active neurons: 1
 >> iter 71000, loss: 0.017858
 >> iter 72000, loss: 0.019568
 >> iter 73000, loss: 0.021620
 >> iter 74000, loss: 0.021013
 >> iter 75000, loss: 0.039910
 >> iter 76000, loss: 0.025003
 >> iter 77000, loss: 0.024645
 >> iter 78000, loss: 0.026432
 >> iter 79000, loss: 0.021312
 >> iter 80000, loss: 0.022997
   Number of active neurons: 1
 >> iter 81000, loss: 0.019689
 >> iter 82000, loss: 0.026719
 >> iter 83000, loss: 0.019215
 >> iter 84000, loss: 0.017689
 >> iter 85000, loss: 0.017282
 >> iter 86000, loss: 0.022704
 >> iter 87000, loss: 0.026794
 >> iter 88000, loss: 0.021532
 >> iter 89000, loss: 0.018847
 >> iter 90000, loss: 0.026256
   Number of active neurons: 1
 >> iter 91000, loss: 0.021849
 >> iter 92000, loss: 0.021072
 >> iter 93000, loss: 0.023179
 >> iter 94000, loss: 0.024325
 >> iter 95000, loss: 0.019746
 >> iter 96000, loss: 0.033605
 >> iter 97000, loss: 0.024088
 >> iter 98000, loss: 0.018596
 >> iter 99000, loss: 0.024062
 >> iter 100000, loss: 0.030496
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.010137
 >> iter 2000, loss: 4.093090
 >> iter 3000, loss: 1.533164
 >> iter 4000, loss: 0.595120
 >> iter 5000, loss: 0.249204
 >> iter 6000, loss: 0.109046
 >> iter 7000, loss: 0.064209
 >> iter 8000, loss: 0.042389
 >> iter 9000, loss: 0.032679
 >> iter 10000, loss: 0.029957
   Number of active neurons: 4
 >> iter 11000, loss: 0.027246
 >> iter 12000, loss: 0.028738
 >> iter 13000, loss: 0.026756
 >> iter 14000, loss: 0.024933
 >> iter 15000, loss: 0.027230
 >> iter 16000, loss: 0.026905
 >> iter 17000, loss: 0.024617
 >> iter 18000, loss: 0.024957
 >> iter 19000, loss: 0.025639
 >> iter 20000, loss: 0.025459
   Number of active neurons: 3
 >> iter 21000, loss: 0.028541
 >> iter 22000, loss: 0.034362
 >> iter 23000, loss: 0.031175
 >> iter 24000, loss: 0.025070
 >> iter 25000, loss: 0.024766
 >> iter 26000, loss: 0.022387
 >> iter 27000, loss: 0.028265
 >> iter 28000, loss: 0.024736
 >> iter 29000, loss: 0.024509
 >> iter 30000, loss: 0.023533
   Number of active neurons: 2
 >> iter 31000, loss: 0.021935
 >> iter 32000, loss: 0.047791
 >> iter 33000, loss: 0.038541
 >> iter 34000, loss: 0.028030
 >> iter 35000, loss: 0.026141
 >> iter 36000, loss: 0.025792
 >> iter 37000, loss: 0.021994
 >> iter 38000, loss: 0.020726
 >> iter 39000, loss: 0.019875
 >> iter 40000, loss: 0.019910
   Number of active neurons: 2
 >> iter 41000, loss: 0.030886
 >> iter 42000, loss: 0.026015
 >> iter 43000, loss: 0.035024
 >> iter 44000, loss: 0.026379
 >> iter 45000, loss: 0.023369
 >> iter 46000, loss: 0.023158
 >> iter 47000, loss: 0.020994
 >> iter 48000, loss: 0.021869
 >> iter 49000, loss: 0.028458
 >> iter 50000, loss: 0.029770
   Number of active neurons: 2
 >> iter 51000, loss: 0.024153
 >> iter 52000, loss: 0.032761
 >> iter 53000, loss: 0.024802
 >> iter 54000, loss: 0.024059
 >> iter 55000, loss: 0.031030
 >> iter 56000, loss: 0.027807
 >> iter 57000, loss: 0.036485
 >> iter 58000, loss: 0.028926
 >> iter 59000, loss: 0.025111
 >> iter 60000, loss: 0.023024
   Number of active neurons: 2
 >> iter 61000, loss: 0.024045
 >> iter 62000, loss: 0.020356
 >> iter 63000, loss: 0.019819
 >> iter 64000, loss: 0.019324
 >> iter 65000, loss: 0.019548
 >> iter 66000, loss: 0.019376
 >> iter 67000, loss: 0.023135
 >> iter 68000, loss: 0.019095
 >> iter 69000, loss: 0.024141
 >> iter 70000, loss: 0.024090
   Number of active neurons: 1
 >> iter 71000, loss: 0.022123
 >> iter 72000, loss: 0.019831
 >> iter 73000, loss: 0.025562
 >> iter 74000, loss: 0.020959
 >> iter 75000, loss: 0.020240
 >> iter 76000, loss: 0.023975
 >> iter 77000, loss: 0.020084
 >> iter 78000, loss: 0.018325
 >> iter 79000, loss: 0.018373
 >> iter 80000, loss: 0.016349
   Number of active neurons: 1
 >> iter 81000, loss: 0.020345
 >> iter 82000, loss: 0.035345
 >> iter 83000, loss: 0.026089
 >> iter 84000, loss: 0.020867
 >> iter 85000, loss: 0.017843
 >> iter 86000, loss: 0.022038
 >> iter 87000, loss: 0.022509
 >> iter 88000, loss: 0.019689
 >> iter 89000, loss: 0.017016
 >> iter 90000, loss: 0.029079
   Number of active neurons: 1
 >> iter 91000, loss: 0.033567
 >> iter 92000, loss: 0.034372
 >> iter 93000, loss: 0.027788
 >> iter 94000, loss: 0.019169
 >> iter 95000, loss: 0.026566
 >> iter 96000, loss: 0.020576
 >> iter 97000, loss: 0.020180
 >> iter 98000, loss: 0.019697
 >> iter 99000, loss: 0.017551
 >> iter 100000, loss: 0.017748
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.944628
 >> iter 2000, loss: 4.060294
 >> iter 3000, loss: 1.561998
 >> iter 4000, loss: 0.599016
 >> iter 5000, loss: 0.240681
 >> iter 6000, loss: 0.110606
 >> iter 7000, loss: 0.062497
 >> iter 8000, loss: 0.043160
 >> iter 9000, loss: 0.035773
 >> iter 10000, loss: 0.030749
   Number of active neurons: 4
 >> iter 11000, loss: 0.035587
 >> iter 12000, loss: 0.030685
 >> iter 13000, loss: 0.034356
 >> iter 14000, loss: 0.029724
 >> iter 15000, loss: 0.026418
 >> iter 16000, loss: 0.029862
 >> iter 17000, loss: 0.027876
 >> iter 18000, loss: 0.036580
 >> iter 19000, loss: 0.043696
 >> iter 20000, loss: 0.071144
   Number of active neurons: 4
 >> iter 21000, loss: 0.043572
 >> iter 22000, loss: 0.037660
 >> iter 23000, loss: 0.030137
 >> iter 24000, loss: 0.029803
 >> iter 25000, loss: 0.028089
 >> iter 26000, loss: 0.030411
 >> iter 27000, loss: 0.032976
 >> iter 28000, loss: 0.026113
 >> iter 29000, loss: 0.025204
 >> iter 30000, loss: 0.022999
   Number of active neurons: 1
 >> iter 31000, loss: 0.025384
 >> iter 32000, loss: 0.025365
 >> iter 33000, loss: 0.026533
 >> iter 34000, loss: 0.022003
 >> iter 35000, loss: 0.050930
 >> iter 36000, loss: 0.031389
 >> iter 37000, loss: 0.023563
 >> iter 38000, loss: 0.037423
 >> iter 39000, loss: 0.024971
 >> iter 40000, loss: 0.023598
   Number of active neurons: 1
 >> iter 41000, loss: 0.025277
 >> iter 42000, loss: 0.023592
 >> iter 43000, loss: 0.022481
 >> iter 44000, loss: 0.018006
 >> iter 45000, loss: 0.017613
 >> iter 46000, loss: 0.020846
 >> iter 47000, loss: 0.023980
 >> iter 48000, loss: 0.020552
 >> iter 49000, loss: 0.020708
 >> iter 50000, loss: 0.017742
   Number of active neurons: 1
 >> iter 51000, loss: 0.019700
 >> iter 52000, loss: 0.018177
 >> iter 53000, loss: 0.022362
 >> iter 54000, loss: 0.027239
 >> iter 55000, loss: 0.021248
 >> iter 56000, loss: 0.020914
 >> iter 57000, loss: 0.026180
 >> iter 58000, loss: 0.022471
 >> iter 59000, loss: 0.018448
 >> iter 60000, loss: 0.026764
   Number of active neurons: 1
 >> iter 61000, loss: 0.032587
 >> iter 62000, loss: 0.060151
 >> iter 63000, loss: 0.033060
 >> iter 64000, loss: 0.023045
 >> iter 65000, loss: 0.018756
 >> iter 66000, loss: 0.018590
 >> iter 67000, loss: 0.020744
 >> iter 68000, loss: 0.017373
 >> iter 69000, loss: 0.019009
 >> iter 70000, loss: 0.022899
   Number of active neurons: 1
 >> iter 71000, loss: 0.019145
 >> iter 72000, loss: 0.018316
 >> iter 73000, loss: 0.019408
 >> iter 74000, loss: 0.017133
 >> iter 75000, loss: 0.015862
 >> iter 76000, loss: 0.017643
 >> iter 77000, loss: 0.020031
 >> iter 78000, loss: 0.020245
 >> iter 79000, loss: 0.024751
 >> iter 80000, loss: 0.024543
   Number of active neurons: 1
 >> iter 81000, loss: 0.019545
 >> iter 82000, loss: 0.019694
 >> iter 83000, loss: 0.030311
 >> iter 84000, loss: 0.033253
 >> iter 85000, loss: 0.021570
 >> iter 86000, loss: 0.017886
 >> iter 87000, loss: 0.019817
 >> iter 88000, loss: 0.020648
 >> iter 89000, loss: 0.028374
 >> iter 90000, loss: 0.023294
   Number of active neurons: 1
 >> iter 91000, loss: 0.019188
 >> iter 92000, loss: 0.022759
 >> iter 93000, loss: 0.017403
 >> iter 94000, loss: 0.028809
 >> iter 95000, loss: 0.025253
 >> iter 96000, loss: 0.024537
 >> iter 97000, loss: 0.025582
 >> iter 98000, loss: 0.024791
 >> iter 99000, loss: 0.021270
 >> iter 100000, loss: 0.020629
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.924388
 >> iter 2000, loss: 4.054701
 >> iter 3000, loss: 1.519522
 >> iter 4000, loss: 0.578851
 >> iter 5000, loss: 0.229511
 >> iter 6000, loss: 0.103373
 >> iter 7000, loss: 0.054321
 >> iter 8000, loss: 0.055852
 >> iter 9000, loss: 0.038014
 >> iter 10000, loss: 0.031159
   Number of active neurons: 4
 >> iter 11000, loss: 0.026825
 >> iter 12000, loss: 0.025705
 >> iter 13000, loss: 0.029197
 >> iter 14000, loss: 0.034460
 >> iter 15000, loss: 0.029209
 >> iter 16000, loss: 0.031537
 >> iter 17000, loss: 0.036233
 >> iter 18000, loss: 0.027022
 >> iter 19000, loss: 0.022771
 >> iter 20000, loss: 0.023806
   Number of active neurons: 3
 >> iter 21000, loss: 0.025172
 >> iter 22000, loss: 0.026330
 >> iter 23000, loss: 0.026097
 >> iter 24000, loss: 0.024864
 >> iter 25000, loss: 0.022572
 >> iter 26000, loss: 0.025110
 >> iter 27000, loss: 0.024095
 >> iter 28000, loss: 0.037053
 >> iter 29000, loss: 0.030134
 >> iter 30000, loss: 0.022358
   Number of active neurons: 2
 >> iter 31000, loss: 0.020878
 >> iter 32000, loss: 0.020183
 >> iter 33000, loss: 0.020641
 >> iter 34000, loss: 0.019782
 >> iter 35000, loss: 0.037223
 >> iter 36000, loss: 0.032255
 >> iter 37000, loss: 0.034626
 >> iter 38000, loss: 0.024451
 >> iter 39000, loss: 0.021048
 >> iter 40000, loss: 0.019864
   Number of active neurons: 2
 >> iter 41000, loss: 0.027249
 >> iter 42000, loss: 0.025626
 >> iter 43000, loss: 0.027292
 >> iter 44000, loss: 0.022838
 >> iter 45000, loss: 0.022414
 >> iter 46000, loss: 0.023897
 >> iter 47000, loss: 0.024562
 >> iter 48000, loss: 0.024709
 >> iter 49000, loss: 0.023192
 >> iter 50000, loss: 0.023429
   Number of active neurons: 2
 >> iter 51000, loss: 0.026443
 >> iter 52000, loss: 0.027023
 >> iter 53000, loss: 0.025307
 >> iter 54000, loss: 0.026927
 >> iter 55000, loss: 0.021269
 >> iter 56000, loss: 0.019608
 >> iter 57000, loss: 0.024119
 >> iter 58000, loss: 0.027270
 >> iter 59000, loss: 0.022480
 >> iter 60000, loss: 0.022743
   Number of active neurons: 2
 >> iter 61000, loss: 0.022343
 >> iter 62000, loss: 0.023297
 >> iter 63000, loss: 0.020820
 >> iter 64000, loss: 0.021900
 >> iter 65000, loss: 0.020544
 >> iter 66000, loss: 0.019095
 >> iter 67000, loss: 0.028930
 >> iter 68000, loss: 0.023553
 >> iter 69000, loss: 0.022802
 >> iter 70000, loss: 0.031906
   Number of active neurons: 2
 >> iter 71000, loss: 0.027110
 >> iter 72000, loss: 0.025371
 >> iter 73000, loss: 0.021737
 >> iter 74000, loss: 0.023543
 >> iter 75000, loss: 0.024429
 >> iter 76000, loss: 0.021146
 >> iter 77000, loss: 0.018884
 >> iter 78000, loss: 0.019718
 >> iter 79000, loss: 0.023864
 >> iter 80000, loss: 0.023285
   Number of active neurons: 2
 >> iter 81000, loss: 0.019978
 >> iter 82000, loss: 0.030730
 >> iter 83000, loss: 0.024399
 >> iter 84000, loss: 0.022154
 >> iter 85000, loss: 0.019717
 >> iter 86000, loss: 0.019960
 >> iter 87000, loss: 0.025919
 >> iter 88000, loss: 0.025438
 >> iter 89000, loss: 0.022865
 >> iter 90000, loss: 0.021225
   Number of active neurons: 2
 >> iter 91000, loss: 0.019537
 >> iter 92000, loss: 0.023284
 >> iter 93000, loss: 0.020905
 >> iter 94000, loss: 0.024345
 >> iter 95000, loss: 0.025107
 >> iter 96000, loss: 0.024017
 >> iter 97000, loss: 0.020989
 >> iter 98000, loss: 0.019538
 >> iter 99000, loss: 0.019255
 >> iter 100000, loss: 0.021006
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.920497
 >> iter 2000, loss: 4.055922
 >> iter 3000, loss: 1.520560
 >> iter 4000, loss: 0.579927
 >> iter 5000, loss: 0.232122
 >> iter 6000, loss: 0.110616
 >> iter 7000, loss: 0.064383
 >> iter 8000, loss: 0.059439
 >> iter 9000, loss: 0.041952
 >> iter 10000, loss: 0.032280
   Number of active neurons: 4
 >> iter 11000, loss: 0.030884
 >> iter 12000, loss: 0.027708
 >> iter 13000, loss: 0.028162
 >> iter 14000, loss: 0.025064
 >> iter 15000, loss: 0.027074
 >> iter 16000, loss: 0.024870
 >> iter 17000, loss: 0.036053
 >> iter 18000, loss: 0.044008
 >> iter 19000, loss: 0.031012
 >> iter 20000, loss: 0.024094
   Number of active neurons: 2
 >> iter 21000, loss: 0.023471
 >> iter 22000, loss: 0.021209
 >> iter 23000, loss: 0.028158
 >> iter 24000, loss: 0.025204
 >> iter 25000, loss: 0.024059
 >> iter 26000, loss: 0.022125
 >> iter 27000, loss: 0.025428
 >> iter 28000, loss: 0.032807
 >> iter 29000, loss: 0.024132
 >> iter 30000, loss: 0.022205
   Number of active neurons: 2
 >> iter 31000, loss: 0.023348
 >> iter 32000, loss: 0.029685
 >> iter 33000, loss: 0.024405
 >> iter 34000, loss: 0.024493
 >> iter 35000, loss: 0.033575
 >> iter 36000, loss: 0.026888
 >> iter 37000, loss: 0.023962
 >> iter 38000, loss: 0.029732
 >> iter 39000, loss: 0.040228
 >> iter 40000, loss: 0.028507
   Number of active neurons: 2
 >> iter 41000, loss: 0.041901
 >> iter 42000, loss: 0.033079
 >> iter 43000, loss: 0.025800
 >> iter 44000, loss: 0.024716
 >> iter 45000, loss: 0.020663
 >> iter 46000, loss: 0.023188
 >> iter 47000, loss: 0.020853
 >> iter 48000, loss: 0.024224
 >> iter 49000, loss: 0.022133
 >> iter 50000, loss: 0.027939
   Number of active neurons: 2
 >> iter 51000, loss: 0.031482
 >> iter 52000, loss: 0.029039
 >> iter 53000, loss: 0.027780
 >> iter 54000, loss: 0.027905
 >> iter 55000, loss: 0.022167
 >> iter 56000, loss: 0.021300
 >> iter 57000, loss: 0.020952
 >> iter 58000, loss: 0.022142
 >> iter 59000, loss: 0.020878
 >> iter 60000, loss: 0.020000
   Number of active neurons: 2
 >> iter 61000, loss: 0.032477
 >> iter 62000, loss: 0.025150
 >> iter 63000, loss: 0.023495
 >> iter 64000, loss: 0.022617
 >> iter 65000, loss: 0.020516
 >> iter 66000, loss: 0.020892
 >> iter 67000, loss: 0.019335
 >> iter 68000, loss: 0.022272
 >> iter 69000, loss: 0.029683
 >> iter 70000, loss: 0.023526
   Number of active neurons: 2
 >> iter 71000, loss: 0.020703
 >> iter 72000, loss: 0.034852
 >> iter 73000, loss: 0.026698
 >> iter 74000, loss: 0.025104
 >> iter 75000, loss: 0.022189
 >> iter 76000, loss: 0.023776
 >> iter 77000, loss: 0.043449
 >> iter 78000, loss: 0.041854
 >> iter 79000, loss: 0.030074
 >> iter 80000, loss: 0.023992
   Number of active neurons: 2
 >> iter 81000, loss: 0.040555
 >> iter 82000, loss: 0.030272
 >> iter 83000, loss: 0.026049
 >> iter 84000, loss: 0.023226
 >> iter 85000, loss: 0.023837
 >> iter 86000, loss: 0.025621
 >> iter 87000, loss: 0.021086
 >> iter 88000, loss: 0.050508
 >> iter 89000, loss: 0.032967
 >> iter 90000, loss: 0.027817
   Number of active neurons: 1
 >> iter 91000, loss: 0.023772
 >> iter 92000, loss: 0.021531
 >> iter 93000, loss: 0.019205
 >> iter 94000, loss: 0.024153
 >> iter 95000, loss: 0.034659
 >> iter 96000, loss: 0.026309
 >> iter 97000, loss: 0.027894
 >> iter 98000, loss: 0.021488
 >> iter 99000, loss: 0.017239
 >> iter 100000, loss: 0.023770
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.898554
 >> iter 2000, loss: 4.051540
 >> iter 3000, loss: 1.513343
 >> iter 4000, loss: 0.579227
 >> iter 5000, loss: 0.232830
 >> iter 6000, loss: 0.105366
 >> iter 7000, loss: 0.057344
 >> iter 8000, loss: 0.040763
 >> iter 9000, loss: 0.049603
 >> iter 10000, loss: 0.036958
   Number of active neurons: 5
 >> iter 11000, loss: 0.031922
 >> iter 12000, loss: 0.029699
 >> iter 13000, loss: 0.026537
 >> iter 14000, loss: 0.026676
 >> iter 15000, loss: 0.031620
 >> iter 16000, loss: 0.028350
 >> iter 17000, loss: 0.029016
 >> iter 18000, loss: 0.037338
 >> iter 19000, loss: 0.029070
 >> iter 20000, loss: 0.028271
   Number of active neurons: 4
 >> iter 21000, loss: 0.026026
 >> iter 22000, loss: 0.030882
 >> iter 23000, loss: 0.026426
 >> iter 24000, loss: 0.030188
 >> iter 25000, loss: 0.029959
 >> iter 26000, loss: 0.027077
 >> iter 27000, loss: 0.039771
 >> iter 28000, loss: 0.043245
 >> iter 29000, loss: 0.045879
 >> iter 30000, loss: 0.032998
   Number of active neurons: 4
 >> iter 31000, loss: 0.031303
 >> iter 32000, loss: 0.031136
 >> iter 33000, loss: 0.030869
 >> iter 34000, loss: 0.025407
 >> iter 35000, loss: 0.024444
 >> iter 36000, loss: 0.030179
 >> iter 37000, loss: 0.025313
 >> iter 38000, loss: 0.022883
 >> iter 39000, loss: 0.031761
 >> iter 40000, loss: 0.025131
   Number of active neurons: 2
 >> iter 41000, loss: 0.022554
 >> iter 42000, loss: 0.022425
 >> iter 43000, loss: 0.027094
 >> iter 44000, loss: 0.022659
 >> iter 45000, loss: 0.022173
 >> iter 46000, loss: 0.044728
 >> iter 47000, loss: 0.031500
 >> iter 48000, loss: 0.023669
 >> iter 49000, loss: 0.025555
 >> iter 50000, loss: 0.023757
   Number of active neurons: 2
 >> iter 51000, loss: 0.021807
 >> iter 52000, loss: 0.030185
 >> iter 53000, loss: 0.024313
 >> iter 54000, loss: 0.022050
 >> iter 55000, loss: 0.024929
 >> iter 56000, loss: 0.022649
 >> iter 57000, loss: 0.022229
 >> iter 58000, loss: 0.022225
 >> iter 59000, loss: 0.031851
 >> iter 60000, loss: 0.027002
   Number of active neurons: 2
 >> iter 61000, loss: 0.025315
 >> iter 62000, loss: 0.021841
 >> iter 63000, loss: 0.020902
 >> iter 64000, loss: 0.024026
 >> iter 65000, loss: 0.023463
 >> iter 66000, loss: 0.024399
 >> iter 67000, loss: 0.030008
 >> iter 68000, loss: 0.023783
 >> iter 69000, loss: 0.021665
 >> iter 70000, loss: 0.020647
   Number of active neurons: 2
 >> iter 71000, loss: 0.022726
 >> iter 72000, loss: 0.022154
 >> iter 73000, loss: 0.022143
 >> iter 74000, loss: 0.023062
 >> iter 75000, loss: 0.020781
 >> iter 76000, loss: 0.023928
 >> iter 77000, loss: 0.022422
 >> iter 78000, loss: 0.023717
 >> iter 79000, loss: 0.045874
 >> iter 80000, loss: 0.030180
   Number of active neurons: 2
 >> iter 81000, loss: 0.029701
 >> iter 82000, loss: 0.024903
 >> iter 83000, loss: 0.023393
 >> iter 84000, loss: 0.025762
 >> iter 85000, loss: 0.024161
 >> iter 86000, loss: 0.024409
 >> iter 87000, loss: 0.021730
 >> iter 88000, loss: 0.031793
 >> iter 89000, loss: 0.032622
 >> iter 90000, loss: 0.025171
   Number of active neurons: 2
 >> iter 91000, loss: 0.024737
 >> iter 92000, loss: 0.021092
 >> iter 93000, loss: 0.022968
 >> iter 94000, loss: 0.021591
 >> iter 95000, loss: 0.021693
 >> iter 96000, loss: 0.026924
 >> iter 97000, loss: 0.026467
 >> iter 98000, loss: 0.023890
 >> iter 99000, loss: 0.022793
 >> iter 100000, loss: 0.020488
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.099259
 >> iter 2000, loss: 4.123457
 >> iter 3000, loss: 1.537583
 >> iter 4000, loss: 0.592258
 >> iter 5000, loss: 0.238162
 >> iter 6000, loss: 0.123182
 >> iter 7000, loss: 0.074036
 >> iter 8000, loss: 0.044626
 >> iter 9000, loss: 0.032350
 >> iter 10000, loss: 0.030107
   Number of active neurons: 3
 >> iter 11000, loss: 0.026513
 >> iter 12000, loss: 0.025300
 >> iter 13000, loss: 0.025505
 >> iter 14000, loss: 0.031027
 >> iter 15000, loss: 0.028064
 >> iter 16000, loss: 0.029112
 >> iter 17000, loss: 0.026772
 >> iter 18000, loss: 0.024341
 >> iter 19000, loss: 0.024087
 >> iter 20000, loss: 0.028237
   Number of active neurons: 3
 >> iter 21000, loss: 0.036042
 >> iter 22000, loss: 0.028598
 >> iter 23000, loss: 0.024756
 >> iter 24000, loss: 0.021517
 >> iter 25000, loss: 0.026676
 >> iter 26000, loss: 0.027266
 >> iter 27000, loss: 0.022208
 >> iter 28000, loss: 0.021330
 >> iter 29000, loss: 0.021944
 >> iter 30000, loss: 0.021028
   Number of active neurons: 2
 >> iter 31000, loss: 0.021969
 >> iter 32000, loss: 0.029493
 >> iter 33000, loss: 0.022584
 >> iter 34000, loss: 0.025340
 >> iter 35000, loss: 0.023623
 >> iter 36000, loss: 0.021367
 >> iter 37000, loss: 0.020924
 >> iter 38000, loss: 0.024633
 >> iter 39000, loss: 0.028485
 >> iter 40000, loss: 0.024582
   Number of active neurons: 2
 >> iter 41000, loss: 0.025542
 >> iter 42000, loss: 0.020821
 >> iter 43000, loss: 0.025992
 >> iter 44000, loss: 0.026765
 >> iter 45000, loss: 0.021992
 >> iter 46000, loss: 0.022368
 >> iter 47000, loss: 0.021090
 >> iter 48000, loss: 0.020338
 >> iter 49000, loss: 0.024622
 >> iter 50000, loss: 0.023834
   Number of active neurons: 2
 >> iter 51000, loss: 0.021988
 >> iter 52000, loss: 0.021287
 >> iter 53000, loss: 0.024422
 >> iter 54000, loss: 0.024262
 >> iter 55000, loss: 0.024410
 >> iter 56000, loss: 0.030100
 >> iter 57000, loss: 0.035008
 >> iter 58000, loss: 0.024974
 >> iter 59000, loss: 0.027977
 >> iter 60000, loss: 0.032468
   Number of active neurons: 2
 >> iter 61000, loss: 0.027591
 >> iter 62000, loss: 0.022074
 >> iter 63000, loss: 0.022309
 >> iter 64000, loss: 0.022494
 >> iter 65000, loss: 0.022245
 >> iter 66000, loss: 0.025549
 >> iter 67000, loss: 0.022928
 >> iter 68000, loss: 0.027951
 >> iter 69000, loss: 0.024120
 >> iter 70000, loss: 0.023750
   Number of active neurons: 2
 >> iter 71000, loss: 0.023350
 >> iter 72000, loss: 0.037792
 >> iter 73000, loss: 0.035260
 >> iter 74000, loss: 0.026833
 >> iter 75000, loss: 0.024506
 >> iter 76000, loss: 0.023271
 >> iter 77000, loss: 0.021627
 >> iter 78000, loss: 0.021871
 >> iter 79000, loss: 0.021788
 >> iter 80000, loss: 0.022931
   Number of active neurons: 2
 >> iter 81000, loss: 0.023380
 >> iter 82000, loss: 0.024019
 >> iter 83000, loss: 0.027100
 >> iter 84000, loss: 0.022299
 >> iter 85000, loss: 0.023904
 >> iter 86000, loss: 0.022761
 >> iter 87000, loss: 0.022099
 >> iter 88000, loss: 0.026352
 >> iter 89000, loss: 0.025936
 >> iter 90000, loss: 0.022345
   Number of active neurons: 2
 >> iter 91000, loss: 0.023002
 >> iter 92000, loss: 0.030494
 >> iter 93000, loss: 0.025772
 >> iter 94000, loss: 0.032517
 >> iter 95000, loss: 0.029828
 >> iter 96000, loss: 0.026771
 >> iter 97000, loss: 0.022475
 >> iter 98000, loss: 0.023755
 >> iter 99000, loss: 0.020817
 >> iter 100000, loss: 0.019723
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.986473
 >> iter 2000, loss: 4.082545
 >> iter 3000, loss: 1.525540
 >> iter 4000, loss: 0.581612
 >> iter 5000, loss: 0.233588
 >> iter 6000, loss: 0.106685
 >> iter 7000, loss: 0.057549
 >> iter 8000, loss: 0.035571
 >> iter 9000, loss: 0.038357
 >> iter 10000, loss: 0.030559
   Number of active neurons: 4
 >> iter 11000, loss: 0.044527
 >> iter 12000, loss: 0.031055
 >> iter 13000, loss: 0.036233
 >> iter 14000, loss: 0.028077
 >> iter 15000, loss: 0.030473
 >> iter 16000, loss: 0.026857
 >> iter 17000, loss: 0.027149
 >> iter 18000, loss: 0.026544
 >> iter 19000, loss: 0.064601
 >> iter 20000, loss: 0.043049
   Number of active neurons: 4
 >> iter 21000, loss: 0.032530
 >> iter 22000, loss: 0.027766
 >> iter 23000, loss: 0.028219
 >> iter 24000, loss: 0.025065
 >> iter 25000, loss: 0.029030
 >> iter 26000, loss: 0.038607
 >> iter 27000, loss: 0.029435
 >> iter 28000, loss: 0.025614
 >> iter 29000, loss: 0.026586
 >> iter 30000, loss: 0.021773
   Number of active neurons: 2
 >> iter 31000, loss: 0.022964
 >> iter 32000, loss: 0.022071
 >> iter 33000, loss: 0.022515
 >> iter 34000, loss: 0.023601
 >> iter 35000, loss: 0.021215
 >> iter 36000, loss: 0.027832
 >> iter 37000, loss: 0.023756
 >> iter 38000, loss: 0.021264
 >> iter 39000, loss: 0.029571
 >> iter 40000, loss: 0.025172
   Number of active neurons: 2
 >> iter 41000, loss: 0.021311
 >> iter 42000, loss: 0.029029
 >> iter 43000, loss: 0.028908
 >> iter 44000, loss: 0.023145
 >> iter 45000, loss: 0.056399
 >> iter 46000, loss: 0.043548
 >> iter 47000, loss: 0.047809
 >> iter 48000, loss: 0.036694
 >> iter 49000, loss: 0.027925
 >> iter 50000, loss: 0.022670
   Number of active neurons: 2
 >> iter 51000, loss: 0.028336
 >> iter 52000, loss: 0.024756
 >> iter 53000, loss: 0.037138
 >> iter 54000, loss: 0.027211
 >> iter 55000, loss: 0.023138
 >> iter 56000, loss: 0.020304
 >> iter 57000, loss: 0.023593
 >> iter 58000, loss: 0.021836
 >> iter 59000, loss: 0.020782
 >> iter 60000, loss: 0.020276
   Number of active neurons: 2
 >> iter 61000, loss: 0.022337
 >> iter 62000, loss: 0.023726
 >> iter 63000, loss: 0.046210
 >> iter 64000, loss: 0.030620
 >> iter 65000, loss: 0.023901
 >> iter 66000, loss: 0.022466
 >> iter 67000, loss: 0.026615
 >> iter 68000, loss: 0.022662
 >> iter 69000, loss: 0.035480
 >> iter 70000, loss: 0.031194
   Number of active neurons: 2
 >> iter 71000, loss: 0.025860
 >> iter 72000, loss: 0.041183
 >> iter 73000, loss: 0.027564
 >> iter 74000, loss: 0.025227
 >> iter 75000, loss: 0.029564
 >> iter 76000, loss: 0.025137
 >> iter 77000, loss: 0.032875
 >> iter 78000, loss: 0.024473
 >> iter 79000, loss: 0.022028
 >> iter 80000, loss: 0.019933
   Number of active neurons: 2
 >> iter 81000, loss: 0.023039
 >> iter 82000, loss: 0.021507
 >> iter 83000, loss: 0.024287
 >> iter 84000, loss: 0.022829
 >> iter 85000, loss: 0.025580
 >> iter 86000, loss: 0.024536
 >> iter 87000, loss: 0.024326
 >> iter 88000, loss: 0.022437
 >> iter 89000, loss: 0.023686
 >> iter 90000, loss: 0.019874
   Number of active neurons: 2
 >> iter 91000, loss: 0.023198
 >> iter 92000, loss: 0.032892
 >> iter 93000, loss: 0.026773
 >> iter 94000, loss: 0.026476
 >> iter 95000, loss: 0.021788
 >> iter 96000, loss: 0.038439
 >> iter 97000, loss: 0.030811
 >> iter 98000, loss: 0.023788
 >> iter 99000, loss: 0.023697
 >> iter 100000, loss: 0.022042
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.811769
 >> iter 2000, loss: 4.018052
 >> iter 3000, loss: 1.514787
 >> iter 4000, loss: 0.576361
 >> iter 5000, loss: 0.234815
 >> iter 6000, loss: 0.105285
 >> iter 7000, loss: 0.061788
 >> iter 8000, loss: 0.038325
 >> iter 9000, loss: 0.031423
 >> iter 10000, loss: 0.029124
   Number of active neurons: 3
 >> iter 11000, loss: 0.027802
 >> iter 12000, loss: 0.028325
 >> iter 13000, loss: 0.029724
 >> iter 14000, loss: 0.032501
 >> iter 15000, loss: 0.026099
 >> iter 16000, loss: 0.025436
 >> iter 17000, loss: 0.024574
 >> iter 18000, loss: 0.024077
 >> iter 19000, loss: 0.031486
 >> iter 20000, loss: 0.028147
   Number of active neurons: 3
 >> iter 21000, loss: 0.024375
 >> iter 22000, loss: 0.024161
 >> iter 23000, loss: 0.023855
 >> iter 24000, loss: 0.042198
 >> iter 25000, loss: 0.031225
 >> iter 26000, loss: 0.026405
 >> iter 27000, loss: 0.043607
 >> iter 28000, loss: 0.038363
 >> iter 29000, loss: 0.029572
 >> iter 30000, loss: 0.034984
   Number of active neurons: 3
 >> iter 31000, loss: 0.026532
 >> iter 32000, loss: 0.024616
 >> iter 33000, loss: 0.024392
 >> iter 34000, loss: 0.026794
 >> iter 35000, loss: 0.027664
 >> iter 36000, loss: 0.023231
 >> iter 37000, loss: 0.028080
 >> iter 38000, loss: 0.028829
 >> iter 39000, loss: 0.024032
 >> iter 40000, loss: 0.023050
   Number of active neurons: 3
 >> iter 41000, loss: 0.025942
 >> iter 42000, loss: 0.028105
 >> iter 43000, loss: 0.027261
 >> iter 44000, loss: 0.033502
 >> iter 45000, loss: 0.025496
 >> iter 46000, loss: 0.026564
 >> iter 47000, loss: 0.025228
 >> iter 48000, loss: 0.025019
 >> iter 49000, loss: 0.045981
 >> iter 50000, loss: 0.031646
   Number of active neurons: 3
 >> iter 51000, loss: 0.027323
 >> iter 52000, loss: 0.028622
 >> iter 53000, loss: 0.023662
 >> iter 54000, loss: 0.026143
 >> iter 55000, loss: 0.048349
 >> iter 56000, loss: 0.044239
 >> iter 57000, loss: 0.034487
 >> iter 58000, loss: 0.053237
 >> iter 59000, loss: 0.032892
 >> iter 60000, loss: 0.033409
   Number of active neurons: 2
 >> iter 61000, loss: 0.025493
 >> iter 62000, loss: 0.022614
 >> iter 63000, loss: 0.024727
 >> iter 64000, loss: 0.023783
 >> iter 65000, loss: 0.030159
 >> iter 66000, loss: 0.024526
 >> iter 67000, loss: 0.035405
 >> iter 68000, loss: 0.057189
 >> iter 69000, loss: 0.036352
 >> iter 70000, loss: 0.031899
   Number of active neurons: 2
 >> iter 71000, loss: 0.035582
 >> iter 72000, loss: 0.038041
 >> iter 73000, loss: 0.026902
 >> iter 74000, loss: 0.022581
 >> iter 75000, loss: 0.039056
 >> iter 76000, loss: 0.028226
 >> iter 77000, loss: 0.023115
 >> iter 78000, loss: 0.036074
 >> iter 79000, loss: 0.029467
 >> iter 80000, loss: 0.025242
   Number of active neurons: 2
 >> iter 81000, loss: 0.047152
 >> iter 82000, loss: 0.037868
 >> iter 83000, loss: 0.026353
 >> iter 84000, loss: 0.022171
 >> iter 85000, loss: 0.020787
 >> iter 86000, loss: 0.038810
 >> iter 87000, loss: 0.028553
 >> iter 88000, loss: 0.022962
 >> iter 89000, loss: 0.023946
 >> iter 90000, loss: 0.020766
   Number of active neurons: 1
 >> iter 91000, loss: 0.028592
 >> iter 92000, loss: 0.027066
 >> iter 93000, loss: 0.020958
 >> iter 94000, loss: 0.019848
 >> iter 95000, loss: 0.020137
 >> iter 96000, loss: 0.020215
 >> iter 97000, loss: 0.019179
 >> iter 98000, loss: 0.017276
 >> iter 99000, loss: 0.015962
 >> iter 100000, loss: 0.018854
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 10.948048
 >> iter 2000, loss: 4.077842
 >> iter 3000, loss: 1.525803
 >> iter 4000, loss: 0.603863
 >> iter 5000, loss: 0.248285
 >> iter 6000, loss: 0.111248
 >> iter 7000, loss: 0.067781
 >> iter 8000, loss: 0.042957
 >> iter 9000, loss: 0.038520
 >> iter 10000, loss: 0.032884
   Number of active neurons: 3
 >> iter 11000, loss: 0.030380
 >> iter 12000, loss: 0.027487
 >> iter 13000, loss: 0.028377
 >> iter 14000, loss: 0.026093
 >> iter 15000, loss: 0.027992
 >> iter 16000, loss: 0.037443
 >> iter 17000, loss: 0.033247
 >> iter 18000, loss: 0.044171
 >> iter 19000, loss: 0.030571
 >> iter 20000, loss: 0.025685
   Number of active neurons: 1
 >> iter 21000, loss: 0.024875
 >> iter 22000, loss: 0.040748
 >> iter 23000, loss: 0.031102
 >> iter 24000, loss: 0.024017
 >> iter 25000, loss: 0.057015
 >> iter 26000, loss: 0.033162
 >> iter 27000, loss: 0.031027
 >> iter 28000, loss: 0.044275
 >> iter 29000, loss: 0.027979
 >> iter 30000, loss: 0.023911
   Number of active neurons: 1
 >> iter 31000, loss: 0.032841
 >> iter 32000, loss: 0.022933
 >> iter 33000, loss: 0.022523
 >> iter 34000, loss: 0.018517
 >> iter 35000, loss: 0.019312
 >> iter 36000, loss: 0.026472
 >> iter 37000, loss: 0.056840
 >> iter 38000, loss: 0.045713
 >> iter 39000, loss: 0.035479
 >> iter 40000, loss: 0.024334
   Number of active neurons: 1
 >> iter 41000, loss: 0.020930
 >> iter 42000, loss: 0.020235
 >> iter 43000, loss: 0.019454
 >> iter 44000, loss: 0.026201
 >> iter 45000, loss: 0.019850
 >> iter 46000, loss: 0.022899
 >> iter 47000, loss: 0.018360
 >> iter 48000, loss: 0.021039
 >> iter 49000, loss: 0.021761
 >> iter 50000, loss: 0.021121
   Number of active neurons: 1
 >> iter 51000, loss: 0.018961
 >> iter 52000, loss: 0.027258
 >> iter 53000, loss: 0.025721
 >> iter 54000, loss: 0.020940
 >> iter 55000, loss: 0.023433
 >> iter 56000, loss: 0.019686
 >> iter 57000, loss: 0.018523
 >> iter 58000, loss: 0.018574
 >> iter 59000, loss: 0.016708
 >> iter 60000, loss: 0.019726
   Number of active neurons: 1
 >> iter 61000, loss: 0.016817
 >> iter 62000, loss: 0.018460
 >> iter 63000, loss: 0.018719
 >> iter 64000, loss: 0.026500
 >> iter 65000, loss: 0.050399
 >> iter 66000, loss: 0.031228
 >> iter 67000, loss: 0.021007
 >> iter 68000, loss: 0.017804
 >> iter 69000, loss: 0.030370
 >> iter 70000, loss: 0.023222
   Number of active neurons: 1
 >> iter 71000, loss: 0.020388
 >> iter 72000, loss: 0.023492
 >> iter 73000, loss: 0.018969
 >> iter 74000, loss: 0.019760
 >> iter 75000, loss: 0.027790
 >> iter 76000, loss: 0.019829
 >> iter 77000, loss: 0.024678
 >> iter 78000, loss: 0.025882
 >> iter 79000, loss: 0.019834
 >> iter 80000, loss: 0.016620
   Number of active neurons: 1
 >> iter 81000, loss: 0.016090
 >> iter 82000, loss: 0.016538
 >> iter 83000, loss: 0.017103
 >> iter 84000, loss: 0.022965
 >> iter 85000, loss: 0.018383
 >> iter 86000, loss: 0.040486
 >> iter 87000, loss: 0.031894
 >> iter 88000, loss: 0.022145
 >> iter 89000, loss: 0.020524
 >> iter 90000, loss: 0.020990
   Number of active neurons: 1
 >> iter 91000, loss: 0.021445
 >> iter 92000, loss: 0.018900
 >> iter 93000, loss: 0.040848
 >> iter 94000, loss: 0.029817
 >> iter 95000, loss: 0.021653
 >> iter 96000, loss: 0.019450
 >> iter 97000, loss: 0.017814
 >> iter 98000, loss: 0.017267
 >> iter 99000, loss: 0.017615
 >> iter 100000, loss: 0.017015
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.975607
 >> iter 2000, loss: 4.085686
 >> iter 3000, loss: 1.529220
 >> iter 4000, loss: 0.578183
 >> iter 5000, loss: 0.231726
 >> iter 6000, loss: 0.112093
 >> iter 7000, loss: 0.060184
 >> iter 8000, loss: 0.045508
 >> iter 9000, loss: 0.036536
 >> iter 10000, loss: 0.031599
   Number of active neurons: 4
 >> iter 11000, loss: 0.033040
 >> iter 12000, loss: 0.027086
 >> iter 13000, loss: 0.026410
 >> iter 14000, loss: 0.023968
 >> iter 15000, loss: 0.030760
 >> iter 16000, loss: 0.026757
 >> iter 17000, loss: 0.026370
 >> iter 18000, loss: 0.026771
 >> iter 19000, loss: 0.028114
 >> iter 20000, loss: 0.024703
   Number of active neurons: 2
 >> iter 21000, loss: 0.030042
 >> iter 22000, loss: 0.032709
 >> iter 23000, loss: 0.028109
 >> iter 24000, loss: 0.023523
 >> iter 25000, loss: 0.021604
 >> iter 26000, loss: 0.024783
 >> iter 27000, loss: 0.022514
 >> iter 28000, loss: 0.021470
 >> iter 29000, loss: 0.026369
 >> iter 30000, loss: 0.022045
   Number of active neurons: 2
 >> iter 31000, loss: 0.033137
 >> iter 32000, loss: 0.024755
 >> iter 33000, loss: 0.023588
 >> iter 34000, loss: 0.023035
 >> iter 35000, loss: 0.020603
 >> iter 36000, loss: 0.022899
 >> iter 37000, loss: 0.040859
 >> iter 38000, loss: 0.042530
 >> iter 39000, loss: 0.028799
 >> iter 40000, loss: 0.027925
   Number of active neurons: 2
 >> iter 41000, loss: 0.023645
 >> iter 42000, loss: 0.022318
 >> iter 43000, loss: 0.024011
 >> iter 44000, loss: 0.021736
 >> iter 45000, loss: 0.026255
 >> iter 46000, loss: 0.035301
 >> iter 47000, loss: 0.028559
 >> iter 48000, loss: 0.025989
 >> iter 49000, loss: 0.033352
 >> iter 50000, loss: 0.026805
   Number of active neurons: 2
 >> iter 51000, loss: 0.024774
 >> iter 52000, loss: 0.022921
 >> iter 53000, loss: 0.030457
 >> iter 54000, loss: 0.023667
 >> iter 55000, loss: 0.020712
 >> iter 56000, loss: 0.020690
 >> iter 57000, loss: 0.019593
 >> iter 58000, loss: 0.023046
 >> iter 59000, loss: 0.056176
 >> iter 60000, loss: 0.039244
   Number of active neurons: 2
 >> iter 61000, loss: 0.027899
 >> iter 62000, loss: 0.024827
 >> iter 63000, loss: 0.023135
 >> iter 64000, loss: 0.022849
 >> iter 65000, loss: 0.024985
 >> iter 66000, loss: 0.021690
 >> iter 67000, loss: 0.031589
 >> iter 68000, loss: 0.024540
 >> iter 69000, loss: 0.022229
 >> iter 70000, loss: 0.021699
   Number of active neurons: 2
 >> iter 71000, loss: 0.024034
 >> iter 72000, loss: 0.022165
 >> iter 73000, loss: 0.022474
 >> iter 74000, loss: 0.023829
 >> iter 75000, loss: 0.022312
 >> iter 76000, loss: 0.020476
 >> iter 77000, loss: 0.022290
 >> iter 78000, loss: 0.023257
 >> iter 79000, loss: 0.026608
 >> iter 80000, loss: 0.025718
   Number of active neurons: 2
 >> iter 81000, loss: 0.030094
 >> iter 82000, loss: 0.025059
 >> iter 83000, loss: 0.021413
 >> iter 84000, loss: 0.034837
 >> iter 85000, loss: 0.026282
 >> iter 86000, loss: 0.026259
 >> iter 87000, loss: 0.023182
 >> iter 88000, loss: 0.022200
 >> iter 89000, loss: 0.024660
 >> iter 90000, loss: 0.028226
   Number of active neurons: 2
 >> iter 91000, loss: 0.025188
 >> iter 92000, loss: 0.026090
 >> iter 93000, loss: 0.029510
 >> iter 94000, loss: 0.024447
 >> iter 95000, loss: 0.026061
 >> iter 96000, loss: 0.022194
 >> iter 97000, loss: 0.024964
 >> iter 98000, loss: 0.025409
 >> iter 99000, loss: 0.040313
 >> iter 100000, loss: 0.027642
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.949437
 >> iter 2000, loss: 4.059629
 >> iter 3000, loss: 1.519674
 >> iter 4000, loss: 0.586623
 >> iter 5000, loss: 0.246175
 >> iter 6000, loss: 0.107777
 >> iter 7000, loss: 0.060466
 >> iter 8000, loss: 0.039195
 >> iter 9000, loss: 0.033008
 >> iter 10000, loss: 0.032770
   Number of active neurons: 3
 >> iter 11000, loss: 0.030757
 >> iter 12000, loss: 0.036563
 >> iter 13000, loss: 0.032368
 >> iter 14000, loss: 0.026245
 >> iter 15000, loss: 0.026172
 >> iter 16000, loss: 0.024575
 >> iter 17000, loss: 0.025640
 >> iter 18000, loss: 0.026912
 >> iter 19000, loss: 0.028486
 >> iter 20000, loss: 0.033920
   Number of active neurons: 3
 >> iter 21000, loss: 0.028433
 >> iter 22000, loss: 0.037917
 >> iter 23000, loss: 0.043713
 >> iter 24000, loss: 0.032486
 >> iter 25000, loss: 0.026236
 >> iter 26000, loss: 0.024572
 >> iter 27000, loss: 0.030959
 >> iter 28000, loss: 0.025844
 >> iter 29000, loss: 0.027113
 >> iter 30000, loss: 0.030536
   Number of active neurons: 3
 >> iter 31000, loss: 0.025157
 >> iter 32000, loss: 0.028905
 >> iter 33000, loss: 0.027338
 >> iter 34000, loss: 0.036802
 >> iter 35000, loss: 0.029576
 >> iter 36000, loss: 0.036694
 >> iter 37000, loss: 0.030983
 >> iter 38000, loss: 0.038704
 >> iter 39000, loss: 0.032905
 >> iter 40000, loss: 0.028978
   Number of active neurons: 3
 >> iter 41000, loss: 0.026916
 >> iter 42000, loss: 0.027446
 >> iter 43000, loss: 0.026531
 >> iter 44000, loss: 0.027890
 >> iter 45000, loss: 0.031673
 >> iter 46000, loss: 0.028860
 >> iter 47000, loss: 0.022613
 >> iter 48000, loss: 0.026981
 >> iter 49000, loss: 0.028237
 >> iter 50000, loss: 0.024763
   Number of active neurons: 2
 >> iter 51000, loss: 0.024657
 >> iter 52000, loss: 0.022229
 >> iter 53000, loss: 0.023401
 >> iter 54000, loss: 0.021498
 >> iter 55000, loss: 0.020498
 >> iter 56000, loss: 0.028910
 >> iter 57000, loss: 0.024122
 >> iter 58000, loss: 0.023815
 >> iter 59000, loss: 0.022431
 >> iter 60000, loss: 0.020797
   Number of active neurons: 2
 >> iter 61000, loss: 0.023839
 >> iter 62000, loss: 0.027842
 >> iter 63000, loss: 0.024299
 >> iter 64000, loss: 0.022595
 >> iter 65000, loss: 0.023340
 >> iter 66000, loss: 0.024311
 >> iter 67000, loss: 0.023826
 >> iter 68000, loss: 0.019336
 >> iter 69000, loss: 0.020485
 >> iter 70000, loss: 0.042345
   Number of active neurons: 1
 >> iter 71000, loss: 0.027219
 >> iter 72000, loss: 0.030363
 >> iter 73000, loss: 0.021190
 >> iter 74000, loss: 0.018484
 >> iter 75000, loss: 0.020219
 >> iter 76000, loss: 0.028288
 >> iter 77000, loss: 0.020245
 >> iter 78000, loss: 0.027386
 >> iter 79000, loss: 0.023403
 >> iter 80000, loss: 0.020193
   Number of active neurons: 1
 >> iter 81000, loss: 0.021061
 >> iter 82000, loss: 0.019186
 >> iter 83000, loss: 0.022293
 >> iter 84000, loss: 0.019737
 >> iter 85000, loss: 0.018143
 >> iter 86000, loss: 0.018059
 >> iter 87000, loss: 0.020526
 >> iter 88000, loss: 0.016468
 >> iter 89000, loss: 0.022180
 >> iter 90000, loss: 0.017784
   Number of active neurons: 1
 >> iter 91000, loss: 0.018907
 >> iter 92000, loss: 0.022450
 >> iter 93000, loss: 0.017790
 >> iter 94000, loss: 0.018468
 >> iter 95000, loss: 0.018928
 >> iter 96000, loss: 0.020923
 >> iter 97000, loss: 0.019049
 >> iter 98000, loss: 0.017151
 >> iter 99000, loss: 0.017549
 >> iter 100000, loss: 0.017056
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 10.904513
 >> iter 2000, loss: 4.060812
 >> iter 3000, loss: 1.513164
 >> iter 4000, loss: 0.575659
 >> iter 5000, loss: 0.231077
 >> iter 6000, loss: 0.102884
 >> iter 7000, loss: 0.053351
 >> iter 8000, loss: 0.039273
 >> iter 9000, loss: 0.034480
 >> iter 10000, loss: 0.029046
   Number of active neurons: 4
 >> iter 11000, loss: 0.031998
 >> iter 12000, loss: 0.027001
 >> iter 13000, loss: 0.034755
 >> iter 14000, loss: 0.028918
 >> iter 15000, loss: 0.031765
 >> iter 16000, loss: 0.029987
 >> iter 17000, loss: 0.025871
 >> iter 18000, loss: 0.030030
 >> iter 19000, loss: 0.028374
 >> iter 20000, loss: 0.025165
   Number of active neurons: 3
 >> iter 21000, loss: 0.027549
 >> iter 22000, loss: 0.025887
 >> iter 23000, loss: 0.026564
 >> iter 24000, loss: 0.040461
 >> iter 25000, loss: 0.030866
 >> iter 26000, loss: 0.026733
 >> iter 27000, loss: 0.025798
 >> iter 28000, loss: 0.025660
 >> iter 29000, loss: 0.025905
 >> iter 30000, loss: 0.032112
   Number of active neurons: 3
 >> iter 31000, loss: 0.035415
 >> iter 32000, loss: 0.027358
 >> iter 33000, loss: 0.033616
 >> iter 34000, loss: 0.027552
 >> iter 35000, loss: 0.024984
 >> iter 36000, loss: 0.024539
 >> iter 37000, loss: 0.025321
 >> iter 38000, loss: 0.026966
 >> iter 39000, loss: 0.025400
 >> iter 40000, loss: 0.035014
   Number of active neurons: 3
 >> iter 41000, loss: 0.028227
 >> iter 42000, loss: 0.024791
 >> iter 43000, loss: 0.026182
 >> iter 44000, loss: 0.030315
 >> iter 45000, loss: 0.029774
 >> iter 46000, loss: 0.026804
 >> iter 47000, loss: 0.023594
 >> iter 48000, loss: 0.028990
 >> iter 49000, loss: 0.026256
 >> iter 50000, loss: 0.042695
   Number of active neurons: 3
 >> iter 51000, loss: 0.033664
 >> iter 52000, loss: 0.028073
 >> iter 53000, loss: 0.024463
 >> iter 54000, loss: 0.025682
 >> iter 55000, loss: 0.024244
 >> iter 56000, loss: 0.029645
 >> iter 57000, loss: 0.027073
 >> iter 58000, loss: 0.041105
 >> iter 59000, loss: 0.028925
 >> iter 60000, loss: 0.028338
   Number of active neurons: 3
 >> iter 61000, loss: 0.034013
 >> iter 62000, loss: 0.032349
 >> iter 63000, loss: 0.031065
 >> iter 64000, loss: 0.026291
 >> iter 65000, loss: 0.035184
 >> iter 66000, loss: 0.029090
 >> iter 67000, loss: 0.027052
 >> iter 68000, loss: 0.025031
 >> iter 69000, loss: 0.024047
 >> iter 70000, loss: 0.022439
   Number of active neurons: 2
 >> iter 71000, loss: 0.023295
 >> iter 72000, loss: 0.022678
 >> iter 73000, loss: 0.021134
 >> iter 74000, loss: 0.021526
 >> iter 75000, loss: 0.026130
 >> iter 76000, loss: 0.024004
 >> iter 77000, loss: 0.021239
 >> iter 78000, loss: 0.025260
 >> iter 79000, loss: 0.022177
 >> iter 80000, loss: 0.018946
   Number of active neurons: 1
 >> iter 81000, loss: 0.017635
 >> iter 82000, loss: 0.023198
 >> iter 83000, loss: 0.024286
 >> iter 84000, loss: 0.029588
 >> iter 85000, loss: 0.026375
 >> iter 86000, loss: 0.027591
 >> iter 87000, loss: 0.023734
 >> iter 88000, loss: 0.020264
 >> iter 89000, loss: 0.019198
 >> iter 90000, loss: 0.021381
   Number of active neurons: 1
 >> iter 91000, loss: 0.018124
 >> iter 92000, loss: 0.020388
 >> iter 93000, loss: 0.018472
 >> iter 94000, loss: 0.020838
 >> iter 95000, loss: 0.018473
 >> iter 96000, loss: 0.021241
 >> iter 97000, loss: 0.020522
 >> iter 98000, loss: 0.036183
 >> iter 99000, loss: 0.028323
 >> iter 100000, loss: 0.030099
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.923844
 >> iter 2000, loss: 4.050886
 >> iter 3000, loss: 1.513869
 >> iter 4000, loss: 0.582661
 >> iter 5000, loss: 0.235561
 >> iter 6000, loss: 0.105715
 >> iter 7000, loss: 0.056989
 >> iter 8000, loss: 0.039238
 >> iter 9000, loss: 0.037954
 >> iter 10000, loss: 0.032928
   Number of active neurons: 4
 >> iter 11000, loss: 0.030931
 >> iter 12000, loss: 0.026830
 >> iter 13000, loss: 0.033715
 >> iter 14000, loss: 0.028176
 >> iter 15000, loss: 0.026945
 >> iter 16000, loss: 0.027069
 >> iter 17000, loss: 0.025130
 >> iter 18000, loss: 0.026764
 >> iter 19000, loss: 0.026150
 >> iter 20000, loss: 0.029765
   Number of active neurons: 3
 >> iter 21000, loss: 0.039924
 >> iter 22000, loss: 0.029477
 >> iter 23000, loss: 0.028466
 >> iter 24000, loss: 0.025963
 >> iter 25000, loss: 0.027034
 >> iter 26000, loss: 0.024158
 >> iter 27000, loss: 0.055274
 >> iter 28000, loss: 0.035923
 >> iter 29000, loss: 0.030788
 >> iter 30000, loss: 0.033492
   Number of active neurons: 3
 >> iter 31000, loss: 0.030803
 >> iter 32000, loss: 0.029227
 >> iter 33000, loss: 0.025539
 >> iter 34000, loss: 0.024093
 >> iter 35000, loss: 0.023590
 >> iter 36000, loss: 0.023290
 >> iter 37000, loss: 0.022410
 >> iter 38000, loss: 0.028773
 >> iter 39000, loss: 0.024855
 >> iter 40000, loss: 0.022963
   Number of active neurons: 2
 >> iter 41000, loss: 0.024810
 >> iter 42000, loss: 0.028195
 >> iter 43000, loss: 0.025964
 >> iter 44000, loss: 0.022758
 >> iter 45000, loss: 0.021408
 >> iter 46000, loss: 0.020424
 >> iter 47000, loss: 0.022406
 >> iter 48000, loss: 0.020280
 >> iter 49000, loss: 0.024266
 >> iter 50000, loss: 0.024995
   Number of active neurons: 2
 >> iter 51000, loss: 0.024248
 >> iter 52000, loss: 0.021102
 >> iter 53000, loss: 0.036035
 >> iter 54000, loss: 0.026649
 >> iter 55000, loss: 0.023004
 >> iter 56000, loss: 0.021255
 >> iter 57000, loss: 0.024622
 >> iter 58000, loss: 0.026978
 >> iter 59000, loss: 0.029474
 >> iter 60000, loss: 0.023241
   Number of active neurons: 2
 >> iter 61000, loss: 0.020568
 >> iter 62000, loss: 0.021200
 >> iter 63000, loss: 0.021007
 >> iter 64000, loss: 0.021006
 >> iter 65000, loss: 0.022095
 >> iter 66000, loss: 0.027158
 >> iter 67000, loss: 0.024566
 >> iter 68000, loss: 0.024747
 >> iter 69000, loss: 0.023110
 >> iter 70000, loss: 0.024219
   Number of active neurons: 2
 >> iter 71000, loss: 0.024787
 >> iter 72000, loss: 0.020844
 >> iter 73000, loss: 0.020121
 >> iter 74000, loss: 0.021269
 >> iter 75000, loss: 0.028976
 >> iter 76000, loss: 0.030960
 >> iter 77000, loss: 0.023450
 >> iter 78000, loss: 0.034966
 >> iter 79000, loss: 0.026062
 >> iter 80000, loss: 0.026963
   Number of active neurons: 2
 >> iter 81000, loss: 0.024228
 >> iter 82000, loss: 0.024905
 >> iter 83000, loss: 0.026599
 >> iter 84000, loss: 0.022175
 >> iter 85000, loss: 0.031671
 >> iter 86000, loss: 0.026371
 >> iter 87000, loss: 0.025630
 >> iter 88000, loss: 0.021938
 >> iter 89000, loss: 0.024887
 >> iter 90000, loss: 0.024245
   Number of active neurons: 2
 >> iter 91000, loss: 0.031095
 >> iter 92000, loss: 0.025149
 >> iter 93000, loss: 0.025065
 >> iter 94000, loss: 0.021864
 >> iter 95000, loss: 0.020378
 >> iter 96000, loss: 0.049505
 >> iter 97000, loss: 0.032076
 >> iter 98000, loss: 0.026247
 >> iter 99000, loss: 0.021558
 >> iter 100000, loss: 0.022079
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

