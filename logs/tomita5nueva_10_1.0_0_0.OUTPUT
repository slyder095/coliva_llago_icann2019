 > Problema: tomita5nueva
 > Args:
   - Hidden size: 10
   - Noise level: 1.0
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.814688
 >> iter 2000, loss: 11.192918
 >> iter 3000, loss: 8.965792
 >> iter 4000, loss: 8.174689
 >> iter 5000, loss: 7.852337
 >> iter 6000, loss: 7.720262
 >> iter 7000, loss: 7.653270
 >> iter 8000, loss: 7.679124
 >> iter 9000, loss: 7.628891
 >> iter 10000, loss: 7.681811
   Number of active neurons: 10
 >> iter 11000, loss: 7.632523
 >> iter 12000, loss: 7.594295
 >> iter 13000, loss: 7.612305
 >> iter 14000, loss: 7.580347
 >> iter 15000, loss: 7.576181
 >> iter 16000, loss: 7.626971
 >> iter 17000, loss: 7.598773
 >> iter 18000, loss: 7.580482
 >> iter 19000, loss: 7.578572
 >> iter 20000, loss: 7.592175
   Number of active neurons: 10
 >> iter 21000, loss: 7.577013
 >> iter 22000, loss: 7.564634
 >> iter 23000, loss: 7.570761
 >> iter 24000, loss: 7.560833
 >> iter 25000, loss: 7.570289
 >> iter 26000, loss: 7.568407
 >> iter 27000, loss: 7.570575
 >> iter 28000, loss: 7.563350
 >> iter 29000, loss: 7.629781
 >> iter 30000, loss: 7.600164
   Number of active neurons: 10
 >> iter 31000, loss: 7.581606
 >> iter 32000, loss: 7.571493
 >> iter 33000, loss: 7.578099
 >> iter 34000, loss: 7.567463
 >> iter 35000, loss: 7.574155
 >> iter 36000, loss: 7.566000
 >> iter 37000, loss: 7.571024
 >> iter 38000, loss: 7.563176
 >> iter 39000, loss: 7.572402
 >> iter 40000, loss: 7.563482
   Number of active neurons: 10
 >> iter 41000, loss: 7.573575
 >> iter 42000, loss: 7.558567
 >> iter 43000, loss: 7.569254
 >> iter 44000, loss: 7.558041
 >> iter 45000, loss: 7.568130
 >> iter 46000, loss: 7.559743
 >> iter 47000, loss: 7.569836
 >> iter 48000, loss: 7.560537
 >> iter 49000, loss: 7.565056
 >> iter 50000, loss: 7.554512
   Number of active neurons: 10
 >> iter 51000, loss: 7.568650
 >> iter 52000, loss: 7.553093
 >> iter 53000, loss: 7.569402
 >> iter 54000, loss: 7.553548
 >> iter 55000, loss: 7.566874
 >> iter 56000, loss: 7.554696
 >> iter 57000, loss: 7.564132
 >> iter 58000, loss: 7.550710
 >> iter 59000, loss: 7.554776
 >> iter 60000, loss: 7.531919
   Number of active neurons: 10
 >> iter 61000, loss: 7.507922
 >> iter 62000, loss: 7.565146
 >> iter 63000, loss: 7.446939
 >> iter 64000, loss: 7.305306
 >> iter 65000, loss: 7.200167
 >> iter 66000, loss: 7.045262
 >> iter 67000, loss: 7.043723
 >> iter 68000, loss: 6.854591
 >> iter 69000, loss: 6.560511
 >> iter 70000, loss: 6.315158
   Number of active neurons: 10
 >> iter 71000, loss: 6.143584
 >> iter 72000, loss: 6.046849
 >> iter 73000, loss: 6.136686
 >> iter 74000, loss: 5.961190
 >> iter 75000, loss: 5.888310
 >> iter 76000, loss: 5.541404
 >> iter 77000, loss: 4.308256
 >> iter 78000, loss: 2.774495
 >> iter 79000, loss: 1.358910
 >> iter 80000, loss: 0.927053
   Number of active neurons: 10
 >> iter 81000, loss: 0.512839
 >> iter 82000, loss: 0.561643
 >> iter 83000, loss: 0.536083
 >> iter 84000, loss: 0.258550
 >> iter 85000, loss: 0.268192
 >> iter 86000, loss: 0.305425
 >> iter 87000, loss: 0.386034
 >> iter 88000, loss: 0.217131
 >> iter 89000, loss: 0.324351
 >> iter 90000, loss: 0.174312
   Number of active neurons: 10
 >> iter 91000, loss: 0.104598
 >> iter 92000, loss: 0.140647
 >> iter 93000, loss: 0.173501
 >> iter 94000, loss: 0.133064
 >> iter 95000, loss: 0.191506
 >> iter 96000, loss: 0.096319
 >> iter 97000, loss: 0.082875
 >> iter 98000, loss: 0.062991
 >> iter 99000, loss: 0.041868
 >> iter 100000, loss: 0.080515
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.799007
 >> iter 2000, loss: 11.231815
 >> iter 3000, loss: 9.043884
 >> iter 4000, loss: 8.159654
 >> iter 5000, loss: 7.918649
 >> iter 6000, loss: 7.760595
 >> iter 7000, loss: 7.673595
 >> iter 8000, loss: 7.620529
 >> iter 9000, loss: 7.609180
 >> iter 10000, loss: 7.593642
   Number of active neurons: 10
 >> iter 11000, loss: 7.585108
 >> iter 12000, loss: 7.600411
 >> iter 13000, loss: 7.587081
 >> iter 14000, loss: 7.594769
 >> iter 15000, loss: 7.609027
 >> iter 16000, loss: 7.573051
 >> iter 17000, loss: 7.577325
 >> iter 18000, loss: 7.570716
 >> iter 19000, loss: 7.572952
 >> iter 20000, loss: 7.562811
   Number of active neurons: 10
 >> iter 21000, loss: 7.570641
 >> iter 22000, loss: 7.562833
 >> iter 23000, loss: 7.565381
 >> iter 24000, loss: 7.558076
 >> iter 25000, loss: 7.569508
 >> iter 26000, loss: 7.596065
 >> iter 27000, loss: 7.581041
 >> iter 28000, loss: 7.568163
 >> iter 29000, loss: 7.566973
 >> iter 30000, loss: 7.564958
   Number of active neurons: 10
 >> iter 31000, loss: 7.569960
 >> iter 32000, loss: 7.565310
 >> iter 33000, loss: 7.569269
 >> iter 34000, loss: 7.563397
 >> iter 35000, loss: 7.568658
 >> iter 36000, loss: 7.559601
 >> iter 37000, loss: 7.585047
 >> iter 38000, loss: 7.588816
 >> iter 39000, loss: 7.582064
 >> iter 40000, loss: 7.567649
   Number of active neurons: 10
 >> iter 41000, loss: 7.572803
 >> iter 42000, loss: 7.566223
 >> iter 43000, loss: 7.574386
 >> iter 44000, loss: 7.557265
 >> iter 45000, loss: 7.591495
 >> iter 46000, loss: 7.564247
 >> iter 47000, loss: 7.570306
 >> iter 48000, loss: 7.576523
 >> iter 49000, loss: 7.546607
 >> iter 50000, loss: 7.481150
   Number of active neurons: 10
 >> iter 51000, loss: 7.460545
 >> iter 52000, loss: 7.423027
 >> iter 53000, loss: 7.243393
 >> iter 54000, loss: 7.160646
 >> iter 55000, loss: 7.041262
 >> iter 56000, loss: 6.970699
 >> iter 57000, loss: 6.943164
 >> iter 58000, loss: 6.919548
 >> iter 59000, loss: 6.874589
 >> iter 60000, loss: 6.819867
   Number of active neurons: 10
 >> iter 61000, loss: 6.755922
 >> iter 62000, loss: 6.661626
 >> iter 63000, loss: 6.662299
 >> iter 64000, loss: 6.471810
 >> iter 65000, loss: 6.349249
 >> iter 66000, loss: 6.165100
 >> iter 67000, loss: 5.993176
 >> iter 68000, loss: 5.781949
 >> iter 69000, loss: 5.581663
 >> iter 70000, loss: 5.339023
   Number of active neurons: 10
 >> iter 71000, loss: 5.046225
 >> iter 72000, loss: 4.706191
 >> iter 73000, loss: 4.145808
 >> iter 74000, loss: 3.680937
 >> iter 75000, loss: 3.502105
 >> iter 76000, loss: 3.350465
 >> iter 77000, loss: 3.201951
 >> iter 78000, loss: 3.142546
 >> iter 79000, loss: 3.138821
 >> iter 80000, loss: 3.151667
   Number of active neurons: 10
 >> iter 81000, loss: 3.097866
 >> iter 82000, loss: 3.038520
 >> iter 83000, loss: 2.978879
 >> iter 84000, loss: 3.277202
 >> iter 85000, loss: 1.437470
 >> iter 86000, loss: 0.755447
 >> iter 87000, loss: 0.407455
 >> iter 88000, loss: 0.208408
 >> iter 89000, loss: 0.181863
 >> iter 90000, loss: 0.125728
   Number of active neurons: 10
 >> iter 91000, loss: 0.119634
 >> iter 92000, loss: 0.150932
 >> iter 93000, loss: 0.288960
 >> iter 94000, loss: 0.119312
 >> iter 95000, loss: 0.059753
 >> iter 96000, loss: 0.066103
 >> iter 97000, loss: 0.037423
 >> iter 98000, loss: 0.110860
 >> iter 99000, loss: 0.053471
 >> iter 100000, loss: 0.030236
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 16.704262
 >> iter 2000, loss: 11.234487
 >> iter 3000, loss: 9.068818
 >> iter 4000, loss: 8.175463
 >> iter 5000, loss: 7.824895
 >> iter 6000, loss: 7.656769
 >> iter 7000, loss: 7.603758
 >> iter 8000, loss: 7.569415
 >> iter 9000, loss: 7.583529
 >> iter 10000, loss: 7.555068
   Number of active neurons: 10
 >> iter 11000, loss: 7.552342
 >> iter 12000, loss: 7.537374
 >> iter 13000, loss: 7.544297
 >> iter 14000, loss: 7.528950
 >> iter 15000, loss: 7.551231
 >> iter 16000, loss: 7.534755
 >> iter 17000, loss: 7.538982
 >> iter 18000, loss: 7.526504
 >> iter 19000, loss: 7.537174
 >> iter 20000, loss: 7.526208
   Number of active neurons: 10
 >> iter 21000, loss: 7.552196
 >> iter 22000, loss: 7.530921
 >> iter 23000, loss: 7.574727
 >> iter 24000, loss: 7.534619
 >> iter 25000, loss: 7.534342
 >> iter 26000, loss: 7.520916
 >> iter 27000, loss: 7.567629
 >> iter 28000, loss: 7.534626
 >> iter 29000, loss: 7.538234
 >> iter 30000, loss: 7.525285
   Number of active neurons: 10
 >> iter 31000, loss: 7.532819
 >> iter 32000, loss: 7.525779
 >> iter 33000, loss: 7.532520
 >> iter 34000, loss: 7.529125
 >> iter 35000, loss: 7.539035
 >> iter 36000, loss: 7.524035
 >> iter 37000, loss: 7.528712
 >> iter 38000, loss: 7.523264
 >> iter 39000, loss: 7.535852
 >> iter 40000, loss: 7.523504
   Number of active neurons: 10
 >> iter 41000, loss: 7.536231
 >> iter 42000, loss: 7.518135
 >> iter 43000, loss: 7.528741
 >> iter 44000, loss: 7.517266
 >> iter 45000, loss: 7.527710
 >> iter 46000, loss: 7.520540
 >> iter 47000, loss: 7.533811
 >> iter 48000, loss: 7.516408
 >> iter 49000, loss: 7.534007
 >> iter 50000, loss: 7.516435
   Number of active neurons: 10
 >> iter 51000, loss: 7.533313
 >> iter 52000, loss: 7.515921
 >> iter 53000, loss: 7.530916
 >> iter 54000, loss: 7.517992
 >> iter 55000, loss: 7.529449
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 56000, loss: 7.514920
 >> iter 57000, loss: 7.529141
 >> iter 58000, loss: 7.511534
 >> iter 59000, loss: 7.519666
 >> iter 60000, loss: 7.503147
   Number of active neurons: 10
 >> iter 61000, loss: 7.509280
 >> iter 62000, loss: 7.501306
 >> iter 63000, loss: 7.467598
 >> iter 64000, loss: 7.387363
 >> iter 65000, loss: 7.292643
 >> iter 66000, loss: 7.134440
 >> iter 67000, loss: 6.981914
 >> iter 68000, loss: 6.781472
 >> iter 69000, loss: 6.606372
 >> iter 70000, loss: 6.496764
   Number of active neurons: 10
 >> iter 71000, loss: 6.425707
 >> iter 72000, loss: 6.368723
 >> iter 73000, loss: 6.334430
 >> iter 74000, loss: 6.266482
 >> iter 75000, loss: 6.253875
 >> iter 76000, loss: 6.199612
 >> iter 77000, loss: 6.188260
 >> iter 78000, loss: 6.159709
 >> iter 79000, loss: 6.230852
 >> iter 80000, loss: 6.153499
   Number of active neurons: 10
 >> iter 81000, loss: 6.129677
 >> iter 82000, loss: 6.103538
 >> iter 83000, loss: 6.117141
 >> iter 84000, loss: 6.089312
 >> iter 85000, loss: 6.070471
 >> iter 86000, loss: 5.959765
 >> iter 87000, loss: 5.732107
 >> iter 88000, loss: 5.581335
 >> iter 89000, loss: 5.453494
 >> iter 90000, loss: 5.163684
   Number of active neurons: 10
 >> iter 91000, loss: 4.922022
 >> iter 92000, loss: 4.983329
 >> iter 93000, loss: 4.840764
 >> iter 94000, loss: 4.653763
 >> iter 95000, loss: 3.391229
 >> iter 96000, loss: 1.828997
 >> iter 97000, loss: 1.033440
 >> iter 98000, loss: 0.596438
 >> iter 99000, loss: 0.485486
 >> iter 100000, loss: 0.553870
   Number of active neurons: 10
 >> iter 101000, loss: 0.510080
 >> iter 102000, loss: 0.346043
 >> iter 103000, loss: 0.278604
 >> iter 104000, loss: 0.257104
 >> iter 105000, loss: 0.233909
 >> iter 106000, loss: 0.157234
 >> iter 107000, loss: 0.180041
 >> iter 108000, loss: 0.156467
 >> iter 109000, loss: 0.106901
 >> iter 110000, loss: 0.255549
   Number of active neurons: 10
 >> iter 111000, loss: 0.135226
 >> iter 112000, loss: 0.135163
 >> iter 113000, loss: 0.177185
 >> iter 114000, loss: 0.145179
 >> iter 115000, loss: 0.141617
 >> iter 116000, loss: 0.106369
 >> iter 117000, loss: 0.092656
 >> iter 118000, loss: 0.147479
 >> iter 119000, loss: 0.099187
 >> iter 120000, loss: 0.109707
   Number of active neurons: 10
 >> iter 121000, loss: 0.089847
 >> iter 122000, loss: 0.064798
 >> iter 123000, loss: 0.107127
 >> iter 124000, loss: 0.185982
 >> iter 125000, loss: 0.130433
 >> iter 126000, loss: 0.088993
 >> iter 127000, loss: 0.047022
 >> iter 128000, loss: 0.121221
 >> iter 129000, loss: 0.121636
 >> iter 130000, loss: 0.122972
   Number of active neurons: 10
 >> iter 131000, loss: 0.151368
 >> iter 132000, loss: 0.132833
 >> iter 133000, loss: 0.072278
 >> iter 134000, loss: 0.126958
 >> iter 135000, loss: 0.063935
 >> iter 136000, loss: 0.035199
 >> iter 137000, loss: 0.101739
 >> iter 138000, loss: 0.045510
 >> iter 139000, loss: 0.024819
 >> iter 140000, loss: 0.016668
   Number of active neurons: 10
 >> iter 141000, loss: 0.014241
 >> iter 142000, loss: 0.037371
 >> iter 143000, loss: 0.020100
 >> iter 144000, loss: 0.018766
 >> iter 145000, loss: 0.037069
 >> iter 146000, loss: 0.076638
 >> iter 147000, loss: 0.034171
 >> iter 148000, loss: 0.021324
 >> iter 149000, loss: 0.013002
 >> iter 150000, loss: 0.029394
   Number of active neurons: 10
 >> iter 151000, loss: 0.028515
 >> iter 152000, loss: 0.017737
 >> iter 153000, loss: 0.060202
 >> iter 154000, loss: 0.027353
 >> iter 155000, loss: 0.068753
 >> iter 156000, loss: 0.030131
 >> iter 157000, loss: 0.059306
 >> iter 158000, loss: 0.026888
 >> iter 159000, loss: 0.016053
 >> iter 160000, loss: 0.010613
   Number of active neurons: 10
 >> iter 161000, loss: 0.008116
 >> iter 162000, loss: 0.053206
 >> iter 163000, loss: 0.024037
 >> iter 164000, loss: 0.024829
 >> iter 165000, loss: 0.013725
 >> iter 166000, loss: 0.012577
 >> iter 167000, loss: 0.008494
 >> iter 168000, loss: 0.018556
 >> iter 169000, loss: 0.120226
 >> iter 170000, loss: 0.051933
   Number of active neurons: 10
 >> iter 171000, loss: 0.023250
 >> iter 172000, loss: 0.012749
 >> iter 173000, loss: 0.037776
 >> iter 174000, loss: 0.018256
 >> iter 175000, loss: 0.011285
 >> iter 176000, loss: 0.008530
 >> iter 177000, loss: 0.010349
 >> iter 178000, loss: 0.101326
 >> iter 179000, loss: 0.052938
 >> iter 180000, loss: 0.044680
   Number of active neurons: 10
 >> iter 181000, loss: 0.024573
 >> iter 182000, loss: 0.033569
 >> iter 183000, loss: 0.016164
 >> iter 184000, loss: 0.030911
 >> iter 185000, loss: 0.015812
 >> iter 186000, loss: 0.057332
 >> iter 187000, loss: 0.050791
 >> iter 188000, loss: 0.025794
 >> iter 189000, loss: 0.021820
 >> iter 190000, loss: 0.011549
   Number of active neurons: 10
 >> iter 191000, loss: 0.011362
 >> iter 192000, loss: 0.007873
 >> iter 193000, loss: 0.011690
 >> iter 194000, loss: 0.007384
 >> iter 195000, loss: 0.006047
 >> iter 196000, loss: 0.007979
 >> iter 197000, loss: 0.005762
 >> iter 198000, loss: 0.018949
 >> iter 199000, loss: 0.076469
 >> iter 200000, loss: 0.042453
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.510606
 >> iter 2000, loss: 11.099878
 >> iter 3000, loss: 8.974938
 >> iter 4000, loss: 8.276035
 >> iter 5000, loss: 7.944130
 >> iter 6000, loss: 7.728783
 >> iter 7000, loss: 7.673801
 >> iter 8000, loss: 7.638101
 >> iter 9000, loss: 7.689881
 >> iter 10000, loss: 7.609764
   Number of active neurons: 9
 >> iter 11000, loss: 7.611910
 >> iter 12000, loss: 7.597562
 >> iter 13000, loss: 7.589948
 >> iter 14000, loss: 7.565853
 >> iter 15000, loss: 7.583124
 >> iter 16000, loss: 7.569850
 >> iter 17000, loss: 7.573862
 >> iter 18000, loss: 7.561300
 >> iter 19000, loss: 7.567803
 >> iter 20000, loss: 7.554630
   Number of active neurons: 10
 >> iter 21000, loss: 7.568070
 >> iter 22000, loss: 7.577683
 >> iter 23000, loss: 7.623613
 >> iter 24000, loss: 7.583996
 >> iter 25000, loss: 7.577260
 >> iter 26000, loss: 7.562667
 >> iter 27000, loss: 7.564916
 >> iter 28000, loss: 7.567001
 >> iter 29000, loss: 7.583476
 >> iter 30000, loss: 7.571126
   Number of active neurons: 10
 >> iter 31000, loss: 7.621349
 >> iter 32000, loss: 7.582524
 >> iter 33000, loss: 7.575099
 >> iter 34000, loss: 7.571482
 >> iter 35000, loss: 7.578490
 >> iter 36000, loss: 7.568811
 >> iter 37000, loss: 7.597925
 >> iter 38000, loss: 7.558799
 >> iter 39000, loss: 7.570231
 >> iter 40000, loss: 7.535834
   Number of active neurons: 10
 >> iter 41000, loss: 7.505817
 >> iter 42000, loss: 7.491751
 >> iter 43000, loss: 7.330778
 >> iter 44000, loss: 7.162695
 >> iter 45000, loss: 7.042440
 >> iter 46000, loss: 6.895472
 >> iter 47000, loss: 6.819172
 >> iter 48000, loss: 6.783580
 >> iter 49000, loss: 6.747563
 >> iter 50000, loss: 6.699004
   Number of active neurons: 10
 >> iter 51000, loss: 6.686386
 >> iter 52000, loss: 6.687857
 >> iter 53000, loss: 6.672343
 >> iter 54000, loss: 6.654345
 >> iter 55000, loss: 6.641973
 >> iter 56000, loss: 6.613877
 >> iter 57000, loss: 6.628034
 >> iter 58000, loss: 6.513959
 >> iter 59000, loss: 6.376305
 >> iter 60000, loss: 6.175278
   Number of active neurons: 10
 >> iter 61000, loss: 6.093769
 >> iter 62000, loss: 5.987900
 >> iter 63000, loss: 5.970749
 >> iter 64000, loss: 5.880741
 >> iter 65000, loss: 5.788884
 >> iter 66000, loss: 5.765401
 >> iter 67000, loss: 5.726307
 >> iter 68000, loss: 5.746720
 >> iter 69000, loss: 5.702943
 >> iter 70000, loss: 5.694152
   Number of active neurons: 10
 >> iter 71000, loss: 5.670084
 >> iter 72000, loss: 5.682749
 >> iter 73000, loss: 5.690966
 >> iter 74000, loss: 5.700863
 >> iter 75000, loss: 5.661665
 >> iter 76000, loss: 5.669671
 >> iter 77000, loss: 5.636041
 >> iter 78000, loss: 5.649951
 >> iter 79000, loss: 5.664771
 >> iter 80000, loss: 5.643485
   Number of active neurons: 10
 >> iter 81000, loss: 5.607904
 >> iter 82000, loss: 5.630718
 >> iter 83000, loss: 5.580346
 >> iter 84000, loss: 5.647340
 >> iter 85000, loss: 5.591107
 >> iter 86000, loss: 5.617834
 >> iter 87000, loss: 5.575915
 >> iter 88000, loss: 5.602933
 >> iter 89000, loss: 5.575902
 >> iter 90000, loss: 5.590897
   Number of active neurons: 10
 >> iter 91000, loss: 5.606756
 >> iter 92000, loss: 5.587000
 >> iter 93000, loss: 5.585755
 >> iter 94000, loss: 5.484718
 >> iter 95000, loss: 5.314229
 >> iter 96000, loss: 5.241332
 >> iter 97000, loss: 5.159158
 >> iter 98000, loss: 5.193409
 >> iter 99000, loss: 5.043924
 >> iter 100000, loss: 4.950339
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 13.0537389252
   - Test - Long: 23.3288335583
   - Test - Big: 12.8318716813
   - Test - A: 15.5122991801
   - Test - B: 10.8392773815
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.387040
 >> iter 2000, loss: 11.020189
 >> iter 3000, loss: 8.921392
 >> iter 4000, loss: 8.099596
 >> iter 5000, loss: 7.839508
 >> iter 6000, loss: 7.750677
 >> iter 7000, loss: 7.719076
 >> iter 8000, loss: 7.636808
 >> iter 9000, loss: 7.664950
 >> iter 10000, loss: 7.631547
   Number of active neurons: 9
 >> iter 11000, loss: 7.615865
 >> iter 12000, loss: 7.598212
 >> iter 13000, loss: 7.585992
 >> iter 14000, loss: 7.601209
 >> iter 15000, loss: 7.586703
 >> iter 16000, loss: 7.565736
 >> iter 17000, loss: 7.587232
 >> iter 18000, loss: 7.582757
 >> iter 19000, loss: 7.613548
 >> iter 20000, loss: 7.575535
   Number of active neurons: 9
 >> iter 21000, loss: 7.600560
 >> iter 22000, loss: 7.564143
 >> iter 23000, loss: 7.560064
 >> iter 24000, loss: 7.561881
 >> iter 25000, loss: 7.562270
 >> iter 26000, loss: 7.603715
 >> iter 27000, loss: 7.585691
 >> iter 28000, loss: 7.560115
 >> iter 29000, loss: 7.609665
 >> iter 30000, loss: 7.565624
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 31000, loss: 7.560642
 >> iter 32000, loss: 7.551280
 >> iter 33000, loss: 7.556100
 >> iter 34000, loss: 7.549664
 >> iter 35000, loss: 7.566094
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 36000, loss: 7.551842
 >> iter 37000, loss: 7.553084
 >> iter 38000, loss: 7.545257
 >> iter 39000, loss: 7.552551
 >> iter 40000, loss: 7.565465
   Number of active neurons: 9
 >> iter 41000, loss: 7.563659
 >> iter 42000, loss: 7.542754
 >> iter 43000, loss: 7.555914
 >> iter 44000, loss: 7.544854
 >> iter 45000, loss: 7.555744
 >> iter 46000, loss: 7.539950
 >> iter 47000, loss: 7.552995
 >> iter 48000, loss: 7.537415
 >> iter 49000, loss: 7.551814
 >> iter 50000, loss: 7.538480
   Number of active neurons: 9
 >> iter 51000, loss: 7.553570
 >> iter 52000, loss: 7.537737
 >> iter 53000, loss: 7.550266
 >> iter 54000, loss: 7.536992
 >> iter 55000, loss: 7.551683
   Number of active neurons: 9
   SHOCK
   Setting new limit to 275000.0 iters...
 >> iter 56000, loss: 7.539364
 >> iter 57000, loss: 7.544870
 >> iter 58000, loss: 7.539319
 >> iter 59000, loss: 7.550023
 >> iter 60000, loss: 7.540826
   Number of active neurons: 10
 >> iter 61000, loss: 7.553380
 >> iter 62000, loss: 7.538157
 >> iter 63000, loss: 7.551478
 >> iter 64000, loss: 7.535636
 >> iter 65000, loss: 7.545925
 >> iter 66000, loss: 7.539501
 >> iter 67000, loss: 7.549757
 >> iter 68000, loss: 7.543998
 >> iter 69000, loss: 7.552300
 >> iter 70000, loss: 7.541823
   Number of active neurons: 9
 >> iter 71000, loss: 7.552243
 >> iter 72000, loss: 7.541012
 >> iter 73000, loss: 7.548097
 >> iter 74000, loss: 7.541664
 >> iter 75000, loss: 7.553540
   Number of active neurons: 9
   SHOCK
   Setting new limit to 287500.0 iters...
 >> iter 76000, loss: 7.545545
 >> iter 77000, loss: 7.553022
 >> iter 78000, loss: 7.545977
 >> iter 79000, loss: 7.550855
 >> iter 80000, loss: 7.563533
   Number of active neurons: 9
   SHOCK
   Setting new limit to 293750.0 iters...
   Number of active neurons: 9
 >> iter 81000, loss: 7.554715
 >> iter 82000, loss: 7.607650
 >> iter 83000, loss: 7.573694
 >> iter 84000, loss: 7.550365
 >> iter 85000, loss: 7.554725
 >> iter 86000, loss: 7.550951
 >> iter 87000, loss: 7.550904
 >> iter 88000, loss: 7.546402
 >> iter 89000, loss: 7.547086
 >> iter 90000, loss: 7.547844
   Number of active neurons: 10
 >> iter 91000, loss: 7.550190
 >> iter 92000, loss: 7.552207
 >> iter 93000, loss: 7.542818
 >> iter 94000, loss: 7.546429
 >> iter 95000, loss: 7.540517
 >> iter 96000, loss: 7.547931
 >> iter 97000, loss: 7.546682
 >> iter 98000, loss: 7.545017
 >> iter 99000, loss: 7.545916
 >> iter 100000, loss: 7.541675
   Number of active neurons: 10
 >> iter 101000, loss: 7.544175
 >> iter 102000, loss: 7.551386
 >> iter 103000, loss: 7.548547
 >> iter 104000, loss: 7.585263
 >> iter 105000, loss: 7.558938
 >> iter 106000, loss: 7.556286
 >> iter 107000, loss: 7.570534
 >> iter 108000, loss: 7.561788
 >> iter 109000, loss: 7.578456
 >> iter 110000, loss: 7.521442
   Number of active neurons: 10
 >> iter 111000, loss: 7.535348
 >> iter 112000, loss: 7.470696
 >> iter 113000, loss: 7.398577
 >> iter 114000, loss: 7.279830
 >> iter 115000, loss: 7.163127
 >> iter 116000, loss: 7.115579
 >> iter 117000, loss: 7.017457
 >> iter 118000, loss: 6.951380
 >> iter 119000, loss: 6.898756
 >> iter 120000, loss: 6.860064
   Number of active neurons: 10
 >> iter 121000, loss: 6.828867
 >> iter 122000, loss: 6.767799
 >> iter 123000, loss: 6.669190
 >> iter 124000, loss: 6.449026
 >> iter 125000, loss: 6.258978
 >> iter 126000, loss: 6.126879
 >> iter 127000, loss: 6.064775
 >> iter 128000, loss: 6.042494
 >> iter 129000, loss: 5.939366
 >> iter 130000, loss: 5.863413
   Number of active neurons: 10
 >> iter 131000, loss: 5.831140
 >> iter 132000, loss: 5.752609
 >> iter 133000, loss: 5.726869
 >> iter 134000, loss: 5.669747
 >> iter 135000, loss: 5.664930
 >> iter 136000, loss: 5.659764
 >> iter 137000, loss: 5.557911
 >> iter 138000, loss: 5.541688
 >> iter 139000, loss: 5.492337
 >> iter 140000, loss: 5.481862
   Number of active neurons: 10
 >> iter 141000, loss: 5.441881
 >> iter 142000, loss: 5.556840
 >> iter 143000, loss: 5.393345
 >> iter 144000, loss: 5.355647
 >> iter 145000, loss: 5.271351
 >> iter 146000, loss: 5.178129
 >> iter 147000, loss: 5.093350
 >> iter 148000, loss: 5.021707
 >> iter 149000, loss: 4.995795
 >> iter 150000, loss: 4.962405
   Number of active neurons: 10
 >> iter 151000, loss: 4.872249
 >> iter 152000, loss: 4.890805
 >> iter 153000, loss: 4.878158
 >> iter 154000, loss: 4.924217
 >> iter 155000, loss: 4.869059
 >> iter 156000, loss: 4.841969
 >> iter 157000, loss: 4.836557
 >> iter 158000, loss: 4.683650
 >> iter 159000, loss: 4.518474
 >> iter 160000, loss: 4.511150
   Number of active neurons: 10
 >> iter 161000, loss: 4.295569
 >> iter 162000, loss: 4.130509
 >> iter 163000, loss: 4.033357
 >> iter 164000, loss: 3.975355
 >> iter 165000, loss: 3.972895
 >> iter 166000, loss: 3.902005
 >> iter 167000, loss: 3.980591
 >> iter 168000, loss: 3.893337
 >> iter 169000, loss: 3.813273
 >> iter 170000, loss: 3.821562
   Number of active neurons: 10
 >> iter 171000, loss: 2.955498
 >> iter 172000, loss: 1.760226
 >> iter 173000, loss: 1.129888
 >> iter 174000, loss: 0.980297
 >> iter 175000, loss: 0.966731
 >> iter 176000, loss: 0.578057
 >> iter 177000, loss: 0.494285
 >> iter 178000, loss: 0.442173
 >> iter 179000, loss: 0.396306
 >> iter 180000, loss: 0.318639
   Number of active neurons: 10
 >> iter 181000, loss: 0.406809
 >> iter 182000, loss: 0.435388
 >> iter 183000, loss: 0.443731
 >> iter 184000, loss: 0.231114
 >> iter 185000, loss: 0.177512
 >> iter 186000, loss: 0.118002
 >> iter 187000, loss: 0.200720
 >> iter 188000, loss: 0.299495
 >> iter 189000, loss: 0.316746
 >> iter 190000, loss: 0.287451
   Number of active neurons: 10
 >> iter 191000, loss: 0.296908
 >> iter 192000, loss: 0.200789
 >> iter 193000, loss: 0.207386
 >> iter 194000, loss: 0.149089
 >> iter 195000, loss: 0.152634
 >> iter 196000, loss: 0.167025
 >> iter 197000, loss: 0.193103
 >> iter 198000, loss: 0.160128
 >> iter 199000, loss: 0.135484
 >> iter 200000, loss: 0.098344
   Number of active neurons: 10
 >> iter 201000, loss: 0.133944
 >> iter 202000, loss: 0.221624
 >> iter 203000, loss: 0.179590
 >> iter 204000, loss: 0.238350
 >> iter 205000, loss: 0.226024
 >> iter 206000, loss: 0.110931
 >> iter 207000, loss: 0.075466
 >> iter 208000, loss: 0.136326
 >> iter 209000, loss: 0.168297
 >> iter 210000, loss: 0.104738
   Number of active neurons: 10
 >> iter 211000, loss: 0.065860
 >> iter 212000, loss: 0.046056
 >> iter 213000, loss: 0.072602
 >> iter 214000, loss: 0.060181
 >> iter 215000, loss: 0.057804
 >> iter 216000, loss: 0.089009
 >> iter 217000, loss: 0.158817
 >> iter 218000, loss: 0.235812
 >> iter 219000, loss: 0.237722
 >> iter 220000, loss: 0.132661
   Number of active neurons: 10
 >> iter 221000, loss: 0.121022
 >> iter 222000, loss: 0.121834
 >> iter 223000, loss: 0.081284
 >> iter 224000, loss: 0.074964
 >> iter 225000, loss: 0.140478
 >> iter 226000, loss: 0.061354
 >> iter 227000, loss: 0.120245
 >> iter 228000, loss: 0.065225
 >> iter 229000, loss: 0.050166
 >> iter 230000, loss: 0.078284
   Number of active neurons: 10
 >> iter 231000, loss: 0.099323
 >> iter 232000, loss: 0.054934
 >> iter 233000, loss: 0.028454
 >> iter 234000, loss: 0.046461
 >> iter 235000, loss: 0.065728
 >> iter 236000, loss: 0.144398
 >> iter 237000, loss: 0.066073
 >> iter 238000, loss: 0.037066
 >> iter 239000, loss: 0.021658
 >> iter 240000, loss: 0.030014
   Number of active neurons: 10
 >> iter 241000, loss: 0.020521
 >> iter 242000, loss: 0.044274
 >> iter 243000, loss: 0.027604
 >> iter 244000, loss: 0.032463
 >> iter 245000, loss: 0.090828
 >> iter 246000, loss: 0.057287
 >> iter 247000, loss: 0.108455
 >> iter 248000, loss: 0.053164
 >> iter 249000, loss: 0.120763
 >> iter 250000, loss: 0.096623
   Number of active neurons: 10
 >> iter 251000, loss: 0.045254
 >> iter 252000, loss: 0.036595
 >> iter 253000, loss: 0.021816
 >> iter 254000, loss: 0.172360
 >> iter 255000, loss: 0.098033
 >> iter 256000, loss: 0.106918
 >> iter 257000, loss: 0.050427
 >> iter 258000, loss: 0.025167
 >> iter 259000, loss: 0.041773
 >> iter 260000, loss: 0.043824
   Number of active neurons: 10
 >> iter 261000, loss: 0.023422
 >> iter 262000, loss: 0.014693
 >> iter 263000, loss: 0.035534
 >> iter 264000, loss: 0.018436
 >> iter 265000, loss: 0.024296
 >> iter 266000, loss: 0.047747
 >> iter 267000, loss: 0.027022
 >> iter 268000, loss: 0.138849
 >> iter 269000, loss: 0.093235
 >> iter 270000, loss: 0.040816
   Number of active neurons: 10
 >> iter 271000, loss: 0.056812
 >> iter 272000, loss: 0.026992
 >> iter 273000, loss: 0.051600
 >> iter 274000, loss: 0.025115
 >> iter 275000, loss: 0.015766
 >> iter 276000, loss: 0.092467
 >> iter 277000, loss: 0.049738
 >> iter 278000, loss: 0.027425
 >> iter 279000, loss: 0.014532
 >> iter 280000, loss: 0.015401
   Number of active neurons: 10
 >> iter 281000, loss: 0.046085
 >> iter 282000, loss: 0.077525
 >> iter 283000, loss: 0.062663
 >> iter 284000, loss: 0.101100
 >> iter 285000, loss: 0.101749
 >> iter 286000, loss: 0.143925
 >> iter 287000, loss: 0.170539
 >> iter 288000, loss: 0.079228
 >> iter 289000, loss: 0.040062
 >> iter 290000, loss: 0.074422
   Number of active neurons: 10
 >> iter 291000, loss: 0.036887
 >> iter 292000, loss: 0.018736
 >> iter 293000, loss: 0.066604
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.715072
 >> iter 2000, loss: 11.232198
 >> iter 3000, loss: 9.031962
 >> iter 4000, loss: 8.144201
 >> iter 5000, loss: 7.876365
 >> iter 6000, loss: 7.707397
 >> iter 7000, loss: 7.659108
 >> iter 8000, loss: 7.632460
 >> iter 9000, loss: 7.650569
 >> iter 10000, loss: 7.599517
   Number of active neurons: 10
 >> iter 11000, loss: 7.600045
 >> iter 12000, loss: 7.638430
 >> iter 13000, loss: 7.603185
 >> iter 14000, loss: 7.572388
 >> iter 15000, loss: 7.637269
 >> iter 16000, loss: 7.594875
 >> iter 17000, loss: 7.578532
 >> iter 18000, loss: 7.604484
 >> iter 19000, loss: 7.679791
 >> iter 20000, loss: 7.599932
   Number of active neurons: 10
 >> iter 21000, loss: 7.578382
 >> iter 22000, loss: 7.558933
 >> iter 23000, loss: 7.600446
 >> iter 24000, loss: 7.580469
 >> iter 25000, loss: 7.566416
 >> iter 26000, loss: 7.549578
 >> iter 27000, loss: 7.553728
 >> iter 28000, loss: 7.548491
 >> iter 29000, loss: 7.554876
 >> iter 30000, loss: 7.550666
   Number of active neurons: 10
 >> iter 31000, loss: 7.559122
 >> iter 32000, loss: 7.553824
 >> iter 33000, loss: 7.560345
 >> iter 34000, loss: 7.548297
 >> iter 35000, loss: 7.557540
 >> iter 36000, loss: 7.549685
 >> iter 37000, loss: 7.557473
 >> iter 38000, loss: 7.563748
 >> iter 39000, loss: 7.557990
 >> iter 40000, loss: 7.545235
   Number of active neurons: 10
 >> iter 41000, loss: 7.555715
 >> iter 42000, loss: 7.544012
 >> iter 43000, loss: 7.554058
 >> iter 44000, loss: 7.538787
 >> iter 45000, loss: 7.549107
 >> iter 46000, loss: 7.540038
 >> iter 47000, loss: 7.563198
 >> iter 48000, loss: 7.539649
 >> iter 49000, loss: 7.553206
 >> iter 50000, loss: 7.539300
   Number of active neurons: 10
 >> iter 51000, loss: 7.555646
 >> iter 52000, loss: 7.555363
 >> iter 53000, loss: 7.560987
 >> iter 54000, loss: 7.541620
 >> iter 55000, loss: 7.549601
 >> iter 56000, loss: 7.541360
 >> iter 57000, loss: 7.555898
 >> iter 58000, loss: 7.542217
 >> iter 59000, loss: 7.549506
 >> iter 60000, loss: 7.542693
   Number of active neurons: 10
 >> iter 61000, loss: 7.551835
 >> iter 62000, loss: 7.537221
 >> iter 63000, loss: 7.549964
 >> iter 64000, loss: 7.537438
 >> iter 65000, loss: 7.549283
 >> iter 66000, loss: 7.541257
 >> iter 67000, loss: 7.550746
 >> iter 68000, loss: 7.541196
 >> iter 69000, loss: 7.550221
 >> iter 70000, loss: 7.541393
   Number of active neurons: 10
 >> iter 71000, loss: 7.553718
 >> iter 72000, loss: 7.544588
 >> iter 73000, loss: 7.555104
 >> iter 74000, loss: 7.544628
 >> iter 75000, loss: 7.554759
 >> iter 76000, loss: 7.544003
 >> iter 77000, loss: 7.552742
 >> iter 78000, loss: 7.548241
 >> iter 79000, loss: 7.552455
 >> iter 80000, loss: 7.545655
   Number of active neurons: 10
 >> iter 81000, loss: 7.552886
 >> iter 82000, loss: 7.543519
 >> iter 83000, loss: 7.549763
 >> iter 84000, loss: 7.541327
 >> iter 85000, loss: 7.545644
 >> iter 86000, loss: 7.541590
 >> iter 87000, loss: 7.549351
 >> iter 88000, loss: 7.547209
 >> iter 89000, loss: 7.543901
 >> iter 90000, loss: 7.540279
   Number of active neurons: 10
 >> iter 91000, loss: 7.545220
 >> iter 92000, loss: 7.547022
 >> iter 93000, loss: 7.545013
 >> iter 94000, loss: 7.547551
 >> iter 95000, loss: 7.544719
 >> iter 96000, loss: 7.545708
 >> iter 97000, loss: 7.544608
 >> iter 98000, loss: 7.543895
 >> iter 99000, loss: 7.546739
 >> iter 100000, loss: 7.550855
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 21.2595748085
   - Test - Long: 24.4987750612
   - Test - Big: 21.1897881021
   - Test - A: 32.8911405906
   - Test - B: 33.404439704
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.697387
 >> iter 2000, loss: 11.170088
 >> iter 3000, loss: 8.958826
 >> iter 4000, loss: 8.110828
 >> iter 5000, loss: 7.792271
 >> iter 6000, loss: 7.752146
 >> iter 7000, loss: 7.669751
 >> iter 8000, loss: 7.616672
 >> iter 9000, loss: 7.602070
 >> iter 10000, loss: 7.586917
   Number of active neurons: 10
 >> iter 11000, loss: 7.589935
 >> iter 12000, loss: 7.583512
 >> iter 13000, loss: 7.588588
 >> iter 14000, loss: 7.577101
 >> iter 15000, loss: 7.580405
 >> iter 16000, loss: 7.577685
 >> iter 17000, loss: 7.595343
 >> iter 18000, loss: 7.577509
 >> iter 19000, loss: 7.589000
 >> iter 20000, loss: 7.569958
   Number of active neurons: 10
 >> iter 21000, loss: 7.577793
 >> iter 22000, loss: 7.565026
 >> iter 23000, loss: 7.570650
 >> iter 24000, loss: 7.563779
 >> iter 25000, loss: 7.588946
 >> iter 26000, loss: 7.572690
 >> iter 27000, loss: 7.573223
 >> iter 28000, loss: 7.561949
 >> iter 29000, loss: 7.564585
 >> iter 30000, loss: 7.555138
   Number of active neurons: 10
 >> iter 31000, loss: 7.543028
 >> iter 32000, loss: 7.479103
 >> iter 33000, loss: 7.454435
 >> iter 34000, loss: 7.322911
 >> iter 35000, loss: 7.251838
 >> iter 36000, loss: 7.181985
 >> iter 37000, loss: 7.079283
 >> iter 38000, loss: 6.931178
 >> iter 39000, loss: 6.886567
 >> iter 40000, loss: 6.746831
   Number of active neurons: 10
 >> iter 41000, loss: 6.608284
 >> iter 42000, loss: 6.337267
 >> iter 43000, loss: 6.364185
 >> iter 44000, loss: 6.226424
 >> iter 45000, loss: 6.096422
 >> iter 46000, loss: 5.984720
 >> iter 47000, loss: 5.909615
 >> iter 48000, loss: 5.924464
 >> iter 49000, loss: 5.852217
 >> iter 50000, loss: 5.825106
   Number of active neurons: 10
 >> iter 51000, loss: 5.802196
 >> iter 52000, loss: 5.738367
 >> iter 53000, loss: 5.714096
 >> iter 54000, loss: 5.689285
 >> iter 55000, loss: 5.700354
 >> iter 56000, loss: 5.671003
 >> iter 57000, loss: 5.693035
 >> iter 58000, loss: 5.545474
 >> iter 59000, loss: 5.527926
 >> iter 60000, loss: 5.479347
   Number of active neurons: 10
 >> iter 61000, loss: 5.452172
 >> iter 62000, loss: 5.396821
 >> iter 63000, loss: 5.392899
 >> iter 64000, loss: 5.378949
 >> iter 65000, loss: 5.319360
 >> iter 66000, loss: 5.292029
 >> iter 67000, loss: 5.248127
 >> iter 68000, loss: 5.216543
 >> iter 69000, loss: 5.230011
 >> iter 70000, loss: 5.200043
   Number of active neurons: 10
 >> iter 71000, loss: 5.272764
 >> iter 72000, loss: 5.258992
 >> iter 73000, loss: 5.256071
 >> iter 74000, loss: 5.394453
 >> iter 75000, loss: 5.348595
 >> iter 76000, loss: 5.280200
 >> iter 77000, loss: 5.295220
 >> iter 78000, loss: 5.220161
 >> iter 79000, loss: 5.177472
 >> iter 80000, loss: 5.157776
   Number of active neurons: 10
 >> iter 81000, loss: 5.329008
 >> iter 82000, loss: 5.162950
 >> iter 83000, loss: 5.092335
 >> iter 84000, loss: 5.065273
 >> iter 85000, loss: 5.050696
 >> iter 86000, loss: 5.066120
 >> iter 87000, loss: 5.030710
 >> iter 88000, loss: 5.021426
 >> iter 89000, loss: 5.076798
 >> iter 90000, loss: 5.026223
   Number of active neurons: 10
 >> iter 91000, loss: 4.998468
 >> iter 92000, loss: 4.930675
 >> iter 93000, loss: 4.901986
 >> iter 94000, loss: 4.906311
 >> iter 95000, loss: 4.895431
 >> iter 96000, loss: 4.875505
 >> iter 97000, loss: 4.863832
 >> iter 98000, loss: 4.876729
 >> iter 99000, loss: 4.819975
 >> iter 100000, loss: 4.746795
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 11.4877702446
   - Test - Long: 23.0088495575
   - Test - Big: 11.2068879311
   - Test - A: 16.2655822945
   - Test - B: 1.93987067529
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.686747
 >> iter 2000, loss: 11.361097
 >> iter 3000, loss: 9.076203
 >> iter 4000, loss: 8.169146
 >> iter 5000, loss: 7.875495
 >> iter 6000, loss: 7.712726
 >> iter 7000, loss: 7.655568
 >> iter 8000, loss: 7.631768
 >> iter 9000, loss: 7.596670
 >> iter 10000, loss: 7.576289
   Number of active neurons: 10
 >> iter 11000, loss: 7.743761
 >> iter 12000, loss: 7.631829
 >> iter 13000, loss: 7.597795
 >> iter 14000, loss: 7.602632
 >> iter 15000, loss: 7.579190
 >> iter 16000, loss: 7.566487
 >> iter 17000, loss: 7.572786
 >> iter 18000, loss: 7.576428
 >> iter 19000, loss: 7.611807
 >> iter 20000, loss: 7.578055
   Number of active neurons: 10
 >> iter 21000, loss: 7.573405
 >> iter 22000, loss: 7.562139
 >> iter 23000, loss: 7.567721
 >> iter 24000, loss: 7.575644
 >> iter 25000, loss: 7.608080
 >> iter 26000, loss: 7.573277
 >> iter 27000, loss: 7.570172
 >> iter 28000, loss: 7.582652
 >> iter 29000, loss: 7.573380
 >> iter 30000, loss: 7.598615
   Number of active neurons: 9
 >> iter 31000, loss: 7.584642
 >> iter 32000, loss: 7.578100
 >> iter 33000, loss: 7.601360
 >> iter 34000, loss: 7.571390
 >> iter 35000, loss: 7.570034
 >> iter 36000, loss: 7.564103
 >> iter 37000, loss: 7.569943
 >> iter 38000, loss: 7.557533
 >> iter 39000, loss: 7.562147
 >> iter 40000, loss: 7.555278
   Number of active neurons: 9
 >> iter 41000, loss: 7.566767
 >> iter 42000, loss: 7.557633
 >> iter 43000, loss: 7.568322
 >> iter 44000, loss: 7.554326
 >> iter 45000, loss: 7.600738
 >> iter 46000, loss: 7.569639
 >> iter 47000, loss: 7.570320
 >> iter 48000, loss: 7.555706
 >> iter 49000, loss: 7.567464
 >> iter 50000, loss: 7.555510
   Number of active neurons: 9
 >> iter 51000, loss: 7.566521
 >> iter 52000, loss: 7.550923
 >> iter 53000, loss: 7.560383
 >> iter 54000, loss: 7.549874
 >> iter 55000, loss: 7.577484
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 56000, loss: 7.559126
 >> iter 57000, loss: 7.569964
 >> iter 58000, loss: 7.555097
 >> iter 59000, loss: 7.565921
 >> iter 60000, loss: 7.555857
   Number of active neurons: 9
 >> iter 61000, loss: 7.562898
 >> iter 62000, loss: 7.552825
 >> iter 63000, loss: 7.563424
 >> iter 64000, loss: 7.557593
 >> iter 65000, loss: 7.565281
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 66000, loss: 7.557267
 >> iter 67000, loss: 7.568371
 >> iter 68000, loss: 7.554352
 >> iter 69000, loss: 7.563459
 >> iter 70000, loss: 7.555179
   Number of active neurons: 10
 >> iter 71000, loss: 7.563210
 >> iter 72000, loss: 7.553719
 >> iter 73000, loss: 7.561206
 >> iter 74000, loss: 7.555146
 >> iter 75000, loss: 7.559584
 >> iter 76000, loss: 7.554778
 >> iter 77000, loss: 7.561542
 >> iter 78000, loss: 7.552903
 >> iter 79000, loss: 7.561909
 >> iter 80000, loss: 7.553267
   Number of active neurons: 9
 >> iter 81000, loss: 7.560736
 >> iter 82000, loss: 7.556488
 >> iter 83000, loss: 7.561713
 >> iter 84000, loss: 7.556125
 >> iter 85000, loss: 7.559900
   Number of active neurons: 9
   SHOCK
   Setting new limit to 275000.0 iters...
 >> iter 86000, loss: 7.553598
 >> iter 87000, loss: 7.557100
 >> iter 88000, loss: 7.554561
 >> iter 89000, loss: 7.562555
 >> iter 90000, loss: 7.627714
   Number of active neurons: 10
 >> iter 91000, loss: 7.585367
 >> iter 92000, loss: 7.570718
 >> iter 93000, loss: 7.540266
 >> iter 94000, loss: 7.533860
 >> iter 95000, loss: 7.511604
 >> iter 96000, loss: 7.353684
 >> iter 97000, loss: 7.198822
 >> iter 98000, loss: 7.141385
 >> iter 99000, loss: 6.926045
 >> iter 100000, loss: 6.789159
   Number of active neurons: 10
 >> iter 101000, loss: 6.731785
 >> iter 102000, loss: 6.634180
 >> iter 103000, loss: 6.501322
 >> iter 104000, loss: 6.370876
 >> iter 105000, loss: 6.366579
 >> iter 106000, loss: 6.294324
 >> iter 107000, loss: 6.202207
 >> iter 108000, loss: 6.121462
 >> iter 109000, loss: 6.031887
 >> iter 110000, loss: 5.958483
   Number of active neurons: 10
 >> iter 111000, loss: 5.786810
 >> iter 112000, loss: 5.685977
 >> iter 113000, loss: 5.700030
 >> iter 114000, loss: 5.543579
 >> iter 115000, loss: 5.459003
 >> iter 116000, loss: 5.439881
 >> iter 117000, loss: 5.376976
 >> iter 118000, loss: 4.160494
 >> iter 119000, loss: 2.862900
 >> iter 120000, loss: 1.952191
   Number of active neurons: 10
 >> iter 121000, loss: 1.480149
 >> iter 122000, loss: 1.250368
 >> iter 123000, loss: 0.957335
 >> iter 124000, loss: 0.840028
 >> iter 125000, loss: 0.762461
 >> iter 126000, loss: 0.607609
 >> iter 127000, loss: 0.479630
 >> iter 128000, loss: 0.520911
 >> iter 129000, loss: 0.515504
 >> iter 130000, loss: 0.466818
   Number of active neurons: 10
 >> iter 131000, loss: 0.356493
 >> iter 132000, loss: 0.346564
 >> iter 133000, loss: 0.215639
 >> iter 134000, loss: 0.272162
 >> iter 135000, loss: 0.327253
 >> iter 136000, loss: 0.381272
 >> iter 137000, loss: 0.390666
 >> iter 138000, loss: 0.342770
 >> iter 139000, loss: 0.225541
 >> iter 140000, loss: 0.177226
   Number of active neurons: 10
 >> iter 141000, loss: 0.260083
 >> iter 142000, loss: 0.255936
 >> iter 143000, loss: 0.216385
 >> iter 144000, loss: 0.169340
 >> iter 145000, loss: 0.287888
 >> iter 146000, loss: 0.254066
 >> iter 147000, loss: 0.309122
 >> iter 148000, loss: 0.245206
 >> iter 149000, loss: 0.267828
 >> iter 150000, loss: 0.280607
   Number of active neurons: 10
 >> iter 151000, loss: 0.290189
 >> iter 152000, loss: 0.313185
 >> iter 153000, loss: 0.270134
 >> iter 154000, loss: 0.224838
 >> iter 155000, loss: 0.338909
 >> iter 156000, loss: 0.266153
 >> iter 157000, loss: 0.227333
 >> iter 158000, loss: 0.246752
 >> iter 159000, loss: 0.130726
 >> iter 160000, loss: 0.203286
   Number of active neurons: 10
 >> iter 161000, loss: 0.219965
 >> iter 162000, loss: 0.232070
 >> iter 163000, loss: 0.285439
 >> iter 164000, loss: 0.249166
 >> iter 165000, loss: 0.222911
 >> iter 166000, loss: 0.198332
 >> iter 167000, loss: 0.193454
 >> iter 168000, loss: 0.224092
 >> iter 169000, loss: 0.251471
 >> iter 170000, loss: 0.212182
   Number of active neurons: 10
 >> iter 171000, loss: 0.161153
 >> iter 172000, loss: 0.156503
 >> iter 173000, loss: 0.211546
 >> iter 174000, loss: 0.240782
 >> iter 175000, loss: 0.169385
 >> iter 176000, loss: 0.173842
 >> iter 177000, loss: 0.168020
 >> iter 178000, loss: 0.190758
 >> iter 179000, loss: 0.123195
 >> iter 180000, loss: 0.078808
   Number of active neurons: 10
 >> iter 181000, loss: 0.207834
 >> iter 182000, loss: 0.130074
 >> iter 183000, loss: 0.133790
 >> iter 184000, loss: 0.080456
 >> iter 185000, loss: 0.082206
 >> iter 186000, loss: 0.087830
 >> iter 187000, loss: 0.174299
 >> iter 188000, loss: 0.139266
 >> iter 189000, loss: 0.138730
 >> iter 190000, loss: 0.076075
   Number of active neurons: 10
 >> iter 191000, loss: 0.144623
 >> iter 192000, loss: 0.186875
 >> iter 193000, loss: 0.226590
 >> iter 194000, loss: 0.171547
 >> iter 195000, loss: 0.134189
 >> iter 196000, loss: 0.157203
 >> iter 197000, loss: 0.092258
 >> iter 198000, loss: 0.143305
 >> iter 199000, loss: 0.078190
 >> iter 200000, loss: 0.099009
   Number of active neurons: 10
 >> iter 201000, loss: 0.081678
 >> iter 202000, loss: 0.106310
 >> iter 203000, loss: 0.146747
 >> iter 204000, loss: 0.152515
 >> iter 205000, loss: 0.127141
 >> iter 206000, loss: 0.149331
 >> iter 207000, loss: 0.234244
 >> iter 208000, loss: 0.118492
 >> iter 209000, loss: 0.074356
 >> iter 210000, loss: 0.211432
   Number of active neurons: 10
 >> iter 211000, loss: 0.118642
 >> iter 212000, loss: 0.138122
 >> iter 213000, loss: 0.079391
 >> iter 214000, loss: 0.127278
 >> iter 215000, loss: 0.057029
 >> iter 216000, loss: 0.135212
 >> iter 217000, loss: 0.168953
 >> iter 218000, loss: 0.076885
 >> iter 219000, loss: 0.050659
 >> iter 220000, loss: 0.058807
   Number of active neurons: 10
 >> iter 221000, loss: 0.077793
 >> iter 222000, loss: 0.126589
 >> iter 223000, loss: 0.089323
 >> iter 224000, loss: 0.099882
 >> iter 225000, loss: 0.086082
 >> iter 226000, loss: 0.043262
 >> iter 227000, loss: 0.163574
 >> iter 228000, loss: 0.116315
 >> iter 229000, loss: 0.080068
 >> iter 230000, loss: 0.052883
   Number of active neurons: 10
 >> iter 231000, loss: 0.034110
 >> iter 232000, loss: 0.020107
 >> iter 233000, loss: 0.050900
 >> iter 234000, loss: 0.045019
 >> iter 235000, loss: 0.069673
 >> iter 236000, loss: 0.082298
 >> iter 237000, loss: 0.052518
 >> iter 238000, loss: 0.059233
 >> iter 239000, loss: 0.060247
 >> iter 240000, loss: 0.089466
   Number of active neurons: 10
 >> iter 241000, loss: 0.126176
 >> iter 242000, loss: 0.168618
 >> iter 243000, loss: 0.177351
 >> iter 244000, loss: 0.120441
 >> iter 245000, loss: 0.062221
 >> iter 246000, loss: 0.047931
 >> iter 247000, loss: 0.053606
 >> iter 248000, loss: 0.039422
 >> iter 249000, loss: 0.073703
 >> iter 250000, loss: 0.034115
   Number of active neurons: 10
 >> iter 251000, loss: 0.038602
 >> iter 252000, loss: 0.095117
 >> iter 253000, loss: 0.042224
 >> iter 254000, loss: 0.022047
 >> iter 255000, loss: 0.018653
 >> iter 256000, loss: 0.068526
 >> iter 257000, loss: 0.038680
 >> iter 258000, loss: 0.053045
 >> iter 259000, loss: 0.100943
 >> iter 260000, loss: 0.049139
   Number of active neurons: 10
 >> iter 261000, loss: 0.109303
 >> iter 262000, loss: 0.104606
 >> iter 263000, loss: 0.044491
 >> iter 264000, loss: 0.171609
 >> iter 265000, loss: 0.086449
 >> iter 266000, loss: 0.038344
 >> iter 267000, loss: 0.020418
 >> iter 268000, loss: 0.179957
 >> iter 269000, loss: 0.111050
 >> iter 270000, loss: 0.087083
   Number of active neurons: 10
 >> iter 271000, loss: 0.057840
 >> iter 272000, loss: 0.092709
 >> iter 273000, loss: 0.061455
 >> iter 274000, loss: 0.042492
 >> iter 275000, loss: 0.056669
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 16.606555
 >> iter 2000, loss: 11.197638
 >> iter 3000, loss: 9.022039
 >> iter 4000, loss: 8.188272
 >> iter 5000, loss: 7.831510
 >> iter 6000, loss: 7.663852
 >> iter 7000, loss: 7.614766
 >> iter 8000, loss: 7.596737
 >> iter 9000, loss: 7.641505
 >> iter 10000, loss: 7.584868
   Number of active neurons: 10
 >> iter 11000, loss: 7.569995
 >> iter 12000, loss: 7.561423
 >> iter 13000, loss: 7.595007
 >> iter 14000, loss: 7.555176
 >> iter 15000, loss: 7.589313
 >> iter 16000, loss: 7.559366
 >> iter 17000, loss: 7.560096
 >> iter 18000, loss: 7.571480
 >> iter 19000, loss: 7.562441
 >> iter 20000, loss: 7.563596
   Number of active neurons: 10
 >> iter 21000, loss: 7.554258
 >> iter 22000, loss: 7.537785
 >> iter 23000, loss: 7.542310
 >> iter 24000, loss: 7.537498
 >> iter 25000, loss: 7.544840
 >> iter 26000, loss: 7.534075
 >> iter 27000, loss: 7.542005
 >> iter 28000, loss: 7.527983
 >> iter 29000, loss: 7.537124
 >> iter 30000, loss: 7.526057
   Number of active neurons: 10
 >> iter 31000, loss: 7.535234
 >> iter 32000, loss: 7.573914
 >> iter 33000, loss: 7.556172
 >> iter 34000, loss: 7.541012
 >> iter 35000, loss: 7.548814
 >> iter 36000, loss: 7.533112
 >> iter 37000, loss: 7.539164
 >> iter 38000, loss: 7.530285
 >> iter 39000, loss: 7.538495
 >> iter 40000, loss: 7.527714
   Number of active neurons: 10
 >> iter 41000, loss: 7.539105
 >> iter 42000, loss: 7.527004
 >> iter 43000, loss: 7.534581
 >> iter 44000, loss: 7.520874
 >> iter 45000, loss: 7.556544
 >> iter 46000, loss: 7.536536
 >> iter 47000, loss: 7.543608
 >> iter 48000, loss: 7.527298
 >> iter 49000, loss: 7.540904
 >> iter 50000, loss: 7.517943
   Number of active neurons: 10
 >> iter 51000, loss: 7.537466
 >> iter 52000, loss: 7.524274
 >> iter 53000, loss: 7.534440
 >> iter 54000, loss: 7.520326
 >> iter 55000, loss: 7.532532
 >> iter 56000, loss: 7.517539
 >> iter 57000, loss: 7.532109
 >> iter 58000, loss: 7.520567
 >> iter 59000, loss: 7.532876
 >> iter 60000, loss: 7.521142
   Number of active neurons: 10
 >> iter 61000, loss: 7.535325
 >> iter 62000, loss: 7.523742
 >> iter 63000, loss: 7.535509
 >> iter 64000, loss: 7.522942
 >> iter 65000, loss: 7.534287
 >> iter 66000, loss: 7.525820
 >> iter 67000, loss: 7.535631
 >> iter 68000, loss: 7.521908
 >> iter 69000, loss: 7.541560
 >> iter 70000, loss: 7.525120
   Number of active neurons: 9
 >> iter 71000, loss: 7.537165
 >> iter 72000, loss: 7.527107
 >> iter 73000, loss: 7.534969
 >> iter 74000, loss: 7.527652
 >> iter 75000, loss: 7.535228
 >> iter 76000, loss: 7.525085
 >> iter 77000, loss: 7.524278
 >> iter 78000, loss: 7.522401
 >> iter 79000, loss: 7.532739
 >> iter 80000, loss: 7.525372
   Number of active neurons: 10
 >> iter 81000, loss: 7.528821
 >> iter 82000, loss: 7.523091
 >> iter 83000, loss: 7.530409
 >> iter 84000, loss: 7.523422
 >> iter 85000, loss: 7.529056
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 86000, loss: 7.525022
 >> iter 87000, loss: 7.525195
 >> iter 88000, loss: 7.523919
 >> iter 89000, loss: 7.524521
 >> iter 90000, loss: 7.523271
   Number of active neurons: 9
 >> iter 91000, loss: 7.521283
 >> iter 92000, loss: 7.519891
 >> iter 93000, loss: 7.522571
 >> iter 94000, loss: 7.522375
 >> iter 95000, loss: 7.523032
 >> iter 96000, loss: 7.522837
 >> iter 97000, loss: 7.523338
 >> iter 98000, loss: 7.521744
 >> iter 99000, loss: 7.525854
 >> iter 100000, loss: 7.524709
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 9
 >> iter 101000, loss: 7.522929
 >> iter 102000, loss: 7.526320
 >> iter 103000, loss: 7.525039
 >> iter 104000, loss: 7.524159
 >> iter 105000, loss: 7.511609
 >> iter 106000, loss: 7.539894
 >> iter 107000, loss: 7.520517
 >> iter 108000, loss: 7.489870
 >> iter 109000, loss: 7.473103
 >> iter 110000, loss: 7.415369
   Number of active neurons: 10
 >> iter 111000, loss: 7.317975
 >> iter 112000, loss: 7.187558
 >> iter 113000, loss: 7.042354
 >> iter 114000, loss: 6.917498
 >> iter 115000, loss: 6.763340
 >> iter 116000, loss: 6.658416
 >> iter 117000, loss: 6.632970
 >> iter 118000, loss: 6.450506
 >> iter 119000, loss: 6.394610
 >> iter 120000, loss: 6.346147
   Number of active neurons: 10
 >> iter 121000, loss: 6.292640
 >> iter 122000, loss: 6.254882
 >> iter 123000, loss: 6.306441
 >> iter 124000, loss: 6.283069
 >> iter 125000, loss: 6.249238
 >> iter 126000, loss: 6.264161
 >> iter 127000, loss: 6.229749
 >> iter 128000, loss: 6.269817
 >> iter 129000, loss: 6.233892
 >> iter 130000, loss: 6.205985
   Number of active neurons: 10
 >> iter 131000, loss: 6.204531
 >> iter 132000, loss: 6.194381
 >> iter 133000, loss: 6.210956
 >> iter 134000, loss: 6.186668
 >> iter 135000, loss: 6.207043
 >> iter 136000, loss: 6.197171
 >> iter 137000, loss: 6.206086
 >> iter 138000, loss: 6.188658
 >> iter 139000, loss: 6.196054
 >> iter 140000, loss: 6.178200
   Number of active neurons: 10
 >> iter 141000, loss: 6.195823
 >> iter 142000, loss: 6.182532
 >> iter 143000, loss: 6.186816
 >> iter 144000, loss: 6.173202
 >> iter 145000, loss: 6.187288
 >> iter 146000, loss: 6.174432
 >> iter 147000, loss: 6.187512
 >> iter 148000, loss: 6.175407
 >> iter 149000, loss: 6.187509
 >> iter 150000, loss: 6.181329
   Number of active neurons: 10
 >> iter 151000, loss: 6.180730
 >> iter 152000, loss: 6.175746
 >> iter 153000, loss: 6.180104
 >> iter 154000, loss: 6.180187
 >> iter 155000, loss: 6.405625
 >> iter 156000, loss: 6.267975
 >> iter 157000, loss: 6.210135
 >> iter 158000, loss: 6.191139
 >> iter 159000, loss: 6.180923
 >> iter 160000, loss: 6.197155
   Number of active neurons: 10
 >> iter 161000, loss: 6.185801
 >> iter 162000, loss: 6.181023
 >> iter 163000, loss: 6.177774
 >> iter 164000, loss: 6.178147
 >> iter 165000, loss: 6.177361
 >> iter 166000, loss: 6.187962
 >> iter 167000, loss: 6.173483
 >> iter 168000, loss: 6.187365
 >> iter 169000, loss: 6.173338
 >> iter 170000, loss: 6.190406
   Number of active neurons: 10
 >> iter 171000, loss: 6.171275
 >> iter 172000, loss: 6.191687
 >> iter 173000, loss: 6.173130
 >> iter 174000, loss: 6.191304
 >> iter 175000, loss: 6.172093
 >> iter 176000, loss: 6.188791
 >> iter 177000, loss: 6.175790
 >> iter 178000, loss: 6.188591
 >> iter 179000, loss: 6.168639
 >> iter 180000, loss: 6.184642
   Number of active neurons: 10
 >> iter 181000, loss: 6.175799
 >> iter 182000, loss: 6.183906
 >> iter 183000, loss: 6.173927
 >> iter 184000, loss: 6.185007
 >> iter 185000, loss: 6.175323
 >> iter 186000, loss: 6.196245
 >> iter 187000, loss: 6.183447
 >> iter 188000, loss: 6.189519
 >> iter 189000, loss: 6.170660
 >> iter 190000, loss: 6.186982
   Number of active neurons: 10
 >> iter 191000, loss: 6.171963
 >> iter 192000, loss: 6.185091
 >> iter 193000, loss: 6.175922
 >> iter 194000, loss: 6.190417
 >> iter 195000, loss: 6.169153
 >> iter 196000, loss: 6.187250
 >> iter 197000, loss: 6.170509
 >> iter 198000, loss: 6.187373
 >> iter 199000, loss: 6.173179
 >> iter 200000, loss: 6.185427
   Number of active neurons: 10
 >> iter 201000, loss: 6.168512
 >> iter 202000, loss: 6.184903
 >> iter 203000, loss: 6.160408
 >> iter 204000, loss: 6.184024
 >> iter 205000, loss: 6.168330
 >> iter 206000, loss: 6.177704
 >> iter 207000, loss: 6.168867
 >> iter 208000, loss: 6.181518
 >> iter 209000, loss: 6.167616
 >> iter 210000, loss: 6.191840
   Number of active neurons: 10
 >> iter 211000, loss: 6.178635
 >> iter 212000, loss: 6.183038
 >> iter 213000, loss: 6.177034
 >> iter 214000, loss: 6.181772
 >> iter 215000, loss: 6.172157
 >> iter 216000, loss: 6.184564
 >> iter 217000, loss: 6.181020
 >> iter 218000, loss: 6.189461
 >> iter 219000, loss: 6.177363
 >> iter 220000, loss: 6.193192
   Number of active neurons: 10
 >> iter 221000, loss: 6.184621
 >> iter 222000, loss: 6.183156
 >> iter 223000, loss: 6.181035
 >> iter 224000, loss: 6.185710
 >> iter 225000, loss: 6.190701
 >> iter 226000, loss: 6.192281
 >> iter 227000, loss: 6.183919
 >> iter 228000, loss: 6.184796
 >> iter 229000, loss: 6.184083
 >> iter 230000, loss: 6.182669
   Number of active neurons: 10
 >> iter 231000, loss: 6.184347
 >> iter 232000, loss: 6.181051
 >> iter 233000, loss: 6.180768
 >> iter 234000, loss: 6.181589
 >> iter 235000, loss: 6.183408
 >> iter 236000, loss: 6.178668
 >> iter 237000, loss: 6.186297
 >> iter 238000, loss: 6.178815
 >> iter 239000, loss: 6.190262
 >> iter 240000, loss: 6.183977
   Number of active neurons: 10
 >> iter 241000, loss: 6.190929
 >> iter 242000, loss: 6.179976
 >> iter 243000, loss: 6.186549
 >> iter 244000, loss: 6.176945
 >> iter 245000, loss: 6.188860
 >> iter 246000, loss: 6.176222
 >> iter 247000, loss: 6.183479
 >> iter 248000, loss: 6.172012
 >> iter 249000, loss: 6.186601
 >> iter 250000, loss: 6.175692
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 17.555648887
   - Test - Long: 24.1887905605
   - Test - Big: 17.2948270517
   - Test - A: 16.3122458503
   - Test - B: 15.8589427372
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.709611
 >> iter 2000, loss: 11.139912
 >> iter 3000, loss: 9.071223
 >> iter 4000, loss: 8.188264
 >> iter 5000, loss: 7.853975
 >> iter 6000, loss: 7.727134
 >> iter 7000, loss: 7.648823
 >> iter 8000, loss: 7.596223
 >> iter 9000, loss: 7.589909
 >> iter 10000, loss: 7.572150
   Number of active neurons: 10
 >> iter 11000, loss: 7.573235
 >> iter 12000, loss: 7.593618
 >> iter 13000, loss: 7.600620
 >> iter 14000, loss: 7.575532
 >> iter 15000, loss: 7.594302
 >> iter 16000, loss: 7.574983
 >> iter 17000, loss: 7.578209
 >> iter 18000, loss: 7.562267
 >> iter 19000, loss: 7.572746
 >> iter 20000, loss: 7.565547
   Number of active neurons: 10
 >> iter 21000, loss: 7.570559
 >> iter 22000, loss: 7.561585
 >> iter 23000, loss: 7.567277
 >> iter 24000, loss: 7.561926
 >> iter 25000, loss: 7.570809
 >> iter 26000, loss: 7.563867
 >> iter 27000, loss: 7.569334
 >> iter 28000, loss: 7.562318
 >> iter 29000, loss: 7.568601
 >> iter 30000, loss: 7.563860
   Number of active neurons: 10
 >> iter 31000, loss: 7.573816
 >> iter 32000, loss: 7.566819
 >> iter 33000, loss: 7.574678
 >> iter 34000, loss: 7.567381
 >> iter 35000, loss: 7.570889
 >> iter 36000, loss: 7.561992
 >> iter 37000, loss: 7.571950
 >> iter 38000, loss: 7.563259
 >> iter 39000, loss: 7.570117
 >> iter 40000, loss: 7.562268
   Number of active neurons: 10
 >> iter 41000, loss: 7.570206
 >> iter 42000, loss: 7.562847
 >> iter 43000, loss: 7.571696
 >> iter 44000, loss: 7.553680
 >> iter 45000, loss: 7.566889
 >> iter 46000, loss: 7.572141
 >> iter 47000, loss: 7.574600
 >> iter 48000, loss: 7.558788
 >> iter 49000, loss: 7.566737
 >> iter 50000, loss: 7.554472
   Number of active neurons: 10
 >> iter 51000, loss: 7.563080
 >> iter 52000, loss: 7.661311
 >> iter 53000, loss: 7.578951
 >> iter 54000, loss: 7.509567
 >> iter 55000, loss: 7.582514
 >> iter 56000, loss: 7.466181
 >> iter 57000, loss: 7.418215
 >> iter 58000, loss: 7.170753
 >> iter 59000, loss: 7.030441
 >> iter 60000, loss: 6.995697
   Number of active neurons: 10
 >> iter 61000, loss: 6.854234
 >> iter 62000, loss: 6.786936
 >> iter 63000, loss: 6.758777
 >> iter 64000, loss: 6.711137
 >> iter 65000, loss: 6.775222
 >> iter 66000, loss: 6.699500
 >> iter 67000, loss: 6.615937
 >> iter 68000, loss: 6.556769
 >> iter 69000, loss: 6.487650
 >> iter 70000, loss: 6.359833
   Number of active neurons: 10
 >> iter 71000, loss: 6.413807
 >> iter 72000, loss: 6.229167
 >> iter 73000, loss: 6.105343
 >> iter 74000, loss: 5.997448
 >> iter 75000, loss: 5.949635
 >> iter 76000, loss: 6.014973
 >> iter 77000, loss: 5.904549
 >> iter 78000, loss: 5.928945
 >> iter 79000, loss: 5.858628
 >> iter 80000, loss: 5.830503
   Number of active neurons: 10
 >> iter 81000, loss: 5.798566
 >> iter 82000, loss: 5.759569
 >> iter 83000, loss: 5.651924
 >> iter 84000, loss: 5.597950
 >> iter 85000, loss: 5.519810
 >> iter 86000, loss: 5.518938
 >> iter 87000, loss: 5.637742
 >> iter 88000, loss: 5.499804
 >> iter 89000, loss: 5.469377
 >> iter 90000, loss: 5.442054
   Number of active neurons: 10
 >> iter 91000, loss: 5.406399
 >> iter 92000, loss: 5.452517
 >> iter 93000, loss: 5.407464
 >> iter 94000, loss: 5.414878
 >> iter 95000, loss: 5.407356
 >> iter 96000, loss: 5.420484
 >> iter 97000, loss: 5.380413
 >> iter 98000, loss: 5.387010
 >> iter 99000, loss: 5.374197
 >> iter 100000, loss: 5.415603
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 13.6817263655
   - Test - Long: 23.4888255587
   - Test - Big: 13.4668653313
   - Test - A: 32.1178588094
   - Test - B: 3.26644890341
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.497008
 >> iter 2000, loss: 11.166071
 >> iter 3000, loss: 9.009057
 >> iter 4000, loss: 8.187699
 >> iter 5000, loss: 7.831135
 >> iter 6000, loss: 7.695549
 >> iter 7000, loss: 7.704032
 >> iter 8000, loss: 7.650833
 >> iter 9000, loss: 7.624696
 >> iter 10000, loss: 7.597914
   Number of active neurons: 10
 >> iter 11000, loss: 7.606557
 >> iter 12000, loss: 7.607108
 >> iter 13000, loss: 7.593786
 >> iter 14000, loss: 7.579053
 >> iter 15000, loss: 7.573472
 >> iter 16000, loss: 7.563269
 >> iter 17000, loss: 7.568441
 >> iter 18000, loss: 7.573143
 >> iter 19000, loss: 7.575696
 >> iter 20000, loss: 7.560255
   Number of active neurons: 10
 >> iter 21000, loss: 7.587048
 >> iter 22000, loss: 7.569080
 >> iter 23000, loss: 7.581745
 >> iter 24000, loss: 7.585530
 >> iter 25000, loss: 7.577226
 >> iter 26000, loss: 7.560450
 >> iter 27000, loss: 7.566075
 >> iter 28000, loss: 7.599524
 >> iter 29000, loss: 7.579825
 >> iter 30000, loss: 7.570170
   Number of active neurons: 10
 >> iter 31000, loss: 7.571116
 >> iter 32000, loss: 7.555697
 >> iter 33000, loss: 7.558485
 >> iter 34000, loss: 7.550129
 >> iter 35000, loss: 7.581489
 >> iter 36000, loss: 7.558116
 >> iter 37000, loss: 7.585062
 >> iter 38000, loss: 7.565121
 >> iter 39000, loss: 7.559043
 >> iter 40000, loss: 7.599780
   Number of active neurons: 10
 >> iter 41000, loss: 7.619751
 >> iter 42000, loss: 7.569071
 >> iter 43000, loss: 7.567817
 >> iter 44000, loss: 7.553104
 >> iter 45000, loss: 7.561787
 >> iter 46000, loss: 7.561766
 >> iter 47000, loss: 7.559634
 >> iter 48000, loss: 7.554118
 >> iter 49000, loss: 7.562635
 >> iter 50000, loss: 7.541531
   Number of active neurons: 10
 >> iter 51000, loss: 7.574975
 >> iter 52000, loss: 7.551567
 >> iter 53000, loss: 7.572086
 >> iter 54000, loss: 7.550194
 >> iter 55000, loss: 7.559417
 >> iter 56000, loss: 7.544875
 >> iter 57000, loss: 7.578631
 >> iter 58000, loss: 7.549524
 >> iter 59000, loss: 7.556609
 >> iter 60000, loss: 7.544089
   Number of active neurons: 10
 >> iter 61000, loss: 7.554407
 >> iter 62000, loss: 7.541628
 >> iter 63000, loss: 7.553745
 >> iter 64000, loss: 7.542232
 >> iter 65000, loss: 7.554350
 >> iter 66000, loss: 7.542407
 >> iter 67000, loss: 7.553673
 >> iter 68000, loss: 7.542583
 >> iter 69000, loss: 7.552630
 >> iter 70000, loss: 7.542387
   Number of active neurons: 10
 >> iter 71000, loss: 7.553076
 >> iter 72000, loss: 7.547530
 >> iter 73000, loss: 7.555225
 >> iter 74000, loss: 7.546217
 >> iter 75000, loss: 7.554305
 >> iter 76000, loss: 7.547744
 >> iter 77000, loss: 7.552392
 >> iter 78000, loss: 7.545091
 >> iter 79000, loss: 7.552254
 >> iter 80000, loss: 7.543147
   Number of active neurons: 10
 >> iter 81000, loss: 7.544654
 >> iter 82000, loss: 7.537544
 >> iter 83000, loss: 7.548673
 >> iter 84000, loss: 7.548943
 >> iter 85000, loss: 7.551088
 >> iter 86000, loss: 7.546795
 >> iter 87000, loss: 7.565629
 >> iter 88000, loss: 7.557955
 >> iter 89000, loss: 7.551259
 >> iter 90000, loss: 7.551040
   Number of active neurons: 10
 >> iter 91000, loss: 7.548496
 >> iter 92000, loss: 7.552051
 >> iter 93000, loss: 7.547632
 >> iter 94000, loss: 7.547989
 >> iter 95000, loss: 7.544686
 >> iter 96000, loss: 7.545923
 >> iter 97000, loss: 7.546333
 >> iter 98000, loss: 7.551601
 >> iter 99000, loss: 7.545283
 >> iter 100000, loss: 7.549563
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 21.2595748085
   - Test - Long: 24.4987750612
   - Test - Big: 21.1897881021
   - Test - A: 32.8911405906
   - Test - B: 33.404439704
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.507283
 >> iter 2000, loss: 11.111545
 >> iter 3000, loss: 8.954240
 >> iter 4000, loss: 8.207215
 >> iter 5000, loss: 7.937698
 >> iter 6000, loss: 7.729168
 >> iter 7000, loss: 7.644820
 >> iter 8000, loss: 7.617899
 >> iter 9000, loss: 7.600454
 >> iter 10000, loss: 7.600868
   Number of active neurons: 10
 >> iter 11000, loss: 7.596944
 >> iter 12000, loss: 7.593816
 >> iter 13000, loss: 7.655442
 >> iter 14000, loss: 7.601150
 >> iter 15000, loss: 7.641938
 >> iter 16000, loss: 7.592697
 >> iter 17000, loss: 7.614718
 >> iter 18000, loss: 7.639973
 >> iter 19000, loss: 7.598912
 >> iter 20000, loss: 7.568765
   Number of active neurons: 10
 >> iter 21000, loss: 7.570034
 >> iter 22000, loss: 7.562831
 >> iter 23000, loss: 7.567893
 >> iter 24000, loss: 7.560324
 >> iter 25000, loss: 7.572096
 >> iter 26000, loss: 7.559536
 >> iter 27000, loss: 7.564552
 >> iter 28000, loss: 7.560872
 >> iter 29000, loss: 7.570668
 >> iter 30000, loss: 7.564349
   Number of active neurons: 10
 >> iter 31000, loss: 7.571169
 >> iter 32000, loss: 7.585687
 >> iter 33000, loss: 7.576846
 >> iter 34000, loss: 7.570026
 >> iter 35000, loss: 7.581773
 >> iter 36000, loss: 7.563813
 >> iter 37000, loss: 7.569203
 >> iter 38000, loss: 7.559885
 >> iter 39000, loss: 7.568748
 >> iter 40000, loss: 7.562367
   Number of active neurons: 10
 >> iter 41000, loss: 7.570182
 >> iter 42000, loss: 7.555862
 >> iter 43000, loss: 7.568595
 >> iter 44000, loss: 7.557731
 >> iter 45000, loss: 7.566485
 >> iter 46000, loss: 7.559844
 >> iter 47000, loss: 7.570864
 >> iter 48000, loss: 7.555456
 >> iter 49000, loss: 7.569644
 >> iter 50000, loss: 7.556083
   Number of active neurons: 10
 >> iter 51000, loss: 7.579462
 >> iter 52000, loss: 7.559118
 >> iter 53000, loss: 7.569904
 >> iter 54000, loss: 7.558541
 >> iter 55000, loss: 7.564393
 >> iter 56000, loss: 7.552295
 >> iter 57000, loss: 7.563882
 >> iter 58000, loss: 7.551319
 >> iter 59000, loss: 7.564509
 >> iter 60000, loss: 7.555796
   Number of active neurons: 10
 >> iter 61000, loss: 7.566648
 >> iter 62000, loss: 7.556795
 >> iter 63000, loss: 7.568203
 >> iter 64000, loss: 7.558566
 >> iter 65000, loss: 7.566918
 >> iter 66000, loss: 7.557449
 >> iter 67000, loss: 7.567502
 >> iter 68000, loss: 7.552698
 >> iter 69000, loss: 7.565036
 >> iter 70000, loss: 7.553434
   Number of active neurons: 10
 >> iter 71000, loss: 7.565712
 >> iter 72000, loss: 7.556358
 >> iter 73000, loss: 7.567287
 >> iter 74000, loss: 7.561670
 >> iter 75000, loss: 7.564438
 >> iter 76000, loss: 7.553476
 >> iter 77000, loss: 7.565648
 >> iter 78000, loss: 7.557082
 >> iter 79000, loss: 7.596508
 >> iter 80000, loss: 7.567875
   Number of active neurons: 10
 >> iter 81000, loss: 7.560963
 >> iter 82000, loss: 7.559738
 >> iter 83000, loss: 7.561322
 >> iter 84000, loss: 7.562635
 >> iter 85000, loss: 7.563041
 >> iter 86000, loss: 7.561597
 >> iter 87000, loss: 7.565320
 >> iter 88000, loss: 7.564649
 >> iter 89000, loss: 7.564601
 >> iter 90000, loss: 7.560570
   Number of active neurons: 10
 >> iter 91000, loss: 7.561525
 >> iter 92000, loss: 7.564476
 >> iter 93000, loss: 7.555905
 >> iter 94000, loss: 7.561926
 >> iter 95000, loss: 7.573670
 >> iter 96000, loss: 7.569277
 >> iter 97000, loss: 7.556651
 >> iter 98000, loss: 7.563114
 >> iter 99000, loss: 7.562735
 >> iter 100000, loss: 7.565019
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 23.4255314894
   - Test - Long: 24.9487525624
   - Test - Big: 23.3407665923
   - Test - A: 17.3255116326
   - Test - B: 15.8589427372
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.624911
 >> iter 2000, loss: 11.187480
 >> iter 3000, loss: 8.978956
 >> iter 4000, loss: 8.203544
 >> iter 5000, loss: 7.866645
 >> iter 6000, loss: 7.714184
 >> iter 7000, loss: 7.630220
 >> iter 8000, loss: 7.600705
 >> iter 9000, loss: 7.594916
 >> iter 10000, loss: 7.574872
   Number of active neurons: 10
 >> iter 11000, loss: 7.586270
 >> iter 12000, loss: 7.584369
 >> iter 13000, loss: 7.580143
 >> iter 14000, loss: 7.571741
 >> iter 15000, loss: 7.574529
 >> iter 16000, loss: 7.571160
 >> iter 17000, loss: 7.575743
 >> iter 18000, loss: 7.587461
 >> iter 19000, loss: 7.580593
 >> iter 20000, loss: 7.566063
   Number of active neurons: 10
 >> iter 21000, loss: 7.619245
 >> iter 22000, loss: 7.582106
 >> iter 23000, loss: 7.586442
 >> iter 24000, loss: 7.599365
 >> iter 25000, loss: 7.582054
 >> iter 26000, loss: 7.565837
 >> iter 27000, loss: 7.594072
 >> iter 28000, loss: 7.590939
 >> iter 29000, loss: 7.585139
 >> iter 30000, loss: 7.590981
   Number of active neurons: 10
 >> iter 31000, loss: 7.574795
 >> iter 32000, loss: 7.604506
 >> iter 33000, loss: 7.632948
 >> iter 34000, loss: 7.592772
 >> iter 35000, loss: 7.587858
 >> iter 36000, loss: 7.630238
 >> iter 37000, loss: 7.544180
 >> iter 38000, loss: 7.455638
 >> iter 39000, loss: 7.434769
 >> iter 40000, loss: 7.281927
   Number of active neurons: 10
 >> iter 41000, loss: 7.091593
 >> iter 42000, loss: 6.944374
 >> iter 43000, loss: 6.762857
 >> iter 44000, loss: 6.539336
 >> iter 45000, loss: 6.428610
 >> iter 46000, loss: 6.367190
 >> iter 47000, loss: 6.320486
 >> iter 48000, loss: 6.249551
 >> iter 49000, loss: 6.253234
 >> iter 50000, loss: 6.232379
   Number of active neurons: 10
 >> iter 51000, loss: 6.253839
 >> iter 52000, loss: 6.206958
 >> iter 53000, loss: 6.234707
 >> iter 54000, loss: 6.082521
 >> iter 55000, loss: 6.040230
 >> iter 56000, loss: 5.964857
 >> iter 57000, loss: 5.962181
 >> iter 58000, loss: 5.947943
 >> iter 59000, loss: 6.009876
 >> iter 60000, loss: 5.942997
   Number of active neurons: 10
 >> iter 61000, loss: 5.934321
 >> iter 62000, loss: 5.887507
 >> iter 63000, loss: 5.917138
 >> iter 64000, loss: 5.873222
 >> iter 65000, loss: 5.893455
 >> iter 66000, loss: 5.874754
 >> iter 67000, loss: 5.875800
 >> iter 68000, loss: 5.848729
 >> iter 69000, loss: 5.860945
 >> iter 70000, loss: 5.852623
   Number of active neurons: 10
 >> iter 71000, loss: 5.880653
 >> iter 72000, loss: 5.859687
 >> iter 73000, loss: 5.903875
 >> iter 74000, loss: 5.868457
 >> iter 75000, loss: 5.886915
 >> iter 76000, loss: 5.853083
 >> iter 77000, loss: 5.886779
 >> iter 78000, loss: 5.851398
 >> iter 79000, loss: 5.899795
 >> iter 80000, loss: 5.856205
   Number of active neurons: 10
 >> iter 81000, loss: 5.849227
 >> iter 82000, loss: 5.917906
 >> iter 83000, loss: 5.873661
 >> iter 84000, loss: 5.921192
 >> iter 85000, loss: 5.858441
 >> iter 86000, loss: 5.838624
 >> iter 87000, loss: 5.836891
 >> iter 88000, loss: 5.833150
 >> iter 89000, loss: 5.826951
 >> iter 90000, loss: 5.809934
   Number of active neurons: 10
 >> iter 91000, loss: 5.796538
 >> iter 92000, loss: 5.822081
 >> iter 93000, loss: 5.796264
 >> iter 94000, loss: 5.795299
 >> iter 95000, loss: 5.846759
 >> iter 96000, loss: 5.780351
 >> iter 97000, loss: 5.791121
 >> iter 98000, loss: 5.753163
 >> iter 99000, loss: 5.650627
 >> iter 100000, loss: 5.634270
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 10.7877842443
   - Test - Long: 22.1738913054
   - Test - Big: 10.468895311
   - Test - A: 10.8059462702
   - Test - B: 11.9458702753
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.593488
 >> iter 2000, loss: 11.120172
 >> iter 3000, loss: 8.967699
 >> iter 4000, loss: 8.166452
 >> iter 5000, loss: 7.907061
 >> iter 6000, loss: 7.719681
 >> iter 7000, loss: 7.661058
 >> iter 8000, loss: 7.631313
 >> iter 9000, loss: 7.616263
 >> iter 10000, loss: 7.607583
   Number of active neurons: 10
 >> iter 11000, loss: 7.607658
 >> iter 12000, loss: 7.635447
 >> iter 13000, loss: 7.617653
 >> iter 14000, loss: 7.603111
 >> iter 15000, loss: 7.596414
 >> iter 16000, loss: 7.585105
 >> iter 17000, loss: 7.590165
 >> iter 18000, loss: 7.580006
 >> iter 19000, loss: 7.586276
 >> iter 20000, loss: 7.577239
   Number of active neurons: 10
 >> iter 21000, loss: 7.600570
 >> iter 22000, loss: 7.584585
 >> iter 23000, loss: 7.584419
 >> iter 24000, loss: 7.578044
 >> iter 25000, loss: 7.586852
 >> iter 26000, loss: 7.578531
 >> iter 27000, loss: 7.586130
 >> iter 28000, loss: 7.580233
 >> iter 29000, loss: 7.585304
 >> iter 30000, loss: 7.605589
   Number of active neurons: 10
 >> iter 31000, loss: 7.596510
 >> iter 32000, loss: 7.587746
 >> iter 33000, loss: 7.589256
 >> iter 34000, loss: 7.581617
 >> iter 35000, loss: 7.584099
 >> iter 36000, loss: 7.579164
 >> iter 37000, loss: 7.582578
 >> iter 38000, loss: 7.576075
 >> iter 39000, loss: 7.584289
 >> iter 40000, loss: 7.572191
   Number of active neurons: 10
 >> iter 41000, loss: 7.578970
 >> iter 42000, loss: 7.570165
 >> iter 43000, loss: 7.577990
 >> iter 44000, loss: 7.570197
 >> iter 45000, loss: 7.580847
 >> iter 46000, loss: 7.582197
 >> iter 47000, loss: 7.584651
 >> iter 48000, loss: 7.575562
 >> iter 49000, loss: 7.584856
 >> iter 50000, loss: 7.573858
   Number of active neurons: 10
 >> iter 51000, loss: 7.585029
 >> iter 52000, loss: 7.568585
 >> iter 53000, loss: 7.583517
 >> iter 54000, loss: 7.571771
 >> iter 55000, loss: 7.578829
 >> iter 56000, loss: 7.565863
 >> iter 57000, loss: 7.579968
 >> iter 58000, loss: 7.570612
 >> iter 59000, loss: 7.580536
 >> iter 60000, loss: 7.570431
   Number of active neurons: 10
 >> iter 61000, loss: 7.579229
 >> iter 62000, loss: 7.570233
 >> iter 63000, loss: 7.578176
 >> iter 64000, loss: 7.570811
 >> iter 65000, loss: 7.580247
 >> iter 66000, loss: 7.575111
 >> iter 67000, loss: 7.582830
 >> iter 68000, loss: 7.572764
 >> iter 69000, loss: 7.582521
 >> iter 70000, loss: 7.573430
   Number of active neurons: 10
 >> iter 71000, loss: 7.581299
 >> iter 72000, loss: 7.571143
 >> iter 73000, loss: 7.575282
 >> iter 74000, loss: 7.567708
 >> iter 75000, loss: 7.574357
 >> iter 76000, loss: 7.579618
 >> iter 77000, loss: 7.574193
 >> iter 78000, loss: 7.543825
 >> iter 79000, loss: 7.487993
 >> iter 80000, loss: 7.360645
   Number of active neurons: 10
 >> iter 81000, loss: 7.267429
 >> iter 82000, loss: 7.165306
 >> iter 83000, loss: 7.110804
 >> iter 84000, loss: 7.000636
 >> iter 85000, loss: 6.965045
 >> iter 86000, loss: 6.858427
 >> iter 87000, loss: 6.765073
 >> iter 88000, loss: 6.724784
 >> iter 89000, loss: 6.641916
 >> iter 90000, loss: 6.597636
   Number of active neurons: 10
 >> iter 91000, loss: 6.536289
 >> iter 92000, loss: 6.440622
 >> iter 93000, loss: 6.336026
 >> iter 94000, loss: 6.022306
 >> iter 95000, loss: 5.631147
 >> iter 96000, loss: 5.247885
 >> iter 97000, loss: 4.994195
 >> iter 98000, loss: 6.379240
 >> iter 99000, loss: 6.592536
 >> iter 100000, loss: 5.138113
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.688665
 >> iter 2000, loss: 11.220460
 >> iter 3000, loss: 9.051115
 >> iter 4000, loss: 8.198970
 >> iter 5000, loss: 7.839088
 >> iter 6000, loss: 7.688885
 >> iter 7000, loss: 7.622166
 >> iter 8000, loss: 7.607816
 >> iter 9000, loss: 7.709347
 >> iter 10000, loss: 7.613622
   Number of active neurons: 10
 >> iter 11000, loss: 7.589729
 >> iter 12000, loss: 7.572127
 >> iter 13000, loss: 7.576508
 >> iter 14000, loss: 7.559047
 >> iter 15000, loss: 7.572704
 >> iter 16000, loss: 7.561287
 >> iter 17000, loss: 7.568805
 >> iter 18000, loss: 7.556707
 >> iter 19000, loss: 7.589964
 >> iter 20000, loss: 7.563553
   Number of active neurons: 10
 >> iter 21000, loss: 7.561913
 >> iter 22000, loss: 7.547087
 >> iter 23000, loss: 7.557387
 >> iter 24000, loss: 7.544228
 >> iter 25000, loss: 7.551462
 >> iter 26000, loss: 7.546494
 >> iter 27000, loss: 7.550780
 >> iter 28000, loss: 7.545852
 >> iter 29000, loss: 7.553654
 >> iter 30000, loss: 7.547546
   Number of active neurons: 10
 >> iter 31000, loss: 7.558476
 >> iter 32000, loss: 7.553926
 >> iter 33000, loss: 7.558773
 >> iter 34000, loss: 7.566079
 >> iter 35000, loss: 7.563205
 >> iter 36000, loss: 7.548099
 >> iter 37000, loss: 7.553047
 >> iter 38000, loss: 7.544069
 >> iter 39000, loss: 7.559261
 >> iter 40000, loss: 7.542753
   Number of active neurons: 10
 >> iter 41000, loss: 7.550415
 >> iter 42000, loss: 7.527671
 >> iter 43000, loss: 7.541097
 >> iter 44000, loss: 7.496435
 >> iter 45000, loss: 7.431614
 >> iter 46000, loss: 7.345651
 >> iter 47000, loss: 7.180105
 >> iter 48000, loss: 7.074835
 >> iter 49000, loss: 7.001851
 >> iter 50000, loss: 6.937890
   Number of active neurons: 10
 >> iter 51000, loss: 6.916375
 >> iter 52000, loss: 6.880862
 >> iter 53000, loss: 6.867489
 >> iter 54000, loss: 6.830167
 >> iter 55000, loss: 6.781096
 >> iter 56000, loss: 6.664781
 >> iter 57000, loss: 6.481513
 >> iter 58000, loss: 6.281802
 >> iter 59000, loss: 5.953159
 >> iter 60000, loss: 5.506003
   Number of active neurons: 10
 >> iter 61000, loss: 4.896982
 >> iter 62000, loss: 4.170327
 >> iter 63000, loss: 3.857343
 >> iter 64000, loss: 3.681904
 >> iter 65000, loss: 3.628110
 >> iter 66000, loss: 3.597838
 >> iter 67000, loss: 3.551453
 >> iter 68000, loss: 3.396721
 >> iter 69000, loss: 3.299260
 >> iter 70000, loss: 3.191920
   Number of active neurons: 10
 >> iter 71000, loss: 3.118183
 >> iter 72000, loss: 3.065637
 >> iter 73000, loss: 3.022484
 >> iter 74000, loss: 3.064554
 >> iter 75000, loss: 3.145286
 >> iter 76000, loss: 3.098993
 >> iter 77000, loss: 3.027045
 >> iter 78000, loss: 3.113228
 >> iter 79000, loss: 3.045120
 >> iter 80000, loss: 3.013510
   Number of active neurons: 10
 >> iter 81000, loss: 2.971040
 >> iter 82000, loss: 2.995613
 >> iter 83000, loss: 2.975954
 >> iter 84000, loss: 2.997946
 >> iter 85000, loss: 2.659456
 >> iter 86000, loss: 1.497256
 >> iter 87000, loss: 0.740484
 >> iter 88000, loss: 0.407345
 >> iter 89000, loss: 0.257437
 >> iter 90000, loss: 0.274002
   Number of active neurons: 10
 >> iter 91000, loss: 0.185134
 >> iter 92000, loss: 0.093161
 >> iter 93000, loss: 0.122879
 >> iter 94000, loss: 0.147787
 >> iter 95000, loss: 0.072837
 >> iter 96000, loss: 0.044912
 >> iter 97000, loss: 0.054195
 >> iter 98000, loss: 0.039168
 >> iter 99000, loss: 0.049630
 >> iter 100000, loss: 0.121135
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455162
   Number of active neurons: 0
 >> iter 1000, loss: 16.382748
 >> iter 2000, loss: 11.043130
 >> iter 3000, loss: 8.945463
 >> iter 4000, loss: 8.170535
 >> iter 5000, loss: 7.847355
 >> iter 6000, loss: 7.710461
 >> iter 7000, loss: 7.664640
 >> iter 8000, loss: 7.683286
 >> iter 9000, loss: 7.705879
 >> iter 10000, loss: 7.673804
   Number of active neurons: 10
 >> iter 11000, loss: 7.650031
 >> iter 12000, loss: 7.631955
 >> iter 13000, loss: 7.626014
 >> iter 14000, loss: 7.608913
 >> iter 15000, loss: 7.622549
 >> iter 16000, loss: 7.604294
 >> iter 17000, loss: 7.610382
 >> iter 18000, loss: 7.600003
 >> iter 19000, loss: 7.606924
 >> iter 20000, loss: 7.596426
   Number of active neurons: 10
 >> iter 21000, loss: 7.603491
 >> iter 22000, loss: 7.598738
 >> iter 23000, loss: 7.601124
 >> iter 24000, loss: 7.595942
 >> iter 25000, loss: 7.603917
 >> iter 26000, loss: 7.597243
 >> iter 27000, loss: 7.619055
 >> iter 28000, loss: 7.605596
 >> iter 29000, loss: 7.608606
 >> iter 30000, loss: 7.601398
   Number of active neurons: 10
 >> iter 31000, loss: 7.603552
 >> iter 32000, loss: 7.657048
 >> iter 33000, loss: 7.627299
 >> iter 34000, loss: 7.632083
 >> iter 35000, loss: 7.619966
 >> iter 36000, loss: 7.612647
 >> iter 37000, loss: 7.613379
 >> iter 38000, loss: 7.603216
 >> iter 39000, loss: 7.606577
 >> iter 40000, loss: 7.598591
   Number of active neurons: 10
 >> iter 41000, loss: 7.605189
 >> iter 42000, loss: 7.600435
 >> iter 43000, loss: 7.604111
 >> iter 44000, loss: 7.593706
 >> iter 45000, loss: 7.604721
 >> iter 46000, loss: 7.596676
 >> iter 47000, loss: 7.605932
 >> iter 48000, loss: 7.596257
 >> iter 49000, loss: 7.606871
 >> iter 50000, loss: 7.594060
   Number of active neurons: 10
 >> iter 51000, loss: 7.601424
 >> iter 52000, loss: 7.591690
 >> iter 53000, loss: 7.600362
 >> iter 54000, loss: 7.610090
 >> iter 55000, loss: 7.608987
 >> iter 56000, loss: 7.587089
 >> iter 57000, loss: 7.593184
 >> iter 58000, loss: 7.577391
 >> iter 59000, loss: 7.584219
 >> iter 60000, loss: 7.575982
   Number of active neurons: 10
 >> iter 61000, loss: 7.587060
 >> iter 62000, loss: 7.575384
 >> iter 63000, loss: 7.586558
 >> iter 64000, loss: 7.575060
 >> iter 65000, loss: 7.585944
 >> iter 66000, loss: 7.574537
 >> iter 67000, loss: 7.584604
 >> iter 68000, loss: 7.577442
 >> iter 69000, loss: 7.586990
 >> iter 70000, loss: 7.576442
   Number of active neurons: 10
 >> iter 71000, loss: 7.583766
 >> iter 72000, loss: 7.578957
 >> iter 73000, loss: 7.583070
 >> iter 74000, loss: 7.580701
 >> iter 75000, loss: 7.587058
 >> iter 76000, loss: 7.576159
 >> iter 77000, loss: 7.581656
 >> iter 78000, loss: 7.575127
 >> iter 79000, loss: 7.583352
 >> iter 80000, loss: 7.581252
   Number of active neurons: 10
 >> iter 81000, loss: 7.584636
 >> iter 82000, loss: 7.678102
 >> iter 83000, loss: 7.620824
 >> iter 84000, loss: 7.591197
 >> iter 85000, loss: 7.586320
 >> iter 86000, loss: 7.579598
 >> iter 87000, loss: 7.579925
 >> iter 88000, loss: 7.580811
 >> iter 89000, loss: 7.577426
 >> iter 90000, loss: 7.581497
   Number of active neurons: 10
 >> iter 91000, loss: 7.578626
 >> iter 92000, loss: 7.583216
 >> iter 93000, loss: 7.580460
 >> iter 94000, loss: 7.584013
 >> iter 95000, loss: 7.577445
 >> iter 96000, loss: 7.584012
 >> iter 97000, loss: 7.575600
 >> iter 98000, loss: 7.582920
 >> iter 99000, loss: 7.582247
 >> iter 100000, loss: 7.584888
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 21.6555668887
   - Test - Long: 24.6087695615
   - Test - Big: 21.4157858421
   - Test - A: 16.1389240717
   - Test - B: 33.5577628158
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 16.777662
 >> iter 2000, loss: 11.201538
 >> iter 3000, loss: 9.021738
 >> iter 4000, loss: 8.170670
 >> iter 5000, loss: 7.889809
 >> iter 6000, loss: 7.709984
 >> iter 7000, loss: 7.651872
 >> iter 8000, loss: 7.614252
 >> iter 9000, loss: 7.626760
 >> iter 10000, loss: 7.602722
   Number of active neurons: 10
 >> iter 11000, loss: 7.609769
 >> iter 12000, loss: 7.586847
 >> iter 13000, loss: 7.590936
 >> iter 14000, loss: 7.620514
 >> iter 15000, loss: 7.603578
 >> iter 16000, loss: 7.583901
 >> iter 17000, loss: 7.586229
 >> iter 18000, loss: 7.584705
 >> iter 19000, loss: 7.590605
 >> iter 20000, loss: 7.602842
   Number of active neurons: 10
 >> iter 21000, loss: 7.598768
 >> iter 22000, loss: 7.584400
 >> iter 23000, loss: 7.596521
 >> iter 24000, loss: 7.587204
 >> iter 25000, loss: 7.584215
 >> iter 26000, loss: 7.578303
 >> iter 27000, loss: 7.583574
 >> iter 28000, loss: 7.577276
 >> iter 29000, loss: 7.592315
 >> iter 30000, loss: 7.585709
   Number of active neurons: 10
 >> iter 31000, loss: 7.587371
 >> iter 32000, loss: 7.579739
 >> iter 33000, loss: 7.585997
 >> iter 34000, loss: 7.581274
 >> iter 35000, loss: 7.587698
 >> iter 36000, loss: 7.580915
 >> iter 37000, loss: 7.583787
 >> iter 38000, loss: 7.634025
 >> iter 39000, loss: 7.606567
 >> iter 40000, loss: 7.583328
   Number of active neurons: 10
 >> iter 41000, loss: 7.588548
 >> iter 42000, loss: 7.597738
 >> iter 43000, loss: 7.624741
 >> iter 44000, loss: 7.588107
 >> iter 45000, loss: 7.588397
 >> iter 46000, loss: 7.578708
 >> iter 47000, loss: 7.586882
 >> iter 48000, loss: 7.574080
 >> iter 49000, loss: 7.586612
 >> iter 50000, loss: 7.571109
   Number of active neurons: 10
 >> iter 51000, loss: 7.583614
 >> iter 52000, loss: 7.563807
 >> iter 53000, loss: 7.569180
 >> iter 54000, loss: 7.554633
 >> iter 55000, loss: 7.563939
 >> iter 56000, loss: 7.556618
 >> iter 57000, loss: 7.564691
 >> iter 58000, loss: 7.555144
 >> iter 59000, loss: 7.565558
 >> iter 60000, loss: 7.558144
   Number of active neurons: 10
 >> iter 61000, loss: 7.567080
 >> iter 62000, loss: 7.561863
 >> iter 63000, loss: 7.579432
 >> iter 64000, loss: 7.566348
 >> iter 65000, loss: 7.570059
 >> iter 66000, loss: 7.557443
 >> iter 67000, loss: 7.562577
 >> iter 68000, loss: 7.561939
 >> iter 69000, loss: 7.571243
 >> iter 70000, loss: 7.560206
   Number of active neurons: 10
 >> iter 71000, loss: 7.565034
 >> iter 72000, loss: 7.558455
 >> iter 73000, loss: 7.567851
 >> iter 74000, loss: 7.562426
 >> iter 75000, loss: 7.567306
 >> iter 76000, loss: 7.557499
 >> iter 77000, loss: 7.564290
 >> iter 78000, loss: 7.561113
 >> iter 79000, loss: 7.567120
 >> iter 80000, loss: 7.559518
   Number of active neurons: 10
 >> iter 81000, loss: 7.574424
 >> iter 82000, loss: 7.565985
 >> iter 83000, loss: 7.566557
 >> iter 84000, loss: 7.563061
 >> iter 85000, loss: 7.566974
 >> iter 86000, loss: 7.606687
 >> iter 87000, loss: 7.580294
 >> iter 88000, loss: 7.564231
 >> iter 89000, loss: 7.562576
 >> iter 90000, loss: 7.550685
   Number of active neurons: 10
 >> iter 91000, loss: 7.560068
 >> iter 92000, loss: 7.622418
 >> iter 93000, loss: 7.506101
 >> iter 94000, loss: 7.366251
 >> iter 95000, loss: 7.221774
 >> iter 96000, loss: 7.148181
 >> iter 97000, loss: 7.055274
 >> iter 98000, loss: 7.024999
 >> iter 99000, loss: 6.971011
 >> iter 100000, loss: 6.943500
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 19.2356152877
   - Test - Long: 24.2487875606
   - Test - Big: 19.1328086719
   - Test - A: 32.8911405906
   - Test - B: 32.4711685888
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.786688
 >> iter 2000, loss: 11.262640
 >> iter 3000, loss: 9.098757
 >> iter 4000, loss: 8.306475
 >> iter 5000, loss: 7.858559
 >> iter 6000, loss: 7.672338
 >> iter 7000, loss: 7.612245
 >> iter 8000, loss: 7.591289
 >> iter 9000, loss: 7.586995
 >> iter 10000, loss: 7.555309
   Number of active neurons: 9
 >> iter 11000, loss: 7.552143
 >> iter 12000, loss: 7.541986
 >> iter 13000, loss: 7.551798
 >> iter 14000, loss: 7.545020
 >> iter 15000, loss: 7.548980
 >> iter 16000, loss: 7.537864
 >> iter 17000, loss: 7.551054
 >> iter 18000, loss: 7.541838
 >> iter 19000, loss: 7.549414
 >> iter 20000, loss: 7.542779
   Number of active neurons: 9
 >> iter 21000, loss: 7.543609
 >> iter 22000, loss: 7.536110
 >> iter 23000, loss: 7.543930
 >> iter 24000, loss: 7.533963
 >> iter 25000, loss: 7.543331
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 26000, loss: 7.535149
 >> iter 27000, loss: 7.540966
 >> iter 28000, loss: 7.532837
 >> iter 29000, loss: 7.542783
 >> iter 30000, loss: 7.539169
   Number of active neurons: 8
 >> iter 31000, loss: 7.546256
 >> iter 32000, loss: 7.540273
 >> iter 33000, loss: 7.546458
 >> iter 34000, loss: 7.537654
 >> iter 35000, loss: 7.546266
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 36000, loss: 7.539925
 >> iter 37000, loss: 7.544789
 >> iter 38000, loss: 7.534790
 >> iter 39000, loss: 7.545501
 >> iter 40000, loss: 7.536536
   Number of active neurons: 9
 >> iter 41000, loss: 7.546450
 >> iter 42000, loss: 7.532578
 >> iter 43000, loss: 7.543154
 >> iter 44000, loss: 7.530969
 >> iter 45000, loss: 7.544977
   Number of active neurons: 8
   SHOCK
   Setting new limit to 275000.0 iters...
 >> iter 46000, loss: 7.536680
 >> iter 47000, loss: 7.543828
 >> iter 48000, loss: 7.531237
 >> iter 49000, loss: 7.544661
 >> iter 50000, loss: 7.530253
   Number of active neurons: 9
 >> iter 51000, loss: 7.543368
 >> iter 52000, loss: 7.525619
 >> iter 53000, loss: 7.544686
 >> iter 54000, loss: 7.530440
 >> iter 55000, loss: 7.540369
   Number of active neurons: 8
   SHOCK
   Setting new limit to 287500.0 iters...
 >> iter 56000, loss: 7.528540
 >> iter 57000, loss: 7.540969
 >> iter 58000, loss: 7.526300
 >> iter 59000, loss: 7.539847
 >> iter 60000, loss: 7.524876
   Number of active neurons: 7
 >> iter 61000, loss: 7.538134
 >> iter 62000, loss: 7.525837
 >> iter 63000, loss: 7.538602
 >> iter 64000, loss: 7.590000
 >> iter 65000, loss: 7.556409
   Number of active neurons: 7
   SHOCK
   Setting new limit to 293750.0 iters...
 >> iter 66000, loss: 7.535589
 >> iter 67000, loss: 7.536151
 >> iter 68000, loss: 7.521371
 >> iter 69000, loss: 7.530724
 >> iter 70000, loss: 7.600690
   Number of active neurons: 9
   SHOCK
   Setting new limit to 296875.0 iters...
   Number of active neurons: 9
 >> iter 71000, loss: 7.557911
 >> iter 72000, loss: 7.504776
 >> iter 73000, loss: 7.440549
 >> iter 74000, loss: 7.388705
 >> iter 75000, loss: 7.291095
 >> iter 76000, loss: 7.200334
 >> iter 77000, loss: 7.103942
 >> iter 78000, loss: 6.957086
 >> iter 79000, loss: 6.757375
 >> iter 80000, loss: 6.494243
   Number of active neurons: 10
 >> iter 81000, loss: 6.378169
 >> iter 82000, loss: 6.335221
 >> iter 83000, loss: 6.276843
 >> iter 84000, loss: 6.218420
 >> iter 85000, loss: 6.215209
 >> iter 86000, loss: 6.184660
 >> iter 87000, loss: 6.194254
 >> iter 88000, loss: 6.163141
 >> iter 89000, loss: 6.177001
 >> iter 90000, loss: 6.154814
   Number of active neurons: 10
 >> iter 91000, loss: 6.153775
 >> iter 92000, loss: 6.147470
 >> iter 93000, loss: 6.148637
 >> iter 94000, loss: 6.132821
 >> iter 95000, loss: 6.142295
 >> iter 96000, loss: 6.132646
 >> iter 97000, loss: 6.152150
 >> iter 98000, loss: 6.124094
 >> iter 99000, loss: 6.137519
 >> iter 100000, loss: 6.133644
   Number of active neurons: 10
 >> iter 101000, loss: 6.135792
 >> iter 102000, loss: 6.115046
 >> iter 103000, loss: 6.125216
 >> iter 104000, loss: 6.099099
 >> iter 105000, loss: 6.067323
 >> iter 106000, loss: 6.011349
 >> iter 107000, loss: 5.973878
 >> iter 108000, loss: 5.790629
 >> iter 109000, loss: 5.698885
 >> iter 110000, loss: 5.438996
   Number of active neurons: 10
 >> iter 111000, loss: 5.212545
 >> iter 112000, loss: 4.683140
 >> iter 113000, loss: 3.722981
 >> iter 114000, loss: 2.322094
 >> iter 115000, loss: 1.525305
 >> iter 116000, loss: 1.017302
 >> iter 117000, loss: 0.892095
 >> iter 118000, loss: 0.665144
 >> iter 119000, loss: 0.814552
 >> iter 120000, loss: 0.581812
   Number of active neurons: 10
 >> iter 121000, loss: 0.574947
 >> iter 122000, loss: 0.335165
 >> iter 123000, loss: 0.473634
 >> iter 124000, loss: 0.364225
 >> iter 125000, loss: 0.344240
 >> iter 126000, loss: 0.162756
 >> iter 127000, loss: 0.109507
 >> iter 128000, loss: 0.294157
 >> iter 129000, loss: 0.323500
 >> iter 130000, loss: 0.412086
   Number of active neurons: 10
 >> iter 131000, loss: 0.477682
 >> iter 132000, loss: 0.463136
 >> iter 133000, loss: 0.319601
 >> iter 134000, loss: 0.230692
 >> iter 135000, loss: 0.204378
 >> iter 136000, loss: 0.223976
 >> iter 137000, loss: 0.177700
 >> iter 138000, loss: 0.178377
 >> iter 139000, loss: 0.242427
 >> iter 140000, loss: 0.114513
   Number of active neurons: 10
 >> iter 141000, loss: 0.128976
 >> iter 142000, loss: 0.234365
 >> iter 143000, loss: 0.148430
 >> iter 144000, loss: 0.102420
 >> iter 145000, loss: 0.081953
 >> iter 146000, loss: 0.126709
 >> iter 147000, loss: 0.158291
 >> iter 148000, loss: 0.094822
 >> iter 149000, loss: 0.184623
 >> iter 150000, loss: 0.156754
   Number of active neurons: 10
 >> iter 151000, loss: 0.199300
 >> iter 152000, loss: 0.161940
 >> iter 153000, loss: 0.209545
 >> iter 154000, loss: 0.154825
 >> iter 155000, loss: 0.073926
 >> iter 156000, loss: 0.134224
 >> iter 157000, loss: 0.100660
 >> iter 158000, loss: 0.169658
 >> iter 159000, loss: 0.308775
 >> iter 160000, loss: 0.186765
   Number of active neurons: 10
 >> iter 161000, loss: 0.099855
 >> iter 162000, loss: 0.055600
 >> iter 163000, loss: 0.114316
 >> iter 164000, loss: 0.076890
 >> iter 165000, loss: 0.120417
 >> iter 166000, loss: 0.077671
 >> iter 167000, loss: 0.045505
 >> iter 168000, loss: 0.066580
 >> iter 169000, loss: 0.135947
 >> iter 170000, loss: 0.061650
   Number of active neurons: 10
 >> iter 171000, loss: 0.062413
 >> iter 172000, loss: 0.060844
 >> iter 173000, loss: 0.119806
 >> iter 174000, loss: 0.152084
 >> iter 175000, loss: 0.093055
 >> iter 176000, loss: 0.094606
 >> iter 177000, loss: 0.108947
 >> iter 178000, loss: 0.102707
 >> iter 179000, loss: 0.051375
 >> iter 180000, loss: 0.072991
   Number of active neurons: 10
 >> iter 181000, loss: 0.053654
 >> iter 182000, loss: 0.032374
 >> iter 183000, loss: 0.118834
 >> iter 184000, loss: 0.111166
 >> iter 185000, loss: 0.149319
 >> iter 186000, loss: 0.105756
 >> iter 187000, loss: 0.054568
 >> iter 188000, loss: 0.057257
 >> iter 189000, loss: 0.154252
 >> iter 190000, loss: 0.110346
   Number of active neurons: 10
 >> iter 191000, loss: 0.087758
 >> iter 192000, loss: 0.067665
 >> iter 193000, loss: 0.037196
 >> iter 194000, loss: 0.051200
 >> iter 195000, loss: 0.039724
 >> iter 196000, loss: 0.032881
 >> iter 197000, loss: 0.093043
 >> iter 198000, loss: 0.082706
 >> iter 199000, loss: 0.091180
 >> iter 200000, loss: 0.131100
   Number of active neurons: 10
 >> iter 201000, loss: 0.126517
 >> iter 202000, loss: 0.084328
 >> iter 203000, loss: 0.056931
 >> iter 204000, loss: 0.061400
 >> iter 205000, loss: 0.084471
 >> iter 206000, loss: 0.081354
 >> iter 207000, loss: 0.067680
 >> iter 208000, loss: 0.031406
 >> iter 209000, loss: 0.162424
 >> iter 210000, loss: 0.095265
   Number of active neurons: 10
 >> iter 211000, loss: 0.086382
 >> iter 212000, loss: 0.200668
 >> iter 213000, loss: 0.099074
 >> iter 214000, loss: 0.058764
 >> iter 215000, loss: 0.176811
 >> iter 216000, loss: 0.114967
 >> iter 217000, loss: 0.055685
 >> iter 218000, loss: 0.096151
 >> iter 219000, loss: 0.045970
 >> iter 220000, loss: 0.026654
   Number of active neurons: 10
 >> iter 221000, loss: 0.183255
 >> iter 222000, loss: 0.164010
 >> iter 223000, loss: 0.073958
 >> iter 224000, loss: 0.054588
 >> iter 225000, loss: 0.031405
 >> iter 226000, loss: 0.046174
 >> iter 227000, loss: 0.037346
 >> iter 228000, loss: 0.028640
 >> iter 229000, loss: 0.030415
 >> iter 230000, loss: 0.037548
   Number of active neurons: 10
 >> iter 231000, loss: 0.026874
 >> iter 232000, loss: 0.023959
 >> iter 233000, loss: 0.015906
 >> iter 234000, loss: 0.106130
 >> iter 235000, loss: 0.043501
 >> iter 236000, loss: 0.085499
 >> iter 237000, loss: 0.036215
 >> iter 238000, loss: 0.022152
 >> iter 239000, loss: 0.104887
 >> iter 240000, loss: 0.059726
   Number of active neurons: 10
 >> iter 241000, loss: 0.094703
 >> iter 242000, loss: 0.044347
 >> iter 243000, loss: 0.056691
 >> iter 244000, loss: 0.118605
 >> iter 245000, loss: 0.093667
 >> iter 246000, loss: 0.041760
 >> iter 247000, loss: 0.050219
 >> iter 248000, loss: 0.057713
 >> iter 249000, loss: 0.065471
 >> iter 250000, loss: 0.039429
   Number of active neurons: 10
 >> iter 251000, loss: 0.030885
 >> iter 252000, loss: 0.125542
 >> iter 253000, loss: 0.062759
 >> iter 254000, loss: 0.053426
 >> iter 255000, loss: 0.025546
 >> iter 256000, loss: 0.046014
 >> iter 257000, loss: 0.028178
 >> iter 258000, loss: 0.021567
 >> iter 259000, loss: 0.049835
 >> iter 260000, loss: 0.038041
   Number of active neurons: 10
 >> iter 261000, loss: 0.022416
 >> iter 262000, loss: 0.044799
 >> iter 263000, loss: 0.030447
 >> iter 264000, loss: 0.033145
 >> iter 265000, loss: 0.015611
 >> iter 266000, loss: 0.068925
 >> iter 267000, loss: 0.030258
 >> iter 268000, loss: 0.019651
 >> iter 269000, loss: 0.020986
 >> iter 270000, loss: 0.014245
   Number of active neurons: 10
 >> iter 271000, loss: 0.016559
 >> iter 272000, loss: 0.010979
 >> iter 273000, loss: 0.007229
 >> iter 274000, loss: 0.012201
 >> iter 275000, loss: 0.018208
 >> iter 276000, loss: 0.019517
 >> iter 277000, loss: 0.026212
 >> iter 278000, loss: 0.016992
 >> iter 279000, loss: 0.016763
 >> iter 280000, loss: 0.008416
   Number of active neurons: 10
 >> iter 281000, loss: 0.007100
 >> iter 282000, loss: 0.005638
 >> iter 283000, loss: 0.004835
 >> iter 284000, loss: 0.052147
 >> iter 285000, loss: 0.049916
 >> iter 286000, loss: 0.041752
 >> iter 287000, loss: 0.039641
 >> iter 288000, loss: 0.021724
 >> iter 289000, loss: 0.011831
 >> iter 290000, loss: 0.050619
   Number of active neurons: 10
 >> iter 291000, loss: 0.107822
 >> iter 292000, loss: 0.091506
 >> iter 293000, loss: 0.075195
 >> iter 294000, loss: 0.030791
 >> iter 295000, loss: 0.027684
 >> iter 296000, loss: 0.013596
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.687641
 >> iter 2000, loss: 11.201638
 >> iter 3000, loss: 8.972975
 >> iter 4000, loss: 8.163740
 >> iter 5000, loss: 7.835452
 >> iter 6000, loss: 7.744079
 >> iter 7000, loss: 7.644550
 >> iter 8000, loss: 7.602265
 >> iter 9000, loss: 7.611142
 >> iter 10000, loss: 7.589820
   Number of active neurons: 10
 >> iter 11000, loss: 7.577971
 >> iter 12000, loss: 7.563946
 >> iter 13000, loss: 7.575946
 >> iter 14000, loss: 7.558130
 >> iter 15000, loss: 7.560836
 >> iter 16000, loss: 7.561612
 >> iter 17000, loss: 7.566250
 >> iter 18000, loss: 7.550645
 >> iter 19000, loss: 7.560454
 >> iter 20000, loss: 7.559166
   Number of active neurons: 10
 >> iter 21000, loss: 7.553907
 >> iter 22000, loss: 7.538331
 >> iter 23000, loss: 7.545918
 >> iter 24000, loss: 7.539086
 >> iter 25000, loss: 7.557089
 >> iter 26000, loss: 7.538066
 >> iter 27000, loss: 7.539277
 >> iter 28000, loss: 7.534275
 >> iter 29000, loss: 7.548358
 >> iter 30000, loss: 7.542683
   Number of active neurons: 10
 >> iter 31000, loss: 7.550029
 >> iter 32000, loss: 7.535074
 >> iter 33000, loss: 7.539806
 >> iter 34000, loss: 7.538717
 >> iter 35000, loss: 7.575305
 >> iter 36000, loss: 7.562784
 >> iter 37000, loss: 7.551562
 >> iter 38000, loss: 7.561557
 >> iter 39000, loss: 7.554265
 >> iter 40000, loss: 7.533472
   Number of active neurons: 10
 >> iter 41000, loss: 7.539937
 >> iter 42000, loss: 7.583309
 >> iter 43000, loss: 7.557505
 >> iter 44000, loss: 7.577816
 >> iter 45000, loss: 7.556155
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 46000, loss: 7.530548
 >> iter 47000, loss: 7.534385
 >> iter 48000, loss: 7.525911
 >> iter 49000, loss: 7.536908
 >> iter 50000, loss: 7.517938
   Number of active neurons: 9
 >> iter 51000, loss: 7.534383
 >> iter 52000, loss: 7.516647
 >> iter 53000, loss: 7.534461
 >> iter 54000, loss: 7.521027
 >> iter 55000, loss: 7.529918
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 56000, loss: 7.520481
 >> iter 57000, loss: 7.538068
 >> iter 58000, loss: 7.517775
 >> iter 59000, loss: 7.533671
 >> iter 60000, loss: 7.522700
   Number of active neurons: 9
 >> iter 61000, loss: 7.535951
 >> iter 62000, loss: 7.522463
 >> iter 63000, loss: 7.530607
 >> iter 64000, loss: 7.517315
 >> iter 65000, loss: 7.529857
   Number of active neurons: 8
   SHOCK
   Setting new limit to 275000.0 iters...
 >> iter 66000, loss: 7.517959
 >> iter 67000, loss: 7.532762
 >> iter 68000, loss: 7.521936
 >> iter 69000, loss: 7.535588
 >> iter 70000, loss: 7.520303
   Number of active neurons: 8
 >> iter 71000, loss: 7.532272
 >> iter 72000, loss: 7.520402
 >> iter 73000, loss: 7.532953
 >> iter 74000, loss: 7.522406
 >> iter 75000, loss: 7.531526
   Number of active neurons: 8
   SHOCK
   Setting new limit to 287500.0 iters...
 >> iter 76000, loss: 7.521375
 >> iter 77000, loss: 7.530766
 >> iter 78000, loss: 7.524045
 >> iter 79000, loss: 7.530607
 >> iter 80000, loss: 7.521284
   Number of active neurons: 8
 >> iter 81000, loss: 7.528088
 >> iter 82000, loss: 7.522835
 >> iter 83000, loss: 7.525835
 >> iter 84000, loss: 7.522087
 >> iter 85000, loss: 7.526857
   Number of active neurons: 8
   SHOCK
   Setting new limit to 293750.0 iters...
 >> iter 86000, loss: 7.522101
 >> iter 87000, loss: 7.529755
 >> iter 88000, loss: 7.523110
 >> iter 89000, loss: 7.521810
 >> iter 90000, loss: 7.520361
   Number of active neurons: 8
 >> iter 91000, loss: 7.519228
 >> iter 92000, loss: 7.522368
 >> iter 93000, loss: 7.520755
 >> iter 94000, loss: 7.523415
 >> iter 95000, loss: 7.525745
   Number of active neurons: 8
   SHOCK
   Setting new limit to 296875.0 iters...
 >> iter 96000, loss: 7.523353
 >> iter 97000, loss: 7.526445
 >> iter 98000, loss: 7.523589
 >> iter 99000, loss: 7.525993
 >> iter 100000, loss: 7.526645
   Number of active neurons: 8
   SHOCK
   Setting new limit to 298437.5 iters...
   Number of active neurons: 8
 >> iter 101000, loss: 7.527706
 >> iter 102000, loss: 7.526741
 >> iter 103000, loss: 7.523557
 >> iter 104000, loss: 7.527024
 >> iter 105000, loss: 7.524270
 >> iter 106000, loss: 7.527860
 >> iter 107000, loss: 7.518002
 >> iter 108000, loss: 7.528521
 >> iter 109000, loss: 7.535027
 >> iter 110000, loss: 7.553227
   Number of active neurons: 9
   SHOCK
   Setting new limit to 299218.75 iters...
   Number of active neurons: 9
 >> iter 111000, loss: 7.534581
 >> iter 112000, loss: 7.509480
 >> iter 113000, loss: 7.513095
 >> iter 114000, loss: 7.462215
 >> iter 115000, loss: 7.389230
 >> iter 116000, loss: 7.272664
 >> iter 117000, loss: 7.132860
 >> iter 118000, loss: 6.984077
 >> iter 119000, loss: 6.855058
 >> iter 120000, loss: 6.715769
   Number of active neurons: 10
 >> iter 121000, loss: 6.557282
 >> iter 122000, loss: 6.453875
 >> iter 123000, loss: 6.377387
 >> iter 124000, loss: 6.334465
 >> iter 125000, loss: 6.332758
 >> iter 126000, loss: 6.289570
 >> iter 127000, loss: 6.271830
 >> iter 128000, loss: 6.244956
 >> iter 129000, loss: 6.246308
 >> iter 130000, loss: 6.220021
   Number of active neurons: 10
 >> iter 131000, loss: 6.225934
 >> iter 132000, loss: 6.245383
 >> iter 133000, loss: 6.272534
 >> iter 134000, loss: 6.226728
 >> iter 135000, loss: 6.260050
 >> iter 136000, loss: 6.210974
 >> iter 137000, loss: 6.209487
 >> iter 138000, loss: 6.174369
 >> iter 139000, loss: 6.286354
 >> iter 140000, loss: 6.211949
   Number of active neurons: 10
 >> iter 141000, loss: 6.236251
 >> iter 142000, loss: 6.147978
 >> iter 143000, loss: 6.132422
 >> iter 144000, loss: 6.099231
 >> iter 145000, loss: 6.062966
 >> iter 146000, loss: 6.019125
 >> iter 147000, loss: 5.989327
 >> iter 148000, loss: 5.969740
 >> iter 149000, loss: 5.938479
 >> iter 150000, loss: 5.890602
   Number of active neurons: 10
 >> iter 151000, loss: 5.862449
 >> iter 152000, loss: 5.814501
 >> iter 153000, loss: 5.782880
 >> iter 154000, loss: 5.777347
 >> iter 155000, loss: 5.750512
 >> iter 156000, loss: 5.714214
 >> iter 157000, loss: 5.806233
 >> iter 158000, loss: 5.677285
 >> iter 159000, loss: 5.625085
 >> iter 160000, loss: 5.600183
   Number of active neurons: 10
 >> iter 161000, loss: 5.533303
 >> iter 162000, loss: 5.551707
 >> iter 163000, loss: 5.494422
 >> iter 164000, loss: 5.441457
 >> iter 165000, loss: 5.331745
 >> iter 166000, loss: 5.412604
 >> iter 167000, loss: 5.247398
 >> iter 168000, loss: 5.117908
 >> iter 169000, loss: 4.823508
 >> iter 170000, loss: 4.672250
   Number of active neurons: 10
 >> iter 171000, loss: 4.697227
 >> iter 172000, loss: 4.581056
 >> iter 173000, loss: 4.526529
 >> iter 174000, loss: 4.512464
 >> iter 175000, loss: 4.203584
 >> iter 176000, loss: 4.013115
 >> iter 177000, loss: 3.774236
 >> iter 178000, loss: 3.546831
 >> iter 179000, loss: 3.182438
 >> iter 180000, loss: 2.890967
   Number of active neurons: 10
 >> iter 181000, loss: 2.867274
 >> iter 182000, loss: 2.856185
 >> iter 183000, loss: 2.683096
 >> iter 184000, loss: 2.661946
 >> iter 185000, loss: 2.684635
 >> iter 186000, loss: 2.713779
 >> iter 187000, loss: 2.502121
 >> iter 188000, loss: 2.478552
 >> iter 189000, loss: 2.225532
 >> iter 190000, loss: 2.306859
   Number of active neurons: 10
 >> iter 191000, loss: 2.201656
 >> iter 192000, loss: 2.190586
 >> iter 193000, loss: 2.393494
 >> iter 194000, loss: 2.404397
 >> iter 195000, loss: 2.352194
 >> iter 196000, loss: 2.431852
 >> iter 197000, loss: 2.384078
 >> iter 198000, loss: 2.576566
 >> iter 199000, loss: 2.549111
 >> iter 200000, loss: 2.404015
   Number of active neurons: 10
 >> iter 201000, loss: 2.400514
 >> iter 202000, loss: 2.219097
 >> iter 203000, loss: 2.108743
 >> iter 204000, loss: 2.078166
 >> iter 205000, loss: 1.835579
 >> iter 206000, loss: 1.844511
 >> iter 207000, loss: 1.748820
 >> iter 208000, loss: 1.616314
 >> iter 209000, loss: 1.423410
 >> iter 210000, loss: 1.611971
   Number of active neurons: 10
 >> iter 211000, loss: 1.393717
 >> iter 212000, loss: 1.546964
 >> iter 213000, loss: 1.354164
 >> iter 214000, loss: 1.549830
 >> iter 215000, loss: 1.665541
 >> iter 216000, loss: 1.936935
 >> iter 217000, loss: 1.708543
 >> iter 218000, loss: 1.452481
 >> iter 219000, loss: 1.228153
 >> iter 220000, loss: 1.212426
   Number of active neurons: 10
 >> iter 221000, loss: 1.031700
 >> iter 222000, loss: 1.063984
 >> iter 223000, loss: 1.179396
 >> iter 224000, loss: 1.314213
 >> iter 225000, loss: 1.059320
 >> iter 226000, loss: 1.393424
 >> iter 227000, loss: 1.224700
 >> iter 228000, loss: 1.313399
 >> iter 229000, loss: 1.265569
 >> iter 230000, loss: 1.317415
   Number of active neurons: 10
 >> iter 231000, loss: 1.144154
 >> iter 232000, loss: 1.100580
 >> iter 233000, loss: 1.229272
 >> iter 234000, loss: 1.232838
 >> iter 235000, loss: 1.106135
 >> iter 236000, loss: 1.184538
 >> iter 237000, loss: 0.941852
 >> iter 238000, loss: 1.046639
 >> iter 239000, loss: 1.273781
 >> iter 240000, loss: 1.242465
   Number of active neurons: 10
 >> iter 241000, loss: 0.924396
 >> iter 242000, loss: 0.786630
 >> iter 243000, loss: 0.679974
 >> iter 244000, loss: 0.780178
 >> iter 245000, loss: 0.793745
 >> iter 246000, loss: 0.832563
 >> iter 247000, loss: 0.635434
 >> iter 248000, loss: 0.788166
 >> iter 249000, loss: 0.637821
 >> iter 250000, loss: 0.930083
   Number of active neurons: 10
 >> iter 251000, loss: 0.879374
 >> iter 252000, loss: 1.052810
 >> iter 253000, loss: 0.858916
 >> iter 254000, loss: 0.767108
 >> iter 255000, loss: 0.895739
 >> iter 256000, loss: 0.732499
 >> iter 257000, loss: 0.707324
 >> iter 258000, loss: 1.014328
 >> iter 259000, loss: 0.929455
 >> iter 260000, loss: 0.750774
   Number of active neurons: 10
 >> iter 261000, loss: 0.580678
 >> iter 262000, loss: 0.782973
 >> iter 263000, loss: 0.647610
 >> iter 264000, loss: 0.797972
 >> iter 265000, loss: 0.827571
 >> iter 266000, loss: 0.969204
 >> iter 267000, loss: 0.831301
 >> iter 268000, loss: 0.755351
 >> iter 269000, loss: 0.677193
 >> iter 270000, loss: 0.853960
   Number of active neurons: 10
 >> iter 271000, loss: 0.723878
 >> iter 272000, loss: 0.811025
 >> iter 273000, loss: 0.743662
 >> iter 274000, loss: 0.707197
 >> iter 275000, loss: 0.741711
 >> iter 276000, loss: 0.566620
 >> iter 277000, loss: 0.591299
 >> iter 278000, loss: 0.730743
 >> iter 279000, loss: 0.555725
 >> iter 280000, loss: 0.737062
   Number of active neurons: 10
 >> iter 281000, loss: 0.590886
 >> iter 282000, loss: 0.612384
 >> iter 283000, loss: 0.614561
 >> iter 284000, loss: 0.781706
 >> iter 285000, loss: 0.670007
 >> iter 286000, loss: 0.623388
 >> iter 287000, loss: 0.636394
 >> iter 288000, loss: 0.643297
 >> iter 289000, loss: 0.544124
 >> iter 290000, loss: 0.594439
   Number of active neurons: 10
 >> iter 291000, loss: 0.657281
 >> iter 292000, loss: 0.955776
 >> iter 293000, loss: 0.897796
 >> iter 294000, loss: 0.691460
 >> iter 295000, loss: 0.881986
 >> iter 296000, loss: 1.065983
 >> iter 297000, loss: 1.016159
 >> iter 298000, loss: 0.832527
 >> iter 299000, loss: 0.608426
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.77598448031
   - Test - Long: 8.58457077146
   - Test - Big: 0.688993110069
   - Test - A: 0.0
   - Test - B: 0.0199986667556
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 16.696972
 >> iter 2000, loss: 11.231009
 >> iter 3000, loss: 8.995398
 >> iter 4000, loss: 8.134239
 >> iter 5000, loss: 7.802464
 >> iter 6000, loss: 7.650573
 >> iter 7000, loss: 7.741096
 >> iter 8000, loss: 7.655801
 >> iter 9000, loss: 7.617867
 >> iter 10000, loss: 7.578589
   Number of active neurons: 10
 >> iter 11000, loss: 7.590413
 >> iter 12000, loss: 7.573392
 >> iter 13000, loss: 7.562104
 >> iter 14000, loss: 7.546859
 >> iter 15000, loss: 7.598955
 >> iter 16000, loss: 7.563345
 >> iter 17000, loss: 7.559678
 >> iter 18000, loss: 7.548016
 >> iter 19000, loss: 7.603716
 >> iter 20000, loss: 7.562524
   Number of active neurons: 10
 >> iter 21000, loss: 7.572030
 >> iter 22000, loss: 7.582340
 >> iter 23000, loss: 7.565394
 >> iter 24000, loss: 7.568789
 >> iter 25000, loss: 7.553998
 >> iter 26000, loss: 7.542019
 >> iter 27000, loss: 7.560892
 >> iter 28000, loss: 7.568049
 >> iter 29000, loss: 7.559796
 >> iter 30000, loss: 7.556214
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 31000, loss: 7.548432
 >> iter 32000, loss: 7.538322
 >> iter 33000, loss: 7.542099
 >> iter 34000, loss: 7.525703
 >> iter 35000, loss: 7.604245
 >> iter 36000, loss: 7.560683
 >> iter 37000, loss: 7.552077
 >> iter 38000, loss: 7.531088
 >> iter 39000, loss: 7.539146
 >> iter 40000, loss: 7.528792
   Number of active neurons: 9
 >> iter 41000, loss: 7.537471
 >> iter 42000, loss: 7.526791
 >> iter 43000, loss: 7.532451
 >> iter 44000, loss: 7.521877
 >> iter 45000, loss: 7.528513
 >> iter 46000, loss: 7.518278
 >> iter 47000, loss: 7.562094
 >> iter 48000, loss: 7.533033
 >> iter 49000, loss: 7.537315
 >> iter 50000, loss: 7.521841
   Number of active neurons: 8
 >> iter 51000, loss: 7.535660
 >> iter 52000, loss: 7.518438
 >> iter 53000, loss: 7.534465
 >> iter 54000, loss: 7.521700
 >> iter 55000, loss: 7.532753
   Number of active neurons: 7
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 56000, loss: 7.520552
 >> iter 57000, loss: 7.529322
 >> iter 58000, loss: 7.516987
 >> iter 59000, loss: 7.551039
 >> iter 60000, loss: 7.528551
   Number of active neurons: 7
 >> iter 61000, loss: 7.532479
 >> iter 62000, loss: 7.519614
 >> iter 63000, loss: 7.532999
 >> iter 64000, loss: 7.532851
 >> iter 65000, loss: 7.535090
   Number of active neurons: 7
   SHOCK
   Setting new limit to 275000.0 iters...
 >> iter 66000, loss: 7.524160
 >> iter 67000, loss: 7.533090
 >> iter 68000, loss: 7.521021
 >> iter 69000, loss: 7.532310
 >> iter 70000, loss: 7.520911
   Number of active neurons: 9
 >> iter 71000, loss: 7.528373
 >> iter 72000, loss: 7.526763
 >> iter 73000, loss: 7.534047
 >> iter 74000, loss: 7.523061
 >> iter 75000, loss: 7.531042
   Number of active neurons: 9
   SHOCK
   Setting new limit to 287500.0 iters...
 >> iter 76000, loss: 7.521880
 >> iter 77000, loss: 7.533076
 >> iter 78000, loss: 7.523693
 >> iter 79000, loss: 7.530353
 >> iter 80000, loss: 7.521557
   Number of active neurons: 8
 >> iter 81000, loss: 7.528704
 >> iter 82000, loss: 7.523121
 >> iter 83000, loss: 7.529449
 >> iter 84000, loss: 7.523444
 >> iter 85000, loss: 7.528327
   Number of active neurons: 9
   SHOCK
   Setting new limit to 293750.0 iters...
 >> iter 86000, loss: 7.521477
 >> iter 87000, loss: 7.531302
 >> iter 88000, loss: 7.525382
 >> iter 89000, loss: 7.526746
 >> iter 90000, loss: 7.525774
   Number of active neurons: 8
 >> iter 91000, loss: 7.524897
 >> iter 92000, loss: 7.525665
 >> iter 93000, loss: 7.526689
 >> iter 94000, loss: 7.529492
 >> iter 95000, loss: 7.524687
 >> iter 96000, loss: 7.528316
 >> iter 97000, loss: 7.545079
 >> iter 98000, loss: 7.534321
 >> iter 99000, loss: 7.530667
 >> iter 100000, loss: 7.530159
   Number of active neurons: 8
   SHOCK
   Setting new limit to 296875.0 iters...
   Number of active neurons: 8
 >> iter 101000, loss: 7.526326
 >> iter 102000, loss: 7.529298
 >> iter 103000, loss: 7.524393
 >> iter 104000, loss: 7.526950
 >> iter 105000, loss: 7.526919
 >> iter 106000, loss: 7.527914
 >> iter 107000, loss: 7.526879
 >> iter 108000, loss: 7.573238
 >> iter 109000, loss: 7.545202
 >> iter 110000, loss: 7.535620
   Number of active neurons: 8
   SHOCK
   Setting new limit to 298437.5 iters...
   Number of active neurons: 8
 >> iter 111000, loss: 7.532743
 >> iter 112000, loss: 7.564738
 >> iter 113000, loss: 7.545570
 >> iter 114000, loss: 7.533086
 >> iter 115000, loss: 7.533450
 >> iter 116000, loss: 7.535457
 >> iter 117000, loss: 7.533945
 >> iter 118000, loss: 7.525473
 >> iter 119000, loss: 7.530036
 >> iter 120000, loss: 7.527261
   Number of active neurons: 8
 >> iter 121000, loss: 7.527434
 >> iter 122000, loss: 7.527061
 >> iter 123000, loss: 7.530605
 >> iter 124000, loss: 7.526704
 >> iter 125000, loss: 7.535489
   Number of active neurons: 8
   SHOCK
   Setting new limit to 299218.75 iters...
 >> iter 126000, loss: 7.527242
 >> iter 127000, loss: 7.533593
 >> iter 128000, loss: 7.526546
 >> iter 129000, loss: 7.530503
 >> iter 130000, loss: 7.527178
   Number of active neurons: 8
 >> iter 131000, loss: 7.534204
 >> iter 132000, loss: 7.527352
 >> iter 133000, loss: 7.534324
 >> iter 134000, loss: 7.524313
 >> iter 135000, loss: 7.529118
   Number of active neurons: 8
   SHOCK
   Setting new limit to 299609.375 iters...
 >> iter 136000, loss: 7.525648
 >> iter 137000, loss: 7.532537
 >> iter 138000, loss: 7.528434
 >> iter 139000, loss: 7.534477
 >> iter 140000, loss: 7.525328
   Number of active neurons: 8
 >> iter 141000, loss: 7.532921
 >> iter 142000, loss: 7.523178
 >> iter 143000, loss: 7.529484
 >> iter 144000, loss: 7.526850
 >> iter 145000, loss: 7.529369
   Number of active neurons: 8
   SHOCK
   Setting new limit to 299804.6875 iters...
 >> iter 146000, loss: 7.525390
 >> iter 147000, loss: 7.533363
 >> iter 148000, loss: 7.527095
 >> iter 149000, loss: 7.527954
 >> iter 150000, loss: 7.530584
   Number of active neurons: 8
   SHOCK
   Setting new limit to 299902.34375 iters...
   Number of active neurons: 8
 >> iter 151000, loss: 7.532012
 >> iter 152000, loss: 7.531689
 >> iter 153000, loss: 7.529812
 >> iter 154000, loss: 7.531765
 >> iter 155000, loss: 7.530390
 >> iter 156000, loss: 7.529848
 >> iter 157000, loss: 7.528556
 >> iter 158000, loss: 7.527319
 >> iter 159000, loss: 7.527636
 >> iter 160000, loss: 7.531892
   Number of active neurons: 8
   SHOCK
   Setting new limit to 299951.171875 iters...
   Number of active neurons: 8
 >> iter 161000, loss: 7.525484
 >> iter 162000, loss: 7.531258
 >> iter 163000, loss: 7.526861
 >> iter 164000, loss: 7.525840
 >> iter 165000, loss: 7.517575
 >> iter 166000, loss: 7.540814
 >> iter 167000, loss: 7.640617
 >> iter 168000, loss: 7.529367
 >> iter 169000, loss: 7.383028
 >> iter 170000, loss: 7.272945
   Number of active neurons: 10
 >> iter 171000, loss: 7.118422
 >> iter 172000, loss: 6.971331
 >> iter 173000, loss: 6.706268
 >> iter 174000, loss: 6.613077
 >> iter 175000, loss: 6.551011
 >> iter 176000, loss: 6.459029
 >> iter 177000, loss: 6.348886
 >> iter 178000, loss: 6.332715
 >> iter 179000, loss: 6.314456
 >> iter 180000, loss: 6.304720
   Number of active neurons: 10
 >> iter 181000, loss: 6.246056
 >> iter 182000, loss: 6.247986
 >> iter 183000, loss: 6.218590
 >> iter 184000, loss: 6.200204
 >> iter 185000, loss: 6.139920
 >> iter 186000, loss: 6.130551
 >> iter 187000, loss: 6.086142
 >> iter 188000, loss: 6.087723
 >> iter 189000, loss: 6.021037
 >> iter 190000, loss: 5.971804
   Number of active neurons: 10
 >> iter 191000, loss: 5.850081
 >> iter 192000, loss: 5.742903
 >> iter 193000, loss: 5.673568
 >> iter 194000, loss: 5.565424
 >> iter 195000, loss: 5.511156
 >> iter 196000, loss: 5.425781
 >> iter 197000, loss: 5.400109
 >> iter 198000, loss: 5.391956
 >> iter 199000, loss: 5.329038
 >> iter 200000, loss: 5.300735
   Number of active neurons: 10
 >> iter 201000, loss: 5.286650
 >> iter 202000, loss: 5.254446
 >> iter 203000, loss: 5.268356
 >> iter 204000, loss: 5.255401
 >> iter 205000, loss: 5.225446
 >> iter 206000, loss: 5.124467
 >> iter 207000, loss: 4.974937
 >> iter 208000, loss: 4.782873
 >> iter 209000, loss: 4.602957
 >> iter 210000, loss: 4.706879
   Number of active neurons: 10
 >> iter 211000, loss: 4.442666
 >> iter 212000, loss: 4.281251
 >> iter 213000, loss: 4.073492
 >> iter 214000, loss: 4.206225
 >> iter 215000, loss: 4.225647
 >> iter 216000, loss: 4.278913
 >> iter 217000, loss: 4.188738
 >> iter 218000, loss: 4.134093
 >> iter 219000, loss: 4.149227
 >> iter 220000, loss: 3.985822
   Number of active neurons: 10
 >> iter 221000, loss: 3.861036
 >> iter 222000, loss: 4.023288
 >> iter 223000, loss: 4.072054
 >> iter 224000, loss: 3.881008
 >> iter 225000, loss: 3.786997
 >> iter 226000, loss: 3.906141
 >> iter 227000, loss: 3.790114
 >> iter 228000, loss: 4.032407
 >> iter 229000, loss: 3.785038
 >> iter 230000, loss: 3.891946
   Number of active neurons: 10
 >> iter 231000, loss: 3.725166
 >> iter 232000, loss: 3.847694
 >> iter 233000, loss: 3.624301
 >> iter 234000, loss: 3.646206
 >> iter 235000, loss: 3.582293
 >> iter 236000, loss: 3.629863
 >> iter 237000, loss: 3.651737
 >> iter 238000, loss: 3.638992
 >> iter 239000, loss: 3.469914
 >> iter 240000, loss: 2.936091
   Number of active neurons: 10
 >> iter 241000, loss: 2.006085
 >> iter 242000, loss: 1.375454
 >> iter 243000, loss: 0.853355
 >> iter 244000, loss: 0.924242
 >> iter 245000, loss: 0.992236
 >> iter 246000, loss: 0.843418
 >> iter 247000, loss: 1.001842
 >> iter 248000, loss: 0.689895
 >> iter 249000, loss: 0.443090
 >> iter 250000, loss: 0.397386
   Number of active neurons: 10
 >> iter 251000, loss: 0.722911
 >> iter 252000, loss: 0.828498
 >> iter 253000, loss: 0.842625
 >> iter 254000, loss: 0.581680
 >> iter 255000, loss: 0.706601
 >> iter 256000, loss: 0.808787
 >> iter 257000, loss: 0.495042
 >> iter 258000, loss: 0.588837
 >> iter 259000, loss: 0.470296
 >> iter 260000, loss: 0.288268
   Number of active neurons: 10
 >> iter 261000, loss: 0.324381
 >> iter 262000, loss: 0.282140
 >> iter 263000, loss: 0.218807
 >> iter 264000, loss: 0.347538
 >> iter 265000, loss: 0.259049
 >> iter 266000, loss: 0.346067
 >> iter 267000, loss: 0.305311
 >> iter 268000, loss: 0.198297
 >> iter 269000, loss: 0.217816
 >> iter 270000, loss: 0.483161
   Number of active neurons: 10
 >> iter 271000, loss: 0.610676
 >> iter 272000, loss: 0.372675
 >> iter 273000, loss: 0.284634
 >> iter 274000, loss: 0.258296
 >> iter 275000, loss: 0.326851
 >> iter 276000, loss: 0.513688
 >> iter 277000, loss: 0.405436
 >> iter 278000, loss: 0.685250
 >> iter 279000, loss: 0.556081
 >> iter 280000, loss: 0.579326
   Number of active neurons: 10
 >> iter 281000, loss: 0.730036
 >> iter 282000, loss: 0.518565
 >> iter 283000, loss: 0.529999
 >> iter 284000, loss: 0.424327
 >> iter 285000, loss: 0.578155
 >> iter 286000, loss: 0.416663
 >> iter 287000, loss: 0.473923
 >> iter 288000, loss: 0.459130
 >> iter 289000, loss: 0.589962
 >> iter 290000, loss: 0.433824
   Number of active neurons: 10
 >> iter 291000, loss: 0.473394
 >> iter 292000, loss: 0.323317
 >> iter 293000, loss: 0.651398
 >> iter 294000, loss: 0.539440
 >> iter 295000, loss: 0.598122
 >> iter 296000, loss: 0.427858
 >> iter 297000, loss: 0.260809
 >> iter 298000, loss: 0.145029
 >> iter 299000, loss: 0.236338
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.207995840083
   - Test - Long: 0.0
   - Test - Big: 0.232997670023
   - Test - A: 0.43330444637
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

